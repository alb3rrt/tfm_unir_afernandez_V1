
# Improving the Transferability of Adversarial Examples with New Iteration Framework and Input Dropout

[arXiv](https://arxiv.org/abs/2106.01617), [PDF](https://arxiv.org/pdf/2106.01617.pdf)

## Authors

- Pengfei Xie
- Linyuan Wang
- Ruoxi Qin
- Kai Qiao
- Shuhao Shi
- Guoen Hu
- Bin Yan

## Abstract

Deep neural networks(DNNs) is vulnerable to be attacked by adversarial examples. Black-box attack is the most threatening attack. At present, black-box attack methods mainly adopt gradient-based iterative attack methods, which usually limit the relationship between the iteration step size, the number of iterations, and the maximum perturbation. In this paper, we propose a new gradient iteration framework, which redefines the relationship between the above three. Under this framework, we easily improve the attack success rate of DI-TI-MIM. In addition, we propose a gradient iterative attack method based on input dropout, which can be well combined with our framework. We further propose a multi dropout rate version of this method. Experimental results show that our best method can achieve attack success rate of 96.2\% for defense model on average, which is higher than the state-of-the-art gradient-based attacks.

## Comments



## Source Code

Official Code



Community Code

- [https://paperswithcode.com/paper/improving-the-transferability-of-adversarial-2](https://paperswithcode.com/paper/improving-the-transferability-of-adversarial-2)

## Bibtex

```tex
@misc{xie2021improving,
      title={Improving the Transferability of Adversarial Examples with New Iteration Framework and Input Dropout}, 
      author={Pengfei Xie and Linyuan Wang and Ruoxi Qin and Kai Qiao and Shuhao Shi and Guoen Hu and Bin Yan},
      year={2021},
      eprint={2106.01617},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```

## Notes

Type your reading notes here...

