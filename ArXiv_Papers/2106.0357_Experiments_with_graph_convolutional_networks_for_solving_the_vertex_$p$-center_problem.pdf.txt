arXiv:2106.00357v1 [cs.LG] 1 Jun 2021

Experiments with graph convolutional networks for solving the vertex p-center problem
Elisabeth Gaar1 and Markus Sinnl1,2
1Institute of Production and Logistics Management, Johannes Kepler University Linz, Linz, Austria
2JKU Business School, Johannes Kepler University Linz, Linz, Austria
Abstract In the last few years, graph convolutional networks (GCN) have become a popular research direction in the machine learning community to tackle NP-hard combinatorial optimization problems (COPs) defined on graphs. While the obtained results are usually still not competitive with problem-specific solution approaches from the operations research community, GCNs often lead to improvements compared to previous machine learning approaches for classical COPs such as the traveling salesperson problem (TSP). In this work we present a preliminary study on using GCNs for solving the vertex p-center problem (pCP), which is another classic COP on graphs. In particular, we investigate whether a successful model based on end-to-end training for the TSP can be adapted to a pCP, which is defined on a similar 2D Euclidean graph input as the usually used version of the TSP. However, the objective of the pCP has a min-max structure which could lead to many symmetric optimal, i.e., ground-truth solutions and other potential difficulties for learning. Our obtained preliminary results show that indeed a direct transfer of network architecture ideas does not seem to work too well. Thus we think that the pCP could be an interesting benchmark problem for new ideas and developments in the area of GCNs.
1 Introduction
In the last few years, graph convolutional networks (GCN) have become a popular research direction in the machine learning community to tackle NP-hard combinatorial optimization problems (COPs) defined on graphs (see, e.g., [3, 18]). In the operations research (OR) community NP-hard problems are usually formulated as integer programming (IP) problems, however, due to the theoretical difficulty, even with sophisticated IP solution frameworks solving large instances of such problems may become computationally intractable. Moreover, such solution frameworks often also need carefully handcrafted heuristics and additional problem-specific knowledge to work well. Thus, alternative approaches such as machine learning algorithms which can be trained to directly learn the solution from problem instances could offer an attractive solution strategy [1, 20].
Using advances in graph representation learning including GCNs, several COPs, such as the travelling salesperson problem (TSP) [15, 11, 12], the vertex cover problem, the maximum cut problem [5, 18] or graph matching [8] have been approach by end-to-end-approaches recently. However, the results in these works show that developing machine learning approaches that are competitive with specialized OR approaches is still an open question, see also the recent survey [3].
elisabeth.gaar@jku.at markus.sinnl@jku.at
1

In this work, we expand the existing literature on the use of GCN for COPs by applying it to the vertex-pcenter problem (pCP). The pCP is a fundamental problem in location science (see, e.g., [16]) and is formally defined as follows.
Definition 1 (Vertex p-center problem). Let p be an integer, I be a set of customer demand points with cardinality |I| = n and J be a set of potential facility locations with cardinality |J| = m  p. Furthermore let d be a distance function such that dij is the distance between each customer demand point i  I and potential facility location j  J. The goal is to find a subset S  J of facilities with cardinality |S| = p to open such that the maximum distance between a customer demand point and its closest open facility is minimized, i.e. such that maxiI minjS{dij} is minimized.
Following the standard convention used in the OR community, in the remainder of this paper we use I = J = V . Similar to approaches for the TSP [11, 12], we focus on instances which are defined on the 2D Euclidean plane, i.e., each point i  V has coordinates xi  Z2. These coordinates will be used as features in our model, together with an underlying graph structure which is defined on the k-nearest neighbors for each vertex. The goal of our approach is to obtain a pSi  [0, 1] for every potential facility location i  V , such that pSi represents the probability that i is in the optimal solution. These probabilities are then transformed into a feasible solution using post-hoc techniques. We use supervised training and the optimal solutions for our test instances are obtained by solving the classical IP formulation for the pCP (see, e.g., [16]). Our whole solution approach closely follows the approach proposed in [11, 12] for the TSP, which is among the state-of-the-art machine learning approaches for the TSP. By doing so, we not only leverage existing work, but also try to investigate how well general machine learning architectures transfer between two COPs, where the input is given in a quite similar way. Aside from this, we believe there are several additional reasons why considering the pCP is an attractive target to study in the machine learning context:
· Due to the min-max structure of the objective function of the pCP, classical direct IP approaches which are usually used in the OR community do not work well (see, e.g., [21]). Thus, state-of-the-art exact solution approaches use the connection of the pCP to the set-cover problem, and iteratively solve a series of set-cover problems, which are defined with a dependency on the objective function value of the pCP. If a good objective function value is known, these approaches can be speed up considerably, and a successful machine learning approach could provide such a good objective function value.
· Compared to the TSP, where optimal solutions to instances are usually unique, there can exist many different optimal solutions for a pCP instance. This is again due to the min-max objective function. This could make end-to-end training harder. Moreover there is also the given cardinality constraint p on the number of vertices in the solution, which could in general make it harder for a machine learning algorithm to discern which vertices should have a high probability to be in a solution, as there will be "symmetric" vertices, where any of them could replace the other without sacrificing solution quality.
· The cardinality constraint could also offer an attractive target for transfer learning, i.e, instead of just trying to transfer the knowledge learned from a graph with few vertices to a graph with more vertices, it could also be interesting to investigate if some transfer between knowledge learned for different values of p is possible.
· Finally, instead of trying to directly find a solution to the problem, machine learning techniques could also be used for instance-size reduction before an exact solution algorithm from the OR community is applied. For example, in the state-of-the-art exact approach [4] for the pCP, it is enough to solve setcover problems defined on just a few hundred customers for instances with ten thousands of vertices. In [4] these customers are found using OR techniques (i.e., problem specific heuristics) during the course of an algorithm. These heuristics could potentially be replaced with machine learning approaches.
In this paper, we present preliminary work to partially address the points raised above.
2

2 Model
Our model consist of a graph convolutional network, and we output for each potential facility location i  V a probability pSi of being in the optimal solution. This is achieved by a sigmoid output layer. In the testphase, we use greedy-heuristics to convert the probabilities to valid solutions. In this section, we give a general description of the network. Details about the concrete number of layers and features used in our experiments are discussed in the next section.

2.1 Input layer
For each i  V , we use the coordinates xi  Z2 as vertex-input features. They are transformed into h-dimensional features using a linear transformation, i.e.,
x0i = A1xi + b
where A1  Rh×2 and b  Rh are learnable parameters.

2.2 Graph convolution layer
As a graph convolution layer, we use the residual gated graph convolutional operator proposed by [2]. When using such a graph convolutional operator, in order to represent the local graph structure for each vertex i  V the features of the neighbors of i are gathered via recursive message passing. Aside from [2], similar operators where also presented in e.g., [6, 17, 14, 9].
For a given vertex i  V , let N (i) be the set of its neighbors in the input graph. Given the vertex features x at layer , the vertex features x +1 at layer + 1 are defined as

xi+1 = xi + ReLU (A2xi +

i,i

i N (i)

A3xi )

with

i,i = (A4xi + A5xi ),

where ReLU denotes the rectified linear unit,  denotes the sigmoid function, denotes the Hadamard product, A2, A3, A4, A5  Rh×h are learnable parameters, and = 0, . . . , L - 1, i.e., L is the index of the last convolution layer.
In our models, we redefine the neighborhood-structure N (i) for a vertex i  V by including not all
neighbors, but by including only the k-nearest neighbors with respect to the distance d for a given integer
k. We will report results obtained by using different values of k.

2.3 Output layer

To compute the probability pSi of vertex i  V to be in the optimal solution, we use the vertex embedding xLi of the last convolution layer with index L and apply a multi-layer perceptron (MLP) followed by a sigmoid

function, i.e.,

pSi = (M LP (xLi )).

2.4 Loss function
We minimize the weighted cross-entropy loss between the ground-truth solution p^i (where p^i = 1 if and only if the location i is in the solution an zero otherwise) and the obtained probabilities pSi . As the classification task is unbalanced (i.e., for each instance, there are p vertices in the solution and n - p outside), we give weight (n - p)/p to the class of vertices i such that p^i = 1. The loss is averaged over mini-batches.

3

2.5 Solution decoding
Given the output-probabilities pSi for all i  V of our model, we implemented the following two strategies to convert the probabilities into a feasible solution SH :
· naive: Sort the vertices according to probabilities in a descending order (ties broken arbitrarily) and pick the p vertices with the largest probabilities to obtain a solution SH .
· greedy: Due to the structure of the problem (i.e., the min-max objective), several vertices can have a nearly identical effect on the solution quality, and once one of these vertices is picked, it does not pay-off to include any of the other "similar" vertices. To take this into account, we tried the following greedystrategy: Sort the vertices according to probabilities in a descending order (ties broken arbitrarily). Pick the vertex with the largest probability and insert it into SH . Then iterate trough the remainder of the sorted list of vertices, but only add a vertex to SH if adding this vertex improves the objective function. Stop when |SH | = p.
3 Experiments
Our proposed model was implemented in Python using PyTorch [19] and PyTorch Geometric [7]. The experiments were done on an AMD Ryzen 5 2600 with 3.4Ghz and six cores, and 16GB of RAM.
3.1 Data set
Similar to other work for COPs on graphs like the TSP (see, e.g., [22, 11, 12]), we train and evaluate our model on fixed-size problem instances. As mentioned above, we are following the standard in the OR community and let I = J = V , and we use instances with n = m = 50. Moreover, we set p = 5. We create each instance by randomly sampling n points in the integer-square [0, 100]2. As distance dii between two vertices i, i  V , we use the Euclidean distance based on their coordinates. The training sets consists of 100,000 pairs of problem instances and optimal solutions, and the test set of 1,000 such pairs. The optimal solutions were calculated by solving the IP formulation using the IP solver CPLEX [10]. We note that the exact solution time for these instances is under one second on average.
3.2 Hyperparameter configuration
We consider three different sets of hyperparameters in our experiments to investigate the influence of the neigborhood-size k and the number of graph convolutional layers L. We note that by using L graph convolutional layers, the network can use the L-hop neighborhood information. We use the following three settings.
· setting A: One graph convolutional layer, MLP with three layers, h = 50 (resulting in approximately 15,000 trainable parameters), neighborhood-size k = 10
· setting B: Three graph convolutional layers, MLP with three layers, h = 100 (resulting in approximately 140,000 trainable parameters), neighborhood-size k = 5
· setting C: Three graph convolutional layers, MLP with three layers, h = 100 (resulting in approximately 140,000 trainable parameters), neighborhood-size k = 10
3.3 Training procedure
We train our model directly in an end-to-end fashion by minimizing the loss function via gradient descent. We use the Adam optimizer [13] with learning rate 0.0001. The training is done using 100 mini-batches of size 1, 000, setting A is trained for 50 epochs, and B and C for 20 epochs (the latter have a larger number of
4

trainable parameters and thus training takes longer). Figure 1 shows a plot of the loss against training-time for all three settings. The training-time for setting A was 4,361 seconds and the loss at the end of training was 1.01. For setting B the training-time was 1,577 seconds and the loss at the end was 1.20. For setting C the training-time was 10,397 seconds and the loss at the end was 1.00. Thus it seems that larger k leads to a lower loss, while the number of layers L or features h does not seem to be as crucial.

log of loss

4 3 2 1 0
0.0

2.5

5.0

7.5

log of training time [s]

Setting
A B C

Figure 1: Training-time against loss for the different settings.

3.4 Results and discussion
To investigate the effect of the information gained by our model, aside from comparing with the solution values z of the ground-truth (i.e., optimal) solutions, we have also implemented a version of the greedy decoder algorithm greedy, which, instead of being initialized with the probabilities pSi for all i  V obtained by our model, is initialized with random values as pSi . This baseline greedy algorithm is denoted by baseline and the obtained values are denoted by zB. In Figures 2, 3, and 4 we present plots of the optimality gaps (z - z)/z · 100 of the solution values z = zN , zG, zB of naive, greedy, baseline, respectively for the instances of our test-set and our different settings.
The results show that the naive decoding strategy works worse than even the random baseline algorithm for all three settings. This is not unexpected, because as discussed in the introduction also for OR-approaches, the "symmetry" of the optimal solutions of instances is often troublesome and the naive decoding strategy does not take care of this issue. Thus, the naive decoding strategy could only work well if the obtained probabilities pSi of our model would already encode some information about this. However, this seems not to be the case. We note that also for problems like the TSP, the combination of the obtained probabilities with a sophisticated post-hoc algorithm to obtain a feasible solution is crucial for a good performance, see e.g., [11, 12]. The min-max structure of the pCP may even increase this difficulty. One potential path to overcome this issue of not being able to deal with multiple optimal solutions for the future is to not only compute one probability pSi for all i  V , but instead to compute multiple probabilities and then using a minimum operator when computing the loss function, like it is done in [18].
Another interesting result which can be seen in the plot is that for settings A and C, which are both settings with k = 10, the greedy approach leads to better solution quality for most of the instances compared to the baseline, while for setting B, baseline outperforms greedy. This seems to be consistent with the value obtained for the loss function, i.e., using only k = 5 leads to a larger loss-value at the end of the training compared to the two settings with k = 10 and now in the evaluation the results show that in this case we did not seem to have learned anything useful.
In general, the optimality-gaps are rather large compared to results obtained e.g., for the TSP in [11, 12]. Thus, it seems that directly using existing graph convolutional approaches for successfully solving the pCP may not be possible. This could be due to the min-max objective function, which makes it different to many other existing COPs on graphs. We think the problem can be an interesting benchmark problem for the machine learning community as potentially new graph convolutional techniques or other advances need to be developed in order to obtain improved results.

5

number of instances [%]

number of instances [%]

100 75 50 25 0 0

50

100

150

200

optimality gap [%]

algorithm
greedy baseline naive

Figure 2: Plot of optimality gap for setting A.

100 75 50 25 0 0

100

200

optimality gap [%]

algorithm
greedy baseline naive

Figure 3: Plot of optimality gap for setting B.

100 75 50 25 0 0

50

100

150

optimality gap [%]

algorithm greedy baseline naive
200

Figure 4: Plot of optimality gap for setting C.

number of instances [%]

References
[1] Yoshua Bengio, Andrea Lodi, and Antoine Prouvost. Machine learning for combinatorial optimization: a methodological tour d'horizon. European Journal of Operational Research, 2020.
[2] Xavier Bresson and Thomas Laurent. Residual gated graph convnets. arXiv preprint arXiv:1711.07553, 2017.
[3] Quentin Cappart, Didier Ch´etelat, Elias Khalil, Andrea Lodi, Christopher Morris, and Petar Velickovi´c. Combinatorial optimization and reasoning with graph neural networks. arXiv preprint arXiv:2102.09544, 2021.
[4] Claudio Contardo, Manuel Iori, and Raphael Kramer. A scalable exact algorithm for the vertex p-center problem. Computers & Operations Research, 103:211­220, 2019.
[5] Hanjun Dai, Elias B Khalil, Yuyu Zhang, Bistra Dilkina, and Le Song. Learning combinatorial optimization algorithms over graphs. arXiv preprint arXiv:1704.01665, 2017.
[6] Micha¨el Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. arXiv preprint arXiv:1606.09375, 2016.

6

[7] Matthias Fey and Jan Eric Lenssen. Fast graph representation learning with pytorch geometric. arXiv preprint arXiv:1903.02428, 2019.
[8] Matthias Fey, Jan E Lenssen, Christopher Morris, Jonathan Masci, and Nils M Kriege. Deep graph matching consensus. arXiv preprint arXiv:2001.09621, 2020.
[9] William L Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs. arXiv preprint arXiv:1706.02216, 2017.
[10] IBM. CPLEX Optimizer, 2021. [11] Chaitanya K Joshi, Thomas Laurent, and Xavier Bresson. An efficient graph convolutional network
technique for the travelling salesman problem. arXiv preprint arXiv:1906.01227, 2019. [12] Chaitanya K Joshi, Quentin Cappart, Louis-Martin Rousseau, Thomas Laurent, and Xavier Bresson.
Learning tsp requires rethinking generalization. arXiv preprint arXiv:2006.07054, 2020. [13] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014. [14] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks.
arXiv preprint arXiv:1609.02907, 2016. [15] Wouter Kool, Herke Van Hoof, and Max Welling. Attention, learn to solve routing problems! arXiv
preprint arXiv:1803.08475, 2018. [16] Gilbert Laporte, Stefan Nickel, and Francisco Saldanha da Gama, editors. Location Science. Springer,
2nd edition, 2019. [17] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural networks.
arXiv preprint arXiv:1511.05493, 2015. [18] Zhuwen Li, Qifeng Chen, and Vladlen Koltun. Combinatorial optimization with graph convolutional
networks and guided tree search. arXiv preprint arXiv:1810.10659, 2018. [19] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, highperformance deep learning library. arXiv preprint arXiv:1912.01703, 2019. [20] Kate A Smith. Neural networks for combinatorial optimization: a review of more than a decade of research. INFORMS Journal on Computing, 11(1):15­34, 1999. [21] Lawrence V Snyder and Zuo-Jun Max Shen. Fundamentals of supply chain theory. Wiley Online Library, 2011. [22] Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. Pointer networks. arXiv preprint arXiv:1506.03134, 2015.
7

