
# Solving Arithmetic Word Problems with Transformers and Preprocessing of Problem Text

[arXiv](https://arxiv.org/abs/2106.0893), [PDF](https://arxiv.org/pdf/2106.0893.pdf)

## Authors

- Kaden Griffith
- Jugal Kalita

## Abstract

This paper outlines the use of Transformer networks trained to translate math word problems to equivalent arithmetic expressions in infix, prefix, and postfix notations. We compare results produced by many neural configurations and find that most configurations outperform previously reported approaches on three of four datasets with significant increases in accuracy of over 20 percentage points. The best neural approaches boost accuracy by 30% when compared to the previous state-of-the-art on some datasets.

## Comments

arXiv admin note: substantial text overlap with arXiv:1912.00871

## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{griffith2021solving,
      title={Solving Arithmetic Word Problems with Transformers and Preprocessing of Problem Text}, 
      author={Kaden Griffith and Jugal Kalita},
      year={2021},
      eprint={2106.00893},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

## Notes

Type your reading notes here...

