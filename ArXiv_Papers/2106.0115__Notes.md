
# Fine-grained Generalization Analysis of Structured Output Prediction

[arXiv](https://arxiv.org/abs/2106.0115), [PDF](https://arxiv.org/pdf/2106.0115.pdf)

## Authors

- Waleed Mustafa
- Yunwen Lei
- Antoine Ledent
- Marius Kloft

## Abstract

In machine learning we often encounter structured output prediction problems (SOPPs), i.e. problems where the output space admits a rich internal structure. Application domains where SOPPs naturally occur include natural language processing, speech recognition, and computer vision. Typical SOPPs have an extremely large label set, which grows exponentially as a function of the size of the output. Existing generalization analysis implies generalization bounds with at least a square-root dependency on the cardinality $d$ of the label set, which can be vacuous in practice. In this paper, we significantly improve the state of the art by developing novel high-probability bounds with a logarithmic dependency on $d$. Moreover, we leverage the lens of algorithmic stability to develop generalization bounds in expectation without any dependency on $d$. Our results therefore build a solid theoretical foundation for learning in large-scale SOPPs. Furthermore, we extend our results to learning with weakly dependent data.

## Comments

To appearn in IJCAI 2021

## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{mustafa2021finegrained,
      title={Fine-grained Generalization Analysis of Structured Output Prediction}, 
      author={Waleed Mustafa and Yunwen Lei and Antoine Ledent and Marius Kloft},
      year={2021},
      eprint={2106.00115},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```

## Notes

Type your reading notes here...

