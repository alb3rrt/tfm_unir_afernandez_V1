
# Memory Wrap: a Data-Efficient and Interpretable Extension to Image Classification Models

[arXiv](https://arxiv.org/abs/2106.01440), [PDF](https://arxiv.org/pdf/2106.01440.pdf)

## Authors

- Biagio La Rosa
- Roberto Capobianco
- Daniele Nardi

## Abstract

Due to their black-box and data-hungry nature, deep learning techniques are not yet widely adopted for real-world applications in critical domains, like healthcare and justice. This paper presents Memory Wrap, a plug-and-play extension to any image classification model. Memory Wrap improves both data-efficiency and model interpretability, adopting a content-attention mechanism between the input and some memories of past training samples. We show that Memory Wrap outperforms standard classifiers when it learns from a limited set of data, and it reaches comparable performance when it learns from the full dataset. We discuss how its structure and content-attention mechanisms make predictions interpretable, compared to standard classifiers. To this end, we both show a method to build explanations by examples and counterfactuals, based on the memory content, and how to exploit them to get insights about its decision process. We test our approach on image classification tasks using several architectures on three different datasets, namely CIFAR10, SVHN, and CINIC10.

## Comments

22 pages

## Source Code

Official Code

- [https://github.com/KRLGroup/memory-wrap](https://github.com/KRLGroup/memory-wrap)

Community Code

- [https://paperswithcode.com/paper/memory-wrap-a-data-efficient-and](https://paperswithcode.com/paper/memory-wrap-a-data-efficient-and)

## Bibtex

```tex
@misc{larosa2021memory,
      title={Memory Wrap: a Data-Efficient and Interpretable Extension to Image Classification Models}, 
      author={Biagio La Rosa and Roberto Capobianco and Daniele Nardi},
      year={2021},
      eprint={2106.01440},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```

## Notes

Type your reading notes here...

