Sequential Domain Adaptation by Synthesizing Distributionally Robust Experts

arXiv:2106.00322v1 [cs.LG] 1 Jun 2021

Bahar Taskesen 1 Man-Chung Yue 2 Jose´ Blanchet 3 Daniel Kuhn 1 Viet Anh Nguyen 3 4

Abstract
Least squares estimators, when trained on a few target domain samples, may predict poorly. Supervised domain adaptation aims to improve the predictive accuracy by exploiting additional labeled training samples from a source distribution that is close to the target distribution. Given available data, we investigate novel strategies to synthesize a family of least squares estimator experts that are robust with regard to moment conditions. When these moment conditions are specified using Kullback-Leibler or Wasserstein-type divergences, we can find the robust estimators efficiently using convex optimization. We use the Bernstein online aggregation algorithm on the proposed family of robust experts to generate predictions for the sequential stream of target test samples. Numerical experiments on real data show that the robust strategies may outperform non-robust interpolations of the empirical least squares estimators.
1. Introduction
A natural approach to improving predictive performance in data-scarce tasks involves translating informative signals from a data-abundant source domain to the data-scarce target domain. This transfer of knowledge is commonly referred to as domain adaptation or transfer learning, and it is increasingly applied in a wide range of settings, see for example Wilson & Cook (2020); Chu & Wang (2018); Weiss et al. (2016) and Redko et al. (2019).
We consider the supervised domain adaptation setting with scarce labeled target data. The key challenge here is the
1Risk Analytics and Optimization Chair, Ecole Polytechnique Fe´de´rale de Lausanne 2Department of Applied Mathematics, The Hong Kong Polytechnic University 3Department of Management Science and Engineering, Stanford University 4VinAI Research, Vietnam. Correspondence to: Bahar Taskesen <bahar.taskesen@epfl.ch>.
Proceedings of the 38 th International Conference on Machine Learning, PMLR 139, 2021. Copyright 2021 by the author(s).

absence of meaningful data to tune any parameters. However, in many practically relevant applications, new data will arrive sequentially to enrich the information on the target domain. In this case, many online algorithms can be utilized to adaptively learn the best predictor on the target domain, which also guarantee optimal asymptotic regrets (Lattimore & Szepesva´ri, 2020).
In this paper, we take a pragmatic approach to resolve a specific setup of the domain adaptation problem. We assume access to a scarce labelled target data, and the future target data arrives sequentially. For example, consider understanding the dynamics of ride-sharing platforms requires insights about the demand and supply from both sides of the market. These insights are signalled through the ride fares, which can be explained by characteristics such as the travel distances and the origin-destination pairs of the trips, the time of the day as well as the weather conditions. The capability to correctly predict ride fares directly translates into improved profit forecasts, and thus it vitally supports the growth of new-coming platforms. In a competitive market, a follower (e.g., Lyft) needs to target a slightly different market segment than the leader (e.g., Uber) who had entered earlier. Thus, the demand and supply characteristics for the follower may differ from those of the leader. Nevertheless, as both platforms provide on-demand transportation, it is reasonable to assume that their supply and demand dynamics are similar. The follower, who possesses limited data, can query demand on the leader's platform to collect data in order to leap forward in its predictive precision. Our approach to solve this problem is illustrated in Figure 1 and it consists of two components:
1. Expert Generation Module: This module generates a set of competitive experts E by fine-tuning the explanatory power of the source domain data and harnessing the signal guidance from the scarce target domain data.
2. Expert Aggregation Module: Acting on the sequential arrival of the unseen target data, this module aggregates the predictive capability of the generated experts via an online aggregation mechanism. In this work we will use the Bernstein Online Aggregation mechanism.
We will propose two ways to generate the experts. The first

aQm`+2 /i (xbi, ybi)Ni=S1 h`;2i /i (xbj , ybj )Nj=T1

1tT2`i :2M2`iBQM

6`K2  /BbiBM+i U /Bbi`B#miBQMH `2;BQM

aQHp2 /Bbi`B#miBQMHHv `Q#mbi H2bi b[m`2b

{

_2T2i |E| iBK2b

1tT2`i ;;`2;iBQM

a2i Q7 2tT2`ib { 1, . . . , |E|}

"2`Mbi2BM PMHBM2
;;`2;iBQM

*mKmHiBp2 HQbb

lMb22M b2[m2MiBH i`;2i /i (xj, yj)Jj=1 Figure 1. The architecture of our framework for supervised domain adaptation when the unseen target test samples arrive sequentially.

approach generates experts corresponding to optimal decisions along a path, with the intention to interpolate between the source and the target distributions. We will consider two types of trajectories, guided by either the Kullback-Leibler or the Wasserstein divergence. The second approach generates distribution regions around both the source and the target. The intersection of these regions is used to generate distributionally robust experts. The geometrical intuition is to find the "direction" induced by the aforementioned divergences, in which the source data can explain the target data. Once the experts are deployed, the aggregation mechanism is executed without re-adapting the experts.
Our ultimate goal is to ensure a competitive performance in the short term and not in the asymptotic regime when the number of test samples from the target domain tends to infinity. Indeed, as soon as the target sample size is sufficient, training the machine learning model on all available target data becomes more attractive. From a short term horizon benchmark, our approach offers an appealing warm start for online training procedure, and it may also lead to a faster convergence rate depending on the underlying algorithm.
Contributions. Our paper explores the expert generation problem in the context of supervised domain adaptation.
· We introduce a novel framework to synthesize a family of robust least squares experts by altering various momentbased distribution sets. These sets gradually interpolate from the source information to the target information, capturing different belief levels on the explanatory power of the source domain onto the target domain.
· We present two intuitive strategies to construct the sets of moment information, namely the "Interpolate, then Robustify" and the "Surround, then Intersect" strategies. Both strategies are simply characterized by two parameters representing the aforementioned explanatory power of belief of the source domain and the level of desired robustness.
· We show that when the moment information is prescribed using a Kullback-Leibler or a Wasserstein-type divergence, the experts are efficiently formed by solving convex optimization problems, that can even be solved by a first-order gradient descent algorithm or off-the-shelf solvers.

This paper is structured as follows. Section 2 delineates the problem setup and describes in details two common strategies to generate experts: the convex combination and the reweighting strategies. Section 3 introduces our framework to generate experts, while Section 4 and 5 dive into details about our "Interpolate, then Robustify" and our "Surround, then Intersect" strategies, respectively. Section 6 demonstrates experimentally that the proposed robust strategies systematically outperform non-robust interpolations of the empirical least squares estimators.
Literature Review. Domain adaptation arises in various applications including natural language processing (Søgaard, 2013; Li, 2012; Jiang & Zhai, 2007; Blitzer et al., 2006), survival analysis (Li et al., 2016) and computer vision (Wang & Deng, 2018; Csurka, 2017). Domain adaptation methods can be classified into three categories. Unsupervised domain adaptation only requires unlabelled target data, but in large amounts (Ghifary et al., 2016; Baktashmotlagh et al., 2013; Ganin & Lempitsky, 2015; Wang et al., 2020; Long et al., 2016; Ben-David et al., 2007; Courty et al., 2017). Semi-supervised domain adaptation requires labelled target data (Yao et al., 2015; Kumar et al., 2010; Sindhwani et al., 2005; Lopez-Paz et al., 2012; Saha et al., 2011; de Mathelin et al., 2020; Sun et al., 2011). Finally, supervised domain adaptation only requires scarce labelled target data (Motiian et al., 2017b;a; Tzeng et al., 2015; Koniusz et al., 2017). If the target data is scarce and label information is available, supervised domain adaptation outperforms unsupervised domain adaptation (Motiian et al., 2017b). The domain adaptation literature further ramifies by imposing different distributional assumptions into covariate shift (Shimodaira, 2000; Sugiyama et al., 2008) or label shift (Lipton et al., 2018; Azizzadenesheli et al., 2019).
The domain adaptation literature for regression problems focuses primarily on instance-based reweighting strategies (Garcke & Vanck, 2014; Sugiyama et al., 2008; Garcke & Vanck, 2014; Huang et al., 2006; Cortes & Mohri, 2014; Chen et al., 2016), which aim to minimize some distance between the source and target distributions. Most of the instance-based methods solve an optimization problem to find the weights of the instances (Garcke & Vanck, 2014; Cortes et al., 2019), which may be computationally expen-

sive when data is abundant. Other approaches rely on deep learning models to minimize the discrepancy between the domain distributions (Zhao et al., 2018; Richard et al., 2020). The literature on regression for domain adaptation also extends towards boosting-based methods (Pardoe & Stone, 2010), and deep learning methods (Salaken et al., 2019).
Our paper also uses ideas and techniques from robust optimization and adversarial training, which have attracted considerable attention in machine learning (Namkoong & Duchi, 2016; Gao et al., 2018; Blanchet et al., 2019; Nguyen et al., 2019a). Robust optimization for least squares problem with uncertain data was studied in Ghaoui & Lebret (1997). Distributionally robust optimization with moment ambiguity sets was proposed in Delage & Ye (2010) and extended in Goh & Sim (2010) and Kuhn et al. (2019). Ambiguity sets prescribed by divergences were previously used to robustify Bayes classification (Nguyen et al., 2019b; 2020).
Our work is also similar to Chen et al. (2016) that consider unsupervised domain adaptation regression, and Wang et al. (2020) that consider robust domain adaption for the classification setting.
Notation. We use Id to denotes the identity matrix in Rd. The set of p-by-p positive (semi-)definite matrices is denoted by Sp++ (Sp+). All proofs are relegated to the Appendix.

2. Problem Statement and Background

We consider a generic linear regression setting, in which X is a d-dimensional covariate and Y is a univariate response
variable. In the context of supervised domain adaptation, we have access to the source domain data (xi, yi)Ni=S1 consisting of NS labelled samples drawn from the source distribution. In addition, we are given a limited number of NT labelled samples (xj, yj)Nj=T1 from the target distribution. Our goal is to predict the responses of the test samples (xj, yj)Jj=1, which are drawn from the target distribution and arrive se-
quentially. To this end, we will construct several experts.
In the linear regression setting, each expert is characterized by a vector   Rd. Given a covariate-response pair (x, y)  Rd × R, we use the square loss function to measure the mismatch between the expert's prediction  x and the actual response y. Using the target domain data (xi, yi)Ni=T1, one approach is to solve the ridge regression problem

min
Rd

1 NT

NT
(
j=1

xj - yj )2 + 



2 2

for some   0 to obtain the empirical target predictor



-1 



T

=

1 NT

NT
xj xj
j=1

+ Id

1 NT

NT
xj yj  .
j=1

When NT is small, however, the empirical target predictor may perform poorly on the future target data (xj, yj)Jj=1.
If the source domain distribution is sufficiently close to the target domain distribution, it is expedient to exploit the available information in the source domain data to construct better predictors for the target domain data. With this promise, one can synthesize several predictors to form an ensemble of experts, and one can apply an online aggregation scheme to predict on the unseen target data. We now first describe several interpolation schemes to generate experts.

Convex Combination Strategy. Denote by S the empirical source predictor, which is obtained by solving the ridge
regression problem on the source data. The convex com-
bination strategy generates predictors by forming convex
combinations between S and T. More precisely, for any   [0, 1] a new predictor is synthesized by setting

 = S + (1 - )T.
The parameter  represents our belief in the explanatory power of the source domain data: if  = 0, the source domain has no power to explain the target domain, and we recover 0 = T, the empirical target predictor. If  = 1, the source domain has an absolute predictive power on the target domain, and it is beneficial to use 1 = S because the sample size NS is large. Discretizing  in the range [0, 1] forms a family of experts E.

Reweighting Strategy. Reweighting samples is a common strategy in domain adaptation, transfer learning and adversarial training. Garcke & Vanck (2014) synthesize experts, for example, by solving

NS

NT

min
Rd

wh,i(
i=1

xi - yi)2 + (
j=1

xj - yj )2 + 



2 2

for some non-negative weights wh,i determined via a Gaussian kernel with bandwidth h > 0 of the form

NS
wh,i = l exp

-

xi - xl

2 2

+

(yi

-

yl)2

h2

l=1

for i = 1, . . . , NS. Here, the parameter vector   RN+S solves the exponential cone optimization problem

NT
max log
j=1

NS
l exp

-

xj - xl

2 2

+

(yj

-

yl)2

h2

l=1

s. t.

NS NS
l exp

-

xi - xl

2 2

+

(yi

-

yl)2

h2

= NS.

i=1 l=1

The predictor h, parametrized by the kernel weight h, that solves the reweighted ridge regression problem has the form

NT

NS

-1

xj xj + wixixi +Id

j=1

i=1

NT

NS

xj yj + wixiyi .

j=1

i=1

Discretizing the bandwidth h forms a family of experts E.

Bernstein Online Aggregation (BOA). We now give a

brief overview on the BOA algorithm, which is a recur-

sive expert aggregation procedure for sequential predic-

tion (Cesa-Bianchi & Lugosi, 2006). For a given set of ex-

perts E = {1, . . . , |E|} and an incumbent weight k,j-1 for expert k at time j - 1, this algorithm aggregates the

individual expert's predictions linearly based on the arrival

of the input data (xj, yj) as

|E | k=1

k,j k

xj .

The

weights

of the experts are updated using the exponential rule

k,j =

exp(-(1 + Lk,j )Lk,j )k,j-1

|E | k=1

exp(-(1

+

Lkj

)Lk,j

)k,j-1

,

where  > 0 is the learning rate and Lk,j = (k xj - yj)2-

|E | k=1

(k

xj

-

yj )2k,j-1.

This algorithm is initialized

with weights k,0  0 satisfying

|E | k=1

k,0

=

1.

The

cumulative loss for the stream of test data (xj, yj)Jj=1 is



J

|E |

2

 k,j k xj - yj  .

(1)

j=1 k=1

For the square loss, the BOA procedure is optimal for the model selection aggregation problem, that is, the excess risk of its batch version achieves the fast rate of convergence log(|E|)/J in deviation; see Wintenberger (2017).

3. Predictor Generation via Distributionally Robust Linear Regression

We now specify our framework to generate the set of competitive experts E for future prediction. Our construction is based on the premises that the source domain carries the explanatory power on the target domain to a certain extent and that the scarce target data can provide directional guidance to pull information from the source data. Moreover, we also leverage ideas from distributionally robust optimization and adversarial training, which have been shown to significantly improve the out-of-sample predictive performance (Duchi & Namkoong, 2018; Mohajerin Esfahani & Kuhn, 2018; Blanchet et al., 2019; Gao, 2020; Lam, 2019).

With this in mind, our expert generation scheme blends
two elements: a distributional probing strategy and a robust
estimation procedure. The distributional probing strategy frames the distribution set B, and then each expert is constructed by solving a distributionally robust least squares
estimation problem of the form

inf
Rd

sup
QB

EQ[(

X - Y )2],

(2)

where Q is a joint distribution over (X, Y ). Generating a collection of distribution sets B in a systematic manner and solving (2) for each such set will form a family of experts E.

In a purely data-driven setting with no additional in-

formation, it is attractive to probe into the distribu-

tional regions in between the empirical source distribution

PS = NS-1

NS i=1

(xi ,yi )

and

the

empirical

target

distribu-

tion PT = NT-1

NT j=1

(xj ,yj ).

Because

probability

distri-

butions reside in infinite-dimensional spaces, framing B in

between PS and PT is a non-trivial task. Fortunately, be-

cause the expected square loss only depends on the first two

moments of the joint distribution of (X, Y ), it suffices to prescribe B using a finite parametrization of distributional

moments. To this end, let p = d + 1 represent the dimension of the joint vector (X, Y ). For a given set U on the space of mean vectors and covariance matrices Rp × Sp+, we consider B as the lifted distribution set that contains all distributions whose moments belong to U, that is,

B = {Q  M(Rp) : Q  (µ, ), (µ, )  U} ,

where M(Rp) denotes the set of all distributions on Rp, and the notation Q  (µ, ) expresses that Q has mean µ and covariance matrix . It is convenient to construct the moment information set U using a divergence on Rp × Sp+. Definition 3.1 (Divergence). A divergence  on Rp × Sp+ satisfies the following properties:
· non-negativity: for any (µ, ), (µ, )  Rp × Sp+, we have ((µ, ) (µ, ))  0,

· indiscernability: ((µ, ) (µ, )) = 0 implies (µ, ) = (µ, ).

In this paper, we will explore two divergences in the space of mean vectors and covariance matrices that are motivated by popular measures of dissimilarity between distributions. The divergence D is motivated by the Kullback-Leibler (KL) divergence.
Definition 3.2 (Kullback-Leibler-type divergence). The divergence D from tuple (µ, )  Rp × Sp++ to tuple (µ, )  Rp × Sp++ amounts to
D (µ, ) (µ, ) (µ - µ) -1(µ - µ)+Tr -1 - log det(-1)-p.

In fact D is equivalent to the KL divergence between two non-degenerate Gaussian distributions N (µ, ) and N (µ, ) (up to a factor of 2). As a consequence, D is non-negative, and it collapses to 0 if and only if  =  and µ = µ. We can also show that D is affine-invariant. However, we emphasize that D is not symmetric and D (µ, ) (µ, ) = D (µ, ) (µ, ) in general.
We also study the divergence W which is motivated by the Wasserstein distance.

Definition 3.3 (Wasserstein-type divergence). The divergence W between two tuples (µ, )  Rp × Sp+ and (µ, )  Rp × Sp+ amounts to

W (µ, ) (µ, )

µ-µ

2 2

+Tr

+-2



1 2



1 2

1
2.

The divergence W coincides with the squared type-2 Wasserstein distance between two Gaussian distributions N (µ, ) and N (µ, ) (Givens & Shortt, 1984). One can readily show that W is non-negative, and it vanishes if and only if (µ, )=(µ, ). Thus, W is a symmetric divergence.
In Sections 4 and 5 we examine in detail two strategies to frame U and its corresponding distribution set B in a principled manner, and we devise optimization techniques to solve the resulting robust estimation problems.

4. "Interpolate, then Robustify" Strategy

"Interpolate, then Robustify" (IR) is an intuitive strategy to systematically probe into distributional regions between PS and PT. Let (µS, S) be the empirical mean vector and covariance matrix of PS, that is,

µS

=

1 NS

NS i=1

xi yi

,

S

=

1 NS

NS i=1

xi yi

xi yi

-µSµS ,

and let (µT, T) be defined analogously for PT. The IR strategy applies repeatedly the following two steps to generate distribution sets. First, interpolate between (µS, S) and (µT, T) to obtain a new pair (µ, ) parametrized by   [0, 1]. Second, construct a moment set U, as a ball of radius  circumscribing the pair (µ, ), then lift the moment set U, to the corresponding distribution set B,. More specifically, (µ, ) is the -barycenter between (µS, S) and (µT, T), which is obtained by solving

min ((µ, )
µRp ,Sp+

(µS, S))+

(3)

(1-)((µ, ) (µT, T)).

 (µb , b )

(µbS, bS)

(µbT, bT)

Figure 2. The dashed curve shows the barycenter interpolations parametrized by   [0, 1]. Ellipses represent U, at different .

Then, we employ the divergence  to construct an uncertainty set U, in the mean-covariance matrix space as
U, (µ, )  Rp × Sp+ : ((µ, ) (µ, ))   .

The outlined procedure is illustrated in Figure 2. An expert is now obtained by solving the distributionally robust least squares problem (2) with respect to the distribution set
B, = {Q  M(Rp) : Q  (µ, ), (µ, )  U,}.
Notice that in this strategy the parameter   [0, 1] characterizes the explanatory power of the source domain to the target domain: if  = 0, then (µ, ) = (µT, T), and if  = 1, then (µ, ) = (µS, S). Thus, as  decreases, (µ, ) is moving farther away from the source information (µS, S), and (µ, ) is pulled towards the target information (µT, T).
The choice of the divergence  influences both the barycenter problem (3) and the formation of the set U,. Next, we study the special case of the IR strategy with the KL-type divergence and the Wasserstein-type divergence.

4.1. Kullback-Leibler-type Divergence
The KL-type divergence D in Definition 3.2 is not symmetric. Hence, it is worthwhile to note that the barycenter problem (3) optimizes over (µ, ) being placed in the first argument of D, and that the set U, is also defined with the pair (µ, ) being placed in the first argument. Under the divergence D, the barycenter (µ, ) admits a closed form expression. This fact is well-known in the field of KL fusion of Gaussian distributions (Battistelli et al., 2013).
Proposition 4.1 (KL barycenter). Suppose that  is the KL-type divergence. If S, T 0, then (µ, ) is the minimizer of the barycenter problem (3) with
 = (-S 1 + (1 - )-T1)-1 0, µ =  -S 1µS + (1 - )-T1µT .
For a given   [0, 1] and   0, the corresponding IR-KL expert is obtained by solving

min
Rd

f,() sup EQ[( X - Y )2] .
QB,

(4)

Problem (4) can be efficiently solved using a gradientdescent algorithm. To do this, the next proposition establishes the relevant properties of f,.
Proposition 4.2 (Properties of f,). The function f, is convex and continuously differentiable with

2 f,() =

2w+( -1)( +µµ )w ( - 1)2

1:d ,

where w = [ , -1] , 1 = w w, 2 = (w µ)2 and   (1, 1 1 + 2 + 1 + 4 2 /(2)] is the unique solution of the equation

 = ( - 1)-212 + ( - 1)-11 + log(1 - -11).

Furthermore, f, is locally smooth at any   Rd, i.e., there exist constants C,  > 0 such that for any   Rd with  -  2  , we have f,( ) - f,() 2  C  -  2.
Thanks to Proposition 4.2, we can apply the adaptive gradient method to solve problem (4) to global optimality, and the algorithm enjoys a sublinear rate |f,(¯k) - f,(,)|  O(k-1), where ¯k is a certain average of the iterates, and , is an optimal solution of (4). The algorithm and its guarantees are detailed in Malitsky & Mishchenko (2019).

4.2. Wasserstein-type Divergence

Under the divergence W in Definition 3.3, problem (3) resembles the Wasserstein barycenter in the space of Gaussian distributions. The result from Agueh & Carlier (2011, §6.2) implies that the barycenter (µ, ) admits a closed form expression following the McCann's interpolant (McCann, 1997, Example 1.7).
Proposition 4.3 (Wasserstein interpolation). Suppose that  is the Wasserstein-type divergence. If S 0, then (µ, ) is the minimizer of problem (3) with

µ = µS + (1 - )µT,  = (Ip + (1 - )L)S(Ip + (1 - )L),

where

L

=

1
T2

1
(T2

S

1
T2

)-

1 2

1
T2 .

For a given   [0, 1] and   0, we obtain the corresponding IR-Wasserstein expert by solving a conic program using off-the-shelf solvers such as MOSEK ApS (2019).
Proposition 4.4 (IR-Wasserstein expert). Suppose that  is the Wasserstein-type divergence. Problem (2) with B  B, is equivalent to the second order cone program

min
Rd

(

+

µµ

)

1 2

 -1

+ 
2

 -1

.
2

5. "Surround, then Intersect" Strategy

"Surround, then Intersect" (SI) probes naturally into the

distributional space by intersecting two balls centered at

the empirical moments. More specifically, this strategy cir-

cumscribes (µS, S) (respectively, (µT, T)) with a ball of radius S (respectively, T) using the -divergence. Consequentially, the moment information set US,T in the mean vector-covariance matrix space is defined as

US ,T

  

(µ, )  Rp × Sp+ such that: ((µ, ) (µS, S))  S
((µ, ) (µT, T))  T  + µµ Ip

   ,

where the small constant  > 0 improves numerical stability. This construction is graphically illustrated in Figure 3. An

expert is now obtained by solving the distributionally robust
least squares problem (2) subject to the distributional set
BS,T = {Q  M(Rp) : Q  (µ, ), (µ, )  US,T } .
Note that BS,T is well-defined only if the radii (S, T) are sufficiently large so that the intersection of the two balls
becomes non-empty. A sensible approach to set these parameters is to fix S and to find a sufficiently large T so that US,T is non-empty. In this way, the SI strategy characterizes the explanatory power of the source domain to the target domain by the radius S: if S = 0 then US,T becomes a singleton {(µS, S)}, representing the belief that the source domain possess absolute explanatory power onto the target domain. As S increases, US,T is gradually pulled towards the empirical target moments (µT, T). Next, we study the special case of the SI strategy with the
KL-type divergence and the Wasserstein-type divergence.

5.1. Kullback-Leibler-type Divergence

Recall that D is asymmetric and (µ, ) is the first argument of D in the definition of US,T . We first study conditions on T under which the ambiguity set BS,T is non-empty.
Proposition 5.1 (Minimum radius). Suppose that  is the KL-type divergence. For any S > 0 the sets US,T and BS,T are non-empty if T  D((µ ,  ) (µT, T)), where  is a maximizer of
sup D((µ, ) (µS, S))+D((µ, ) (µT, T))-S s. t.   R+,  = (1 + )(-S 1 + -T1)-1  Sp+,
µ =  (-S 1µS + -T1µT)/(1 + )  Rp

The above optimization problem is effectively onedimensional and can therefore be solved by bisection on .
The next theorem asserts that the SI-KL experts are formed
by solving a semidefinite program.
Theorem 5.2 (SI-KL Expert). Suppose that  is the KLtype divergence and B  BS,T is non-empty. Then  = (MXX )-1MXY solves problem (2), where (MXX , MXY ) is a solution of the convex semidefinite program

sup  s. t. MXX  Rd×d, MXY  Rd×1, MY Y  R
  R+, µ  Rp, M  Sp++, t  R+ µk -k 1µk - 2µk -k 1µ + Tr M -k 1 - log det(M -k 1)-log(1-t) - p  k k  {S, T}

Mµ µt

0,

MXX MXY

MXY MY Y - 

0

M=

MXX MXY

MXY MY Y

Ip.

5.2. Wasserstein-type Divergence
The space Rp × Sp+ can be endowed with a distance inherited from the Wasserstein distance between Gaussian

(µbS, bS)

(µbT, bT)

S (µbS, bS)

T (µbT, bT)

(µbS, bS)

(µbT, bT)

(µbS, bS)

(µbT, bT)

Figure 3. Varying (S, T) frames different moment sets US,T (hatched regions). The radius S increases from left to right.

distribution. For any S > 0, the minimum radius for T that makes BS,T non-empty is known in closed form.
Proposition 5.3 (Minimum radius). Suppose that  is the Wasserstein-type divergence. For any S > 0 the sets US,T and BS,T are non-empty if

T 

W((µS, S)

(µT, T)) - S

2
.

The next theorem asserts that the SI-Wasserstein experts are
constructed by solving a semidefinite program.
Theorem 5.4 (SI-Wasserstein expert). Suppose that  is the Wasserstein-type divergence and B  BS,T is nonempty. Then  = (MXX )-1MXY solves problem (2), where (MXX , MXY ) is a solution of the linear semidefinite program

sup 

s. t. MXX  Rd×d, MXY  Rd×1, MY Y  R

  R+, µ  Rp, M, H  Sp+, CS, CT Rp×p

µk

2 2

-

2µk

µ+

Tr

M +k -2Ck

 k

H Ck Ck k

0

k  {S, T}

M -H µ µ

0

MXX MXY MXY MY Y -

0,

M=

MXX MXY

MXY MY Y

Ip.

6. Numerical Experiments

The second-order cone and semidefinite programs are modelled in MATLAB via YALMIP (Lo¨fberg, 2004) and solved with MOSEK ApS (2019). All experiments are run on an Intel i7-8700 CPU (3.2 GHz) computer with 16GB RAM. The corresponding codes are available at https: //github.com/RAO-EPFL/DR-DA.git.

We now aim to assess the performance of experts and demonstrate the effects of robustness. In all experiments we generate the set E = {1, . . . , |E|} of experts with |E| = 10.

We consider four family of robust experts generated by:
· IR-KL: with  = D((µT, T) (µS, S))/(3|E|) and  is spaced from 1 to 0 in exponentially increasing steps.1

1We say that  is spaced from a to b in K exponen-

tially increasing steps if 1 = a and k+1 = k - (a -

b) exp(k)/

K-1 i=1

exp(i)

for

all

k



{2,

.

.

.

,

K

-

1}.

· IR-WASS: with =W((µT, T) (µS, S))/(3|E|) and  is spaced from 1 to 0 in exponentially increasing steps.
· SI-KL: with S spaced from 10-3 to D((µT, T) (µS, S))-1 in exponentially increasing steps. For a given S, T is set to the sum of the minimum target radius satisfying the condition of Proposition 5.1 and S/2.2
· SI-WASS: with S spaced from 10-4 to W((µT, T) (µS, S)) in increasing exponential steps. For a given S, T is set to the sum of the minimum radius that satisfies the condition in Proposition 5.3 and S/2.
We benchmark against the Convex Combination (CC) and Reweighting (RW) experts in Section 2 generated by
· CC-L: with  equally spaced in [0, 1], thus provides uniformly spaced distributional regions in between domains.
· CC-TL: with  equally spaced in [0, 0.5], thus distributional regions are formed around the target domain.
· CC-SL: with  equally spaced in [0.5, 1], thus distributional regions are formed around the source domain.
· CC-TE: with  spaced from 0 to 1 in exponentially increasing steps, thus the constructed distributional regions are concentrated towards the target domain.
· CC-SE: with  spaced from 1 to 0 in exponentially increasing steps, thus the constructed distributional regions are concentrated towards the source domain.
· RWS: with h equally spaced in [0.5, 10].
We consider a family of sequential empirical ridge regression estimators generated by training for each J over · LSE-T, the union of the target dataset (xj, yj)Nj=T1, and
the sequentially arriving target test data (xj, yj)Jj=-11,
· LSE-T&S, the union of the source data (xi, yi)Ni=S1, the target data (xj, yj)Nj=T1 and the sequentially arriving target test data (xj, yj )Jj=-11.
Note that both LSE-T and LSE-T&S predictors dynamically incorporate the new data to adapt the prediction. Thereby, they have an unfair advantage in the long run over the other experts that are trained only once at the beginning with NT samples from the test domain.
2If d  15, then the minimum value of S is set to 5 to improve numerical stability.

Data Set Uber&Lyft
US Births (2018)
Life Expectancy
House Prices in KC
California Housing

Time
5 10 50 100
5 10 50 100
5 10 50 100
5 10 50 100
5 10 50 100

IR-KL
17.65 13.67 13.39 15.24
79.83 115.47 107.40 117.03
33.18 25.59 19.81 19.02
1.58 1.52 1.34 1.34
63.33 68.08 70.08 72.80

IR-WASS
1.00 1.00 1.00 1.00
1.02 1.02 1.01 1.01
1.00 1.00 1.00 1.00
1.00 1.00 1.00 1.00
1.05 1.04 1.01 1.003

SI-KL
199.28 111.52 60.29 59.06
44.71 39.35 40.04 53.13
6.24 5.45 8.70 8.25
1.21 1.20 1.31 1.30
3.31 2.42 1.97 1.90

SI-WASS
1.01 1.01 1.01 1.01
1.00 1.00 1.00 1.00
1.03 1.02 1.01 1.005
1.01 1.01 1.01 1.01
1.00 1.00 1.00 1.00

CC-L
34.04 30.85 25.87 26.01
64.99 45.59 42.74 45.35
17.24 12.49 7.57 6.82
3.98 3.58 2.79 2.65
27.63 20.57 11.79 9.71

CC-TL
98.43 99.22 85.06 85.77
257.60 195.14 192.46 208.65
77.06 60.19 44.00 41.40
8.87 7.77 6.52 6.54
102.82 91.86 81.72 79.19

CC-SL
12.03 11.40 9.72 9.91
25.13 18.33 13.12 12.94
7.38 5.50 3.10 2.68
2.12 2.02 1.86 1.91
9.60 6.23 2.49 1.83

CC-TE
155.71 161.72 147.45 148.49
432.09 339.11 361.51 397.33
125.71 104.00 84.98 83.60
13.31 11.70 10.37 10.74
181.52 169.87 170.18 173.96

CC-SE
1.74 1.58 1.42 1.41
2.07 1.60 1.31 1.22
1.46 1.40 1.38 1.38
1.29 1.27 1.27 1.27
1.35 1.19 1.05 1.04

RWS
1.45 1.34 1.16 1.12
4.50 3.29 2.00 1.75
1.15 1.15 1.10 1.08
1.23 1.23 1.20 1.18
1.17 1.17 1.13 1.14

Table 1. Normalized cumulative loss values averaged over 100 independent runs.

LSE-T
119.65 137.15 57.85 31.25
727.88 524.39 191.27 104.75
255.08 167.15 39.83 20.42
11.75 6.93 3.91 2.72
96.43 45.64 10.17 5.81

LSE-T&S
11.08 6.32 2.12 1.57
39.17 19.28 5.20 3.19
20.72 10.73 3.15 2.10
3.70 2.25 1.30 1.12
54.34 24.76 5.63 3.39

The main reason behind using exponential step sizes originates from the asymmetric nature of D. For simplicity, we also use it for experts with W. To ensure fairness in the competition between experts, we vary the parameters of the non-robust experts also in exponential steps.
We compare the performance of our model against the above non-robust benchmarks on 5 Kaggle datasets:3
· Uber&Lyft contains d = 38 features of Uber and Lyft cab rides in Boston including the distances, date and time of the hailing, a weather summary for that day. The prediction target is the price of the ride. We divide the dataset based on the company, Uber (source) and Lyft (target).
· US Births (2018) has d = 36 predictive features of child births in the United States in the year of 2018 including the gender of the infant, mother's weight gain, and mother's per-pregnancy body mass index. The task is to predict the weight of the infants. We divide the dataset based on gender: male (source) and female (target).
· Life Expectancy contains d = 19 predictive features, and the target variable is the life expectancy at birth. The dataset is divided into two subgroups: developing (source) and developed (target) countries.
· House Prices in King Country contains d = 14 predictive variables, the target variable is the transaction price of the houses. We split the dataset into two domains: houses built in [1950, 2000) (source) and [2000, 2010] (target).
· California Housing Prices has d = 9 predictive features, the target variable is the price of houses. We divide this dataset into houses with less than an hour drive to the ocean shore (source) and houses in inland (target).
We use all samples from the source domain for training, and we form the target training set by drawing NT = d samples
3Descriptions and download links are provided in the appendix.

from the target dataset. Later, we randomly sample J = 1000 data points from the remaining target samples to form the sequentially arriving target test samples. Note that the performance of the experts is sensitive to the data, and thus we replicate this procedure 100 times. We set the regularization parameter of the ridge regression problem to  = 10-6 and the learning rate of the BOA algorithm to  = 0.5. We measure the performance of the experts by the cumulative loss (1) calculated for every J. Table 1 shows the average cumulative loss of each aggregated expert obtained by the BOA algorithm for all datasets and for J = {5, 10, 50, 100} across 100 independent runs. In each row, the minimum loss is normalized to 1, and the remaining entries are presented by the multiplicative factor of the minimum value. This result suggests that the IRWASS and SI-WASS experts perform favorably over the competitors in that their cumulative loss at each time step is substantially lower than that of most other competitors.
Figure 4. Cumulative loss averaged over 100 runs, Uber&Lyft.
Figure 4 demonstrates how the average cumulative loss

in (1) grows over time for the Uber&Lyft dataset. Figure 4 shows that the loss of LSE-T&S is initially constant at a high level, which highlights the discrepancy between the two domain distributions. The growth rate of LSE-T decays faster than that of other experts, and the time when LSE-T saturates indicates when the combined target domain data alone is sufficient to construct a single, competitive predictor without using any source domain data.
Concluding Remarks. The theoretical and experimental results in this paper suggest that IR-WASS and SI-WASS are attractive schemes to generate a family of robust least squares experts. Moreover, the IR-WASS and SI-WASS experts are extremely easy to compute because it requires solving only a second-order cone or a linear semidefinite program. We observe that KL-type divergence schemes are less numerically stable due to the computation of the logdeterminant and the inverse of a nearly singular covariance matrix T. Setting the parameters for KL-type divergence schemes is also harder due to the asymmetry of the divergence D. While this paper focuses solely on interpolating schemes, it would also be interesting to explore extrapolating schemes in future research.
Acknowledgments
Material in this paper is based upon work supported by the Air Force Office of Scientific Research under award number FA9550-20-1-0397. Additional support is gratefully acknowledged from NSF grants 1915967, 1820942, 1838676, and also from the China Merchant Bank. Man-Chung Yue gratefully acknowledges the support by HKRGC under the Early Career Scheme Funding 25302420.
References
Agueh, M. and Carlier, G. Barycenters in the Wasserstein space. SIAM Journal on Mathematical Analysis, 43(2): 904­924, 2011.
Azizzadenesheli, K., Liu, A., Yang, F., and Anandkumar, A. Regularized learning for domain adaptation under label shifts. In International Conference on Learning Representations, 2019.
Baktashmotlagh, M., Harandi, M. T., Lovell, B. C., and Salzmann, M. Unsupervised domain adaptation by domain invariant projection. In IEEE International Conference on Computer Vision, pp. 769­776, 2013.
Battistelli, G., Chisci, L., Fantacci, C., Farina, A., and Graziano, A. Consensus CPHD filter for distributed multitarget tracking. IEEE Journal of Selected Topics in Signal Processing, 7(3):508­520, 2013.
Ben-David, S., Blitzer, J., Crammer, K., Pereira, F., et al.

Analysis of representations for domain adaptation. Advances in Neural Information Processing Systems, 19: 137, 2007.
Bernstein, D. S. Matrix Mathematics: Theory, Facts, and Formulas. Princeton University Press, 2009.
Bertsekas, D. Convex Optimization Theory. Athena Scientific, 2009.
Blanchet, J., Kang, Y., and Murthy, K. Robust Wasserstein profile inference and applications to machine learning. Journal of Applied Probability, 56(3):830­857, 2019.
Blitzer, J., McDonald, R., and Pereira, F. Domain adaptation with structural correspondence learning. In Conference on Empirical Methods in Natural Language Processing, pp. 120­128, 2006.
Cesa-Bianchi, N. and Lugosi, G. Prediction, Learning, and Games. Cambridge University Press, 2006.
Chen, X., Monfort, M., Liu, A., and Ziebart, B. D. Robust covariate shift regression. In Artificial Intelligence and Statistics, pp. 1270­1279, 2016.
Chu, C. and Wang, R. A survey of domain adaptation for neural machine translation. In International Conference on Computational Linguistics, pp. 1304­1319. Association for Computational Linguistics, 2018.
Cortes, C. and Mohri, M. Domain adaptation and sample bias correction theory and algorithm for regression. Theoretical Computer Science, 519:103 ­ 126, 2014.
Cortes, C., Mohri, M., and Medina, A. M. Adaptation based on generalized discrepancy. Journal of Machine Learning Research, 20(1):1­30, 2019.
Courty, N., Flamary, R., Tuia, D., and Rakotomamonjy, A. Optimal transport for domain adaptation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39 (9):1853­1865, 2017.
Csurka, G. A Comprehensive Survey on Domain Adaptation for Visual Applications, pp. 1­35. Springer International Publishing, 2017.
de Mathelin, A., Richard, G., Mougeot, M., and Vayatis, N. Adversarial weighting for domain adaptation in regression. arXiv preprint arXiv:2006.08251, 2020.
Delage, E. and Ye, Y. Distributionally robust optimization under moment uncertainty with application to data-driven problems. Operations Research, 58(3):595­612, 2010.
Duchi, J. and Namkoong, H. Learning models with uniform performance via distributionally robust optimization. arXiv preprint arXiv:1810.08750, 2018.

Ganin, Y. and Lempitsky, V. Unsupervised domain adaptation by backpropagation. In International Conference on Machine Learning, pp. 1180­1189, 2015.
Gao, R. Finite-sample guarantees for Wasserstein distributionally robust optimization: Breaking the curse of dimensionality. arXiv preprint arXiv:2009.04382, 2020.
Gao, R., Xie, L., Xie, Y., and Xu, H. Robust hypothesis testing using Wasserstein uncertainty sets. In Advances in Neural Information Processing Systems, pp. 7913­7923, 2018.
Garcke, J. and Vanck, T. Importance weighted inductive transfer learning for regression. In Joint European conference on machine learning and knowledge discovery in databases, pp. 466­481, 2014.
Ghaoui, L. E. and Lebret, H. Robust solutions to leastsquares problems with uncertain data. SIAM Journal on Matrix Analysis and Applications, 18(4):1035­1064, 1997.
Ghifary, M., Kleijn, W. B., Zhang, M., Balduzzi, D., and Li, W. Deep reconstruction-classification networks for unsupervised domain adaptation. In European Conference on Computer Vision, pp. 597­613, 2016.
Givens, C. and Shortt, R. A class of Wasserstein metrics for probability distributions. The Michigan Mathematical Journal, 31(2):231­240, 1984.
Goh, J. and Sim, M. Distributionally robust optimization and its tractable approximations. Operations Research, 58(4):902­917, 2010.
Huang, J., Gretton, A., Borgwardt, K., Scho¨lkopf, B., and Smola, A. Correcting sample selection bias by unlabeled data. Advances in Neural Information Processing Systems, 19:601­608, 2006.
Jiang, J. and Zhai, C. Instance weighting for domain adaptation in NLP. In Association of Computational Linguistics, pp. 264­271, 2007.
Koniusz, P., Tas, Y., and Porikli, F. Domain adaptation by mixture of alignments of second-or higher-order scatter tensors. In IEEE Conference on Computer Vision and Pattern Recognition, pp. 4478­4487, 2017.
Kuhn, D., Mohajerin Esfahani, P., Nguyen, V. A., and Shafieezadeh-Abadeh, S. Wasserstein distributionally robust optimization: Theory and applications in machine learning. In Operations Research & Management Science in the Age of Analytics, pp. 130­166. 2019.
Kumar, A., Saha, A., and Daume, H. Co-regularization based semi-supervised domain adaptation. Advances in

Neural Information Processing Systems, pp. 478­486, 2010.
Lam, H. Recovering best statistical guarantees via the empirical divergence-based distributionally robust optimization. Operations Research, 67(4):1090­1105, 2019.
Lattimore, T. and Szepesva´ri, C. Bandit Algorithms. Cambridge University Press, 2020.
Li, Q. Literature survey: Domain adaptation algorithms for natural language processing. Department of Computer Science The Graduate Center, The City University of New York, pp. 8­10, 2012.
Li, Y., Wang, L., Wang, J., Ye, J., and Reddy, C. K. Transfer learning for survival analysis via efficient L2,1-norm regularized Cox regression. In IEEE International Conference on Data Mining, pp. 231­240, 2016.
Lipton, Z., Wang, Y.-X., and Smola, A. Detecting and correcting for label shift with black box predictors. In International Conference on Machine Learning, pp. 3122­ 3130, 2018.
Lo¨fberg, J. YALMIP: A toolbox for modeling and optimization in MATLAB. In IEEE International Conference on Robotics and Automation, pp. 284­289, 2004.
Long, M., Zhu, H., Wang, J., and Jordan, M. I. Unsupervised domain adaptation with residual transfer networks. In International Conference on Neural Information Processing Systems, pp. 136­144, 2016.
Lopez-Paz, D., Herna´ndez-Lobato, J. M., and Scho¨lkopf, B. Semi-supervised domain adaptation with non-parametric copulas. In International Conference on Neural Information Processing Systems, pp. 665­673, 2012.
Malitsky, Y. and Mishchenko, K. Adaptive gradient descent without descent. arXiv preprint arXiv:1910.09529, 2019.
McCann, R. J. A convexity principle for interacting gases. Advances in Mathematics, 128(1):153­179, 1997.
Mohajerin Esfahani, P. and Kuhn, D. Data-driven distributionally robust optimization using the Wasserstein metric: Performance guarantees and tractable reformulations. Mathematical Programming, 171(1):115­166, 2018.
MOSEK ApS. The MOSEK optimization toolbox. Version 9.2., 2019.
Motiian, S., Jones, Q., Iranmanesh, S., and Doretto, G. Few-shot adversarial domain adaptation. In Advances in Neural Information Processing Systems, volume 30, pp. 6670­6680, 2017a.

Motiian, S., Piccirilli, M., Adjeroh, D. A., and Doretto, G. Unified deep supervised domain adaptation and generalization. In IEEE International Conference on Computer Vision, pp. 5715­5725, 2017b.
Namkoong, H. and Duchi, J. C. Stochastic gradient methods for distributionally robust optimization with fdivergences. In Advances in Neural Information Processing Systems, volume 29, pp. 2208­2216, 2016.
Nguyen, V. A., Shafieezadeh-Abadeh, S., Yue, M.-C., Kuhn, D., and Wiesemann, W. Calculating optimistic likelihoods using (geodesically) convex optimization. In Advances in Neural Information Processing Systems, 2019a.
Nguyen, V. A., Shafieezadeh-Abadeh, S., Yue, M.-C., Kuhn, D., and Wiesemann, W. Optimistic distributionally robust optimization for nonparametric likelihood approximation. In Advances in Neural Information Processing Systems 32, 2019b.
Nguyen, V. A., Si, N., and Blanchet, J. Robust Bayesian classification using an optimistic score ratio. In International Conference on Machine Learning, 2020.
Pardoe, D. and Stone, P. Boosting for regression transfer. In International Conference on Machine Learning, 2010.
Redko, I., Morvant, E., Habrard, A., Sebban, M., and Bennani, Y. Advances in Domain Adaptation Theory. Elsevier, 2019.
Richard, G., de Mathelin, A., He´brail, G., Mougeot, M., and Vayatis, N. Unsupervised multi-source domain adaptation for regression. 2020.
Saha, A., Rai, P., Daume´, H., Venkatasubramanian, S., and DuVall, S. L. Active supervised domain adaptation. In Machine Learning and Knowledge Discovery in Databases, pp. 97­112, 2011.
Salaken, S. M., Khosravi, A., Nguyen, T., and Nahavandi, S. Seeded transfer learning for regression problems with deep learning. Expert Systems with Applications, 115: 565 ­ 577, 2019.
Shafieezadeh-Abadeh, S., Nguyen, V. A., Kuhn, D., and Mohajerin Esfahani, P. Wasserstein distributionally robust Kalman filtering. In Advances in Neural Information Processing Systems, volume 31, pp. 8474­8483, 2018.
Shimodaira, H. Improving predictive inference under covariate shift by weighting the log-likelihood function. Journal of Statistical Planning and Inference, 90(2):227­244, 2000.
Sindhwani, V., Niyogi, P., and Belkin, M. A coregularization approach to semi-supervised learning with

multiple views. In ICML workshop on learning with multiple views, pp. 74­79, 2005.
Sion, M. On general minimax theorems. Pacific Journal of Mathematics, 8(1):171­176, 1958.
Søgaard, A. Semi-supervised learning and domain adaptation in natural language processing. Synthesis Lectures on Human Language Technologies, 6(2):1­103, 2013.
Still, G. Lectures on Parametric Optimization: An Introduction. 2018.
Sugiyama, M., Suzuki, T., Nakajima, S., Kashima, H., von Bu¨nau, P., and Kawanabe, M. Direct importance estimation for covariate shift adaptation. Annals of the Institute of Statistical Mathematics, 60(4):699­746, 2008.
Sun, Q., Chattopadhyay, R., Panchanathan, S., and Ye, J. A two-stage weighting framework for multi-source domain adaptation. In Advances in Neural Information Processing Systems, volume 24, pp. 505­513, 2011.
Tzeng, E., Hoffman, J., Darrell, T., and Saenko, K. Simultaneous deep transfer across domains and tasks. In IEEE International Conference on Computer Vision, pp. 4068­4076, 2015.
Villani, C. Optimal Transport: Old and New. Springer Science & Business Media, 2008.
Wang, H., Liu, A., Yu, Z., Yue, Y., and Anandkumar, A. Distributionally robust learning for unsupervised domain adaptation. arXiv preprint arXiv:2010.05784, 2020.
Wang, M. and Deng, W. Deep visual domain adaptation: A survey. Neurocomputing, 312:135 ­ 153, 2018.
Weiss, K., Khoshgoftaar, T. M., and Wang, D. A survey of transfer learning. Journal of Big Data, 3(1):1­40, 2016.
Wilson, G. and Cook, D. J. A survey of unsupervised deep domain adaptation. ACM Transactions on Intelligent Systems and Technology, 11(5):1­46, 2020.
Wintenberger, O. Optimal learning with Bernstein online aggregation. Machine Learning, 106(1):119­141, 2017.
Yao, T., Pan, Y., Ngo, C.-W., Li, H., and Mei, T. Semisupervised domain adaptation with subspace learning for visual recognition. In IEEE conference on Computer Vision and Pattern Recognition, pp. 2142­2150, 2015.
Zhao, H., Zhang, S., Wu, G., Moura, J. M. F., Costeira, J. P., and Gordon, G. J. Adversarial multiple source domain adaptation. In Advances in Neural Information Processing Systems, volume 31, 2018.

A. Appendix
A.1. Proof of Section 4
Proof of Proposition 4.1. Note that optimization problem (3) constitutes an unbounded convex optimization problem when  is the Kullback-Leibler-type divergence of Definition 3.1. Let g(µ, ) D((µ, ) (µS, S)) + (1 - )D((µ, ) (µT, T)), then, the first order optimality condition reads
µg(µ, ) = 2-S 1(µ - µS) + 2(1 - )-T1(µ - µT) = 0, g(µ, ) = -S 1 - -1 + (1 - )-T1 - (1 - )-1 = 0.
One can then show (µ, ) provided in statement of Proposition 4.1 solves the system of equalities above.

Below we prove Proposition 4.2. In the proof of Proposition 4.2 and its auxiliary lemmas, Lemma A.1 and Lemma A.2, we

omit the subscripts  and  to avoid clutter.

Lemma A.1 (Dual problem). Fix (µ, )  Rp × Sp++ and   0. For any symmetric matrix H  Sp, the optimization

problem





sup
µ,

Tr H( + µµ )

 s. t.

Tr -1 - log det(-1) - p + (µ - µ) -1(µ - µ)  , 0

(A.5a)

admits the dual formulation

inf

( - µ

-1µ) + 2µ

-1[-1

-

H ]-1 -1 µ

-



log

det(I

-



1 2

H

1 2

/)

s. t.   0, -1 H.

(A.5b)

Proof of Lemma A.1. For any µ  Rp such that (µ - µ) -1(µ - µ)  , denote the set Sµ as

Sµ   Sp++ : Tr -1 - log det   µ ,

where µ  R is defined as µ  + p - log det  - (µ - µ) -1(µ - µ). Using these auxiliary notations, problem (A.5a) can be re-expressed as a nested program of the form

sup µ Hµ + sup Tr H

µ

Sµ

s. t. (µ - µ) -1(µ - µ)  ,

where we emphasize that the constraint on µ is redundant, but it is added to ensure the feasibility of the inner supremum over  for every feasible value of µ of the outer problem. We now proceed to reformulate the supremum subproblem over .
Assume momentarily that H = 0 and that µ satisfies (µ - µ) -1(µ - µ) < . In this case, one can verify that  is a Slater point of the convex set Sµ. Using a duality argument, we find

sup
Sµ

Tr

H

= sup inf
 0 0

Tr

H

+  µ - Tr

-1

+ log det 

= inf
0

µ + sup Tr (H - -1) +  log det 
0

,

where the last equality follows from strong duality (Bertsekas, 2009, Proposition 5.3.1). If H - -1  0, then the inner supremum problem becomes unbounded. To see this, let   R+ be the maximum eigenvalue of H - -1 with the corresponding eigenvector v, then the sequence (k)kN with k = I + kvv attains the asymptotic maximum objective
value of +. If H - -1  0 then the inner supremum problem admits the unique optimal solution

 () = (-1 - H)-1,

(A.6)

which is obtained by solving the first-order optimality condition. By placing this optimal solution into the objective function and arranging terms, we have

sup Tr H = inf

  - (µ - µ)

-1(µ - µ)

-



log

det(I

-



1 2

H



1 2

/).

Sµ

0 -1 H

(A.7)

We now argue that the above equality also holds when µ is chosen such that (µ - µ) -1(µ - µ) = . In this case, Sµ

collapses into a singleton {}, and the left-hand side supremum problem attains the value Tr H . The right-hand side

infimum problem becomes

inf

-



log

det(I

-



1 2

H



1 2

/).

0

-1 H

One can show using the l'Hopital rule that

lim

-



log

det(I

-

1 2

H

1 2

/)

=

Tr

H

,

+

which implies that the equality holds. Furthermore, when H = 0, the left-hand side of (A.7) evaluates to 0, while the infimum problem on the right-hand side of (A.7) also attains the optimal value of 0 asymptotically as  decreases to 0. This implies that (A.7) holds for all H  Sp and for any µ satisfying (µ - µ) -1(µ - µ)  .
The above line of argument shows that problem (A.5a) can now be expressed as the following maximin problem

sup

inf

µ

Hµ +   - (µ - µ)

-1(µ - µ)

-



log

det(I

-



1 2

H

1 2

/).

µ:(µ-µ)

-1 (µ-µ)

0 -1 H

For any   0 such that -1 H, the objective function is concave in µ. For any µ, the objective function is convex in .

Furthermore, the feasible set of µ is convex and compact, and the feasible set of  is convex. As a consequence, we can

apply Sion's minimax theorem (Sion, 1958) to interchange the supremum and the infimum operators, and problem (A.5a) is

equivalent to









-



log

det(I

-



1 2

H



1 2

/)



inf
0



-1 H

+

sup

µ Hµ - (µ - µ) -1(µ - µ)  .

µ:(µ-µ) -1(µ-µ)

For any  which is feasible for the outer problem, the inner supremum problem is a convex quadratic optimization problem because -1 H. Using a strong duality argument, the value of the inner supremum equals to the value of

inf  - ( + )µ -1µ + sup µ (H - ( + )-1)µ + 2( + )(-1µ) µ

0

µ

= inf  - ( + )µ -1µ + ( + )2(-1µ) [( + )-1 - H]-1(-1µ),
0

where the equality follows from the fact that the unique optimal solution in the variable µ is given by

( + )[( + )-1 - H]-1-1µ.

(A.8)

By combining two layers of infimum problem and using a change of variables    + , problem (A.5a) can now be written as

inf

( - µ

-1µ) + 2µ

-1[-1

-

H ]-1 -1 µ

-



log

det(I

-



1 2

H

1 2

/)

s. t.   0, -1 H,  -   0.

(A.9)

We now proceed to eliminate the multiplier  from the above problem. To this end, rewrite the above optimization problem
as inf ( - µ -1µ) + 2µ -1[-1 - H]-1-1µ + g() s. t.   0, -1 H,

where g() is defined for every feasible value of  as

g()

inf

-

log

det(I

-



1 2

H

1 2

/)

s. t.   0, -1 H,   .

(A.10)

Let g0() denote the objective function of the above optimization, which is independent of . Let 1, . . . , p be the

eigenvalues

of

1 2

H

1 2

,

we

can

write

the

function

g

directly

using

the

eigenvalues

1,

.

.

.

,

p

as

p
g0() = - log(1 - i/).
i=1

It is easy to verify by basic algebra manipulation that the gradient of g0 satisfies

p

g0() =

log

i=1

  - i

-



 - i

+ p  0,

which

implies

that

the

value

of



that

solves

(A.10)

is

,

and

thus

g()

=

-

log

det(I

-

1 2

H



1 2

/).

Substituting



by



in problem (A.9) leads to the desired claim.

Lemma A.2 (Optimal solution attaining f ()). For any (µ, )  Rp × Sp++,   R++ and w  Rp, f () equals to the optimal value of the optimization problem

sup w ( + µµ )w
µ, 0
s. t. Tr -1 - log det(-1) - p + (µ - µ) -1(µ - µ)  ,

(A.11a)

which admits the unique optimal solution  =  ( -1 - ww )-1,

µ =  -1µ,

(A.11b)

with  > w w being the unique solution of the nonlinear equation

 = (w µ)2w w + w w + log ( - w w)2  - w w

1-

w

w 

.

(A.11c)

Moreover, we have   w w 1 + 2 + 1 + 4(w µ)2 /(2).

Proof of Lemma A.2. First, note that

f () = sup EQ ( X - Y )2 = sup EQ w  w = sup w  + µµ w,

QB

QB

(µ,)U

which, by the definition of U and definition (3.2), equals to the optimal value of problem (A.11a).

From the duality result in Lemma A.1, problem (A.11a) is equivalent to

inf

( - µ

-1µ) + (-1µ)

[-1 - ww

]-1(-1µ)

-



log

det(I

-



1 2

ww



1 2

/)

s. t.   0, -1 ww .

Applying Bernstein (2009, Fact 2.16.3), we have the equalities

det(I

-



1 2

ww



1 2

/)

=

1

-

w

w/

(-1 - ww )-1 = -1 + -2 1 - w w/ -1ww ,

and thus by some algebraic manipulations we can rewrite

f () =

inf  + (w µ)2 -  log 1 - w w/
-w w
s. t.  > w w.

(A.12)

Let f0 be the objective function of the above optimization problem. The gradient of f0 satisfies

f0()

=



-

(w µ)2w w ( - w w)2

-



w w - w w

-

log

1-

w

w 

.

By the above expression of f0() and the strict convexity of f0(), the value  that solves (A.11c) is also the unique minimizer of (A.12). In other words, f0() = f ().
We now proceed to show that (µ ,  ) defined as in (A.11b) is feasible and optimal. First, we prove feasibility of (µ ,  ). By direct computation,

(µ - µ) -1(µ - µ) = µ (-1 - I)-1( -1 - I)µ = (µ w)2w w . ( - w w)2

(A.13a)

Moreover, because  -1 = I + ( - w w)-1ww , we have

Tr

 -1

- log det( -1) - p = (

-w

w)-1w

w + log

1

-

w

w 

.

Combining (A.13a) and (A.13b), we have

Tr  -1 - log det( -1) - p + (µ - µ) -1(µ - µ) = ,

(A.13b)

where the first equality follows from the definition of D, and the second equality follows from the fact that  solves (A.11c). This shows the feasibility of (µ ,  ).
Next, we prove the optimality of (µ ,  ). Through a tedious computation, one can show that

w ( + (µ )(µ ) )w = w ( +  -1µµ -1 )w

=w w 1 + w w

+ (µ w)2 1 + 2w w + (w µ)2(w w)2

 - w w

 - w w

( - w w)2

=  w w + ( )2(µ w)2  - w w ( - w w)2

=  w w +  (µ w)2w w +  (µ w)2  - w w ( - w w)2  - w w

=

-

log

1

-

w

w 

+

 (µ w)2  - w w

= f0(

) = f (),

where the antepenultimate equality follows from the fact that  solves (A.11c), and the last equality holds because  is the minimizer of (A.12). Therefore, (µ ,  ) is optimal to problem (A.11a). The uniqueness of (µ ,  ) now follows from the unique solution of  and µ with respect to the dual variables from (A.6) and (A.8), respectively.

It now remains to show the upper bound on  . Towards that end, we note that for any  > w w,

0 =  - (w µ)2w w - w w - log ( - w w)2  - w w

1

-

w

w 

>  - (w µ)2w w - w w . ( - w w)2  - w w

Solving the above quadratic inequality in the variable  - w w yields the desired bound. This completes the proof.

We are now ready to prove Proposition 4.2.

Proof of Proposition 4.2. The convexity of f follows immediately by noting that it is the pointwise supremum of the family of convex functions EQ[( X - Y )2] parametrized by Q.

To prove the continuously differentiability and the formula for the gradient, recall the expression (A.12) for the function

f ():

f () =

inf  + (w µ)2 -  log 1 - w w/
-w w
s. t.  > w w.

(A.14)

Problem (A.14) has only one constraint. Therefore, LICQ (hence MFCQ) always holds, which implies that the Lagrange multiplier  of problem (A.14) is unique for any . Also, it is easy to see that the constraint of problem (A.14) is never binding. So,  = 0 for any . The Lagrangian function L : R × R  R is given by

L(, )

=



+

2  - 1

-  log

1

-

1 

+ (1 - ),

where 1 = w w and 2 = (w µ)2. The first derivative with respect to  is

dL d

(, )

=



-

12 ( - 1)2

-

log

1

-

1 

-



1 - 1

-

.

The second derivative with respect to  is

d2L d2

(,



)

=

(

1 - 1)3

22

+

1 

(

-

1)

.

From the proof of Lemma A.2, we have that the minimizer  of problem (A.14) is precisely the  defined by equation (A.11c) (below we write  instead of  to emphasize and keep track of the dependence on ). Therefore, for any , the minimizer  exists and is unique. So, there exists some constant  > 0 such that

d2L d2

(, )





>

0.

Therefore, for any , the strong second order condition at  holds (see Still (2018, Definition 6.2)). By Still (2018, Theorem

6.7),

f () = L(, ) = L(, 0)   Rd.

(A.15)

Then we compute

Hence,

wL(, ) = w

(w µ)2 -  log  - w w

1-

w

w 

+ (w w - )

=

22 ( - 1

)2

w

+

(

2 - 1)

µµ

w

+

(

2 - 1)

w

+

2 w.

L(, )

=

dw d

· wL(, ) = [Id 0d] · wL(, ),

which, when combined with (A.15), yields the desired gradient formula

2 2w+( -1)(+µµ )w

f () =

( - 1)2

1:d .

By Still (2018, Theorem 6.5), the function    is locally Lipschitz continuous, i.e., for any   Rd, there exists c,  > 0 such that if  -  2  , then

| - |  c  -  2 .

Note that 1 and 2 are both locally Lipschitz continuous in . Also, it is easy to see that  > 1 for any . Thus, f () is locally Lipschitz continuous in .

Proof of 4.3. Noting that problem (3) is the barycenter problem between two Gaussian distributions with respect to the Wasserstein distance, the proof then directly follows from Agueh & Carlier (2011, §6.2) and McCann (1997, Example 1.7).

Proof of Proposition 4.4. Again we omit the subscripts  and . Reminding that  = (X, Y ), we find

sup EQ[( X - Y )2] = sup EQ[(w )2]

QB

QB



inf s. t.

= 

 

 

-

µ

2 2

-

Tr

R+, z  R+,

 Z

+z  Sp+

+

Tr

Z

I - ww



1 2



1 2

Z

0,

I - ww µ

µ z

0

=

inf

 -

µ

2 2

-

Tr



+ 2µ (I - ww )-1µ + 2 Tr (I - ww )-1

s. t.   w 22,

(A.16)

where the second equality follows from Kuhn et al. (2019, Lemma 2). By applying Bernstein (2009, Fact 2.16.3), we find

(I - ww )-1 = -1I + -2 1 - w 22/ -1ww .

(A.17)

Combining (A.16) and (A.17), we get

sup EQ[( X - Y )2] =
QB

inf

 + w

( + µµ

)w/( -

w

2 2

)

s. t.



w

2 2

.

One can verify through the first-order optimality condition that the optimal solution  is





 = w 2 w 2+

w

( + µµ 

)w  ,

and by replacing this value  into the objective function, we find

sup EQ[( X - Y )2] =
QB

w ( + µµ )w +  w 2 2,

which then completes the proof.

A.2. Proof of Section 5 Lemma A.3 (Compactness). For k  {S, T}, the set
Vk = {(µ, M )  Rp × Sp++ : M - µµ  Sp++, D((µ, M - µµ ) (µk, k))  k} is convex and compact. Furthermore, the set
V {(µ, M )  Rp × Sp++ : (µ, M - µµ )  US,T } is also convex and compact.

Proof of Lemma A.3. For any (µ, M )  Rp × Sp++ such that M - µµ  Sp++, we find
D (µ, M - µµ ) (µk, k) =(µ - µk) -k 1(µ - µk) + Tr (M - µµ )-1 - log det((M - µµ )-k 1) - p =µk -k 1µk - 2µk -k 1µ + Tr M -k 1 - log det(M -k 1) - log(1 - µ M -1µ) - p,
where in the last expression, we have used the determinant formula (Bernstein, 2009, Fact 2.16.3) to rewrite
det(M - µµ ) = (1 - µ M -1µ) det M.

(A.18)

Because M - µµ  Sp++, one can show that 1 - µ M -1µ > 0 by invoking the Schur complement, and as such, the logarithm term in the last expression is well-defined. Moreover, we can write

  Vk = (µ, M ) :

(µ, M )  Rp × Sp++, M - µµ  Sp++, t  R+ :

µk -k 1µk - 2µk -k 1µ + Tr M -k 1 - log det(M -k 1) - log(1 - t) - p  

Mµ µt

0

   ,

(A.19)

which is a convex set. Notice that by Schur complement, the semidefinite constraint is equivalent to t  µ M -1µ. Next, we show that Vk is compact. Denote by Uk = {(µ, )  Rp × Sp+ : D((µ, ) (µk, k))  k}. Then, it is easy to see that Vk is the image of Uk under the continuous mapping (µ, )  (µ,  + µµ ). Therefore, it suffices to prove the compactness of Uk. Towards that end, we note that

D (µ, ) (µk, k) = (µk - µ) -k 1(µk - µ) + Tr -k 1 - log det(-k 1) - p

is a continuous and coercive function in (µ, ). Thus, as a level set of D (µ, ) (µk, k) , Uk is closed and bounded, and hence compact.

To prove the last claim, by the definitions of V and US,T we write

V = {(µ, M )  Rp × Sp++ : (µ, M - µµ )  US,T } ={(µ, M )  Rp × Sp++ : (µ, M )  VS}  {(µ, M )  Rp × Sp++ : (µ, M )  VT}  {(µ, M )  Rp × Sp++ : M

I }. (A.20)

The convexity of {(µ, M )  in (A.20). Furthermore, from {(µ, M )  Rp × Sp++ : (µ, M

Rp × Sp++ :
the first part )  VT} are

(µ, M - µµ of the proof, compact sets,

ws)oeiks nUthoewSi,rtTihn}attetrbhsoeetnchtif{oo(nllµ.o,AwMlsso)fr,othmRe tlphae×stcsSoep+nt v+{e(xµ: i,(tyµM,oM)f t)hRepthV×rSee}Sp+sae+ntds:

M I} in (A.20) is closed. Since any closed subset of a compact set is again compact, we conclude that V is compact.

This completes the proof.

Proof of Theorem 5.2. As  = (X, Y ), we can rewrite

min
Rd

sup
QBS ,T

EQ[(

X - Y )2]

= min sup
Rd QBS,T

 -1

EQ[

]

 -1

= min

sup

Rd (µ,M -µµ )US,T

 -1

M

 -1

= min sup
Rd (µ,M )V

 -1

M

 -1

= sup min
(µ,M )V Rd

 -1

M

 -1

= sup MY Y - MXY MX-X1 MXY
(µ,M )V

(A.21a) (A.21b)
(A.21c) (A.21d)

where (A.21c) follows from the Sion's minimax theorem, which holds because the objective function is convex in , concave in M , and Lemma A.3. Equation (A.21d) exploits the unique optimal solution in  as  = MX-X1 MXY , in which the matrix inverse is well defined because M 0 for any feasible M .
Finally, after an application of the Schur complement reformulation to (A.21d), the nonlinear semidefinite program in the theorem statement follows from representations (A.19) and (A.20). This completes the proof.

Proof of Proposition 5.3. It is well-known that the space of probability measures equipped with the Wasserstein distance
W2 is a geodesic metric space (see Villani (2008, Section 7) for example), meaning that for any two probability distributions N0 and N1, there exists a constant-speed geodesic curve [0, 1] a  Na satisfying

W2(Na, Na ) = |a - a |W2(N0, N1) a, a  [0, 1].

The claim follows trivially if W2(NS, NT)  S. Therefore, we assume W2(NS, NT) > S.
Consider the the geodesic Nt from N0 = NS to N1 = NT. Also, denote by Uk = {(µ, )  Rp × Sp+ : D((µ, ) (µk, k))  k} for k  {S, T}. Then, US and UT has empty intersection if and only if
W2(Na, NS)  S = W2(Na, NT) > T a  [0, 1],

which is in turn equivalent to

aW2(NT, NS)  S = (1 - a)W2(NT, NS)  T a  [0, 1].

Picking

a

=

S W2 (NT ,NS )



(0, 1),

then

we

have

1

-

S W2(NT, NS)

W2(NT, NS)  T.

The above inequality can be rewritten as which contradicts with our supposition

W2(NT, NS)  S + T,

T 

W((µS, S)

(µT, T)) - S

2
.

Thus, US and UT has non-empty intersection.

Proof of Theorem 5.4. As  = (X, Y ), we can rewrite

min
Rd

sup
QBS ,T

(P)

EQ

[(

X - Y )2]

= min

sup

Rd (µ,M -µµ )US,T

 -1

M

 -1

=

sup

min

(µ,M -µµ )US,T Rd

 -1

M

 -1

=

sup

MY Y - MXY MX-X1 MXY

(µ,M -µµ )US,T

(A.22a)
(A.22b) (A.22c)

where (A.22b) follows from the Sion's minimax theorem, which holds because the objective function is convex in , concave

in M , and the set optimal solution

US ,T in  as

is 

compact (Shafieezadeh-Abadeh et al., = MX-X1 MXY , in which the matrix

2018, Lemma A.6). Equation (A.22c) inverse is well defined because M -

exploits µµ

the unique I for any

feasible M .

B. Additional Numerical Results
In the following the details of the datasets used in Section 6 are presented.
· Uber&Lyft4 has NS = 5000 instances in the source domain and 5000 available samples in the target domain. · US Births (2018)5 has NS = 5172 samples in the source domain and 4828 available samples in the target domain. · Life Expectancy6 has NS = 1407 instances in the source domain and 242 available samples in the target domain. · House Prices in King County7 has NS = 543 instances in the source domain and 334 available samples in the target
domain. · California Housing Prices8 has NS = 9034 instances in the source domain, and 6496 available instances in the target
domain.

Figure A.5 demonstrates how the average cumulative loss in (1) grows over time for the US Births (2018), Life Expectancy, House Prices in KC and California Housing datasets. The results suggest that the IR-WASS and SI-WASS experts perform favorably over the competitors in that their cumulative loss at each time step is lower than that of most other competitors.

4Available publicly at https://www.kaggle.com/brllrb/uber-and-lyft-dataset-boston-ma 5Available publicly at https://www.kaggle.com/des137/us-births-2018 6Available publicly at https://www.kaggle.com/kumarajarshi/life-expectancy-who 7Available publicly at https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data 8The modified version that we use is available publicly at https://www.kaggle.com/camnugent/
california-housing-prices and the original dataset is available publicly at https://www.dcc.fc.up.pt/~ltorgo/
Regression/cal_housing.html

(a) US Births (2018)

(b) Life Expectancy

(c) House Prices in KC

(d) California Housing

Figure A.5. Cumulative loss averaged over 100 runs on logarithmic scale

