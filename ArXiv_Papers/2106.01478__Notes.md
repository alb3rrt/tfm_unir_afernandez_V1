
# Evaluating the Efficacy of Summarization Evaluation across Languages

[arXiv](https://arxiv.org/abs/2106.01478), [PDF](https://arxiv.org/pdf/2106.01478.pdf)

## Authors

- Fajri Koto
- Jey Han Lau
- Timothy Baldwin

## Abstract

While automatic summarization evaluation methods developed for English are routinely applied to other languages, this is the first attempt to systematically quantify their panlinguistic efficacy. We take a summarization corpus for eight different languages, and manually annotate generated summaries for focus (precision) and coverage (recall). Based on this, we evaluate 19 summarization evaluation metrics, and find that using multilingual BERT within BERTScore performs well across all languages, at a level above that for English.

## Comments

Findings of ACL 2021

## Source Code

Official Code

- [https://github.com/fajri91/Multi_SummEval](https://github.com/fajri91/Multi_SummEval)

Community Code

- [https://paperswithcode.com/paper/evaluating-the-efficacy-of-summarization](https://paperswithcode.com/paper/evaluating-the-efficacy-of-summarization)

## Bibtex

```tex
@misc{koto2021evaluating,
      title={Evaluating the Efficacy of Summarization Evaluation across Languages}, 
      author={Fajri Koto and Jey Han Lau and Timothy Baldwin},
      year={2021},
      eprint={2106.01478},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

## Notes

Type your reading notes here...

