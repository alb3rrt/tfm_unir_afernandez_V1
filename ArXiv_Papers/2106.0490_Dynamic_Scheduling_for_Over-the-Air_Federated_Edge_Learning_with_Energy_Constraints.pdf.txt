arXiv:2106.00490v1 [cs.LG] 31 May 2021

1
Dynamic Scheduling for Over-the-Air Federated
Edge Learning with Energy Constraints
Yuxuan Sun, Member, IEEE, Sheng Zhou, Member, IEEE, Zhisheng Niu, Fellow, IEEE, Deniz Gu¨ndu¨z, Senior Member, IEEE
Abstract
Machine learning and wireless communication technologies are jointly facilitating an intelligent edge, where federated edge learning (FEEL) is a promising training framework. As wireless devices involved in FEEL are resource limited in terms of communication bandwidth, computing power and battery capacity, it is important to carefully schedule them to optimize the training performance. In this work, we consider an over-the-air FEEL system with analog gradient aggregation, and propose an energy-aware dynamic device scheduling algorithm to optimize the training performance under energy constraints of devices, where both communication energy for gradient aggregation and computation energy for local training are included. The consideration of computation energy makes dynamic scheduling challenging, as devices are scheduled before local training, but the communication energy for over-theair aggregation depends on the l2-norm of local gradient, which is known after local training. We thus incorporate estimation methods into scheduling to predict the gradient norm. Taking the estimation error into account, we characterize the performance gap between the proposed algorithm and its offline counterpart. Experimental results show that, under a highly unbalanced local data distribution, the proposed algorithm can increase the accuracy by 4.9% on CIFAR-10 dataset compared with the myopic benchmark, while satisfying the energy constraints.
Index Terms
Y. Sun, S. Zhou and Z. Niu are with the Beijing National Research Center for Information Science and Technology, Department of Electronic Engineering, Tsinghua University, Beijing 100084, China (e-mail: sunyuxuan@tsinghua.edu.cn, sheng.zhou@tsinghua.edu.cn, niuzhs@tsinghua.edu.cn).
D. Gu¨ndu¨z is with the Department of Electrical and Electronic Engineering, Imperial College London, London SW7 2BT, UK (e-mail: d.gunduz@imperial.ac.uk).
Part of this work has been presented in IEEE ICC 2020 [1].

2
Federated edge learning, over-the-air computation, energy constraints, dynamic scheduling, Lyapunov optimization.
I. INTRODUCTION Many emerging applications at the wireless edge, such as autonomous driving, virtual reality and Internet of things (IoT), are powered by modern machine learning (ML) techniques. Datadriven approaches also penetrate into the wireless network itself for channel estimation, encoding and decoding, resource allocation, etc. [2], [3]. The complex ML models for these applications need to be trained over massive datasets, while data samples are usually generated by edge devices. Traditional centralized training methods can hardly be competent, as collecting data at one location would create network congestion, lead to extremely high transmission cost and may cause privacy concerns. On the other hand, computing capabilities of base stations (BSs) and edge devices, such as mobile phones, smart vehicles and IoT sensors, are becoming increasingly powerful, enabling intensive computations at the edge [4]. In this context, federated learning (FL) is considered as a promising training framework that can exploit distributed data and computational resources with limited communication and privacy leakage [5]­[7]. In FL, multiple devices train a shared model collaboratively with local data, and a central parameter server (PS) coordinates training and aggregates global model periodically. The limited communication resource and non-independent and identically distributed (i.i.d.) data, i.e., the distribution of local data at one device is not identical with that of other devices or the global data, are the two major challenges in FL [8], [9]. Current methods to improve the communication efficiency of FL mainly include model compression [12]­[15], device scheduling [16], [17], and enabling multiple local iterations [15], [18]. Under non-i.i.d. data, the training performance can be improved by sharing global i.i.d. data with devices [9] or the PS [19], introducing data redundancy [1], or scheduling devices based on their importance [17]. In a wireless network, FL can be carried out among wireless edge devices coordinated by a BS, called federated edge learning (FEEL). In FEEL, participating devices are often resource limited in terms of wireless bandwidth, computing capability and battery capacity. A key challenge is to design device scheduling and resource allocation algorithms that optimize the training performance under device energy constraints and training delay budget. Considering the communication energy constraints, an energy-efficient bandwidth allocation policy is proposed

3
to maximize the fraction of scheduled devices in [20], while an online algorithm is designed to maximize the sum utility of scheduling in [21]. Due to the timeliness requirements of FEEL tasks at the wireless edge [22], training delay is also becoming a key performance metric. The total communication delay for training is minimized by joint device selection and wireless resource allocation in [23], while the total training delay taking into account both local computations and model transmission is minimized in [24] by balancing the trade-off between the average delay per round and the total number of rounds required for convergence. Communication delay is combined with the importance of each update for probabilistic scheduling in [25]. A hierarchical FEEL framework is proposed in [26], where the end-to-end training delay is minimized by the joint optimization of update interval and model compression. The trade-off between total energy consumption for communication and computation and the training delay is further considered in [27]­[29], yielding a joint design of local computation speed and wireless resource allocation.
The literature above mainly focuses on the implementation of FEEL via digital wireless communications. However, the unique communication requirement of FEEL, i.e., the PS only needs the average of local model updates rather than each individual vector, makes the separate design of learning and communication protocol highly suboptimal [30]. A new solution called over-the-air computation is facilitated to further improve the communication efficiency [31]­ [35], which is achieved by synchronizing the devices to transmit their local gradients or models in an analog fashion, and exploiting the superposition property of a wireless multiple access channel (MAC) to do the summation over-the-air. Power limits of devices can highly degrade the training performance, which yields the design of power allocation schemes over noisy channels [32], fading channels [33] and broadband fading channels [34]. Power control algorithms that take into account the importance of updates [36], uplink and downlink noise [37], [38], gradient statistics [39] and non-i.i.d. data [40] are further proposed. While over-the-air FEEL requires accurate channel state information (CSI), it is shown in [41] that multiple antennas can help to relax the CSI requirement. The impact of imperfect CSI or synchronization across devices is considered in [42], and a digital realization of over-the-air FEEL is further proposed in [43], based on one-bit gradient quantization and majority voting.
Existing papers on over-the-air FEEL mainly consider average power constraints for communication, but have not considered the computation energy for local model training, which is in fact non-negligible for edge devices. In this work, we aim to optimize the training perfor-

4
mance under total energy constraints of devices by designing an energy-aware dynamic device scheduling algorithm, where energy is consumed for both communication and computation. The introduction of computation energy makes the scheduling decisions challenging due to the causality of decision making and energy consumption. This is because, in over-the-air FEEL, the communication energy of each device for gradient aggregation depends on the l2-norm of its local gradient estimate, which can only be obtained after computation. However, online scheduling decision should be made at the start of each training round before computation. Note that this issue does not arise in the case of digital communication, as the transmission power can be chosen independently of the local update.
The main contributions of this work are summarized as follows: 1) We characterize the convergence bound of the considered over-the-air FEEL system, based on which we formulate a device scheduling problem to optimize the training performance under the total energy budget of each device. Both the communication energy for gradient aggregation and the computation energy for local gradient calculation are included. 2) Due to the unavailability of future system states, we design an energy-aware dynamic device scheduling algorithm based on Lyapunov optimization, where a virtual queue is constructed to indicate the up-to-date energy deficit and enable online decision making. 3) To further address the challenge that communication energy is unknown at the device scheduling point, we propose estimation methods to predict the l2-norm of the local gradients upon scheduling, and characterize the theoretical performance guarantee of the proposed scheduling algorithm by taking the error of energy estimation into consideration. 4) Experiments on MNIST and CIFAR-10 datasets validate that the proposed dynamic device scheduling algorithm can achieve higher model accuracies compared with the myopic benchmark, while satisfying the energy limits. Under a highly-non-i.i.d. scenario, the accuracy can be increased by 4.9%. The impact of design parameters on the training performance and energy consumption are also evaluated to provide guidelines for practical implementations. The rest of this paper is organized as follows. In Section II, we introduce the system model and problem formulation. In Section III, we carry out convergence analysis. The energy-aware dynamic device scheduling algorithm is developed in Section IV with its performance guarantee. Experimental results are shown in Section V, and conclusions are given in Section VI.

5

Fig. 1. Illustration of the considered over-the-air FEEL system.

II. SYSTEM MODEL AND PROBLEM FORMULATION

A. System Overview

As shown in Fig. 1, we consider a FEEL system with one PS and N devices, denoted by

N = {1, 2, . . . , N }. Each device n  N has a local dataset Dn with D data samples, and the global dataset is denoted by D = n=1,...,N Dn with N D data samples.
Given a single data sample x  D, a loss function f (w, x) is used to measure the fitting

performance of an s-dimensional model vector w  Rs. At device n  N , the local loss function

Fn(w) is defined as the the average loss over local data samples, i.e.,

1

Fn(w) D

f (w, x).

(1)

xDn

The goal of the FEEL task is to train a shared global model w that minimizes the global loss

function F (w), which is defined as

1N

1N

F (w) N

Fn(w) = N D

f (w, x).

(2)

n=1

n=1 xDn

Under the coordination of the PS, the FEEL system iterates the following three steps until the

termination condition is satisfied: 1) the PS broadcasts the up-to-date global model to a subset

of devices, which are scheduled to participate in the current training process; 2) the scheduled

devices compute their local gradients with local datasets; and 3) the PS aggregates the local

gradients over a wireless MAC and updates the global model. Each iteration consisting of these

three steps is called a training round, which is indexed by t in the following. The termination

conditions that are commonly used for FEEL include the convergence of the global model, or

6
reaching a preset maximum number of training rounds. Since we consider an energy-limited wireless scenario, we set the total number of training rounds to T .

B. Local Gradient Computation

At the start of the t-th training round, the PS schedules a subset of devices Bt  N , and broadcasts the global model vector wt-1 obtained in the last round to these scheduled devices. Let n,t  {0, 1} be an indicator, with n,t = 1 if device n is scheduled to participate in the t-th

training round, and n,t = 0 otherwise. Thus Bt = {n|n,t = 1, n  N }. We also assume that

the broadcast of wt-1 is error-free since the PS is a more capable node with sufficient power.

Each scheduled device n  Bt computes the local gradient estimate g~n,t by running the

stochastic gradient descent (SGD) algorithm on a local mini-batch Ln,t  Dn, according to

1

g~n,t

=

Lb

f
xLn,t

(wt-1, x) ,

(3)

where Lb = |Ln,t|  D is the batch size, and Ln,t is uniformly selected at random from the

local dataset Dn. We remark here that, a single-iteration gradient update is considered in this

work, but the proposed algorithm can be extended to a more general case where multiple local

iterations are carried out in each training round. Also note that, the batch size is considered

as a hyper-parameter rather than an optimization variable, and set to an identical value across

devices in this work, since local data might be non-i.i.d. across devices and local training should

guarantee the fairness by exploiting the same amount of data.

We assume that for device n, the computation energy for calculating the local gradient

on a single data sample is en, which can be estimated according to the number of floating

point operations (FLOPs) of the ML model and the computation frequency of the device [29]. Therefore, the computation energy consumption En[c,pt] at device n in round t is given by

En[c,pt] = enLb.

(4)

C. Gradient Aggregation Over-the-Air We assume that the devices transmit their local gradients over a noisy wireless MAC in an
analog fashion for global gradient aggregation. To enable the summation of local gradients overthe-air, transmissions are synchronized across all the scheduled devices, and the transmit power

7

of each device is aligned with the others. To be specific, let hn,t be the wireless channel gain between device n and the PS, which is assumed to remain constant during one transmission

period. Note that, the device scheduling policy designed in this work is applicable to arbitrary

channel models. Moreover, as local gradient computation takes time and the wireless channel is

time variant, the channel gain observed at the start of each training round may not be precise.

The observation error, i.e., the difference between the observed channel gain that determines the

device scheduling and its true value during transmission, will also be considered in the following.

Let t be the power scalar that determines the received SNR at the PS. Then the transmit power

pn,t of each scheduled device n  Bt is set to

pn,t

=

t , hn,t

(5)

and pn,tg~n,t is transmitted from device n to the PS. The communication energy consumption En[t,rt] at device n in round t is then given by

En[t,rt] =

pn,tg~n,t

2 2

=

t2 h2n,t

g~n,t

2,
2

(6)

where x 2 represents the l2-norm of vector x. Therefore, if device n is scheduled in the t-th

round, the total energy consumption En,t for computation and communication is

En,t

=

En[t,rt]

+

En[c,pt]

=

t2 h2n,t

g~n,t

2 2

+

enLb.

(7)

At the PS, the received signal yt is given by

yt =

hn,tpn,tg~n,t + zt = t

g~n,t + zt,

(8)

nBt

nBt

where zt  Rs is an additive white Gaussian noise vector, in which each entry is i.i.d. and

follows Gaussian distribution with zero mean and variance 02.

In FEEL, we aim to update the global model vector wt according to

wt = wt-1 - t

nBt g~n,t , |Bt|

(9)

where t is the learning rate in the t-th training round, and | · | denotes the cardinality of a set.

Due to channel noise, the actual global model is updated according to

wt

=

wt-1

-

t

yt t|Bt|

=

wt-1

- t

nBt g~n,t + zt

.

|Bt|

t|Bt|

(10)

8

D. Problem Formulation
Given the total number of training rounds T and the initial global model vector w0, we aim to minimize the expected global loss E[F (wT )] under the energy constraints of devices, by optimizing the device scheduling {n,t} and power scalar {t}. The expectation E[F (wT )] is taken over the randomness of channel noise and data sampling for local SGD. The problem is formulated as

P1 :

min
{t, n,t}Tt=1
s.t.

E[F (wT )]
T
n,tEn,t  E¯n, n,
t=1

t > 0, n,t  {0, 1}, n, t.

(11a) (11b) (11c)

In the first constraint (11b), E¯n represents the total energy budget of device n, and the inequality indicates that for each device, the total energy consumption for both local gradient computation and wireless communication over T training rounds cannot exceed its given budget. The second

constraint limits the ranges of optimization variables.

Based on the law of telescoping sums, problem P1 can be re-written as

P2 : min {t, n,t}Tt=1

T
E[F (wt)] - E[F (wt-1)]
t=1

(12)

s.t. constraints (11b), (11c).

There are three major challenges to solve problem P2:

1) The inexplicit form of the objective function: Since the neural network architectures for

ML might be deep and diverse, and the evolution of the model vector is very complex during

the training process, it is hard to express E[F (wT )] or E[F (wt)] - E[F (wt-1)] in closed form. 2) The unavailability of future information: Optimally solving problem P2 requires the system

states of future training rounds due to the existence of total energy constraints, which are not

available in practice. Therefore, we aim to design an online scheduling algorithm in this work,

which only relies on the system states in the current training round.

3) The causality of decision making and energy consumption: A unique characteristic of over-

the-air FEEL is that the communication energy (6) depends on the l2-norm of local gradient

through

g~n,t

2,
2

which

can

only

be

acquired

after

computing

the

gradient

in

each

round.

9
However, online device scheduling decision should be made before gradient computation, in order not to consume computation energy at unscheduled devices, or even not to transmit global updates to these devices. This means that the exact energy consumption in the current training round is unknown upon decision making. Moreover, the channel gain hn,t observed at the start of each round may not be precise, making the estimation of communication energy more inaccurate.
To address these challenges, we first substitute the objective function with its upper bound based on the convergence analysis in Section III. Then in Section IV, we design an online device scheduling algorithm based on Lyapunov optimization, where the unknown instantaneous states for decision making, including the l2-norm of local gradients and the wireless channel gains, are substituted with their estimates, and in particular, the impact of the estimation error on the performance of the proposed algorithm is analyzed.

III. CONVERGENCE ANALYSIS AND PROBLEM TRANSFORMATION

In this section, we provide an upper bound for the objective function in problem P2 based

on the convergence analysis, and transform the original optimization problem to an alternative

form with explicit expressions.

For the simplicity of notation, we define the local full gradient on device n in the t-th round

as gn,t

Fn(wt-1)

=

1 D

xDn f (wt-1, x), the global full gradient in round t as gt

F (wt-1)

=

1 N

N n=1

gn,t,

and

the

optimum

loss

as

F

minwRs F (w).

To facilitate the convergence analysis, we make the following assumptions according to the

state-of-the-art literature, including [12]­[15], [32]­[34], [43], etc.

Assumption 1. Stochastic gradient is unbiased and variance-bounded, i.e., for any device n and training round t, taking the expectation over stochastic data sampling, we have

Exn [f (wt-1, xn)] = ELn,t g~n,t = gt, Exn

f (wt-1, xn) - gt

2 2

 G2, n, t,

(13)

where xn  Dn is a data sample, Ln,t  Dn is a stochastic mini-batch, and G is a constant.

Assumption 2. Loss functions F1(w), . . . , FN (w) are l-smooth, i.e., for v, w  Rs and n  N ,

Fn(v)

-

Fn(w)



FnT(w)(v

-

w)

+

l 2

v-w

2 2

.

(14)

10

Assumption 3. Loss functions F1(w), . . . , FN (w) are µ-strongly convex, i.e., for v, w  Rs

and n  N ,

Fn(v)

-

Fn(w)



FnT(w)(v

-

w)

+

µ 2

v-w

2 2

.

(15)

A. Convergence Analysis Based on the assumptions above, we provide a single-round convergence guarantee in the
following lemma by characterizing the upper bound of E[F (wt)] - E[F (wt-1)].

Lemma 1. Given the global model vector wt-1 and the set of scheduled devices Bt at the

beginning of round t, the single-round convergence is upper-bounded by

E[F (wt)] - E[F (wt-1)]  -t

1 - lt 2

gt

2 2

+

lt2 2

G2 Lb|Bt|

+

02s t2|Bt|2

,

(16)

where the expectation is taken over the randomness of channel noise and SGD.

Proof. See Appendix A. Based on Lemma 1, the convergence performance of over-the-air FEEL after T training rounds
is given in the following theorem.

Theorem 1. Given the global model vector w0 and any device scheduling sequence {Bt, t =

1, . . . , T }, after T rounds of training,

T

T -1

T

E[F (wT )] - F   (E[F (w0)] - F ) (1 - µi) + Ai

(1 - µi) + AT ,

(17)

i=1

i=1 j=i+1

where At

t 2

+ G2
Lb|Bt|

02 s t2 |Bt |2

and

the

learning

rate

satisfies

t



min{

1 l

,

1},

t.

Proof. See Appendix B.

According to Lemma 1 and Theorem 1, we can see that the number of devices |Bt| scheduled in each round makes a key contribution to the convergence rate of training. While existing papers [1], [20], [21] maximize the weighted fraction of devices scheduled over time, we provide a more reasonable objective function based on the theoretical characterization. We also remark that, although Assumption 1 indicates i.i.d. local data, our proposed algorithm can also work well under non-i.i.d. data as being validated in the experiments in Section V.

11

B. Problem Transformation

As discussed in Section II-D, the objective function

T t=1

E[F

(wt)]

-

E[F

(wt-1)]

in

problem

P2 cannot be expressed explicitly. To make the optimization problem tractable, we substitute

the objective function with its convergence bound according to Lemma 1, and formulate an

alternative optimization problem:

P3 : min {t, n,t}Tt=1

T
-t
t=1

1 - lt 2



gt

2 2

+

lt2 2

  Lb

G2

N n=1

n,t

+

t2



02s



N n=1

n,t

2

(18)

s.t. constraints (11b), (11c),

where we recall that t and n,t are the power scalar and worker scheduling indicator, respectively.

Moreover, due to the unavailability of future system states, we aim to design an online

algorithm to solve problem P3, and ignore the impact of current decision on the future system

states. As the global full gradient gt defined on the whole dataset is fixed given the global model vector wt-1 at the start of training round t, and the learning rate t and smoothness parameter l are hyper-parameters, the first term in (18) is a constant. Therefore, we ignore this term and

transform the optimization problem to

P4 : min {t, n,t}Tt=1

 T lt2  t=1 2  Lb

G2

N n=1

n,t

+

t2



02s



N n=1

n,t

2

(19)

s.t. constraints (11b), (11c).

IV. ENERGY-AWARE DYNAMIC DEVICE SCHEDULING ALGORITHM
In this section, we propose an energy-aware dynamic device scheduling algorithm that solves problem P4 in an online fashion. To address the challenge brought by the causality of decision making and communication energy consumption, we first propose two heuristics to estimate the l2-norm of local gradient estimates. Then, we design an online scheduling algorithm based on Lyapunov optimization, and characterize the worst-case performance of the proposed algorithm, which takes the error of energy estimation into consideration. Finally, we provide some practical considerations for real implementations.

12

A. Estimating the l2-Norm of Local Gradients

We propose two heuristics in the following to estimate the l2-norm of local gradients

g~n,t

2 2

at the start of each training round t.

1) Compute the l2-norm of local gradients with a smaller mini-batch (EST-C):

An additional step is introduced at the start of each training round. To be specific, the PS

broadcasts the up-to-date global model wt-1 to all the devices. Then, each device randomly

selects a mini-batch Ln,t  Dn with batch size Le to calculate a local gradient estimate g~[ne,stt]:

g~[ne,stt]

=

1 Le

f
xLn,t

(wt-1, x) .

(20)

The computation energy should be modified as En[c,pt] = n,ten(Lb - Le) + enLe.

We further assume that each device can upload the value of

g~[ne,stt]

2
2 to the PS with negligible

cost, which is used as the estimation of the l2-norm of local gradient for device n in round t.

Let G2n,t be the variance of the stochastic gradient on a single data sample for device n in

round t. Following the same proof of Lemma 1 as (38), the exact value of gradient norm and

its estimation have the following expectations:

E

g~n,t

2 2

=

gn,t

2 + G2n,t , 2 Lb

E

g~[ne,stt]

2 2

=

gn,t

2 + G2n,t . 2 Le

(21)

As Lb is typically much larger than Le, the expressions above indicate that the estimation may

suffer from a large deviation due to the gradient variance.

2) Estimate with past information (EST-P):

A simpler and more straightforward way is to use the most recent l2-norm of local gradient to estimate the current one at each device. Let tn = arg maxt{t|n,t = 1} be the most recent round in which device n is scheduled. The estimated l2-norm of the current local gradient estimate is:

g~[ne,stt]

2=
2

g~n,tn

2.
2

(22)

We will show in Fig. 2 and Fig. 3 in Section V that, under our considered datasets, estimation by EST-P is more accurate due to the strong temporal correlation of gradients. Moreover, compared with EST-C that requires additional computation and communication, EST-P method is computation-free and only needs each device to report the l2-norm of local gradients when it is scheduled. Therefore, we use EST-P to estimate the l2-norm of local gradient in the following device scheduling algorithm.

13

B. Energy-Aware Dynamic Device Scheduling Algorithm

To enable online scheduling without any future information while satisfying the total energy

constraints of devices, we construct a virtual queue qn,t for each device n to indicate the gap

between the cumulative energy consumption till round t and the budget, evolved as

qn,t+1 = max

qn,t

+

n,tEn,t

-

E¯n , T

0

,

(23)

with initial value qn,1 = 0, n  N .

Recall that the causality of device scheduling and energy consumption leads to the unawareness

of En,t at the start of round t. Based on the estimated l2-norm of local gradient

g~[ne,stt]

2
2 by EST-P

and the wireless channel gain h~n,t observed at the beginning of round t, the estimated energy

consumption of device n at round t, denoted by E~n,t, is given by

E~n,t

=

t2 h~ 2n,t

g~[ne,stt]

2 2

+

enLb.

(24)

Let Ut

lt2 2

Lb

G2

+ N ( ) n=1

n,t

02 s

t2

N n=1

n,t

2

. Inspired by the drift-plus-penalty algorithm of

Lyapunov optimization [44], the online scheduling aims to solve the following problem:

N

P5 : min V Ut + n,tqn,tE~n,t

{t, n,t}

n=1

(25a)

s.t. t > 0, n,t  {0, 1}, n,

(25b)

where V is an adjustable weight parameter to balance the loss Ut and energy consumption. Compared to the classical drift-plus-penalty algorithm where all the states in the current round are known, the drift term qn,tE~n,t in P5 is an approximation, and thus we call it estimated-driftplus-penalty algorithm.
Notice that problem P5 is a mixed integer non-linear programming problem, which is still very difficult to solve. Meanwhile, existing work has shown that the convergence performance of FEEL with over-the-air gradient aggragation is not very sensitive to the power scalar t, as long as the received SNR or the power limit of each device is larger than a threshold [32]. Therefore, we further decouple the optimization variables in P5 by considering the power scalar t as a hyper-parameter, and then develop the optimal solution to the online device scheduling problem. 1) Received SNR and Power Scalar t

14

The power scalar t is chosen as follows. In the t-th round, the expected received SNR at the

PS side is denoted by t, given by

t = E

t

nBt g~n,t

2 2

zt

2 2

=

t2 02s

2

g~n,t .

nBt

2

(26)

Let 0 be a pre-defined SNR threshold. The power scalar is set according to

t =

002s



minnN g~n,t 2

002s

minnN

g~

[est] n,t

,
2

(27)

such that the expectation of the received SNR can meet the threshold 0 even in the worst case

when a single device is scheduled. Recall that g~[ne,stt] 2 according to the EST-P method.
2) Optimal Online Device Scheduling

g~n,t 2 is unknown and thus approximated by

Given the power scalar t, the device scheduling {n,t} in the t-th round aims to solve

N

P6 : min V Ut + n,tqn,tE~n,t

{n,t }

n=1

(28a)

s.t. n,t  {0, 1}, n.

(28b)

An optimal solution to problem P6 is shown in Algorithm 1. In Line 1, we sort Ct = qn,tE~n,t, n in the ascending order, and let Ct[m] be the m-th smallest value of Ct. Many sorting algorithms such as Heapsort or Mergesort can be used, with worst-case complexity O(N log N ).

In Lines 2-4, we iterate over the possible number of scheduled devices k  {1, . . . , N }, and

calculate the corresponding minimum estimated-drift-plus-penalty vt(k) according to

vt(k)

lt2 2

G2 Lbk

+

02s t2k2

k

+

Ct[k].

n=1

(29)

The optimal number of devices k to be scheduled is obtained by finding the minimum vt(k)

according to Line 5, and k devices with smallest estimated drift qn,tE~n,t are scheduled, as shown

Lines 6-8. Besides Line 1, all the other steps are with complexity O(N ), and thus the complexity

of Algorithm 1 is O(N log N ).

3) The Complete Algorithm

The proposed energy-aware dynamic device scheduling algorithm is summarized in Algorithm

2. In the t-th training round, the PS makes device scheduling decision by solving P6 based on the

estimated energy consumption and the virtual queue, which is run in an online fashion without

15

Algorithm 1 Optimal Online Device Scheduling to P6 1: Sort Ct = qn,tE~n,t, n and let Ct[m] be the m-th smallest value of Ct. 2: for k = 1, . . . , N do

3: Calculate vt(k) according to (29).

4: end for

5: Get k = arg mink{vt(k) | k = 1, . . . , N }.

6: for n = 1, . . . , N do

7:

Let n,t = 1 if qn,tE~n,t  Ct[k], and n,t = 0 otherwise.

8: end for

Algorithm 2 Energy-Aware Dynamic Device Scheduling Algorithm

1: Initialization: initialize global model w0. Each device n runs local SGD according to (3)

to report

g~n,0

2 2

to

the

PS,

and

let

qn,1

=

0.

2: for t = 1, . . . , T do

3: The PS set t according to (27), acquires channel gains h~n,t and calculates the estimated

energy consumption E~n,t according to (24) for all devices.

4: The PS schedules a subset of devices Bt by solving P6 according to Algorithm 1.

5: The PS broadcasts wt-1 and t to the scheduled devices n  Bt.

6: Each scheduled device n  Bt updates local gradient g~n,t according to (3), and transmits

g~ t
hn,t n,t

simultaneously

with

all

the

other

scheduled

devices.

7: The PS receives yt and updates the global model wt according to (10).

8: Each scheduled device n  Bt reports En,t and the PS updates the virtual queue qn,t for

all devices according to (23).

9: end for

any future information. The weight parameter V and the virtual queue states {qn,t, n} jointly balance the training gain of the FEEL task and the energy consumption of devices. In particular, a larger V puts more emphasis on scheduling more devices so as to accelerate the convergence rate. Meanwhile, a larger qn,t indicates that the cumulative energy consumption of device n till the current round far exceeds the budget, so that the device tends to save energy. As shown in Algorithm 1, the optimal solution to P6 also indicates that devices with smaller values of

16

qn,tE~n,t are always scheduled first, as their energy is relatively sufficient.

Then, the up-to-date global model vector wt-1 is broadcast to the scheduled devices, who run local SGD to compute local gradients g~n,t in parallel. After computation, local gradients are aggregated over-the-air and the global model is updated by the PS. Finally, the PS collects

the actual energy consumption of each scheduled device, which also contains the information

of local gradient norm

g~n,t

, and updates the virtual queue states for all the devices to guide
2

the scheduling decision in the next training round.

C. Performance Analysis

The performance of the proposed dynamic device scheduling algorithm is characterized by

comparing with its optimal offline counterpart, which is achieved by solving the optimal device

scheduling {n,t} to problem P4 while taking {t} as a pre-defined hyper-parameter sequence.

Let

T t=1

Ut

be

the

offline

optimal

cumulative

loss

of

P4

by

scheduling

device

sequence

{n,t},

and define

T t=1

Ut

as

the

cumulative

loss

of

the

proposed

algorithm,

which

is

achieved

by

solving the online device scheduling problem P6 in each round. To enable the theoretical

analysis, we neglect the impact of current scheduling decision on the future gradient norm

for the offline counterpart. Meanwhile, we do not limit the distributions of wireless channel or

local gradient norms, which can be non-stationary over time.

The performance guarantee of the proposed algorithm is shown in the following theorem.

Theorem 2. Compared to the offline optimal solution, the cumulative loss of Algorithm 2 can

be bounded by

T

Ut 

T

Ut

+

0T 2

+

T (T

- V

1)0

N n=1

n

,

(30)

t=1

t=1

and the total energy consumption of Algorithm 2 can be bounded by

where 0

T
n,tEn,t  E¯n +
t=1

T

N

2V Ut + 20T 2 + 2T (T - 1)0 n ,

t=1

n=1

max{n,t} E~n,t - En,t , 0

N n=1

1 2

n2

and

n

maxt

En,t

-

E¯n T

.

(31)

Proof. See Appendix C.

17
Theorem 2 shows that, the training performance of the proposed energy-aware dynamic device scheduling algorithm can be bounded with respect to its optimal offline counterpart, while the deviation between the cumulative energy consumption of each device and its budget is also bounded. The worst-case performance can be improved by reducing the upper bound of the energy overuse n and the maximum energy estimation error 0. Moreover, the trade-off between the training performance of the FEEL task and maximum energy consumption of each device can be balanced by the weight parameter V .
We also remark here that, compared to the state-of-the-art that also applies Lyapunov optimization to solve scheduling problem under energy constraints [1], [21], [45], our analysis further shows the impact of estimation error on the performance bound.

D. Implementation Issues

To enable the efficient implementation of the proposed algorithm in s real system, we provide

some practical considerations as follows.

1) Communication Rescheduling

The key motivation of rescheduling is to avoid using significantly more energy than expected

when the estimation error of E~n,t is large. To be specific, after local gradient computation, each

scheduled device can learn its exact energy consumption En,t by calculating the local gradient

norm

g~n,t

2 2

and

acquiring

the

accurate

channel

gain

hn,t.

If

En,t

- E~n,t



h,

where

h

>

0

is

a given threshold, then the device is scheduled for gradient aggregation. Otherwise, the device

backs off from the communication step.

2) Minimum Value of Virtual Queue

The typical evolution of virtual queue is given in (23), in which the minimum queue value is

set to 0. In problem P6, qn,t = 0 indicates that the energy consumption is not considered in the

current scheduling round, and thus the device is scheduled. However, the energy consumption

En,t might be large, leading to a large deviation n and thus a poor worst-case performance. To avoid such cases, we instead set qmin > 0 as the minimum value of the virtual queue in practice. 3) Estimations of Smoothness Parameter l and Variance Bound G2

Our algorithm is designed based on the convergence analysis under Assumptions in Section

III. These hyper-parameters should be estimated in practice. According to the definition of

18

smoothness, l is estimated by the maximum value of

g~ n,t -g~ n,t-1 wt-1 -wt-2

during training, while each

device can count the variance of local gradients to set a reasonable variance bound G2.

V. EXPERIMENTS
In this section, we evaluate the proposed energy-aware dynamic device scheduling algorithm for an image classification task using both MNIST1 and CIFAR-102 datasets. We consider N = 10 devices and both i.i.d. and non-i.i.d. datasets on devices. For the i.i.d. case, the training dataset of MNIST with 60000 samples (or CIFAR-10 with 50000 samples) is randomly partitioned into N disjoint subsets, and each device holds one subset. For the non-i.i.d. case, we sort the data samples by their labels, and each device holds a disjoint subset of data with m labels (represented by `non-i.i.d. (m)' in the following). Note that the data distributions are more skewed for smaller m, and they become i.i.d. when m is equal to the total number of classes in the dataset.
For MNIST, we train a multilayer perceptron (MLP) which has a 784-unit input layer with ReLU activation, a 64-unit hidden layer, and a 10-unit softmax output layer, with 50890 parameters in total. The total number of rounds is set to T = 200, and 10 local iterations are carried out per round with batch size Lb = 64. In each round, the total computation energy is 1J for each device. For CIFAR-10, we train a convolutional neural network (CNN) with the following structure: two 3 × 3 convolution layers each with 32 channels and followed by a 2 × 2 max pooling layer, two 3 × 3 convolution layers each with 64 channels and followed by a 2 × 2 max pooling layer, a fully connected layer with 120 units, and finally a 10-unit softmax output layer. Each convolution or fully connected layer is activated by ReLU, and the total number of model parameters is 258898. We train the model for T = 10000 rounds, and one mini-batch is run per round with batch size Lb = 64. Local computation energy per round per device is set to 10J.
For both MNIST and CIFAR-10, the learning rate t is set to 0.05, t, a momentum of 0.9 is adopted, and cross entropy is adopted as the loss function. The wireless channel follows Rayleigh fading with scale parameter 1, and by default we assume that the accurate channel gain can be observed, i.e., h~n,t = hn,t. The variance of channel noise is 02 = 10-6. The power scalar is selected according to (27), where the default SNR threshold is 0 = 5. For the dynamic
1http://yann.lecun.com/exdb/mnist/ 2https://www.cs.toronto.edu/ kriz/cifar.html

19

Gradient norm

120 100

LLLLbbbb

= = = =

4 8 16 64

80

60

40

20

0 0 25 50 75 R1ou0n0d 125 150 175 200

Gradient norm

14 12

LLLLbbbb

= = = =

4 8 16 64

10

8

6

4

2

0 0 25 50 75 R1ou0n0d 125 150 175 200

(a) I.i.d. local data.

(b) Non-i.i.d. (m = 1).

Fig. 2. The l2-norm of local gradients and their estimated values on the MNIST dataset.

Gradient norm

1.4 1.2

LLLbbb

= = =

4 8 64

1.0

0.8

0.6

0.4

0.2

0.0 0

2000

4000 Round 6000

8000 10000

Gradient norm

1.6 1.4

LLLbbb

= = =

4 8 64

1.2

1.0

0.8

0.6

0.4

0.2

0.0 0

2000

4000 Round 6000

8000

10000

(a) I.i.d. local data.

(b) Non-i.i.d. (m = 2).

Fig. 3. The l2-norm of local gradients and their estimated values on the CIFAR-10 dataset.

scheduling algorithm, the minimum value of virtual queue is qmin = 0.1, and the maximum estimation error h = 0.5E~n,t is allowed for communication reschedule.

A. l2-Norm of Local Gradients

In Fig. 2 and Fig. 3, we first evaluate the EST-C and EST-P methods proposed in Section IV-A that estimate the l2-norm of local gradient, by observing the temporal variations of the gradients. To eliminate the impact of device scheduling, we do not limit the energy consumption

and all devices are scheduled. The batch size Lb used for the model training is 64. In each round,

each device further computes its local gradient with smaller batch sizes Lb = 4, 8 and 16 and

records the corresponding estimated gradient norm, which is adopted by the EST-C method as

g~[ne,stt]

2 2

.

For

the

EST-P method,

g~[ne,stt]

2 2

will

be

given

the

value

of

the

l2-norm

of

gradients

with Lb = 64 at a certain round before t. Each curve is averaged over 50 and 20 runs for MNIST

20

Test accuracy (%)

100
96.8 96.8 96.6
95

90

85

80

iid

95.8 94.9 93.8

95.4 93.5 92.6

Optimal benchmark Dynamic (proposed) Myopic policy

non-iid (m=2) non-iid (m=1)

Cumulative energy usage (unified)

1.0

Dynamic, m=1

Dynamic, m=2

0.8

Dynamic, iid Myopic, m=1

Myopic, m=2

0.6

Myopic, iid

0.4

0.2

0.0 0 25 50 75 R1ou0n0d 125 150 175 200

(a) Accuracy on test dataset.

(b) Unified cumulative energy usage.

Fig. 4. Performance of the proposed dynamic scheduling algorithm and benchmarks on MNIST.

Test accuracy (%)

80 79.4 78.9

75

75.6

70

65

60

iid

79.4 77.7 75.0

79.5 76.5

71.6 Optimal benchmark Dynamic (proposed) Myopic policy

non-iid (m=2) non-iid (m=1)

Cumulative energy usage (unified)

1.0

Dynamic, m=1

Dynamic, m=2

0.8

Dynamic, iid Myopic, m=1

Myopic, m=2

0.6

Myopic, iid

0.4

0.2

0.0 0

2000

4000 Round 6000

8000 10000

(a) Accuracy on test dataset.

(b) Unified cumulative energy usage.

Fig. 5. Performance of the proposed dynamic scheduling algorithm and benchmarks on CIFAR-10.

and CIFAR-10, respectively. As shown in Fig. 2 and Fig. 3, the gradient norms achieved by different batch sizes are highly
varying, and a smaller batch size yields a higher l2-norm of gradient due to the non-negligible gradient variance, which is consistent with the analysis in (21). This result indicates that the EST-C method cannot provide an accurate estimation of gradient norm. Meanwhile, with a fixed batch size, such as Lb = 64, the gradient norm has a strong temporal correlation. Therefore, the EST-P method can provide a much better estimate of the gradient norm, which is embedded in the proposed dynamic device scheduling algorithm.
B. Performance of the Proposed Device Scheduling Algorithm We compare the performance of the proposed scheduling algorithm with two benchmarks: 1) Optimal benchmark: Devices do not have energy limitations, so that all of them participate
in each training round.

21

2) Myopic policy: For each device n, the maximum energy that can be used in round t is

given by

the

remaining

energy divided

by

the remaining

number

of

rounds,

i.e.,

E¯n-

. t-1
 =1

n,t En,t

T -t+1

In Fig. 4, we compare the training performance and energy consumption of the proposed

dynamic scheduling algorithm with the optimal and myopic benchmarks on MNIST. Let E¯ = 1J

be the energy budget per round, and the total energy budget of each device is E¯n = T E¯, n.

For non-i.i.d. data with 1 label per device, the weight parameter is V = 5 × 107, while for the

other two cases, V = 108. The training performance is characterized by the accuracy of the

MLP model on the test dataset, as shown in Fig. 4(a). Results show that our proposed dynamic

scheduling algorithm achieves the optimal accuracy under i.i.d. data, and always outperforms the

myopic policy. The maximum value of the unified cumulative energy usage across devices till

the t-th round, given by maxnN

, t


=1

n,

En,

tE¯

is

plotted

in

Fig.

4(b).

For

the

myopic

policy,

the energy required for computation and communication exceeds the budget at the beginning of

training, thus no devices can be scheduled. However, our proposed algorithm enables devices to

use energy in a more flexible way, thus improving the training performance. Similar comparison is made on CIFAR-10 dataset in Fig. 5, where E¯ = 8J and V = 5 × 1011.

Note that compared to the local computation energy required per round (10J), the energy budget

is relatively limited, and the advantage of the proposed dynamic scheduling over the myopic

policy is more prominent in such a scenario. In particular, under the highly non-i.i.d. case with

m = 1, dynamic scheduling improves the accuracy by 4.9% compared to the myopic policy,

by utilizing 10% more energy in a more balanced manner. We can also see that our proposed

algorithm can satisfy the energy constraints of devices under both datasets (at the end of training,

the unified energy usage is smaller than 1).

In the following, we further explore the impact of key parameters on the training performance

and energy consumption with CIFAR-10, as it is more challenging than MNIST. We focus on

the non-i.i.d. case, where each device has a local subset with m = 2 labels.

Fig. 6 validates that the weight parameter V can balance the trade-off between the training performance and energy consumption, where E¯ = 8J. As V increases, devices use energy in a

more aggressive manner, leading to a higher energy usage and more scheduled devices, so as to

accelerate the convergence. However, if V is too large, such as V = 1012, energy is not given

enough attention and finally the limit is violated. In practical systems, V should be judiciously

selected to optimize the training performance while satisfying the energy constraints.

Test accuracy (%)

22

80

1.2

1.0

Dynamic, V = 1012

Average fraction of workers scheduled

Cumulative energy usage (unified)

70 60

1.0

Dynamic, V = 5 × 1011 Dynamic, V = 1010

Myopic policy

0.8

0.8

50

0.6

0.6

40

0.4

30

Optimal benchmark

0.4

Dynamic, V = 1012

20

Dynamic, V = 5 × 1011 Dynamic, V = 1010

0.2

0.2

Dynamic, V = 1012 Dynamic, V = 5 × 1011

Dynamic, V = 1010

10 0

2000

4000

Myopic policy
6000 8000

10000

0.0 0

2000 4000 6000 8000 10000 0.0 0

Myopic policy
2000 4000 6000 8000 10000

Round

Round

Round

(a) Accuracy on test dataset.

(b) Unified cumulative energy usage.

(c) Scheduled devices.

Fig. 6. Performance of the proposed algorithm under different weight parameter V on CIFAR-10.

80

1.0

1.0

Fraction of workers scheduled

Cumulative energy usage (unified)

70

0.8

0.9 0.8

60

0.7

50

0.6

0.6

40 30 20 10
0

SNR=10

SNR=5 SNR=1

0.4

SNR=0.1

SNR=0.1 (true)

0.2

2000

4000 Round 6000

8000 10000 0.0 0

0.5

0.4

SNR=0.1 SNR=1

0.3

SNR=0.1 SNR=1

SNR=5 SNR=10

0.2

SNR=5 SNR=10

2000

4000 Round 6000

8000 10000 0.1 0

2000

4000 Round 6000

8000 10000

(a) Accuracy on test dataset.

(b) Unified cumulative energy usage.

(c) Scheduled devices.

Fig. 7. Performance of the proposed algorithm under different received SNR thresholds on CIFAR-10.

Test accuracy (%)

The impact of the received SNR threshold 0 on the training performance and energy consumption with the proposed dynamic scheduling algorithm is shown in Fig. 7, where E¯ = 8J, and V = 2.5 × 1011. In Fig. 7(a), the curve marked with `true' plots the model accuracy on the test dataset in the current round, with SNR threshold 0.1, while the other curves present the best test accuracy up-to-date. The maximum cumulative energy usage and instantaneous fraction of devices that are scheduled in each round is shown in Fig. 7(b) and Fig. 7(c), respectively. Clearly, a smaller SNR threshold helps to save communication energy, and thus more devices can be scheduled in each round. However, the cumulative noise might degrade the accuracy or even diverge the training if the SNR is too low, for instance when SNR = 0.1. On the other hand, a larger SNR, such as SNR = 10, makes communication more energy-consuming, which also degrades the training performance due to fewer participants. A proper value of the received SNR threshold should be given to balance the negative impact of noise and the energy consumption. As shown in Fig. 7, SNR = 5 is the best choice under our simulation setting.

23

Test accuracy (%)

80 77.7

75

75.0

70

65

60 E = 8

78.6 76.9 Opt:79.4 79.1 78.3

Dynamic (proposed) Myopic policy

E = 10

E = 14

Cumulative energy usage (unified)

1.0

Dynamic, E = 14

Dynamic, E = 10

0.8

Dynamic, E = 8

Myopic, E = 14

Myopic, E = 10

0.6

Myopic, E = 8

0.4

0.2

0.0 0

2000

4000 Round 6000

8000 10000

(a) Accuracy on test dataset.

(b) Unified cumulative energy usage.

Fig. 8. Performance of the proposed algorithm and benchmarks under different energy budgets on CIFAR-10.

Test accuracy (%)

80
77.7

75

75.0

70

65

60 No Error

77.2 74.5

77.1 74.5

77.3 74.8

Dynamic (proposed) Myopic policy
10% Error 20% Error 30% Error

Fig. 9. Performance of the proposed algorithm and myopic benchmark under different channel estimation errors on CIFAR-10.

We compare our proposed algorithm with optimal and myopic benchmarks under different energy budgets in Fig. 8. For E¯ = 14J, we set V = 1010, and for E¯ = 8J or 10J, we let V = 5 × 1011. Our proposed dynamic scheduling algorithm always outperforms the myopic
benchmark by achieving higher accuracy and utilizing energy more efficiently, and approaches the optimal accuracy as E¯ increases. Moreover, the accuracy gap between the proposed algorithm and myopic policy is 2.7%, 1.7% and 0.8% for E¯ = 8, 10 and 14, respectively, indicating that
the dynamic scheduling algorithm is particularly promising under the energy-limited regime.
Finally, we evaluate the robustness of the proposed dynamic scheduling algorithm by introducing channel observation errors, where E¯ = 8J and V = 5 × 1011. In Fig. 9, the first group of bars are obtained without channel observation error, i.e., h~n,t = hn,t. The second to the forth group of bars suffer inaccurate channel observations. For example, if the error is 20%, then h~n,t is uniformly distributed within [0.8hn,t, 1.2hn,t]. A larger observation error further leads to less accurate energy estimations E~n,t. However, the training performance of the proposed

24
dynamic scheduling algorithm only suffers a tiny degradation, which validates its robustness in practical scenarios. We also mention that the myopic policy also performs well under different observation errors compared to the error-free case. Nevertheless, the proposed algorithm still beats the myopic policy by a significant margin in all the scenarios.

VI. CONCLUSIONS
We have investigated the device scheduling problem for FEEL with over-the-air gradient aggregation, aiming to optimize the training performance under joint communication and computation energy limits of devices. Convergence analysis has been carried out showing the importance of device participation to the training performance, and an energy-aware dynamic device scheduling algorithm has been developed. In particular, we have noticed the existence of unobservable states, mainly the l2-norm of local gradients, for online decision making in over-the-air FEEL, and proposed an estimated-drift-plus-penalty solution based on the Lyapunov optimization framework accordingly. We have characterized a theoretical guarantee for the proposed dynamic scheduling algorithm by taking the deviation of estimated states into consideration. Experiments on MNIST and CIFAR-10 datasets have been carried out to validate the theoretical findings. Compared to the myopic benchmark, we have shown a significant 4.9% accuracy improvement on CIFAR-10 for a highly non-i.i.d. data distribution and stringent energy constraints.
As future directions, heterogeneous data distributions across devices can be considered, where local datasets represent different number of classes. We would like to observe if data diversity of a device should be taken into account for the scheduling decision. The trade-off between training delay and energy consumption in over-the-air FEEL is also worth further investigation.

APPENDIX A

PROOF OF LEMMA 1

For the simplicity of notation, let g~t updated according to

, z~ nBt g~n,t

|Bt|

t

. zt
t|Bt|

Thus

the

global

model

is

wt = wt-1 - t(g~t + z~t).

(32)

According to Assumption 2, the gap of loss between two adjacent rounds can be bounded by

F

(wt)

-

F

(wt-1)



F

(wt-1)T(wt

-

wt-1)

+

l 2

wt - wt-1

2 2

(33)

25

=

-tgTt (g~t

+

z~t)

+

lt2 2

g~t + z~t

2 2

.

(34)

Recall that each entry in the noise vector zt follows Gaussian distribution with zero mean and variance 02. Taking the expectation over noise, and considering the fact that the channel noise

and local gradient are independent, we can obtain

Ezt

g~t + z~t

2 2

=

g~t

2 2

+

Ezt

z~t

2 2

=

g~t

2 2

+

02s t2|Bt

|2

,

(35)

Ezt

[F (wt)

-

F

(wt-1)]



-tgTt g~t

+

lt2 2

g~t

2 2

+

lt2 2

02s t2|Bt|2

.

(36)

Taking the expectation over stochastic data sampling, and based on Assumption 1, we get

ELn,t [g~t] = ELn,t

nBt g~n,t |Bt|

= gt,

(37)



ELn,t

g~t

2 2

= E

nBt

xLn,t f (wt-1, x) Lb|Bt|

2 

gt

2 2

+

G2 .
Lb|Bt|

2

(38)

Finally, taking the expectation over noise and SGD on the left hand side of (36), and substi-

tuting its right hand side with (37) and (38), we have

E[F (wt) - F (wt-1)]  -t

gt

2 2

+

lt2 2

gt

2 2

+

G2 Lb|Bt|

+

lt2 2

02s t2|Bt|2

= -t

1 - lt 2

gt

2 2

+

lt2 2

G2 Lb|Bt|

+

02s t2|Bt|2

.

(39)

Since E[F (wt) - F (wt-1)] = E[F (wt)] - E[F (wt-1)], Lemma 1 is proved.

APPENDIX B PROOF OF THEOREM 1

By the µ-strong convexity of the loss functions (Assumption 3), the Polyak-Lojasiewicz inequality holds

gt

2 2



2µ(F

(wt-1)

-

F

).

(40)

Substituting

(40)

into

Lemma

1,

and

assuming

that

t



1 l

(thus

1-

lt 2



1 2

),

we

can

obtain

E[F (wt) - F (wt-1)]  -t

1 - lt 2

gt

2 2

+

lt2 2

G2 Lb|Bt|

+

02s t2|Bt|2



-tµ(E[F (wt-1)]

-

F )

+

t 2

G2 Lb|Bt|

+

02s t2|Bt|2

.

(41)

26

Let At

t 2

+ G2
Lb|Bt|

02 s t2 |Bt |2

, and thus (41) can be re-written as

E[F (wt)] - F   (1 - µt)(E[F (wt-1)] - F ) + At.

(42)

With recursion, we can prove Theorem 1:

E[F (wt)] - F   (1 - µt)(E[F (wt-1)] - F ) + At

 (1 - µt)(1 - µt-1)(E[F (wt-2)] - F ) + (1 - µt)At-1 + At

t

t-1

t

 · · ·  (E[F (w0)] - F ) (1 - µi) + Ai (1 - µi) + At. (43)

i=1

i=1 j=i+1

APPENDIX C

PROOF OF THEOREM 2

Let yn,t

n,tEn,t

-

E¯n T

,

and

y~n,t

n,tE~n,t

-

E¯n T

.

Define

the

error

of

estimated

energy

consumption at device n in the t-th round as n,t n,tE~n,t-n,tEn,t = y~n,t-yn,t, with maximum

absolute value 0 max{n,t} E~n,t - En,t . According to the evolution of the virtual queue,

which is defined in (23), it is easy to prove that qn2,t+1  (qn,t + yn,t)2 and yn,t  qn,t+1 - qn,t.

Define the Lyapunov function as L(t)

N n=1

1 2

qn2,t

,

and

the

Lyapunov

drift

of

a

single

round

as 1(t) L(t + 1) - L(t), which is given by

N
1(t) = L(t + 1) - L(t) =

1 2

qn2,t+1

-

1 2

qn2,t

n=1

N

n=1

1 2

yn2,t

+

qn,tyn,t

N
 0 + qn,tyn,t,
n=1

(44)

where 0

N n=1

1 2

n2

and

n

maxt {|yn,t|}. By adding V Ut on both sides of (44), an upper

bound on the single-round drift-plus-penalty function is given by

N

1(t) + V Ut  0 + qn,tyn,t + V Ut

n=1

N
= 0 + qn,t

n,tEn,t

-

E¯n T

+ V Ut

(45)

n=1

N

= 0 + qn,t (y~n,t - n,t) + V Ut

n=1

N
= 0 + qn,t

n,tE~n,t

-

n,t

-

E¯n T

+ V Ut.

(46)

n=1

27

The classical drift-plus-penalty algorithm of Lyapunov optimization aims to minimize the

upper bound of 1(t) + V Ut, as shown in (45). Since we do not have the exact value of En,t,

we instead minimize the estimated-drift-plus-penalty, as shown in (46).

Define the T -round drift as T

L(T + 1) - L(1) =

N n=1

1 2

qn2,T

+1.

Then

the

T -round

drift-plus-penalty function can be bounded by:

T

T

T + V Ut 

t=1

t=1

N
0 + qn,t(y~n,t - n,t)
n=1

T
+ V Ut
t=1

T

N

N

= 0T +

qn,ty~n,t + V Ut - qn,tn,t

(47)

t=1 n=1

n=1

We use superscript  to represent the optimal offline solution of P4 (t is not an optimization

variable), superscript  to represent the classical drift-plus-penalty algorithm, i.e., min{n,t} V Ut+

N n=1

n,tqn,tEn,t

,

and



to

represent

our

proposed

estimated-drift-plus-penalty

algorithm

that

solves P6.

The T -round drift-plus-penalty is bounded by:

T

T

T + V

Ut  0T +

t=1

t=1

N

N

qn,ty~n,t + V Ut -

qn,tn ,t

n=1

n=1

(a)

T

 0T +

t=1

T

= 0T +

t=1

T

= 0T +

t=1

N

N

qn,ty~n (t) + V Ut - qn,tn,t

n=1

n=1

N
qn,t
n=1

yn ,t + n ,t

N

+ V Ut -

qn,tn ,t

n=1

N

N

qn,tyn,t + V Ut +

qn,t n ,t - n ,t

n=1

n=1

(b)

T

 0T +

t=1

N

N

qn,tyn,t + V Ut + 20 qn,t .

n=1

n=1

(48)

Inequality (a) holds because optimally solving P6 yields a minimum value

N n=1

qn,t y~n ,t +V

Ut

for each t. Inequality (b) holds since the drift-plus-penalty algorithm achieves the minimum value

of

N n=1

qn,tyn,t

+

V

Ut,

and

thus

plugging

in

the

optimal

offline

policy

on

the

right-hand-side

increases the value.

Now we bound the right-hand-side of (48). Note that qn,t+1 - qn,t  n, t, n, and thus

t-1
qn,t = qn,t - qn,1 = (qn,+1 - qn, )  (t - 1)n,
 =1

(49)

28

qn,tyn,t = (qn,t - qn,1)yn,t  (t - 1)n2 .

(50)

Substituting (49) and (50) into (48) yields

T

T

TN

TN

T + V

Ut  0T + V

Ut +

(t - 1)n2 + 20

(t - 1)n

t=1

t=1

t=1 n=1

t=1 n=1

T

N

= 0T + V Ut + 0T (T - 1) + T (T - 1)0 n

t=1

n=1

T

N

= V Ut + 0T 2 + T (T - 1)0 n.

(51)

t=1

n=1

Notice that T  0, (30) in Theorem 2 can be derived from (51) by dividing both sides by V .

As

Ut

> 0,

and

for

n,

1 2

qn2,T

+1



T ,

we

get

T

T

T

yn,t =

n,tEn,t - E¯n 

qn,t+1 - qn,t = qn,T +1

t=1

t=1

t=1

T

N

 2T = 2V Ut + 20T 2 + 2T (T - 1)0 n.

(52)

t=1

n=1

Thus eq. (31) in Theorem 2 is proved.

REFERENCES
[1] Y. Sun, S. Zhou, and D. Gunduz, "Energy-aware analog aggregation for federated learning with redundant data," in Proc. IEEE Int. Conf. Commun. (ICC), Dublin, Ireland, Jun. 2020.
[2] C. Jiang, H. Zhang, Y. Ren, Z. Han, K. -C. Chen, and L. Hanzo, "Machine learning paradigms for next-generation wireless networks," IEEE Wireless Commun., vol. 24, no. 2, pp. 98-105, Apr. 2017.
[3] D. Gunduz, P. de Kerret, N. D. Sidiropoulos, D. Gesbert, C. R. Murthy and M. van der Schaar, "Machine learning in the air," IEEE J. Sel. Areas Commun., vol. 37, no. 10, pp. 2184-2199, Oct. 2019.
[4] J. Park, S. Samarakoon, M. Bennis, and M. Debbah, "Wireless network intelligence at the edge," in Proceedings of the IEEE, vol. 107, no. 11, pp. 2204-2239, Nov. 2019.
[5] J. Konecny, H. B. McMahan, F. X. Yu, P. Richta´rik, A. T. Suresh, and D. Bacon, "Federated learning: Strategies for improving communication efficiency," NIPS Workshop on Private Multi-Party Machine Learning, Oct. 2016.
[6] B. McMahan, E. Moore, D. Ramage, et al. "Communication-efficient learning of deep networks from decentralized data," in Proc. Artificial Intelligence and Statistics (AIStats), Apr. 2017.
[7] K. Bonawitz, et al. "Towards federated learning at scale: System design," in Proc. Conf. Systems and Machine Learning, Stanford, CA, USA, Apr. 2019.
[8] T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, "Federated learning: Challenges, methods, and future directions," in IEEE Signal Process. Mag., vol. 37, no. 3, pp. 50­60, 2020.

29
[9] Y. Zhao, M. Li, L. Lai, N. Suda, D. Civin, and V. Chandra, "Federated learning with non-iid data," arXiv preprint arXiv:1806.00582, Jun. 2018.
[10] W. Y. B. Lim, et al., "Federated learning in mobile edge networks: A comprehensive survey," in IEEE Commun. Surveys Tuts., vol. 22, no. 3, pp. 2031-2063, thirdquarter 2020.
[11] M. Chen, D. Gunduz, K. Huang, W. Saad, M. Bennis, A. V. Feljan, and H. V. Poor, "Distributed learning in wireless networks: Recent progress and future challenges," arXiv preprint arXiv:2104.02151, Apr. 2021.
[12] D. Alistarh, D. Grubic, J. Li, R. Tomioka, and M. Vojnovic, "QSGD: Communication-efficient SGD via gradient quantization and encoding," in Proc. Advances in Neural Information Processing Systems (NIPS), Dec. 2017.
[13] J. Wangni, J. Wang, J. Liu, and T. Zhang, "Gradient sparsification for communication-efficient distributed optimization," in Advances in Neural Information Processing Systems (NIPS), Dec. 2018.
[14] Y. Du, S. Yang, and K. Huang, "High-dimensional stochastic gradient quantization for communication-efficient edge learning," IEEE Trans. Signal Process., vol. 68, pp. 2128-2142, Mar. 2020.
[15] A. Reisizadeh, A. Mokhtari, H. Hassani, A. Jadbabaie, R. Pedarsani, "FedPAQ: A communicationefficient federated learning method with periodic averaging and quantization," in International Conference on Artificial Intelligence and Statistics (AIStats), Jun. 2020.
[16] H. H. Yang, Z. Liu, T. Q. S. Quek, and H. V. Poor, "Scheduling policies for federated learning in wireless networks," IEEE Trans. Commun., vol. 68, no. 1, pp. 317-333, Jan. 2020.
[17] M. Mohammadi Amiri, D. Gunduz, S. R. Kulkarni, and H. V. Poor, "Convergence of update aware device scheduling for federated learning at the wireless edge," in IEEE Trans. Wireless Commun., early access, Jan. 2021.
[18] S. Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya, T. He and K. Chan, "Adaptive federated learning in resource constrained edge computing systems," IEEE J. Sel. Areas Commun., vol. 37, no. 6, pp. 1205-1221, Jun. 2019.
[19] N. Yoshida, T. Nishio, M. Morikura, K. Yamamoto and R. Yonetani, "Hybrid-FL for wireless networks: Cooperative learning mechanism using non-iid data," in Proc. IEEE Int. Conf. Commun. (ICC), Dublin, Ireland, Jun. 2020.
[20] Q. Zeng, Y. Du, K. K. Leung, and K. Huang, "Energy-efficient radio resource allocation for federated edge learning," in Proc. IEEE Int. Conf. Commun. Workshops, Dublin, Ireland, Jun. 2020.
[21] J. Xu and H. Wang, "Client selection and bandwidth allocation in wireless federated learning networks: A long-term perspective," in IEEE Trans. Wireless Commun., early access, Oct. 2020.
[22] Y. Sun, W. Shi, X. Huang, S. Zhou and Z. Niu, "Edge learning with timeliness constraints: Challenges and solutions," in IEEE Commun. Mag., vol. 58, no. 12, pp. 27-33, Dec. 2020.
[23] M. Chen, H. V. Poor, W. Saad and S. Cui, "Convergence time optimization for federated learning over wireless networks," in IEEE Trans. Wireless Commun., early access, Dec. 2020.
[24] W. Shi, S. Zhou, Z. Niu, M. Jiang and L. Geng, "Joint device scheduling and resource allocation for latency constrained wireless federated learning," in IEEE Trans. Wireless Commun., vol. 20, no. 1, pp. 453-467, Jan. 2021.
[25] J. Ren, Y. He, D. Wen, G. Yu, K. Huang and D. Guo, "Scheduling for cellular federated edge learning with importance and channel awareness," in IEEE Trans. Wireless Commun., vol. 19, no. 11, pp. 7690-7703, Nov. 2020.
[26] M. S. H. Abad, E. Ozfatura, D. Gunduz, and O. Ercetin, "Hierarchical federated learning across heterogeneous cellular networks," IEEE Int. Conf. Acoustics, Speech and Signal Process. (ICASSP), Barcelona, Spain, May 2020.
[27] N. H. Tran, W. Bao, A. Zomaya, M. N. H. Nguyen and C. S. Hong, "Federated learning over wireless networks: Optimization model design and analysis," in Proc. IEEE INFOCOM, Paris, France, May 2019.

30
[28] Z. Yang, M. Chen, W. Saad, C. S. Hong and M. Shikh-Bahaei, "Energy efficient federated learning over wireless communication networks," in IEEE Trans. Wireless Commun., early access, Nov. 2020.
[29] X. Mo and J. Xu, "Energy-efficient federated edge learning with joint communication and computation design," arXiv preprint arXiv:2003.00199, Mar. 2020.
[30] D. Gunduz, D. B. Kurka, M. Jankowski, M. Mohammadi Amiri, E. Ozfatura and S. Sreekumar, "Communicate to learn at the edge," in IEEE Commun. Mag., vol. 58, no. 12, pp. 14-19, Dec. 2020.
[31] G. Zhu, D. Liu, Y. Du, C. You, J. Zhang and K. Huang, "Toward an intelligent edge: Wireless communication meets machine learning," in IEEE Commun. Mag., vol. 58, no. 1, pp. 19-25, Jan. 2020.
[32] M. Mohammadi Amiri and D. Gunduz, "Machine learning at the wireless edge: Distributed stochastic gradient descent over-the-air," IEEE Trans. Signal Process., vol. 68, pp. 2155-2169, Apr. 2020.
[33] M. Mohammodi Amiri and D. Gunduz, "Federated learning over wireless fading channels," in IEEE Trans. Wireless Commun., vol. 19, no. 5, pp. 3546-3557, May 2020.
[34] G. Zhu, Y. Wang, and K. Huang, "Low-latency broadband analog aggregation for federated edge learning," in IEEE Trans. Wireless Commun., vol. 19, no. 1, pp. 491-506, Jan. 2020.
[35] G. Zhu, J. Xu and K. Huang, "Over-the-air computing for 6G: Turning air into a computer." arXiv preprint arXiv:2009.02181 Sept. 2020.
[36] H. Guo, A. Liu and V. K. N. Lau, "Analog gradient aggregation for federated learning over wireless networks: Customized design and convergence analysis," in IEEE Internet Things J., vol. 8, no. 1, pp. 197-210, Jan. 2021.
[37] X. Wei and C. Shen, "Federated learning over noisy channels: Convergence analysis and design examples," arXiv preprint arXiv:2101.02198, Jan. 2021.
[38] M. M. Amiri, D. Gunduz, S. R. Kulkarni, and H. V. Poor, "Convergence of federated learning over a noisy downlink," arXiv preprint arXiv:2008.11141, Aug. 2020.
[39] N. Zhang and M. Tao, "Gradient statistics aware power control for over-the-air federated learning in fading channels," arXiv preprint arXiv:2003.02089, Mar. 2020.
[40] T. Sery, N. Shlezinger, K. Cohen, and Y. C. Eldar, "Over-the-air federated learning from heterogeneous data," arXiv preprint arXiv:2009.12787, Sept. 2020.
[41] M. Mohammodi Amiri, T. M. Duman, D. Gunduz, S. R. Kulkarni, H. V. Poor, "Blind federated edge learning." arXiv preprint arXiv:2010.10030, Oct. 2020.
[42] Y. Shao, D. Gunduz, S. C. Liew, "Federated edge learning with misaligned over-the-air computation," arXiv preprint arXiv:2102.13604, Feb. 2021.
[43] G. Zhu, Y. Du, D. Gunduz and K. Huang, "One-bit over-the-air aggregation for communication-efficient federated edge learning: Design and convergence analysis," in IEEE Trans. Wireless Commun., Nov. 2020.
[44] M. J. Neely, Stochastic Network Optimization With Application to Communication and Queueing Systems. San Rafael, CA, USA: Morgan & Claypool, 2010.
[45] Y. Sun, S. Zhou, and J. Xu, "EMM: Energy-aware mobility management for mobile edge computing in ultra dense networks," in IEEE J. Sel. Areas Commun., vol. 35, no. 11, pp. 2637-2646, Nov. 2017.

