arXiv:2106.00288v1 [q-fin.RM] 1 Jun 2021

A Bayesian realized threshold measurement GARCH framework for financial tail risk forecasting
Chao Wang, Richard Gerlach Discipline of Business Analytics, The University of Sydney
Abstract In this paper, an innovative threshold measurement equation is proposed to be employed in a Realized-GARCH framework. The proposed framework employs a nonlinear threshold regression specification to consider the leverage effect and model the contemporaneous dependence between the observed realized measures and hidden volatility. A Bayesian Markov Chain Monte Carlo method is adapted and employed for the model estimation and forecasting, with its validity assessed via a simulation study. The usefulness of the proposed measurement equation in a Realized-GARCH model has been evaluated via a comprehensive empirical study, by forecasting the 1% and 2.5% Value-at-Risk and Expected Shortfall on six market indices. The proposed framework is shown to be capable of producing competitive tail risk forecasting results, compared to the original Realized-GARCH. Especially, the proposed model is favoured during the high volatility 2008 Global Financial Crisis period. Keywords: threshold measurement, Realized-GARCH, Markov Chain Monte Carlo, Value-at-Risk, Expected Shortfall.
1

1 Introduction

A major concern for regulators and owners of financial institutions is the financial risk management and forecasting. Value-at-Risk (VaR) is one of the most commonly used risk measures and employed by many financial institutions as an important risk management tool. VaR represents the market risk as one number and has become a standard risk measurement metric in recent decades. Let It be the information available at time t and

Ft(r) = P r(rt  r|It-1)

be the Cumulative Distribution Function (CDF) of return rt conditional on It-1. We assume that Ft(.) is strictly increasing and continuous on the real line . Under this assumption, the  level VaR (quantile) at time t can be defined as:

Qt = Ft-1(), 0 <  < 1.

However, VaR has been criticized, because it cannot measure the expected loss for extreme, violating returns and is also not mathematically coherent: i.e., it can favour nondiversification. Expected Shortfall (ES), proposed by Artzner (1997) and Artzner et al. (1999), calculates the expected value of return being below the quantile of its distribution. Therefore, in recent years it has become more widely employed for tail risk measurement. The Basel III Accord, implemented in 2019, places new emphasis on ES . Compared to VaR, ES possesses a number of attractive properties. For example, ES is a subadditive risk measure and is mathematically coherent.

Within the same framework as above for defining VaR, the  level ES can be shown

to be equal to the tail conditional expectation of rt (see Acerbi and Tasche, 2002, among others):

ESt = E(rt|rt  Qt,, It-1).

(1)

It is very important for institutions to have access to highly accurate VaR and ES forecasts and models, allowing accurate capital allocation, to avoid both default and overallocation of funds. As recommended in Basel II and III Accords, both daily Value-atRisk (VaR) and Expected Shortfall (ES) are estimated in this paper, . Basel III Accords

1

recommends the 2.5% level as the target quantile level which is studied in this paper. A more extreme and potentially challenging 1% quantile level is also considered.
In parametric VaR and ES estimation and forecasting, producing accurate volatility estimates and forecasts plays a crucial role. The Autoregressive Conditional Heteroskedastic (ARCH) and Generalized ARCH (GARCH), proposed in Engle (1982) and Bollerslev (1986) respectively, gain high popularity in recent decades.
Black (1976) discovers the now well-known phenomenon of leverage effect (volatility asymmetry): higher volatility is correlated with negative shocks in asset returns. Many studies in the literature develop nonlinear GARCH models to capture it, such as EGARCH (Nelson, 1991) and GJR-GARCH (Glosten et al., 1993). Poon and Granger (2003) also show that asymmetric volatility models outperform symmetric models in forecasting asset return volatility.
In addition to EGARCH and GJR-GARCH, another popular type of volatility models to capture the volatility asymmetry is the threshold autoregressive specifications, see Tong (1978) and Tong (1990) as examples. A double threshold GARCH model is developed in Li and Li (1996). Chen et al. (2008) propose to forecast volatility using threshold heteroskedastic models by employing the intra-day high-low range.
With the availability of high frequency data, various realized measures have been proposed and allow potentially more accurate volatility estimation compared to the daily return, such as Realized Variance (RV) (Andersen and Bollerslev (1998), Andersen et al. (2003)). Hansen et al. (2012) propose a Realized-GARCH framework. In addition to the GARCH equation, in Realized-GARCH a measurement equation that contemporaneously links the unobserved volatility with a realized measure is included. The Realized-GARCH is shown to be capable of producing accurate volatility estimation and forecasting results, by employing RV and other realized measures. The Realized-GARCH model has gained popularity in the recent decade, with various extensions proposed. A Realized-EGARCH is developed in Hansen and Huang (2016) which allows for multiple realized measure to be employed. Huang et al. (2016) develop a long memory realized heterogeneous autoregressive GARCH (Realized-HAR-GARCH). Chen and Watanabe (2019) extend the Realized-
2

GARCH model to a threshold framework by employing a threshold GARCH equation (Realized-Threshold-GARCH). Gerlach and Wang (2020) propose a semi-parametric realized conditional autoregressive expectile framework (Realized-CARE).
For all the above mentioned extensions of Realized-GARCH model, in general a measurement equation that follows the specification in the original Realized-GARCH model is employed. In this paper, our main contribution is to propose an innovative threshold measurement equation which can be utilized to capture volatility asymmetries and the leverage effect. The proposed framework is motivated by the success of various threshold autoregressive volatility specifications. The proposed new measurement equation has the same number of parameters as the original one in the Realized-GARCH and can be employed in all the above mentioned extended Realized-GARCH models, such as RealizedEGARCH, Realized-HAR-GARCH, Realized-Threshold-GARCH and Realized-CARE. In our paper, we mainly evaluate the impact of incorporating this new threshold measurement equation into the Realized-GARCH, named as Realized-T-M-GARCH. We would also like to emphasize that the proposed Realized-T-M-GARCH model is different to the Realized-Threshold-GARCH model in Chen and Watanabe (2019) which uses a threshold GARCH equation.
Further, an adaptive Bayesian MCMC algorithm is adopted for the estimation of the proposed model. The validity of the employed MCMC is evaluated via a simulation study. To evaluate the performance of the proposed Realized-T-M-GARCH model, employing realized variance as input, the accuracy of the associated 1% and 2.5% VaR and ES forecasts are assessed via comprehensive empirical studies. The proposed model produces competitive tail risk forecasting results compared to the original Realized-GARCH model. Especially, clear improvements in the risk forecasting accuracy are observed during the high volatility period, i.e., the 2008 Global Financial Crisis (GFC) period.
The paper is structured as follows: Section 2 reviews the Realized-GARCH model and proposes the Realized-T-M-GARCH model. The associated likelihood and the MCMC algorithm for model estimation are presented in Section 3. The simulation and empirical results are discussed in Section 4 and Section 5 respectively. Section 6 concludes the
3

paper.

2 Model Proposed

2.1 Realized-GARCH

The Realized-GARCH model with log specification of Hansen et al. (2012) can be written as:

rt = htzt,

(2)

log(ht) =  + log(ht-1) + log(xt-1),

log(xt) =  + log(ht) + 1zt + 2(zt2 - 1) + t,

where rt = [log(Ct) - log(Ct-1)] × 100 is the percentage log-return for day t, zt i.i.d. D1(0, 1), t i.i.d. D2(0, 1) and xt is a realized measure, e.g. RV. D1(0, 1) and D2(0, 1) indicate distributions that have mean 0 and variance 1. The three equations in order in model (2) are: the return equation, the GARCH equation and the measurement equation, respectively. The measurement equation is an observation equation that captures the dependence between the latent volatility and the realized measure. The term 1zt + 2(zt2 - 1) is used to capture the leverage effect.
The leverage term in the EGARCH model employs the form 1zt + 2 (|zt| - E[|zt|]). Therefore, the leverage term 1zt + 2(zt2 - 1) in Realized-GARCH is a quadratic variable (constructed from Hermite polynomials) of the version in EGARCH (see page 270 in Hansen and Huang (2016) for a detailed discussion and comparison of the two specifications).

Hansen et al. (2012) choose Gaussian errors, e.g. D1(0, 1) = D2(0, 1)  N (0, 1). Watanabe (2012) allow D1(0, 1) to be a standardised Student-t and skewed Student-t of Ferna´ndez and Steel (1998). Student-t is also the choice of D1(0, 1) in Gerlach and Wang (2016). Contino and Gerlach (2017) further test D2(0, 1) as a Student-t distribution, while their findings show that changing the distribution of D2(0, 1) will not significantly affect the model performance.

4

2.2 Realized threshold measurement GARCH

In a regression model, it is commonly assumed that the coefficients are fixed, such as the log(xt) =  + log(ht) component in the measurement equation of the RealizedGARCH. However, in some situations it is more appropriate to allow the regression coefficients to vary as a function of time or as a function of some relevant variables. Such regression frameworks are called switching regression or regime regression model, see Goldfeld and Quandat (1972), Granger et al. (1993) as examples. The GJR-GARCH utilizes such framework in modelling the volatility asymmetry and leverage effect, and takes the following form for the volatility component:

ht =  + ht-1 + ( + It-1)rt2-1,

(3)

where It-1 = 1 if rt-1  0, otherwise It-1 = 0. Therefore, the framework is capable of modelling the volatility asymmetrically according to the lagged return is positive or negative.

Another popular way of capturing the volatility asymmetry is by incorporating a

threshold GARCH specification (see Li and Li, 1996, among others):



ht

=

1 2

+ +

1ht-1 2ht-1

+ +

1rt2-1, 2rt2-1,

zt-1  c, zt-1 > c,

(4)

where zt is a threshold variable and c is the threshold value.

Motivated by the specifications (3) and (4), we propose an innovative threshold measurement equation to be employed in the Realized-GARCH framework. The proposed framework is named as realized threshold measurement GARCH (Realized-T-M-GARCH) and is shown as:

5

Realized-T-M-GARCH

rt = htzt,

(5)

log(ht) = + log(ht-1) + log(xt-1), 1 + 1log(ht), zt-1  c,
mt = 2 + 2log(ht), zt-1 > c, log(xt) = mt + t.

In our paper, we choose zt to be self-exciting, that is, zt = rt, and c = 0, as typical choices in the literature. Therefore, the sign asymmetry is considered.
Compared to the Realized-GARCH as in (2), the proposed Realized-T-M-GARCH models the leverage effect in a different (threshold) manner. In addition, the proposed threshold measurement has exactly the same number of parameters as the RealizedGARCH.
Although not investigated in our paper, the proposed threshold measurement has more potential flexibility and could be easily further extended. For example, the threshold variable zt can be chosen as the realized measure xt and threshold values c can be estimated instead of fixed, thus the size asymmetry can be also considered. Threshold variable zt can be also selected as other exogenous economic variables to allow it to be a potentially more flexible and informative dynamic process.
Further, as mentioned the framework can be easily employed in the other extensions of the Realized-GARCH framework. Incorporating the threshold measurement equation into the Realzied-Threshold-GARCH of Chen and Watanabe (2019), a realized double threshold GARCH can be proposed as below, although its performance is not investigated in this paper.

6

Realized-Double-Threshold-GARCH

rt =  htzt,

(6)

1 + 1log(ht-1) + 1log(xt-1), zt-1  c, log(ht) = 2 + 2log(ht-1) + 2log(xt-1) zt-1 > c,



1 + 1log(ht), zt-1  c, mt = 2 + 2log(ht), zt-1 > c,

log(xt) = mt + t,

Stationarity is an important issue in volatility modelling. As derived in Hansen et al.

(2012) and Gerlach and Wang (2016), by substituting the threshold measurement equa-

tion into volatility equation the required stationary condition for the Realized-T-M-

GARCH model is:

 + 1 < 1;  + 2 < 1.

(7)

Since the log specification is used, the non-negativity concern of the volatility is not an

issue. Following Watanabe (2012) and Gerlach and Wang (2016), Student-t distribution

is used as the distribution D1 of return equation, while other distributions can be used and tested in the proposed framework.

3 Likelihood and Bayesian Estimation

3.1 Likelihood

As in Hansen et al. (2012), when D1 = D2  N (0, 1) the log-likelihood function for model

(2) is:

(r, x; ) = -21 n

log(2) + log(ht) + rt2/ht

-

1 2

n

log(2) + log(2) + 2t /2 , (8)

t=1

t=1

(r;)

(x|r;)

where t = log(xt) -  - log(ht) - 1zt - 2(zt2 - 1). The log-likelihood (r, x; ) function

equals to the sum of two parts (r; ) and (x|r; ) which are derived from the GARCH

and measurement equation respectively.

7

In our paper, we focus on testing the proposed Realized-T-M-GARCH framework

which employs return equation error as D1  t(0, 1) and measurement equation error

as D2  N (0, 1). t(0, 1) represents a Student-t distribution with  degrees of freedom

and variance scaled to 1 (by using

-2 

factor).

The

framework

is

called

Realized-T-M-

GARCH-tN.

(x|r; ) remains the same as the one in Equation (8) under the threshold measure-

ment equation specification, as long as the D2 distribution remain unchanged. Therefore,

by updating (r; ) according to the Student-t distribution, the log-likelihood function for

the proposed Realized-T-M-GARCH-tN model is:

n
(r, x; ) = -

A()

+

1 2

log(ht)

+



+ 2

1

t=1

1

+

rt2 ht( -

2)

(9)

(r;)

-

1 2

n

log(2) + log(2) + 2t /2

t=1

(r|x;)

where t = xt - 1 - 1ht when rt-1  0, t = xt - 2 - 2ht when rt-1 > 0, and

A() = - log



+1 2

+

1 2

log((

-

2))

+

log



 2

.

The parameter vector to be

estimated is now  = (, , , 1, 1, 2, 2, , ), under the constraints in Equation (7).

 > 4 is further restricted to ensure the first four moments of the error distribution are

finite.

For comparison purpose, we also incorporate Student-t distribution as D1 and Normal distribution as D2 in the Realized-GARCH (Realized-GARCH-tN). It has identical loglikelihood as the Realized-T-M-GARCH-tN framework.

3.2 Bayesian Estimation
Motivated by the MCMC results in Gerlach and Wang (2016) and Gerlach and Wang (2020), an adaptive Markov Chain Monte Carlo (MCMC) procedure is employed for the estimation and forecasting of both Realized-T-M-GARCH-tN and ealized-GARCH-tN, also to make the later model performance comparison a fair one. The likelihood for both models, as in Equation (9), involves 9 unknown parameters.
8

The motivations of employing the Bayesian MCMC approach (instead of maximum likelihood estimation (MLE)) are discussed in Gerlach and Wang (2016). For example, the estimation of Realized-T-M-GARCH and Realized-GARCH require constrained MLE, to ensure stationarity, and this may cause issues in the optimisation and the standard error calculation (Silvapulle and Sen, 2005). Therefore, in this paper we have adapted and extended the adaptive MCMC method in Gerlach and Wang (2020) which contains two steps: a burn-in step and a "independent" Metropolis-Hastings (IMH) step.

First, the parameter blocking is employed for the MCMC estimation of Realized-TM-GARCH-tN. Three blocks are chosen as: 1 = (, , , 1, 2); 2 = (1, 2, ) and 3 = (). The choice is motivated by the face that parameters within the same block are more strongly correlated, in the posterior (or likelihood), than those between blocks. For example, the stationarity condition causes correlation between iterates of , , 1, 2, thus they are kept together in one block. Similarly, three blocks for the Realized-GARCH-tN model are also used: 1 = (, , , ); 2 = (, 1, 2, ) and 3 = (). Uninformative prior are chosen for both models over the possible stationarity region, i.e., ()  I(A), which is a flat prior for  over the region A which satisfies the stationarity condition in Equation (7).

For the burn-in period, a Metropolis algorithm (Metropolis et al., 1953) employing

a mixture of 3 Gaussian proposal distributions, with a random walk mean vector, is

employed for each block of parameters. In addition, an iterative "epoch" method in

Chen et al. (2017) is employed, aim to enhance the convergence of MCMC chains. The

proposal variance-covariance (var-cov) matrix of each block in each mixture element is set

as

Ci1,

where

C1

=

1; C2

=

100; C3

=

0.01,

with

1

initially

set

to

2.38 (di

)

Idi

,

where

di

is

the dimension of the block (i) of parameters being generated, and Idi is the identity matrix

of dimension di. This proposal var-cov matrix is subsequently tuned, aiming towards a

target acceptance rate of 23.4% (if di > 4, or 35% if 2  di  4, or 44% if di = 1), as standard, via the algorithm of Gelman et al. (1997). After running the first epoch with

20,000 iterations, the var-cov matrix of each parameter block is calculated after discarding

the first 2,000 iterates. Such updated var-cov matrix is then employed in the proposal

distribution of next epoch. After running each epoch, the standard deviations of each

9

parameter chain are also calculated and compared to that of the previous epoch. Such epoch process is repeated until the mean absolute percentage change of these standard deviations is less than 10%, which takes approximately three to four epochs in both the simulation and empirical study.
In the IMH step (10,000 iterations), again a mixture of three Gaussian proposal distributions is utilised for each parameter block. The sample mean vector of the last epoch iterates (after discarding the first 2,000 iterates) in the burn-in period is used as the mean vector of the IMH step. For var-cov matrix, after discarding the first 2,000 iterates, the sample covariance matrix of the last epoch iterates for each block is calculated as 2. Then the proposal variance-covariance matrix in each element is calculated as Ci2, where C1 = 1; C2 = 100; C3 = 0.01.
Lastly, all the IMH iterates (still discarding the first 2,000 iterates) are employed to calculate the VaR and ES forecasts, the posterior mean of which is used as the final tail risk forecasts.

4 Simulation Study

A simulation study is designed to illustrate the validity of the adapted MCMC, in terms of parameter estimation, VaR and ES forecasting accuracy.
1000 replicated data sets of size n = 1900 (chosen based on empirical study in-sample size) are simulated from the following simulation model which incorporates the RealizedT-M-GARCH-tN specification.
Simulation Model

rt = htzt, zt  t=10(0, 1)

(10)

log(ht) = 0.1 + 0.65log(ht-1) + 0.3log(xt-1), -0.2 + 0.95log(ht), rt-1  0,
mt = -0.5 + 0.92log(ht), rt-1 > 0, log(xt) = mt + 0.6t ,

10

The true values of the parameters in the simulation model are selected based on the parameter estimates of the empirical study. The estimated parameter values of RealizedT-M-GARCH-tN are in general consistent with the ones in the Realized-GARCH, while distinctive behaviours are observed for the parameters in the measurement equation.
Specifically, in a Realized-GARCH the  parameter is typically estimated to be between 0.3 and 0.55 in the empirical study. This parameter may be compared with  in a conventional GARCH model, which measures the coefficient associated with volatility estimator (square return in GARCH). However, with a more efficient and informative realized measure employed, the estimated  parameter is in general greater than estimated  in GARCH. Under the Realized-T-M-GARCH framework, we have similar observations. Thus, the true values of  in the simulation model is selected as 0.3.
In a Realized-GARCH, the estimates of  are close to unity, which suggests that the realized measure xt is roughly proportional to the conditional variance of daily returns. The parameter  in a Realized-GARCH is always negative. This suggests that the incorporated realized measures are roughly proportional to the conditional variance, with a small negative correction (given by estimates of ). One potential reason for this is that the returns employed in this paper are close-to-close and include overnight price movements, but the realized variance is only measured when the market is open which may slightly underestimate true volatility on average (downside bias). The leverage effect is prominent in stock indices, with the estimates of 1 always as negative in a Realized-GARCH.
To support the discussion on the threshold measurement equation true parameter value selection of the Realized-T-M-GARCH-tG simulation model, we present the S&P500 out-of-sample 1&2, 1&2 parameter estimates in Figure 1. The details of empirical results will be discussed later in the empirical section. In general, Figure 1 shows that the 1&2, 1&2 in the threshold measurement display distinctive behaviours with different estimated values.
More specifically, as in the second plot in Figure 1 the 2 estimated value is tend to be more negative (when lagged return is positive, rt-1 > 0) than the 1 estimated value (rt-1  0). Such results lend evidence on the fact of leverage effect which is successfully
11

10 5 0 -5
-10
-0.1 -0.2 -0.3 -0.4 -0.5 -0.6
1
0.95
0.9
0.85
0.99 0.985
0.98 0.975
0.97 0.965

S&P500 return

2009

2010

2011

2012

2013

2014

2015

2016

xi-1 lagged return negative xi-2 lagged return positive

2009

2010

2011

2012

2013

2014

2015

2016

phi-1 lagged return negative phi-2 lagged return positive

2009

2010

2011

2012

2013

2014

2015

2016

Persistent level lagged return negative Persistent level lagged return positive

2009

2010

2011

2012

2013

2014

2015

2016

Figure 1: S&P 500 out-of-sample threshold measurement equation parameter estimates and persistent level.

12

captured by the 1 and 2 parameters, with more negative bias correction is required when the lagged return is positive. Therefore, in the simulation model the true values for 1 and 2 are selected as -0.2 and -0.5 respectively. This finding is actually consistent with the Realized-GARCH 1 estimate which is always negative, so when a return (or correspondingly the error term zt) is positive there is more negative bias correction required.

In addition, comparing to the Realized-GARCH which has one regression coefficient  that links the observed realized measure xt and hidden conditional variance ht. The proposed Realized-T-M-GARCH includes two separate coefficients 1 and 2 in two regimes which can potentially model the relationship between xt and ht more flexibly. The estimates of 1 and 2 in the empirical study provide potential support on this. Both parameter are estimated to be close to 1, while different values are observed at different forecasting steps, as in the third plot in Figure 1. The true parameter values for 1 and 2 are chosen as 0.95 and 0.92 respectively. Lastly, although the persistence levels of two regimes (fourth plot in Figure 1),  +1 and  +2, are both very close to 1, distinctive behaviours are again observed during the out-of-sample period.

Overall, the true parameter values in the simulation model represent typical results observed in the empirical study. In the simulation model, rt is analogous to a daily return and xt is analogous to the daily realized measure.

Simulation results of both 1% and 2.5% quantile levels are presented. All initial parameter values are arbitrarily set equal to 0.25 to start the MCMC chains.

The "True" one-step-ahead level  VaR forecast from the above simulation model is

calculated as:

Qt+1 =

ht+1t- 1()



- 

2,

where t- 1() is the inverse of Student-t's CDF with the  degrees of freedom on quantile

level .

-2 

is

used

to

scale

the

Student-t

distribution

to

variance

1.

ES

forecast

from

the same model is calculated as:

13

ESt+1 = -

ht+1

g(t- 1()) 

 + (t- 1())2 -1

where g is the Student-t Probability Density Function (PDF).



- 

2,

These "True" VaR and ES forecasts are calculated for each data set. The averages of the these "True" forecasts, over the 1000 data sets, are given in the "True" column of Table 1.

The simulation results are summarised in Table 1. The Mean column shows the average parameter estimates and average VaR&ES forecasts across all 1000 simulated data sets. The Root Mean Squared Error (RMSE) between the parameter estimates and parameter true values (and VaR and ES forecasts and their "True" values) are also shown. In general, the MCMC algorithm produces accurate parameter estimates and tailrisk forecasts in terms of bias (difference between True and Mean columns) and precision (RMSE). Specifically, both 1% and 2.5% VaR&ES forecasts are close to their true values with bias less than 0.05 and RMSE less than 0.15. This means the employed MCMC procedure could produce accurate parameter estimates and tail risk forecasts.

Table 1: Summary statistics for the MCMC estimator of the Realized-T-M-GARCH model,

data simulated from Model 1.
n = 1900

MCMC

Parameter

True

Mean RMSE



0.1000 0.0993 0.0169



0.6500 0.6426 0.0236



0.3000 0.3021 0.0259

1

-0.2000 -0.1983 0.0420

1

0.9500 0.9635 0.0811

2

-0.5000 -0.4935 0.0426

2

0.9200 0.9320 0.0835



0.6000 0.6011 0.0100



10.0000 12.3515 3.9844

1% VaRt+1 2.5% VaRt+1 1% ESt+1 2.5% VaRt+1

-2.4576 -1.9813 -2.9907 -2.5068

-2.4424 -1.9762 -2.9589 -2.4886

0.0905 0.0616 0.1456 0.0996

14

Further, since the main development of the paper is the threshold measurement equation, Figure 2 presents the histograms of parameter estimates of all 1000 simulated data sets for 1&2 and 1&2. As can be seen, although parameters 1&2 and 1&2 have different true values, the adapted MCMC algorithm is capable of estimating all four parameters accurately, with the RMSE values around 0.04 for 1&2, and around 0.08 for 1&2 respectively.
Figure 2: Histograms of 1000 parameter estimates for 1&2 and 1&2 in the threshold measurement equation. True vertical line represents parameter true value from the simulation model. Mean vertical line represents the average of 1000 parameter estimates from MCMC.
5 Empirical Study
5.1 Data and forecasting setup
Six market indices are assessed in the empirical section, including S&P500, NASDAQ (both US), FTSE 100 (UK), DAX (Germany), SMI (Swiss) and ASX200 (Australia), with time period from January 2000 to December 2015. The high frequency closing
15

prices, observed at 5-minute intervals within trading hours, are downloaded from Thomson Reuters Tick History. The 5-minute data are employed to calculate the daily RV. The daily closing prices are also collected and used to calculate the daily return.
As discussed in Section 4, the daily returns employed are close-to-close, including the overnight price movement, while the RV is only calculated while the market is open. Therefore, the employed realized measures may have some downside bias for the true volatility of close-to-close returns, which can be captured and corrected by the 1 and 2 parameters in the Realized-T-M-GARCH framework.
A fixed size in-sample data is employed for estimation, combined with a rolling window approach, to produce each one-step-ahead VaR and ES forecast. Table 2 reports the insample size for each series, which differs due to different non-trading days occurring in each market.
Two forecasting studies with different out-of-sample sizes are conducted. The first study aims to assess the performance of the models for the 2008 GFC high volatility period, thus the initial date of the out-of-sample forecasting period is chosen as January 2008. Then for each index the out-of-sample size m is chosen as 400, meaning that the end of the forecasting period is around August 2009.
An eight year out-of-sample period is employed in the second forecasting study with the start date of the out-of-sample still chosen as Jan 2008 and out-of-sample size m as 2000. Therefore, the end of the forecasting period is around December 2015.
Both daily one-step-ahead VaR and ES forecasts are considered for the returns on the six indices, using  = 1%; 2.5%.
The proposed Realized-T-M-GARCH-tG and Realized-GARCH-tG, both estimated with MCMC, are included in the forecasting study to compare their performance.
In addition, for comparison purpose EGARCH and GJR-GARCH, both with Studentt distribution, are also included. Further, a GARCH with historical simulation (GARCHHS) approach is also included, where either a GJR-GARCH-t or a EGARCH-t is fit to the in-sample data, then standardised VaR and ES are estimated via historical simulation
16

from the sample of returns (e.g. r1, . . . , rn), standardised by dividing their GARCHestimated conditional standard deviation, i.e., rt/ h^t. Then, forecasts of VaR, ES are found by multiplying the standardised VaR and ES estimates by the forecast h^n+1 from the GJR-GARCH-t or the EGARCH-t model. All these GARCH type models are estimated by MLE.
5.2 VaR forecasting

Since quantiles are elicitable, as defined in Gneiting (2011), and the standard quantile loss function is strictly consistent, which means the expected quantile loss is a minimum at the true quantile series. In this section, the quantile loss over the out-of-sample period is used to compare the VaR forecast accuracy of the competing models. The most accurate VaR forecasting model is expected to produce the minimized aggregated quantile loss function, given as in Equation (11):

n+m
( - I(rt < Qt))(rt - Qt) ,
t=n+1

(11)

where n is the in-sample size and m is the out-of-sample size. Qn+1, . . . , Qn+m is a series

of quantile forecasts at levels  = 1%; 2.5% for the returns rn+1, . . . , rn+m.

Values of the out-of-sample quantile loss are presented in Table 2 and 3. The average loss is included in the Avg Loss column. The average rank based on ranks of quantile loss across six markets is calculated and shown in the Avg Rank column. Box indicates the favoured model and dashed box indicates the 2nd ranked model based on the average loss and rank.

For the GFC forecasting study, Table 2 shows that the proposed Realized-T-MGARCH-tG framework is characterized by very competitive performances, on both 1% and 2.5% quantile levels. On the 1% level, Realized-T-M-GARCH-tG ranks as the best on average (1.33), with smallest average quantile loss produced (25.2). Its performance is followed by Realized-GARCH-tG which has the same average rank as EGARCH-tHS. On the 2.5% level, the best ranked model (2.00) with the smallest average quantile

17

loss (52.4) is still Realized-T-M-GARCH-tG. The model with the second smallest loss is Realized-GARCH-tG, while the second best ranked model is EGARCH-t-HS. The performance of EGARCH-t and GJR-GARCH-t is in general close. Lastly, the effectiveness of incorporating realized measure in the quantile forecasting is clear, with the RealizedT-M-GARCH-tG and Realized-GARCH-tG in general better ranked with smaller loss produced.

Table 2: For the GFC study, quantile loss function values across the markets. Out-of-sample
size m = 400.  = 1%; 2.5% .

Model  = 1% EGARCH-t GJR-GARCH-t EGARCH-t-HS GJR-GARCH-t-HS Realized-GARCH-tG
Realized-T-M-GARCH-tG  = 2.5% EGARCH-t GJR-GARCH-t EGARCH-t-HS GJR-GARCH-t-HS Realized-GARCH-tG
Realized-T-M-GARCH-tG Out-of-sample m In-sample n

S&P500
27.3 26.0 26.1 26.2 26.7 25.7
59.8 55.4 57.1 55.1 56.2 54.9 400 2018

NASDAQ
32.8 32.0 32.4 32.2 30.0 29.2
62.8 62.0 62.7 62.0 59.4 58.7 400 2003

FTSE
26.1 26.8 24.8 25.7 24.4 24.3
54.7 54.9 52.3 53.1 51.2 51.1 400 2081

DAX
26.3 27.1 26.5 27.0 26.8 26.6
53.4 54.0 52.6 53.8 55.3 55.3 400 2066

SMI
26.9 27.8 26.1 27.0 26.3 25.3
51.4 52.3 50.8 52.2 52.6 51.7 400 2033

ASX200
21.5 22.3 20.7 22.0 20.0 20.0
47.8 47.2 45.5 46.1 42.6 42.5 400 1986

Avg Loss
26.8 27.0 26.1 26.7 25.7 25.2
55.0 54.3 53.5 53.7 52.9 52.4

Avg Rank
4.33 4.83 3.00 4.50 3.00 1.33
4.50 4.50 3.00 3.33 3.67 2.00

Note:Based on average loss and rank, box indicates the favoured model, dashed box indicates
the 2nd ranked model.

Table 3 includes the quantile forecasting results for the eight year out-of-sample study. For the more extreme 1% quantile level, the first and second best performed models are still Realized-T-M-GARCH-tG and Realized-GARCH-tG. However, for the 2.5% level, the best performing model is EGARCH-t-HS with average loss 162.4. Its performance is closely followed by Realized-T-M-GARCH-tG with average loss 162.5. The GJR-GARCHt-HS model also produces competitive results and is second best ranked (together with Realized-T-M-GARCH-tG).
To conclude, for both forecasting studies the proposed Realized-T-M-GARCH-tG model is characterised by very competitive quantile loss results. This demonstrates the validity and effectiveness of incorporating the threshold measurement equation to consider the leverage effect and forecast VaR accurately.

18

Table 3: Quantile loss function values across the markets. Out-of-sample size m = 2000.
 = 1%; 2.5%.

Model  = 1% EGARCH-t GJR-GARCH-t EGARCH-t-HS GJR-GARCH-t-HS Realized-GARCH-tG
Realized-T-M-GARCH-tG  = 2.5% EGARCH-t GJR-GARCH-t EGARCH-t-HS
GJR-GARCH-t-HS Realized-GARCH-tG Realized-T-M-GARCH-tG Out-of-sample m In-sample n

S&P500
77.4 74.9 76.7 75.2 74.9 74.7
166.9 162.9 163.7 161.0 162.0 161.1 2000 2018

NASDAQ
88.8 86.6 88.3 86.5 84.5 84.1
184.0 183.1 182.3 180.6 178.7 178.6 2000 2003

FTSE
72.5 73.3 71.3 71.9 72.2 72.2
155.2 156.4 153.0 154.5 154.1 154.0 2000 2081

DAX
86.3 87.8 86.9 88.0 84.3 84.3
181.6 182.9 179.5 180.7 185.1 185.2 2000 2066

SMI
79.9 82.6 78.9 81.7 80.8 80.5
159.3 159.4 157.5 159.3 161.8 161.2 2000 2033

ASX200
64.3 64.8 64.0 64.6 62.9 62.8
140.3 141.7 138.4 139.8 134.9 134.9 2000 1986

Avg Loss
78.2 78.3 77.7 78.0 76.6 76.4
164.6 164.4 162.4 162.6 162.8 162.5

Avg Rank
4.33 5.00 3.17 4.17 2.50 1.83
4.50 4.83 2.50 2.83 3.50 2.83

Note:Based on average loss and rank, box indicates the favoured model, dashed box indicates
the 2nd ranked model.

5.3 ES forecasting

The same set of models is employed to generate one-step-ahead forecasts of 1% and 2.5% ES during the forecast period for all six series.

To evaluate the proposed Realized-T-M-GARCH, we assess the ability of the different models under comparison to forecast VaR and ES jointly, employing a strictly consistent VaR and ES joint loss function.

Fissler and Ziegel (2016) find the class of jointly consistent scoring functions for VaR and ES i.e., their expectations are uniquely minimized by the true VaR and ES series. The general form of this functional family is:

St(rt, Qt, ESt)

=

(It - )G1(Qt) - ItG1(rt) + G2(ESt)

ESt

-

Qt

+

It 

(Qt

-

rt)

- H(ESt) + a(rt) ,

(12)

where G1(.) is increasing, G2(.) is strictly increasing and strictly convex, G2 = H and limx- G2(x) = 0 and a(·) is a real-valued integrable function.
As presented in Taylor (2019), assuming rt to have zero mean, making the choices: G1(x) = 0, G2(x) = -1/x, H(x) = -log(-x) and a = 1 - log(1 - ), which satisfy the

19

required criteria, returns the scoring function:

St(rt, Qt, ESt) = -log

-1 ESt

-

(rt

-

Qt)( - I(rt ESt

<

Qt)) .

(13)

Taylor (2019) refers to Equation (13) as the Asymmetric Laplace (AL) log score which is

used to jointly assess the VaR and ES forecasting accuracy.

First, Figure 3 shows the S&P500 1% ES forecasts from EGARCH-t, RealizedGARCH-tG and Realized-T-M-GARCH-tG during the GFC period. As can be seen, the ES forecasts from Realized-T-M-GARCH-tG and Realized-GARCH-tG present some distinctive behaviours during the highly volatile period, i.e., around Oct 2008. To make a more in-depth comparison of these models, Figure 4 presents the S&P 500 1% VaR&ES AL joint loss (log-score) values for each time step across the out-of-sample period of the GFC study. In general, the Realized-T-M-GARCH-tG VaR&ES forecasts are characterized by smaller joint loss values than the ones from the Realized-GARCH-tG, such as Oct 2008 and Dec 2008. In addition, there are two joint loss value jumps for the Realized-GARCH-tG during the first half of 2009, while such jumps are not observed for the Realized-T-M-GARCH-tG model. Such reduced VaR&ES joint loss values, especially during the high volatility period, reflect the potential additional tail risk forecasting efficiency that can be gained from the threshold measurement specification in a RealizedGARCH framework. These observations are also consistently presented across different indices.

As a more comprehensive comparison, Table 4 and Table 5 report, for each model and

index, the value of the loss function in Equation (13) aggregated over the out-of-sample

period: S =

n+m t=n+1

St,

with

m

=

400

and

m

=

2000

respectively.

Regarding the joint loss of the GFC study, Realized-T-M-GARCH-tG is again the

best ranked model with the smallest average loss produced, on both 1% and 2.5% quantile

levels. The second best performing model is Realized-GARCH-t. Comparing models with

and without high frequency information, the performance of Realized-T-M-GARCH-tG

and Realized-GARCH-tG is clearly favoured.

With respect to the joint loss values produced with longer forecasting horizon, on the 1% quantile level the preferred model with the smallest average loss and best rank is

20

15
SP500 Return EGARCH-t Realized-GARCH-tG Realized-Threshold-Measurement-GARCH-tG 10

5

0

-5

-10

-15

-20 Jan 2008

Apr 2008

Jul 2008

Oct 2008

Jan 2009

Apr 2009

Jul 2009

Oct 2009

Figure 3: S&P 500 1% ES forecasts from EGARCH-t, Realized-GARCH-tG and RealizedT-M-GARCH-tG during the GFC period.

21

10 5 0 -5
-10 Jan 2008

Apr 2008

Jul 2008

Oct 2008

Jan 2009

Apr 2009

S&P500 return

Jul 2009

Oct 2009

40

20

0 Jan 2008

Apr 2008

Jul 2008

Oct 2008

Realized-GARCH-tG

Jan 2009

Apr 2009

Jul 2009

Oct 2009

40

20

0 Jan 2008

Apr 2008

Jul 2008

Oct 2008

Realized-Threshold-Measurement-GARCH-tG

Jan 2009

Apr 2009

Jul 2009

Oct 2009

Figure 4: S&P 500 1% VaR&ES forecasts AL joint loss values from EGARCH-t, RealizedGARCH-tG and Realized-T-M-GARCH-tG during the GFC period.

22

Table 4: For the GFC study, VaR and ES joint loss function values across the markets. Out-
of-sample size m = 400.  = 1%; 2.5%.

Model  = 1% EGARCH-t GJR-GARCH-t EGARCH-t-HS GJR-GARCH-t-HS
Realized-GARCH-tG
Realized-T-M-GARCH-tG  = 2.5% EGARCH-t GJR-GARCH-t EGARCH-t-HS GJR-GARCH-t-HS
Realized-GARCH-tG
Realized-T-M-GARCH-tG Out-of-sample m In-sample n

S&P500
1167.6 1123.9 1134.0 1119.8 1120.0 1102.0
1114.2 1078.6 1085.1 1069.3 1067.6 1056.7
400 2018

NASDAQ
1244.6 1228.1 1226.3 1226.4 1182.7 1173.4
1131.5 1124.4 1126.6 1122.5 1091.4 1085.7
400 2003

FTSE
1205.5 1208.2 1160.9 1164.1 1103.3 1101.1
1108.8 1107.0 1073.3 1073.9 1038.6 1037.4
400 2081

DAX
1161.1 1186.8 1156.3 1174.5 1176.2 1179.8
1068.2 1082.6 1058.4 1076.9 1088.3 1091.1
400 2066

SMI
1135.5 1170.6 1106.0 1139.1 1104.2 1083.7
1031.9 1047.7 1019.4 1037.7 1035.4 1019.5
400 2033

ASX200
1066.2 1088.8 1039.6 1068.3 1028.0 1028.0
1030.3 1027.9 995.1 1007.2 975.6 975.1
400 1986

Avg Loss
1163.4 1167.7 1137.2 1148.7 1119.1 1111.3
1080.8 1078.1 1059.7 1064.6 1049.5 1044.3

Avg Rank
4.50 5.50 3.00 3.83 2.50 1.67
4.83 4.67 3.00 3.67 2.83 2.00

Note:Based on average loss and rank, box indicates the favoured model, dashed box indicates
the 2nd ranked model.

Realized-GARCH-tG, which is closely followed by the Realized-T-M-GARCH-tG framework. With  = 2.5% which is a less extreme quantile level than 1%, Realized-T-MGARCH-tG generates competitive results compared to Realized-GARCH-tG, with both models ranked as 2.67. The joint loss values of two models are very close as well, 4244.0 and 4242.5 respectively. The best ranked model is GJR-GARCH-t-HS (2.00).
Overall, the joint loss results lend further support on the usefulness of the proposed Realized-T-M-GARCH framework. The model produces competitive results, comparing to the competing models, for both forecasting studies and both quantile levels. Especially, for the highly volatile GFC period, the Realized-T-M-GARCH framework is clearly preferred, with potential reasons as discussed when presenting Figure 3 and 4.

6 Conclusion

In this paper, an innovative threshold measurement equation is proposed and its validity is evaluated in a Realized-GARCH framework. Through incorporating a threshold regression specification, the proposed measurement equation is capable of capturing the leverage effect in a manner that is different to the original Realized-GARCH in Hansen et al. (2012). The contemporaneous dependence between the observed realized

23

Table 5: VaR and ES joint loss function values across the markets. Out-of-sample size m = 2000.
 = 1%; 2.5%.

Model  = 1% EGARCH-t GJR-GARCH-t EGARCH-t-HS GJR-GARCH-t-HS Realized-GARCH-tG
Realized-T-M-GARCH-tG  = 2.5% EGARCH-t GJR-GARCH-t EGARCH-t-HS
GJR-GARCH-t-HS
Realized-GARCH-tG
Realized-T-M-GARCH-tG Out-of-sample m In-sample n

S&P500
4587.6 4459.0 4539.0 4436.8 4415.8 4433.0
4290.6 4239.2 4225.1 4174.1 4183.9 4188.0 2000 2018

NASDAQ
4837.2 4743.6 4782.7 4717.4 4715.0 4706.7
4517.6 4490.2 4464.5 4428.8 4429.4 4426.3 2000 2003

FTSE
4537.7 4486.0 4479.9 4422.8 4420.3 4421.0
4192.1 4183.8 4146.9 4131.3 4144.5 4144.3 2000 2081

DAX
4949.5 4981.8 4924.8 4947.4 4822.6 4831.6
4585.2 4601.4 4542.8 4556.6 4582.9 4591.5 2000 2066

SMI
4689.9 4778.7 4604.2 4684.5 4630.5 4646.0
4245.2 4253.6 4185.5 4216.0 4226.2 4225.6 2000 2033

ASX200
4277.6 4245.0 4258.8 4225.1 4149.5 4148.9
3990.4 4009.1 3953.9 3962.5 3888.0 3888.3 2000 1986

Avg Loss
4646.6 4615.7 4598.2 4572.3 4525.6 4531.2
4303.5 4296.2 4253.1 4244.9 4242.5 4244.0

Avg Rank
5.67 4.83 3.83 3.33 1.50 1.83
5.33 5.50 2.83 2.00 2.67 2.67

Note:Based on average loss and rank, box indicates the favoured model, dashed box indicates
the 2nd ranked model.

measures and hidden volatility is also successfully modelled in the proposed framework, in a way that is potentially more flexible compared to the one in Realized-GARCH. This threshold measurement equation can be employed in various extensions of the RealizedGARCH, such as Realized-EGARCH, Realized-HAR-GARCH, Realized-Threshold-GARCH and Realized-CARE, etc.
The estimation of the proposed Realized-T-M-GARCH model employs an adaptive Bayesian MCMC method, the validity of which is evaluated via a simulation study. In a empirical study with six market indices and two out-of-sample sizes, the effectiveness of the proposed model is evaluated. The Realized-T-M-GARCH model produces 1 and 2 estimates that are capable of adjusting the RV bias dependent on the sign of the lagged return. In addition, the 1 and 2 parameters in the threshold measurement equation present different behaviours which could potentially model the relationship between the realized measure and volatility in a more flexible way, compared to the Realized-GARCH. Both observations show that the proposed threshold measurement equation is capable of capturing the leverage effect successfully.
The 1% and 2.5% VaR and ES forecasting results lend further evidence on the usefulness of the proposed framework. Comparing to the Realized-GARCH, the Realized-T-MGARCH model produces competitive quantile loss and joint loss values for an eight year

24

out-of-sample period. Focusing on the high volatility 2008 GFC period, the Realized-TM-GARCH is in general favoured.
This work could be extended by a number of ways. First, the effectiveness of incorporating the proposed framework in Realized-EGARCH, Realized-HAR-GARCH, RealizedThreshold-GARCH and Realized-CARE, etc, could be evaluated and compared. Second, multiple realized measures could be considered as input to the proposed threshold measurement equation. The impact of such extended framework on volatility and tail risk forecasting accuracy could be investigated. Third, the current threshold specification could be potentially extended by a smooth transition framework, see the smooth transition GARCH of Gonz´alez-Rivera (1998) and Anderson et al. (1999), or the smooth transition dynamic range models of Lin et al. (2012) as examples.
25

References
Acerbi, C. and D. Tasche (2002). Expected shortfall: A natural coherent alternative to value at risk. Economic Notes 31 (2), 379­388.
Andersen, T. G. and T. Bollerslev (1998). Answering the skeptics: Yes, standard volatility models do provide accurate forecasts. International economic review , 885­905.
Andersen, T. G., T. Bollerslev, F. X. Diebold, and P. Labys (2003). Modeling and forecasting realized volatility. Econometrica 71 (2), 579­625.
Anderson, H. M., K. Nam, and F. Vahid (1999). Asymmetric nonlinear smooth transition garch models. In Nonlinear time series analysis of economic and financial data, pp. 191­207. Springer.
Artzner, P. (1997). Thinking coherently. Risk , 68­71.
Artzner, P., F. Delbaen, J. Eber, and D. Heath (1999). Coherent measures of risk. Mathematical Finance 9 (3), 203­228.
Black, F. (1976). Studies of stock market volatility changes. 1976 Proceedings of the American Statistical Association Bisiness and Economic Statistics Section.
Bollerslev, T. (1986). Generalized autoregressive conditional heteroskedasticity. Journal of econometrics 31 (3), 307­327.
Chen, C. W., R. Gerlach, and E. M. Lin (2008). Volatility forecasting using threshold heteroskedastic models of the intra-day range. Computational Statistics & Data Analysis 52 (6), 2990­3010.
Chen, C. W. and T. Watanabe (2019). Bayesian modeling and forecasting of valueat-risk via threshold realized volatility. Applied Stochastic Models in Business and Industry 35 (3), 747­765.
Chen, W. Y., G. W. Peters, R. H. Gerlach, and S. A. Sisson (2017). Dynamic quantile function models. arXiv preprint arXiv:1707.02587 .
26

Contino, C. and R. H. Gerlach (2017). Bayesian tail-risk forecasting using realized garch. Applied Stochastic Models in Business and Industry 33 (2), 213­236.
Engle, R. F. (1982). Autoregressive conditional heteroscedasticity with estimates of the variance of united kingdom inflation. Econometrica: Journal of the econometric society, 987­1007.
Ferna´ndez, C. and M. F. Steel (1998). On bayesian modeling of fat tails and skewness. Journal of the american statistical association 93 (441), 359­371.
Fissler, T. and J. F. Ziegel (2016). Higher order elicitability and Osband's principle. The Annals of Statistics 44 (4), 1680­1707.
Gelman, A., W. R. Gilks, and G. O. Roberts (1997). Weak convergence and optimal scaling of random walk metropolis algorithms. The annals of applied probability 7 (1), 110­120.
Gerlach, R. and C. Wang (2016). Forecasting risk via realized garch, incorporating the realized range. Quantitative Finance 16 (4), 501­511.
Gerlach, R. and C. Wang (2020). Bayesian semi-parametric realized conditional autoregressive expectile models for tail risk forecasting. Journal of Financial Econometrics (In Press).
Glosten, L. R., R. Jagannathan, and D. E. Runkle (1993). On the relation between the expected value and the volatility of the nominal excess return on stocks. The journal of finance 48 (5), 1779­1801.
Gneiting, T. (2011). Making and evaluating point forecasts. Journal of the American Statistical Association 106 (494), 746­762.
Goldfeld, S. M. and R. E. Quandat (1972). Nonlinear methods in econometrics.
Gonz´alez-Rivera, G. (1998). Smooth-transition garch models. Studies in Nonlinear Dynamics & Econometrics 3 (2).
27

Granger, C. W., T. Terasvirta, et al. (1993). Modelling non-linear economic relationships. OUP Catalogue.
Hansen, P. R. and Z. Huang (2016). Exponential garch modeling with realized measures of volatility. Journal of Business & Economic Statistics 34 (2), 269­287.
Hansen, P. R., Z. Huang, and H. H. Shek (2012). Realized garch: a joint model for returns and realized measures of volatility. Journal of Applied Econometrics 27 (6), 877­906.
Huang, Z., H. Liu, and T. Wang (2016). Modeling long memory volatility using realized measures of volatility: A realized har garch model. Economic Modelling 52, 812­821.
Li, C. and W. K. Li (1996). On a double-threshold autoregressive heteroscedastic time series model. Journal of applied econometrics 11 (3), 253­274.
Lin, E. M., C. W. Chen, and R. Gerlach (2012). Forecasting volatility with asymmetric smooth transition dynamic range models. International Journal of Forecasting 28 (2), 384­399.
Nelson, D. B. (1991). Conditional heteroskedasticity in asset returns: A new approach. Econometrica: Journal of the Econometric Society, 347­370.
Poon, S.-H. and C. W. Granger (2003). Forecasting volatility in financial markets: A review. Journal of economic literature 41 (2), 478­539.
Silvapulle, M. J. and P. K. Sen (2005). Constrained statistical inference: Inequality, order and shape restrictions. John Wiley & Sons.
Taylor, J. W. (2019). Forecasting value at risk and expected shortfall using a semiparametric approach based on the asymmetric laplace distribution. Journal of Business & Economic Statistics 37 (1), 121­133.
Tong, H. (1978). On a threshold model.
Tong, H. (1990). Non-linear time series: a dynamical system approach. Oxford University Press.
28

Watanabe, T. (2012). Quantile forecasts of financial returns using realized garch models. The Japanese Economic Review 63 (1), 68­80.
29

