
# Towards Explainable Convolutional Features for Music Audio Modeling

[arXiv](https://arxiv.org/abs/2106.0110), [PDF](https://arxiv.org/pdf/2106.0110.pdf)

## Authors

- Anna K. Yanchenko
- Mohammadreza Soltani
- Robert J. Ravier
- Sayan Mukherjee
- Vahid Tarokh

## Abstract

Audio signals are often represented as spectrograms and treated as 2D images. In this light, deep convolutional architectures are widely used for music audio tasks even though these two data types have very different structures. In this work, we attempt to "open the black-box" on deep convolutional models to inform future architectures for music audio tasks, and explain the excellent performance of deep convolutions that model spectrograms as 2D images. To this end, we expand recent explainability discussions in deep learning for natural image data to music audio data through systematic experiments using the deep features learned by various convolutional architectures. We demonstrate that deep convolutional features perform well across various target tasks, whether or not they are extracted from deep architectures originally trained on that task. Additionally, deep features exhibit high similarity to hand-crafted wavelet features, whether the deep features are extracted from a trained or untrained model.

## Comments

Code available at this https URL

## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{yanchenko2021explainable,
      title={Towards Explainable Convolutional Features for Music Audio Modeling}, 
      author={Anna K. Yanchenko and Mohammadreza Soltani and Robert J. Ravier and Sayan Mukherjee and Vahid Tarokh},
      year={2021},
      eprint={2106.00110},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}
```

## Notes

Type your reading notes here...

