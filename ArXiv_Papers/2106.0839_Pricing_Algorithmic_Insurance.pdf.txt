arXiv:2106.00839v1 [cs.LG] 1 Jun 2021

Pricing Algorithmic Insurance
Dimitris Bertsimas
Sloan School of Management, Massachusetts Institute of Technology, MA, USA dbertsim@mit.edu
Agni Orfanoudaki
Operations Research Center, Massachusetts Institute of Technology, MA, USA, agniorf@mit.edu As machine learning algorithms start to get integrated into the decision-making process of companies and organizations, insurance products will be developed to protect their owners from risk. We introduce the concept of algorithmic insurance and present a quantitative framework to enable the pricing of the derived insurance contracts. We propose an optimization formulation to estimate the risk exposure and price for a binary classification model. Our approach outlines how properties of the model, such as accuracy, interpretability and generalizability, can influence the insurance contract evaluation. To showcase a practical implementation of the proposed framework, we present a case study of medical malpractice in the context of breast cancer detection. Our analysis focuses on measuring the effect of the model parameters on the expected financial loss and identifying the aspects of algorithmic performance that predominantly affect the price of the contract. Key words : Algorithmic Insurance, Machine Learning, Algorithmic Risk
1. Introduction
Data-driven analytical models and machine learning (ML) algorithms have started transforming large facets of the economy, becoming the driver of innovation in digital marketing, self-driving cars and medical imaging, among others. While the use of artificial intelligence expands across all segments of society, algorithms are expected to replace human judgement in many cases (Coglianese and Lehr 2016). However, there is still a lot of resistance in employing these tools in practice as different types of concerns are emerging about algorithmic decision-making (Char et al. 2018). Dietvorst et al. (2015) defined this phenomenon as algorithm aversion, identifying a wide range of factors, including ethical issues, related to the use of algorithms that are not resolved yet (Dietvorst et al. 2018). One of the persistent challenges related to the implementation of ML models in practice
1

Bertsimas et al.: Pricing Algorithmic Insurance

2

Article submitted for publication

is centered around the question of responsibility in case of erroneous algorithmic decisions making

(Singh et al. 2016).

This is not the first time that modern societies are called to face such dilemmas. Similar situations

haven gained spotlight in the past, such as when cars became accessible to the broader consumer

audience in urban areas after World War I. By that time, motor vehicles had become fast and less

expensive and manufacturers were expecting an increasing portion of society to enter the market.

Nevertheless, the vast majority of households were still reluctant to adopt the technology as it

could entail disproportionately high financial risks. In the absence of insurance policies, injured

victims would seldom get any compensation in an accident, and drivers often faced considerable

costs for damage to their car and property. To ensure that all vehicle owners and drivers can be

protected against the risk of causing injury or death to third parties, the Road Traffic Act was

established in 1930 in the United Kingdom, introducing the first compulsory car insurance scheme

(Senn 1930). Over the years, legal questions related to responsibility became inextricably linked

to third party liability. In general terms, third party liability insurance provides protection against

claims resulting from physical injuries to people and/or damage to property (Reed et al. 2016).

Nowadays, liability coverage has become so important that it is often required for automotive

insurance policies, product manufacturers, and anyone who practices medicine or law.

As ML algorithms are expected to replace human decision-making in cases where their predictive

and prescriptive performance yields better outcomes, a new type of liability insurance could be

developed to protect their owners from risk. Potential examples are self-driving cars (third party

liability), preventive maintenance based on ML (general liability) and image recognition systems for

MRI machines (medical liability). If there were legal contracts that individuals and organizations

could sign to protect themselves from algorithmic mistakes, the implementation of ML tools would

be significantly faster and less contentious (Bertolini et al. 2016).

To propel the effective use and widespread adoption of ML algorithms, we introduce in this paper

the concept of algorithmic insurance contracts and provide quantitative tools to evaluate them.

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

3

Our goal is to propose a methodology to price insurance contracts in situations where decisions

are made by ML algorithms. Specifically, we address how the properties of ML models, such as

interpretability and generalizability, can influence pricing.

The prerequisites of this type of contracts are, as in all cases of insurance, (i) an agreement

between the parties, (ii) the existence of a risk to the insured party or potential third parties,

(iii) the payment of a premium (Bertolini 2013). We determine the premium as a function of the

assumed risk. Hence it varies according to both the likelihood of its occurrence (frequency), and

the magnitude of the consequences that may arise once it materializes (severity). Thus, the main

focus of this work is the determination of an appropriate premium pricing strategy for every policy

given the expected risk exposure.

The pricing of traditional non-life insurance products is usually conducted using the fundamental

principles of actuarial science and asset pricing theory (Cummins 1990, Embrechts 2000). Leverag-

ing historic observations from prior realizations of risk, underwriters are able to create probabilistic

models that estimate the potential risk exposure, the relative frequency of adverse events, and

associate an appropriate price.

The key challenge of algorithmic insurance is the absence of historic claims that could be used

to directly apply existing underwriting processes. During the initial implementation of ML-driven

decision-making tools, very limited information regarding past algorithmic mistakes is available.

For example, since fully autonomous cars have not been deployed yet, it is impossible to collect

information with respect to past accidents they have caused. We overcome this limitation by

centering our approach around the data that participated in the training and validation process

of the ML models. By leveraging this valuable resource and other properties of the algorithm,

we introduce a series of tools for insurance companies and data scientists that will allow them to

evaluate the litigation risk associated with the implementation of a ML algorithm under different

scenarios.

Bertsimas et al.: Pricing Algorithmic Insurance

4

Article submitted for publication

Contributions

We present for the first time a data-driven methodology to price insurance contracts in situations where decisions are made by ML algorithms. Our contributions can be summarized as follows:
1. We introduce an optimization formulation that leverages measures of risk from the financial literature to simultaneously estimate the risk exposure and price for a given binary classification model. We extend the formulation using robust optimization to different types of uncertainty sets around historical scenarios of loss.
2. We propose how to price algorithmic liability based on properties of the underlying ML method, such as accuracy, interpretability and generalizability.
3. We provide a case-study for medical liability and analyze the potential effect of the model parameters in simulated experiments.
4. We show that the most impactful parameter on the risk exposure of the predictive model is the chosen classification threshold. Our analysis also illustrates that the convexity of the selected interpretability function dictates whether a smaller or larger degree of transparency is needed to significantly reduce the expected financial loss of the contract. Finally, we demonstrate that the use of Generative Adversarial Networks (GANs) allows decision makers to measure the effect of distributional changes in the data on the expected financial loss.
The structure of the paper is as follows. In Section 2, we introduce a case study of medical liability in the context of breast cancer detection that serves to define in a concrete way the problem we are addressing. In Section 3, we present the baseline optimization formulation that leads to the simultaneous estimation of price and risk exposure. In Section 4, we incorporate the predictive accuracy of a binary classification model into the estimation process of future expected loss. In Section 5, we demonstrate how to include a ML algorithm's interpretability into the pricing strategy. Section 6 focuses on data generalizability and its effect on the premium determination. In each of the Sections 4-6, we use the medical liability case study to showcase a practical implementation of the framework and highlight the effect of the model parameters. In Section 7, we discuss the key findings from the computational experiments, the limitations of the framework, and future applications of the proposed approach. We conclude in Section 8.

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

5

2. A Case Study of Medical Liability for Malignant Tumor Detection

In this section, we introduce a case study of algorithmic insurance for medical liability. The case study will illustrate a practical implementation of the proposed risk evaluation framework.
We delve into breast cancer, a carcinoma that is estimated to affect one out of eight women at some point in their lifetime (SEER 2020). According to the American Cancer Society, more than 250,000 women are diagnosed with invasive breast cancer every year in the US (Siegel et al. 2018). Due to widely established screening policies and improved therapies, breast cancer has now one of the lowest mortality rates among carcinomas (Berry et al. 2005). Nevertheless, medical malpractice related to breast cancer and breast imaging remains common and costly for both radiologists and healthcare organizations involved (Lee et al. 2020). In the future, the widespread implementation of artificial intelligence algorithms is expected to improve the diagnostic accuracy and reduce diagnostic errors in carcinomas (Kim et al. 2020, Yala et al. 2019).
Given the transformative role that ML can play in this application area, we focus on a case study for breast cancer detection to illustrate a practical implementation of the proposed pricing framework. First, we describe the dataset that we use to train the underlying predictive model. Subsequently, we present an overview of historical medical malpractice lawsuits for breast cancer detection.

Data Description For our analysis, we will use the Breast Cancer Wisconsin Diagnostic dataset from the UCI ML Repository (Dua and Graff 2017). The features of the dataset represent characteristics of the cell nuclei of a breast mass (Street et al. 1993). This information was acquired from digitized images of fine needle aspirate (FNA) analyses. FNA biopsies are recommended to women who are suspected to suffer from breast cancer. During this procedure, a small amount of breast tissue or fluid is taken from the suspicious area and is checked for cancer cells. The dataset contains ten features related to the cell nucleus of each sample, including radius, texture, perimeter, area, smoothness, degree of compactness, concavity, presence concave points, symmetry, and fractal dimension. The outcome of interest is whether the sample belongs to a benign or malignant tumor.

6 Medical Malpractice Lawsuits for Breast Cancer

Bertsimas et al.: Pricing Algorithmic Insurance Article submitted for publication

Lawsuits involving breast cancer are the most common cause of medical malpractice litigation in the United States (Whang et al. 2013). An analysis from credentialing data of 8401 radiologists, revealed that breast cancer was the most frequently missed diagnosis, followed by nonvertebral fractures and spinal fractures (Whang et al. 2013). Breast cancer imaging lawsuits involve physicians from multiple specialties, radiology being the most common. Lee et al. (2020) identified 253 cases in the US from 2005 to 2015 that resulted in plaintiff payment where the average award amount was $978,858. The median award amount in cases with a verdict was $862,500 with interquartile range (IQR) ($500,000 to $2,009,460) while, in cases that concluded with a settlement, it was as high as $1,162,500 with IQR ($17,000 to $2,000,000).
In a separate study conducted from 1995 to 1997, 218 surgical pathology and FNA claims were reviewed. Breast FNA corresponded to 6% of those records while breast biopsy accounted for another 14% (Anderson and Troxel 2005). 54% of breast biopsy claims referred to false-negative diagnoses of breast carcinoma, whereas 35% were for the false positive diagnosis of cancer, demonstrating the importance of high sensitivity and specificity for the binary classification model (Le et al. 2016). Malpractice claims from false positive FNAs are usually attributed to wrong interpretations by the medical team. The most common case is when a fibroadenoma is misclassified as carcinoma resulting in unnecessary mastectomy or axillary node sampling if breast conservation is elected (Anderson and Troxel 2005). Such cases can result in malpractice claims of more than $800,000 (Rosen&Perry, Gismondi&Associates 2012).
In the following sections, we analyze the impact of predictive performance, interpretability, and generalizability on the insurance contract. The goal is to understand the effect of the model parameters and highlight the algorithmic aspects that may significantly affect the risk exposure of an insurance contract.

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

7

3. Quantifying the Risk Exposure

Our goal in this section is to provide a baseline optimization framework to quantify the risk

exposure of the insurance contract and the associated price. We present both a nominal and a

robust formulation of the problem based on the expected severity and frequency of the claims.

Our framework estimates risk exposure using tools from the finance literature. We resort to two

well established statistical techniques used to measure the level of financial risk within a firm or an

investment portfolio over a specific time frame; the Value-at-Risk (VaR) and the Conditional-Value-

at-Risk (CVaR). VaR answers the question of what is the maximum loss with a specified confidence

level (Jorion 2000). CVaR is the expected loss if that confidence level is ever crossed. Though VaR

is a widely accepted and used measure, it is not coherent as it violates the subadditivity property

of coherent measures (Artzner et al. 1999). VaR is neither convex nor smooth, and it may result to

multiple local extrema (Rockafellar and Uryasev 2000). As a result, optimizing this measure under

different constraints is quite complex. For this reason, we focus on CVaR, which is a coherent and

convex risk measure and can be optimized using linear optimization (Uryasev 2000, Artzner et al.

1999).

We consider P premium categories, corresponding to the different classes of claims that we

insure. For example, referring to the medical malpractice problem, we could classify the patients

into three age groups ([0, 30), [30, 50], [50, 120)), in which case P = 3. Let f (x, z) be a loss function

that takes as input a decision vector of premiums x = (x1, . . . , xP ) and a random vector of losses z = (z1, . . . , zP ). The decision vector x belongs to a feasible set of prices X. The loss function f (x, z) is equal to the difference between the price and the future loss in case there is a claim:

P

f (x, z) = max{0, zj - xj}.

(1)

j=1

Uryasev (2000) proposed a framework for the simultaneous calculation of VaR and CVaR as

well as the determination of the associated premium based on the distribution of the losses (see

Appendix for an overview). The author also noticed that in the real-world we do not have the

Bertsimas et al.: Pricing Algorithmic Insurance

8

Article submitted for publication

analytical representation of the density function of z to estimate the probability that the loss

function does not exceed a threshold value . However, using past observations, we have access to

scenarios yj, with j  [J], sampled from the density p(z). Thus, the following CVaR approximation

was introduced:

J

F(x, ) =  +  (f (x, yj) - )+,

(2)

j=1

where  is the a given confidence level,  = ((1 - )J)-1 and  is the variable that represents VaR.

If f (x, y) is convex w.r.t. to x, then F(x, ) is a convex non-smooth function w.r.t. to (x, ).

Thus, linear optimization can be used to solve the problem of interest. Several studies have shown

that this approach provides a very powerful, fast, and numerically stable technique which can solve

problems with a large number of variables and past scenarios (McNeil et al. 2015, Markowitz 2010,

Bertsimas et al. 2004).

A Nominal Formulation for Algorithmic Insurance
We adjust the formulation introduced by Uryasev (2000) to the algorithmic insurance setting. The proposed framework is based on a linear optimization formulation that leverages data-driven scenarios yj. We present in the following sections a quantitative process to simulate J scenarios yj for a given number of observations N . The loss function f (·) is not linear since it is defined as f (x, y) = max{0, (y - x)}. We can also restrict the price vector x within fixed lower (lp) and upper bounds (Hp) that reflect the pricing constraints of the insured party. We let [P ] represent the set of premium categories that are included in the contract. We propose the following baseline formulation:

J

minimize  +  zj

j=1 P

subject to zj  max{0, (ypj - xp)} - , j  [J ],

(3)

p=1

zj  0,

j  [J],

lp  xp  Hp

p  [P ].

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

9

Finally, we can solve Equation (3) using a cutting planes algorithm or by linearizing the con-

straints, which results in:

J
minimize  +  zj
j=1 P
subject to zj  wpj - , j  [J ],
p=1

zj  0,

j  [J],

(4)

wpj  0,

j  [J], p  [P ],

wpj  ypj - xp, j  [J ], p  [P ],

lp  xp  Hp p  [P ].

A Robust Formulation for Algorithmic Insurance Solutions to optimization problems can exhibit high sensitivity to perturbations in the problem parameters (Ben-Tal and Nemirovski 2000). In the setting of algorithmic insurance, uncertainty lies at the center of the problem, gaining even higher significance. In the absence of real-world past scenarios yj, we propose a data-driven way to generate them in Sections 4-6, combining the model properties with historical claims of past cases based on human decisions. Undoubtedly, the presented modeling approach contains noise in the proposed scenarios yj which can be attributed either to the probabilistic assumptions or to the model performance. Robust optimization offers a solution to this problem proposing uncertainty models that are not stochastic, but rather deterministic and set-based. Leveraging these techniques, we introduce two robust formulations.
Box Uncertainty with -Robustness. We will apply the notion of -Robustness proposed by (Bertsimas and Sim 2004). We first assume that the scenarios yj lie in the uncertainty set:

U1 = {y|µpj - pjpj  ypj  µpj + pjpj,    }.

(5)

Therefore, in this setting, the formulation of the robust counterpart is the following:

Bertsimas et al.: Pricing Algorithmic Insurance

10

Article submitted for publication

J
minimize  +  zj
j=1 P
subject to zj  wpj - ,
p=1

j  [J],

zj  0,

j  [J],

(6)

wpj  0,

j  [J], p  [P ],

wpj + xp  µpj + pjpj, j  [J ], p  [P ],

lp  xp  Hp

p  [P ].

Polyhedral Uncertainty with -Robustness. Here, we assume that the scenarios yj lie in the uncertainty set:

U2 = {y|µpj - pjpj  ypj  µpj + pjpj,  1  }.

(7)

Based on this definition, the corresponding robust formulation follows:

J
minimize  +  zj
j=1 P
subject to zj  wpj - ,
p=1
zj  0,

j  [J], j  [J],

wpj  0,

j  [J], p  [P ],

wpj + xp  µpjqpj - µpjspj + r, j  [J ], p  [P ],

(8)

qpj - spj = 1,

j  [J], p  [P ],

-pjqpj - pjspj + r  0, qp,j  0, sp,j  0,

j  [J], p  [P ], j  [J], p  [P ], j  [J], p  [P ],

r0

lp  xp  Hp

p  [P ].

We refer the reader to the Appendix and the work of Bertsimas and den Hertog (2021) for the

detailed derivation of the robust counterpart from the nominal problem.

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

11

4. The Effect of Predictive Performance

The optimization formulations in Section 3 are based on historical scenarios of loss y. In this section, our goal is to derive these scenarios of loss in the absence of historical claims based on the predictive performance of a ML model.
To achieve this objective, we propose a data-driven approach that leverages available information regarding both the frequency and severity of future claims. We argue that the claim frequency of an erroneous algorithmic decision is a function of the model's predictive performance (e.g., AUC). Higher sensitivity reduces the probability of a false negative algorithmic mistake while models with higher specificity are less likely to perform a false negative error. The expected claims cost (severity), though, will depend on the nature of the decision and the type of error.
Going back to the case study, suppose that a pathologist receives FNA samples from which, using their knowledge and experience, determines whether a patient has a malignant breast tumor or not. Depending on the doctor's response the patient will or will not follow cancer treatment. In the case the physician proposes an erroneous diagnosis, there is an associated cost with this decision:
· If the patient is diagnosed with cancer but does not actually have it, there is the additional cost of unnecessary treatment that may even result to a needless mastectomy. We will assume that this cost is captured by a random variable K with mean µ and variance µ.
· If the patient is not diagnosed with cancer but actually has the disease, the severity of the outcome for the patient is likely increased, since it is known that early detection is critical in cancer patients. This increase of severity is associated with a higher litigation cost, which is captured by a random variable L with mean M and variance M .
Suppose now that instead of a doctor, a ML model is taking up the task of deciding, based on the FNA samples, whether the patient has cancer or not. This is not only a hypothetical example as at the Massachusetts General Hospital radiology department a ML model is partially responsible for the screening process of patients with mammograms (Yala et al. 2019). Typically, the output

Bertsimas et al.: Pricing Algorithmic Insurance

12

Article submitted for publication

of such binary classification algorithms is a prediction score. The model assigns to each input

observation an individual risk score that indicates how likely it is for each sample to be associated

with the outcome of interest (e.g., cancer diagnosis). To map each observation to a crisp class label,

a classification threshold  must be defined. For example, if the pathology department has specified

a classification threshold  = 0.3, then all patients whose FNA outcome has probability of being

positive > 0.3 are diagnosed with breast cancer. In the same example, all samples for which the

model predicts a score of  0.3 are classified as cancer-free.

Let xi be the feature vector of patient i and g(·) is the probability that patient i has breast

cancer. Then the class of i is defined as follows:



 

1,

if

g(xi) > ,

class(i) =

 

0,

otherwise.

Depending on the value of this threshold  , the ability of the algorithm to identify false positives and false negative cases varies. Higher values of  improve the specificity of the model, avoiding unnecessary alerts to healthy patients. On the other hand, lower values of  improve the sensitivity of the model, resulting in the timely warning of a higher number of cancer cases. Both measures are threshold dependent. Thus, we can formally define them as follows:
· Let   [0, 1] be the specificity of the ML model for a classification threshold  . The probability that a sick patient will be erroneously classified is then 1 -  .
· Let   [0, 1] be the sensitivity of the ML model for a classification threshold  . Thus, the probability that a healthy patient will be wrongly classified is 1 -  .
Taking all the above into consideration, the claim cost of a new patient that is diagnosed by the ML model is captured by the random variable S:

S = (1 -  )K + (1 -  )L.

(9)

Therefore, the expected value of the individual claim cost is equal to:

E(S) = (1 -  )µ + (1 -  )M.

(10)

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

13

The corresponding variance is  = (1 -  )2µ2 + (1 -  )2M 2 + 2(1 -  )(1 -  )µM (K, L). If we assume that N patients are expected to arrive at the hospital during the contract period, then the

total expected loss of the insurance is:

E(C) = N E(S) = N ((1 -  )µ + (1 -  )M ).

(11)

Case Study: Experimental Setup We perform a series of computational experiments in the case study of interest. The goal is to evaluate the effect of the model parameters on the risk appreciation framework. We fix the number of scenarios to J = 1000 and assume that N = 100 patients are served within the contract period. We hypothesized that the litigation cost variables K, L follow independent normal distributions. In this setting, we do not distinguish between different price segments, assuming that P = 1. We vary the values of µ, µ, M, M between the lower and upper ranges obtained from historic medical malpractice cases of breast cancer such as the ones presented in Section 2. We study the impact of the classification threshold  as well as the confidence level . We constrain the contract premium to $10,000 and $50,000. We quantify the effect of the  parameter in the robust optimization formulation. We use bootstrapping across 10 random seeds. We report the average performance across all iterations. The parameter ranges are detailed in Table 1.
The data was randomly split into training (75%) and testing sets (25%). Missing values in each partition were imputed using the MedImpute algorithm (Bertsimas et al. 2021). We use the Random Forests algorithm to train the binary classification models (Breiman 2001). We apply 10-fold crossvalidation to set the number of estimators and the maximum depth of the individual tree-based models. The average AUC of the final model on the testing set is 99.36%. The statistical analysis was conducted using Python 3.7 and Julia 1.3 (Pedregosa et al. 2011, Bezanson et al. 2017). The codebase for all of the experiments is available as a Github repository (Orfanoudaki 2021).

Bertsimas et al.: Pricing Algorithmic Insurance

14

Article submitted for publication

Parameter Range



3



0.9, 0.95, 0.99

lp

$10,000

Hp

$10,000, $50,000

µ

$100,000 $500,000

mu

$25,000, $150,000

M

$500,000, $1,000,000

M

$150,000, $400,000



0.01 - 0.75

J

1,000

Table 1

N

100

Parameter ranges for the computational experiments.

Case Study: The Implementation Framework

The proposed formulation enables decision makers to estimate for a given confidence level () and a

vector of historic claims (y): (i) the prices (x) for each product class (i.e., age groups, vehicle types);

(ii) the VaR (); (iii) the CVaR which corresponds to the objective function (min  + 

J j=1

zj

).

The input necessary to apply it involves:

· A binary classification model (e.g., image recognition classifier for mammograms) with a rep-

resentative testing set g(·);

· Random variables K, L that represent the litigation cost for false negative and false positive

cases with means µ, M , variances µ2, M 2 , and covariance Cov(K, L) respectively; · The number of patients that the algorithm will serve during the contract, N ;

· The number of past scenarios for the optimization formulation, J;

· Upper and lower bounds for the price, lp, Hp.

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

15

If past data from the implemented algorithm with prior cases of litigation claims were available,

we would use the historical observations. In the absence of such information, we use random variable

realizations to get the cost approximation of false positive and negative cases. Thus, the total cost

for scenario j of a fixed contract period for price segment p can be computed as follows:

N
ypj = (1 - p)Kpji + (1 - p)Lpji.
i=1

(12)

Algorithm 1 summarizes the proposed process that combines all the components of our approach.

Algorithm 1 Framework Implementation Procedure Output: prices (x), VaR (), CVaR

Input: , g(·), lp, Hp, K, L, J, N, Xtrain, Xtest

1: Train model g(·) using Xtrain

2: Get predicted probabilities for Xtest 3: while j  J do

4: while i  N do

5: Calculate scenario yj sampling from K, L for patient i.

6:

i=i+1

7: end while

8: j = j + 1

9: end while

10: Solve the optimization formulation

Case Study: The Effect of the Classification Threshold  The first question that we aim to answer is what is the effect of the classification threshold  on the estimated CVaR of the contract. In Figure 1 we depict two scenarios of a low and a high litigation claims distribution. The blue curve corresponds to µ = $100, 000, µ = $25, 000, M = $500, 000, M = $150, 000. The yellow curve corresponds to µ = $500, 000, µ = $150, 000, M = $1, 000, 000, M =

Bertsimas et al.: Pricing Algorithmic Insurance

16

Article submitted for publication

$450, 000. On the horizontal axis we project the threshold values and on the vertical axis the

CVaR. The findings of this analysis reveal that the most significant determinant of CVaR is the

selected classification threshold  . The expected costs for the false positive and false negative case

re-scale the CVaR function. Moreover, the effect of µ is more prominent for lower values of  that

negatively impact the specificity of the model. On the contrary, M gains more significance for

higher values of  . The average AUC of the binary classification models is 99.36% and thus for any

given threshold, the probability of a false negative and a false positive is very low. Notice that the

CVaR of both curves in Figure 1 is minimized for  = 0.3. This is due to the fact that when   0.3,

the model sensitivity on the testing set is equal to one. Therefore, for  = 0.3 the model specificity

is maximized for the best possible value of sensitivity. This analysis demonstrates that the selected

classification threshold  can dramatically affect the CVaR value even for fixed distributions of

litigation costs.

Figure 1 CVaR as a function of the  parameter for two different combinations of the K, L distributions.

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

17

(a) 3-Dimensional Illustration.

(b) 2-Dimensional Illustration

Figure 2

when M = $600K.
CVaR as a function of µ for  = 0.3 and  = 0.4.

(c) 2-Dimensional Illustration when µ = $500K.

Case Study: The Effect of the Claims Cost Expected Value The next question that we address relates to quantifying the impact of the means of the random variables K, L on the contract's risk exposure. Figure 2 provides three-dimensional and twodimensional illustrations of CVaR as we vary the expected values M and µ for   {0.3, 0.4}. In

Bertsimas et al.: Pricing Algorithmic Insurance

18

Article submitted for publication

these experiments, µ and M correspond to 20% of µ and M respectively. Figure 2a shows CVaR as a function of both M and µ. When  = 0.3, the model does not include any litigation cost

for false negative claims and CVaR is a linear function of the model specificity. This is evident

in Figures 2b-2c too. For a fixed value of µ, any increase or decrease of M does not affect the

contract's financial risk. On the other hand, as illustrated in Figures 2b-2c, when  = 0.4 both

model sensitivity and specificity affect the exposed risk of the contract in a linear fashion. In this

case, CVaR depends on the distribution of both K and L and thus it is a linear function of µ and

M . As we decrease the value of  below 0.3, the probability of a false positive claim is increasing

and as a result CVaR is also increasing. For example, when  = 0.25 the model specificity is 97.24%

while when  = 0.15 the specificity drops to 94.49%. These results highlight that CVaR is a linear

function of both M and µ.

Case Study: The Effect of Robust Optimization, the Premium and the Confidence Level  Subsequently, we investigate the role of the the premium, the type of the formulation, and the confidence level  in the determination of CVaR. We summarize our findings in Table 2. The premium value xp is set in the vast majority of the experiments by the upper bound Hp. Only in cases where both M and µ are below $50, 000, this constraint is not binding. Naturally, higher premium values result to lower VaR and CVaR for the contract. The  parameter also has a linear effect on the final risk estimation as it is incorporated as a scalar in the objective function of the formulation. In addition, the results in Table 2 reveal the benefit of the robust optimization approach. As we expected, the box uncertainty sets are more conservative than the polyhedral uncertainty approach. The latter yields very similar results to the nominal problem while also accounting for uncertainty in the scenarios y.
5. The Effect of Interpretability
In the effort to price the risk of algorithmic decision-making, interpretability may play a crucial role. In this section, we incorporate the degree of a ML model's transparency in the proposed

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

19

Premium Formulation  = 0.9  = 0.95  = 0.99

$ 10,000 box

$ 300,536 $ 302,959 $ 306,714

$ 10,000 nominal

$ 276,117 $ 278,071 $ 281,631

$ 10,000 polyhedral $ 279,611 $ 282,084 $ 285,251

$ 50,000 box

$ 260,536 $ 262,959 $ 266,714

$ 50,000 nominal

$ 236,117 $ 238,071 $ 241,631

Table 2

$ 50,000 polyhedral $ 239,611 $ 242,084 $ 245,251
Average CVaR as we vary the premium price, the type of formulation, and the confidence level . These results correspond to  = 0.3, µ = $100, 000, µ = $25, 000,  = 3.

pricing framework. We outline a class of functions that capture the impact of interpretability on algorithmic risk evaluation and showcase a practical application in the case study of medical liability.
Consequential decision-making up until recently has been strictly controlled by humans. In this setting, the outcome of any decision can be associated with reasoning that would justify the action. Thus, a human decision can be evaluated based on the logic followed and, subsequently, the decision agent can be held accountable for their judgement. Supervised learning algorithms do not necessarily provide a reason why a given observation should receive a specific label. They can only state that certain inputs are correlated with that label. As a result, interpretability has remained an ill-defined term of ML (Lipton 2018).
In the context of algorithmic liability, one could argue that the interpretability of a model is a measure of how much human input could be involved in the risk estimation process. We will focus on the setting of complete automation where human input is possible only prior to the model implementation in practice. In this context, experts may be called to review and approve the algorithm prior to its integration to avoid erroneous decision rules in the learner. Consider the case of a fully interpretable, tree-based model for malignant tumor detection. The physician in charge can easily review the algorithm's recommendations based on their own knowledge and experience

Bertsimas et al.: Pricing Algorithmic Insurance

20

Article submitted for publication

prior to its implementation. The level of algorithmic transparency directly affects the degree to

which human judgement can be involved. Interpretable models allow for synergies between the ML

algorithm and the experts' input. Therefore, we argue that the combination of artificial and human

intelligence is likely to lead to more accurate estimations and may improve the risk exposure of

the contract.

Our goal is to quantify this effect and provide measures of how interpretability can impact

algorithmic risk evaluation. Suppose that ch is the risk exposure for an insurance contract when a human expert is making all the decisions. Notice that ch is known from historical claims. cml is the risk exposure for the same contract when a ML model is the sole decision maker. We assume

that ch > cml to ensure that there are financial incentives from the use of the ML model. We let   [0, 1] be the interpretability parameter that measures the degree of algorithmic transparency

and assume that a model's risk exposure c() is a function of the interpretability parameter.

When  = 0, the ML model is treated as a "black-box" and thus a human agent is unable to

provide additional input that may improve the model's performance (c(0) = cml). To the contrary, when  = 1, the model is intuitive and explainable for the decision maker and as a result there

are synergies between the ML model and the human agent, resulting in a lower cost c(1) = cml,   (0, 1).

The determination of the  parameter depends on the ML model, the application and the problem

under consideration. We assume that the relative benefit of interpretability directly depends on the

relative

ratio

of

cml ch



(0, 1).

The

latter

ratio

captures

the

relative

improvement

of

a

ML

model

over

human judgement in economic terms. In cases where the edge of algorithmic decision making is

small (cml  ch), the value of interpretability is high, since an expert's opinion can yield equivalent results to an algorithm. In this setting, the synergies between the decision maker and the machine

are stronger, correspondingly decreasing the expected risk exposure. On the other hand, when ch

is significantly higher than cml, interpretability gains less importance as human input might not

be

as

informative.

Based

on

these

assumptions,

a

potential

value

for



is

(1 -

cml ch

),

capturing

the

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

21

synergies between the two types of decision makers. It follows that when  = 1, the cost is equal to

c

=

cml(1

-

cml ch

).

If

we

model

the

contractual

risk

exposure

c

for

all

values

of





(0,

1)

as

the

linear

interpolation

of

these

two

scenarios

(see

Figure

3),

then

c

=

- c2ml ch



+

cml.

Figure 3

The

linear

interpolation

of

the

c

function

for





[0, 1]

when



=

(1 -

cml ch

).

However, interpretability does not necessarily have a linear effect on risk exposure and model performance. One can hypothesize that the effect of interpretability on the cost is non-linear. If c is concave function, the positive effect of interpretability on the risk exposure is more prominent for higher values of . To the contrary, if we assume that c is convex, even with small degrees of interpretability, we can observe significant reductions in the expected risk. Though it remains challenging to fully characterize the interpretability effect, our approach provides flexible options to decision makers to measure its impact as a function of the  parameter.
Identifying a single value for this parameter and determining a specific definition or degree of interpretability has been a major challenge in the ML field (Carvalho et al. 2019). Most definitions involve human input in the evaluation process which impedes systematic quantitative analysis (Lipton 2016). Bertsimas et al. (2019) have recently introduced a quantitative approach to specify the price of interpretability as the tradeoff with predictive accuracy for a given model. Alternative approaches that could be directly incorporated in the pricing framework include the work of Schmidt and Biessmann (2019) and Ribeiro et al. (2016). We expect that an increasing number

Bertsimas et al.: Pricing Algorithmic Insurance

22

Article submitted for publication

of interpretability definitions will be available in the future considering the importance of understanding a model's proposed associations between the input variables and the output labels.

Case Study: The Effect of Interpretability

In Figure 4, we provide concrete examples of functions that model the effect of interpretability in

the risk estimation process for the case study of medical liability. On the horizontal axis we project

the  parameter and on the vertical axis the CVaR. Each graph corresponds to a different function c,

including

concave,

convex,

and

linear

examples.

In

this

setting,

we

assume

that



=

(1

-

cml ch

),

cml

=

$500K, and consider four distinct scenarios of ch. Notice when c is convex, such as in Figures 4b

and 4d, even with low degrees interpretability, we can derive effective synergies between the model

and the human agent that can significantly reduce the risk exposure. Respectively, when modeling

the effect of interpretability with a concave function, like the ones presented in Figures 4a,4c, the

majority of the risk reductions will only be observed for higher values of . This intuition can

guide the decision for the determination of the interpretability function in future applications of

the framework.

6. The Effect of Model Generalizability

In this section, the goal is to quantify the effect of algorithmic generalizability on the pricing framework. We propose the generation of synthetic data using GANs to measure the impact on the performance of the ML model and apply our approach in the case study of interest.
Generalizability refers to a model's ability to properly adapt to new, previously unseen data, drawn from the same or a different distribution as the one used to create the model. In the context of algorithmic insurance, generalizability becomes pertinent when the model is applied to a new population whose data have not been tested by the algorithm in the past. Going back to the case study of interest, let the binary classification model for malignant tumor detection be exclusively trained on samples drawn from a Caucasian population at an academic hospital in Massachusetts. Suppose that a community hospital in Louisiana is now interested to integrate the system in its

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

23

(a)

c

=

-

c2ml ch

(tan(

 4

))

+

cml

.

(b)

c

=

-

c2ml ch

(sin(

 2

))

+

cml

.

(c)

c

=

-

c2ml ch

2

+

cml.

(d)

c

=

-

c2ml ch

 

+ cml.

Figure 4

(e)

c

=

-

c2ml ch



+ cml.

Risk Exposure c as a function of the interpretability parameter  and risk exposure ch for a fixed value

of cml = $500K.

electronic health records database which started collecting medical data only one year ago. What is the appropriate pricing strategy for this center? If the hospital had at its disposal data from the patient population it serves throughout a span of multiple years, we would directly be able to externally validate its performance. However, in the absence of this valuable resource, an alternative approach is needed to adjust the pricing strategy of the contract.
We propose testing the predictive performance of the algorithm on synthetic observations that resemble the original training set, controlling the degree of similarity to get estimations of risk variability. Multiple approaches have been proposed in the literature to generate synthetic data. A

Bertsimas et al.: Pricing Algorithmic Insurance

24

Article submitted for publication

quite common approach is to induce noise with Gaussian random variables in the existing dataset. Nevertheless, this simple technique directly affects the existing correlations and associates between the covariates distorting the true geometry of the feature space. Another well established technique for data augmentation is referred to as the Synthetic Minority Oversampling Technique (SMOTE) which is very frequently applied in classification datasets that have a severe class imbalance (Chawla et al. 2002). However, this approach does not let the user directly control the degree of similarity between the newly created instances and the original data distribution.
The proposed framework requires the use of parameters that effectively control the degree of similarity between the real and the synthetic data. Our objective is to introduce a mechanism that would allow decision makers to quantitatively compare the additional cost of the insurance contract with respect to the ability of the model to generalize to datasets with different levels of variability from the original training and testing sets. Though it is not possible to provide theoretical guarantees about the predictive performance of a given classifier in a new unknown distribution, we can conduct extensive simulations that test the discrimination capability of the learner in adverse scenarios.

Generative Adversarial Networks to Generate Synthetic Data To perform this analysis we resort to GANs. This neural network architecture was first introduced in 2014 with the goal of synthesizing artificial images that are indistinguishable from authentic figures (Goodfellow et al. 2014). Since then, GANs have become the predominant method of data augmentation for images and text (Wang et al. 2017). They are used to increase the amount of data by adding slightly modified copies of already existing samples or newly created synthetic data from existing observations (Radford et al. 2015, Goodfellow 2017, Zhang et al. 2017).
GANs involve a unique architecture in which a pair of networks are trained simultaneously and in competition with each other. Training a robust GAN architecture is a non-trivial task due to problems like vanishing gradients and mode-collapse which may result in poor discrimination performance and synthetic samples with limited diversity (Radford et al. 2015, Salimans et al.

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

25

2016). The Wasserstein GANs (WGAN) architecture was introduced to remedy these issues using

the Wasserstein distance as the loss function (Arjovsky et al. 2017). The Conditional GAN (CGAN)

is a specific class of GANs that involves the conditional generation of images by a generator model,

resulting in new data observations with associated class labels (Mirza and Osindero 2014). This

modification to the GAN architecture permits learning the distributions specific to each class label,

producing samples for both labels with higher quality.

Recently, researchers showed that WCGANs can lead to very promising results in synthesizing

tabular data, comprising only densely connected layers (McKeever and Singh Walia 2020, Somorjit

and Verma 2020). These efforts highlighted the potential impact that GANs may have in structured

data sources, providing researchers with higher flexibility and control in the data generation process.

This technique also offers a promising alternative to solve the problem of interest; creating synthetic

data while explicitly controlling the degree of similarity. By varying the number of epochs, we

will control the differences in the distributions between the synthetic and the real-world data.

This parameter constitutes the number of complete passes through the training process. A higher

number of epochs gives the opportunity to the algorithm to converge, minimizing the loss function.

Thus, we can directly compare the discriminator loss function to the number of epochs, adjusting

the degree of dissimilarity between the synthetic samples and the real training set.

Due to their complicated structure and despite large strides in terms of theoretical progress,

evaluating and comparing GANs remains a challenging task. While several metrics have been

proposed, there is no consensus in the scientific community as to which measure provides a more

holistic and objective model evaluation (Alqahtani et al. 2019, Borji 2019). We propose the use of

the GAN quality index (GQI) for our analysis (Ye et al. 2018). To compute this metric, we will

compare the performance of the generator G and the model we are seeking to price Creal. First,

we generate the synthetic samples with the associated class labels using the CGAN architecture.

A second classifier, called the GAN-induced classifier CGAN is trained on the generated data. The

GQI is defined as the ratio of the accuracies (or AUCs) of the two classifiers when applied to the

real test data:

GQI = ACC(CGAN) . AC C (CREAL )

Bertsimas et al.: Pricing Algorithmic Insurance

26

Article submitted for publication

Higher GQI means that the GAN distribution better matches the real data distribution.

Case Study: The Effect of Generalizability We apply the proposed approach to the case study of medical liability using a GAN architecture. The goal is to investigate the effect of generalizability on the contract's risk exposure using synthetic samples while controlling the degree of similarity to the original dataset. The GAN network was built leveraging the GAN-Sandbox package and was implemented in Python using the Keras library with a Tensorflow backend (Dietz 2017, Chollet et al. 2015, Abadi et al. 2016).

(a) Number of Epochs = 0. (b) Number of Epochs = 20. (c) Number of Epochs = 40.

(d) Number of Epochs = 60. (e) Number of Epochs = 150.

(f) Real Data.

Figure 5 The derived distributions from the GAN model of two of the most predictive features. Cell Shape

Uniformity is depicted on the vertical axis and Clump Thickness is illustrated on the horizontal axis.

All values have been normalized to [0,1]. Each graph corresponds to the output of the GAN model for

a given number of epochs. Figure 5f corresponds to the real distribution of the features.

In Figure 5, we present the changes in the features' distribution as a function of the number of epochs parameter in a WCGAN architecture. Following the architecture presented by VegaM´arquez et al. (2019), the GAN model comprises a generator network with one input layer and three dense layers and an adversarial network with one input layer and four dense layers. We

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

27

measure the similarity of the derived distributions between the synthetic (GAN-Generated) and the real data for a different number of epochs in the training process. An epoch is defined as one cycle through the training process of the network, corresponding to the number of training iterations between the generator and the adversarial network. The hypothesis in Section 6 is validated, as we observe that a higher number of epochs results in features distributions that better resemble the real data distribution (Figure 5). This effect is directly present in quantitative metrics, such as the GQI index, which is also positively correlated with the number of epochs in the model.
In Figure 6, we project CVaR as a function of the number of epochs parameter. The underlying binary classification model is the same as the one used in Figure 1 where µ = $100, 000, µ = $25, 000, M = $500, 000, M = $150, 000, derived on the training sample of the original Breast Cancer Wisconsin Diagnostic dataset. The CVaR is then measured with respect to the discrimination performance of the classifier on the GAN-Generated synthetic data. The output of CGAN architectures includes both independent features and associated labels that are subsequently used to compute the sensitivity and specificity of the model for different values of  . In Figure 6, we only project the best CVaR value across all potential thresholds  . This graph reveals a linear relationship between the number of epochs and the CVaR. This finding highlights to decision makers the cost effect of applying a pre-trained learner in datasets with varied degrees of distribution similarity to the original training population.
7. Discussion

In this paper, we construct a framework for pricing algorithmic risk and provide a comprehensive case study for its implementation. Our work constitutes the first attempt to quantify the litigation risk resulting from erroneous algorithmic decision-making in the context of binary classification models. The framework is agnostic to the type of learner and application area. It can be easily extended in other fields, such as predictive maintenance and autonomous vehicles among others. The proposed models are data-driven and parametric, since such contracts have not been implemented by the industry yet and extensive experimentation is needed prior to launching them.

Bertsimas et al.: Pricing Algorithmic Insurance

28

Article submitted for publication

Figure 6

CVaR as a function of the number of epochs parameter. The color indicates the GQI metric for the underlying binary classification model.

Classification Threshold  : Our work reveals that, given fixed distributions for litigation costs, the choice of the classification threshold  plays the most significant role in the determination of the contract's financial risk. This finding provides decision makers with a new way of assessing the balance between sensitivity and specificity. The direct association of risk exposure to the threshold  leads to more informed decisions regarding the financial implementation of a classifier in practice. Our findings validate the assumption that when a false positive and a false negative have disproportionate implications for the organization the choice of the  threshold becomes even more critical.
Interpretability: The proposed framework incorporates the critical aspect of model interpretability. We argue that in cases where the risk of human decision making is comparable to algorithm-driven decision rules, interpretability gains greater value. We also show that the convexity of the interpretability function indicates whether a smaller or a higher degree of model transparency is needed to achieve significant synergies between human agents and the ML algorithm.

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

29

Generalizability: We consider the use of GANs to evaluate the effect of model generalizability in the risk evaluation process. We illustrate a linear relationship between CVaR and the number of training epochs of the GAN network. The latter is also positively correlated with similarity metrics between the generated and the true data distribution. Thus, we allow decision makers to adjust the contract pricing to settings where the classifier is applied to a new population that was not part of the original training and validation set.
Limitations: Central to the limitations of this study is the absence of historic claims records from real-world litigation cases of malpractice. We assume that insurance companies have in their possession this kind of information from which the scenarios y could be directly constructed. Our analysis takes a conservative view over the litigation process assuming that every erroneously classified sample will resort to a litigation claim. In reality, only a portion of misdiagnosed patients file a malpractice lawsuit and only a subset of those are successful. In this paper, the computational experiments have been based on normally distributed random variables but other distributions could also be explored in future investigations. We would also like to note that medical malpractice is a particularly challenging field and the implementation of ML models such as the one in Section 2 faces a lot of regulation constraints. As a result, it is very likely that such models will continue to be validated by medical experts in the coming years. Finally, this work does not account for dynamic decision-making processes, such as the triple FNA strategy, that usually results in improved clinical outcomes for the patients and significantly reduces the amount of claims (Anderson and Troxel 2005).
8. Conclusions

Our work aims to set the foundations in the novel area of algorithmic insurance. We propose quantitative tools that allow decision makers, modelers, and insurance companies to estimate the litigation risk of binary classification models. This approach takes into consideration the predictive performance of the classifier accounting also for uncertainty in the data. We incorporate measures of interpretability and generalizability to provide a holistic appreciation of the model. We believe

Bertsimas et al.: Pricing Algorithmic Insurance

30

Article submitted for publication

that this framework can serve as the basis of a new research area that will expedite the adoption

and implementation of ML models in practice.

Acknowledgments
The authors would like to thank Dr. Luca Marighetti for insightful discussions regarding algorithmic insurance.
References
Abadi M, Agarwal A, Barham P, Brevdo E, Chen Z, Citro C, Corrado GS, Davis A, Dean J, Devin M, et al. (2016) Tensorflow: Large-scale machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467 .
Alqahtani H, Kavakli-Thorne M, Kumar G, SBSSTC F (2019) An analysis of evaluation metrics of gans. International Conference on Information Technology and Applications (ICITA).
Anderson RE, Troxel DB (2005) Breast cancer litigation. Medical Malpractice, 153­166 (Springer). Arjovsky M, Chintala S, Bottou L (2017) Wasserstein generative adversarial networks. International confer-
ence on machine learning, 214­223 (PMLR). Artzner P, Delbaen F, Eber JM, Heath D (1999) Coherent measures of risk. Mathematical finance 9(3):203­
228. Ben-Tal A, Nemirovski A (2000) Robust solutions of linear programming problems contaminated with uncer-
tain data. Mathematical programming 88(3):411­424. Berry DA, Cronin KA, Plevritis SK, Fryback DG, Clarke L, Zelen M, Mandelblatt JS, Yakovlev AY, Habbema
JDF, Feuer EJ (2005) Effect of screening and adjuvant therapy on mortality from breast cancer. New England Journal of Medicine 353(17):1784­1792. Bertolini A (2013) Robots as products: the case for a realistic analysis of robotic applications and liability rules. Law, innovation and technology 5(2):214­247. Bertolini A, Salvini P, Pagliai T, Morachioli A, Acerbi G, Cavallo F, Turchetti G, Dario P (2016) On robots and insurance. International Journal of Social Robotics 8(3):381­391.

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

31

Bertsimas D, Delarue A, Jaillet P, Martin S (2019) The price of interpretability. arXiv preprint arXiv:1907.03419 .

Bertsimas D, den Hertog D (2021) Robust and Adaptive Optimization (Dynamic Ideas LLC).

Bertsimas D, Lauprete GJ, Samarov A (2004) Shortfall as a risk measure: properties, optimization and applications. Journal of Economic Dynamics and control 28(7):1353­1381.

Bertsimas D, Orfanoudaki A, Pawlowski C (2021) Imputation of clinical covariates in time series. Machine Learning 110(1):185­248.

Bertsimas D, Sim M (2004) The price of robustness. Operations research 52(1):35­53.

Bezanson J, Edelman A, Karpinski S, Shah VB (2017) Julia: A fresh approach to numerical computing. SIAM review 59(1):65­98, URL https://doi.org/10.1137/141000671.

Borji A (2019) Pros and cons of gan evaluation measures. Computer Vision and Image Understanding 179:41­65.

Breiman L (2001) Random forests. Machine Learning 45(1):5­32.

Carvalho DV, Pereira EM, Cardoso JS (2019) Machine learning interpretability: A survey on methods and metrics. Electronics 8(8):832.

Char DS, Shah NH, Magnus D (2018) Implementing machine learning in health care--addressing ethical challenges. The New England journal of medicine 378(11):981.

Chawla NV, Bowyer KW, Hall LO, Kegelmeyer WP (2002) Smote: Synthetic minority over-sampling technique. Journal of Artificial Intelligence Research 16:321­357, ISSN 1076-9757, URL http://dx.doi. org/10.1613/jair.953.

Chollet F, et al. (2015) Keras. URL https://github.com/fchollet/keras.

Coglianese C, Lehr D (2016) Regulating by robot: Administrative decision making in the machine-learning era. Geo. LJ 105:1147.

Cummins JD (1990) Asset pricing models and insurance ratemaking. ASTIN Bulletin: The Journal of the IAA 20(2):125­166.

Bertsimas et al.: Pricing Algorithmic Insurance

32

Article submitted for publication

Dietvorst BJ, Simmons JP, Massey C (2015) Algorithm aversion: People erroneously avoid algorithms after seeing them err. Journal of Experimental Psychology: General 144(1):114.

Dietvorst BJ, Simmons JP, Massey C (2018) Overcoming algorithm aversion: People will use imperfect algorithms if they can (even slightly) modify them. Management Science 64(3):1155­1170.

Dietz M (2017) Gan-sandbox. URL https://github.com/mjdietzx/GAN-Sandbox.

Dua D, Graff C (2017) UCI machine learning repository. URL http://archive.ics.uci.edu/ml.

Embrechts P (2000) Actuarial versus financial pricing of insurance. The Journal of Risk Finance .

Gismondi&Associates (2012) Unnecessary mastectomy performed due to misdiagnosis -- the law offices of gismondi & associates. URL https://www.gislaw.com/2012/11/ unnecessary-mastectomy-performed-due-to-misdiagnosis/, (Accessed on 03/12/2021).

Goodfellow I (2017) Nips 2016 tutorial: Generative adversarial networks.

Goodfellow IJ, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, Courville A, Bengio Y (2014) Generative adversarial networks. arXiv preprint arXiv:1406.2661 .

Jorion P (2000) Value at risk (McGraw-Hill Professional Publishing).

Kim HE, Kim HH, Han BK, Kim KH, Han K, Nam H, Lee EH, Kim EK (2020) Changes in cancer detection and false-positive recall in mammography using artificial intelligence: a retrospective, multireader study. The Lancet Digital Health 2(3):e138­e148, ISSN 2589-7500, URL http://dx.doi.org/https://doi. org/10.1016/S2589-7500(20)30003-0.

Le MT, Mothersill CE, Seymour CB, McNeill FE (2016) Is the false-positive rate in mammography in north america too high? The British journal of radiology 89(1065):20160045.

Lee MV, Konstantinoff K, Gegios A, Miles K, Appleton C, Hui D (2020) Breast cancer malpractice litigation: A 10-year analysis and update in trends. Clinical imaging 60(1):26­32.

Lipton ZC (2016) The mythos of model interpretability. arXiv preprint arXiv:1606.03490 .

Lipton ZC (2018) The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery. Queue 16(3):31­57.

Markowitz HM (2010) Portfolio theory: as i still see it. Annu. Rev. Financ. Econ. 2(1):1­23.

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

33

McKeever S, Singh Walia M (2020) Synthesising Tabular Datasets Using Wasserstein Conditional GANS with Gradient Penalty (WCGAN-GP) (Technological University Dublin).

McNeil AJ, Frey R, Embrechts P (2015) Quantitative risk management: concepts, techniques and tools-revised edition (Princeton university press).

Mirza M, Osindero S (2014) Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784 .

Orfanoudaki A (2021) Algorithmicinsurance. URL https://github.com/agniorf/AlgorithmicInsurance.

Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, Blondel M, Prettenhofer P, Weiss R, Dubourg V, et al. (2011) Scikit-learn: Machine learning in python. the Journal of machine Learning research 12:2825­2830.

Radford A, Metz L, Chintala S (2015) Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434 .

Reed C, Kennedy E, Silva S (2016) Responsibility, autonomy and accountability: legal liability for machine learning. Queen Mary School of Law Legal Studies Research Paper (243).

Ribeiro MT, Singh S, Guestrin C (2016) Model-agnostic interpretability of machine learning. arXiv preprint arXiv:1606.05386 .

Rockafellar RT, Uryasev S (2000) Optimization of conditional value-at-risk. Journal of risk 2:21­42.

Rosen&Perry () Patient Undergoes Unnecessary Mastectomy after Being Misdiagnosed with Breast Cancer -- Pittsburgh Medical Malpractice Settlements -- Rosen & Perry. URL https://www.caringlawyers.com/verdicts-settlements/ patient-undergoes-unnecessary-mastectomy-after-being-misdiagnosed-with-breast-cancer/, (Accessed on 03/12/2021).

Salimans T, Goodfellow I, Zaremba W, Cheung V, Radford A, Chen X (2016) Improved techniques for training gans. arXiv preprint arXiv:1606.03498 .

Schmidt P, Biessmann F (2019) Quantifying interpretability and trust in machine learning systems. arXiv preprint arXiv:1901.08558 .

SEER (2020) Female breast cancer -- cancer stat facts. URL https://seer.cancer.gov/statfacts/html/ breast.html, (Accessed on 03/12/2021).

Bertsimas et al.: Pricing Algorithmic Insurance

34

Article submitted for publication

Senn M (1930) Road Traffic Act 1930. URL http://www.legislation.gov.uk.

Siegel RL, Miller KD, Jemal A (2018) Cancer statistics, 2018. CA: A Cancer Journal for Clinicians 68(1):7­ 30, URL http://dx.doi.org/https://doi.org/10.3322/caac.21442.

Singh J, Walden I, Crowcroft J, Bacon J (2016) Responsibility & machine learning: Part of a process. Available at SSRN 2860048 .

Somorjit L, Verma M (2020) Variants of generative adversarial networks for credit card fraud detection. International Conference on Computational Intelligence, Security and Internet of Things, 133­143 (Springer).

Street WN, Wolberg WH, Mangasarian OL (1993) Nuclear feature extraction for breast tumor diagnosis. Biomedical image processing and biomedical visualization, volume 1905, 861­870 (International Society for Optics and Photonics).

Uryasev S (1995) Derivatives of probability functions and some applications. Annals of Operations Research 56(1):287­311.

Uryasev S (2000) Conditional value-at-risk: Optimization algorithms and applications. Proceedings of the IEEE/IAFE/INFORMS 2000 Conference on Computational Intelligence for Financial Engineering (CIFEr)(Cat. No. 00TH8520), 49­57 (IEEE).

Vega-M´arquez B, Rubio-Escudero C, Riquelme JC, Nepomuceno-Chamorro I (2019) Creation of synthetic data with conditional generative adversarial networks. International Workshop on Soft Computing Models in Industrial and Environmental Applications, 231­240 (Springer).

Wang J, Perez L, et al. (2017) The effectiveness of data augmentation in image classification using deep learning. Convolutional Neural Networks Vis. Recognit 11.

Whang JS, Baker SR, Patel R, Luk L, Castro III A (2013) The causes of medical malpractice suits against radiologists in the united states. Radiology 266(2):548­554.

Yala A, Lehman C, Schuster T, Portnoi T, Barzilay R (2019) A deep learning mammography-based model for improved breast cancer risk prediction. Radiology 292(1):60­66.

Ye Y, Wang L, Wu Y, Chen Y, Tian Y, Liu Z, Zhang Z (2018) Gan quality index (GQI) by gan-induced classifier.

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

35

Zhang H, Xu T, Li H, Zhang S, Wang X, Huang X, Metaxas D (2017) Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks.

36
Appendix

Bertsimas et al.: Pricing Algorithmic Insurance Article submitted for publication

A. Background for the Simultaneous Minimization of CVaR and Calculation of VaR

Following the notation proposed by Uryasev (2000), we let: · p(y) the probability density function of y; · (x, ) the probability that the loss function f (x, y) does not exceed some threshold value ; · (x, ) the VaR function; the percentile of the loss distribution with confidence level . Based
on this definition, (x, (x, )) = . · (x) is the CVaR or the conditional expected loss defined as:

(x) = (1 - )-1

f (x, y)p(y)dy.

f (x,y)>(x,)

(13)

Equation (13) is complex due to the (x, ) function involved in its definition. For this reason,

the authors of Uryasev (2000) introduce a simpler function:

F(x, ) =  + (1 - )-1

(f (x, y) - )p(y)dy,

(14)

f (x,y)>

which can be used instead of CVaR. By minimizing this function w.r.t  we can directly derive

CVaR.

(x) = F(x, (x, )) = minF(x, ).

(15)

It also follows that F(x, ) is convex w.r.t.  and that its minimum point is the VaR measure. This finding allows us to leverage the function F(x, ) for optimizing CVaR and simultaneously calculating VaR (Uryasev 2000):

minxX(x) = minxX,F(x, ).

(16)

In this way, we can optimize CVaR and find VaR in tandem. Under general conditions (see (Uryasev 1995)) and if X is also convex, this problem is equivalent to solving a smooth convex optimization problem.

Bertsimas et al.: Pricing Algorithmic Insurance

Article submitted for publication

37

B. Robust Formulations

Box Uncertainty with -Robustness. First, we investigate the problem of maxyU1 wpj + xp  ypj. That is equivalent to

max

ypj

subject to µpj - pjpj  ypj, j  [J ], p  [P ],

ypj  µpj + pjpj, j  [J ], p  [P ],

(17)

max p,j  , p,j
p,j  0,

j  [J], p  [P ], j  [J], p  [P ].

Notice that the maximum of pj is less than  if and only if all pj are less than . To maximize over ypj, we set all ypj to their upper bound ypj = µpj + pjpj. Hence, the robust counterpart for this uncertainty set is:

J
minimize  +  zj
j=1 P
subject to zj  wpj - ,
p=1

j  [J],

zj  0,

j  [J],

(18)

wpj  0,

j  [J], p  [P ],

wpj + xp  µpj + pjpj, j  [J ], p  [P ],

lp  xp  Hp

p  [P ].

Polyhedral Uncertainty with -Robustness. In this setting, we study the problem of maxyU2 wpj + xp  ypj. That is equivalent to the formulation:

Bertsimas et al.: Pricing Algorithmic Insurance

38

Article submitted for publication

max

ypj

subject to µpj - pjpj  ypj, j  [J ], p  [P ],

ypj  µpj + pjpj, j  [J ], p  [P ],

(19)

p,j = ,
p,j
p,j  0,

j  [J], p  [P ].

In order to define the robust counterpart, we need to look at the dual of Equation (19).

min

µpj qpj - µpj spj + r

subject to qpj - spj = 1,

j  [J], p  [P ],

-pjqpj - pjspj + r  0, j  [J ], p  [P ], (20)

qp,j  0,

j  [J], p  [P ],

sp,j  0,

j  [J], p  [P ],

r  0.

Due to strong duality, the solution to this problem can be used to derive the robust counterpart.

Bertsimas et al.: Pricing Algorithmic Insurance Article submitted for publication

J
minimize  +  zj
j=1 P
subject to zj  wpj - ,
p=1
zj  0,

j  [J], j  [J],

wpj  0,

j  [J], p  [P ],

wpj + xp  µpjqpj - µpjspj + r, j  [J ], p  [P ],

qpj - spj = 1,

j  [J], p  [P ],

-pjqpj - pjspj + r  0, qp,j  0, sp,j  0,

j  [J], p  [P ], j  [J], p  [P ], j  [J], p  [P ],

r0

lp  xp  Hp

p  [P ].

39 (21)

