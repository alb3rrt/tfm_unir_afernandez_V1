
# Evaluating Word Embeddings with Categorical Modularity

[arXiv](https://arxiv.org/abs/2106.0877), [PDF](https://arxiv.org/pdf/2106.0877.pdf)

## Authors

- Sílvia Casacuberta
- Karina Halevy
- Damián E. Blasi

## Abstract

We introduce categorical modularity, a novel low-resource intrinsic metric to evaluate word embedding quality. Categorical modularity is a graph modularity metric based on the $k$-nearest neighbor graph constructed with embedding vectors of words from a fixed set of semantic categories, in which the goal is to measure the proportion of words that have nearest neighbors within the same categories. We use a core set of 500 words belonging to 59 neurobiologically motivated semantic categories in 29 languages and analyze three word embedding models per language (FastText, MUSE, and subs2vec). We find moderate to strong positive correlations between categorical modularity and performance on the monolingual tasks of sentiment analysis and word similarity calculation and on the cross-lingual task of bilingual lexicon induction both to and from English. Overall, we suggest that categorical modularity provides non-trivial predictive information about downstream task performance, with breakdowns of correlations by model suggesting some meta-predictive properties about semantic information loss as well.

## Comments

Accepted to Findings of ACL 2021 (Long Paper)

## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{casacuberta2021evaluating,
      title={Evaluating Word Embeddings with Categorical Modularity}, 
      author={Sílvia Casacuberta and Karina Halevy and Damián E. Blasi},
      year={2021},
      eprint={2106.00877},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

## Notes

Type your reading notes here...

