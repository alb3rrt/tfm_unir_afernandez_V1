arXiv:2106.01588v1 [cs.GT] 3 Jun 2021

Resource-Aware Cost-Sharing Mechanisms with Priors
Vasilis Gkatzelis1, Emmanouil Pountourakis1, and Alkmini Sgouritsa2
1Drexel University 2University of Liverpool
Abstract
In a decentralized system with m machines, we study the selfish scheduling problem where each user strategically chooses which machine to use. Each machine incurs a cost, which is a function of the total load assigned to it, and some cost-sharing mechanism distributes this cost among the machine's users. The users choose a machine aiming to minimize their own share of the cost, so the cost-sharing mechanism induces a game among them. We approach this problem from the perspective of a designer who can select which cost-sharing mechanism to use, aiming to minimize the price of anarchy (PoA) of the induced games.
Recent work introduced the class of resource-aware cost-sharing mechanisms, whose decisions can depend on the set of machines in the system, but are oblivious to the total number of users. These mechanisms can guarantee low PoA bounds for instances where the cost functions of the machines are all convex or concave, but can suffer from very high PoA for cost functions that deviate from these families.
In this paper we show that if we enhance the class of resource-aware mechanisms with some prior information regarding the users, then they can achieve low PoA for a much more general family of cost functions. We first show that, as long as the mechanism knows just two of the participating users, then it can assign special roles to them and ensure a constant PoA. We then extend this idea to settings where the mechanism has access to the probability with which each user is present in the system. For all these instances, we provide a mechanism that achieves an expected PoA that is logarithmic in the expected number of users.
1 Introduction
In this paper we revisit a classic selfish scheduling problem: in a large decentralized system with a set M of machines and a set N of registered users, each day some subset of these users enter the system seeking to process some task. Each user assigns their task to one of the machines, generating a cost that depends on the machine's total load, and the cost of each machine is then charged to its users, through some cost-sharing mechanism. The users' goal is to minimize their own share of the cost, so they strategically assign their task to the machine that would yield the smallest cost share. However, their cost share depends on the congestion of each machine, and thus on the strategic choices of all the other users currently in the system, giving rise to a game.
The need to better understand these games and to evaluate the efficiency of their outcomes lies at the heart of Algorithmic Game Theory, and some of the first seminal papers in this literature analyzed the price of anarchy (PoA) of such games, i.e., the extent to which the performance of their Nash equilibria approximates the optimal performance. Much of this work, e.g., in congestion games and network formation games, assumed that the users share the cost equally, in accordance with the Shapley value cost-sharing mechanism
gkatz@drexel.edu manolis@drexel.edu alkmini@liv.ac.uk
1

(e,g., see Chapters 18 and 19, respectively, from Nisan et al. [2007]). However, it soon became clear that the

equal-sharing policy can lead to highly inefficient outcomes, even in very simple instances Anshelevich et al.

[2008]. As a result, subsequent work focused on the design of alternative, more sophisticated, cost-sharing

mechanisms, with the goal of reducing the PoA.

The first to study the extent to which a designer can reduce the PoA using improved cost-sharing

mechanisms were Chen et al. [2010]. One of their main goals was to analyze mechanisms that are stable

(i.e., guarantee the existence of pure Nash equilibria in the games they induce) and decentralized (i.e., have

limited information regarding the overall state of the system). Taking the need for decentralization to an

extreme, they focused on the class of oblivious cost-sharing mechanisms1, which decide how to share the

cost of each machine among its users without using any information regarding the set of other users or

machines that are present in the system. After providing a precise characterization of stable mechanisms

for network formation games (where the resources that the agents use have constant cost-functions), they

systematically analyzed their performance. Building on this work, von Falkenhausen and Harks [2013] and

then Christodoulou et al. [2017] considered more general classes of cost functions. Among other results,

von Falkenhausen and Harks [2013] showed that no oblivious cost-sharing mechanism can guarantee a PoA

bound better than linear function in the number of agents, even for instances with concave cost functions.

Motivated by this limitation of oblivious mechanisms, subsequent work introduced the model of resource-

aware mechanisms Christodoulou and Sgouritsa [2019], Christodoulou et al. [2017]. Compared to oblivious

mechanisms, resource-aware ones are more informed: their decision regarding how to share the cost of a

machine can also depend on the set of other machines that are available in the system. Using this additional

information, Christodoulou et al. [2017] managed to overcome the limitations of oblivious mechanisms and

design resource-aware mechanisms that achieve a constant PoA for convex and concave cost functions. On

the negative side, they showed that there resource-aware cost-sharing mechanism can

exists a achieve

class of seemingly a PoA better than

Osi(mpnl)e.

cost

functions

for

which

no

These negative results suggest that it may be impossible for resource-aware mechanisms to achieve a

constant PoA for interesting cost functions beyond convex and concave. However, although resource-aware

mechanisms are more informed than oblivious ones, they are still severely limited in terms of what they

know about the users in the system. In this paper we enhance resource-aware mechanisms with some prior

information regarding the users in the system, and we show that this is sufficient for us to design cost-sharing

mechanisms that achieve low PoA for a very broad class of cost functions.

1.1 Our Results
Our main results show that, using only a limited amount of prior information regarding the set of users in the system, resource-aware cost-sharing mechanisms can guarantee a low price of anarchy for a very wide class of selfish scheduling problems.

Cost functions. In contrast to prior work in cost-sharing mechanisms, which was mostly restricted to either convex or concave cost functions, our positive result applies to a much larger class of functions. Specifically, we consider any instance where the cost functions of the machines satisfy a mild condition regarding how fast they can grow. We call a cost function bounded if it satisfies the condition that c( + 1)/c() = O(1) for all  > 0, i.e., that the relative jump in the cost function can be upper bounded by some constant. Although the class of bounded functions does not capture extreme examples of cost functions such as c() = , where c( + 1)/c() > , it captures the vast majority of functions that may characterize the cost incurred by some machine as a function of its load. For example, it includes all polynomial and even exponential cost functions. Note that this class also contains highly complicated functions that may not have a closed-form expression.

Games with two known users We first consider resource-aware mechanisms that are oblivious to the set of users in the system, with the exception of just two users. The main idea behind our proposed mechanism is
1Also known as uniform mechanisms.

2

to assign special roles to these two users, referred to as enforcers, and carefully incentivize them to enforce an approximately efficient assignment in equilibrium. Using this approach we manage to guarantee a constant PoA for instances with any combination of bounded cost functions.
Theorem: For any class of scheduling games with two known users and bounded cost functions, there exists a stable resource-aware cost-sharing mechanism that achieves a constant PoA.
Games with stochastic user arrivals. We then extend this idea to the case where each user enters the system with some probability p, and the mechanism knows p but not the realization. To achieve a good PoA bound for this class of instances we assign the role of the enforcer to more users, depending on the value of p, and guarantee an expected PoA that is at most logarithmic in the expected number of users. Theorem: For any class of scheduling games with i.i.d. arrivals2 and bounded cost functions, there exists a stable resource-aware cost-sharing mechanism that achieves an expected PoA of O(log(n~)), where n~ = p|N | is the expected number of users.
Technical obstacles Designing efficient cost-sharing mechanisms for such a wide family of instances is quite demanding: the structure of the optimal assignment can change, depending on the actual number, n, of users in the system, but the mechanism is oblivious to this number. So, how can the mechanism approximate the optimal solution without knowing n? Prior work focused on the case of concave or convex cost functions, and designed mechanisms leveraging the fact that the corresponding optimal assignments are reasonably "well behaved": for concave costs there always exists an optimal solution where all the jobs are assigned to a single machine, and for convex costs an optimal assignment can be reached using a simple greedy solution (e.g., Christodoulou et al. [2017, 2020]). However, we cannot expect to find such convenient structural properties when dealing with the vast family of bounded functions, because the optimal assignment can change radically as a function of n.
To deal with this fundamental obstacle, we propose a novel solution: rather than trying to implement the optimal assignment in equilibrium, we instead seek to implement a "well behaved" alternative assignment implied by an online algorithm. This algorithm assigns jobs to machines using a predetermined assignment sequence which is independent of the total number of jobs, n. We prove that this algorithm has a constant competitive ratio and then carefully design our cost-sharing mechanisms aiming to implement the outcome of this algorithm in equilibrium, thus inheriting a good approximation guarantee. We believe this technique may be of independent interest.
1.2 Related Work
Our work extends the recent literature that uses resource-aware cost-sharing mechanisms to achieve low PoA in different classes of games. Christodoulou and Sgouritsa [2019] were the first to study this family of mechanisms3, focusing on the class of network formation games (like Chen et al. [2010] did for the family of oblivious mechanisms). Unlike the scheduling games that we study in this paper, network formation games take place over a graph: each agent is associated with a vertex of the graph and needs to use a path connecting that vertex to a designated sink-vertex, and each edge of the graph corresponds to a resource with a constant cost function. One can think of the games in our paper as the special case where the graph has just two vertices (a source and a sink) and several parallel edges: each edge corresponds to one of the machines, and every agent needs to choose one of these edges in order to get from the source to the sink. From this perspective, our games are more restricted in terms of the users' strategy space, but quite more general in terms of the classes of cost functions. Christodoulou and Sgouritsa [2019] showed that when the graph is outerplanar, then resource-aware mechanisms can outperform oblivious ones, but they also proved that an analogous separation is not possible for general graphs. In subsequent work, Christodoulou et al. [2017] designed resource-aware mechanisms for the same class of scheduling games that we study in this
2We also extend this result to hold even if each bidder i arrives with a different probability, pi. 3In their paper, Christodoulou and Sgouritsa [2019] refer to these mechanisms as universal instead of resource-aware.
3

paper, and were able to achieve a constant PoA for instances with convex and concave cost functions. In a recent paper, Christodoulou et al. [2020] extended many of these results to more general graphs, beyond parallel links, including directed acyclic or series parallel graphs with convex or concave cost functions on the edges.
The assumption that the cost-sharing mechanism may have additional prior information regarding the users was also part of the model studied by Christodoulou and Sgouritsa [2019] for the case of network formation games. Specifically, rather than assuming that the source vertex of each agent is chosen adversarially, they assumed that it is drawn from a distribution over all vertices. The cost-sharing mechanism is aware of this stochastic process, so they designed a mechanism that leverages this information to achieve a constant PoA. Following-up on this work Christodoulou et al. [2019] extended the constant PoA to also include Bayesian Nash equilibria.
Ensuring that a cost-sharing mechanism is stable can be quite demanding, so characterizations of stable mechanisms can be very useful. Building on the impressive characterization of stable oblivious mechanisms by Chen et al. [2010], Gopalakrishnan et al. [2014] provided a characterization for the set of stable oblivious cost-sharing mechanisms. They proved that these mechanisms correspondend to the class of generalized weighted Shapley values. Leveraging this characterization, Gkatzelis et al. [2016] analyzed this family of cost-sharing protocols and showed that the unweighted Shapley value achieves the optimal price of anarchy guarantees for a large family of network cost-sharing games.
Other papers on the design and analysis of cost-sharing protocols include Harks and von Falkenhausen [2014], who focused on capacitated facility location games, Marden and Wierman [2013] who considered a utility maximization model, and Harks et al. [2021], who considered a model that imposes some constraints over the portions of the cost that can be shared among the agents. Also, Harks and Miller [2011] studied the performance of several cost-sharing protocols in a setting, where each player can declare a different demand for each resource.
Finally, there are several other models in which cost-sharing has played a central role. For example, Moulin and Shenker [2001] focused on participation games, while Moulin [2008] and Mosk-Aoyama and Roughgarden [2009] studied queueing games. Caragiannis et al. [2017] recently also pointed out some connections between cost-sharing mechanisms and the literature on coordination mechanisms, which started with the work of Christodoulou et al. [2009] and led to several papers focusing on decentralized scheduling policies for machine scheduling games Immorlica et al. [2009], Azar et al. [2015], Caragiannis [2013], Abed and Huang [2012], Kollias [2013], Cole et al. [2015], Christodoulou et al. [2014], Bhattacharya et al. [2014]. Just like the research on cost-sharing mechanisms, most of the work in coordination mechanisms studies how the price of anarchy varies with the choice of local scheduling policies on each machine (i.e., the order in which to process jobs assigned to the same machine).
2 Preliminaries
We analyze the scheduling games that arise in a decentralized system with a set M = {1, 2, . . . , m} of m machines and a set N = {1, 2, . . . , n} of n users. Each user owns a job and needs to schedule it on one of the machines. Each machine j  M is characterized by a cost function cj : N  R, where cj() is the cost that the machine would incur for processing a total of  jobs. The cost function satisfies cj(0) = 0 and it is non-decreasing.
The strategy profile, s = (s1, s2, . . . , sn), of a scheduling game is a schedule, where si corresponds to the machine that player i chooses for her job. We use Sj(s) = {i  N : si = j} to denote the set of players who scheduled their jobs on machine j in profile s, and j(s) = |Sj(s)| to denote the load on machine j in s. Therefore, the cost of machine j in this schedule is cj(j(s)), and the overall generated cost is C(s) = jM cj(j(s)). For notational simplicity, apart from cj(j(s)), we also use cj(s) to denote the cost of machine j in s, since j's load is directly implied by s.
Cost-Sharing Mechanisms. A cost-sharing mechanism is a protocol that determines the cost of each agent using a machine. Formally, a cost-sharing mechanism  defines at each schedule s a nonnegative cost share ij (s) for each j  M and i  Sj(s). Since the machine that i uses, i.e., si, is implied by s, we also
4

denote this cost share as i(s). In any schedule s, the cost of each machine j must be fully covered by the agents using it, so iSj(s) i(s)  cj(j(s)). We use C^(s) = jM iSj(s) i(s) to denote the overall cost suffered by the users in s. Since the agents pay at least the cost they generate, we have C^(s)  C(s) for every

profile s. If there exists some profile for which this inequality is strict, i.e., the cost suffered by the users is

greater than the cost that they generated, then we say that the cost-sharing mechanism uses overcharging.

Resource-Aware Mechanisms. In the class of resource-aware cost-sharing mechanisms, the value of

the cost-share ij (s) for each i  Sj(s) can depend on the set Sj(s) of agents using that machine, on the set of machines M , and their cost functions, but not on the set N \ Sj(s) of agents using other machines.

In this paper we enhance this class of mechanisms with some prior stochastic information regarding the set

N \ Sj(s), which enriches the set of cost-sharing functions that we can implement, allowing us to achieve improved performance guarantees.

Pure Nash Equilibrium (PNE). A tuple (N, M, c, ) of a set of agents, a set of machines and their

cost functions c = (cj)jM , and a cost-sharing mechanism, defines a scheduling game G. The goal of every user in this game is to choose a machine that minimizes her own share of the cost, determined by . A

strategy profile s is a pure Nash equilibrium (PNE) of this game G if for every player i  N , and every

strategy si  M

i(s) = i(si, s-i)  i(si, s-i),

where s-i denotes the profile of strategies for all agents other than i. In other words, in a PNE s no agent can decrease her cost share by unilaterally deviating from machine si to si if all the other agents' choices remain fixed.
Stability. In accordance with prior work, we restrict our attention to stable cost-sharing mechanisms, i.e., ones that induce games possessing at least one PNE.
Price of Anarchy (PoA). To measure the performance of a cost-sharing mechanism in a given game, G, we evaluate the total cost C^(s) suffered by the users in the worst equilibrium s, and compare it to the minimum total cost they could suffer. If we let Eq(G) be the set of all PNE of G and F (G) denote the set of all its feasible schedules, then the price of anarchy (PoA) of game G is

PoA(G)

=

maxsEq(G) C^(s) minsF (G) C(s)

.

Rather than evaluating the performance of cost-sharing mechanisms on a single game, we evaluate them on large classes of games. A class of scheduling games, G, is defined by a tuple (N , C, ), which comprises a universe of players N , a universe of cost functions C, and a cost sharing mechanism . An instance of a scheduling game G  G consists of some subset of users S  N , a set M of machines with cost functions from C, and the cost sharing mechanism . The worst-case price of anarchy of mechanism  for a class of games G is then defined as PoA(G) = supGG PoA(G). We also consider settings where the subset of agents, S, is drawn from N based on some distribution P . In that case, we evaluate the expected price of anarchy of  as
ExpectedPoA(G) = sup E [PoA((S, M, c, ))] .
M,cC|M| SP
In other words, given an adversarial choice of machines M using cost functions from C, we evaluate the expected PoA over the randomness of P in defining the subset of agents S.
Classes of Cost Functions. We say that a cost function is bounded if c( + 1)/c() = O(1) for all  > 0. Another class of functions that plays an important role in prior work is that of capacitated constant cost functions. That is, functions such that c() = c when   t and c() =  when  > t, for some positive constants c and t. Note that, although these cost functions are not bounded, one of our first results shows that we can achieve a small PoA for them as well, as long as their capacity, t, is at least 4. Finally, a 4-step function is a step function whose segments have length at least 4. In other words, the value of a 4-step function does not change more than once within any interval of length 4 in its domain. Note that capacitated constant functions with capacity at least 4 are a special case of a 4-step function. Also, it is easy to verify that for any bounded cost function c, there exists a 4-step function c such that c()  c() and

5

c()/c() = O(1) for all  > 04. This means that we can always approximate a bounded cost function using a 4-step function, so in the rest of the paper we assume that the cost functions are all 4-step functions.
Global Ordering. Our mechanisms, as well as many mechanisms in the related work (e.g. Moulin [1999], Christodoulou et al. [2017, 2020]), use a global ordering  over the universe N of players in deciding how to distribute the cost. Although the externality of the users in the games that we study is symmetric (e.g., they all cause the same marginal increase in the cost of a machine), the mechanism needs to share the cost unevenly among them to achieve a good PoA5. The global ordering provides a consistent way for the mechanism to differentiate between these users. To ensure that no fairness concerns arise from the asymmetry introduced by these mechanisms, we assume that this global ordering can change periodically in a predetermined way, thus providing a symmetric treatment of the users over time.

3 Online Scheduling Algorithm

The main obstacle that resource-aware mechanisms face in approximating the optimal solution is that they do not know the number n of agents that are present in the system. Since the optimal solution can change radically as a function of n, how can the cost-sharing mechanism try to approximate it without knowing the value of n?
Rather than trying to implement the optimal assignment as an equilibrium, the main idea behind our solution is to instead implement a much more "well behaved" allocation that, in turn, closely approximates the cost of the optimal assignment. Specifically, we define an online algorithm, called Delayed-OPT, which sequentially assigns jobs to machines using a predetermined order, without knowing the value of n. We show that this algorithm has a constant competitive ratio and then we design cost-sharing mechanisms aiming to implement the outcome of this algorithm in equilibrium.
If A(n) is the outcome of the online algorithm and OPT(n) is the optimal allocation (i.e. the feasible schedule with the minimum social cost) when the total number of jobs is n, then the competitive ratio is equal to maxn{C(A(n))/C(OPT(n))}. To simplify the description of the Delayed-OPT online algorithm, without loss of generality we normalize the costs functions. That is, all costs are multiplied by the same constant such that the minimum non-zero cost is equal to 1.For each k  N, let ak = max{q  N : C(OPT(q)) < 2k} be the largest number of jobs such that the optimal social cost for scheduling these jobs remains less than 2k (Figure 1 shows two examples for capacitated constant cost functions). Using this definition, let jk denote the number of jobs assigned to machine j in the optimal allocation when the total number of jobs is ak.
When the qth job arrives, the Delayed-OPT finds the smallest value of k such that for some machine j  M the number of jobs, j, assigned to it so far is less than jk. Then, among all such machines, the algorithm assigns this job to the one that has the smallest index6. The algorithm then increments the value of j by one and moves on to the next job. A formal description of the Delayed-OPT algorithm is provided as Algorithm 1, below, and two examples of the induced assignment are provided in Figure 1.
Lemma 1. If q  ak for some k  N, then the value of k computed by the algorithm in the iteration corresponding to the qth job satisfies k  k.

Proof. Assume that this is not the case. This would mean that in that iteration of the algorithm, for every machine j  M we have j  jk . Summing over all j  M , this would yield

j 

jk = ak .

jM

jM

But, since q = jM j + 1, this contradicts the fact that q  ak .
4To verify this fact, note that given a bounded function c, we can define a 4-step function c such that for every k  N, if   [4k - 3, 4k] then c() = c(4k). Clearly, c()  c() for all  > 0. Also, since c is bounded, this means that for every  we have c()/c()  c( + 4)/c() = O(1).
5It is well known that the PoA is linear in the number of agents if we share the cost equally Anshelevich et al. [2008]. 6We assume that the machines have some arbitrary, but fixed, ordering indicated by their indices.

6

c3 = 15 10

9

c2 = 2 8 47

c1 = 1 3

6

125

a5 = 10 a4 = 6 a3 = 4 a2 = 4 a1 = 1 a0 = 0

c5 = 7 11 10 9 8 7
c2 = 2 c3 = 2 c4 = 2 6 c1 = 1 3 13 15 5
1 2 12 14 4

a4 = 15 a3 = 8 a2 = 3 a1 = 1 a0 = 0

(a)

(b)

Figure 1: These figures depict machines with capacitated constant cost functions. Figure (a) shows three machines whose cost is 1, 2, and 15 for any load up to 1, 3, and 6, respectively (and the cost becomes infinite for any load beyond that). Similarly, Figure (b) shows five machines whose cost is 1, 2, 2, 2, and 7 for any load up to 1, 2, 2, 2, and 8, respectively. In both figures, the ak values are given on the right, and each number inside the machines represents a job with the number indicating the order of their arrival. The figures show how the Delayed-OPT algorithm assigns the jobs to the machines, e.g. the first job is assigned to the first machine in both cases.

ALGORITHM 1: Delayed-OPT Online Algorithm

1 q0

// Initialize counter for the number of jobs

2 j  0 for each j  M

// Initialize all loads to zero

3 while there exist more jobs do

4 qq+1

5 k  min{k  N | j  M : j < jk} 6 j  arg min{j  M | j < jk}

7 j  j + 1

// Assign job to first machine that has not reached target load

We now proceed to show that the competitive ratio of this algorithm is less than 4.

Theorem 2. The competitive ratio of the Delayed-OPT algorithm is less than 4.

Proof. Let k  N be the minimum value such that n  ak. The load that the algorithm assigns on any

machine j is no more than maxkk{jk }. As a result, the cost of the Delayed-OPT algorithm for n jobs

is

C(A(n)) 

C(OPT(ak )) <

2k < 2k+1,

k k

k k

while the optimal cost is C(OPT(n))  C(OPT(ak-1 + 1))  2k-1, leading to a competitive ratio of less than 2k+1/2k-1 = 4.

The following lemma will be useful in the next sections.
Lemma 3. If cj() = cj( + ) for some machine j and some loads ,  > 0, then right after the iteration that the Delayed-OPT algorithm assigns the th job at machine j, it assigns the next  jobs at the same machine.

7

Proof. Suppose that in the iteration that the Delayed-OPT algorithm assigns the th job at machine j it computes k to be the smallest value such that there exists a machine j with j < jk. Since the algorithm assigns the current job to machine j, at this iteration j < jk and j has the smallest index among machines that satisfy this inequality.
Moreover, since the cost functions are all non-decreasing, the cost of machine j is the same for all loads between  and  + , which means that jk   + . To better see this suppose on the contrary that jk <  + . The allocation that assigns another job to machine j has the same cost with current optimal allocation, i.e. C(OPT(ak)) = C(OPT(ak + 1)). This is a contradiction to the definition of ak that needs to satisfy that C(OPT(ak)) < C(OPT(ak + 1)).
Overall, in the next iteration, j < jk and j should be the smallest index that satisfies this inequality, otherwise this wouldn't be true in the previous iteration. Therefore, the Delayed-OPT algorithm assigns the next job to machine j and by induction it should assign all the following jobs until the load of machine j becomes  + . Figure 1 shows such examples.
4 Resource-Aware Mechanism for Games with Two Known Users
In this section we consider resource-aware mechanisms that are oblivious to the set of users in the system, with the exception of just two users. Formally, we consider classes of games such that for every game G in this class, the set of agents, S, always contains two known agents. Note that the set S is otherwise totally unrestricted and can also contain an adversarially chosen subset of the agents from N , so this class of games is quite general. In fact, since the optimal allocation may very heavily depend on the total number of agents that participate in the game, the aforementioned restriction is seemingly benign. In what follows, we propose a resource-aware mechanism that assigns a special role to the two known agents, leading to very efficient equilibria for any bounded cost function. In fact we show that the assignment of every Nash equilibrium in the induced game is the same as the outcome of the Delayed-OPT algorithm when scheduling |S| jobs.
As a warm-up, we first consider the games whose cost functions are drawn from the class of capacitated cost functions, and then we go on to extend our result beyond this class.
4.1 Warm-up: A Class of Capacitated Constant Functions
In order to more clearly capture the intuition behind how our proposed mechanism works, we first focus on games whose cost functions are capacitated constant, with a capacity of at least 4. That is, for every machine j we have cj() = cj when   tj and cj() =  otherwise, where cj > 0 and tj  4 are constants7. Note that these cost functions are actually not bounded, since they jump from some constant to infinity when their capacity is exceeded, so this section also shows that our positive results can even be extended to cost functions beyond the class of bounded ones.
Before presenting our protocol, we make an important observation, that can be derived directly from Lemma 3, regarding the allocation of the Delayed-OPT algorithm when the machines have capacitated constant cost functions.
Observation 1. For any instance involving a set M of machines with capacitated constant cost functions, there exists an ordering of the machines in M such that the Delayed-OPT algorithm fills up machine j up to its capacity before assigning any job to any machine j that is later in the ordering.
Let D = {1, 2} be the set of the two agents, called enforcers, who are guaranteed to participate, and let R = S \ D be the rest of the agents, which we call regular agents. Also, given some set of agents S, let h(S) be the first (highest priority) agent in S according to a global ordering . For simplicity we assume that the machines are renamed according to the ordering implied by the Delayed-OPT algorithm (Observation 1),
7The assumption of cj > 0 for all j is w.l.o.g. because if there are machines with zero cost, we may charge everybody with 0, unless the machine load exceeds its capacity, in which case everybody is charged with infinity. In both the Delayed-OPT algorithm and any Nash equilibrium those machines are firstly occupied up to their capacity and then other machines are used resulting in a PoA equal to the one that ignores those machines.
8

and let Zj = kj ck be the sum of the costs of the first j machines in this ordering. Note that the value of Zj is strictly increasing with j by our convention that cj > 0 for all j. Finally, to define the protocol we also use an arbitrarily small positive value j for each machine j to be used as a special charge for enforcers in some cases; j values are strictly decreasing values, i.e. j > j+1.
Brief description of the protocol. The enforcers are charged with the small value j for using machine j only in two cases: i) if they are together in j along with at least one regular agent (if there were no regular
agent, the enforcers should cover the cost of the machine) and the load of machine j doesn't exceed its
capacity tj, ii) if the enforcer is alone in j and the load of machine j exceeds its capacity tj. In any other case they pay Zj. Regarding the regular agents, the highest priority regular agent always pays a non-zero charge. More specifically, if machine j's load doesn't exceed tj, the highest priority regular agent pays the cost of j, cj, if the machine is full (i.e. its load equals tj) and there is no enforcer in j; otherwise, meaning when j's load is less than tj or there is an enforcer in j, the highest priority regular agent pays Zj. The rest of the regular agents are charged with 0 if j's load doesn't exceed tj. If j's load exceeds tj, then everybody is charged with infinity.

Protocol. Given a strategy profile s, the cost share of any enforcer i  D for using machine j is

j  i(s) = j Zj

if j(s)  tj and D  Sj(s) if j(s) > tj and D  Sj(s) = {i} otherwise.

The cost share of any regular agent i  R for using machine j is

 0   cj 
i(s) = Zj
Zj  

if j(s)  tj and i = h(Sj(s)  R) if j(s) = tj, D  Sj(s) =  and i = h(Sj(s)  R) if j(s) = tj, D  Sj(s) =  and i = h(Sj(s)  R) if j(s) < tj and i = h(Sj(s)  R) otherwise.

The main idea behind this protocol is that in the equilibrium if agents use some machine, all machines with lower indices should be full (i.e. its load equals its capacity). As we mentioned above, Zj values are strictly increasing. As a result if some agent is charged Zj in machine j, she prefers to deviate to a non-full machine (non-full means that its load is less that its capacity) with smaller index. Such an agent exists when the machine is not full or when an enforcer is using it. However, there is no such agent when the machine is full with only regular agents, where the importance of enforcers comes in place as we explain next. We note here that it is crucial to keep the budget balance in full machines without enforcers so that we do not lose in efficiency too much.
If a machine that is not used by the Delayed-OPT algorithm is full with only regular agents, enforcers are going to disrupt them and push them to machines with lower indices. The reason is because j values are decreasing, so enforcers prefer to occupy machines with higher indices. So, if an enforcer deviates to a full machine j, the load of that machine will exceed capacity and the enforcer will be charged j.
The cases where the charges of the enforcers are high (Zj) are crucial in order to guarantee stability as we show in Theorem 5.

Theorem 4. The PoA for the class of capacitated constant cost functions, assuming two enforcers, is constant.

Proof. It is sufficient to show that the social cost of any Nash equilibrium is constant away from the cost induced by the Delayed-OPT algorithm, which in turn is constant away from the cost of the optimal allocation.
In fact we show that under any pure Nash equilibrium, the allocation is the same with the outcome of the Delayed-OPT algorithm; that is for any used machine r, all prior machines j < r are fully used. Then,

9

it is easy to check that, regarding the overcharging, each enforcer may "cause" some regular agent to pay at most the cost of the outcome of the Delayed-OPT algorithm and each enforcer itself may pay some arbitrarily small value j.8
For the sake of contradiction suppose that in some Nash equilibrium there exist machines j < r such that machine r is used and machine j is not full. Let r be the largest possible such index.
 If r is not full, or if it is full and has at least one enforcer, there exists an agent paying Zr and if he deviates to j he should pay at most Zj < Zr, so he has an incentive to deviate (Figure 2).
 If r is full with only regular agents, there exists an enforcer in an earlier machine j < r paying at least j . That enforcer has an incentive to deviate to r where he will pay r < j (Figure 3).

cj
cr c1

cj cr

deviates

deviates

enforcer

highest priority

highest priority

1

j

r

regular agent

j

r

regular agent

(a)

(b)

Figure 2: In this figure we assume that machine j is not full and there exists a non empty machine r, with r > j (where r is the maximum such index). If machine r is either not full (a) or has an enforcer (b), then there is always a regular agent from r that prefers to deviate to j.

cj

c1

cj deviates

cr

enforcer

1

j

j

r

Figure 3: In this figure we assume that machine j is not full and there exists a non empty machine r, with r > j (where r is the maximum such index). If machine r is full with only regular agents, then any enforcer prefers to deviate to r.
In both cases there exists an agent with an incentive to deviate to another machine which is a contradiction to our assumption that this is a Nash equilibrium.
Theorem 5. The protocol for the class of capacitated constant cost functions, assuming two enforcers, is stable.
Proof. In order to show stability, we create a strategy profile that is an equilibrium for any set of agents S  N as long as D  S.
8There is no Nash equilibrium where the enforcers are charged more than some j, unless there is no regular agent where we again have the same overcharging.

10

Let n be the number of agents in the system, where n - 2 of them are regular agents, since there exist two enforcers. Suppose that r machines are occupied based on the Delayed-OPT algorithm, with the first r - 1 machines being fully occupied and machine r having nr  tr agents. The strategy profile we create depends on the value of nr.
Case of nr  2. In this case, we create a strategy profile where the enforcers use the last full machine r - 1 (unless r = 1, meaning that there is no regular agent, and the enforcers use machine 1 which is a Nash equilibrium). The regular agents are placed according to the outcome of the Delayed-OPT algorithm such that in the last machine r the lowest priority agents are placed (Figure 4 (a)). Next we show that nobody has an incentive to deviate from this strategy profile and therefore it is stable.
The enforcers are currently charged with r-1 and if they deviate to any previous machine j with j < r-1 they will be charged with j > r-1. Moreover, if they unilaterally deviate to r they will be charged Zr > r-1 because they will be the only enforcer there. Deviating to any other machine j with j > r will result in an even higher charge, since the enforcer will be alone there. Overall, enforcers have no incentive to deviate.
From the regular agents' perspective, nobody has an incentive to deviate to a full machine j < r because its load then will exceed its capacity resulting in infinity charges. Additionally, no agent currently located to some machine j  r has an incentive to deviate to an empty machine j > r, because he is currently charged at most Zj and if he deviates to j, he will be charged Zj > Zj. The last case to check is if an agent currently located to some machine j < r, has an incentive to deviate to r. Note that if he deviates to r, the machine will still not be full and he will be the highest priority agent, as in r we allocated the lowest priority agents; therefore, he will be charged Zr > Zj, where Zj is the maximum he may currently be charged.
Case of nr > 2. In this case, we create a strategy profile where the enforcers use that last machine r. The regular agents are placed according to the outcome of the Delayed-OPT algorithm such that in the last machine r the lowest priority agents are placed (Figure 4 (b)). Similar arguments hold in this case in order to show that nobody has an incentive to deviate from this strategy profile.
More specifically the enforcers are currently charged with r and any deviation will result in a charge of either j with j < r or Zj with j > r, which are both strictly greater than r.
Regarding the regular agents, as before, nobody wants to deviate to a full machine or to a machine j > r. Any agent currently using some machine j < r is charged with at most Zj and if he deviated to machine r he would pay at least Zr > Zj because he would be the highest priority agent in r.

cr-1

cr

c1 enforcers

c1

lowest priority regular agents

1

r-1 r

1

(a)

cr
enforcers lowest priority regular agents r (b)

Figure 4: This figure shows the stable outcomes when the Delayed-OPT algorithm allocates in the last machine (a) at most two agents and (b) more than two agents.
In Appendix A we give some intuition on why we may need of at least two enforcers and the capacities to be at least 4. Both restrictions are important in order to guarantee stability.

11

4.2 Bounded Cost Functions
We now extend the result of Section 4.1 to the class of bounded cost functions. For simplicity, we focus on the class of 4-step cost functions which naturally generalize the capacitated cost functions considered above; as we discussed in Section 2, any bounded cost function can be approximated by a 4-step cost function, so our results directly extend to bounded cost functions as well.
A key difference between the segments of 4-step functions and the capacitated constant functions is that having a single job in a segment may have two meanings in the respective machines with capacitated constant functions: it may be considered as i) having a single job in the machine with capacitated constant function corresponding to that segment or ii) having an overload in the machine with capacitated constant function corresponding to the previous segment of the step function. In order to overcome this ambiguity we slightly change our protocol in order to handle those two cases consistently and get the same results.
Let agents D = {1, 2} be the two agents/enforcers who are guaranteed to participate, and let R = S \ D be the regular agents. Before describing the protocol we need to give some further definitions; Figure 5 gives some intuition for some of the following definitions.
4.2.1 Preliminaries

We first provide an alternative definition of a 4-step function. In the rest of the paper, we will be assuming that all the machine cost functions are 4-step functions.

Definition 6. A function c is called 4-step function if the following are true: there are steps of lengths

t(1), t(2),     4 such that for all k and all x  [1 +

k-1 k =1

t(k),

k k =1

t(k)]

we

have

that

k

c(x) = c

t(k) = c~(k).

k =1

That is, the cost function increases only when an extra step needs to be used. If any number of jobs
between one and t(1) are undertaken by this machine, the cost is c~(1). Then if one more job is added the
cost jumps to c~(2) and then the cost for t(1) + 1 up to t(1) + t(2) jobs remains c~(2), and so forth. Note that trivially all functions on natural numbers are 1-step functions.
Length and cost of a segment. According to Definition 6, we define segment k of machine j to be the kth step of machine j's cost function cj and has length tj(k) and cost c~j(k).
Last used segment j(j(s)) = j (s). For each machine j and profile s, we denote by j(s) the last segment that is used in machine j under s. It holds that cj(s) = c~j(j (s)).
Machine's excess wj(j(s)) = wj (s). For each machine j and profile s, we denote by wj(s) the number of jobs occupying the last segment of machine j under s if that segment is not filled to capacity. If the
number of jobs fill the last segment to capacity then we set wj (s) to 0. More formally,

wj (s) =

j(s) - 0

j (s)-1 k=1

tj

(k)

if j(s) > otherwise

j (s)-1 k=1

tj

(k

)

Segment order . Lemma 3 implies that the Delayed-OPT algorithm fills up a segment up to its capacity before assigning any job to any other segment. Therefore, a priority order on the segments can be derived according to the Delayed-OPT algorithm that assigns for every machine j and segment k a number j (k). The function  respects the order of the machine step costs, i.e. it is strictly monotone.
Definition of Zj(k). Similarly to the case of capacitated constant functions, we define

Zj(k) =

j

k

:j

max
(k )j

(k)

c~j

(k

),

which is the aggregate cost of all machines if all segments up to j (k) in the priority order are occupied. W.l.o.g. the Zj(k) values are strictly increasing according to the order defined by . This is by assuming

12

non-zero costs which is w.l.o.g. according to footnote 7, and additionally if two consecutive segments have
the same cost, we may assume that they are merged into a single segment.
Definition of j(k). We also use an arbitrarily small positive value j(k) for each segment k of machine j to be used as a special charge for enforcers in some cases; j(k) values are strictly decreasing values according to the order , i.e. if j(k) > j (k) then j(k) < j (k).
First two machines. We further distinguish two machines 1 and 2 to be the first and the second
machines, respectively, to be used by the Delayed-OPT algorithm. Highest priority agents h(S). Given some set of agents S, hi(S) is the ith agent in S according to
the global ordering .

Protocol. Given a strategy profile s we next define the cost shares of the agents. For simplicity, we drop

the dependency on the load and on s since there is no ambiguity. The cost share of any enforcer i  D using

machine j is

j(j )

if wj = 1 and D  Sj



i(s) = j(j - 1) if wj = 1, D  Sj = {i} and j > 1

Zj(j )

otherwise.

The cost share of any regular agent i  R using machine j is

 cj   Zj(j ) 
i(s) = Zj(j )
Zj(j )  0

if wj = 0, D  Sj =  and i = h1(Sj  R) if wj = 0, D  Sj =  and i = h1(Sj  R) if wj = 1 and i  {h1(Sj  R), h2(Sj  R)} if wj / {0, 1} and i = h1(Sj  R) otherwise.

w1(A) = 0 c~1(3) 1(3) = 11
c~1(2) 1(2) = 5 c~1(1) 1(1) = 1
1

w2(A) = 0 2(4) = 9
2(3) = 6
2(2) = 3 2(1) = 2
2

w3(A) > 0 3(3) = 10 3(2) = 7
3(1) = 4 3

w4(A) = 0 4(2) = 12 t4(2)
4(1) = 8 t4(1) 4

Figure 5: This figure shows an example of the first four machines in the order that are used by the Delayed-
OPT algorithm. The cost functions belong to the class of 4-step functions. In the figure, c~1(k) is the cost of machine 1 when the kth step/segment is used but not the (k + 1)th, and t4(k) is the length of the kth step/segment of machine 4. The j (k) values show the order that the Delayed-OPT algorithm fills the segments. In this example, the allocation A of the Delayed-OPT algorithm fully uses the first 6 segments and also part of the 7th segment. The excess of all machines but the third are 0 and machine 3 has positive excess since its 2nd segment is not fully used.

Theorem 7. The PoA for the class of 4-step cost functions, assuming two enforcers, is constant.

13

Proof. We will show that the total cost of any induced pure Nash equilibrium, assuming two enforcers, is constant away the total cost induced by the Delayed-OPT algorithm which in turns is a constant approximation to the cost of the optimal allocation. In order to show this, we will show that any pure Nash equilibrium s has the same allocation with the Delayed-OPT algorithm allocation A. This means that for any machine j the load in s and A are the same, i.e. j(s) = j(A). Claim 1. For any Nash equilibrium s, j(s) = j(A) for all j.
Proof. For the sake of contradiction suppose that there exists some Nash equilibrium s with different allocation than A. Then there should be a machine r with r(s) > r(A). If there are many machines with more load in s than in A, we choose r to be the one with the maximum r(r(s)).
For any machine j, with j(s)  j(A), it holds that the last segment of machine j under A precedes the last segment of machine r under s according to segment order , i.e. j(j (A)) < r(r(s)), meaning that overall r(r(s)) is the maximum among used segments under s. The reason is that, if l is the last machine used by the Delayed-OPT algorithm, the excess of all other machines different than l is 0 under A, and therefore if r = l, r(s) is not used in A; by the definition of  order, j (j(A)) < r(r(A)+1)  r(r(s)). If r = l, it trivially holds that j(j (A)) < r(r(A))  r(r(s)).
Next we show that under s either a regular agent or an enforcer has an incentive to deviate leading to a contradiction.
 If there is at least one enforcer in machine r, or r(s) is not full, i.e. wr(s) = 0, the highest priority regular agent in r, h1(Sr(s)  R), is paying Zr(r(s)). If this agent deviated to any machine j, with j(s) < j(A) (there exists at least one because r(s) > r(A)), the total load on that machine would be at most j(A) and therefore the agent's payment would be at most Zj(j(A)) < Zr(r(s)).
 If machine r has only regular agents and 0 excess, i.e. wr(s) = 0, there exists an enforcer in some machine j = r that is charged with at least j (j (s)). If he deviated to machine r, the excess of that machine would become 1 and he would be the only enforcer in machine r, therefore, he would be charged with r(r(s)) < j (j (s)), where the inequality holds because r(r(s)) is the maximum among used segments under s.
Theorem 8. The protocol for the class of 4-step cost functions, assuming two enforcers, is stable.
Due to space limitations we refer the reader to the appendix for the proof of the theorem.
5 Resource-Aware Mechanism for Games with Stochastic Arrivals
In this section we study the case of stochastic arrivals, where each agent i appears in the system with probability pi and the mechanism has access to p = (p1, p2, . . . , p|N |). Let S be the random set of the arriving agents and M be a set of machines whose cost functions are from the class of 4-step functions. We design a cost sharing scheme with the goal of minimizing the expected price of anarchy defined as follows:
ExpectedPoA(G) = sup E [PoA((S, M, c, ))] .
M,cC|M| SP
Our main theorem (Theorem 12) bounds the expected price of anarchy of our protocol in relation to the expected number of arriving agents n~ = ESp[|S|]. For the sake of simplicity in this section we prove the case of identical agents that is pi = p for all i. The proof for the general case (Theorem 14) can be found
14

in the appendix. We show that for the case of independently arriving agents there exists a protocol using

3

+

3

log(p|N |) - log(1-p)



enforcers

that

achieves

an

expected

price

of

anarchy

of

at

least

ExpectedPoA(G) = O log E [|S|] = O(log n~) .
Sp

Protocol. The protocol is similar to the one we defined with the guaranteed enforcers. However rather than using the two guaranteed agents as the enforcers we choose an appropriate set of enforcers using the distributional information we have. In order to guarantee stability for any number of enforcers we adjust the cost sharing protocol by adding two rest points for enforcers where they pay 0 share; we further slightly modify the cost shares of enforcers to include cases where many enforcers use the same machine.
Given the set of arriving agents S and a strategy profile s we next define the cost shares of the agents. Let D  S be the set of enforcers in S and R = S \ D be the set of regular agents in S. For simplicity, we drop the dependency on the load and on s since there is no ambiguity. The cost share of any enforcer i  D using machine j is

0





i(s)

=

j (j j (j

) -

1)



Zj(j )

if j  {1, 2}, wj  {0, tj(j ) - 1} and D  Sj = {i} if wj = 1, D  Sj  {i}, R  Sj =  and i  {h1(Sj  D), h2(Sj  D)} if wj = 1, D  Sj = {i} and j > 1 otherwise.

The cost share of any regular agent i  R using machine j is (the same as in Section 4.2)

 cj   Zj(j ) 
i(s) = Zj(j )
Zj(j )  0

if wj = 0, D  Sj =  and i = h1(Sj  R) if wj = 0, D  Sj =  and i = h1(Sj  R) if wj = 1 and i  {h1(Sj  R), h2(Sj  R)} if wj / {0, 1} and i = h1(Sj  R) otherwise.

We refer the reader to the appendix for the proof of the following theorem.

Theorem 9. The protocol for the class of 4-step cost functions is stable for any number of enforcers.

Next we continue with upper bounding the expected price of anarchy of our protocol. First we prove two important lemmas on how far the cost of any Nash equilibrium may be from the cost of the allocation A of the Delayed-OPT algorithm, conditioned on the number of enforcers in the system. We distinguish two cases of having at least three enforcers or at most two enforcers in the system. In the first case, the proof is similar to the one of Theorem 7, but we now need at least three enforcers because based on the protocol at most two enforcers may pay 0 cost shares; those enforcers have no incentive to deviate to machines that are not used in A and are full with regular agents.

Lemma 10. If d  3 enforcers arrive then the cost of the Nash equilibrium is no more than d + 3 times the cost of the allocation A of the Delayed-OPT algorithm, by ignoring the arbitrarily small charges of j(k) values.

Proof. Since we have two rest points for the enforcers (first case of the cost shares), meaning that at most two enforcers may pay 0 in any Nash equilibrium s, if d  3 enforcers appear in the system, then at least one of them must pay a non-zero share. Following the proof of Theorem 7 we can easily infer that s uses the exact same allocation as the Delayed-OPT algorithm (Claim 1). Next we need to bound the overcharging cost. Note that any cost share Zj(j (A)) for some j is no more than the cost of A. As a result we simply need to bound the number of agents charged with such a cost share. Let dj be the number of enforcers in machine j.

15

First, we examine the machines other than the last machine used by the Delayed-OPT algorithm. By
definition, such machine j will have zero excess, wj(A) = 0. Therefore, if there are only regular agents there will be no overcharging. If there are only enforcers the overcharging is dj Zj(j (A)) which is at most dj times the total cost of A. If there is at least one enforcer and at least one regular agent, then we have at
most one regular agent paying Zj(j (A)) and either one enforcer is paying 0 or two enforcers are paying the arbitrarily small value j(j (A)). In any case, the overcharging is at most dj times the total cost of A, by ignoring the j(j(A)) values.
Second, let's consider the last machine r used by the Delayed-OPT algorithm. At most two regular
agents are charged with Zr(r(A)) (if wr(A) = 1). It is also possible that all the enforcers are charged with Zr(r(A)) and therefore, the total overcharging in machine r is at most dr + 2 times the total cost of A, by ignoring again the r(r(A)) values.
Overall, the overcharging is at most d + 2 times the total cost of A and as a result, the total cost of s is
no more than d + 3 times the total cost of A.

Lemma 11. If r regular agents and d  2 enforcers arrive then the cost of the Nash equilibrium s is no more than r + d times the cost of the allocation A of the Delayed-OPT algorithm, by ignoring the arbitrarily small charges of j(k) values.
Proof. If the allocation of s is not the same as A, there must be some machine j such that j(s) < j(A). This implies that any agent can deviate to this machine and pay at most Zj(j (A)). As a result the cost of any agent (enforcer or regular) under s is no more than Zj(j(A)) which is upper bounded by the total cost of A. Therefore, the total cost of s is no more than r + d times the total cost of A.

Next we upper bound the price of anarchy in the special case where the agents arrival probabilities are identical, that is pi = p for all i  N . Note that in this case the expected number of agents is n~ = ESp[|S|] = p|N |.

Theorem 12. For independently arriving agents with identical probabilities p and for the class of 4-step

cost

functions,

there

exists

a

protocol

using

|D|

=

3

+

3

log(p|N |) - log(1-p)



enforcers

that

achieves

an

expected

price

of anarchy of

ExpectedPoA(G) = O(log( E [|S|])) = O(log n~) .
Sp

Before proceeding with the proof of Theorem 12, we state the following lemma. The proof of the lemma is in the appendix.

Lemma

13.

If

we

choose

a

set

of

enforcers

D

such

that

|D|

=

3

+

3

log(p|N |) - log(1-p)



then

P[d  2] E [|S| | d  2]  9 ,
Sp

where P is the probability symbol and d = |S  D| is a random variable depending on p.

Proof. (Theorem 12) Let S be a random set of arriving agents, G be the corresponding game, Eq(G) be the set of Nash equilibria for G and A be the allocation of the Delayed-OPT algorithm for the set S. Moreover, let d = |S  D| be a random variable depending on p. Combining both Lemmas 10 and 11 we get that the expected ratio of the cost of the worst case equilibrium to the cost of the allocation of the Delayed-OPT algorithm is

E
Sp

maxsEq(G) C^(s) C(A)

= P[d  2] E [|S| | d  2] + P[d  3] E [d + 3 | d  3] .

Sp

Sp

(1)

We can bound the second summand of Equation (1) as

16

P[d  3] E [d + 3 | d  3]  E [d + 3 | d  3]

Sp

Sp

 E [d | d  0] + 6 = p|D| + 6 .

(2)

Sp

Combining Lemma 13, Equation (1) and Equation (2) we get that

E maxsE(G) C^(s)

Sp

C(A)



p|D| + 15  3 log(p|N |)

p - log(1 - p)

 + 18



3 log(p|N |)

p - log(1 - p)

+ 18

 3 log(p|N |) + 18 = 3 log n~ + 18 ,

(3)

where

the

last

inequality

is

due

to

(

-

p log(1-p)

)

1

for

p

0.

The

fact

that

the

cost

of

the

Delayed-OPT

algorithm outcome is a constant approximation to the optimum cost completes the proof.

Next we upper bound the price of anarchy when the agents arrival probabilities are not necessarily

identical. For pi being the probability that agent i arrives, n~ = ESp[|S|] =

|N | i=1

pi

is

the

expected

number

of agents. The proof of the theorem is in the appendix.

Theorem 14. For independently arriving agents with not necessarily identical probabilities and for the class of 4-step cost functions, there exists a protocol that achieves an expected price of anarchy of

ExpectedPoA(G) = O(log( E [|S|])) = O(log n~) .
Sp

Acknowledgments
The authors would like to thank Giorgos Christodoulou for helpful discussions during the initial stages of this project. The work of the first author was partially supported by NSF CAREER award CCF-2047907.

References
F. Abed and C.-C. Huang. Preemptive coordination mechanisms for unrelated machines. In European Symposium on Algorithms, pages 1223. Springer, 2012.
E. Anshelevich, A. Dasgupta, J. M. Kleinberg, E . Tardos, T. Wexler, and T. Roughgarden. The price of stability for network design with fair cost allocation. SIAM J. Comput., 38(4):16021623, 2008.
Y. Azar, L. Fleischer, K. Jain, V. S. Mirrokni, and Z. Svitkina. Optimal coordination mechanisms for unrelated machine scheduling. Operations Research, 63(3):489500, 2015.
S. Bhattacharya, S. Im, J. Kulkarni, and K. Munagala. Coordination mechanisms from (almost) all scheduling policies. In 5th conference on Innovations in theoretical computer science, pages 121134. ACM, 2014.
I. Caragiannis. Efficient coordination mechanisms for unrelated machine scheduling. Algorithmica, 66(3): 512540, 2013.
I. Caragiannis, V. Gkatzelis, and C. Vinci. Coordination mechanisms, cost-sharing, and approximation algorithms for scheduling. In N. R. Devanur and P. Lu, editors, Web and Internet Economics - 13th International Conference, WINE 2017, Bangalore, India, December 17-20, 2017, Proceedings, volume 10660 of Lecture Notes in Computer Science, pages 7487. Springer, 2017.

17

H.-L. Chen, T. Roughgarden, and G. Valiant. Designing network protocols for good equilibria. SIAM Journal on Computing, 39(5):17991832, 2010.
G. Christodoulou and A. Sgouritsa. Designing networks with good equilibria under uncertainty. SIAM J. Comput., 48(4):13641396, 2019.
G. Christodoulou, E. Koutsoupias, and A. Nanavati. Coordination mechanisms. Theor. Comput. Sci., 410 (36):33273336, 2009.
G. Christodoulou, K. Mehlhorn, and E. Pyrga. Improving the price of anarchy for selfish routing via coordination mechanisms. Algorithmica, 69(3):619640, 2014.
G. Christodoulou, V. Gkatzelis, and A. Sgouritsa. Cost-sharing methods for scheduling games under uncertainty. In Proceedings of the 2017 ACM Conference on Economics and Computation, EC '17, Cambridge, MA, USA, June 26-30, 2017, pages 441458, 2017.
G. Christodoulou, S. Leonardi, and A. Sgouritsa. Designing cost-sharing methods for bayesian games. Theory of computing systems, 63(1):425, 2019.
G. Christodoulou, V. Gkatzelis, M. Latifian, and A. Sgouritsa. Resource-aware protocols for network costsharing games. In P. Bir큢, J. D. Hartline, M. Ostrovsky, and A. D. Procaccia, editors, EC '20: The 21st ACM Conference on Economics and Computation, Virtual Event, Hungary, July 13-17, 2020, pages 81107. ACM, 2020.
R. Cole, J. R. Correa, V. Gkatzelis, V. S. Mirrokni, and N. Olver. Decentralized utilitarian mechanisms for scheduling games. Games and Economic Behavior, 92:306326, 2015.
V. Gkatzelis, K. Kollias, and T. Roughgarden. Optimal cost-sharing in general resource selection games. Operations Research, 64(6):12301238, 2016.
R. Gopalakrishnan, J. R. Marden, and A. Wierman. Potential games are necessary to ensure pure nash equilibria in cost sharing games. Mathematics of Operations Research, 2014.
T. Harks and K. Miller. The worst-case efficiency of cost sharing methods in resource allocation games. Operations Research, 59(6):14911503, 2011.
T. Harks and P. von Falkenhausen. Optimal cost sharing for capacitated facility location games. Eur. J. Oper. Res., 239(1):187198, 2014.
T. Harks, M. Hoefer, A. Schedel, and M. Surek. Efficient black-box reductions for separable cost sharing. Mathematics of Operations Research, 46(1):134158, 2021.
N. Immorlica, L. E. Li, V. S. Mirrokni, and A. S. Schulz. Coordination mechanisms for selfish scheduling. Theoretical Computer Science, 410(17):15891598, 2009.
K. Kollias. Nonpreemptive coordination mechanisms for identical machines. Theory of Computing Systems, 53(3):424440, 2013.
J. R. Marden and A. Wierman. Distributed welfare games. Operations Research, 61(1):155168, 2013.
D. Mosk-Aoyama and T. Roughgarden. Worst-case efficiency analysis of queueing disciplines. In International Colloquium on Automata, Languages and Programming, pages 546557. Springer, 2009.
H. Moulin. Incremental cost sharing: Characterization by coalition strategy-proofness. Social Choice and Welfare, 16(2):279320, 1999. ISSN 1432-217X.
H. Moulin. The price of anarchy of serial, average and incremental cost sharing. Economic Theory, 36(3): 379405, 2008.
18

H. Moulin and S. J. Shenker. Strategyproof sharing of submodular costs: budget balance versus efficiency. Economic Theory, 18(3):511533, 2001.
N. Nisan, T. Roughgarden, E. Tardos, and V. V. Vazirani, editors. Algorithmic Game Theory. Cambridge University Press, 2007.
P. von Falkenhausen and T. Harks. Optimal cost sharing for resource selection games. Mathematics of Operations Research, 38(1):184208, 2013.
A Additional Discussion Regarding our Results
In this section we briefly address some more technical aspects regarding our results and its comparison to prior work. We first discuss the type of overcharging that we use in our mechanisms, and compare it to the types of overcharging that has been used in prior work. We then provide some (partial) justification and intuition behind some limits that we require on the number of enforcers, and the capacities of the capacitated constant cost functions.
Power of overcharging. At the core of our cost-sharing mechanism lies the ability of enforcers to penalize other agents through overcharging. In fact, the total amount of overcharging that our mechanism enforces can depend not only on the number of agents using a machine, but also on the actual set of agents (e.g., on whether one of them is an enforcer or not). This is in contrast to the way that some prior cost-sharing mechanisms have used overcharging, e.g., in Christodoulou et al. [2017, 2020]. In fact, the result of Christodoulou et al. [2017], showing that no resource-aware mechanism can achieve a PoA better than O( n), even if it uses overcharging, assumes that the amount of overcharging would depend only on the number of users, not the set of users of the corresponding machine. In light of this observation, one could argue that our mechanisms in this paper do not only leverage the additional information that they have, relative to prior-free resourceaware mechanisms; they actually also leverage the ability to introduce overcharging in a more flexible way.
Restriction on the number of enforcers. Assume that there was only one enforcer appearing in the system. Consider a number of agents such that in the allocation of the Delayed-OPT algorithm the last machine r is fully used, i.e., nr = tr agents are allocated in machine r. The enforcer should not have an incentive to deviate to machines full of regular agents and therefore, he should pay at most r-1. Moreover, he should pay more than r+1 so he deviates to machine r + 1 if it is full of regular agents. This is the reason we assume the monotonicity on the j values and we allocate the enforcer in machine r.
Consider now a number of agents such that in the allocation of the Delayed-OPT algorithm machine r is used by nr = tr - 1 agents. In the stable outcome, if we allocate the enforcer to any full machine j, he has an incentive to deviate to the last machine, make it full and pay r < j. Therefore, the only option is to allocate the enforcer to the last machine r. In order for such allocation to be an equilibrium, he should be charged with some r < r-1 so he has no incentive to deviate to prior machines full of regular agents. By considering now nr = tr - 2 and using the same arguments we can show that if the enforcer uses machine r, he should be charged with something strictly less than r-1. Similarly, for any nr we can show that the enforcer should be charged with an amount strictly less than r-1, and therefore the same should hold for nr = 1. But for nr = 1 the enforcer would be alone in r and hence, he should pay at least cr which leads to a contradiction. Considering enforcers in pairs resolves this issue and results in the existence of stable outcomes.
Restriction on the capacities. This was derived from the need to distinguish between the two cases in the proof of Lemma 5. First notice that the two enforcers should be together, otherwise they have an incentive to deviate to a machine full of regular agents. Suppose now that nr = 2 agents use the last machine r based on the allocation of the Delayed-OPT algorithm. If both enforcers were placed in machine r, one of
19

them should be charged with at least cr/2 and still have an incentive to deviate to a full machine. Therefore, for nr  2, in any equilibrium the enforcers do not use r.
One the other hand, in the case that nr = tr - 1, if no enforcer was placed in machine r, the lowest priority agent i in machine j that the enforcers use, may have an incentive to deviate to machine r. This could be the case because agent i is currently charged with Zj, which could possibly be greater than cr, where cr would be the maximum charge of agent i if he deviated to machine r; the reason is that r would become full. This means that for nr = tr - 1, in any equilibrium at least one enforcer should use machine r (this automatically means that tr should be different than 1).
Overall, the above two points indicate the restriction of tr - 1 > 2, which results in the requirement of tj  4 for all machines j.
B Missing Proofs from Section 4
B.1 Proof of Theorem 8
We next show how we construct a strategy profile that is a Nash equilibrium. Let A be the allocation according to the Delayed-OPT algorithm and let r be the last machine used by the Delayed-OPT algorithm. We will consider cases based on the excess of that machine, wr(A), and its load, r(A). For any other machine j = r note that j has 0 excess, i.e. wj (A) = 0.
For the construction of the Nash equilibrium we allocate the agents the same way as the Delayed-OPT algorithm does, but we need to carefully assign the enforcers and regular agents to the appropriate machines in order to ensure stability. The following assignment guarantees stability.
 If only one machine is used by the Delayed-OPT algorithm, then simply allocating any agent to this machine would be Nash equilibrium.
 If more than one machine is used by the Delayed-OPT algorithm, we distinguish between two cases based on the values of wr(A) and r(A).
 wr(A) = 1 and r(A) > 2: We allocate the two enforcers to machine r and the regular agents in a way such that the allocation coincides with A by ensuring that agents paying non-zero cost shares are the highest priority agents, with the lowest among them to be allocated to machine r. Obviously, regular agents paying 0 have no incentive to deviate. If an enforcer from machine r deviated to another machine j then the excess would increase to 1 and the enforcer would pay j(j (A)), but ,by the definition of the j(k) values, this is higher than his current payment of r(r(A)). Finally, regarding regular agents with non-zero cost shares, if they deviated to machine r they would have the highest priority and pay at least Zr(r(A)) which is more than their current charge. If they deviated to any machine j = r, they would increase the excess to 1 and pay Zj((j (A) + 1)) > Zr(r(A)).
 wr(A) = 1 or r(A) = 2: We allocate the two enforcers to machine r = r that is the last machine used by the Delayed-OPT algorithm before r.9 We allocate the regular agents in a way such that the allocation coincides with A by ensuring that agents paying non-zero cost shares are the highest priority agents with the two lowest among them (or the one lowest, if r(A) = 1) to be allocated to machine r. Similarly, regular agents paying 0 have no incentive to deviate. If an enforcer from machine r deviated to another machine j = r the same argument as before holds. If he deviated to machine r, he would be the only enforcer and the excess of r would become either 2 or 3, meaning that his charge would be Zr(r(A)). Finally, regarding regular agents with non-zero cost shares, the same arguments as before hold.
9We do not assign the enforcers to machine r, because in the cases that the excess is 1 and there are two enforcers or there is no regular agents, the enforcers pay a high cost.
20

C Missing Proofs from Section 5
C.1 Proof of Theorem 9
We show how we construct a strategy profile that is a Nash equilibrium similarly to Theorem 8. Let A be the allocation according to the Delayed-OPT algorithm and let r be the last machine used by the Delayed-OPT algorithm. We will consider cases based on the excess of that machine, wr(A) and its load, r(A).
If only one machine is used in the Delayed-OPT algorithm then simply allocating any agent to this machine would be Nash equilibrium. Next we consider separately the cases of no enforcer, one enforcer and at least two enforcers.
 Only regular agents
 If wr(A) = tr(r(A)) - 1, we assign agents according to A making sure that the highest priority agents are responsible for non-zero costs, i.e. if an agent has a cost share of 0 then all lower priority agents have a cost share of 0. Additionally we ensure that among the agents paying non-zero cost, the lowest priority agents are allocated to machine r; in other words, if wr(A) = 1 we ensure that the two highest priority agents in machine r have the lowest priority among agents with non-zero cost shares and if wr(A) = 1 we ensure that the one highest priority agent in machine r has the lowest priority among agents with non-zero cost shares. Every agent with 0 cost share has no incentive to deviate. Consider some agent with non-zero cost share. Deviating to some machine j = r would increase the excess to 1 causing the two highest priority agents to pay a non-zero cost share equal to Zr(r(A) + 1) > Zr(r(A)). Currently there is only one agent charged with non-zero cost share in machine j, and therefore the deviating agent would have one of the two highest priorities which means that the deviation is not profitable. If the agent deviated to r, since wr(A) = tr(r(A)) - 1 and the agent has higher priority than any agent in machine r, he would pay either Zr((r(A) + 1)) if wr(A) = 0 or Zr(r(A)) otherwise. In either case this is not a desirable deviation.
 If wr = tr(r(A)) - 1 then we may need to alter the allocation A as follows. Let j be the machine with the highest total cost cj(A) according to A. We move one agent from machine j to machine r (or do nothing if j = r). Similarly as above, we make sure that the highest priority agents are responsible for non-zero costs and the lowest priority of those are placed in machine j. We claim that this assignment is a Nash equilibrium. Naturally agents that have 0 cost share have no incentive to deviate. If an agent with non-zero cost deviates to some machine j = j will result in excess of 1 and will pay Zj (j (A) + 1) > Zr(r(A)). Deviating to machine j will result in 0 excess and since the agent has the highest priority will pay the total cost of the machine. But since this agent was already paying the total cost of another machine and the cost of machine j is the highest the deviation is not profitable.
 Exactly one enforcer
 If wr(A) = tr(r(A)) - 1, we put the enforcer to either machine 1 or 2 depending on which of them has excess of 0 (always one of them has) so that the enforcer pays 0. We allocate arbitrarily the rest of the agents according to A making sure that the highest priority agents are responsible for non-zero costs, ensuring that the lowest priority agents among them are allocated to machine r. Since the machine that the enforcer occupies (machine 1 or 2) has excess 0 the enforcer pays 0 and has no incentive to deviate. The same arguments as in the case of only regular agents can be used here in order to show that no regular agent has an incentive to deviate.
 If wr(A) = tr(r(A)) - 1 then we allocate the enforcer to either machine 1 or 2 depending on which of them has excess of 0; let f be that machine. We first assign the regular agents according
21

to A and then adjust the assignment as follows. Let j be the machine with the maximum total cost cj(A) according to A. If Zf (f (A)) > cj(A) we change j to be f . Then we move one agent from machine j to machine r, unless j = r, and similarly as above, we make sure that the highest priority agents are responsible for non-zero costs and the lowest priority among them are placed in machine j. The enforcer pays 0 since machine f has either excess 0 or excess tf (f (A) - 1) and therefore the enforcer has no incentive to deviate. If any agent deviated to some machine j = j would result in a cost Zj (j (A) + 1) > Zr(r(A)). Deviating to machine j would result in a cost share equal to either Zf (f (A)) if j = f or cj(A) otherwise. Since we picked j such that the cost share of deviating to be the maximum, the deviation is not profitable.
 At least two enforcers Let d be the number of enforcers that arrive and f be either machine 1 or 2 as long as it is different from r; f has excess of 0. We allocate the agents according to A and we assign the spots to enforcers and regular agents as follows:
 wr(A) = 1 and r(A) > 2 We allocate the enforcers in pairs, following their priority order from high to low, to machines with increasing j(j (A)), starting from machine r; in the case that d is odd, we assign only one enforcer to machine f . If there are more enforcers, we allocate one more enforcer based on the priority order to machine f in the case that d is odd and the rest of the enforcers are allocated arbitrarily.
 r(A)  2 Similarly as above, we allocate the enforcers in pairs as above but by ignoring machine r. If there are more enforcers we allocate the next pair10 to machine r if r(A) = 2 or the next enforcer to machine r if r(A) = 1. If there are more enforcers we allocate the next one to machine f if it has only one enforcer and the rest arbitrarily.
 wr(A) = 1 and r(A) > 2 We start allocating the enforcers as in the second case with the only difference that we if we allocate a pair of enforcers in machine r, we make sure that the highest priority pair of enforcers is allocated in r.
We allocate the regular agents arbitrarily making sure that the highest priority regular agents are charged with non-zero cost shares, ensuring that machine r has the lowest priority among them.
Obviously, agents paying 0 have no incentive to deviate.
If an enforcer deviated to machine r and the first case applies where wr(A) = 1 and r(A) > 2, then machine r has already the two highest priority enforcers and therefore the deviating enforcer would pay either Zr(r(A) + 1) or Zr(r(A)) both of which are not profitable. If an enforcer deviated to r and r(A)  2 then either he would be the only enforcer or r had no regular agent; in both cases the deviating enforcer would pay Zr(r(A)). If an enforcer deviated to r and r(A) > 2 but wr(A) = 1, the excess of r would become 2 and machine either r has already the two highest priority enforcers or it has no enforcer, meaning in both cases that the deviating enforcer would pay Zr(r(A)).
If an enforcer deviated to another machine j then the excess increases to 1. If there was already at least one enforcer then the deviating enforcer would pay Zj(j(A) + 1) > Zr(r(A)). If there was no other enforcer then the deviating enforcer would pay j(j(A)) but by our assignment this must be higher than the current payment of the enforcer.
Finally if any regular agent with non-zero cost share deviated to r, he would be the highest priority agent and pay Zr(r(A) + 1) or Zr(r(A)) and if he deviated to j = r he would increase the excess to 1 and pay Zj(j(A) + 1) > Zr(r(A)).
10Note that there would be a pair of enforcers because if d is odd, we would have allocated odd number of enforcers so far and if d is even we would have allocated even number of enforcers so far.
22

C.2 Proof of Lemma 13
We consider two cases with respect to the expected number of agents. If p|N |  1,

P[d  2] E [|S| | d  2]  E [|S| | d  2]  p|N \ D| + 2  p|N | + 2  3 .

Sp

Sp

If p|N | > 1,

P[d  2] E [|S| | d  2]]  (P[d = 0] + P[d = 1] + P[d = 2])(p|N \ D| + 2)
Sp
 ((1 - p)|D| + (1 - p)|D|-1p|D| + (1 - p)|D|-2p2|D|2)(p|N | + 2)  (1 + p|D| + p2|D|2)(1 - p)|D|-2(p|N | + 2)  3(p|N |)2(1 - p)|D|-2(p|N | + 2)  9(p|N |)3(1 - p)|D|-2



9(p|N

|)3(1

-

p)

log

1 (|N |p)3

log(1-p)

=

9(p|N

|)3

1 (p|N

|)3

=

9.

where

the

last

inequality

comes

from

the

fact

that

|D|

-

2

=

1

+

 log

1 (|N |p)3

log(1-p)

  log

1 (|N |p)3

log(1-p)

C.3 Proof of Theorem 14

Let S be a random set of arriving agents, G be the corresponding game, Eq(G) be the set of Nash equilibria for G and A be the allocation of the Delayed-OPT algorithm for the set S. Moreover, let d = |S  D| be a random variable depending on p = (p1, p2, . . . , p|N |). Similarly to the proof of Theorem 12, combining both Lemmas 10 and 11 we get that the expected ratio of the cost of the worst case equilibrium to the cost of the allocation of the Delayed-OPT algorithm is

E
Sp

maxsEq(G) C^(s) C(A)

= P[d  2] E [|S| | d  2] + P[d  3] E [d + 3 | d  3] .

Sp

Sp

(4)

W.l.o.g. assume p1  p2      p|N |. Then we designate the set of enforcers D to be the agents

associated with the highest probabilities such that

|D| i=3

pi

=

3 log n~

(we

always

designate

as

enforcers

the

two agents with the highest probability). We first bound the probability P[d  2] for the case that n~ > 1 as

follows.

23

P[d  2] = P[d = 0] + P[d = 1] + P[d = 2]

|D|

|D|

|D|

|D|

|D|

|D|

= (1 - pi) + pj 

(1 - pi) + pk 

pj 

(1 - pi)

i=1

j=1

i=1,i=j

k=1

j=1,j=k

i=1,i/ {j,k}

|D|

 |D|

|D|

|D|



 (1 - pi) 1 + pj + pk 

pj 

i=3

j=1

k=1

j=1,j=k



|D| i=3

(1

-

pi)

|D| - 2

|D|-2 

|N |

|N |

|N | 

1 + pj + pk  pj

j=1

k=1

j=1



1-

|D| i=3

pi

|D| - 2

|D|-2
 3n~2 = 3n~2

1

-

3 log n~ |D| - 2

|D|-2



3n~2e-3 log n~

=

3n~2

1 n~3

=

3 n~

,

where the second inequality comes from the AM/GM inequality:

k i=1

xi

1/k
 1/k

k i=1

xi ,

and

the

final

inequality follows from the fact that (1 - x/k)k  e-x. As a result, we can bound the first summand of (4)

by 9 as follows.

If n~  1, then

P[d  2] E[|S| | d  2]  E[|S| | d  2]  n~ + 2  3 ,

(5)

otherwise,

P[d



2] E[|S|

|

d



2]



3 n~

(n~

+

2)



9.

(6)

Similarly to Equation (2) we can bound the second summand of (4) as

|D|

|D|

P[d  3] E[d + 3 | d  3]  E[d | d  0] + 6  pi + 6  pi + 8 = 3 log n~ + 8

(7)

i=1

i=3

Combining Equations (4), (5), (6) and (7) completes the proof of the theorem.

24

