
# Claim Matching Beyond English to Scale Global Fact-Checking

[arXiv](https://arxiv.org/abs/2106.0853), [PDF](https://arxiv.org/pdf/2106.0853.pdf)

## Authors

- Ashkan Kazemi
- Kiran Garimella
- Devin Gaffney
- Scott A. Hale

## Abstract

Manual fact-checking does not scale well to serve the needs of the internet. This issue is further compounded in non-English contexts. In this paper, we discuss claim matching as a possible solution to scale fact-checking. We define claim matching as the task of identifying pairs of textual messages containing claims that can be served with one fact-check. We construct a novel dataset of WhatsApp tipline and public group messages alongside fact-checked claims that are first annotated for containing "claim-like statements" and then matched with potentially similar items and annotated for claim matching. Our dataset contains content in high-resource (English, Hindi) and lower-resource (Bengali, Malayalam, Tamil) languages. We train our own embedding model using knowledge distillation and a high-quality "teacher" model in order to address the imbalance in embedding quality between the low- and high-resource languages in our dataset. We provide evaluations on the performance of our solution and compare with baselines and existing state-of-the-art multilingual embedding models, namely LASER and LaBSE. We demonstrate that our performance exceeds LASER and LaBSE in all settings. We release our annotated datasets, codebooks, and trained embedding model to allow for further research.

## Comments

to appear in ACL 2021 as a long paper

## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{kazemi2021claim,
      title={Claim Matching Beyond English to Scale Global Fact-Checking}, 
      author={Ashkan Kazemi and Kiran Garimella and Devin Gaffney and Scott A. Hale},
      year={2021},
      eprint={2106.00853},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

## Notes

Type your reading notes here...

