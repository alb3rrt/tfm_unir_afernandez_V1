arXiv:2106.01790v1 [math.PR] 3 Jun 2021

STRONG SOLUTIONS OF A STOCHASTIC DIFFERENTIAL EQUATION WITH IRREGULAR RANDOM DRIFT

HELGE HOLDEN, KENNETH H. KARLSEN, AND PETER H.C. PANG

Abstract. We present a well-posedness result for strong solutions of onedimensional stochastic differential equations (SDEs) of the form

dX = u(, t, X) dt + 1 (, t, X)(, t, X) dt + (, t, X) dW (t), 2

where the drift coefficient u is random and irregular. The random and regular

noise coefficient  may vanish. The main contribution is a pathwise uniqueness result under the assumptions that u belongs to Lp(; L([0, T ]; H 1(R))) for any finite p  1, E |u(t) - u(0)|2H 1(R)  0 as t  0, and u satisfies the one-sided

gradient bound xu(, t, x)  K(, t), where the process K(, t) > 0 exhibits

an

exponential

moment

bound

of

the

form

E exp

p

´T
t

K(s) ds

t-2p for

small times t, for some p  1. This study is motivated by ongoing work

on the well-posedness of the stochastic Hunter­Saxton equation, a stochastic

perturbation of a nonlinear transport equation that arises in the modelling

of the director field of a nematic liquid crystal. In this context, the one-

sided bound acts as a selection principle for dissipative weak solutions of the

stochastic partial differential equation (SPDE).

1. Introduction

1.1. Main result. In this paper, we prove strong existence and pathwise unique-

ness for a class of one-dimensional SDEs with rough random drift u = u(, t, x)

and a noise coefficient  = (, t, x) that is random and possibly degenerate. We

fix a stochastic basis S = (, F , {Ft}t0, P) consisting of a complete probability space (, F , P) and a complete right-continuous filtration {Ft}t0. Moreover, we fix a standard Brownian motion W on S adapted to the filtration {Ft}t0.
We are interested in strong solutions X, i.e., P-almost surely continuous and

{Ft}t0-adapted stochastic processes X satisfying

(1.1)

dX

=

u(, t, X)

dt

+

1 4

2  (, t, X) dt + (, t, X) dW,

X(0) = x  R,

where



denotes

the

x-derivative

of



=

(, t, x),

so

that

1 4

2



=

1 2

x

.

For

a

deterministic, sufficiently regular  = (x), the SDE (1.1) can be written as

(1.2)

dX = u(, t, X) dt + (X)  dW,

where  denotes the Stratonovich differential.
The random non-smooth drift u is an {Ft}t0-progressively measurable process that belongs to Lp(; L([0, T ]; H 1(R))), for p  [1, ). The semi-normed vector space H 1(R) is defined as the subspace of functions in L(R) having a weak derivative in L2(R), with semi-norm |h|H 1(R) = xh L2(R). Note that this ensures that

Date: June 4, 2021. 2010 Mathematics Subject Classification. 60H10, 34F05. Key words and phrases. Stochastic differential equation, random drift, irregular drift, one-sided gradient bound, strong solution, well-posedness, existence, uniqueness. This research was partially supported by the Research Council of Norway Toppforsk project Waves and Nonlinear Phenomena (WaNP) (250070).
1

2

HOLDEN, KARLSEN, AND PANG

u

is

1 2

-H¨older

continuous

in

x,

which

is

not

enough

for

uniqueness.

We

additionally

assume that u satisfies the following one-sided gradient bound:

(1.3)

q(, t, x) := xu(, t, x)  K(, t), where K > 0,

and, for some p > 1,

(1.4)

^T E exp p K(s) ds


p,T -2p, for all   (0, 1).

Here we use the notation h1  h2 if h1  C()h2 for some constant C that may depend on , and non-negative functions h1, h2. Finally, we require a strong temporal continuity condition at t = 0:

(1.5)

lim
t0

E

|u(t)

-

u(0)|2H 1(R)

=

0.

The conditions imposed on the drift u are motivated by the work [9], in which u solves a nonlinear stochastic transport equation, and the one-sided gradient bound

(1.3) acts as a selection principle for dissipative weak solutions of this SPDE. We

will return to the motivation behind the key condition (1.3) later. Regarding the noise coefficient , let us discuss the case of a deterministic  first,

cf. (1.2). In this case, we assume that  = (x) satisfies

(1.6)

  C2(R), , , 2   L(R).

For such a , which is necessarily globally Lipschitz continuous and of linear growth,

the the

second derivative latter is when ,

122are

= ()2 +  bounded and

is bounded on R. An example ensuring  is compactly supported on R; then

2  1. The noise coefficient  is allowed to vanish in this work.

The main contribution of this paper is the treatment of the irregular random

drift u. However, it turns out that our methods are sufficiently flexible to allow for

a wider class of random noise coefficients  = (, t, x). The conditions defining

this class appear somewhat eloborate, but any deterministic  = (x) satisfying

(1.6) belongs to this class. First, we require that  = (, t, x) is progressively measurable (on S), and that , 2  are globally x-Lipschitz in the sense that

(1.7) |(, t, x) - (, t, y)| , 2  (, t, x) - 2  (, t, y)  (, t) |x - y| ,

where the progressively measurable process (t) = (, t) exhibits exponential moments,

(1.8)

^T E exp p 2(t) dt < , p > 0.
0

The exponential moments (1.8) are used to prove the existence of a solution X that belongs (locally) to Lp(; C([0, T ])) for any finite p  1. Dropping the requirement of arbitrary p-moments, one can relax (1.8) somewhat.
By Jensen's inequality, the condition (1.8) implies

(1.9)

^T E 2(t) dt < ,

0

which will be used on certain occasions. Finally, we will also need the following

technical conditions:

(1.10a)

2  (0)

< ;

L(×R)

(1.10b) 2  (t) - 2  (0)  L2( × R), uniformly on [0, T ];

(1.10c)

lim E 2  (t) - 2  (0) 2

= 0;

t0

L2(R)

SDES WITH IRREGULAR RANDOM DRIFT

3

(1.10d)

^T E |(t, 0)|p dt < ,

^T E

2  (t, 0) p dt < ,

p  [1, ).

0

0

Remark 1.1. It is possible to consider  = (, t, x) such that 2  satisfies the same conditions (1.3) and (1.5) as q. In this case, for our existence result, we must additionally assume (1.9). However, these conditions will fail to include the linear case (x) = a + bx, which originally motivated this study (see Section 1.3).

Our main result is the following theorem.
Theorem 1.1. Suppose u  Lp(; L([0, T ]; H 1(R))) satisfies conditions (1.3) and (1.5), and  satisfies (1.7), (1.8), (1.10a)­(1.10d). There exists a unique strong solution of (1.1).

The central part of Theorem 1.1 is the uniqueness assertion (cf. Theorem 2.2). We prove pathwise uniqueness by a careful estimation of the difference between two solutions, making essential use of the Tanaka formula, the exponential moment bound (1.3), and a recent stochastic Gronwall inequality [18, 21] (see Lemma 2.1 below). The exponential bound (1.3), along with (1.5), allows us to control the difference between the two solutions for short times t   (  1), which is the main challenge in demonstrating pathwise uniqueness. When   0, our uniqueness result recovers [21, Prop. A]. The detailed proof reported in Section 2 can be viewed as a surprisingly non-trivial stochastic extension of the ODE proof in [21].
In Section 3, we demonstrate existence of strong solutions to the SDE (1.1) (cf. Theorem 3.7). We approximate (1.1) using "one-sided truncations" {uR} of the drift u, and then make use of Krylov's theorem [10] for SDEs with random coefficients to solve (1.1) with u = uR. This produces a family of solutions {XR}, indexed by the truncation level R with R  . We show that {XR} constitutes a Cauchy sequence in the space L1/2(; C([0, T ])), with metric d(X1, X2) := E supt[0,T ] |X1(t) - X2(t)|1/2 (cf. Proposition 3.5) [1, 4.7.62]. The proof of this result proceeds along the lines of the uniqueness argument. The Cauchy property, along with (1.8) and R-independent p-moments of XR (cf. Lemma 3.3), implies the existence of a limit X  L2(; C([0, T ]) such that XR  X in L2(; C([0, T ]). It is straightforward to deduce that X is a solution of (1.1) (cf. Theorem 3.7).
Before discussing the literature on SDEs with irregular drift and the motivation behind our particular class of drift coefficients u, let us supply a relevant example of the process K arising in (1.3).

Remark 1.2. Consider the SDE (1.2) with deterministic  = (x) satisfying (1.6). According to Section 1.3 below, it makes sense to impose the condition

(1.11)

q(, t, x) = xu(, t, x)  C

+

1 2

e- 

´t
0

e-



L W (t) L W (s)

, ds

where C  0 is a constant. Let us verify that q satisfies (1.3). With

K(, t) := C +

1 2

e-  L W (t)

´t
0

e-



L W (s) ds

=

C

+

2

d dt

log

1^

t
e-



L W (s) ds

20

,

we find that I() := E exp

p

´T


K ( ,

s)

ds

satisfies

I() = epC(T -) E

´T
0

exp (-



L W (s)) ds

´
0

exp

(-



L W (s)) ds

2p
.

4

HOLDEN, KARLSEN, AND PANG

By the Cauchy­Schwarz inequality, I() T,p (I-)1/2(I+)1/2, where

^T

4p

I+ := E

exp -  L W (s) ds ,

0

^

I- := E

exp -  L W (s) ds

0

We estimate I- as follows:

-4p

I-  E

 min exp (-
s[0,]



L W (s))

-4p
.

-4p

E

 exp

-



L

max
s[0,]

W

(s)

= 2

^ -4p exp

2 0

4p



L

x

-

x2 2

dx

p, -4p,

where we have used that the law on [0, ) of maxs[0,] W (s) is equivalent to the law of |W ()| [15, Prop. III.3.7], for which we have

P |W (t)|  dx = 2 e-x2/(2t) dx. 2t

Similarly, I+ ,T,p 1. Hence I() p,T, -2p (for all finite p), i.e., (1.3) holds.

1.2. Background. Let us contextualise our result by discussing some previous studies on the well-posedness of SDEs. There is a very rich literature studying the existence and uniqueness of solutions, which begins with Ito^'s work on SDEs with globally Lipschitz coefficients (see [15, Chap. IX]). Often the Lipschitz condition is too strong. While weak existence is relatively easy to obtain for non-smooth coefficients (via, say, Girsanov's theorem), the construction of strong solutions is a more delicate matter. Strong solutions of SDEs with rough deterministic coefficients have been studied by many authors, beginning with [23, 17], and later [7, 8, 11, 6], to mention just a few examples. Most of these works use the Fokker­Planck PDE associated with the SDE, the Krylov estimate, and the Zvonkin transformation, which require the noise coefficient to be non-degenerate (uniformly elliptic). As a consequence, the results hold under very weak conditions on the drift, much weaker than in deterministic ODEs. For recent work on the well-posedness of SDEs with (Sobolev) rough coefficients and degenerate noise, see [2]. A probabilistic approach based on Malliavin calculus (nondegenerate noise) is developed in [12, 13]. Most of the cited articles assume additive noise. The works [19, 20] consider multiplicative noise under non-degeneracy and Sobolev regularity conditions on the noise coefficient. For a detailed study of one-dimensional SDEs, see the book [3].
The influential paper [5] studied stochastic regularisation in linear transport SPDEs with non-smooth velocity b, for which the characteristic equation is

(1.12)

dX = b(t, X) dt + dW.

Using the Ito^­Tanaka trick and solution regularity of the associated Fokker­Planck equation (a backward parabolic equation), they establish uniqueness of solutions to stochastic transport equations under a regularity condition on b that is weaker than in the DiPerna­Lions­Ambrosio theory of deterministic transport equations. To do so they prove the existence and uniqueness of solutions to the SDE (1.12) with minimal regularity assumptions on b using the short-time smooth flow of the associated backward parabolic equation. In [5, Sec. 6.2] they give negative examples showing that their results do not hold for equations with random drift b, a typical example of which is b = b(, t, x) = |x - W (t)|1/2  1. Whilst this b is locally in

SDES WITH IRREGULAR RANDOM DRIFT

5

H 1(R), xb does not satisfy a one-sided bound of the form (1.3). Motivated by [5], there were many additional works studying strong solutions of SDEs like (1.12) with non-smooth drift b, but almost all of them assume that b is deterministic.
Let us turn our attention to SDEs with random coefficients. In [10], Krylov established the existence and uniqueness of strong solutions to

(1.13)

dX = b(, t, X) dt + (, t, X) dW,

under some boundedness, monotonicity, and coercivity conditions on the random coefficients b and . His proof is based on a detailed convergence analysis of the Euler discretization scheme. We state Krylov's result as Theorem 3.1 below, and use it in Section 3 as a part of the existence proof. Because of an indispensable "logarithmic divergence" at t = 0, Krylov's theorem does not apply to the SDE (1.1) with u satisfying the one-sided gradient bound (1.3).
With a random drift b and   1 in (1.13), the work [4] partially recovered the results of [5] under an additional condition of Malliavin differentiability of b. The proof employed a Girsanov transformation idea [23], which extends the Ito^­Tanaka trick in [5], by considering a backward parabolic SPDE instead of the Fokker­ Planck PDE associated with X for a deterministic b. We also refer to [14] for a related result, which allows for the drift b(, t, x) = b1(t, x) + b2(, t, x), where the deterministic part b1 is measurable and of linear growth. In contrast, the random part b2 is sufficiently smooth in t, x and Malliavin differentiable in . These results were extended and sharpened in [22] to the SDE (1.13) with non-degenerate noise and random coefficients b and  satisfying similar (t, x)-regularity and Malliavin differentiability conditions. An illustrative example of random drift b covered by these recent works is b(, t, x) = f (t, x, W (t)) for a function f that is Lipschitz continuous in the last variable. The works [4, 14, 22] cannot handle the SDE (1.13) with random drift u  Lp(; L([0, T ]; H 1(R))) satisfying (1.3) and (1.5), even if we were to assume that (·) > 0. The proof of our Theorem 1.1 will not use ideas based on the associated backward SPDE, nor will we impose non-degeneracy or Malliavin differentiability conditions on our coefficients.

1.3. Motivation. We conclude this introduction with a brief motivation of the current study, which stems from our ongoing investigation into the uniqueness and dissipation properties of solutions to the stochastic Hunter­Saxton equation [9]

(1.14)

dq

+

x

(uq)

dt

-

1 2

q2

dt

+

x

(q)



dW

=

0,

xu = q.

Existence results, along with a specific distribution for wave-breaking (finite-time blowup and continuation), were derived for the nonlinear transport-type SPDE (1.14) in [9]. These results were derived under the condition that  is linear. Solutions to (1.14) were constructed from its characteristic equation, namely the SDE (1.1).
Using the Ito^­Wentzell theorem and the characteristic equation (1.2), the following Lagrangian formulation of (1.14) can be postulated:

(1.15)

dQ

=

-

1 2

Q2

dt

-

Q



dW,

Q(0) = q(0, x).

This SDE can be solved exactly as a stochastic Verhulst equation. The solution is

Q(t, x) =

1 q(0,x)

e-W (t)

+

1 2

´t
0

e-W (s)

. ds

In [9], we constructed the drift u directly in such a way that it was obvious that (1.1) was well-posed, and Q(t, x) = xu(t, X(t, x)) solved (1.15), providing us with a way to construct solutions to the stochastic Hunter­Saxton equation (1.14) along

6

HOLDEN, KARLSEN, AND PANG

characteristics. The solution to the SDE (1.15) identifies the dissipative solution of the SPDE (1.14) with an Oleinik-type (one-sided gradient) bound. This motivates our study of the SDE (1.1) with random drift u satisfying (1.11), and thus (1.3).
In an ongoing work, we study the uniqueness question for the stochastic Hunter­ Saxton equation (1.14). In that work, starting from a solution to the SPDE (1.14), we must derive properties of the solution to the characteristic equation (1.2). The well-posedness theorem in the present paper, which we believe is of independent interest, is needed as a part of that endeavour.

Remark 1.3. Finally, we present an example of a random drift u motivated by

(1.14), cf. [9]. Fixing a number c  R, let Z1(t) be the unique solution to

Z1(t)

=

c2 2

^t
0

Z1(s) ds

+

^t
0

c Z1(s) dW.

Fixing a number v0 > 0, we introduce

^t

exp -cW (s)

Z2(t) = Z1(t) + exp

cW (t) +

0

-v0

+

1 2

´s
0

exp

-cW (r)

ds dr

.

Finally, we set

exp -cW (t)

Z3(t) =

Z2(t) - Z1(t)

-v0 +

1 2

´t
0

exp

-cW (s)

. ds

Denote by T  = T () the (blow-up) time for which

^t lim exp -cW (s) ds = 2v0.
tT  0
Now we define the adapted and continuous drift coefficient u by

u(, t, x)

=

x- Z2(t)

Z1(t) - Z1(t)

Z3

(t)1[0,T



)×[Z1(t),Z2

(t))

+ Z3(t)1[0,T )×[Z2(t),).

Clearly, the gradient

exp -cW (t)

xu(t)

=

-v0

+

1 2

´t
0

exp

-cW (s)

ds 1[0,T )×[Z1(t),Z2(t))

blows up (xu  - while |u| remains bounded) as t  T  but evidently (1.11), and thus (1.3), holds. Besides, xu  Lp(; L([0, T ]; H 1(R))) for all p  1, and one can easily check that u obeys (1.5). Note that u(t)  0 for all t > T , which corresponds

to a dissipative solution of the stochastic Hunter­Saxton equation (1.14).

2. Pathwise uniqueness
In this section, we prove the uniqueness part of Theorem 1.1. We make essential use of the stochastic Gronwall inequality established recently by Scheutzow [16]. The proof in [16] relies on a martingale inequality of Burkholder that holds for continuous martingales. Below we recall a mild refinement due to Xie and Zhang [18, Lemma 3.8] which holds for general discontinuous martingales. The stochastic Gronwall lemma provides an upper bound for the pth moment of a process  that does not depend on the martingale part M of the inequality. It is this convenient "martingale uniformity" that forces p  (0, 1).
Lemma 2.1 ([18]). Fix a stochastic basis S. Let (t) and (t) be non-negative adapted processes, A(t) be a non-decreasing adapted process starting at A(0) = 0, and M be a local martingale with M (0) = 0. Suppose  is c`adla`g in time and satisfies the following pathwise differential inequality:
d   dt +  dA + dM on [0, T ].

SDES WITH IRREGULAR RANDOM DRIFT

7

For any 0 < p < r < 1 and t  [0, T ],

1/p

E sup p(s)
s[0,t]

 Cp,r

E exp

1

r -

r

A(t)

(1-r)/r

^t

E (0) + (s) ds ,

0

1/p

where Cp,r =

r r-p

.

We are now in a position to prove the following result.

Theorem 2.2 (Pathwise uniqueness). Suppose u  Lp(; L([0, T ]; H 1(R))) satisfies conditions (1.3) and (1.5), and  satisfies (1.7), (1.9)­(1.10c). Let X1 and X2 be two (strong) solutions of the SDE (1.1) on [0, T ], with T > 0 finite. Uniqueness holds in the following sense:

(2.1)

E sup |X2(t) - X1(t)|1/2 = 0.
t[0,T ]

Consequently, P    : X1(, t) = X2(, t) t  [0, T ] = 1, i.e., X1 and X2 are indistinguishable.

Proof. Let X1, X2, and T be as in the statement of the theorem. Without loss of generality, we assume throughout the proof that

(2.2)

|Xi(t)|  N, t  [0, T ], i = 1, 2,

for some N > 0. Indeed, introducing the stopping time

N := inf {t  [0, T ] : |X1(t)| > N or |X2(t)| > N } ,

we may replace Xi by X~i(t) := Xi t  N , which satisfies X~i(t)  N for all t  (0, N ]. The SDE for X~i becomes

X~i(t)

=

x

+

^ tN
0

u(s,

Xi(s))

ds

+

1 4

^ tN
0

2  (s, Xi(s)) ds

^ tN

+

(s, Xi(s)) dW (s)

0

^t =x+ u
0

s, X~i(s)

ds

+

1 4

^t
0

2



s, X~i(s)

ds

^t +  s, X~i(s) dW (s), t  [0, N ].

0

We can therefore apply the upcoming argument to X~2 - X~1 on [0, N ] instead of to X2 - X1 on [0, T ], to deduce that

E sup |X2 (t  N ) - X1 (t  N )|1/2 = 0,
t[0,T ]

for any finite N . By the continuity of X1 and X2, we have that N  T a.s. as N  . Therefore, sending N  , we arrive at (2.1).

In what follows, we consider X2 - X1 and assume (2.2). We have by linearity

d(X2

-

X1)

=

(u(t,

X2)

-

u(t,

X1))

dt

+

1 4

+ ((t, X2) - (t, X1)) dW.

2  (t, X2) - 2  (t, X1) dt

Set Y := |X2 - X1|. By the Tanaka formula,

dY

= sgn (X2 - X1)

d (X2 - X1) +

1 2

((t, X2) - (t, X1))2

dL0Y (t).

8

HOLDEN, KARLSEN, AND PANG

Since the local time L0Y at 0 of Y is supported on the zero set of X2 - X1, which is a subset of the zero set of (t, X2) - (t, X1), the local time correction term is zero. Set (t) := ((t, X2) - (t, X1)) /Y (t), which is a process uniformly bounded in absolute value by (t) of (1.9). Integrating in time yields

(2.3)

^t

^ X2(s)

Y (t) = sgn (X2(s) - X1(s))

0

X1 (s)

^t

+ (s)Y (s) dW (s),

0

q(s, y)

+

1 4

2  (s, y)

dy ds

where, in view of (1.9) and (2.2), the last term is a square-integrable martingale

starting from zero; see (1.11) for the definition q. Making use of (1.10b) and taking

the expectation, we obtain

^t

^ X2(s)

E Y (t) = E sgn (X2(s) - X1(s))

q(s, y) dy ds

0

X1 (s)

+

1 4

E

^t
0

sgn(X2(s)

-

X1(s))

^ X2(s)
X1(s)

2

 (s, y) dy ds

^t  E Y 1/2(s)
0

q(s)

L2 (s )

ds

+

1 4

2  (0)

^t E Y (s) ds

L(×R) 0

+

1 4

E

^t
0

Y

1/2(s)

2  (s) - 2  (0)

ds

L2 (s )

^t  (E Y (s))1/2
0

E

q(s)

2 L2 (s )

1/2

+

1 4

E

2  (s) - 2  (0) 2

1/2
ds

L2 (s )

+

1 4

2  (0)

^t E Y (s) ds,

L(×R) 0

by the Cauchy­Schwarz inequality. Here, s denotes the (random) interval

s = X1(s)  X2(s), X1(s)  X2(s) .

Taking the supremum over t  [0, ] on both sides gives

sup E Y (t)

t[0,]



 4

2  (0)

sup E Y (t) +  sup (E Y (t))1/2

L(×R) t[0,]

t[0,]

× sup
t[0,]

E

q(t)

2 L2 (t )

1/2

+

1 4

E

2  (t) - 2  (0) 2

1/2
.

L2 (t )

Fix



so

small

that

 4

2

 (0)


L(×R)

1 2

.

The first term on the right-hand

side can be absorbed by the term on the left-hand side. We then divide through by

sup (E Y (t))1/2 and square both sides, eventually arriving at

t[0,]

(2.4)

sup E Y (t)  82 sup E

t[0,]

t[0,]

q(t)

2 L2(R)

+

2  (t) - 2  (0) 2
L2(R)

2.

The estimate (2.4) allows us to control E Y (t) near t = 0. Using the one-sided bound (1.11), which deteriorates near t = 0 for every   , in combination with

SDES WITH IRREGULAR RANDOM DRIFT

9

the quadratic short-time estimate (2.4), we will next deduce a global estimate on

the entire time interval [0, T ].

Given the short-time estimate (2.4), we begin afresh from (2.3). Again let  be so

small that  2  (0)

 2, and t > . We can then write the inequality

L(×R)

^

^ X2(s)

Y (t) = sgn (X2(s) - X1(s))

q(s, y) dy ds

0

X1 (s)

^t

^ X2(s)

+ sgn (X2(s) - X1(s))

q(s, y) dy ds



X1 (s)

+

1 4

^t
0

sgn (X2(s)

-

X1(s))

^ X2(s)
X1 (s)

2

 (s, y) dy ds

^t

+ (s)Y (s) dW (s)

0

^t

^t

 (s) ds + Y (s) dA(s) + M (t),

0

0

where, for t  [0, T ],

and,

^t

M (t) := (s)Y (s) dW (s),

0

^ X2(t)

(t) := 1{t}sgn (X2(t) - X1(t))

|q(t, y)| dy,

X1 (t)

^t

(2.5)

A(t) := 1{s}K(s) + (s) ds,
0

for K(t) = K(, t) defined in (1.3), and because, from (1.7),

1 4

sgn

(X2(s)

-

X1(s))

^ X2(s)
X1 (s)

2

 (s, y) dy



1 4

Y

(s)(s).

The adapted process  is non-negative. Furthermore, using first the Cauchy­ Schwarz inequality and then the short-time estimate (2.4), we have

where

^t

^

E (s) ds  (E Y (s))1/2

E

q(s)

2 L2 (s )

1/2
ds

0

0

() :=

sup

E

q(s)

2 L2 (s )

s[0,]

1/2
.

2(),

We will show that () = o(1) as   0. Furthermore, A is a non-decreasing adapted process with A(0) = 0. From (1.4) and (1.8),

^t

^t

E exp (µA(t)) = E exp µ K(s) ds + µ (s) ds



0

^t

1/2

^t

1/2

 E exp 2µ K(s) ds

E exp 2µ (s) ds



0

 Cµ-2µ,

for a number µ such that 2µ = p, cf. (1.4). Finally, by (1.9) and (2.2), M is a (square-integrable) martingale with M (0) = 0.

10

HOLDEN, KARLSEN, AND PANG

Hence,

in

view

of

Lemma

2.1,

the

stochastic

Gronwall

inequality

with

p

=

1 2

and

a suitable r  (1/2, 1), we arrive at

(2.6)
2
E sup Y 1/2(s) 
s[0,t]

2r 2 2r - 1

E exp

1

r -

r

A

(t)

(1-r)/r ^ t

E

(s) dt

0

(1.3)
 CreC(t-)

-2r/(1-r) (1-r)/r 2()

(),

where Cr is a constant depending only on r and C is coming from (1.10a). Next we will show that the right-continuity condition (1.5) ensures that

(2.7)

lim sup E
0 t[0,]

q(t)

2 L2 (t )

=

0.

Clearly,

sup

E

q(t)

2 L2 (t )



2

sup

E

q(t) - q(0)

2 L2 (t )

+

2

sup

E

q(0)

2 L2 (t )

.

t[0,]

t[0,]

t[0,]

The first term on the right-hand side is bounded by 2 supt[0,] E |u(t) - u0|2H 1(R),

which tends to zero by (1.5). Since |t| = Y (t), (2.4) implies 1t  0, P-almost

surely, as t  0. We have E

q(0)

2 L2 (t )

=

E

1t

q(0)

2 L2(R)

 0 as t  0 by

the dominated convergence theorem, since q(0)  L2( × R). This proves (2.7).

Given (2.7) and (1.10c), it follows that () = o(1) as   0. As a result, we can

send   0 in (2.6) to reach the conclusion that E sups[0,t] Y 1/2(s) = 0, for any t  [0, T ], which implies the desired result (2.1).

Remark 2.1. We point out that whilst the result above holds for q(0)  L2(R), that is, q2(0)  L1(R), it fails for general q(t) for which the right-continuity limit limt0 q2(t) exists only in the sense of measures--but not in L1 as required by (1.5). An example comes from the deterministic Hunter­Saxton equation with an initial condition of the form q2(0) = 0. Although it is possible to define characteristics for this case, the characteristics emanating from x = 0 are not unique. The temporal
continuity condition (1.5) is essential.

3. Existence of solution
In this section, we establish the existence of strong solutions for the SDE (1.1) by approximating (1.1) using a truncated coefficient in a way that allows us to apply a well-posedness theorem of Krylov, reproduced below. We then show that the solutions to the approximating SDEs form a Cauchy sequence in an appropriate space, from which we recover a solution to our SDE.
We begin by recalling Krylov's theorem for the well-posedness of SDEs with random coefficients [10, Thm. 1.2].
Theorem 3.1. [10] Let S be a stochastic basis. Assume that for any   , t  0, and x  Rd, we have V (, t, x)  Rd×d and b(, t, x)  Rd, and that V and b are continuous in x for any (, t), and measurable in (, t). Moreover, assume
(i) boundedness: for any T,   [0, ),   , and any matrix norm V ,
^T sup |b(t, x)| + V (t, x) 2 dt < .
0 |x|<
(ii) monotonicity: for all t,   [0, ), x, y  B(0), the ball with radius  and centred at the origin, and   ,
2(x - y) · b(t, x) - b(t, y) + V (t, x) - V (t, y) 2  K~ (t, ) |x - y|2 .

SDES WITH IRREGULAR RANDOM DRIFT

11

(iii) coercivity: for all t,   [0, ), x  B(0), and   , 2x · b(t, x) + V (t, x) 2  K~ (t, 1) 1 + |x|2 ,

where K~ (t, ) is an adapted non-negative processes satisfying

(3.1)

^T K~ (t, ) dt < , for all   , T,   [0, ).

0

Let X0 be an F0-measurable Rd-valued random variable. Then the SDE

dX(t) = b(t, X(t)) dt + V (t, X(t)) dW (t), X(0) = X0

has a solution which is unique up to indistinguishability. Moreover,

(3.2)

E e-(t)X2(t)  x2 + 1,

^t (t) := K~ (s, 1) ds.
0

Remark 3.1 (Logarithmic divergence). The monotonicity condition in Theorem 3.1 can be viewed as a one-sided Lipschitz condition. In our motivating example, cf. Remark 1.2 and the one-sided gradient bound (1.11), we have

(x - y) (u(t, x) - u(t, y))  |x - y|2

C+

e-  L W (t)

1 2

´t
0

e-



L W (s) ds

.

Unfortunately, the factor multiplying |x - y|2 is not sufficiently well controlled at

t = 0 to ensure (3.1). There is the possibility of a logarithmic divergence in the

temporal integral. As a result, Theorem 3.1 does not apply to our problem.

Next we introduce an approximate SDE by truncating the gradient q = xu. The reason for doing so is explained in Remark 3.1. The strong well-posedness of these approximate SDEs then follows from Theorem 3.1.

Lemma 3.2. Suppose u  Lp(; L([0, T ]; H 1(R))) satisfies conditions (1.3) and (1.5), and  satisfies (1.7), (1.9)­(1.10c). Fix R > 0. Let uR be the process obtained from q := xu by one-sided truncation at level R:

(3.3)

^x

uR(t, x) :=

R(q(t, y)) dy,

-

R(q) :=

q, R,

if q  R, if q > R.

The SDE

(3.4)

dXR

=

uR(t, XR)

dt

+

1 4

2  (t, XR) dt + (t, XR) dW (t),

has a unique strong solution.

X(0) = x  R

Proof.

We

take

b=

uR +

1 4

2



= uR +

1 2





and

V

= ,

on Rd

with d = 1.

The

lemma follows from Theorem 3.1 once we have verified conditions (i), (ii), and (iii).

By assumption, E

u

p L([0,T ]×R)

E |u|pL([0,T ];H 1(R)) p 1 for all p  [1, ).

Of course, the same bound holds for uR:

(3.5)

E

uR

p L([0,T ]×R)

p 1.

From this bound (with p = 1),

sup |uR(, t, x)| < , for P-a.e.   .
t[0,T ]
|x|<

The Lipschitz condition (1.7) and (1.9), (1.10d) imply

^T sup

2

 (t, x) dt

^ 

T

0 |x|<

0

2  (t, 0) + (t) dt < .

12

HOLDEN, KARLSEN, AND PANG

Similarly, we have

^T

^T

sup 2(t, x) dt 

|(t, 0)| + (t) 2 dt < .

0 |x|<

0

Hence

^T sup
0 |x|<

uR(t,

x)

+

1 4

2  (t, x)

+ |(t, x)|2

which is (i).

For condition (ii), we have by (1.7) that

dt < ,

2(x - y)

uR(t, x)

-

uR(t,

y)

+

1 4

2  (t, x) - 1 4

2  (t, y)

+ |(t, x) - (t, y)|2

 2 |x - y|

^y
R(q(t, z)) dz
x

+

1 4

(t)

|x

-

y|

+ 2(t) |x - y|2

 2R + (t) + 2(t) |x - y|2 =: K~1(t) |x - y|2 ,

and K~1(t) is readily seen to satisfy (3.1) by (1.9). Finally, condition (iii) is a result of

2x

uR(t, x)

+

1 2

x

2

 (t, x) + 2(t, x)

 2 |x|

uR(t)

L(R)

+

1 2

|x|

2  (t, 0) + (t) |x| + |(t, 0)| + (t) |x| 2



uR(t) L(R) +

2

 (t, 0)

+

1 2

(t)

+

22(t,

0)

+

2(t)

1 + x2

=: K~2(t) 1 + x2 ,

where we have used (1.7), (1.9), and (1.10d). By (3.5), (1.9), and (1.10d), it follows that K~2 satisfies (3.1).
If we take K~ (t, ) = K~ (t) := K~1(t) + K~2(t) (so K~ is independent of , but
dependent on R), then all three conditions are verified.

The next lemma supplies R-independent estimates for XR in Lp(; C([0, T ])) for any finite p. Note carefully that the L2-estimate on XR(t) coming from Theorem 3.1, cf. (3.2), is useless because our K depends on R.

Lemma 3.3. Let XR be the solution constructed in Lemma 3.2. Assume in addition that (1.8) and (1.10d) hold. We have the uniform-in-R bound

(3.6)

E sup |X |p T,p |x|4p x,T,p 1,
t[0,T ]

p  [1, ).

Proof. We make frequent use of the following elementary inequalities, which hold for all r  2 and a, b,  > 0:

ar-1b



(r

- r

1)

ar

+

1 r-1

r

br

,

ar-2b2



(r

- r

2)

ar

+

2 (r-1)/2r

br

.

By Ito^'s formula, |XR(t)|2p = |x|2p + I1(t) + I2(t) + I3(t) + M (t), where

^t I1(t) = 2p sgn (XR) |XR|2p-1 uR(s, XR) ds,

0

I2(t)

=

p 2

^t
0

sgn (XR) |XR|2p-1

2

 (s, XR) ds,

^t I3(t) = p(2p - 1) |XR|2p-2 2(s, XR) ds,

0

SDES WITH IRREGULAR RANDOM DRIFT

13

^t M (t) = 2p sgn (XR) |XR|2p-1 (s, XR) dW (s).
0
Given (1.7), we readily derive the bounds

^t

I1(t)  t

uR

2p L([0,T ]×R)

+

C~p

|XR|2p ds,

0

^t I2(t)  C~p

(1 + (s)) |XR|2p +

2  (s, 0) 2p

ds,

0

^t

^t

I3(t)  C~p

1 + 2(s) |XR|2p ds + C~p |(s, 0)|2p ds,

0

0

for a constant C~p depending only p. From this we obtain the inequality

^t

|XR(t)|2p  |x|2p + t

uR

2p L([0,T

]×R)

+

Cp

2  (s, 0) 2p ds

0

^t

^t

+ Cp |(s, 0)|2p ds + Cp 1 + 2(s) |XR(s)|2p ds + M (t),

0

0

for another constant Cp depending only p. For any N > 0, introduce the stopping time

N := inf {t  [0, T ] : |XR(t)| > N } .

By the continuity of XR we have that N  T , P-almost surely, as N  . Clearly, for t  [0, T ],

|XR (t  N )|2p  |x|2p + (t  N )

uR

2p L([0,T ]×R)

^ tN
+ Cp
0
^ tN
+ Cp
0

2

 (s, 0)

2p

^ ds + Cp

tN

|(s, 0)|2p

ds

0

1 + 2(s) |XR(s  N )|2p ds + M (t  N ),

where t  M (t  N ) is a (square-integrable) martingale starting from zero.

Using

the

stochastic

Gronwall

inequality

(Lemma

2.1

with

exponents

1 2

and

2 3

),

1/2
E sup |XR (t  N )|p
t[0,T ]

^T

1/2

 E exp Cp

1 + 2(t) dt

0

×E

^T

|x|2p + T

uR

2p L([0,T ]×R)

+

2

 (s, 0) 2p

^ ds +

T

|(t, 0)|2p

dt

.

0

0

Given (1.10d) and (3.5), we conclude that
E sup |XR (t  N )|p
t[0,T ]

x,T,p 1.

Finally, sending N  , we arrive at (3.6).

To show that {XR} is a Cauchy sequence, we will require some compactness properties of uR as R  . Since uR is constructed from u in an explicit manner, this is not difficult to establish:

14

HOLDEN, KARLSEN, AND PANG

Lemma 3.4. Suppose u  Lp(; L([0, T ]; H 1(R))), for p  [1, ). Let uR be defined by the construction (3.3). We have the convergence

(3.7)

E sup |uR(t) - u(t)|2H 1(R) R- 0.
t[0,T ]

Moreover, for any finite p  1,

(3.8)

E

uR - u

p L([0,T ]×R)

R-

0.

Proof. We have that |uR(t) - u(t)|2H 1(R)) equals

^

^

IR(t) := |R(q(t, y)) - q(t, y)|2 dy = |R - q(t, y)|2 1{q(t,y)>R} dy

R

R

^  4 |q(t, y)|2 1{q(t,y)>R} dy.
R

Since E

q

2 L([0,T ];L2(R))

1 by assumption, we find that E IR(t) tends to zero as

R  0, uniformly in t  [0, T ]; hence (3.7) holds. We also have

^x

I~R(t) := |uR(t) - u(t)| =

R(q(t, y)) - q(t, y) dy

-



^x |R
-

- q(t, y)| 1{q(t,y)>R} dy



1 R

q(t)

2 L2(R)

.

By assumption, for all p  1 we have q  Lp(; L([0, T ]; L2(R))) and therefore E supt[0,T ] I~R(t) p R- 0. This proves the claim (3.8).

The next result, which is the main contribution of this section, reveals that {XR} is a Cauchy sequence in L1/2(; C([0, T ])).

Proposition 3.5. Under the assumptions of Lemma 3.2, suppose in addition that
(1.8) is true and also that (1.10d) holds with p = 2. The solutions XR to (3.4), which satisfy the R-independent bound E supt[0,T ] |XR(t)| T,x 1 (cf. Lemma 3.3), form a sequence {XR} that is Cauchy in L1/2(; C([0, T ])).

Proof. For N, R, R > 0, define

NR,R := inf {t  [0, T ] : |XR(t)| > N or |XR(t)| > N } .

Replace XR by X~R(t) := XR t  NR,R , which satisfies X~R(t)  N for all t  0, NR,R . The SDE for X~R becomes

^t X~R(t) = x + uR
0

s, X~R(s)

ds

+

1 4

^t
0

2



s, X~R(s)

ds

^t +  s, X~R(s) dW (s), t  0, NR,R .
0

Applying the upcoming argument to X~R-X~R on the time interval 0, NR,R , where X~R (·) := XR ·  NR,R , we deduce that for any  > 0 there exists R0 = R0() such that, for all t  [0, T ],

E sup XR s  NR,R - XR s  NR,R

1/2
< ,

for all R, R  R0,

s[0,t]

SDES WITH IRREGULAR RANDOM DRIFT

15

see (3.15). To conclude from this, one notices that NR,R  T as N  , uniformly in R, R. Indeed, the R-independent bound (Lemma 3.3) E sup |XR| 1 implies
t[0,T ]

P NR,R < T







P  sup |XR(t)| t[0,NR]



N,

NR

<

T



1 N

E sup |XR(t)|
t[0,T ]



0,

as N  , uniformly in R. Hence, NR,R  T as N  , uniformly in R, R. Given the preceding discussion, in what follows, there is no loss of generality in
assuming that

(3.9)

|XR(t)| , |XR (t)|  N, for all t  [0, T ],

for some given N > 0, when seeking to establish that

Y (t) = YR,R (t) := |XR(t) - XR(t)| , R, R  [0, ),

satisfies the Cauchy property (3.15). The Tanaka formula gives

(3.10)

^t

Y (t) = sgn(XR - XR ) (uR(s, XR) - uR(s, XR )) ds

0

^t

+ sgn(XR - XR ) (uR(s, XR ) - uR (s, XR )) ds

0

+

1 4

^t
0

sgn(XR

-

XR )

2  (s, XR) - 2  (s, XR ) ds

^t

+ sgn(XR - XR ) ((s, XR) - (s, XR )) dW (s).

0

This is very similar to (2.3), except for the difference uR(s, XR ) - uR(s, XR ). First we seek to estimate Y (t) over a short time period t  [0, ]. In (3.10), as
in the previous section, we write

^t

sgn (XR - XR ) (uR(s, XR) - uR(s, XR )) ds
0

+

1 4

^t
0

sgn (XR

-

XR )

2  (s, XR) - 2  (s, XR ) ds

^t

^ XR(s)

= sgn (XR - XR )

R(q(s, y)) dy ds

0

XR (s)

+

1 4

^t
0

sgn (XR

-

XR )

^ XR(s)
XR (s)

2  (s, y) - 2  (0, y) dy ds

+

1 4

^t
0

sgn (XR

-

XR )

^ XR(s)
XR (s)

2

 (0, y) dy ds.

Estimating by the Cauchy­Schwarz inequality,

(3.11)

^t

Y (t)  sgn (XR - XR ) (uR(s, XR ) - uR (s, XR )) ds

0

^t

+ Y 1/2(s) q(s) L2(s) ds
0

+

1

^

t
Y 1/2(s)

2  (s) - 2  (0)

ds

40

L2 (s )

+

1 4

^t
0

^t

2  (0)

Y (s) ds + (s)Y (s) dW (s),

L(×R)

0

16

HOLDEN, KARLSEN, AND PANG

where (t) := ((t, XR) - (t, XR )) /Y (t) is a process bounded in absolute value by (t) of (1.9). Here, s denotes the (random) interval

s = XR(s)  XR (s), XR(s)  XR (s) .

Given (3.9), the last term in (3.11) is a square-integrable martingale starting from zero. Taking the expectation, and estimating as in the proof of Theorem 2.2,

E Y (t)  t E uR - uR L([0,t]×R)

^t + (E Y (s))1/2

E

q(s)

2 L2 (s )

1/2
ds

0

+

1 4

^t
0

(E

Y

(s))1/2

E

2  (s) - 2  (0) 2
L2 (s )

+

1 4

^t
0

2  (0)

E Y (s) ds.

L(×R)

1/2
ds

Taking form ab =

the12suaprem2umb

over t  [0, ],



1 4

a2

+ b2),

and applying we find

Young's

inequality

(in

the

sup E Y (t)   E uR - uR L([0,]×R)
t[0,]

+

1 4

sup E Y
t[0,]

(t)

+

2

sup E
t[0,]

q(s)

2 L2 (s )

+

1 16

sup E Y
t[0,]

(s)

+

2 4

sup E
t[0,]

2  (s) - 2  (0) 2
L2 (s )

+

 4

2  (0)

sup E Y (t).

L(×R) t[0,]

In

what

follows,

we

fix



so

small

that

1 4

+

1 16

+

 4

2

 (0)


L(×R)

1 2

.

Since

 and R, R are independent parameters, given (3.8) of Lemma 3.4, we can take

R0 = R0() so large that

(3.12)

E uR - uR L([0,]×R)  E uR - uR L([0,T ]×R)  5/2 = 2o(1), as   0,

for all R, R  R0(). This gives us

sup E Y (t)  22

3/2 + sup E

q(s)

2 L2(R)

t[0,]

t[0,]

+ sup E 2  (s) - 2  (0) 2

.

t[0,]

L2(R)

Importantly, from (1.10c) and (2.7) we conclude that

(3.13)

sup E Y (t) = 2o(1), as   0.
t[0,]

As in the proof of Theorem 2.2, we estimate Y again (this time on the entire time interval [0, T ]). From (3.11), we arrive at the integral inequality

^t

^t

Y (t)  (s) ds + Y (s) dA(s) + M (t),

0

0

SDES WITH IRREGULAR RANDOM DRIFT

17

where, for t  [0, T ],

^t M (t) := (s)Y (s) dW,
0
(t) := 1{t}Y 1/2(s) q(s) L2(s) + T

uR - uR L([0,T ]×R) ,

and, as in (2.5),

^t
A(t) := 1{s}K(s) + (s) ds.
0

Since we have not assumed an exponential moment bound for the difference uR - uR L([0,T ]×R), it becomes imperative to include this term as a part of  and not A. The process  is non-negative and, by (1.10c), (3.13) and (3.12), is controlled thus:

(3.14)

^t E (s) ds = 2o(1), as   0.
0

Now

we

apply

Lemma

2.1,

the

stochastic

Gronwall

inequality

with

p

=

1 2

and

a

suitable r 

1 2

,

1

.

In

view

of

(1.3)

and

(3.14),

2
E sup Y 1/2(t)  CreC(t-)-22o(1) = o(1),
s[0,t]

as   0.

Therefore, given any  > 0, we can find  = () and R0 = R0() := R()  R () such that, for all t  [0, T ],

(3.15)

E sup YR1,/R2 (s) < , R, R  R0.
s[0,t]

This concludes the proof of the proposition.

Proposition 3.5 implies convergence in probability.
Lemma 3.6. Under the assumptions of Lemma 3.2, suppose in addition that (1.8) is true and also that (1.10d) holds with p = 2. Then there exists a P-almost surely continuous and {Ft}t0-adapted stochastic processes X :  × [0, )  R such that

(3.16)

lim P sup |XR(t) - X(t)| >  = 0,

R

t[0,T ]

for all  > 0, for all finite T > 0.

Proof. By Chebyshev's inequality and Proposition 3.5, we obtain

P

sup |XR(t) - XR(t)| > 
t[0,T ]



1

E sup |XR(t) - XR (t)|1/2
t[0,T ]

R,R-

0,

so that {XR} is a Cauchy sequence in the space of continuous processes with respect to locally (in t) uniform convergence in probability. Since this space is complete, the lemma follows.

It remains to identify the limit X as a solution to the original SDE (1.1).
Theorem 3.7 (Existence of solution). Under the assumptions of Theorem 1.1, there exists a strong solution X to the SDE (1.1).

18

HOLDEN, KARLSEN, AND PANG

Proof. Fix a finite number T > 0. By Lemma 3.2, there exists a unique strong solution XR to the SDE (3.4), such that

XR(t)

=

x

+

^t
0

uR(s,

XR)

ds

+

1 4

^t
0

2

^  (s, XR) ds +

t
(s, XR) dW (s).

0

Let X be the limit process constructed in Lemma 3.6. Then

I (t)

:=

X

-

x

-

^t
0

u(s, X) ds

-

1 4

^t
0

2

^t  (s, X) ds - (s, X) dW (s)
0

= IR(1)(t) + IR(2)(t) + IR(3)(t) + MR(t),

where

^t IR(1)(t) = X(t) - XR(t), IR(2)(t) = (uR(s, XR) - u(s, X)) ds,
0

IR(3)(t)

=

1 4

^t
0

2  (s, XR) - 2  (s, X) ds,

^t

MR(t) = (s, XR) - (s, X) dW (s).

0

Because of the path continuity of X, it is enough to prove that I(t) = 0 P-almost surely, for any fixed t  [0, T ]. To this end, we will verify that

IR(1)(t), IR(2)(t), IR(3)(t), MR(t) R- 0, P-a.s.,

at least for some subsequence Rn  0 as n  . Since convergence in probability, cf. (3.16), implies almost sure convergence along
a subsequence, we have

(3.17)

sup |XRn (t) - X(t)| n- 0, P-a.s.,
t[0,T ]

which implies that IR(1n)(t)  0, P-almost surely, as n  . Given (3.8), we have that

uRn - u L([0,T ]×R) n- 0, P-a.s.

Using this and the P-almost sure bound

q

2 L([0,T ];L2(R))

<

,

we

obtain

^ t^ X

^t

IR(2n)(t) 

Rn (q(s, y)) dy ds + (uRn (s, X) - u(s, X)) ds

0 XRn

0

1/2
 T sup |XRn (s) - X(s)|
s[0,T ]

q

2 L([0,T ];L2(R))

1/2

+ T uRn - u L([0,T ]×R) n- 0, P-a.s.

By (1.7), (1.9), and (3.17),

^T

IR(3n)(t) 

(s) |XRn (s) - X(s)| ds

0

^T



(s) ds sup |XRn (s) - X(s)| n- 0,

0

s[0,T ]

P-a.s.

Recall the bound E supt[0,T ] |XR(t)| T,x 1, which holds uniformly in R (here we need (1.8) and (1.10d) with p = 2). Set S(t) := supnN sups[0,t] |XRn (s)|, which is bounded, P-almost surely. For N  [0, ), introduce the stopping time

N := inf {t  [0, T ] : S(t) > N } .

SDES WITH IRREGULAR RANDOM DRIFT

19

Clearly, P N < t  0 as N  . By (1.7), (1.9), (3.17) and the dominated convergence theorem,

^ tN

2

E

 (s, XRn(s)) -  (s, X(s)) dW (s)

0

^t = E 1[0,N ](s) | (s, XRn(s)) -  (s, X(s))|2 ds n- 0.
0

As a result, for any  > 0,

P |MRn (t)| >   P |MRn (t)| > , N  t + P N < t



1 2

E

^t
0

 (s, XRn (s)) -  (s, X(s))

2
dW (s) + P

N < t

.

Sending first n   and then N  , we conclude that MRn(t) n- 0 in probability, and therefore, along a further subsequence (not relabelled),

MRn (t) n- 0, P-a.s.

This completes the proof that X is a solution of the SDE (1.1).

References
[1] I. Bogachev. Measure Theory, Volume I. Springer-Verlag, Heidelberg, Berlin, 2007. [2] N. Champagnat and P.-E. Jabin. Strong solutions to stochastic differential equations with
rough coefficients. Ann. Probab., 46(3):1498­1541, 2018. [3] A. S. Cherny and H.-J. Engelbert. Singular Stochastic Differential Equations, volume 1858
of Lecture Notes in Mathematics. Springer-Verlag, Berlin, 2005. [4] R. Duboscq and A. R´eveillac. Stochastic regularization effects of semi-martingales on random
functions. J. Math. Pures Appl. (9), 106(6):1141­1173, 2016. [5] F. Flandoli, M. Gubinelli, and E. Priola. Well-posedness of the transport equation by sto-
chastic perturbation. Invent. Math., 180(1):1­53, 2010. [6] E. Fedrizzi and F. Flandoli. Pathwise uniqueness and continuous dependence of SDEs with
non-regular drift. Stochastics, 83(3):241­257, 2011. [7] I. Gyo¨ngy and N. Krylov. Existence of strong solutions for Ito^'s stochastic equations via
approximations. Probab. Theory Related Fields, 105(2):143­158, 1996. [8] I. Gyo¨ngy and T. Mart´inez. On stochastic differential equations with locally unbounded drift.
Czechoslovak Math. J., 51(126)(4):763­783, 2001. [9] H. Holden, K. H. Karlsen, and P. H. Pang. The Hunter­Saxton equation with noise. J.
Differential Equations, 270:725­786, 2021. [10] N. V. Krylov. On Kolmogorov's equations for finite-dimensional diffusions. In Stochastic
PDE's and Kolmogorov Equations in Infinite Dimensions (Cetraro, 1998), volume 1715 of Lecture Notes in Math., pages 1­63. Springer, Berlin, 1999. [11] N. V. Krylov and M. Ro¨ckner. Strong solutions of stochastic equations with singular time dependent drift. Probab. Theory Related Fields, 131(2):154­196, 2005. [12] F. Proske. Stochastic differential equations--some new ideas. Stochastics, 79(6):563­600, 2007. [13] O. Menoukeu-Pamen, T. Meyer-Brandis, T. Nilssen, F. Proske, and T. Zhang. A variational approach to the construction and Malliavin differentiability of strong solutions of SDE's. Math. Ann., 357(2):761­799, 2013. [14] O. Menoukeu-Pamen and L. Tangpi. Strong solutions of some one-dimensional SDEs with random and unbounded drifts. SIAM J. Math. Anal., 51(5):4105­4141, 2019. [15] D. Revuz and M. Yor. Continuous Martingales and Brownian Motion. Springer-Verlag, Berlin, third edition, 1999. [16] M. Scheutzow. A stochastic Gronwall lemma. Infin. Dimens. Anal. Quantum Probab. Relat. Top., 16(2):1350019, 4, 2013. [17] A. Y. Veretennikov. On the strong solutions of stochastic differential equations. Theory of Probability & Its Applications, 24(2):354­366, 1980. [18] L. Xie and X. Zhang. Ergodicity of stochastic differential equations with jumps and singular coefficients. Ann. Inst. Henri Poincar´e Probab. Stat., 56(1):175­229, 2020. [19] X. Zhang. Stochastic homeomorphism flows of SDEs with singular drifts and Sobolev diffusion coefficients. Electron. J. Probab., 16:no. 38, 1096­1116, 2011.

20

HOLDEN, KARLSEN, AND PANG

[20] X. Zhang. Strong solutions of SDEs with singular drift and Sobolev diffusion coefficients. Stochastic Process. Appl., 115(11):1805­1818, 2005.
[21] P. Zhang and Y. Zheng. Existence and uniqueness of solutions of an asymptotic equation arising from a variational wave equation with general data. Arch. Ration. Mech. Anal., 155(1):49­ 83, 2000.
[22] G. Zhao. SDEs with random and irregular coefficients. Preprint arXiv:2003.04436, 2020. [23] A. K. Zvonkin. A transformation of the phase space of a diffusion process that will remove
the drift. Mat. Sb. (N.S.), 93(135):129­149, 152, 1974.
(Helge Holden) Department of Mathematical Sciences, NTNU Norwegian University of Science and Technology, NO-7491 Trondheim, Norway
Email address: helge.holden@ntnu.no URL: https://www.ntnu.edu/employees/holden
(Kenneth H. Karlsen) Department of Mathematics, University of Oslo, P.O. Box 1053, NO-0316 Oslo, Norway
Email address: kennethk@math.uio.no
(Peter H.C. Pang) Department of Mathematical Sciences, NTNU Norwegian University of Science and Technology, NO-7491 Trondheim, Norway
Email address: peter.pang@ntnu.no

