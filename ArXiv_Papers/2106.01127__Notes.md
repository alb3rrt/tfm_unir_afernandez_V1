
# Towards Robust Classification Model by Counterfactual and Invariant Data Generation

[arXiv](https://arxiv.org/abs/2106.01127), [PDF](https://arxiv.org/pdf/2106.01127.pdf)

## Authors

- Chun-Hao Chang
- George Alexandru Adam
- Anna Goldenberg

## Abstract

Despite the success of machine learning applications in science, industry, and society in general, many approaches are known to be non-robust, often relying on spurious correlations to make predictions. Spuriousness occurs when some features correlate with labels but are not causal; relying on such features prevents models from generalizing to unseen environments where such correlations break. In this work, we focus on image classification and propose two data generation processes to reduce spuriousness. Given human annotations of the subset of the features responsible (causal) for the labels (e.g. bounding boxes), we modify this causal set to generate a surrogate image that no longer has the same label (i.e. a counterfactual image). We also alter non-causal features to generate images still recognized as the original labels, which helps to learn a model invariant to these features. In several challenging datasets, our data generations outperform state-of-the-art methods in accuracy when spurious correlations break, and increase the saliency focus on causal features providing better explanations.

## Comments

Accepted in 2021 CVPR

## Source Code

Official Code



Community Code

- [https://paperswithcode.com/paper/towards-robust-classification-model-by](https://paperswithcode.com/paper/towards-robust-classification-model-by)

## Bibtex

```tex
@misc{chang2021robust,
      title={Towards Robust Classification Model by Counterfactual and Invariant Data Generation}, 
      author={Chun-Hao Chang and George Alexandru Adam and Anna Goldenberg},
      year={2021},
      eprint={2106.01127},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

## Notes

Type your reading notes here...

