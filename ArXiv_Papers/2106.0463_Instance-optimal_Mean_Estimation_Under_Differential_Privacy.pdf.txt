Instance-optimal Mean Estimation Under Differential Privacy

arXiv:2106.00463v1 [cs.CR] 1 Jun 2021

Ziyue Huang, Yuting Liang, Ke Yi {zhuangbq,yliangbs,yike}@cse.ust.hk
Department of Computer Science Hong Kong University of Science and Technology

Abstract
Mean estimation under differential privacy is a fundamental problem, but worstcase optimal mechanisms do not offer meaningful utility guarantees in practice when the global sensitivity is very large. Instead, various heuristics have been proposed to reduce the error on real-world data that do not resemble the worst-case instance. This paper takes a principled approach, yielding a mechanism that is instance-optimal in a strong sense. In addition to its theoretical optimality, the mechanism is also simple and practical, and adapts to a variety of data characteristics without the need of parameter tuning. It easily extends to the local and shuffle model as well.

1 Introduction

Mean estimation is one of the most fundamental problems in statistics, optimization, and machine learning. However, privacy concerns forbid us from using the exact mean in these applications, and the problem of how to achieve the smallest error under a given privacy model has received considerable attention in the literature. Differential privacy (DP) is a rigorous mathematical definition for protecting individual privacy and has emerged as the golden standard in privacy-preserving data analysis nowadays, which has been deployed by Apple [17], Google [23], and Microsoft [18].

Given a data set D := {xi}i[n]  U d, where U = [u], i.e., each coordinate of the input vector

is an integer (real-valued coordinates can be handled by quantization; see remark 2), our goal is

to

obtain

a

differentially

private

estimation

M (D)

for

the

mean

f (D)

=

1
n

n i=1

xi

with

small

2

error M (D) - f (D) 2. Because f (·) has global 2 sensitivity GSf = du/n, the standard DP

mechanism just adds Gaussian noise scaled to GSf to each coordinate of f (D), which results in an 2 error proportional to du/n. This simple mechanism is worst-case optimal [29], but it is certainly undesirable in practice, as people often conservatively use a large u (e.g., u = 232) but the actual

dataset D may have much smaller coordinates. Instead, the clipped-mean estimator [1] (see Section

3.1 for details) has been widely used as an effective heuristic, but two questions remain unresolved:

(1) how to choose the clipping threshold C; and (2) if it can yield any optimality guarantees. We

answer these questions in a fairly strong sense in this paper.

1.1 Instance Optimality
As worst-case optimality is theoretically trivial and practically meaningless for the mean estimation problem when the global sensitivity is too large, one may aim at instance optimality. More precisely, let M be the class of DP mechanisms and let
Rins(D) := inf inf{ | Pr[ M (D) - f (D) 2  ]  2/3}
M M

Preprint. Under review.

be the smallest error any M can achieve (with constant probability) on D, then the standard definition of instance optimality requires us to design an M such that

Pr[ M (D) - f (D) 2  c · Rins(D)]  2/3

(1)

for every D, where c is called the optimality ratio. Unfortunately, for any D, one can design a trivial M (·)  f (D) that has 0 error on D (but fails miserably on other instances), so Rins(·)  0, which rules out instance-optimal DP mechanisms by a standard argument [22].
Since Rins(·) is unachievable, relaxed versions can be considered. The above trivial M exists because it is only required to work well on one instance D. Imposing higher requirements on M would yield relaxed notions of instance optimality. One natural requirement is that M should work well not just on D, but also on its neighbors, i.e., we raise the target error from Rins(D) to

Rnbr(D) := inf

sup inf{ | Pr[ M (D ) - f (D ) 2  ]  2/3}.

M M D :dham(D,D )1

Vahdan [36] observes that Rnbr(D) is exactly LSf (D), the local sensitivity of f at D, up to constant factors. However, LSf (·) may not be an appropriate target to shoot at, depending on what f is. For the MEDIAN problem, LSf (D) = 0 for certain D's and no DP mechanisms can achieve this error [34], while for mean estimation, LSf (D) = (GSf ) = ( du/n) for all D, so this relaxation turns instance optimality into worst-case optimality.
The reason why the above relaxation is "too much" for the mean estimation problem is that D may change one vector of D arbitrarily, e.g., from (0, . . . , 0) to (u, . . . , u). We restrict this. More precisely, letting supp(D) denote the set of distinct vectors in D, we consider the target error

Rin-nbr(D) := inf

sup

inf{ | Pr[ M (D )-f (D ) 2  ]  2/3},

M M D :dham(D,D )1,supp(D )supp(D)

namely, we require M to work well only on D and its in-neighbors, in which a vector can only be changed to another one already existing in D. Correspondingly, an instance-optimal M (w.r.t. the in-neighborhood) is one such that (1) holds where Rins is replaced by Rin-nbr.
We make a few notes on this notion of instance optimality: (1) This optimality is only about the utility of the mechanism, not its privacy. We still require the mechanism to satisfy the DP requirement between any D, D such that dham(D, D ) = 1, not necessarily one and its in-neighbors. (2) In general, a smaller neighborhood leads to a stronger notion of instance optimality. Thus, the optimality using in-neighbors is stronger than that using all neighbors, which is in turn stronger than worst-case optimality (i.e., D can be any instance), while the latter two are actually the same for the mean estimation problem. (3) For an instance-optimal M (by our notion), there still exist D, M such that M does better on D than M , but it is not possible for M to achieve a smaller error than the error of M on D over all in-neighbor of D. This is more meaningful than ranging over all neighbors of D, some of which (e.g., one with (u, . . . , u) as a datum) are unlikely to be the actual instances encountered in practice.

1.2 Our Results

To

design

an

M (D)

for

the

mean

function

f (D)

=

1 n

n i=1

xi

that

achieves

an

error

w.r.t.

Rin-nbr(D)

for all D, we need an upper bound and a lower bound. For the lower bound, we show that Rin-nbr(D) =

(w(D)/n), where w(D) := max1i<jn xi - xj 2 is the diameter of D. Thus, from the upper

bound side, it suffices to show that the mechanism's error is bounded by c · w(D)/n. This is achieved

in two steps. First, we use the clipped-mean estimator, but find the clipping threshold C that optimizes

its bias-variance trade-off, which is a certain quantile of the norms of the vectors in D. However, we

cannot use the optimal C directly, as it would violate DP. Thus, we use a simple binary search based

algorithm that can find any specific quantile privately with an optimal rank error. This results in a DP

mechanism with error O~( d/)·r(D)/n, where r(D) := maxi xi 2 and  is the privacy parameter (formal definition given in Section 2). To reduce the error from r(D) to w(D), in the second step, we

rotate and shift D into a D~ such that r(D~) = O(w(D)) w.h.p., and apply the clipped-mean estimator

(with our privatized optimal clipping threshold) on D~, leading to an error of O~( d/) · w(D)/n for

n = ~ ( d/). We also show that the optimality ratio c = O~( d/) is optimal, i.e., any mechanism

M (D) having error c · w(D)/n for all D must have c = ~ ( d/).

2

Our mechanism has the following applications: (1) It can be applied directly to statistical mean estimation, where the vectors in D are i.i.d. samples from a certain distribution and one would like to estimate the mean of the distribution (in contrast, the version defined above is referred to as empirical mean estimation). For concreteness, we show how this is done for the multivariate Gaussian distributions N (µ, ). The sample size-error trade-off of our mechanism matches the known optimal bound in the statistical setting [9]. More importantly, our mechanism requires only crude a priori bounds on µ and  (i.e., the error depends on these bounds logarithmically), while the existing mechanism [9] needs a constant-factor approximation of 1. The reason why our mechanism adapts well to  is exactly its instance optimality, that its error is proportional to w(D) for every D. (2) By simply changing the primitive operations, our mechanism easily extends to the local and shuffle model of differential privacy. In doing so, we also extend the one-dimensional summation/mean estimation protocol in the shuffle model [6] to high dimensions.
In addition to the theoretical optimality, our mechanism is also simple and practical. Most importantly, there is no (internal) parameter to tune. Yet, our experimental results demonstrate that our mechanism outperforms the state-of-the-art algorithm [9] with the best parameters tuned for each specific setting.
1.3 Related Work
Asi and Duchi [5] recently initialized the study on instance optimality under DP. They propose two ways to relax (equivalently, strengthen the requirement on M ) the strict instance optimality, which is unachievable. The first is to require M to be unbiased. This is not appropriate for mean estimation, since many estimators, including clipped-mean, is not unbiased. The second is to require M to work well over all the r-distance neighbors of D for r  1. Thus, their optimality is weaker than using Rnbr(·), hence not appropriate for the mean estimation problem (i.e., their optimality is the same as worst-case optimality). Instance optimality has not been studied in the local or shuffle model; existing protocols in these two models [8, 20, 6] all have errors proportional to the global sensitivity.
How to choose the clipping threshold C for the clipped mean estimator has been extensively studied [3, 4, 35, 33], but existing methods do not offer any optimality guarantees. In particular, Andrew et al. [4] also use a quantile (actually, median) as C, but as we shall see, median is actually not the optimal choice. Furthermore, they use online gradient descent to find a privatized quantile, which does not have any theoretical error guarantees.
In the statistical setting, where the data are i.i.d. samples from some specific distribution, there are numerous methods [27, 9, 28, 30] that can avoid an error proportional to the global sensitivity, by exploiting the concentration property of the distribution. In particular, Biswas et al. [9] provide a simple and practical mechanism for multivariate Gaussian data. However, their method needs a constant-factor approximation of , while our method works with an unknown . They also provide a DP mechanism to estimate , but it does not guarantee a constant-factor approximation. Furthermore, estimating  first would consume the privacy budget from the mean estimation problem itself. In the local model, the algorithm in [24] uses a quantile estimation procedure based on binary search as a subroutine for one-dimensional Gaussian data.
Very recently, the relationship between the error of mean estimation and the diameter of the dataset has been exploited in [16] for low-communication protocols, but they do not consider privacy. Our DP protocols in the local and shuffle models have communication cost O~(d) per user (we do not state the communication costs in the theorems as they are not our major concern); it would be interesting to see if ideas from [16] can be used to reduce it further.
2 Preliminaries
2.1 Differential Privacy in the Central Model
Definition 1 (Differential Privacy (DP) [22]). For  > 0 and   0, a randomized algorithm M : X n  Y is (, )-differentially private if for any neighboring datasets D  D (i.e., dham(D, D ) = 1) and any E  Y,
Pr[M (D)  E]  e · Pr[M (D )  E] + .
1More precisely, it needs a ^ such that C1I ^ -1/2^ -1/2 C2I for constants 0 < C1 < C2.
3

Definition 2 (Concentrated Differential Privacy (zCDP) [11]). For  > 0, a randomized algorithm M : X n  Y is -zCDP if for any D  D ,
D(M (D)||M (D ))  
for all  > 1, where D(M (D)||M (D )) is the -Rényi divergence between M (D) and M (D ).

Note

that

(, 0)-DP

implies

2 2

-zCDP,

which

implies

(

2 2

+



2 log

1 

,

)-DP

for

any



>

0.

To

release a numeric function f (D) taking values in Rd, the most common technique for achieving

zCDP is by masking the result with Gaussian noise calibrated to the 2-sensitivity of f .

Lemma 1 (Gaussian Mechanism [11]). Let f : X n  Rd be a function with global 2-sensitivity GSf := maxDD f (D) - f (D ) 2. For a given data set D  X n, the mechanism that releases

f (D) + N

0,

GS2f 2

· Id×d

satisfies -zCDP.

Lemma 2 (Composition Theorem [11, 22]). If M is an adaptive composition of differentially private algorithms M1, M2, . . . , Mk, then

1. If each Mi satisfies (i, i)-DP, then M satisfies ( i i, i i)-DP.

2. For all , ,   0, if each Mi satisfies (, )-DP, then M satisfies ( , k +  )-DP, where

=

2k

log

1 



+

k(e

-

1).

3. If each Mi satisfies i-zCDP, then M satisfies ( i i)-zCDP.

2.2 Differential Privacy in the Local Model and Shuffle Model

The above definitions of DP and zCDP assume that D is handled by a trusted curator and only the output of the mechanism will be released to the public. Therefore, if the curator is corrupted, the privacy of all users will be breached. For weaker trust assumptions, the most popular models are the local model and the shuffle model, where each user holds their datum and locally privatizes (by some randomized mechanism) the message before sending it out for analysis. Hence, there is no third-party who has direct access to D. Formally, each user holds one datum xi  D, and the protocol interacts with the dataset using some local randomizer R : X  Y, and the privacy guarantee is defined over the transcript (all messages sent during the protocol). For simplicity, we only present the definition for one-round protocols; the privacy guarantee of multi-round protocols can be composed across all rounds by the composition theorem. The definition below uses zCDP; other DP notions can be defined similarly.
Definition 3 (Local Model (LDP)). A protocol using R(·) as the local randomizer satisfies -zCDP in the local model if for any x, x  X , any  > 1, D(R(x)||R(x ))  .
Due to the much stronger privacy requirement, the best accuracy guarantee of LDP protocols for several fundamental problems [13, 7, 19, 32] is a n-factor worse than that in the central model. The shuffle model is established on an intermediary level of trust assumption between the local model and the central model and aims for obtaining errors closer to the central model. The key feature of the shuffle model is a trusted shuffler S, which can permute all messages randomly before sending them to the analyzer, so that an adversary cannot identify the source of any message. Specifically, we consider the multi-message shuffle model, where each local randomizer R : X  Ym outputs m messages, and the transcript of the protocol P (D) is a random permutation of all mn messages. The following definition uses (, )-DP; the other two DP notions can also be defined similarly, but they do not offer the improvements that we want over LDP protocols.
Definition 4 (Shuffle Model). A protocol P satisfies (, )-DP in the shuffle model if for any D  D , and any set E  Ymn, Pr[P (D)  E]  e · Pr[P (D )  E] + .

3 Our Method

3.1 Clipped-Mean Estimator

In

the

rest

of

the

paper,

we

focus

on

the

mean

function

f (D)

=

1 n

n i=1

xi.

Since

GSf

is

large,

a

very natural idea is to clip each vector in its 2 norm by some threshold C. This reduces GSf to

4

2C/n, leading to the clipped-mean estimator [1]:

1n

C

2C 2

MC (D) = n min
i=1

,1 xi 2

· xi + N

0, n2 I

.

(2)

Lemma 3. For any given C, MC(D) satisfies -zCDP, and has an expected 2 error at most

1n

C 2d

E [ MC (D) - f (D) 2]  E(C; D) := n

max{ xi 2 - C, 0} + n ·

. 

i=1

Proof. The privacy guarantee easily follows from Lemma 1. The error of MC(D) is composed

of two parts: the bias from clipping and the (square root of the) variance from the Gaussian noise

N (0, 2C2/(n) · I). Because the 2 clipping does not change the direction of the input vector, the

bias

introduced

by

clipping

is

at

most

1 n

i max{ xi 2 - C, 0}. The variance introduced by the

Gaussian noise is at most C2/n2 · 2d/ by Jensen inequality.

An important remaining question is how to set the clipping threshold C. Setting it too low will result in a large bias, while setting it too high will introduce a large amount of noise. We show how to choose the optimal C to balance this bias-variance trade-off. It is easy to see that the error E(C; D) is a convex function w.r.t. C, thus the optimal C can be found by setting the derivative of E(C; D) to zero, i.e.,

E(C; D) 1

1

C

= |{i  [n] | n

xi 2 > C}| - n ·

2d/ = 0.

Therefore, the optimal choice of C is the (n - 2d/)-th quantile of { xi 2}i[n].

3.2 Private Quantile Selection

However, we cannot use the optimal C directly, as it would violate DP. Instead, we find a privatized

quantile with small rank error. Specifically, for this problem, D consists of a sequence of ordered

integers 0  x(1)  · · ·  x(n)  u. We would like to design a DP mechanism that, for a given

m,

returns

an

x

(which

is

not

necessarily

an

element

in

D)

such

that

x(m- )



x



x(m+

2 )

w.h.p.

Here  is referred to as the rank error. Existing methods on private range counting queries [12, 21]

can be used for this purpose, but they actually find all quantiles, which is an overkill. Instead, we use

a simple binary search algorithm [26, 15], which not only simplifies the algorithm, but also reduces

the rank error (by polylog(u) factors) to nearly optimal. Our algorithm PrivQuant makes use of a

function NoisyRC([a, b], D) that returns a noisy count of |D  [a, b]|.

Algorithm 1 DP Quantile Selection by Binary Search; PrivQuant

Input: the data set D : 0  x(1)  · · ·  x(n)  u; m  [n].

Output: a DP approximation to x(m).

1: left  0, right  u

2: while left < right do

3: mid  (left + right)/2

4: c~  NoisyRC([0, mid], D)

5: if c~  m then

6:

left  mid + 1

7: else

8:

right  mid

9: return (left + right)/2

The following lemma is straightforward: Lemma 4. If |NoisyRC([0, mid], D) - |D  [0, mid]||   for every call to NoisyRC([0, mid], D), then Algorithm 1 returns a quantile with rank error  .
2Define x(j) = 0 for j < 1 and x(j) = u for j > n.

5

In the central DP model, we simply use NoisyRC([0, mid], D) = |D  [0, mid]| + N (0, log u/(2)).

Theorem 1. The algorithm PrivQuant preserves -CDP, and it returns a quantile with rank error 

with probability at least 1 -  for  =

log

u

log

log 

u /(2).

Proof. It is clear that the range query |[0, mid]  D| has sensitivity 1, thus adding noise drawn from

N (0, log

u/(2))

preserves

 log

u

-CDP

for

each

invocation.

Because

there

are

log u

iterations

in

the

while-loop, the privacy guarantee follows from the composition theorem of CDP.

In the algorithm, we draw at most log u Gaussian noises whose absolute values are simultaneously bounded by  with probability 1 -  by a union bound. Conditioned upon this event, the theorem follows from Lemma 4.

In Section 4, we prove an ( log u/) lower bound (Corollary 2) on the rank error under zCDP for constant . Thus the algorithm is optimal up to just an O( log log u)-factor.

We can now use PrivQuant to find an approximately optimal clipping threshold. Specifically,

we invoke PrivQuant with  = /4 to find the max{n - max{ 2d/,  }, 1}-th quantile of

{

xi

2 2

}i[n].

They

are

integers

no

more

than

du2,

so

replacing

u

by

du2

in

Theorem

1

yields

a

rank

error of  = 2

log(du) log

log(du) 

/.

Then

we

set

C~

as

the

square

root

of

the

returned

quantile.

Finally, we return the clipped mean estimator MC~(D) with  = 3/4. The following theorem analyzes its error.

Theorem 2. Our mean estimation mechanism is -zCDP and has 2 error O( d/ +  ) · r(D)/n

with probability 1 - , where  = 2

log(du)

log

log(du) 

/.

Proof. The privacy guarantee easily follows from the composition theorem of zCDP. Next, we analyze the accuracy. By the rank error guarantee, at most 2d/ +  vectors are clipped by the threshold C~.
Each clipped vector has norm at most r(D), so the bias is at most ( 2d/ +  ) · r(D)/n. For the error due to the noise, we use the following tail bound of the multivariate Gaussian distribution:

Lemma 5 ([31]). If X  N (0, I), then Pr X 2  d + 2 d log(1/) + 2 log(1/)  .

Thus, with probability 1 - , the norm of the noise is bounded by O

d + log

1 

·

nC~ 



O d/ +  · r(D)/n. This inequality requires C~  r(D), which holds as long as n >

max{ 2d/,  }. If this is not the case (note that checking this condition is DP as it does not involve D), we can just return 0, which trivially achieves error r(D)  O( d/ +  ) · r(D)/n.

3.3 Shifted-Clipped-Mean Estimator

To reduce the error from being proportional to r(D) to being proportional to w(D), we perform a

random rotation on D followed by a translation. The rotation is done by x^i := HDxi, where H is the

Hadamard matrix, D is a diagonal matrix whose diagonal entry is independently and uniformly drawn

from {-1, +1}. Note that for now we omit the normalization coefficient 1 so that each coordinate
d
of x^i is still an integer; we will apply the normalization to the final estimator instead. Then, for

each j  [d], we invoke PrivQuant with  = /(4d) to find an approximate median of {x^i}i[n]

along dimension j, denoted as c~j. Next, we shift the dataset to be centered around c~ = (c~1, . . . , c~d),

obtaining D~ = {x~i := x^i - c~}i[n]. Note that c~ has integer coordinates, so does x~i. Finally, we apply

the clipped-mean estimator in Theorem 2 with 

=

3 4



on

D~,

obtaining

an

estimation

y~,

and

return

y := ( 1 HD)-1 1 (y~ + c~) as the mean estimator over D.

d

d

Theorem 3. Set  =

log(du)

log

d

log(du) 

/

and

assume

n

=

 ( d).

Our mean estimation

mechanism is -zCDP, and has 2 error O (

d/ +  )

log

nd 

· w(D)/n with probability 1 - .

6

Proof. The privacy guarantee follows from the composition theorem of -zCDP, as

d j=1

/(4d)

+

3/4 = . Next, we analyze the error. We need a lemma from [2], which intuitively says that the

random rotation "evenly spreads out" the norm to all the dimensions:

Lemma 6 ([2]). Let H and D be defined as above. Then, for any x  Rd and any  > 0,

1 Pr  HDx



x 

2

·

4d 2 log  .

d



d



Moreover, note that the transformation by 1 HD or ( 1 HD)-1 is orthogonal, so the

d

d

2 norm of

any vector will be preserved.

Applying Lemma 6 on xi - xj for all i, j  [n] and a union bound, we have maxi,j x^i - x^j  =

O(

log

nd 

)

· w(D)

with

probability

1

- /3.

Over

the

rotated

dataset

{x^i}i[n],

we

use

PrivQuant

to find an approximate median c~j along each dimension j  [d] with privacy parameter  = /(4d). By the rank error guarantee of PrivQuant (Theorem 1) and a union bound, if n = ( d),

we have mini x^i,j  c~j  maxi x^i,j for all j  [d] with probability 1 - /3. Note that the

length of this interval is | mini x^i,j - maxi x^i,j| = O(

log

nd 

)

·

w(D).

Thus the region

(c~1

±

O(

log

nd 

)

·

w(D),

.

.

.

,

c~d

±

O(

log

nd 

)

·

w(D))

contains

every

data

point

x^i,

hence

maxi

x^i -

c~ 2 = O(

d

log

nd 

)

·

w(D).

This

means

that

the

shifted

data

set

D~

=

{x^i

-

c~}i[n]

has

r(D~)

=

O(

d log

nd 

)

·

w(D).

Thus,

when

we

apply

the

clipped-mean

estimator

in

Theorem

2

over

D~

to

obtain its mean estimation y~, we have

(y~

+

c~)

-

1 n

i x^i 2 = O((

d/ +  )

d

log

nd 

)

·

w(D)/n.

Finally, we use y = ( 1 HD)-1 1 (y~ + c~) as the mean estimation for D, and conclude that

d

d

1

y- n

xi =

i

2

1

-1 1

1

 HD d

· d

(y~ + c~) - n

x^i
i

=O
2

nd w(D)

d/ +  log ·

.



n

Remark 1. The Hadamard transform requires d to be some power of 2. If this is not the case, we

can pad each xi with extra 0's to dimension d¯ = 2 log d , denoted as x¯i. If there is an estimation y¯ for

1 n

i

x¯i,

we

discard

the

last

d¯-

d

coordinates

of

y¯

to

obtain

y

as

the

estimation

for

1 n

i xi. Then,

we have y - i xi/n 2  y¯ - i x¯i/n 2, since the last d¯- d coordinates of each x¯i are 0. The

padding does not change w(D), so Theorem 3 still holds.

Remark 2. For a dataset with real coordinates bounded by R (in absoluate value), one can quantize each coordinate to an integer using bucket size / d, for any 0 <  < R, and then apply our algorithm over an integer universe of size u = 2R d/. This just brings an additive  error to the error bound of Theorem 3.

3.4 Statistical Mean Estimation
Suppose D consists of i.i.d. samples drawn from the multivariate Gaussian distribution N (µ, ), and we wish to estimate µ, assuming a priori bounds µ 2  R and m2 inI  m2 axI. Note that in the statistical setting, the privacy requirement should be satisfied between any two neighboring instances (not i.i.d.), but utility is analyzed under the i.i.d. assumption.
We first clip each sample xi  xi · min{R / xi 2, 1} where R := R + 2max d + log4n . Then all coordinates are bounded by R and we apply our mechanism with bucket size / d where  = min d/n. Privacy is straightforward, since two instances are neighbors after the R -clipping only if they are neighbors before the clipping. We analyze its error below:

7

Corollary 1. Set  = 

log(du) log

4d

log(du) 

/

where u

=

 2R n/min,

and

assume n

=

( d). Then our algorithm returns a µ^ such that with probability 1 - ,



µ^ - µ 2 = O

1/2 2

n d + log ·


1 + n

d log 

nd 

+



log

nd 

n

n

.

Proof. We may assume that no sample gets clipped by R , because by Lemma 5, with probability 1 -

/4, no sample has norm greater than R . The error consists of two parts, the statistical error f (D)-

µ 2 and the empirical error µ^ - f (D) 2. The former is bounded by O( 1/2 2

d

+

log

n 

·

1 n

)

with probability 1-/4 by standard statistical analysis. To bound the latter using Theorem 3, we note

that w(D)  O( 1/2 2

d

+

log

n 

)

with

probability

1

-

/4

by

standard

concentration

analysis

of the multivariate Gaussian distribution. Plugging this into Theorem 3 yields the error bound in the

corollary. Note that the additive  error due to quantization is dominated by O( 1/2 2 d/n).

Remark 3.


When



=

I

and

ignoring

logO(1)(

dnR 

·

max min

)

factors,

the

error

in

Corollary

1

becomes

O~

d n

+

dn

, matching the known optimal bound for Gaussian mean estimation [9].

4 Lower Bounds

In this section we establish the instance optimality of Theorem 3 via three lower bounds: (1) Rin-nbr(D) = (w(D)/n) for all D; (2) an ~ ( d/) lower bound on the optimality ratio, and (3) that the condition n = ~ ( d/) is necessary.
The first lower bound follows from an observation by Vadhan [36]:
Lemma 7 ([36]). For any f , any (, )-DP mechanism M , and any neighboring datasets D0  D1, there is a b  {0, 1} such that
1 1+ Pr[ M (Db) - f (Db) 2 < f (D0) - f (D1) 2/2] < 2 + 1 + e- .
Theorem 4. For  < 0.1,  < 0.1, Rin-nbr(D) = (w(D)/n).

Proof. By the definition of Rin-nbr(D), it suffices to show that there exists an in-neighbor D of D such that any M must incur error (w(D)/n) with probability at least 1/3 on either D or D . Let
xi, xj be the two vectors in D that attain the diameter, i.e., xi - xj 2 = w(D). We let D be the dataset obtained by changing xi to xj in D. It can be verified that f (D) - f (D ) 2 = w(D)/n for the mean function f . Then plugging D0 = D, D1 = D into Lemma 7 proves the theorem.

The lower bound on the optimality ratio is by the reduction from statistical mean estimation, for which there are known lower bounds:

Lcoevmarmiaanc8e([227I],)a. nFyo(r,a)G-DauPssmiaenchdainsitsrmibu(tfioornw=ithO~u(nkdn/o(wnnR)m)e)afonrµestim[a-tiRng,

R]d and known µ must incur 2

error ~ (d/(n)) with constant probability.

Theorem 5. Let M be any -zCDP mechanism for mean estimation that has 2 error c · w(D)/n with constant probability for any D = {xi}i[n] drawn from [u]d. If  < O~( d/n), then c = ~ ( d/).

Pmreocohfa. nLisemmmisa(8O~i(mpli)e,sa)-lDowP.eSr ibnocuendw(oDf )~ (=dO/~((nd)))

for for

-zCDP mechanisms, since a -zCDP Gaussian data N (µ, 2I) w.h.p., the

reduction in Corollary 1 converts a c · w(D/n) error for empirical mean to an error of O( d/n) +

c · w(D)/n = O(

d/n(1

+

c n

))

for

Gaussian

mean

estimation.

Comparing

with

the

above

lower

bound, we obtain

c 1+ 

= ~

n

d .
n

8

If  = O~( d/n), the RHS is ~ (1), then c = ~ ( d/).
For the lower bound on n, we consider a weaker problem (so the lower bound is stronger), which is the d-dimensional version of the interior point problem [10]: Given a dataset D = {xi}i[n] drawn from [u]d, the mechanism is only required to return a y  [u]d such that mini xij  yj  maxi xij for all j with constant probability. Theorem 6. If there exists a -zCDP mechanism that solves the interior point problem with success probability 2/3, then n = ( d log u/).
Proof. We need a lemma from [11] to bound the mutual information of a -zCDP mechanism.
Lemma 9 ([11]). Let M : X n  Y satisfy -zCDP. Let X be a random variable in X n. Then, I(X; M (X))  n2, where I(·; ·) denotes mutual information.
Take X = [u]d and let M be a -zCDP mechanism for the interior point problem. Let X be n copies of Z, which is uniformly drawn from X , i.e., X = {xi = Z}i[n]. Note that X is a random variable drawn from a universe of size |X |, and by the accuracy guarantee of M , Z can be recovered from M (X) with probability 2/3. Then, by the Fano's inequality, we have
I(X; M (X)) = H(X) - H(X | M (X)) = log |X | - H(X | M (X)) 2  log |X | - log 2 - log |X | = (log |X |). 3
Then the theorem follows from Lemma 9 and the fact that log |X | = d log u.
Given a quantile selection mechanism with rank error  , by finding the median, the 1-dimensional interior point problem can be solved when n = O( ). The following corollary then follows from Theorem 6. Corollary 2. Any -zCDP mechanism for the quantile selection problem must have rank error ( log u/).

5 Extension to the Local Model and Shuffle Model

Our mean estimation framework can be summarized as follows: (1) Given D = {x1, . . . , xn},

perform a random rotation, obtaining D^ = {x^i := HDxi}i[n]; (2) For each j  [d], find an

approximate median c~j of D^ along dimension j. Shift D^ to be centered around c~, obtaining D~ =

{x~i := x^i - c~}; (3) Find a clipping threshold C, which is the m-th quantile over the 2 norms of the vectors in D~. In the central model, the optimal choice is m = n - 2d/; (4) Perform

2 clipping over D~ using C, and obtain a mean estimator y~ of the clipped vectors. Finally, return

y = ( 1 HD)-1 1 (y~ + c~).

d

d

We note that each step has their counterparts in the local and the shuffle model: Step (1) is easy, where the randomized diagonal matrix D can be generated using public randomness, or sent from the aggregator to each user if public randomness is not available. Step (2) and (3) both rely on quantile selection, which have alternatives in the local model and shuffle model. Step (4) is also easy since all vectors have norms bounded by C. Below we elaborate on the details.

5.1 The Local Model

For step (4), the standard LDP mechanism is that each user applies the Gaussian mechanism (Lemma

1) with GS = 2C to inject noise to their clipped vector, sends it out, and the aggregator adds them up

and divides the sum by n. Thus, the bias of the clipped-mean estimator is the same as that in Lemma

 3, while the noise increases by a n-factor, to C

2d n

.

Correspondingly,

the

optimal

choice

of

C

becomes the m = (n - 2dn/)-th quantile.

9

For quantile selection in step (2) and (3), we use the LDP range counting protocol in [14]. This one-round protocol returns a data structure from which any range counting query can be answered.

Lemma 10 ([14]). There is a one-round -zCDP3 protocol in the local model that answers all range

counting queries within error O(

n/

log2

u

log

u 

)

with

probability

at

least

1

-

.

Putting things together, we obtain the following result:

Theorem 7. Set  =

n/ log2(du) log

du 

and

assume

n

=

 ( d).

There

is

a

3-round

-zCDP

mean estimation mechanism in the local model, achieving an 2-error of O (

dn/ +  )

log

nd 

·

w(D)/n with probability 1 - .

Proof. The proof is the basically the same as that of Theorem 2 and 3, except that m and  now take different values. Step (2), (3), and (4) each require a round.

5.2 The Shuffle Model
 We see that the error in the local model is worse than that in the central model by a n-factor. It turns out that in the shuffle model, we can match the result in the central model up to logarithmic factors, albeit with (, )-DP. This is mostly due to highly accurate summation and range counting protocols discovered recently for the shuffle model. We start with the summation protocol, restated for 1D mean estimation:

Lemma 11 ([6]). Given n real values D = {xi}i[n] where |xi|  C, there is an (, )-DP mean

estimation protocol in the shuffle model that returns a y such that E[(y - f (D))2] = O

C n

2

.

Directly result in

applying this an 2 error of

protocol in step (4) over O~(Cd/(n)). Below we

C -clipped show how

vtoecrteodrus caeloitngtoeOa~c(hCdimd/e(nsnio)n),

would hence

matching the error of the clipped-mean estimator in the central model. Given d-dimensional vectors

D = {xi}i[n] with 2 norm bounded by C (in the full algorithm, this would be the dataset after rotation, shifting, and clipping, but we abuse the notation and still use D), we apply another random

rotation x^i = HDxi. By Lemma 6, the coordinates of all x^i are bounded (in absolute value) by

C = O(C log(nd)) w.h.p. Next, we clip each coordinate to C and invoke Lemma 11 with privacy

parameter  = /

2

d

log

d 

,  = /d along each dimension. This yields a d-dimensional mean

estimator y^. Finally, we return y := ( 1 HD)-1 1 y^.

d

d

Lemma 12. Given D = {xi}i[n]  Rd where xi 2  C for all i, there is a oneround (, )-DP mean estimation protocol in the shuffle model that returns a y such that

Pr

y - f (D) 2  O

C n

log(nd)

log

d 

 2/3.

Proof. Privacy of this protocol follows directly from advanced composition (Lemma 2). Below we analyze its accuracy. Conditioned upon the event that all coordinates are bounded by C , which happens with probability 5/6, the C -clipping on each coordinate has no effects. Then

1

1

E[ y - f (D) 2] =  E d

y^ - n

x^i

i

2



2

1

1

=  E d

j

y^j - n x^i,j 
i

1 
d



2

1

E  y^j - n x^i,j 

j

i

3The protocol in [14] actually achieves (, 0)-DP, but we only need its zCDP version.

10

 1 · d · O d

C2

C

d

=O

d log(nd) log ,

n

n



where the first inequality follows from Jensen's inequality and the second inequality is by Lemma 11. Then the theorem follows from the Markov inequality.

Replacing the clipped-mean estimator with the protocol above, the optimal choice for C becomes

the m =

n-

1 

d

log(nd)

log

d 

-th quantile. For the NoisyRC queries in the algorithm

PrivQuant, we can use the following range counting mechanism [25] in the shuffle model:

Lemma 13 ([25]). There is a one-round (, )-DP protocol in the shuffle model that answers all

range counting queries within error O

1 

log2

u

log3

u 

log

log(u/) 

with probability 1 - .

Putting things together, we obtain the following result.

Theorem 8.

Set 

=

1 

log3.5(du)

log

d log(du) 

and

assume

n

=





d

log

d 

.

There is

a 3-round (, )-DP mean estimation mechanism in the shuffle model, achieving an 2-error of

O

1 

d

log

d 

+



log(nd) · w(D)/n with probability 2/3.

6 Experiments

102

Non-private

COINPRESS t = 1

COINPRESS t = 2

101

COINPRESS t = 3 COINPRESS t = 4

COINPRESS t = 10

CM

100

Shifted-CM

102

Non-private

COINPRESS t = 1

COINPRESS t = 2

101

COINPRESS t = 3 COINPRESS t = 4

COINPRESS t = 10

CM

100

Shifted-CM

102

Non-private

COINPRESS t = 1

COINPRESS t = 2

101

COINPRESS t = 3 COINPRESS t = 4

COINPRESS t = 10

CM

100

Shifted-CM

10-1

10-1

10-1

10-2 24

25

26

27

28

29

210

d

10-2 24

25

26

27

28

29

210

d

10-2 24

25

26

27

28

29

210

d

(a) µ = 0 · 1d.

(b) µ = 5 · 1d.

(c) µ = 10 · 1d.



Figure 1: 2 error vs. d for N (µ, Id×d), where n = 4000,  = 0.5, R = 50 d.

102

102

102

Non-private

Non-private

Non-private

COINPRESS t = 1

COINPRESS t = 1

COINPRESS t = 1

COINPRESS t = 2

COINPRESS t = 2

COINPRESS t = 2

COINPRESS t = 3

COINPRESS t = 3

COINPRESS t = 3

101

COINPRESS t = 4 COINPRESS t = 10

101

COINPRESS t = 4 COINPRESS t = 10

101

COINPRESS t = 4 COINPRESS t = 10

CM

CM

CM

Shifted-CM

Shifted-CM

Shifted-CM

100

100

100

2 error 2 error 2 error

2 error 2 error 2 error

10-10.0

0.1

0.2

0.3

0.4

0.5



10-10.0

0.1

0.2

0.3

0.4

0.5



10-10.0

0.1

0.2

0.3

0.4

0.5



(a) µ = 0 · 1d.

(b) µ = 5 · 1d.

(c) µ = 10 · 1d.



Figure 2: 2 error vs.  for N (µ, Id×d), where n = 4000, d = 128, R = 50 d.

We performed both statistical and empirical mean estimation experiments to evaluate our method.
For statistical mean estimation, we used multivariate Gaussian distributions with various µ and .
All algorithms are given the same R, min, max. We tried various R, while fixing min = 0.1 and max = R/ d. For empirical mean estimation, we used a real-world dataset, MNIST, which consists of 70,000 images of handwritten digits, where each image is represented by a vector of dimension d = 784 = 28 × 28. We quantized the values to integers [u] for u = 210. We measured the 2 error by taking the trimmed mean with trimming parameter 0.1 over 100 trials (as in [9]).

11

2 error 2 error 2 error

6.1 Results in the Central Model

For the central model, we compared with COINPRESS [9]. It starts with a given confidence ball of radius R that captures the mean, and iteratively refines the confidence ball. The number of iterations t is an important internal parameter in this algorithm; we tried t = 1, 2, 3, 4, 10 following their suggestion.

102

Non-private

COINPRESS t = 1

101

COINPRESS t = 2 COINPRESS t = 3

COINPRESS t = 4

COINPRESS t = 10

100

CM

Shifted-CM

10-1

10-2

102

Non-private

COINPRESS t = 1

COINPRESS t = 2

COINPRESS t = 3

101

COINPRESS t = 4 COINPRESS t = 10

CM

Shifted-CM

100

102

Non-private

COINPRESS t = 1

COINPRESS t = 2

COINPRESS t = 3

101

COINPRESS t = 4 COINPRESS t = 10

CM

Shifted-CM

100

10-3 24

25

26

27

28

29

210

d

10-1 24

25

26

27

28

29

210

d

10-1 24

25

26

27

28

29

210

d

(a) j2 = 0.1 for all j  [d].

(b) j2 = 10.

(c) j2  [0, 10].

Figure 3: 2 error vs. d for N (µ, ), where  = diag([12, 22, . . . , d2]), n = 4000,  = 0.5, R = 50 d.

102

102

102

Non-private

Non-private

Non-private

COINPRESS t = 1

COINPRESS t = 1

COINPRESS t = 1

COINPRESS t = 2

COINPRESS t = 2

COINPRESS t = 2

101

COINPRESS t = 3 COINPRESS t = 4

COINPRESS t = 10

COINPRESS t = 3

COINPRESS t = 4

COINPRESS t = 10

101

COINPRESS t = 3 COINPRESS t = 4 COINPRESS t = 10

CM

CM

CM

100

Shifted-CM

101

Shifted-CM

Shifted-CM

100 10-1

10-20.0

0.1

0.2

0.3

0.4

0.5



1000.0

0.1

0.2

0.3

0.4

0.5



10-10.0

0.1

0.2

0.3

0.4

0.5



(a) j2 = 0.1 for all j  [d].

(b) j2 = 10 for all j  [d].

(c) j2  [0, 10].

Figure 4: 2 error vs.  for N (µ, ), where  = diag([12, 22, . . . , d2]), n = 4000, d = 128, R = 50 d.

The results for statistical mean estimation are shown in Fig. 1 to 5, where the detailed parameter settings are given in the captions. The results show that our method (Shifted-CM) performs at least as well as COINPRESS with the best t across a variety of settings. In particular, when  is not identity Id×d, our method significantly outperforms COINPRESS and offers errors close to the non-private estimator as demonstrated in Fig. 3 and Fig. 4. Moreover, as seen from Fig. 3, 4, and 5, the best choice of t for COINPRESS is quite sensitive to  and R, making it difficult to tune in practice.

102

102

102

COINPRESS t = 1

COINPRESS t = 1

COINPRESS t = 1

COINPRESS t = 2

COINPRESS t = 2

COINPRESS t = 2

COINPRESS t = 3

COINPRESS t = 3

COINPRESS t = 3

COINPRESS t = 4

COINPRESS t = 4

COINPRESS t = 4

101

COINPRESS t = 10 Shifted-CM

101

COINPRESS t = 10 Shifted-CM

101

COINPRESS t = 10 Shifted-CM

Non-private

Non-private

Non-private

100

100

100

2 error 2 error 2 error

2 error 2 error 2 error

10-1

500

1000

1500

2000

R

10-1

500

1000

1500

2000

R

10-1

500

1000

1500

2000

R

(a) µ = 0 · 1d.

(b) µ = 5 · 1d.

(c) µ = 10 · 1d.

Figure 5: 2 error vs. R for N (µ, ), where  = diag([12, 22, . . . , d2]) and j2 u.a.r. [0, 10] for each j  [d], n = 4000,  = 0.5, d = 128.

Both our method and COINPRESS are translation-invariant. This can be verified from Fig. 1, 2, and 5, where the results are not effected by µ. However, the approaches taken are different: COINPRESS uses an iterative process, while we shift the dataset to be centered around an approximate center

12

2 error 2 error 2 error

2 error 2 error 2 error

point. In Fig. 1 and 2, we also include CM, our estimator without this shift operation, which is indeed affected by µ.

102

102

102

COINPRESS t = 1

COINPRESS t = 1

COINPRESS t = 1

COINPRESS t = 2

COINPRESS t = 2

COINPRESS t = 2

COINPRESS t = 3

COINPRESS t = 3

COINPRESS t = 3

101

COINPRESS t = 4 COINPRESS t = 10

101

COINPRESS t = 4 COINPRESS t = 10

101

COINPRESS t = 4 COINPRESS t = 10

Shifted-CM

Shifted-CM

Shifted-CM

100

100

100

10-1

10-1

10-1

10-2

2-3

2-2

2-1

20

21



10-2

2-3

2-2

2-1

20

21



10-2

2-3

2-2

2-1

20

21



(a) digit 0.

(b) digit 1.

(c) digit 2.



Figure 6: 2 error vs.  for various digits in MNIST, where d = 784, R = 50 d.

For empirical mean estimation on the MNIST dataset, we see in Fig. 6 that our method outperforms COINPRESS for various privacy levels. This means that this dataset, as with most real-world datasets, does not follow Gaussian distribution with an identity . The instance-optimality of our method is precisely the reason behind its robustness to different distributional assumptions, or the lack of.

108

108

108

107

107

107

106

106 105 27

50% 75% 85% 95% Ours 28 29 210 211 212 213 214 215 d
(a)  = 0.1.

106 105 27

50% 75% 85% 95% Ours 28 29 210 211 212 213 214 215 d
(b)  = 0.5.

50%

105

75%

85%

95%

Ours

104 27

28

29 210 211 212 213 214 215

d

(c)  = 1.

Figure 7: 2 error vs. d for clipping at various quantiles of the norms on a synthetic dataset.

One important component of our method is the optimal clipping threshold C, which is the (n -
2d/)-th quantile of the norms. Note that this depends on d and . Prior work [4] used a fixed quantile (e.g., the median). To better see the relationship between the optimal C and d, , we used a synthetic dataset D = {i · 1d}i[n] with n = 500 and tried different quantiles as the clipping threshold. The results in Fig. 7 confirm our theoretical analysis: The optimal C indeed depends on d and , while our choice attains the optimum.

6.2 Results in the Local Model
In the local model, there is no prior work on high-dimensional mean estimation. The existing method [24] works only for 1D data. To avoid disadvantaging their method, we used Gaussian distribution with an identity  (a  with different components would make their method even worse), and apply their method coordinate-wise. They adopt (, )-DP, so we compose across all dimensions by the advanced composition theorem. We also convert our -zCDP guarantee to (, )-DP for a fair comparison and set  = 10-9 in all the experiments.
Their method has two versions: KnownVar and UnkVar. The former requires  to be known, while the latter only requires   [min, max], the same as our method. The results are reported in Fig. 8 to 10, where we vary d, , and R, respectively, on a set of n = 105 samples generated from N (µ, Id×d). Our method even outperforms KnownVar, which is actually not a fair comparison.
However, compared with the central model, there is still a large gap from our LDP algorithm to the non-private mean, due to the inherent hardness of the local model. By our theoretical analysis, this gap can be greatly reduced in the shuffle model, once a practical implementation of the range counting protocol from [25] is available.

13

2 error

103

UnkVar

KnownVar

102

Non-private

Shifted-CM

101

103

UnkVar

KnownVar

102

Non-private

Shifted-CM

101

103

UnkVar

KnownVar

102

Non-private

Shifted-CM

101

2 error

2 error

100

100

100

10-1

10-1

10-1

10-2

10-2

10-2

10-3

21

22

23

24

25

d

10-3

21

22

23

24

25

d

10-3

21

22

23

24

25

d

(a) µ = 0 · 1d.

(b) µ = 5 · 1d.

(c) µ = 10 · 1d.

 Figure 8: 2 error vs. d for N (µ, Id×d) in the local model, where n = 105,  = 1, R = 20 d.

103

102

102

102

101

101

101

100

10-1

UnkVar

10-2

KnownVar

Non-private

Shifted-CM

10-3 0.5

1.0

1.5

2.0

2.5



2 error

100

10-1

10-2

UnkVar KnownVar

Non-private

Shifted-CM

10-3 0.5

1.0

1.5

2.0

2.5



2 error

100

10-1

10-2

UnkVar KnownVar

Non-private

Shifted-CM

10-3 0.5

1.0

1.5

2.0

2.5



(a) µ = 0 · 1d.

(b) µ = 5 · 1d.

(c) µ = 10 · 1d.

 Figure 9: 2 error vs.  for N (µ, Id×d) in the local model, where n = 105, d = 8, R = 20 d.

2 error

References
[1] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pages 308­318, 2016.
[2] Nir Ailon and Bernard Chazelle. The fast johnson­lindenstrauss transform and approximate nearest neighbors. SIAM Journal on computing, 39(1):302­322, 2009.
[3] Kareem Amin, Alex Kulesza, Andres Munoz, and Sergei Vassilvtiskii. Bounding user contributions: A bias-variance trade-off in differential privacy. In International Conference on Machine Learning, pages 263­271. PMLR, 2019.
[4] Galen Andrew, Om Thakkar, H Brendan McMahan, and Swaroop Ramaswamy. Differentially private learning with adaptive clipping. arXiv preprint arXiv:1905.03871, 2019.
[5] Hilal Asi and John C Duchi. Instance-optimality in differential privacy via approximate inverse sensitivity mechanisms. Advances in Neural Information Processing Systems, 33, 2020.
[6] Borja Balle, James Bell, Adria Gascón, and Kobbi Nissim. Private summation in the multimessage shuffle model. In Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security, pages 657­676, 2020.

103

UnkVar

KnownVar

102

Non-private

Shifted-CM

101

103

UnkVar

KnownVar

102

Non-private

Shifted-CM

101

103

UnkVar

KnownVar

102

Non-private

Shifted-CM

101

100

100

100

10-1

10-1

10-1

10-2

10-2

10-2

10-3

100

200

300

400

500

R

10-3

100

200

300

400

500

R

10-3

100

200

300

400

500

R

(a) µ = 0 · 1d.

(b) µ = 5 · 1d.

(c) µ = 10 · 1d.

Figure 10: 2 error vs. R for N (µ, Id×d) in the local model, where n = 105,  = 1, d = 8.

2 error 2 error 2 error

14

[7] Raef Bassily and Adam Smith. Local, private, efficient protocols for succinct histograms. In Proceedings of the forty-seventh annual ACM symposium on Theory of computing, pages 127­135, 2015.
[8] Abhishek Bhowmick, John Duchi, Julien Freudiger, Gaurav Kapoor, and Ryan Rogers. Protection against reconstruction and its applications in private federated learning. arXiv preprint arXiv:1812.00984, 2018.
[9] Sourav Biswas, Yihe Dong, Gautam Kamath, and Jonathan Ullman. Coinpress: Practical private mean and covariance estimation. Advances in Neural and Information Processing Systems, 2020.
[10] Mark Bun, Kobbi Nissim, Uri Stemmer, and Salil Vadhan. Differentially private release and learning of threshold functions. In 2015 IEEE 56th Annual Symposium on Foundations of Computer Science, pages 634­649. IEEE, 2015.
[11] Mark Bun and Thomas Steinke. Concentrated differential privacy: Simplifications, extensions, and lower bounds. In Theory of Cryptography Conference, pages 635­658. Springer, 2016.
[12] T.-H. Hubert Chan, Elaine Shi, and Dawn Song. Private and continual release of statistics. ACM Transactions on Information and System Security, 2011.
[13] TH Hubert Chan, Elaine Shi, and Dawn Song. Optimal lower bound for differentially private multi-party aggregation. In European Symposium on Algorithms, pages 277­288. Springer, 2012.
[14] Graham Cormode, Tejas Kulkarni, and Divesh Srivastava. Answering range queries under local differential privacy. Proceedings of the VLDB Endowment, 12(10):1126­1138, 2019.
[15] Graham Cormode and Shan Muthukrishnan. An improved data stream summary: the count-min sketch and its applications. Journal of Algorithms, 55(1):58­75, 2005.
[16] Peter Davies, Vijaykrishna Gurunanthan, Niusha Moshrefi, Saleh Ashkboos, and Dan Alistarh. New bounds for distributed mean estimation and variance reduction. In International Conference on Learning Representations, 2021.
[17] Apple Differential Privacy Team. Learning with privacy at scale. https: //machinelearning.apple.com/docs/learning-with-privacy-at-scale/ appledifferentialprivacysystem.pdf. December 2017.
[18] Bolin Ding, Janardhan Kulkarni, and Sergey Yekhanin. Collecting telemetry data privately. In NIPS, 2017.
[19] John Duchi and Ryan Rogers. Lower bounds for locally private estimation via communication complexity. In Conference on Learning Theory, pages 1161­1191. PMLR, 2019.
[20] John C Duchi, Michael I Jordan, and Martin J Wainwright. Local privacy, data processing inequalities, and minimax rates. arXiv preprint arXiv:1302.3203, 2013.
[21] Cynthia Dwork, Moni Naor, Omer Reingold, and Guy N Rothblum. Pure differential privacy for rectangle queries via private partitions. In International Conference on the Theory and Application of Cryptology and Information Security, pages 735­751. Springer, 2015.
[22] Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy. Foundations and Trends in Theoretical Computer Science, 9(3-4):211­407, 2014.
[23] Úlfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. Rappor: Randomized aggregatable privacy-preserving ordinal response. In Proceedings of the 2014 ACM SIGSAC conference on computer and communications security, pages 1054­1067, 2014.
[24] Marco Gaboardi, Ryan Rogers, and Or Sheffet. Locally private mean estimation: z-test and tight confidence intervals. In The 22nd International Conference on Artificial Intelligence and Statistics, pages 2545­2554. PMLR, 2019.
[25] Badih Ghazi, Noah Golowich, Ravi Kumar, Rasmus Pagh, and Ameya Velingker. On the power of multiple anonymous messages. In EuroCRYPT, 2021.
[26] Anna C Gilbert, Yannis Kotidis, S Muthukrishnan, and Martin J Strauss. How to summarize the universe: Dynamic maintenance of quantiles. In VLDB'02: Proceedings of the 28th International Conference on Very Large Databases, pages 454­465. Elsevier, 2002.
15

[27] Gautam Kamath, Jerry Li, Vikrant Singhal, and Jonathan Ullman. Privately learning highdimensional distributions. In Conference on Learning Theory, pages 1853­1902. PMLR, 2019.
[28] Gautam Kamath, Vikrant Singhal, and Jonathan Ullman. Private mean estimation of heavy-tailed distributions. In Conference on Learning Theory, pages 2204­2235. PMLR, 2020.
[29] Gautam Kamath and Jonathan Ullman. A primer on private statistics. arXiv preprint arXiv:2005.00010, 2020.
[30] Vishesh Karwa and Salil Vadhan. Finite sample differentially private confidence intervals. In 9th Innovations in Theoretical Computer Science Conference (ITCS 2018). Schloss DagstuhlLeibniz-Zentrum fuer Informatik, 2018.
[31] Beatrice Laurent and Pascal Massart. Adaptive estimation of a quadratic functional by model selection. Annals of Statistics, pages 1302­1338, 2000.
[32] Andrew McGregor, Ilya Mironov, Toniann Pitassi, Omer Reingold, Kunal Talwar, and Salil Vadhan. The limits of two-party differential privacy. In 2010 IEEE 51st Annual Symposium on Foundations of Computer Science, pages 81­90. IEEE, 2010.
[33] H Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. Learning differentially private recurrent language models. arXiv preprint arXiv:1710.06963, 2017.
[34] Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Smooth sensitivity and sampling in private data analysis. In Proceedings of the thirty-ninth annual ACM symposium on Theory of computing, pages 75­84, 2007.
[35] Venkatadheeraj Pichapati, Ananda Theertha Suresh, Felix X Yu, Sashank J Reddi, and Sanjiv Kumar. Adaclip: Adaptive clipping for private sgd. arXiv preprint arXiv:1908.07643, 2019.
[36] Salil Vadhan. The complexity of differential privacy. In Tutorials on the Foundations of Cryptography, pages 347­450. Springer, 2017.
16

