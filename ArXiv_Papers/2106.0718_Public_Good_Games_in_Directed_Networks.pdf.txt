arXiv:2106.00718v1 [cs.GT] 1 Jun 2021

Public Good Games in Directed Networks
CHRISTOS PAPADIMITRIOU and BINGHUI PENG, Columbia University
Public goods games in undirected networks are generally known to have pure Nash equilibria, which are easy to find. In contrast, we prove that, in directed networks, a broad range of public goods games have intractable equilibrium problems: The existence of pure Nash equilibria is NP-hard to decide, and mixed Nash equilibria are PPAD-hard to find. We define general utility public goods games, and prove a complexity dichotomy result for finding pure equilibria, and a PPAD-completeness proof for mixed Nash equilibria. Even in the divisible goods variant of the problem, where existence is easy to prove, finding the equilibrium is PPAD-complete. Finally, when the treewidth of the directed network is appropriately bounded, we prove that polynomial-time algorithms are possible.
CCS Concepts: · Theory of computation  Algorithmic game theory; Exact and approximate computation of equilibria; Network games.
Additional Key Words and Phrases: public goods game, network game, equilibrium computation.
ACM Reference Format: Christos Papadimitriou and Binghui Peng. 2021. Public Good Games in Directed Networks. In Proceedings of the 22nd ACM Conference on Economics and Computation (EC '21), July 18­23, 2021, Budapest, Hungary. ACM, New York, NY, USA, 23 pages. https://doi.org/10.1145/3465456.3467616
1 INTRODUCTION
A public good is a resource which, once produced, is available to all (non-excludability), and can be enjoyed collectively by many agents (non-rivalry1). Scientific knowledge [41], open-source software, vaccination for an infectious disease, volunteer work, information resources, and clean environment are fine examples of public goods. Since public goods can be produced at a cost and contribute to the utility of others, they enable a variety of strategic behaviors such as free-riding. Game theoretic formulations of public goods have been extensively studied by economists -- see [3] for a classical framework for the public goods problem within which a unique Nash equilibrium exists.
Networks are perfect arenas for public goods games [7]. Networks model the fact that a particular public good, such as a piece of software or protection due to the immunization of an individual, may not be accessible by all, but only by the neighbors of the node where it is produced. A node's utility then is an nondecreasing function of the goods in the neighborhood, minus the cost of the goods produced by the node. Almost all of the literature deals with the homogeneous case, where all nodes have the same two strategies (produce the common goods at a cost, or not) and the same utility function (see [44] for an exception); in fact, the nondecreasing functions max and sum are typically considered. In this paper, we assume that all nodes have the same utility (even though they have different circumstances due to network connectivity, and hence the game is not symmetric unless the graph is), and we consider very general utility functions. There is extensive work on
1Non-rivalry was called collective consumption by Paul Samuelson, who initiated the study of the subject [38].
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. EC '21, July 18­23, 2021, Budapest, Hungary © 2021 Association for Computing Machinery. ACM ISBN 978-1-4503-8554-1/21/07. . . $15.00 https://doi.org/10.1145/3465456.3467616

public goods in undirected networks (see the related work subsection), and the rough consensus seems to be that, in just about all variants of the problem (again, with the exception of [44]), pure Nash equilibria exist -- typically corresponding to independent or dominating sets of the graph -- and are easy to find.
Undirected graphs have limitations as models of utility transfer. The ability to enjoy the public goods produced by others is not necessarily symmetric -- for example, clean air in a neighboring city is of no use if that city is downwind; if my house is on a co-worker's way to work, then the good of carpooling to work produced by my co-worker benefits me, but not vice-versa; while social networks are often directed: Twitter, Instagram, Flickr, and others. There has been some work on public goods in directed networks, e.g. [32], where sufficient conditions for the existence of equilibria are developed. The general impression one gets from the literature is that the matter of equilibria in the directed case is more subtle.
This paper is a comprehensive exploration of the complexity of the equilibrium problem in public goods games on directed graphs.
The simplest and most widely studied variant of the problem is the indivisible case with the max utility: the decision a node faces is whether or not to produce the good; and a node does not need to produce the good if one or more of its predecessors have it. It turns out to be quite intricate. It is easy to see that a pure equilibrium may not exist (consider a directed odd cycle), and it turns out that it is NP-complete to decide if a pure equilibrium does exist. We give a simple reduction to that effect (Theorem 3.1).
We then generalize this NP-completeness result to a full complexity dichotomy of nondecreasing utility functions. We identify three families of utility functions that can be solved in polynomial time: The flat functions, the steep functions, and the alternating functions. The first two have trivial equlibria where all nodes abstain or all nodes produce the good, respectively. In the case of alternating functions, finding a pure Nash equilibrium is shown to be equivalent to solving a system of equations in F2. The main part of the proof entails showing that all other functions make the equilibrium problem NP-hard (Theorem 3.4).
Since pure equilibria in these games are fraught with non-existence and NP-completeness, can we find in polynomial time a mixed Nash equilibrium (guaranteed to exist by Nash's theorem)? We prove (Theorem 4.1) that this problem is PPAD-complete, even in the simplest case of the max utility; this is perhaps the most technically demanding proof in this paper. We reduce from the generalized circuit problem, proved to be PPAD-hard in [11, 37]. The reduction requires several new ideas, including the definition of a new kind of intermediate game -- in addition to several that already exist in this literature -- which we call the threshold game, and we believe is of interest in its own right. Finally, when the goods are divisible, the max case of the problem (the utility is the maximum of the neighbors minus the good's cost) is one where it can be seen through a simple averaging argument that a mixed equilibrium exists; we show that this too is PPAD-complete to find, this time by a reduction from mixed Nash equilibria in two-player win-lose games [1, 16].
All of our complexity results hold for sparse networks, with indegrees and outdegrees at most three. But how about networks that are tree-like in the sense of graph minors [35]? We show that, when the (underlying undirected) network has bounded treewidth, essentially all versions of the Nash equilibrium problem of network public goods games can be solved, or at least approximated arbitrarily close, in polynomial time. Our algorithm and techniques are inspired by [19] and [42], but several substantial adaptations and innovations are needed.
Our contributions. In summary, our main contributions are these:

· Sweeping intractability results for the equilibrium problem of public goods games in directed networks, including a novel PPAD-completeness proof through threshold games, an intriguing analysis of polynomial special cases for the pure equilibrium problem culminating in a precise P/NP-complete dichotomy, and even a very different PPAD-completeness proof for divisible goods.
· The formulation of public goods games in networks with a general objective function -- beyond the two functions treated in the literature, max and sum -- leading to a surprisingly rich and diverse family of problems (Section 3). In the discussion section we point out that the complexity of such classes of equilibrium problems is open even for undirected networks.
· An approximation algorithm when the treewidth is (log /log log ), through the development of new and enhanced techniques for approximating equilibrium problems in graphical games with small treewidth.
1.1 Related work
Bramoullé and Kranton [7] initiated the study of public goods in a network. They consider a type of pure Nash equilibrium called specialized equilibrium, and prove that such equilibria are stable under small perturbations, universal (always exist), and in fact computable by a natural distributed algorithm, since they correspond to maximal independent sets of the graph; see [2, 5, 8, 17, 23, 24, 30, 32, 40, 44] for follow-up works. Bramoullé et. al. [8] extended the theory to imperfectly substitutable public goods, and proved the existence of a unique Nash equilibrium, assuming that the graph's lowest eigenvalue is sufficiently small. Allouch [2] differentiates private provision from public provision, and again characterizes the existence and uniqueness of a Nash equilibrium through the lowest eigenvalue of the graph. Public goods games were first generalized to directed graphs in [32], who provide sufficient conditions for pure Nash equilibria to exist. The only complexity result regarding such public goods games we are aware of is [44]: finding a pure Nash equilibrium of a discrete version of the public goods game, albeit in the far more general case of heterogeneous agents, is NP-hard. We refer interested readers to the surveys [6, 26, 28] for a general coverage of this area.
Our work uses certain ideas from graphical games [29]. It is NP-hard to find a pure Nash equilibrium [27] and PPAD-hard to compute, even approximately, a mixed Nash equilibrium [11, 18, 37] of a general graphical game with maximum degree 3. However, the problem is tractable in several settings [19, 20, 42]. Daskalakis and Papadimitriou [19] developed a polynomial-time approximation scheme (PTAS) for computing an -approximate Nash equilibrium when the game has bounded strategy size, the network has bounded neighborhood size and (log ) treewidth. Thomas and Leeuwen [42] provided an algorithm that computes a pure Nash equilibrium in poly( , | |), where is the strategy size, the treewidth of the graph and | | the size of the payoff matrix. We use similar ideas in our main algorithmic result for computing Nash equilibria in public goods problems for networks of bounded treewidth, but we have to address the problem that, in the present case, the parameter | | of this algorithm is exponential.
The PPAD complexity class was introduced by Papadimitriou [34] to capture one particular genre of total search functions, encompassing the notion of equilibrium. The PPAD-completeness of Nash equilibria was established in [11, 18] and extended recently in [36, 37]. Over the past decades, a broad range of problems have been proved to be PPAD-hard, including equilibrium computation [1, 12, 16, 21], market equilibrium [9, 10, 14, 15, 43], equilibrium in auction [13, 25], fair allocation [33], min-max optimization [22] and problems in financial networks [39].

2 MODEL
A public goods game is a game with players, defined through a directed graph ( , ) without loops, where = {1, . . . , } is the set of players. We use ( ) to denote the neighborhood of , namely incoming neighbors of agent , i.e., ( ) = { }  { |( , )  }. We assume common game theoretic terms and notation, such as strategy, strategy profile, pure Nash equilibrium and (mixed) Nash equilibrium. If s = ( 1, . . . , ) is a strategy profile, we use - to denote actions adopted by all agents except .
As is almost always done with public goods games, we assume that all players have the same strategy space and the same utility function. In the indivisible good (discrete) case, the strategy space of all players is = {0, 1}, while in the divisible (continuous) case = [0, ). To define the utility function of a player , we start that defining the price or cost of producing the good , common to all players. In the indivisible case, it is a single real ( ) = > 0. In the divisible case it is a function : R+  R+.
Once has been fixed, the common utility function of agent for the strategy profile s is (s) = (s) - ( ), where is a symmetric social composition function of the strategies played by the players in ( ). Since players may have different indegrees, and thus different sizes of neighborhood, we assume for uniformity that the common social composition function is a symmetric function from to the reals, where the strategies of players not in ( ) are all set to zero -- a value that does not affect . The composition functions studied by the vast majority of the literature is the max (or best shot, or or) function in the indivisible case, picking the maximum of the neighborhood's 0 - 1 choices, while in the divisible case the composition functions max and sum is used. In indivisible good games with max composition, in the literature it is always assumed that  1, because otherwise = 1 creates ties between contributing and free-riding. For more general indivisible good games and social composition functions , we shall also avoid ties between contributing and free-riding. This can be achieved by assuming that all values of are rational (not a significant loss of generality), while is also rational but with a large denominator (technically, larger than the square of the largest denominator used in the values of ). This completes the definition of the common general utility function , and thus of the game. We are interested in the standard concepts of pure and mixed Nash equilibrium. A strategy profile s = ( 1, . . . , ) of the public good game is a (pure) Nash equilibrium, if no agent can derive better utility by changing their own strategy,
( , - )  ( , - )   ,  ,   .
In a mixed Nash equilibrium  = (1, . . . ,  ), each agent plays a distribution  over its strategy set , and satisfies

E [ ( , - )]  E

( , - )   ,    .

(1)

 , - -

- -

Define Supp( ) to be the support of the distribution  , i.e., Supp( ) = { |  ,  ( ) > 0}. Then the definition in (1) is equivalent to

  ,   Supp( ),   : E [ ( , - )]  E

( , - ) .

- -

- -

An -approximately well supported Nash equilibrium ( -Nash) is then defined as

  ,   Supp( ),   : E [ ( , - )]  E

( , - ) - .

(2)

- -

- -

3 PURE NASH EQUILIBRIA: A DICHOTOMY
In this section we characterize the complexity of finding pure equilibria, focusing first on the best shot (max, or) function. In contrast to undirected networks, where every maximal independent set corresponds to a pure Nash equilibrium, pure Nash equilibria may not exist in directed graphs (see Figure 1). We show in this section that determining whether a pure Nash equilibrium exists is NP-complete, and then generalize this to a sweeping complexity dichotomy result, characterizing precisely -- modulo the PNP conjecture -- the kinds of utility functions that have tractable Nash equilibrium problems.

Fig. 1. Odd cycles have no pure Nash equilibrium.

T

3.1. Deciding whether a pure Nash equilibrium exists in an indivisible public good game

with the max social composition function is NP-complete.

P . In an equilibrium profile s = ( 1, . . . , ), for each agent , we have = 1 if  = 0, and = 0 otherwise. In another words, an agent would purchase the good if, and only if, none of
its predecessors possesses the good. The reduction is from 3SAT, and employs the following two gadgets (see Figure. 2 and Figure. 3).

¯

¯

···

10 ¯2 1 32

1  ¯2  3

6

345

7

Fig. 2. Variable gadget.

Fig. 3. Clause gadget.

Variable gadget. For each variable , we construct a directed path with 2 nodes, where is the number of times appears in the 3SAT instance. The path is directed, with the exception that there is a bi-directional edge between the first two nodes. The bi-directional edge forces the choice (exactly one of the first two nodes has the good), and the rest of the path propagates it (either all odd nodes have the good and all even nodes do not, or the other way around).
Clause gadget. The clause gadget consists of two parts. The left part is an OR gadget, in that node 4 must equal the disjunction of nodes 0, 1, and 2. To see this, suppose that none of these three nodes has the good; then node 3 must have it, and so node 4 does not. And if one or more of nodes 0, 1, 2 has the good, then 3 does not have the good, and thus 4 must have it.
The right part forces the clause to be true -- that is, in any equilibrium profile, agent 4 must play strategy 1 and buys the good. This is because if 4 does not provide the good, then 5, 6, 7 is an isolated odd circle, which cannot exist in a pure Nash equilibrium. On the other hand, players 4

and 6 buying the good, and players 5 and 7 not buying it, is a pure Nash equilibrium of the four rightmost nodes. In summary, the clause gadget ensures that at least one of the nodes 0, 1, 2 buys the good.
Putting things together, given any 3SAT instance we can construct a public good game by composing variable gadgets and clause gadgets in the obvious way, so that the pure Nash equilibria of the public good game are in one to one correspondence with the satisfiable solutions of the 3SAT instance, concluding the proof.

We want to generalize this result to any social composition function , and so we start with the question: For which composition functions is the pure Nash equilibrium problem polynomial-
time solvable? Consider a symmetric, non-decreasing function : {0, 1}  R+ without loss of generality with (0 ) = 0. Because of symmetry, we can treat as a function from N to +, since its value depends on =1 ; we shall use the same symbol for this form of 2, and recall that
(0) = 0. Since is monotone, it can be also thought as a sequence of nonnegative steps. Call flat if (1)  ; that is, the first step of does not provide sufficient incentive to produce the
good. Obviously, all flat functions have the all-zero pure Nash equilibrium, and so the problem is
trivial. Call now steep if for all  0, ( + 1)  ( ) + ; that is, all steps are at least . Then all nodes have an incentive to produce the good no matter what anybody else is doing, and so the
all-ones solution is a pure Nash equilibrium, and again the problem is trivial. We have shown:

Lemma 3.2. The pure Nash equilibrium problem is in P if the utility function is flat. Ditto for steep functions.

Are there any other tractable cases? It turns out, that there is one more: Call alternating if for all  0, ( + 1) < ( ) + if is odd, and ( + 1) > ( ) + if is even.

Lemma 3.3. The pure Nash equilibrium problem is in P if the utility function is alternating.

P . Let = ( 1, . . . , ) be the equilibrium profile with  {0, 1}. Based on the definition of alternating utility function, we have that for any  [ ]

1 =0

( , )  = 0( mod2) ( , )  = 1( mod2).

That is, a player chooses to produce when there is an even number of neighboring players who produce the good. Hence, the equilibrium problem reduces to the solution of a linear system of equations in F2 with one 0 - 1 variable per player, with one equation for each player :

+

= 1(mod2).

( , )

This can be solved in polynomial time with Gaussian elimination, say.

We next establish that, unless P = NP, these are the only tractable cases:

T

3.4. If the utility function does not belong in these three classes: (1) flat; (2) steep; or (3)

alternating, then the pure Nash equilibrium problem is NP-complete.

P . We use the variable gadgets and the clause gadgets in the proof of Theorem 3.1 (see Figure 2 and Figure3), but we reduce from several different NP-hard problems. First, observe that when is not flat, steep, or alternating, there must be a  0 such that ( + 1) > ( ) + ,

2That is, we assume that has values for all integers, not limited to the size of the network; this is obviously a harmless convention.

( + 2) < ( + 1) + . We start by assuming that = 0, that is, (1) > and (2) < (1) + .

We divide the proof into four cases.

Case 1 Suppose (3) < (2) + , (4) < (3) + , then it is easy to check that the construction

of Theorem 3.1 works. Indeed, a function satisfying (1) > , (2) < (1) + , (3) < (2) +

, (4) < (3) + is, for the purposes of the network constructed in the proof of the previous

theorem, equivalent to the max function.

Case 2 Suppose (3) < (2) + , (4) > (3) + . We can still use the network constructed

in the proof of Theorem 3.1. The difference is that we reduce from N

SAT, since the

clause gadget is satisfied if and only if one or two literals are true.

Case 3 Suppose (3) > (2) + , (4) > (3) + . Again, we consider the network constructed

in the proof of Theorem 3.1. We can check that the clause gadget is satifiable if and only if exactly

one of the literal is true. The NP-hardness then comes from O

3SAT.

Case 4 Suppose (3) > (2) + , (4) < (3) + . Since we assume is not alternating, there

exists  1 satisfying (2 + 1) > (2 ) + , (2 + 2) < (2 + 1) + , and (2 + 3), (2 + 4)

does not obey (2 + 3) > (2 + 2) + , (2 + 4) < (2 + 3) + . We create 2 new players

who have no incoming edges and directed edges to all other nodes. These 2 players will provide

the good at equilibrium, and thus the remaining players start the game with 2 copies of the good already. The game for the original player is then changed to the function ~ ( ) = ( - 2 ), and

NP-completeness follows from cases (1­3).

Finally, suppose that > 0. Add new players who have no incoming edges, and directed

edges to all other nodes. At equilibrium, these nodes will provide the good, and so the remaining

players will start the game with copies of the good already provided. Therefore, the game for the

remaining players will be as if ( ) was changed to ( - ), that is to say, to a function covered

by the previous paragraph.

We only need to be cautious about one exception: (1) > , . . . , ( + 1) > ( ) + , ( + 2) <

( + 1) + , ( + 3) > ( + 2) + , ( + 4) < ( + 3) + , since could be alternating after

( ). We still create new players and direct them to all other agents, except for node 3 in every

clause gadget, for which we only connect - 1 players to it. It is easy to check that our argument

in Theorem 3.1 works, with one modification: the clause gadget is satisfiable if and only if exactly

two of the literals are true. This, again, is NP-complete, as we can reduce from O

3SAT.

4 PPAD-HARDNESS OF MIXED NASH EQUILIBRIA
We next examine mixed Nash equilibria of indivisible public goods games. In a mixed Nash equilibrium, agents randomize over the two actions and choose to buy the public good with some probability. We denote by the probability that agent purchases the good. Also, by = ± we mean that -   + . For ease of presentation, we assume = 1 and < 1 throughout the proof. The following result is the main technical contribution of this paper.

T

4.1. There exists some constant > 0, such that it is PPAD-hard to find an -Nash of the

indivisible public goods game.

We start with a high level overview of the proof. We reduce from the -GCIRCUIT problem (see Definition 4.5), which is shown to be PPAD-hard for sufficiently small constant > 0 by Rubinstein [37]. Our reduction consists of two steps. We first introduce an intermediate game, called the threshold game (see Definition 4.2), where each individual's strategy depends solely on the summation of its neighbors' strategies. The threshold game exhibits rich algorithmic and complexity structure, which we believe could be of independent interest. We show a correspondence between equilibrium profiles of threshold games and those of public goods games (Lemma 4.4); hence it suffices to demonstrate PPAD-hardness of finding an -approximate equilibrium of threshold games.

The threshold game is semi-anonymous, and thus we can only modify the local structure of the

graph in order to construct all 9 types of gates { , × , =, +, -, <, , , ¬}. We start by

constructing an elementary gadget

1 2

-

(see

Figure

5),

and

use

it

as

a

building

block

to

gradually

construct

most

of

the

gates.

We

restrict

the

players'

equilibrium

strategies

to

be

in

[0,

1 2

+

] in

the arithmetic (non-logic) gates. The logic gates ( , , ¬) are special: in order to prove PPAD-

hardness for constant , we need them to be error-resilient, in that they do not amplify errors

of the input. We achieve this by restricting players' equilibrium strategy to be {0, 1} (instead of

{0,

1 2

})

when

doing

logic

operations,

and

construct

transformer

gadgets

1 2

,1,

1,

1 2

to

map

between

the

domains

{0,

1 2

}

and

{0,

1}.

4.1 Equivalence between public goods games and threshold games We first introduce the threshold game.

Definition 4.2. (Threshold game) A threshold game G( , , ) is defined on a directed graph = ( , ), with a threshold (0 < < 1). The vertices of the graph represent players with strategy space [0, 1]. A strategy profile x = ( 1, . . . , )  [0, 1] is an equilibrium if it satisfies

 0



>

=

1

arbitrary

 <. =

(3)

Note that can be an arbitrary number in [0, 1] if  = .

We define the -approximate equilibrium in a threshold game as follows:

Definition 4.3. ( -approximate equilibrium of threshold game) Let > 0 be a constant satisfying < < 1- . An -approximate equilibrium x = ( 1, . . . , )  [0, 1] of a threshold game G( , , )
satisfies

 0 ±



>+

= 1± arbitrary

 <-

.

 [ - , + ]

(4)

We next establish the equivalence between threshold games and public good games. The proof can be found in Appendix A

Lemma 4.4. There is a polynomial time reduction between the threshold game and the public good

game. Specifically, (1) given any threshold game G( , , ) with 0 < < 1, we can construct a

public good game and map any -Nash of the public goods game to an 8 -approximate equilibrium

of threshold game G( , , ), for

<

min{0.1,

8

,

1- 8

};

(2)

given

any

public

good

game

with

=

1, 0 < < 1, we can construct a threshold game G( , , ) and map any -approximate equilibrium

of threshold game to an -Nash of public goods game, where = -4 log is a constant depending

only on .

4.2 Reducing generalized circuits to threshold games
Next, we give the definition of generalized circuits.
Definition 4.5. (Generalized circuit [11]) A generalized circuit is a tuple ( , T ), where is a set of nodes and T is a collection of gates. Every gate  T is a 5-tuple = ( , 1, 2, , ), where
 { , × , =, +, -, <, , , ¬} is the type of the gate; 1, 2   { } are the input nodes,  R  { } is a real parameter and is the output node.
The collection T of gates must satisfy the following important property. For every two gates ,   T , = ( , 1, 2, , ) and  = ( , 1, 2, , ), we must have  .

The -GCIRCUIT is the problem of finding an -approximate assignment for the generalized

circuit. Notice that we replace

,

× with

1,
2

×

1 2

for

ease

of

proof.

Definition 4.6. Given a generalized circuit S = ( , T ), we say an assignment x :  [0, 1]

-approximately satisfies S, if it satisfies the constraints shown in table 1.

Gate

1( )
2

×

1 2

(

|

1|

)

=(| 1 | )

+(| 1, 2 | )

-(| 1, 2 | )

<(| 1, 2 | )

(| 1, 2 | )

(| 1, 2 | )

¬(| 1 | )

Constraint

x[

]

=

1 2

±

x[

]

=

1 2

· x[

1]

±

x[ ] = x[ 1] ±

x[

]

= min{x[

1]

+ x[

2],

1 2

}

±

x[ ] = max{x[ 1] - x[ 2], 0} ±

x[ ] =

1 2

±

0±

x[ 1] < x[ 2] - x[ 1] > x[ 2] +

x[ ] =

1 2

±

0±

x[

1]

=

1 2

±

 x[

2]

=

1 2

±

x[ 1] = 0 ±  x[ 2] = 0 ±

1± x[ ] =
0±

x[

1]

=

1 2

±

 x[

2]

=

1 2

±

x[ 1] = 0 ±  x[ 2] = 0 ±

x[ ] =

1 2

±

0±

x[ 1] = 0 ±

x[

1]

=

1 2

±

Table 1

To complete the proof we must reduce -GCIRCUIT to computing an -approximate equilibrium of the threshold game.

T

4.7. It is PPAD-hard to find an -approximate equilibrium of the threshold game, for

some constant > 0.

The proof of this result can be found in Appendix A. It is based on an elementary game gadget

1 2

-

(

|

1,

2|

), where

1,

2

{

} are input players, 

is the output player. The gadget

consists of a directed cycle, where 1, 2 have directed edges to the auxiliary player , has a

directed edge to the auxiliary player , points to the output player and there is a directed edge

from to . The output player could have many outgoing edges, but it only has one incoming

edge from the internal node

.

The

intention is

that,

at equilibrium,

x[

]

=

max{

1 2

- x[

1] -

x[ 2], 0}. The core of the proof, which we omit here, entails the construction and deployment of

gates =, +, -, whose design is based on the elementary gadget described above.

Combining Theorem 4.7 and Lemma 4.4, the proof of Theorem 4.1 is complete.

Theorem 4.1 only covers the max utility function. We conjecture that it holds for all utility func-

tions except for the polynomial cases discussed in Theorem 3.4. There are several interesting chal-

lenges in extending the proof to this direction.

5 DIVISIBLE GOODS
For divisible public goods games in directed graphs, we study the three most studied utility functions, and completely characterize the equilibrium problem:

· For the summation utility (the utility of each node is the sum of the amounts of goods provided by its predecessors), a pure Nash equilibrium always exists, but it is PPAD-complete to find one.
· For the best-shot function (max), a pure Nash equilibrium may not exist and it is PPAD-hard to find a mixed Nash equilibrium; the reasons are quite similar to the indivisible case.
· Finally, for the weakest-link function (min), it turns out that there are always multiple trivial pure Nash equilibria, as no player has the incentive to supply any amount of the good.

5.1 Summation
When the utility function is the summation, Bramoulle et. al. [7] prove that there is always a pure Nash equilibrium3. Here, we prove it is PPAD-hard to find one, when the network is directed. In fact, we prove a slightly stronger result: call a strategy profile s = ( 1, . . . , ) an -approximate pure Nash equilibrium, if = ( - ) ± , where (·) is the best response of agent .

T

5.1. It is PPAD-hard to find an -approximate pure Nash equilibrium of public goods

games, for = 1/poly( ).

We reduce from the mixed Nash equilibrium problem in two-player win-lose games. A twoplayer game ( , ) is win-lose if ,  {0, 1} × . It is known [1, 16] that finding an -Nash of two-player win-lose game is PPAD-hard for = 1/poly( ). Given an instance ( , ) of a two player win-lose game, we construct a divisible public goods game on a directed network, such that we can map any -approximate pure Nash equilibrium of the public goods game to a poly( ) · Nash of two-player win-lose game ( , ). In order to do so, we first symmetrize the win-lose game (Lemma 5.2), and then reduce it to the public goods game (Lemma 5.3).
For convenience, we assume that ,  {-1, 0} × and that there is no weakly-dominated strategy for both row and column players. Moreover, we assume every column (row) of ( ) contains at least one 0 entry -- otherwise, there is a trivial pure Nash equilibrium. Define a symmetric game ( , ) as follows:

-1 =

-1 and

-1 =

-1 ,

where -1 denotes an × all -1 matrix. We notice that ,  {-1, 0}2 ×2 and = . The above symmetrization is standard in the literature [31], and it is known that for any symmetric Nash equilibrium ( , ) of ( , ), ( /| |, /| |) is a Nash equilibrium for ( , ). The following lemma states that approximation is preserved:

Lemma 5.2. Suppose ( , ) is a symmetric -Nash equilibrium of game ( , ). Then ( ~, ~) = ( /| |, /| |) is a 4n -Nash of the win-lose game ( , ).

P

. We first prove that |

|, |

|



1 4

.

Notice

that

-1

=

-1

-| |e + = -| |e +

,

3They actually prove it for undirected networks, but their proof generalizes easily to the directed case, as the best response function for each agent is still continuous in - , and existence of a pure Nash equilibrium follows from Brouwer's fix point theorem. In fact, when the valuation function is strictly concave, it can be shown that there are only pure Nash equilibria [7]: It is always better to replace the mixed strategy with its mean value, but also, replacing by the mean value does not create pure Neq.

where e = {1, . . . , 1} denotes the n-dimension all 1 vector. The proof is by contradiction. Suppose

|

|<

1 4

;

it

then

follows

that

max -| | + (
[ ]

)

 -|

|

<

-1

+

1 4

,

where the second step follows from |

| =1-|

|

>

1

-

1 4

by our assumption

max -| | + (
[ ]

)

>

-

1 4

+ max(
[ ]

)



-

1 4

+1

(

)

=

-

1 4

+1

[ ] [ ]

11 - +
4

· (1 -

1 )-
4

+ 1 · (1 -

)

=

-1

+

3 4

.

[ ]

The first step follows from |

|

<

1 4

.

We

repalce

max

with

average

in

the

second

step.

The

fourth

step comes from the fact that there exists at least one 0 entry for each column of the payoff matrix

. Thus we have

max -| | + ( ) - max -| | + (

[ ]

[ ]

1 ) >2 > ,

which contradicts with the fact that |

|

>

1-

1 4

.

Therefore,

we

have

>

1 4

,

>

1 4

.

Consequently,

for any ,  [ ], > 0, we have (-| | + ( ) ) - (-| | + ( ) ) = ( ) - ( ) > . Hence,

we have ( ~) - ( ~) > 4 for any ,  [ ] and ~ > 0. The same holds for the column player,

confirming that ( ~, ~) = ( /| |, /| |) is a 4n -Nash of the win-lose game ( , ).

Define = - - and = - = + ; note that  {0, 1} and the diagonal entries are zero. Now we claim:

Lemma 5.3. Let be the adjacency matrix of the directed network of a public goods game (with divisible goods game and summation utility of the players). Then from any -pure Nash equilibrium s = ( 1, . . . , ) of the public goods game, we can find a symmetric 3 -Nash of game ( , ).
P . Let s = ( 1, . . . , ) be an -approximate pure Nash equilibrium of the public goods game, then for any agent  [ ], we have  ( )  1 - . Otherwise, agent would increase its effort. Moreover, we claim that  ( ) > 1 + implies = 0 ± . This holds because (1) if  > 1, then the best response of agent is ( - ) = 0, it then follows = 0 ± ; (2)  )  1, then the best response is ( - ) = 1 -  ) and - ( - ) =  ( ) - 1 > , which contradicts with the equilibrium condition. In summary, for all  [ ], we have

( s)  1 - = 0 ± or ( ) = 1 ± . Denote s = max{s - , 0}, then we have
( s)  1 - ( + 1) s = 0 or ( s) = 1 ± .

Since = -
Since |s|  game ( , )

, we have ( s)  -1 + ( + 1)
s = 0 or ( s) = -1 ± .  (1)   1 - ( + 1) , we we conclude that s/|s| is a symmetric 3

-Nash of the

Combining Lemma 5.3 and Lemma 5.2, we conclude that it is PPAD-hard to find an -approximate pure Nash equilibrium of public goods game, for = 1/poly( ). This concludes the proof of Theorem 5.1.

5.2 Best-shot rule
When the utility function is the best-shot rule (i.e., the utility of a node is the maximum of the provisions by its predecessors), there is a simple proof that there is no pure Nash equilibrium: First we prove that, in any pure Nash equilibrium, an agent plays either 0 or 1 (not any number between (0, 1)). Then the result follows from the example shown in Figure 1.
For mixed Nash equilibria, we have the following theorem, shown through a simple reduction from the indivisible case

T

5.4. When the utility function is the best-shot rule (max), it is PPAD-hard to find a mixed

Nash equilibrium of the public goods game.

P . We set the valuation function to be ( ) = max{1, }. We assume in an equilibrium profile, the player prefers a mixed combination over action 0, 1 to a stategy  (0, 1) if they have the same utility guarantee. We then prove that, in a mixed Nash equilibrium, an agent will only play a mixed strategy over actions 0 and 1. To see this, first, in an equilibrium profile, no player chooses to play with > 1 in the support of its mixed strategy, since it can decrease it to 1, which reduces the cost and does not affect the utility. Next, if a player chooses to play  (0, 1) in the support of its mixed strategy, then we claim it is always better to replace with a convex combination of 0 and 1, i.e. chooses 0 with probability 1 - and chooses 1 with probality . We divide into two cases. (1) If the max production of neighbors is   . Then the utility for later profile gets larger while the cost remains the same. (2) If the max production of neighbors is  < , then both the cost and utility remains the same.
Assuming all agent play mixed strategies over actions 0 and 1 in the equilibrium profile, it is not hard to modify the proof of Theorem 4.1 to show that it is PPAD-hard to find a mixed Nash equilibrium. We conclude the proof here.

6 THE BOUNDED TREEWIDTH ALGORITHM

When the treewidth of the underlying graph is bounded by

log log log

, we develop a PTAS for

computing an -Nash of the (indivisible) public goods game. We first recall the definition of tree

decomposition.

Definition 6.1. (Tree decomposition) A tree decomposition4 of a graph ( , ) is a tree , with nodes 1, . . . | |. Each node is a subset of , and it satisfies:
(1) The union of equals . (2) For each edge ( , )  , there exists a node that contains both vertices and . (3) For any vertex  , the set of tree nodes that contain the vertex forms a connected sub-tree
of .
The width of a tree decomposition is defined as max1  | | | | - 1 and the treewidth of a graph , denoted as twd( ), is the minimum width among all tree decompositions of the graph .

We will call the vertices of nodes, and those of vertices. The treewidth twd( ) will be abbreviated by , while is the maximum degree of . Our main result is shown below. Comparing with the general result of [19], we get rid of the exponential dependence on . Alas, we make no assumptions on the sparsity of the graph.

4In defining treewidth, we ignore directions of the edges.

T

6.2. Given an indivisible public goods game defined on a network ( , ), we can find an

-Nash equilibrium in time poly( ) · min{2 / , 16 log( )/ } ( ) . In particular, when the treewidth

is

log log log

, we can find an -Nash equilibrium in poly( ) · 1

( ) time.

First, a few notes about the proof. The time complexity of our algorithm depends minimally on , while is in the exponent of the algorithm in [19]. To achieve this, we need to circumvent several difficulties, explained below. Like the proof in [19], we first need to show the existence of an approximate Nash equilibrium with probabilities that are multiples of a small real > 0. Simply applying the total variation bound gives = ( ), which is not coarse enough. In Lemma 6.3, we use a probabilistic argument showing the existence of an approximate Nash equilibrium after discretizing the strategy space. In particular, we randomly round a Nash equilibrium, for = ( log ) and utilize the concentration property. Another difficulty is that the algorithm [19] works on the primal graph (see [19] for the definition), whose treewidth can be · , yielding an exponential dependence on . Instead, our algorithm directly works on the the original graph through dynamic programming, with no exponential dependence on . Our dynamic programming method bares some similarities with the approach in [42]. However, we must modify significantly that algorithm, whose running time has a polynomial dependency on the size of the payoff matrix, which in our case be exponential.
Now, to prove the theorem, by Lemma 4.4, it suffices to show how to compute an -approximate equilibrium of a threshold game G( , , ). Again, we assume = 1/2 for simplicity. We discretize the strategy space of each player to = [ ], where = max{ /2 , /16 log }. We first show that there exists an -approximate pure Nash equilibrium in strategy space.

Lemma 6.3. For any threshold game G(

,

,

1 2

),

there

exists

an

-approximate equilibrium when we

restrict the strategy space to be [ ] , where = /16 log .

P

. Suppose x = ( 1, . . . ,

) is an equilibrium profile of the threshold game G(

,

,

1 2

)

.

For

any  [ ], suppose  [ , ( + 1) ], then we randomly round to ~  { , ( + 1) }, and

we have

~ = ( + 1)

with prob. - with prob. 1 - + .

We remark that E[ ~ ] = and ( ~ - ) is a binary random variable that takes value in {0, }, with
mean ( - ). The rest of the proof establishes that ( ~1, . . . , ~ ) is an -approximate equilibrium with positive probability, therefore proving its existence.
By the multiplicative Chernoff bound, for any  [ ], if  ( - ) =  (E[ ~ ] - ) < , then we have

Pr ~ -

- =0

(5)





and

Pr

~-





 = Pr

~-



- E[ ~ ] -


  exp - 3  -2. (6)

If  ( - ) =  (E[ ~ ] - )  [ , 2], then we have

Pr

~-





If  ( - ) =

 = Pr

~ - - E[ ~ ] - 





 2 exp - 2

2
 E[ ~ ] - 

 2 exp - 4

 (E[ ~ ] - ) > 2, it then follows that = 0 and we have

 -2. (7)

Pr

~ < 1  Pr

~-





<1

 exp

-1 4

 -2.

(8)

Combining Eq. (5) (6) (7) (8) and using an union bound, we conclude that ( ~1, . . . , ~ ) satisfies equilibrium condition with probability at least (1 - 1/ ), completing the proof.

We next provide an algorithm that finds an -approximate equilibrium based on dynamic programming. A nice tree decomposition is a tree decomposition that only contains the following four types of nodes (see Figure 4 for an illustration).
(1) Leaf node. (2) Forget node. Such a node has only one child , and  = \{ } for some vertex  . (3) Introduce node. Such a node has only one child node , and  =  { } for some vertex
. (4) Join node. Such a node has exact two children nodes 1, 2, and = 1 = 2.
Any tree decomposition can be converted into a nice tree decomposition, of size at most · | |, in linear time without enlarging the width [4].

,,

,

,

,

,,

,

,

Forget

Introduce

Join

Fig. 4. An illustration for three types of nodes of a nice tree decomposition.

Now, we have

Lemma 6.4. Given a threshold game G(

,

,

1 2

)

with

the

strategy

space

[

]

, and a nice tree decom-

position of the graph ( , ), we can compute an -approximate equilibrium in - ( ) time.

P . Given a nice tree decomposition , we compute an -approximate equilibrium via a bottom-up approach. For any node  , we use to denote all vertices contained in and its sub-tree. We compute a table : [ ] | | × [ ] | |  {0, 1} for each node , and we note that the size of the table is bounded by - ( ) . Ideally, we would set an entry ( 1, . . . , | |, 1, . . . , | |) = 1, iff there exists a strategy profile ( 1, . . . , | |) of vertex set , such that
(i) for any vertex  \ , the vertex satisfies the equilibrium condition,

(ii) for any vertex  , = and  ( \ ) = , i.e., the summation of vertex 's neighbor in \ is .

We remark that vertices in do not need to satisfy the equilibrium condition, and we only record

the summation of their neighbors in \ . Next, we show how to do update the table in a bottom-

up manner.

(1) Leaf. For any leaf  and ,  [ ] | |, we set ( , ) = 1 if and only if = (0, . . . , 0).

(2) Forget. Suppose  =  { } is the parent node, ,  [ ] | | and ,  [ ], we set

 ( , , , ) = 1 if ( , ) = 1 and = 0; we set  ( , , , ) = 0 otherwise.

(3) Introduce. Suppose  = \{ } is the parent node and ,  [ ] |  |, we set  ( , ) = 1

iff there exists ( , , , )  [ ]2| |, such that ( , , , ) = 1 and the vertex satisfies the

equilibrium condition, i.e., (i) if +  

>

1 2

,

then

= 0 ± ; (ii)

+



<

1 2

,

then

=1± .

(4) Join. Suppose node has two children, 1, 2, and = 1 = 2. Then for any ,  [ ] | |, we set ( , ) = 1 iff there exists 1, 2  [ ] | |, such that 1 ( , 1) = 1, 2 ( , 2) = 1, and for any
 , [ ] = min{ 1 [ ] + 2 [ ], 1}.

After we reach the root and complete the table , we verify equilibrium conditions for all

vertices  . To be more specific, if there exists a configuration ( , )  [ ] | | × [ ] | |, such

that ( , ) = 1 and all vertices in satisfy the equilibrium, i.e., (i) if +  

>

1 2

+

then = 0 ± ; (ii) if +  

<

1 2

-

then

= 1 ± ; we then confirm that there exists an

-approximate equilibrium. We can find one by either fixing the strategy of all vertices  to be

, and recursively computing equilibrium profiles in the sub-tree; or we can associate a satisfiable

assignment (if there exists one) for each entry during the dynamic programming process. We

output that there is no -approximate equilibrium profile otherwise.

Combining Lemma 6.4 and Lemma 6.3, we conclude the proof of Theorem 6.2. We can show a similar result for divisible public good games with the summation rule. Again, when the treewidth of the underlying graph is bounded by (log /log log ), there is a PTAS for finding an -approximate pure Nash equilibrium of the public goods game:

T

6.5. Given a divisible public goods game with summation utility defined on a directed

network ( , ), we can find an -approximate pure Nash equilibrium in time poly( )·min{2 / , 16 log( / )} (

time. In particular, when the treewidth is (log /log log ), we can find an -approximate pure Nash equilibrium in poly( ) · ( 1 ) ( ) time.

The proof is similar to Theorem 6.2, and is omitted.

7 DISCUSSION
We explore the complexity of equilibria in public goods games played on directed graphs. One striking conclusion is the ubiquity of PPAD-completeness in this domain. For a number of quite different reasons, very different variants of the problem are shown to share the same fate -- and a rather sophisticated fate at that. This is in stark contrast with the corresponding public goods games in undirected graphs, where the consensus is that equilibria are rather boring (but see the discussion below of some intriguing problems in undirected networks raised by this work). Note that graphical games are already intractable when they are symmetric -- but, of course, this is because the local normal form games in each neighborhood can simulate any asymmetry.
Are public good games in directed networks real? It can be argued5 that some of the directed graphs we evoked in the introduction (towns that are downwind or upriver from one another, or
5Many thanks to the reviewers for bringing this point up.

the relationship "B is on A's way to work") are transitive, and it is easy to see that public good games on such directed graphs have trivial equilibrium problems. On the other hand, many social networks with sharing features are asymmetric and non-transitive, and so are infection networks in much of epidemic modeling. In addition, we hope that our techniques and techniques may be a public good of some value to the community.
For the indivisible case, we found that there are three special cases of utilities that admit polynomial time solution: Flat utilities, steep utilities, plus a third polynomial case, alternating utilities, which is quite unexpected and intriguing (its algorithm relies on the solution of a system of equations in F2). We show that these are the only tractable cases. But there is an interesting variant of this problem which is quite mysterious: Suppose that we allow the utility function to be such that certain steps of have height exactly , and therefore nodes can be indifferent between buying the good and free-riding. We suspect that this variant is subject to the same dichotomy, but it seems much harder to prove. Consider for example the function (1) = 1 > , ( ) = 1 + for all > 1. Then it is easy to see that, in this case, odd cycles do have an equilibrium, with all players producing the good: the step makes them indifferent to doing so. This deprives us of a valuable gadget. It turns out that there is a 7-node, 21-edge gadget with no equilibrium for this case: the node set is {1, . . . , 7} and the edges go from to + 1, + 2, 1 + 4 mod 7. But this does not immediately give us an NP-hardness proof, nor does it generalize to other composition functions with steps.
We believe that the general form of the utility function of public goods games in networks (Section 3) has not been articulated in the past, and it does lead to an interesting complexity classification problem. We note that the equilibrium situation in this generality is open in the undirected case. Take for example the case where < 1 and is the threshold function ( ) = 1 if  2 and zero otherwise; we believe that this case is NP-complete. The complexity dichotomy problem in undirected networks with general utility functions is a very interesting open problem raised by this work.
The divisible good games under the summation utility are something of a mystery when it comes to mixed equilibria. As with other games with uncountable strategy spaces, it is not easy to characterize mixed Nash equilibria in a tangible, useful way. We believe that positive results may be possible here: Could it be that there are always mixed Nash equilibria with small support, and in fact they are easy to find? There are reasons for hope for a truly positive result in this case.
The intractability of simple Nash equilibrium problems in common goods games in directed networks is an indication that asymmetry in social systems -- a notion intuitively coterminous with unfairness -- may consistently lead to instability. Can the intractability proofs help identify the features of the directed networks, and of the agents and their utilities, which are at the root of such instability? This could lead to principles for better design of social networks, or beneficial interventions therein.
ACKNOWLEDGMENTS
The authors would like to thank Xi Chen and two anonymous EC reviewers for their very helpful feedback.This research was supported by NSF grants CCF-1763970 AF and CCF-1910700 AF, and a grant from Softbank.
REFERENCES
[1] Tim Abbott, Daniel Kane, and Paul Valiant. 2005. On the complexity of two-player win-lose games. In 46th Annual IEEE Symposium on Foundations of Computer Science (FOCS'05). IEEE, 113­122.
[2] Nizar Allouch. 2015. On the private provision of public goods on networks. Journal of Economic Theory 157 (2015), 527­552.
[3] Theodore Bergstrom, Lawrence Blume, and Hal Varian. 1986. On the private provision of public goods. Journal of Public Economics 29, 1 (1986), 25­49.

[4] Hans L Bodlaender and Arie MCA Koster. 2008. Combinatorial optimization on graphs of bounded treewidth. Comput. J. 51, 3 (2008), 255­269.
[5] Leonardo Boncinelli and Paolo Pin. 2012. Stochastic stability in best shot network games. Games and Economic Behavior 75, 2 (2012), 538­554.
[6] Yann Bramoullé and Rachel Kranton. [n.d.]. Games Played on Networks. In The Oxford Handbook of the Economics of Networks.
[7] Yann Bramoullé, Rachel Kranton, et al. 2007. Public goods in networks. Journal of Economic Theory 135, 1 (2007), 478­494.
[8] Yann Bramoullé, Rachel Kranton, and Martin D'amours. 2014. Strategic interaction and networks. American Economic Review 104, 3 (2014), 898­930.
[9] Wei Chen, Pinyan Lu, Xiaorui Sun, Bo Tang, Yajun Wang, and Zeyuan Allen Zhu. 2011. Optimal pricing in social networks with incomplete information. In International Workshop on Internet and Network Economics. Springer, 49­ 60.
[10] Xi Chen, Decheng Dai, Ye Du, and Shang-Hua Teng. 2009. Settling the complexity of Arrow-Debreu equilibria in markets with additively separable utilities. In 2009 50th Annual IEEE Symposium on Foundations of Computer Science. IEEE, 273­282.
[11] Xi Chen, Xiaotie Deng, and Shang-Hua Teng. 2009. Settling the complexity of computing two-player Nash equilibria. Journal of the ACM (JACM) 56, 3 (2009), 1­57.
[12] Xi Chen, David Durfee, and Anthi Orfanou. 2015. On the complexity of Nash equilibria in anonymous games. In Proceedings of the forty-seventh annual ACM symposium on Theory of computing. 381­390.
[13] Xi Chen, Christian Kroer, and Rachitesh Kumar. 2021. The Complexity of Pacing for Second-Price Auctions. In Proceedings of the 22nd ACM Conference on Electronic Commerce.
[14] Xi Chen, Dimitris Paparas, and Mihalis Yannakakis. 2013. The complexity of non-monotone markets. In Proceedings of the forty-fifth annual ACM symposium on Theory of computing. 181­190.
[15] Xi Chen and Shang-Hua Teng. 2009. Spending is not easier than trading: on the computational equivalence of Fisher and Arrow-Debreu equilibria. In International Symposium on Algorithms and Computation. Springer, 647­656.
[16] Xi Chen, Shang-Hua Teng, and Paul Valiant. 2007. The approximation complexity of win-lose games. In SODA, Vol. 7. 159­168.
[17] Luca Dall Asta, Paolo Pin, and Abolfazl Ramezanpour. 2011. Optimal equilibria of the best shot game. Journal of Public Economic Theory 13, 6 (2011), 885­901.
[18] Constantinos Daskalakis, Paul W Goldberg, and Christos H Papadimitriou. 2009. The complexity of computing a Nash equilibrium. SIAM J. Comput. 39, 1 (2009), 195­259.
[19] Constantinos Daskalakis and Christos H Papadimitriou. 2006. Computing pure Nash equilibria in graphical games via Markov random fields. In Proceedings of the 7th ACM conference on Electronic commerce. 91­99.
[20] Constantinos Daskalakis and Christos H Papadimitriou. 2015. Approximate Nash equilibria in anonymous games. Journal of Economic Theory 156 (2015), 207­245.
[21] Constantinos Daskalakis, Grant Schoenebeck, Gregory Valiant, and Paul Valiant. 2009. On the complexity of Nash equilibria of action-graph games. In Proceedings of the twentieth annual ACM-SIAM symposium on Discrete algorithms. SIAM, 710­719.
[22] Constantinos Daskalakis, Stratis Skoulakis, and Manolis Zampetakis. 2021. The complexity of constrained min-max optimization. In Proceedings of the 53th Annual ACM SIGACT Symposium on Theory of Computing.
[23] Matthew Elliott and Benjamin Golub. 2019. A network approach to public goods. Journal of Political Economy 127, 2 (2019), 730­776.
[24] Michal Feldman, David Kempe, Brendan Lucier, and Renato Paes Leme. 2013. Pricing public goods for private sale. In Proceedings of the fourteenth ACM conference on Electronic commerce. 417­434.
[25] Aris Filos-Ratsikas, Yiannis Giannakopoulos, Alexandros Hollender, Philip Lazos, and Diogo Poças. 2021. On the Complexity of Equilibrium Computation in First-Price Auctions. In Proceedings of the 22nd ACM Conference on Electronic Commerce.
[26] Andrea Galeotti, Sanjeev Goyal, Matthew O Jackson, Fernando Vega-Redondo, and Leeat Yariv. 2010. Network games. The review of economic studies 77, 1 (2010), 218­244.
[27] Georg Gottlob, Gianluigi Greco, and Francesco Scarcello. 2005. Pure Nash equilibria: Hard and easy games. Journal of Artificial Intelligence Research 24 (2005), 357­406.
[28] Matthew O Jackson and Yves Zenou. 2015. Games on networks. In Handbook of game theory with economic applications. Vol. 4. Elsevier, 95­163.
[29] Michael Kearns, Michael L Littman, and Satinder Singh. 2001. Graphical models for game theory. In the 17th Conference in Uncertainty in Artificial Intelligence, UAI (2001).

[30] David Kempe, Sixie Yu, and Yevgeniy Vorobeychik. 2020. Inducing Equilibria in Networked Public Goods Games through Network Structure Modification. In Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems. 611­619.
[31] Carlton E Lemke and Joseph T Howson, Jr. 1964. Equilibrium points of bimatrix games. Journal of the Society for industrial and Applied Mathematics 12, 2 (1964), 413­423.
[32] Dunia López-Pintado. 2013. Public goods in directed networks. Economics Letters 121, 2 (2013), 160­162. [33] Abraham Othman, Christos Papadimitriou, and Aviad Rubinstein. 2016. The complexity of fairness through equilib-
rium. ACM Transactions on Economics and Computation (TEAC) 4, 4 (2016), 1­19. [34] Christos H Papadimitriou. 1994. On the complexity of the parity argument and other inefficient proofs of existence.
Journal of Computer and system Sciences 48, 3 (1994), 498­532. [35] Neil Robertson and Paul D. Seymour. 1986. Graph minors. II. Algorithmic aspects of tree-width. Journal of algorithms
7, 3 (1986), 309­322. [36] Aviad Rubinstein. 2016. Settling the complexity of computing approximate two-player Nash equilibria. In 2016 IEEE
57th Annual Symposium on Foundations of Computer Science (FOCS). IEEE, 258­265. [37] Aviad Rubinstein. 2018. Inapproximability of Nash equilibrium. SIAM J. Comput. 47, 3 (2018), 917­959. [38] Paul A Samuelson. 1954. The pure theory of public expenditure. The review of economics and statistics (1954), 387­389. [39] Steffen Schuldenzucker, Sven Seuken, and Stefano Battiston. 2017. Finding Clearing Payments in Financial Networks
with Credit Default Swaps is PPAD-complete. In 8th Innovations in Theoretical Computer Science Conference (ITCS 2017). [40] Kijung Shin, Euiwoong Lee, Dhivya Eswaran, and Ariel D Procaccia. 2017. Why you should charge your friends for borrowing your stuff. In Proceedings of the 26th International Joint Conference on Artificial Intelligence. 395­401. [41] Joseph E Stiglitz. 1999. Knowledge as a global public good. Global public goods 1, 9 (1999), 308­326. [42] Antonis Thomas and Jan van Leeuwen. 2015. Pure Nash equilibria in graphical games and treewidth. Algorithmica 71, 3 (2015), 581­604. [43] Vijay V Vazirani and Mihalis Yannakakis. 2011. Market equilibrium under separable, piecewise-linear, concave utilities. Journal of the ACM (JACM) 58, 3 (2011), 1­25. [44] Sixie Yu, Kai Zhou, P Jeffrey Brantingham, and Yevgeniy Vorobeychik. 2020. Computing Equilibria in Binary Networked Public Goods Games.. In AAAI. 2310­2317.

A OMITTED PROOF FROM SECTION 4

A.1 Missing proof from Section 4.1

Lemma 4.4. There is a polynomial time reduction between the threshold game and the public good

game. Specifically, (1) given any threshold game G( , , ) with 0 < < 1, we can construct a

public good game and map any -Nash of the public goods game to an 8 -approximate equilibrium

of threshold game G( , , ), for

<

min{0.1,

8

,

1- 8

};

(2)

given

any

public

good

game

with

=

1, 0 < < 1, we can construct a threshold game G( , , ) and map any -approximate equilibrium

of threshold game to an -Nash of public goods game, where = -4 log is a constant depending

only on .

P . We first reduce the threshold game to the public good game. Given an instance of the threshold game G( , , ), we construct a public good game as follow. We keep the network
( , ) unchanged and set the value of the good to be = 1 and the price to be = -  (0, 1). For any -Nash s = ( 1, · · · , ) of the public good game, we construct an -approximate equilibrium x = ( 1, · · · , ) of G( , , ) as
= min{- log(1 - ), 1}  [0, 1],  .

Consider any agent in the public good game, its utility is specified as

thus we have

( , -)= 1-

1-  (1 - )

=1 = 0,

(1, - ) - (0, - ) = (1 - ) - .


We divide into three cases.
Case 1.  (1 - ) - > . This implies have

= 1 and

= min{- log(1 - ), 1} = 1. Now we

(1 - ) - >  (1 - ) > +  log (1 - ) > log( + )







 - log(1 - ) < - log( + ) < - log = .


Since max  {- log(1 - )}   - log(1 - ) < < 1, we have  =  - log(1 - ) < , this satisfies the equilibrium condition of the threshold game.
Case 2.  (1 - ) - < - . This implies = 0 and = 0. Similar to the first case, we have

(1 - ) - < -  (1 - ) < -  log (1 - ) < log( - )







 - log(1 - ) > - log( - ) > - log = .


Since < 1 and - log(1 - ) > 0 for   , we conclude that  =  min{- log(1 - ), 1} > , this satisfies the equilibrium condition of the threshold game.

Case 3  (1 - ) -  [- , ]. This time can be any number in [0, 1], so does . We need to verify that   [ - 8 , + 8 ]. We have

(1 - ) -  [- , ]  (1 - )  [ - , + ]





 - log(1 - )  [- log( + ), - log( - )].


When

<

<

min{0.1,

8,

1- 8

},

we

can

prove

that

[- log(

+

), - log(

-

)]  [

-8 ,

+ 8 ].

We defer the calculation to lemma A.1. Now we have  =  min{- log(1 - ), 1} =

 - log(1 - )  [ - 8 , + 8 ], which satisfies the equilibrium condition.

We next show there is a polynomial time reduction from public good games to threshold games.

Similar as above, given an instance of public good game defined on ( , ), = 1, 0 < < 1,

we construct a threshold game on the same network ( , ), with

=

1 2

.

Given

an

-approximate

equilibrium x = ( 1, . . . , ) of the threshold game, we recover an -4 log( ) -Nash s = ( 1, . . . , )

of the public good game as follow,

1- 2 =1



1 2

+

otherwise.

For any agent , if 

>

1 2

+

, then

= 0 and

= 0 by definition. It then follows that

(1, - ) - (0, - ) =  (1 - ) -   2 -  1+2 - < 0. Hence, it satisfies

the equilibrium condition. If 

<

1 2

-

, then

= 1 and

= 1. Meanwhile, we have

(1, - ) - (0, - ) =  2 - > 1-2 - > 0. Finally, if 



[

1 2

-

,

1 2

+

], we

have (1, - ) - (0, - ) =  (1 - ) - =  2 -  [ ( 2 - 1), ( -2 - 1)] 

[2 log( ) , -4 log( ) ]. Here we use the facts that  - 1  2 for < 1. Therefore, we

have verified that s = ( 1, . . . , ) is an -4 log( ) -Nash of the public good game. Hence, setting

= -4 log , we conclude the proof.

Lemma A.1. For any 0 < < 1 and 0 <
(1) - log( - - ) < + 8 , (2) - log( - + ) > - 8 .

<

min{0.1,

8,

1- 8

},

we

have

P . We have

- log( - - ) < + 8  log( - - ) > -( + 8 )  - - > -( +8 )  - 1 - -8 >  1 - -8 > 3 .

By simple calculations, we can show 1 - -8 > 3 for < 0.1. On the other side, we have - log( - + ) > - 8  log( - + ) < -( - 8 )  - + < - · 8  - ( 8 - 1) 

This follows from the fact that

-( 8

- 1)



1 3

(

8

- 1)



8 3

>

.

A.2 Missing proof from Section 4.2 We provide PPAD-hardness proof for threshold game.

T

A.2 (R

T

4.7). It is PPAD-hard to find an -approximate equi-

librium of the threshold game, for some constant > 0.

P

. We fix the threshold

=

1 2

in the rest

of

the

proof. Furthermore, we restrict

the equi-

librium

strategy

in

[0,

1 2

+

]  {1}, since for any

-approximate equilibrium x = (

1, . . . ,

), we

could set

~= 1



1 2

+

otherwise

and we can easily verify that x~ = [ ~1, . . . , ~ ] is still an -approximate equilibrium. We use the

strategies of players in the threshold game to represent an -approximate assignment to -GCIRCUIT,

and build all 9 types of gates in { , × , =, +, -, <, , , ¬}. We start from constructing

an elementary game gadget

1 2

-

(

|

1,

2|

) (see Figure 5), where

1,

2

{

} are input players,

 is the output player. The output player could have many out-coming edges, but it only has

one in coming edge from the internal node

. The elementary gadget

1 2

-

(

|

1,

2|

) serves as a

building block for later constructions and proves useful throughout our proof. Ideally, it poses the

constraint that x[

]

=

max{

1 2

- x[

1] - x[

2], 0}

in an equilibrium.

2 1
Fig. 5. Elementary gadget

Lemma A.3. Consider the game gadget

1 2

-

(

|

1,

2|

) constructed in Figure 5. In any

-approximate

equilibrium of the threshold game G(

,

,

1 2

),

we

have

x[

]

=

max{

1 2

- x[

1]

- x[

2], 0}

±

. In

particular, if we set 2 =

, then x[

]

=

max{

1 2

-x[

1], 0}±

; if we set

1,

2=

, then x[

]=

1 2

±

.

P . Consider the in-coming neighbors of player , = { , 1, 2}. In an -approximate

equilibrium, if x[

] +x[

1] +x[

2] >

1 2

+

, we have x[

] = 0±

and x[

] = 1 ± . It then follows

that x[

] = 0±

. This implies x[

1] +x[

2]

>

1 2

,

and

thus

max{

1 2

-

x[

1] -x[

2], 0}±

= 0 ± . This

satisfies the equilibrium condition. If x[

]

+ x[

1]

+ x[

2]

<

1 2

-

, then we have x[

] = 1±

and

x[ ] = 0± , this again implies x[ ] = 1± . This contradicts with the fact that x[ ] +x[ 1] +x[ 2] <

1 2

-

. In summary, we have x[

]

=

max{

1 2

- x[

1] - x[

2], 0} ±

.

Now we are ready to construct

=,

+,

-,

1 and
2

×

1 2

.

We

assume

the

inputs

of

these

gates

belong

to

[0,

1 2

+

], except for the COPY gate. This assumption is not a loss of generality since: (1)

if the input node 1 is also the output node of another gate, then it is value is guaranteed to be in

[0,

1 2

+

] by our construction below; (2) otherwise, we can always apply a COPY gate to restrict

its

value

in

[0,

1 2

+

].

(1) COPY

=(| 1 | ). Concatenating

1 2

-

(

|

1|

2) with

1 2

-

(

|

2|

), then we have x[

2]

=

max{

1 2

-

x[ 1], 0} ±

, and x[

]

=

max{

1 2

-

x[

2], 0} ±

=

min{x[

1],

1 2

}

±

2

.

(2) ADD

+(| 1, 2 | ). Concatenating

1 2

-

(

|

1,

2|

3) with

1 2

-

(

|

3|

), then we have x[ 3] =

max{

1 2

- x[

1]

- x[

2], 0}

±

and x[

]

=

max{

1 2

- x[

3], 0} ±

=

min{x[

1]

+ x[

2],

1 2

}

±

2

.

(3) SUBTRACT

-(| 1, 2 | ). Concatenating

1 2

-

(

|

1|

3) with

1 2

-

(

|

2,

3|

), then we have

x[

3]

=

max{

1 2

-

x[

1], 0} ±

and x[

]

=

max{

1 2

-

x

[

2] -x[

3], 0} ±

= max{x[ 1] - x[ 2], 0} ± 2 .

(4) VALUE

1 ( ). We can simply use
2

1 2

-

(

|

1|

) with

1=

, i.e., there is no input to the

gadget.

(5) HALF 1 (| 1 | , ). The HALF gate is shown in Figure 6. In order to halve the value of the 2
input player, we need to carefully compose 4 elementary gadgets. Ideally, in an equilibrium profile,

we expect x[

]

=

1 2

- x[

1], x[

] = x[ 1] - x[ ] and x[

]

=

1 2

- x[

1] + x[

]. The fourth gadget

poses the constraint that

1 2

- x[

1]

+ x[

]

+ x[

]

=

1 2

,

i.e.,

x[

1]

= 2x[

]. Formally, we have

2

3

1

4

1
Fig. 6. HALF gate

Lemma A.4. Consider the game gadget constructed in Figure 6, in any -approximate equilibrium

of the threshold game G(

,

,

1 2

),

we

have

x[

]

=

1 2

max{x[

1],

1 2

}

±

5

.

P

. By Lemma A.3, we have x[

]

=

max{

1 2

-

x[

1], 0}

±

=

1 2

-

x[

1]

±2

.

The

second

equality holds since we assume x[

1]



1 2

+

. Consequently, we have x[

]

=

max{

1 2

-

(

1 2

-

x[ 1]) - x[ ], 0} ± 3 = max{x[ 1] - x[ ], 0} ± 3 . We consider two cases.

(1) If x[ 1]  x[ ], then we have x[

] = x[ 1] - x[ ] ± 3

and x[

]

=

max{

1 2

- x[

1]

+

x[ ], 0} ± 4

=

1 2

- x[

1]

+ x[

]

±4

.

Now

consider

the fourth

gadget, we

conclude

that

x[

]

=

max{

1 2

-

(

1 2

- x[

1] + x[

]), 0} ± 5

=

x[

1]

- x[

]

±5

, which implies that x[

]

=

1 2

x[

1] + 3

.

(2) If x[ 1] < x[ ], then we have x[

] = 0 ± 3 . This implies x[

]

=

1 2

±4

and x[ ] = 0 ± 5 .

Since we assume x[ 1] < x[ ], it follows that x[ 1] < 5

and x[ ] =

1 2

x[

1]

±

5

.

Hence,

we

conclude the proof.

Logic gates can be implemented simply as +, - and 1 . However, gates constructed this way 2
are not error resilient, i.e., they would amplify the input errors, and this would only establish PPAD-

hardness for approximation = 1/poly( ). Error resilience brings this up to a fixed constant. The

idea

is

that

we

first

convert

{0,

1 2

}

to

{0,

1},

do

logic

operations

on

{0,

1}

(which

is

error

resilient),

and

finally

transform

back

to

{0,

1 2

}

We first construct a gadget

1,

1 2

(

|

1|

)

that

transforms

{0,

1}

to

{0,

1 2

}.

We

can

simply

use

the

COPY gate and it satisfies

x[ ] =

0±3

1 2

±

3

x[ 1] = 0 ± x[ 1] = 1 ±

.

Before we construct

1 2

,1

(

|

1|

),

which

transforms

{0,

1 2

}

to

{0,

1},

we

construct

the

comparison

gadget.

1

1 2

-

2

1

1 2

2

Fig. 7. Comparison gadget.

Fig. 8. OR gadget.

¯ Fig. 9. Not gadget.

(6) COMPARE

< (| 1, 2 | ). We first apply

1 2

-

(

|

2|

), then connect

, 1 to a new vertice

(see fig. 7). Finally, we concatenate a gadget

1,

1 2

(

|

| ). Since we will never compare numbers

greater

than

1 2

+

, we have x[

]

=

max{

1 2

-

x[

2], 0}

±

=

1 2

- x[

2]

±2

and x[

] + x[ 1] =

1 2

- x[

2] + x[

1] ± 2

. If x[

1]

<

x[

2] - 3

, then x[

] + x[

1]

<

1 2

-

. This implies x[

] = 1±

and x[

]

=

1 2

±3

. If x[

1]

>

x[

2]

+3

, then x[

]

+ x[

1]

>

1 2

+

and x[

] = 0 ± . It then

follows that x[ ] = 0 ± 3 .

Now, we can just use a truncated version

<(

1 4

,

1

), which does not include the last

1,

1 2

(

|

|)

gadget), as the transformer gadget

1 2

,1

(

|

1|

). It satisfies

x[ ] =

0± 1±

x[ 1] = 0 ±

x[

1]

=

1 2

±

.

We next construct the logic gates.

(7) OR (| 1, 2 | ). We first apply transformation gadgets

1 2

,1

(

|

1|

) and

1 2

,1

(

|

2|

), then

connects and to a new vertex , which is then connected to the vertex (see Figure 8).

Finally, we concatenate the transformation gate

1,

1 2

(|

|

). Suppose x[ 1]

=

1 2

±

3

, it then

follows x[ ] = 1 ± 3 . Therefore, x[ ] = 0 ± and x[ ] = 1 ± . After the transformation, we

have x[

]

=

1 2

±3

. Similarly, x[

1]

=

1 2

±3

. On the other hand, if

x[

1], x[

2]

=

0±3

, then we

have x[ ], x[ ] = 0 ± 6 and x[ ] = 1 ± . Hence, x[ ] = 0 ± . After the transformation, we

get x[ ] = 0 ± 3 .

(8) NOT

(| 1 | ). We first apply

1 2

,1

(

|

1|

). We then connect

to a new node

, and apply

1,

1 2

(

|

| ) (see Figure 9); proof omitted.

We can construct the AND gadget  (| 1, 2 | ) using  (| 1 | ) and ¬ (| 1, 2 | ). Thus far,

we have constructed all 9 types of gates { , × , =, +, -, <, , , ¬}, and therefore, we

conclude the proof for Theorem 4.7.

