arXiv:2106.01104v1 [stat.ME] 2 Jun 2021

Filtrated Common Functional Principal Components for Multivariate Functional data
Shuhao Jiao1, Ron D. Frostig2, and Hernando Ombao1
1Statistics Program, KAUST, Saudi Arabia 2Department of Neurobiology and Behavior, UC Irvine, USA
Abstract
Local field potentials (LFPs) are signals that measure electrical activity in localized cortical regions from multiple implanted tetrodes in the human or animal brain. They can be treated as multivariate functional data (i.e., curves observed at many tetrodes spread across a patch on the surface of the cortex). Most multivariate functional data contain both global features (which are shared in common to all curves) as well isolated features (common only to a small subset of curves). The goal is this paper is to develop a procedure for capturing this common features. We propose a novel tree-structured functional principal component (filt-fPC) model through low-dimensional functional representation, specifically via filtration. A popular approach to dimension reduction of functional data is functional principal components analysis (fPCA). Ordinary fPCA can only capture the major information of one population, but fail to reveal the similarity of variation pattern of different groups, which is potentially related to functional connectivity of brain. One major advantage of the proposed filt-fPC method is the ability to extracting components that are common to multiple groups, and meanwhile preserves the idiosyncratic individual features of different groups, leading to a parsimonious and interpretable low dimensional representation of multivariate functional data. Another advantage is that the extracted functional principal components satisfy the orthonormal property for each set, making filt-fPC scores easy to be obtained. The proposed filt-fPC method was employed to study the impact of a shock (induced stroke) on the functional organization structure of the rat brain. Finally we point to further directions as this filtration idea can also be generalized to other functional statistical models, such as functional regression, classification and functional times series models.
Key words: Functional principal component, Community detection, Dimension reduction, Multivariate functional data, Network filtration, Unsupervised learning, Weighted network. shuhao.jiao@kaust.edu.sa rfrostig@uci.edu hernando.ombao@kaust.edu.sa
1

1 Introduction
1.1 Data description and statistical challenges
This work is motivated by a neuroscience project conducted by co-author (R. D. Frostig, UC Irvine) where the goal is to study the impact of an extreme shock (such as a stroke) on the functional organization of the rat brain. The experiment, described in Wann (2017), simulated ischemic stroke by clamping the medial cerebral artery. Brain activity was continuously monitored over several hours through the local field potential (LFP) recordings from 32 micro-tetrodes that were directly implanted onto the rat cortex. In this experimental set-up, two phases or groups of the LFP recording were considered: pre-stroke onset and post-stroke onset (post-clamping). In the experiment, the researchers focused on the 10-minute period around stroke onset (5 minutes immediately prior to the stroke onset and 5 minutes during the post-stroke onset phase). The LFP data was segmented into separate epochs where each epoch corresponds to 1-second quasi-stationary recordings. Thus, each of the pre-stroke and post-stroke onset phases consists of 300 multivariate (32-dimensional) functional curves. Figure 1 displays one pre-stroke onset epoch from the first 15 tetrodes and Figure 2 shows the placement of the micro-tetrodes. The plots convey that the trajectories from some tetrodes share similar variation patterns due to the spatial correlation, while individual variation features also exist across tetrodes. Therefore the functional principal components of some tetrodes should be similar, but not identical since the signals captured by specific tetrodes should also present their own unique features of variation pattern.
Figure 1: One pre-stroke onset epoch (1 second) of the first 15 tetrodes
2

These LFPs are zero-mean signals, and thus to study the impact of stroke on rat brain, we will specifically examine the changes in the covariance structure of epoch trajectories by studying the pre-stroke and post-stroke onset epochs separately. Here, we say "covariance structure" instead of "covariance operator" because the major interest here is the variation pattern instead of variability level.
Figure 2: Placement of the 32 microtetrodes in the cortex of the rat. There are 8 columns (blue) of micro-tetrodes, each column having 4 layers (red) over a cortical patch (Wann (2017)).
The goal here is to develop a statistical method that extracts both (i) common components across all tetrodes for pre-stroke and post-stroke onset epochs separately and (ii) idiosyncratic or tetrode-specific unique components. As the functional principal components of different tetrodes can be quite similar due to the synchronization phenomenon, it is possible to obtain a much more parsimonious filt-fPC representation by employing common components across different tetrodes.
1.2 Existing fPCA methods for multivariate functional data
Functional data analysis is an active area driven primarily by its wide range of potential applications. Due to the infinite dimensionality of functional data, one of the fundamental techniques in analyzing functional data is dimension reduction. Functional principal component analysis (fPCA), as described in Ramsay & Silverman (2004), is a widely-applied dimension reduction technique for functional data analysis because it gives the optimal approximation of functions with respect to the integrated square error of reconstruction, and at the same time yields results that are easily interpretable in the sense that it captures the principal directions of variation.
In many experiments, multiple functional trajectories are collected simultaneously for a sample of subjects or experimental units. Such type of functional data are called as multivariate functional data. Statistical methods for multivariate functional data need to be developed to account for the simultaneous variation of multiple groups of functions, which, in our application, might be correlated across tetrodes within both the pre-stroke and post-stroke onset phases. However, there are only a few methods that are appropriate for this type of functional data.
3

Applying ordinary univariate fPCA to all groups together may not be suitable for multivariate functional data, especially when there is substantial variation in the covariance functions of different groups of functions, and employing group-wise fPCs for each group may lead to a huge number of fPCs when the number of groups is large. In addition, univariate fPCA ignore the dependence between components of the multivariate functional data. Several methods for multivariate functional principal component analysis have been recently developed. Kayano & Konishi (2009) developed functional principal component analysis for multivariate functions with Gaussian-shape basis. Berrendero et al. (2011) proposed the multivariate principal component with functional scores. Chiou et al. (2014) and Jacques & Preda (2014) proposed the multivariate principal component which describe the variation pattern of multiple groups jointly, and Happ & Greven (2018) developed the multivariate functional principal component for functions defined over different domains. Di et al. (2009) proposed multilevel functional principal components which explain the variability within and between different groups of functions, and Di et al. (2014) extended this to sparse sampled multilevel functional data. Greven et al. (2011) developed a similar framework of longitudinal functional principal component by combining the covariance of within-subject and between-subject components.
There are also methods on principal component analysis of multiple multivariate data. Common principal component analysis (CPCA, see e.g. Flury (1984), Benko et al. (2009)) and partial common principal component analysis (PCPCA, see e.g. Flury (1987), Schott (1999), Wang et al. (2019)) aim to find the common principal component for multi-group multivariate data. Crainiceanu et al. (2011) proposed a population value decomposition (PVD) procedure, and the common eigenvectors are obtained from concatenated individual eigenvectors. Lock et al. (2013) and Feng et al. (2018) proposed JIVE and AJIVE procedures to extract common and individual components for multiblock data. Unlike these methods, our method is developed for functional data.
Compared to the existing multivariate functional principal components analysis (MfPCA) proposed in Chiou et al. (2014) and Happ & Greven (2018), our proposed filtrated principal components (filt-fPC) analysis consists of multiple sets of scores. The MfPCA method in Chiou et al. (2014) can be viewed as the univariate fPCA on concatenated functions. In other words, their MfPCA method is equivalent to univariate fPCA method on concatenated functions and employ one single set of concatenated principal components for all groups of data. In contrast, our proposed filt-fPC simultaneously extracts both common and individual features. Thus, the proposed filt-fPC has the advantage of giving a more detailed analysis.
It must be emphasized that, unlike CPCA and PCPCA, the main goal of this paper is not to find the actual common principal components across different groups of data. Instead, we aim to develop an easy-to-implement dimension reduction algorithm for multivariate functional data simultaneously and efficiently, and reveal the potential dependence between different groups. Specifically, we wish the approximation of filtfPCs of all groups are efficient with respect to integrated square error, and meanwhile, extract common features of different groups. We understand it is tempting to find
4

the actual common principal components, however, in practice, the actual common principal components do not necessarily account for much variability for each group. Thus instead of finding the potentially trivial actual common principal components, we propose another type of "common principal component" which is more practically useful.
Thus our method leads to a more detailed and sophisticated analysis, in the sense that our approach reveals both the individual features and the dependence between different groups of functions. Moreover, a weakness of the current univariate representation of multiple functional data is that it does not guarantee that all groups of functions are approximated well. The advantage of the filt-fPC over the longitudinal-type fPC (see e.g. Di et al. (2009) and Greven et al. (2011)) is that filt-fPCs are a series of orthonormal basis for each group, which then implies that the spaces of different components are completely separated. By the orthogonality property of the filt-fPCs, the fPC scores can be obtained by taking the inner product. Thus it is easier to obtain the scores for filtfPCs compared with longitudinal-type fPCs, which usually needs further complicated steps to obtain the scores as the fPCs are not orthogonal. The thus obtained filt-fPC scores can be important in further statistical inference and modeling, such as regression and classification.
1.3 The proposed filt-fPC method
In this article, we propose a new algorithm to obtain principal components of multivariate functional data. The filt-fPC is a data-driven method that extracts the principal components via filtrations with different thresholds. At each filtrations step, we extract the common filtrated principal component of multiple groups of functions.
Inspired by the idea of multi-thresholding in network analysis, we build on this to find the hierarchically nested structure of variation pattern. Chung et al. (2017) applied a similar idea called graph filtration to measure the similarity of different weighted networks. However, they proposed to try all possible thresholds, which is not suitable in our case, as one of the goals here is to reduce the dimension, and if we try all possible thresholds, the dimension will be extremely large, leading to computational intractability. Thus we need to carefully specify the thresholds, and we propose a data-adaptive approach in Section 3.3.
The hierarchical tree structure of filt-fPCs is visualized in Figure 3. The filt-fPCs typically capture the common variation patten of partial groups, where the filt-fPCs in the first layer capture the most common principal components. Over the sequence of filtrations, the groups will be separated into more smaller communities where the common principal components are obtained. Therefore, the obtained filt-fPCs tend to explain more idiosyncratic variation features.
Typically, two sets of groups will share some common filt-fPCs if two qualitative conditions hold: 1). They share similar variation patterns; 2). The shared patterns account
5

The 1st filt-fPC

The 2nd filt-fPC

······

The 2nd filt-fPC

The 3rd filt-fPC · · · The 3rd filt-fPC · · · The 3rd filt-fPC · · · The 3rd filt-fPC

...

...

...

...

...

...

...

...

Figure 3: Hierarchical tree structure of filt-fPC. The filt-fPCs in different rectangle of the same layer explain the common variation pattern for different communities of groups. Generally, there can be multiple communities in the first layer.

for a sufficient large proportion of variability. These conditions may lead to marginal increase of total number of filt-fPCs, since the actual common principal components may be trivial, and in our procedure, common filt-fPCs can be detected only when they are not trivial for the groups where the they are employed. The common and trivial components will be discarded without much loss.
The proposed filt-fPC method has the following advantages, which will be demonstrated in simulations and analysis of the rat LFP trajectories:

1. It efficiently reduces the dimension of multivariate functional trajectories with much less principal components compared to ordinary group-wise fPC.
2. It produces functional principal components that are easy to interpret.
3. It produces functional principal components that will potentially reveal both the dependence and difference of various groups of functions.
4. It produces basis functions that are orthonormal within each group and thus greatly reduces computational burden.

Lastly, we would like to emphasize that this paper is a start point of applying filtration technique to functional data. The same strategy can be also adapted to many functional data models and problems, such as functional linear regression model, functional autoregressive model, and functional classification problem with multivariate functional data. This technique is useful especially when the sample size is limited, which is often the case in real data analysis of functional data.
The rest of the paper is organized as follows. In Section 2, we introduce some preliminaries of functional data. Section 3 presents the filtration procedure, a new community detection algorithm, and the computing procedure of filtrated functional principal component. Section 4 presents some simulation results. Section 5 presents the real data
6

analysis on the local field potential of rat brain activity. Conclusions and summaries are made in Section 6.

2 Preliminaries of functional data

The notation X(t)  LpH = LpH(, A, P) indicates that, for some p > 0, a H-valued function X(t) satisfies E{ X(t) p} < , and here H = L2[0, 2]. In what follows, we

assume all trajectories {Xk(t) : k  N} being functions defined in the Hilbert space

L2[0, 1], where the inner product is defined as

x, y

=

1 0

x(t)y(t)dt,

and

the

norm

is

defined as

x 2=

1 0

x(t)2dt

<

.

If

X (t)



L1H ,

we define the

mean

function

by

µ(t)

=

E{X(t)}, and if X(t)  L2H, we define the covariance operator  : L2[0, 1]  L2[0, 1]

by (x(t)) = E[ X - µ, x (X - µ)(t)], where x(t)  L2[0, 1]. By the Mercer's theorem,

we have the following expression for the symmetric positive-definite compact operator

(x),


(x) = j j, x j(t),

x  L2[0, 1]

j=1

where {j : j  N+} are the positive eigenvalues (in strictly descending order) and {j(t) : j  N+} are the corresponding normalized eigenfunctions, so that (j) = jj and j = 1. {j(t) : j  N+} forms a sequence of orthonormal bases for L2[0, 1]. Let {Xn(t) : n  N} be a sequence of functional trajectories with mean function µ and covariance operator (x), then by the statement of Karhunen-Lo`eve theorem, under
mild conditions, Xn(t) admits the representation


Xn(t) = µ(t) + Xn - µ, j j(t),
j=1

n  N.

The coefficients { Xn - µ, j : j  N+} in this expansion are called the fPC scores of Xn(t). Suppose that we have N samples X1(t), . . . , XN (t), then in practice we usually estimate µ pointwisely by

1N

µ^(t) = N

Xn(t),

n=1

and the covariance operator by

t  [0, 1],

1N

(x(t)) = N

Xn - µ^, x (Xn - µ^)(t),

n=1

x  L2[0, 1].

Now we define a Hilbert space M = (L2[0, 1])G for multivariate functional data X =
(X1, . . . , XG) as a compact metric space equipped with the inner product X1, X2 M =
G
fv X1v, X2v . In this definition, (f1, . . . , fG) is a set of fixed constants, indicating
v=1
the importance of different components of X , and fv  0.

7

For a community C including partial elements of X , the common filtrated functional principal component is defined as

arg min fvE Xv - Xv,  Xv 2.  =1 vC
The following proposition indicates how to find the filt-fPC given a community C.

Proposition 1. Let X  M, where each element Xv is squared integrable random process in L2[0, 1]. The minimizer of fvE Xv - Xv,   2 under  = 1 is the
iC
first eigenfunction of the symmetric positive definite operator fvv(·), where v(·) =
iC
E{ Xv, · Xv}.

Remark 1. Proposition 1 indicates how to obtain the filt-fPCs given a community

structure. In practice, we can replace fvv(·) with its empirical version fvv(·),

vC

vC

and set its first eigenfunction as the filt-fPC of community C. By Theorem 3.1 in

Hormann and Kokoszka (2010), fvv(·) is a consistent estimator of fvv(·) under

vC

vC

some mild conditions.

3 Network model and filtrated fPCA

3.1 The filt-fPC representation

Recall that there are multiple groups of functions in our experiment for both the prestroke and the post-stroke onset phase, and our primary aim is to find the principal components that jointly explain the variability of multiple groups in a filtrating manner, i.e., obtain the common fPCs for each of the tree-structured communities. The first principal components capture the most significant common variation pattern, and as over the sequence of the filtration, the filt-fPCs tend to reveal localized (smaller communities of groups) patterns and idiosyncratic individual variation features.

Now define Xvn(t) to be the n-th function in group v for v = 1, . . . , G, n = 1, . . . , N . In our application, G = 32, corresponding to 32 tetrodes, and N = 300 corresponding to 300 epochs. The key idea of filt-fPC is to represent {Xvn(t) : v = 1, . . . , G, n = 1, . . . , N } in the following form,



Xvn(t) = µv(t) +

Xvn

-

µv ,

(cv,d) d

(cv,d) d

(t),

d=1

(3-1)

where cv,d is the community index of group v in the d-th layer.

Here, we define a community as the set of groups where the same filt-fPC are employed for all the groups in that set, and we develop a novel thresholding­detection method to

8

find the communities for each filt-fPC, as will be discussed in Section 3.2 and 3.3. µv is

the mean function of the v-th tetrode epochs, which is zero in our project since LPFs

always

oscillate

near

zero.

((1cv,1

),

(cv,2) 2

,

.

.

.)

are

a

series

of

orthonormal

basis

functions,

and

hence adaptive

to

the

unique

feature

of each

layer.

{

Xvn

-

µv ,

(cv,d) d

: d  N+}

are the filt-fPC scores of group v.

Remark 2. Expression (3-1) is not the most efficient representation for each single set v, but presents a parsimonious basis representation for the G groups jointly. The number of filt-fPCs would be very small if most groups are clustered into the same community, and in this case, the common variation patterns dominate the functions across all groups.

3.2 Weighted brain network and multi-thresholding

A preliminary step prior to finding the common filt-fPCs is to evaluate the similarity of the covariance structures. We motivate our approach by first developing the notion of similarity through a weighted network model. A weighted network model is a triple (N, E, ), where N is the node set, E is the edge set, and  is the set of edge weights. Here, the edge set E is defined to be complete if every pair of nodes are connected to each other, which is the case in our application, and  represents the strength of the connection between each pair of nodes in N , which is potentially related to group dependence. In our application, the nodes represent tetrodes, edges can be viewed as the existence of functional connectivity between two nodes, and edge weights evaluate the similarity of covariance structures. In our application, a small value of edge weight indicates similar variation patter.

The principle is that, if two nodes are connected, then the two groups of functions are considered to share some similar variation patterns. Over the sequence of filtrations, more edges are truncated with increasing thresholds, which indicates the common components disappear or become trivial and the filt-fPCs extract more distinctive variation pattern of smaller communities.

The first step is to specify a sequence of positive thresholds {d : d  1} in strictly decreasing order, and the number of thresholds is identical to the number of the filtrated principal components of each group. For each d, we truncate the edge weights as follows

idj =

ij , 0,

if ij  d if ij > d.

where i, j = 1, . . . , G, and then apply our proposed community detection algorithm (see Section 3.4) to separate the nodes into different disjoint communities.

Figure 4 presents an toy example of multi-thresholding, where in the second thresholding, the nodes are separated into three communities, and thus we have 3 filt-fPCs in the second layer. The last threshold truncates all the edges, so that all nodes are not connected, and the thus obtained filt-fPCs explain the idiosyncratic variation pattern

9

of each individual group. In our method, the thresholds are selected in a data-adaptive way. More details will be discussed in Section 3.3.

Figure 4: Multi-thresholded networks. In the original weighted network, there are only two values of edge weight, say, 0.9,0.2, and the thresholds are 1,0.6 and 0.1 corresponding to the three subfigures.
The edge weight  should be a reasonable measure of the similarity between different covariance functions. In our application, we define the weight of edge adjacent to nodes i and j, ij, as ij = Ci - Cj S, where Ci is the scaled covariance operator of the trajectories of the i-th group, defined as Ci = i/ j1 ij, and ij is the j-th eigenvalue of covariance operator of the i-th group i, and · S denotes the Hilbert-Schmidt norm. The scaling step prevents the groups with high variability from overly laying influence on the filt-fPCs.

3.3 Selection of community structure

3.3.1 Generalized information criterion

Motivated by generalized information criterion (GIC, Nishii (1984)), we propose a penalized criterion, which follows the format: measure of model fitting + tuning parameter × measure of model complexity. Specifically, for a given community structure C, we define the GIC value to be

G
GIC(C,1:D) = -N -1 fv
v=1

ND
Xvn, (dc) 2
n=1 d=1

+ N (C,1:D),

(3-2)

where C is the cardinal (the total number of communities) of C. The optimal community is defined as the minimizer of GIC(·). Notationally, C,1:D represents the first D layers of community structure C.

To illustrate the large-sample property of the selected community structure, we introduce the following concepts. Let {vd : d  1} being the ordinary fPCs of the v-th group, and the following concept quantifies the difference between the filt-fPCs and ordinary fPCs.

10

Definition 1 ( -oracle community structure). A community structure C is called  -oracle community structure ( -oracle CS) if the following conditions are satisfied.

1). E

G

D
( Xvn, vd 2 -

Xvn

,

(cv,d d

)

2)

= O(D- );

v=1 d=1

2). C has the minimal cardinal among all the community structures satisfying 1).

We classify the community structures into three categories H,- (under-fitted), H and H,+ (over-fitted), defined respectively as

H,- = C : ,D := E

GD

( Xvn, vd 2 -

Xvn

,

(cv,d d

)

2)

= O(D-1, ), 1, < 

,

v=1 d=1

H = C : ,D := E

GD

( Xvn, vd 2 -

Xvn

,

(cv,d d

)

2)

= O(D- )

,

v=1 d=1

H,+ = C : ,D := E

GD

( Xvn, vd 2 -

Xvn

,

(cv,d d

)

2)

= O(D-2, ), 2, > 

.

v=1 d=1

To establish the consistency of the criterion, we make the following regularity assumptions. In the following, "const." signifies a positive constant.

Assumption 1. {Xvn(t) : n  1} is L4 - m-approximable process for any v, and

max
t[0,1]

EXv2n(t)

<



for

any

v.

Assumption 2. For an arbitrary subset U  {1, . . . , G}, the eigenvalues of the operator vU v(x), x  L2[0, 1], are distinct.
Assumption 3. For each v, the covariance operator Cv(x) admits the spectral decomposition
Cv(x)(t) = vj vj, x vj(t),
j1
and there exists some  > 1, so that infv(vj - v,j+1)  const.j-.

Assumption 4. There exists some > 0, so that inf|1,- | > and inf|2,- | > . For two arbitrary community structure C1, C2  H , |1,D - 2,D| = o(DN- ).
Assumption 5. DN = N 1/,  > 2( +  + 1),  / < 1/2.

Assumption 1 indicates that the functions in all the groups are weakly dependent (see Ho¨rmann et al. (2010)). Assumption 2 and 3 assures the identifiability of the filt-fPCs. Assumption 4 assure the identifiability of the  -oracle CS. Assumption 5 includes all the regularity conditions on the decay rate of the tuning parameter.  > 2( +  + 1) prevents the estimation error to be overly large.
Notationally, define ,d = C,1:d - C,1:d as the difference of community number in the first d layers. With the Assumption (1)--(6), we can develop the theorem displayed
11

below, which literally illustrates the conditions under which the  -oracle CS can be found with probability 1 asymptotically, but essentially demonstrates how the selection of the tuning parameters influences the efficiency of the filt-fPCs.

Theorem 1. Suppose that Assumption (1)--(6) hold, and H = , if the two conditions below hold

N < O(min{|,DN |-1N -1,/}), N > O(max{|,DN |-1}N -/),

C  H- C  H+,

the selected community structure C by minimizing (3-2) satisfies P (C = C )  1 as N  .

Remark 3. Theorem 1 provides some guidance of how to select the tuning parameter N and dimension DN as the sample size grows larger. The cardinal difference ,DN depends on the community detection algorithm, which is an unsupervised learning
process. Our community detection algorithm will be developed in Section 3.4.

Remark 4. Practically, for a given D, cross-validation (CV) is always a good method for selecting the tuning parameter. In each CV iteration b, we can spare some data to calculate the total residual mean of squares (TRMS),

B

(#I(b)B)-1

Rv(Dn ) 2,

v1

b=1 nI(b)

over all iterations (B is the number of iterations, I(b) is the training set in the b iteration, and # signifies the set size) and select the tuning parameter so that the TRMS is decent and the corresponding community structure is parsimonious.

3.3.2 Iterative selection of thresholds

Since optimal, exhaustive community selection is hard to implement, we develop an iterative procedure to select the thresholds which determine the community structure. How to select the thresholds for truncating the weighted edges remains an open question. A typical selection criterion in network analysis is to select thresholds so that a desired or persistent network structure is preserved. This is a feasible method if pre-knowledge of communities are available. However, in practice, such pre-knowledge is not always available and a data-adaptive method is necessary for general cases.

The goal of filt-fPCs is to find a decent parsimonious approximation for all groups of

functions. Without loss of generality, it is assumed µv = 0 for all v  1. Therefore, we propose the following iterative GIC selection procedure, which is regularized

by the number of communities in each layer. Denote the filt-fPC score as Zvn,d =

Rv(dn-1),

(cv,d d

)

,

where

Rv(dn)(t)

=

Xvn

-

d

Xvn

,

(cv,j j

)

(cv,j j

),

then

the

GIC

value

at

j=1

12

layer d can be expressed as

G
GIC((dcv,d) : v = 1, . . . , G) = - fv
v=1

N

N -1

Zv2n,d

n=1

+ N (d)Cd,

where N (d) is typically a decreasing function with respect to d. We propose to minimize the above quantity to determine the community structure for layer d. Supposing the (d-1)-th threshold is d-1, the d-th threshold is searched along the interval [0, d-1]. To save computational burden, the thresholds are selected from finite threshold candidates, where each candidate truncates at least one more edge than the smaller candidates.

Denote the community structure selected by the iterative GIC procedure as Citer. The following theorem demonstrates that, under some regularity conditions on {N (d) : d  1}, the iteratively selected community structure will not fall into the under-fitted class if the sample size is large enough, which theoretically guarantees the good performance of the proposed iterative procedure.

Theorem 2. Suppose that Assumption (1)--(6) hold and N = d1 N (d) satisfies the conditions in Theorem 1. If N -1 sup -N2(d)  0, then asymptotically almost surely,
d1
Citer / H,-
Remark 5. By Assumption 5, it follows that N -1-N2  0, and the assumption N -1 sup -N2(d)  0 restricts that the tuning parameter N (d) in each layer d is not
d1
selected overly small. This theorem tells us that, as the GIC criterion with the tuning parameter N = N (d) yields the  -oracle community structure, the iterative selec-
d1
tion procedure is guaranteed to produce decent community structure for better filt-fPC approximation with respect to the approximation error.

Remark 6. The selection of N (d) is typically influenced by two main factors, that is, the overall decay rate of eigenvalues of v's, and the total variability of G groups of functions. For example, if we set N (d) = d-, which is determined by two constant parameters , , then  is related to the overall variability of all groups of functions,
and  is related to the overall decay rate of the eigenvalues of the covariance operators.

3.4 Centroid-based community detection
Community detection, or graph partition, is a widely-accepted tool to reveal the hidden relation among nodes in a network. A popular principle of the existing community detection algorithm for weighted network is making the node within a community more connected than nodes in different communities. The result of such algorithm is that the total edge weights within a community is typically significantly smaller (if small value of edge weight indicates stronger connection) than that of edges connecting different communities (see e.g. Lu et al. (2013), Shen et al. (2016) and Palowitch et al. (2017)).
13

However, in this paper, our goal is to find the common principal components that jointly explain the variation of different groups in a filtrating way, and the community detection is implemented multiple times, thus it is not necessary to require that the intra-community degree (summation of weights within a community) is significantly smaller than between-community degree for a specific layer. This motivates us to find a new community detection algorithm.

Here we define the centroid node vc as the node of which the degree (node degree is defined as the summation of weight of edges adjacent to the node) is minimal, and the community Cvc as the collection of nodes that are connected to the centroid node vc (including the centroid node). Specifically, for a network (N, E, ), the communities and the centroid nodes are defined as the solution to the following optimization problem

(Cvci , vci :

i



1)

=

arg min Cvci N,vciN

(#Evci )-1
i1

jCvci

vcij ,

where #Evc denotes the number of edges adjacent to the centroid node vc in Cvc. In practice, the solution is obtained iteratively over all possible centroid nodes vc and communities Cvc. Specifically, we iterate between detecting the centroid node of a community, and expanding the community by finding all the nodes connected to the
centroid node. The pseudo code of the algorithm is shown in Algorithm 1. where ""
signifies adjacency.

During the iteration, the number of communities may decrease as some communities could be included by others. Some nodes may be assigned to multiple communities, and we re-assign such nodes to the community where they have smaller node degree (step 16­21). #C denotes the number of nodes in community C.
Remark 7. The idea of the community detection algorithm comes from the fact that, given C1, C2, C3, if C1 - C2 S and C2 - C3 S are small, then C1 - C3 S should also be small by the triangular inequality of the Hilbert-Schmidt norm.

3.5 Filtrated functional principal component

In this section, we introduce how to obtain the filtrated functional principal components for each community. Let Xvn(t) be the n-th epoch trajectory obtained from the v-th tetrode. Suppose C11, C12, . . . are the communities in the first layer, then the common filt-fPC of groups in C1i, 1i, is defined as:

1i = arg max  =1

N

fv(1) N

Xvn,  2,

vC1i n=1

for v  C1i, i = 1, 2, . . . .

where fv(d) is the positive weight of group v in the d-th layer.

To make the filtrated principal components corresponding to each group orthogonal, we propose to obtain the second filt-fPC from the projection residuals, say, Rv(1n) =

14

Algorithm 1 Community detection

1: Set k = 1, Nr = N , M = 0. 2: while M < G do

3: Set the node with the most adjacent edges in Nr to be the

centroid node vck.

4: for v in Nr \ vck do

5:

If v  vck , assign v to Cvck .

6: end for

7: Set M = M + #Cvck , Nr = Nr \ Cvck , k = k + 1. 8: end while

9: Set Cvc1, . . . , Cvck as the initial communities. 10: Repeat 11-22 till convergence:

11: for in 1, . . . , k do

12: Set vc = arg min

ij

iCvc ji,jCvc

13: for j in N \ vc do

14:

If j is connected to vc , assign j to Cvc .

15: end for

16: for 1, 2 in 1 : k and 1 = 2 do

17:

if Cvc 1  Cvc 2 = , then

18:

Assign

v  Cvc 1  Cvc 2

to

Cvc

,
1

19:

if (#Cvc 1 )-1

vj

<

(#Cvc

)-1
2

vj, otherwise to Cvc 2 .

jCvc 1

jCvc 2

20:

end if

21: end for

22: end for

23: return the non-empty communities in Cvc1, . . . , Cvck .

Xvn - Xvn, 1i 1i, for v  C1i. The second filt-fPCs are obtained by maximizing the following quantities,

2i = arg max  =1

N

fv(2) N

Rv(1n), 

2,

vC2i n=1

for v  C2i, i = 1, 2, . . . .

Then repeat this projection-maximization procedure till the filt-fPCs are found for all communities of all layers. As illustrated in Proposition 1, the maximizer of the objective

function

N

fv(d) N

Rv(dn-1),  2

vCdi n=1

is the first eigenfunction of the weighted sum of covariance operators

fv(d)(vd)(·),

vCdi

N
where (vd)(·) = N -1 {Rv(dn-1) Rv(dn-1), · }, d  2.

n=1

15

Proposition 2. The filtrated principal components {(dcv,d), d  1} are orthonormal for any v  1.
This proposition is important in the sense that, each filt-fPC pertains to a unique variation feature, and in the finite-dimensional projection of functional linear models, orthonormality avoids cross terms and leads to a concise finite-dimensional representation.

4 Simulation studies

The goal here is to investigate the performance of the proposed filt-fPC method for
analyzing simulated multivariate functions. In the simulations, samples were generated
5
from the following model Xvn(t) = vn,dvd(t), where vd(t) are orthonormal basis
d=1
across v and d. 500 functions were simulated for each of the 16 groups. To obtain
{vd(t) : v  1, d  1}, we first randomly simulated 22 functions with 23 Fourier functions {Fi(t) : i = 1, . . . , 23},

 

1,

Fi(t) = 2 cos(2kt),

 2 sin(2kt),

if i = 1, if i = 2k, if i = 2k + 1,

and then applied Gram-Schmidt process to obtain 22 orthonormal basis functions {B1(t), . . . , B22(t)}. The scores {vn,d : d = 1, . . . , 5} are independent and follow normal distribution N (0, 1.2-d) for v = 1, . . . , 12, and N (0, 1.2d-6), for group v = 13, . . . , 16. The five basis functions employed to generate functions in each group are shown in Table 1.

v

vd(t), d = 1, 2, 3, 4, 5

v

vd(t), d = 1, 2, 3, 4, 5

1 B1(t) B2(t) B3(t) B4(t) B5(t) 9 B1(t) B2(t) B3(t) B4(t) B5(t)

2 B1(t) B2(t) B3(t) B4(t) B6(t) 10 B1(t) B2(t) B3(t) B4(t) B6(t)

3 B1(t) B2(t) B7(t) B8(t) B9(t) 11 B1(t) B2(t) B7(t) B8(t) B9(t)

4 B1(t) B2(t) B7(t) B8(t) B10(t) 12 B1(t) B2(t) B7(t) B8(t) B10(t)

5 B1(t) B11(t) B12(t) B13(t) B14(t) 13 B1(t) B11(t) B12(t) B13(t) B14(t)

6 B1(t) B11(t) B12(t) B15(t) B16(t) 14 B1(t) B11(t) B12(t) B15(t) B16(t)

7 B1(t) B11(t) B17(t) B18(t) B19(t) 15 B1(t) B11(t) B17(t) B18(t) B19(t)

8 B1(t) B11(t) B20(t) B21(t) B22(t) 16 B1(t) B11(t) B20(t) B21(t) B22(t)

Table 1: Basis functions of different groups

The GIC criterion was employed to iteratively detect the community structure, and the penalty term follows the format d = d-. The selected candidates for  are 0.05, 0.1,
16

0.2, 0.3, 0.5, and for  are 1, 1.1, 1.2, 1.3, 1.4. Here we used the ratio

16 500
R=
v=1 n=1

Rv(5n) 2

16 500 v=1 n=1

Xvn 2

to evaluate the approximation performance of the estimated filt-fPCs. The corresponding ratio R according to different pairs of ,  are displayed in Table 2.

  0.05
0.1 0.2 0.3 0.5

1
0.0415 (42) 0.0297 (31) 2.0756 (25) 4.9863 (22) 15.5799 (13)

1.1
0.0415 (42) 0.0297 (31) 2.0756 (25) 2.0756 (25) 9.5763 (17)

1.2
0.0415 (42) 0.0297 (31) 2.0756 (25) 2.0756 (25) 8.1039 (18)

1.3
0.0415 (42) 0.0297 (31) 0.0316 (30) 2.0756 (25) 4.9864 (22)

1.4
0.0415 (42) 0.0297 (31) 0.0297 (31) 2.0756 (25) 4.9864 (22)

Table 2: R values () according to each pair of , , the value in the perenthesis is the total number of filt-fPCs.

A reasonable selection of ,  is 0.2, 1.3, and the corresponding community structure is
1st layer : C1­C16. 2nd layer : C1­C4, C9­C12; C5­C8, C13­C15; C16. 3rd layer : C1, C2, C9, C10; C3, C4, C11, C12; C5, C13; C6, C14; C7, C15; C8; C16. 4th layer : C1, C2, C9, C10; C3, C4, C11, C12; C5, C13; C6, C14; C7, C15; C8; C16. 5th layer : C1, C9; C2, C10; C3, C11; C4, C12; C5; C6; C7; C8; C13; C14; C15; C16.
Based on the result, we can capture most information of the 16 groups with 30 filt-fPCs instead of 80 (16 × 5) group-wise functional principal components. The dimension is significantly reduced with a parsimonious filt-fPC representation. Group 16 is separated from other groups in the 2nd layer because the difference between B22(t) and other Bi(t)'s are more pronounced than others pairs of basis.

5 The analysis of LFPs of rat brain
5.1 Data processing and visualization
The (0, 10)Hz components were extracted from each epoch trajectory, and the filt-fPCs were found for the (0, 10)Hz components under pre-stroke and post-stroke onset phase separately. The same procedure can be employed for any other frequency bands. Here we considered and compared the overall variation pattern difference of pre-stroke and post-stroke onset epochs. If the potential structural breaks in the covariance structure
17

along the sequences are of interest, we can first detect the break points by some methods (e.g., Jiao et al. (2020)) and apply filt-fPCA to each local quasi-stationary sequence segmented by the detected break points. Visualization of post-stroke onset epochs reveals that irregular extreme values occasionally occurs. Therefore, to stabilize the variance of the post-stroke onset recordings, we applied the square root transformation to the post-stroke onset epochs, and outlier epochs were removed from each tetrode, where outlier epochs in each group are defined as those whose norm is beyond the interval [Q1 - 1.5 × IQR, Q3 + 1.5 × IQR], and here IQR = Q3 - Q1 and Q1, Q3 are the first and third quantile of the l2-norm of the epoch trajectories. Denoting the covariance operator of the trajectories from the v-th tetrode as kv, k = 1, 2, v = 1, . . . , 32, all covariance operators are scaled by the summation of their eigenvalues, say, Ckv = kv/ kv,i. Here, k = 1 indicates pre-stroke onset state
i1
and k = 2 indicates post-stroke onset state. Two networks (N, E, 1), (N, E, 2) were constructed for the pre-stroke and post-stroke epochs separately. The node set N have 32 nodes representing the 32 tetrodes, and edge set E is complete which means all nodes are connected originally. The Figure 5 displays the Hilbert Schmidt norm k,ij = Ci - Cj S, k = 1, 2, i, j = 1, . . . , 32, which serve as the edge weights in the analysis. Figure 6 displays the cell-wise absolute value of edge weight difference between pre-stroke and post-stroke onset states, say, |1,ij - 2,ij|.
Figure 5: Hilbert-Schmidt norm Cki - Ckj S, i, j = 1, . . . , 32, k = 1, 2.
From Figure 5 and 6, we can see that after the simulated stroke was induced, the epoch trajectories from the 32 tetrodes present more similar variation pattern, and we refer to this phenomenon as "signal-synchronization". Particularly, tetrode 9 and 10 behaved very differently from other tetrodes before the simulated stroke, and this discrepancy diminished to a large extend after the stroke was induced, thus these two tetrodes are good indicators of real stroke.
18

Figure 6: The difference between pre-stroke and post-stroke onset edge weights

5.2 Permutation test on discrepancy of weight matrices

We employed permutation test to test the significance of the discrepancy between weight

matrices 1, 2. The procedure is now briefly described. The 600 epochs of each tetrode are permuted to form new sequences of epochs {Xv(bn) : v = 1, . . . , 32, n = 1, . . . , 600}.

The first 300 epochs of different tetodes were used to calculated the covariance operator

(1bi), and the rest 300 epochs were used to calculated the covariance operator (2bi), defined

as

(1bi)(x) =

1 300

300

Xi(nb)

Xi(nb), x

,

(2bi)(x)

=

1 300

600

Xi(nb) Xi(nb), x .

n=1

n=301

The covariance functions were scaled by the summation of their eigenvalues to obtain C1(bi) and C2(bi), then obtained the Hilbert-Schmidt norm Ck(bi) - Ck(bj) S , denoted as k(b,i)j, k = 1, 2. The discrepancy of the matrix k(b) = {k(b,i)j}3i,2j between the first 300 and the rest 300 epochs were evaluated by the Frobenius norm Db = 1(b) - 2(b) F . The
procedure was repeated for 200 times, and the Frobenius norm of the original sequences

was found greater than the 95% quantile of D1, . . . , D200. Therefore, the discrepancy of weight matrices is significant, making the following comparison reasonable and nec-

essary. Figure 7 shows the average weights of edges adjacent to each node, defined

as j1 k,ij/32, i = 1, 2, . . . , 32. Generally the weights shrinked after the simulated stroke due to "signal-synchronization".

5.3 Community detection and filt-fPCs
The proposed iterative GIC selection procedure was employed to select the community structure, and the tuning parameters were set to be (d) = 0.03 × d-1.8 for both pre-stroke and post-stroke onset groups to conduct the comparison for the community structures under the two brain states.
19

Figure 7: Means of weights of different tetrodes Clearly, the covariance structure of different groups after the simulated stroke became more similar. The signals from some tetrodes are consistently different from those of other tetrodes, e.g., tetrodes 9, 10, 13, 17, 27. Over the sequence of filtrations, the 32 tetrodes were separated into more and more communities. Figure 8 and 10 display the community detection result under the two brain states, where the points with the same color and shape are in the same community. Clearly, after the stroke was induced, most tetrodes were clustered in the same community, leading to a much more parsimonious filt-fPC representation. The first four filtrated functional principal components of pre-stroke and post-stoke onset trajectories are presented in Figure 9 and Figure 11 respectively.
20

Figure 8: Community structures of pre-stroke onset epochs
Figure 9: The first 4 filt-fPC of pre-stroke onset epochs 21

Figure 10: Community structures of post-stroke onset epochs
Figure 11: The first 4 filt-fPC of post-stroke onset epochs. 22

5.4 Approximation efficiency

To demonstrate the efficiency of the filt-fPC representation, we calculated the approximation error of the first D (D = 1, . . . , 20) filt-fPCs for each tetrode v, defined as

N

D

evD = N -1

Xvn(t) -

Xvn

,

(cv,d d

)

(cv,d d

)

(t)

.

n=1

d=1

Figure 12 and Figure 13 present the approximation error of the 32 tetrodes with 1­ 20 filt-fPCs, and clearly, the performance of the obtained filt-fPCs are typically very similar to that of ordinary fPCs.

5.5 Summary
Now the real data analysis results are summarized as follows:
· (Efficiency) Typically, the first few filt-fPCs can account for the similar portion of variance as ordinary fPCs do, and this demonstrate the efficiency filt-fPCs.
· Before the stroke-onset, the epoch trajectories from tetrode 9 and 10 admit much lower dimensional representation and thus requires less filt-fPCs to approximate, making these two groups separated from the other tetrodes at the first layer. After the stroke-onset, the epoch trajectories from these two tetrodes display less compressed spectral distribution. Thus these two tetrodes are good indicators of real strokes.
· (Signal-synchronization) Post-stroke onset epochs share much more similar covariance structure than pre-stroke onset epochs, and as a result, we can use much less filt-fPCs to represent post-stroke onset epoch trajectories.

23

Figure 12: Approximation error of pre-stroke onset epochs with 1­20 filt-fPCs. (solid line: ordinary fPC; dotted line: filt-fPC)
24

Figure 13: Approximation error of post-stroke onset epochs with 1­20 filt-fPCs. (solid line: ordinary fPC; dotted line: filt-fPC)
6 Conclusions
Local field potential (LPF) provides informative brain signals, and are usually collected from multiple tetrodes inserted on pre-specified patches on the cortex. The trajectories collected from different tetrodes simultaneously can be considered as multivariate functional data. Similar covariance structure of different tetrodes should be taken into account. Filt-fPC analysis provides a novel and efficient way to represent multivariate functional trajectories, e.g., LPF oscillations. We demonstrate how to find the common filtrated functional principal components in this paper. Specifically, we first apply multi-thresholding to the weighted brain network, established from data to measure
25

the similarity of covariance structure of different groups of functions, and then use our novel centroid-based community detection algorithm to find the communities, where one common filtrated principal component is employed for all the groups in the same community. The application of filt-fPC to local field potentials of rat brain revealed the synchronization phenomenon after the stroke, which was induced midway in the experiment. The method is suitable for a broad range of data, such as longitudinal functional data, spatial-temporal data, and brain signals collected from multiple locations on the brain of an experimental unit.
The idea of this dimensional reduction framework can be employed in many existing functional models with multivariate functional data, such as (generalized) functional linear regression model, functional auto-regressive model, functional classification problems. The estimation of these functional linear models are always conducted in a finite dimensional space spanned by, for example, functional principal component. When the number of groups is large, group-wise ordinary fPCs may yield the "n < p" problem in the finite-dimensional projection of the models (see e.g., Ramsay & Silverman (2004) and Aue et al. (2015)), making it necessary to find a more parsimonious representation for multivariate functional data. The filtration techniques can help solve such problem, and such methods have several advantages: 1). The method is able to extract the common variation pattern of different groups of functions, and the overall dimension of the multivariate functional data can be reduced significantly. 2). The idiosyncratic variation pattern of each individual group can be preserved. 3). The whole procedure is totally data-adaptive, and thus is suitable for a broad range of cases. 4). The filtrated functional principal components are orthogonal to each other for each group, leading to a concise basis representation.
References
Aue, A., Norinho, D. D. & H¨ormann, S. (2015), `On the prediction of stationary functional time series', Journal of the American Statistical Association 110(509), 378­392.
Benko, M., Ha¨rdle, W., Kneip, A. et al. (2009), `Common functional principal components', The Annals of Statistics 37(1), 1­34.
Berrendero, J. R., Justel, A. & Svarc, M. (2011), `Principal components for multivariate functional data', Computational Statistics & Data Analysis 55(9), 2619­2634.
Chiou, J.-M., Chen, Y.-T. & Yang, Y.-F. (2014), `Multivariate functional principal component analysis: A normalization approach', Statistica Sinica pp. 1571­1596.
Chung, M. K., Lee, H., Solo, V., Davidson, R. J. & Pollak, S. D. (2017), Topological distances between brain networks, in `International Workshop on Connectomics in Neuroimaging', Springer, pp. 161­170.
Crainiceanu, C. M., Caffo, B. S., Luo, S., Zipunnikov, V. M. & Punjabi, N. M. (2011), `Population value decomposition, a framework for the analysis of image populations', Journal of the American Statistical Association 106(495), 775­790.
26

Di, C., Crainiceanu, C. M. & Jank, W. S. (2014), `Multilevel sparse functional principal component analysis', Stat 3(1), 126­143.
Di, C.-Z., Crainiceanu, C. M., Caffo, B. S. & Punjabi, N. M. (2009), `Multilevel functional principal component analysis', The annals of applied statistics 3(1), 458.
Feng, Q., Jiang, M., Hannig, J. & Marron, J. (2018), `Angle-based joint and individual variation explained', Journal of multivariate analysis 166, 241­265.
Flury, B. K. (1987), `Two generalizations of the common principal component model', Biometrika 74(1), 59­69.
Flury, B. N. (1984), `Common principal components in k groups', Journal of the American Statistical Association 79(388), 892­898.
Greven, S., Crainiceanu, C., Caffo, B. & Reich, D. (2011), Longitudinal functional principal component analysis, in `Recent Advances in Functional Data Analysis and Related Topics', Springer, pp. 149­154.
Happ, C. & Greven, S. (2018), `Multivariate functional principal component analysis for data observed on different (dimensional) domains', Journal of the American Statistical Association 113(522), 649­659.
Ho¨rmann, S., Kokoszka, P. et al. (2010), `Weakly dependent functional data', The Annals of Statistics 38(3), 1845­1884.
Jacques, J. & Preda, C. (2014), `Model-based clustering for multivariate functional data', Computational Statistics & Data Analysis 71, 92­106.
Jiao, S., Frostig, R. & Ombao, H. (2020), `Break point detection for functional covariance', arXiv:2006.13887 .
Kayano, M. & Konishi, S. (2009), `Functional principal component analysis via regularized gaussian basis expansions and its application to unbalanced data', Journal of Statistical Planning and Inference 139(7), 2388­2398.
Lock, E. F., Hoadley, K. A., Marron, J. S. & Nobel, A. B. (2013), `Joint and individual variation explained (jive) for integrated analysis of multiple data types', The annals of applied statistics 7(1), 523.
Lu, Z., Wen, Y. & Cao, G. (2013), Community detection in weighted networks: Algorithms and applications, in `2013 IEEE International Conference on Pervasive Computing and Communications (PerCom)', IEEE, pp. 179­184.
Nishii, R. (1984), `Asymptotic properties of criteria for selection of variables in multiple regression', The Annals of Statistics pp. 758­765.
Palowitch, J., Bhamidi, S. & Nobel, A. B. (2017), `Significance-based community detection in weighted networks', The Journal of Machine Learning Research 18(1), 6899­ 6946.
27

Ramsay, J. O. & Silverman, B. W. (2004), `Functional data analysis', Encyclopedia of Statistical Sciences 4.
Schott, J. R. (1999), `Partial common principal component subspaces', Biometrika 86(4), 899­908.
Shen, Y., Liu, Y. & Xing, W. (2016), `Community detection in weighted networks via recursive edge-filtration', Journal of Communications 11(5), 484­490.
Wang, B., Luo, X., Zhao, Y. & Caffo, B. (2019), `Semiparametric partial common principal component analysis for covariance matrices', bioRxiv p. 808527.
Wann, E. G. (2017), Large-scale spatiotemporal neuronal activity dynamics predict cortical viability in a rodent model of ischemic stroke, PhD thesis, UC Irvine.
28

