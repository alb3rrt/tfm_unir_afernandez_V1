1

EmoDNN: Understanding emotions from short texts through a deep neural network ensemble

Sara Kamran, Raziyeh Zall, Mohammad Reza Kangavari, Saeid Hosseini, Sana Rahmani, and Wen Hua

arXiv:2106.01706v1 [cs.LG] 3 Jun 2021

Abstract--The latent knowledge in the emotions and the opinions of the individuals that are manifested via social networks are crucial to numerous applications including social management, dynamical processes, and public security. Affective computing, as an interdisciplinary research field, linking artificial intelligence to cognitive inference, is capable to exploit emotion-oriented knowledge from brief contents. The textual contents convey hidden information such as personality and cognition about corresponding authors that can determine both correlations and variations between users. Emotion recognition from brief contents should embrace the contrast between authors where the differences in personality and cognition can be traced within emotional expressions. To tackle this challenge, we devise a framework that, on the one hand, infers latent individual aspects, from brief contents and, on the other hand, presents a novel ensemble classifier equipped with dynamic dropout convnets to extract emotions from textual context. To categorize short text contents, our proposed method conjointly leverages cognitive factors and exploits hidden information. We utilize the outcome vectors in a novel embedding model to foster emotion-pertinent features that are collectively assembled by lexicon inductions. Experimental results show that compared to other competitors, our proposed model can achieve a higher performance in recognizing emotion from noisy contents.
Index Terms--Affective Computing, Cognitive Factors, Personality, Emotion recognition, Ensemble learning
!

1 INTRODUCTION

U NDERSTANDING emotional information from short text content finds important applications in numerous domains: (i) In conversation transcripts in user contents [1]. (ii) In the political context, to foster the prediction of the ballet results [2]. (iii) In health, to better recognize the people affected by extreme depressions [3][4] (iv) In sales and finance, to enhance the product development [5] and predict the market fluctuations [6]. Nowadays, with the spread of social networks, people share their brief contents conveying latent cues such as personality that can identify the contrast between authors. Given a single short-text si with corresponding cognitive cues pj, we aim to identify the emotions explaining si. Compared to comprehensive formal documents, individuals usually tend more to reveal their instant emotions through composing informal social media posts. Accordingly, we can utilize such rich content to exploit real-world emotion-related social communities. However, challenges abound: Challenge 1 (Ignoring Author Latent Information)
Numerous prior works [7][8][9][10] identify the emotions from textual contents disregarding the individual differences between authors, while such contrast including personality can affect the way people express their emotions [11]. As Holtgraves et al. [12] report, the personality-based correlations are more likely manifested in the emotionpertinent expressions. Table 1 demonstrates the correlation
· S. Kamran, R. Zall, M. R. Kangavari, and S. Rahmani are with School of computer engineering, Iran University of Science and Technology. Email: sara.kamran72@gmail.com, zall razieh@comp.iust.ac.ir, kanagvari@iust.ac.ir, rahmany.sana@gmail.com
· S. Hosseini is with the Faculty of Computing and Information Technology, Sohar University, Oman. Email: sahosseini@su.edu.om
· W. Hua is with the School of Information Technology and Electrical Engineering, University of Queensland, Australia. E-mail: w.hua@uq.edu.au

(a) High Cognitive Factors

(b) Low Cognitive Factors

Fig. 1: Emotion words connect to cognitive factors

between a tweet and relevant emotion and cognitive vectors. Here emotion vector comprises the score for each emotion [anger, disgust, etc.] where we use a similar vector to express personality through Extraversion, Openness, etc. The respective binary and floating values in the emotion and personality vectors imply whether the short-text corresponds to each emotion or cognitive factors. To investigate how human personality can affect the emotion manifest in expressions, we consume the SemEval dataset [13] to set up an observation based on the distribution probabilities of the words. We select the expressions with various emotional intensities that are further pertinent to diverse cognitive factors. As Fig. 1 demonstrates, the distribution probabilities for each emotional word differ in various cognitive factors. Users with high NEU (Neuroticism) have low emotional stability and frequently use distressing words, like terrible. So their short text contents include more emotional words compared to the user of the low NEU weights. Interestingly, users with low EXT (Extraversion) are reluctant to interact with others and tend to express negative emotions such as fear, depression, and

2

Emotion

Cognitive Factors

Tweet

anger disgust

fear joy sadness

OPE. CON. EXT.

AGR. NEU.

I've never been so excited to start a semester!

4.1

3.5

3.38

3.623

2.559

I'm a shy person

4.11

3.498

3.392 3.622

2.561

I am just so bitter today

4.0

3.508

3.366 3.564

2.58

TABLE 1: Conceptual relevance

anger more frequently than other users with high EXT load. individual characteristics [19]. Various studies predict and

Individuals with a high rate of CON (Conscientiousness) identify personality traits [15] from social networks. The

use a greater number of positive emotional words, such methods for cognitive prediction are of two categories: 1)

as happy, joy, and smile in their contents. From another Machine learning methods; 2) Deep learning models.

perspective, people with high AGR (Agreeableness) weights General machine learning algorithms [20] leverage various

rarely utilize emotional-related words. Therefore, the pro- features [21] including linguistic stats such as word count

posed consensus results reveal how cognitive factors can [22] and social network attributes like the number of friends

influence emotional expressions in short-text contents. Since to estimate personality traits [23]. Deep Neural network ap-

individuals with identical cognitive factors exhibit similar proaches [24][25][19][26] surpass traditional methods. Sun

emotions, we leverage the latent aspects of personalities to et al. [25] combine bidirectional LSTMs (Long Short Term

enhance our ability to detect emotions.

Memory networks) with CNNs (Convolutional Neural Net-

Challenge 2 (Noisy Short Text)

work) to infer structures of texts. Similarly, [19] devise

Short texts include important information but they are AttRCNN structure to understand the semantic features that

brief and error-prone. Hence, it is a tedious task to associate are amended by the statistical linguistic features. However,

emotion cues with cognitive features.

[26] utilizes essential statistics including Mairesse features,

Challenge 3 (The Scarceness of Annotated Dataset)

the number of words, and an average length of sentences

All prevailing datasets have either emotional labels that are combined within convnets in a hybrid manner. We

[14][13] or cognitive labels [15]. So, due to the scarceness initially exploit latent personal characteristics by a modified

of the dataset which contains both emotion and cognitive Support Vector Regression (SVR) model and subsequently

annotations, one of our challenges is to create datasets that adopt CNN convents to extract feeling sentiments.

are annotated by emotion and cognitive cues.

TABLE 2: Literature

Contributions. While our prior works [16][17] handle short text contents to detect attributed segments [18] and identify concepts, removing the perturbation caused by external knowledge bases, this paper recognizes the emotions through leveraging the cognitive factors from similar brief context. To this end, we utilize cognitive factors of individuals to categorize short texts to feed our novel ensemble classifier. Furthermore, in our proposed framework, we detect the emotion embedding of short texts with the help of an external knowledge-base which is associated with emotion lexicons. Accordingly, we extract multi-channel features in short texts to enrich the short-text inference models. Our contributions are fourfold:
· We develop a framework on emotion recognition through ensemble learning which leverages the cognitive cues to distinguish between short-text authors.
· We propose a regression approach for inferring latent cues about short-text authors.
· We design a multi-channel feature extraction algorithm based on emotion lexicons and attention mechanisms that fuse various embedding models to retrieve preferable vectors.
· We devise a cognitive aware aggregation function to combine the results of different base classifiers in the ensemble model.
The rest of our paper is as follows: in Sec. 2, we study the literature; in Sec 3, we provide the problem and our framework; in Sec. 4 and 5, we respectively explain our model and experiments. The paper is concluded in Sec. 6.

Category Personality Prediction
Emotion Recognition

Approaches Machine Learning Deep Learning Lexicon-Based
Machine Learning
Deep Learning

references [20][22][23] [19][24][25][26] [27][28] [7][8][9][29] [30][31][32] [33][34] [1][10][35][36] [37][38][39][40]

2.2 Emotion Recognition
Affective Computing [41] as an emerged field of research has attracted significant attention. Because it results in systems that can automatically recognize human emotions and eminently influence decision-making procedures. Emotions can be detected by heuristic, machine learning, and deep learning approaches [42]. The lexicon-based heuristic approaches [27][28] find keywords in textual contents and assign emotion labels based on lexicon tags, referenced from knowledge-base tools such as NRC-EIL [27] and DepecheMood [28]. Machine learning models [8][33] not only consider lexicons but also extract effective textual features from input corpus, concluded by decision rules to recognize emotions based on the trained explicit labels. The ML models include Na¨ive Bayes (NB) [8], Random Forest (RF) [34], Support Vector Machine (SVM) [33][8][29][34], Logistic Regression (LR) [32], and some trending deep learning methods [10][39]. The Na¨ive Bayes classifiers [8] efficiently utilize various word classes to perform prediction but result in lower accuracies. Random forests [34] fuse a combination of treebased predictors where each tree depends on the values

2 RELATED WORK
As briefed in Table 2, the related work comprises personality
prediction and emotion recognition.
2.1 Personality Prediction

of a random vector, sampled independently and with the same distribution from the trees in the forest. Random forest approaches are more efficient than the SVM methods [8][29] but empirically gain less accuracy. Both Esmin [7]

Personality is a psychological construct and it aims to under- and Xu [9] et al. use hierarchical classification techniques

stand various human behaviors with stable and measurable to perceive emotion cues. Such techniques integrate three

3

levels: neutrality versus emotionality, sentiment analysis, and emotion recognition. Utilizing domain-specific emotion lexicons, a combination of n-grams, and part of speech (pos) tagging features can foster the classification performance of the SVM modules [30]. On the contrary, the intelligible rulebased methods share the goal of finding regularities in data, expressing the form of If-Else rules [31]. In emotion detection, the rule-based models infer emotion-related events that undertake the cause [31]. Deep neural network models [35][39][36][1] have promoted the performance of prior Natural Language Processing (NLP) techniques, including emotion analysis and recognition. CNN (Convolutional NN) [10][36] and RNN (Recurrent NN)[10][38] are two common deep learning architectures that are often integrated at the top of embedding modules, e.g., GloVe and Word2Vec, to infer emotionpertinent cues in textual contents. While the convnets can effectively extract n-gram features, they are not as productive as the RNN schemes in attaining correlation within longterm sequences. Nonetheless, CNN models are distorted toward subsequent context and neglect previous words. To address the issue, LSTM models [39] exploit the intensity of emotions out of brief contents in a bidirectional manner which results in preferable outputs in single and multi-label classification tasks. The Deep Rolling model [40] combines LSTM and CNN into an ensemble to create a non-linear emotion-prediction model. Absorbed by the appealing performance of the deep neural network models [42], we devise a novel ensemble classifier equipped with dynamic dropout convnets that further leverages individual latent aspects, known as cognitive cues. Moreover, we propose a nontrivial method to extract features from emotion and semantic contents to feed the convnets in ensembles.
3 PROBLEM STATEMENT
In this section, we elucidate preliminary concepts, problem statement for author linking, and our proposed framework.
3.1 Preliminary Concepts Definition 1. (short-text message) si  S refers to a short-text that is composed by an author. Accordingly, S is our corpus which includes all short-texts. Definition 2. (cognitive factors) pi  P (P = {pi|i  [1, ..., q]}) refers to a cognitive factor (e.g., neuroticism). Each factor reveals one latent perception for the given message. Definition 3. (emotion) ei  E (E = {ei|i  [1, ..., k]}) refers to a basic emotion such as happiness. Each emotion can be correlated with multiple cognitive factors.
Definition 4. (cognitive category) Each cognitive category ci  C can represent a set of short texts that are highly correlated based on pertinent cognitive factors, representing a hidden cognitive coupling. Definition 5. (ensemble) hci  H refers to a base classifier that is induced from cognitive category ci(ci  C). Accordingly, H (H = {hc1 , hc2 , ..., hcn }) includes all base classifiers. Definition 6. (emotion Vector) Vsi = [vi,j|j  [1, ..., k]] denotes the emotion scores for short text si  S where vi,j  R is an emotion score for jth basic emotion ej  E.
Definition 7. (cognitive Vector) Fsi = [fi,j|j  [1, ..., q]] denotes the cognitive factor scores for the short text si  S where fi,j is a cognitive score for jth factor pj  P . Fsi represents short text si in cognitive space with q dimension according to P .

3.2 Problem Definition Problem 1. (identifying cognitive factors) Given a message si our goal is to retrieve the cognitive vector Fsi for si. Problem 2. (extracting multi-channel features) Given the set of short texts pertinent to a cognitive category ci, our goal is to extract the set of features through tracking the emotional cues. Problem 3. (recognizing emotion through cognitive factors) Given the message si and its associated cognitive vector Fsi , our goal is to construct the emotion vector Vsi .
Fig. 2: Framework 3.3 Framework Overview The problem of emotion recognition through cognitive cues in brief contents includes two steps: (1) to extract the categories of short text messages via inclusive cognitive cues. (2) to learn an effective ensemble classifier to identify emotions by leveraging the extracted categories. Fig. 2 illustrates our proposed framework. In the offline part, since a dataset enclosed with both emotion and cognitive annotations is scarce, as a prerequisite to emotion recognition, we initially augment the cognitive annotations within the dataset. To this end, we adopt the SVR to retrieve the cognitive vectors. Considering the impact of each cognitive factor on emotion-related expressions, we then apply categorization on textual contents. As a result, each category can include highly-correlated short texts aligned with the associated cognitive vector. Consequently, we extract the set of features by tracking the emotional cues in the short texts of each cognitive category. We then apply the emotion lexicons together with word vectors to learn each of the corresponding base classifiers(e.g., extraversion). To continue, given the short text contents enclosed with emotion annotations, we induce the ensemble classifier to convey emotion recognition. We can aggregate the base classifiers into an ensemble to convey helpful information according to the cognitive similarities. In the online part, we aim to predict emotion labels for the input short text. To accomplish the task, we firstly extract cognitive vectors from the input. We then select a set of relevant classifiers based on the input cognitive features. Finally, we aggregate various outputs from classifiers to make the final prediction.
4 METHODOLOGY
4.1 Offline Phase 4.1.1 Inferring cognitive factors For investigating the influence of cognitive factors on emotion recognition, we need a dataset that includes both emotional and cognitive annotations. We assume that our dataset includes emotion annotations, as ground truth. Hence, we aim to compensate the cognitive annotations. To this end, we can leverage another source dataset with cognitive features to annotate our target dataset. We use a

cognitive annotation dataset DP = {si, Fsi }(i = 1, . . . , n) to infer cognitive vectors of short texts in emotional annota-

tion dataset DE = {si, Vsi }(i = 1, . . . , m) where P and E denote the source and target datasets. Here m and n denote

the number of short texts in source and target datasets. To

identify cognitive scores, we train a diverse model for each cognitive factor q on DP to infer the proportionate cognitive space of DE. In each model, we adopt the effective Support

Vector estimation tool [43] to designate a decision surface

to maximize the distance between different classes. In the

source dataset, there are a set of points (si, fsi,j ) where xi

is the feature vector extracted from si and fsi,j  Fsi is the target value for each model j  [1, ..., q]. Eq. 1 demonstrates

the objective function.

pq = f (xi) = wxi + b, b  R, w, xi  Rd

(1)

Where w is the slope of the line, and b is the intercept. Our

aim is to use SVR to find a surface that minimizes the pre-

diction error in optimization function, Eq. 2. In regression,

a soft-margin ( ) approach is employed similar to SVM. We

add slack variables i + i to guard against outliers.

1 Min 2

w

2+C

n
(i + i)

(2)

i=1

Here  and  are the distance of data points that lie outside

the margin.

 fsi,j

-

wT

xi

-

b

+ i

M = wT xi + b - fsi,j

+ i

(3)

i, i 0

Our optimization goal is to achieve the conditions in Eq. 3

that

we solve with finding L(w, , , , , , )

t=he21Lawgr2an+gCiannin(Ei q+.

4. i)+

n

i=1

(fsi,j - wT xi - - i)+

i=n 1

(4)

(-fsi,j + wT xi - - i)-

i=1

n

ii + i i

i=1
The Lagrange multipliers, denoted by , , , , are non-

negative real numbers. The minimum of Eq. 4 is found by

taking its partial derivatives with respect to the variables

and then equating to zero. We also obtain the values of w

and b through Eq. 5 and Eq. 6.

n

w = ( - )xi

(5)

i=1

b = -fsi,j + wT xi -

(6)

4.1.2 Cognitive categorization Given emotion annotated dataset DE, we aim to acquire a

set of cognitive categories, denoted by C. As elucidated in

Section 1, authors with different cognitive cues express their

emotions using various vocabs in emotion. Given such an

intuition and based on the cognitive vector Fsi of the set P , we can map each short text si  DE to q dimensions. Subse-
quently, we can obtain the set C of cognitive categories from the emotion annotation dataset DE by splitting the space

into two subspaces. Where we can define the lower and up-

per subspaces for each cognitive factor pj  P . Accordingly,

the short texts with lower and higher levels of a cognitive

factor, pj, will be respectively appended to the pertinent categories of c2j-1, c2j. Hence, clustering [44] and border

4

classifiers, like SVM [8], cannot cohesively distinguish the

categories. To this end, we diversely adopt an entropy-based categorizing method to acquire partitioning value in each cognitive factor to obtain lower and higher bounds. To get the partitioning threshold vector a = {j|j  [1, ..., q]}, we presumed that the source dataset incorporates the cognitive factor classes. So we employed the entropy approach to attain the partition value of j for each cognitive factor pj that minimized the impurity in the resultant categories. For each given cognitive factor pj, we considered a set of partitioning points in a similar range as pj in DP and evaluated them based on entropy to find the best partitioning point, j. In this regard, based on each partitioning point T , we splitted the DP into two subsets of d1 and d2 and computed the entropy of resulting subsets accordingly to input cognitive class of pj. We determined two classes k = {k1, k2} for each cognitive factor pj  P where entropy of di(i = {1, 2}) was defined as Eq. 7.

Entropy(di) =

P (km, di) log P (km, di)

(7)

m{1,2}

Here P (km, di) is the probability of short texts in di per-

taining class km. Given input dataset DP , cognitive factor

pj, and partitioning point T , Eq. 8 computes the class

information entropy E(pj, T, DP ) for the splits made by T .

Here j is the partitioning criterion in Eq. 9.

E(pj , T, DP ) =

|dm| |DP |

E

ntropy(dm)

(8)

m{1,2}

j = arg min{E(pj, T, Dp)}

(9)

T

We then used j in Eq. 10 to obtain cognitive categories.

pj  P :

c2j-1 = {[si, Vsi ]|fi,j < j } c2j = {[si, Vsi ]|fi,j  j }

(10)

Consequently, the pair of sets (c2j-1,c2j) formed by j on each parameter pj can constitute the short texts with a low and high order of cognitive factor. We now elucidate various properties for each set of cognitive categories (C = (c1, ..., cn)): Lemma 1. a cognitive category ci can not be empty (i  [1, ..., 2q] : ci = ).

Proof. Since the max. and min. values for each cognitive factor i do not equate (min(DiE) = max(DiE)) and the splitter parameter i is between min. and max. values (min(DiE) < i < max(DiE)) so we can justify that ci can
not be empty (Eq. 11):

if i > min(DiE) = sj : fj,i < i if i < max(DiE) = sj : fj,i > i

= ci =  (11)

Lemma 2. The aggregated data for all cognitive categories forms the original dataset DE (i  [1, ..., 2q] : ci = DE).

Proof. Suppose we have two categories of c2j  DE and c2j-1  DE where we assign the short text sk  DE to

either c2j or c2j-1. So we can justify the rules in Eq. 12 for

the cognitive factor j in sk:

sk  DE : sk  c2j or sk  c2j-1 =

c2j  c2j-1 = DE =

ci = DE

(12)

i[1,...,2q]

Lemma 3. The intersection of two cognitive categories for the same parameter (e.g. c2j and c2j-1) partitioned by the specified

threshold j will result in null. As stated in Eq. 13, the intersec-

tion of the same pair (c2j,c2j-1) with other cognitive categories

ci can be non-empty.



j  [1, ..., q], i  [1, ..., 2q]

c2j-1  ci =  if 2j - 1 = i 

= c2j  ci = 

if i = 2j

(13)

c2j-1  c2j = 

Proof. Given cognitive factor j, each short text can be asso-

ciated either with low c2j-1 or high c2j status, resulting in

c2j-1  c2j = . However, given all q cognitive factors for

each short text with q cognitive categories every pair c2j-1

and ci can share common textual contents.

Lemma 4. Short texts in a cognitive category cm have a similar

feature according to their pertinent cognitive factor

m+1 2

. The

p m+1 in all of short texts are larger than  m+1 or are smaller

2

2

than  m+1 .

2

Proof. Suppose m  [1, ..., 2q] and i, j  [1, ..., |cm|], we

can use contradiction logic to prove si, sj  cm stated by

f f , i,

m+1 2

j,

m+1 2

>

m

or

fi,

m+1 2

,

fj,

m+1 2

 m. Let

si



cm

and sj

/

cm

where

fi,

m+1 2

,

fj,

m+1 2

> m.

According to Eq. 10:

Therefore,

1. si  cm  fi,

m+1 2

> m

2. sj

/ cm

 fj,

m+1 2

< m

the assumption sj / cm with

(14) condition

fj,

m+1 2

> m contradicts with our initial hypothesis.

Therefore,

if

fi,

m+1 2

>

m

and

fj,

m+1 2

> m, si  cm,

sj will be in the same cognitive category(cm). In this way,

condition fi,

m+1 2

, fj,

m+1 2

 m can also be proved.

4.1.3 Multi-channel features

The embedding models can capture syntactic and seman-

tic regularities within the corpus to represent each word

with a real-valued vector. GloVe [17][45][16] uses word

pair co-occurrences, and CBOW [46] predicts a word given

its context. However, the resultant word vectors fail to

acknowledge emotion cues in short text contents. Let 

be the corpus containing the set of words associated with textual contents of an emotion annotated dataset, DE. We

can then tokenize each short text si into a set of words

(si = {o1, o2, ..., o|si|}) where oj   (j  {1, . . . , |si|}) is the jth word in short text si. We can represent the contextwise word vector corresponding to the jth by utilizing the embedding function  :   Rd in Eq. 15.

Ojcontext = (oj )

(15)

Here, Ojcontext is the context-wise vector for the given word j. Let L = {l|  [1, ..., t]} be the set and t as the number

of emotion lexicons where DepecheMood [28] and NRC-EIL

[27] infer the lexical vectors to designate each word with

continuous scores for emotional or polarized orientations.

Consequently, we can propose a hybrid vectorization pro-

cess to include emotional aspects of the words. To this end,

we assume that Ojemotion = [oj,i|i  [1, ..., k]] is an emotionwise word vector associated to jth word. Here, k denotes
the number of basic emotions and oj,i is the ith emotion

scores for the given word oj. t

Ojemotion =

(oj , l)

(16)

=1
As Eq. 16 formalizes, the function  :   Rk receives the

input word oj and retrieves the emotion scores through the

lexicon knowledge-base l where t denotes the number of

emotion lexicons and gives the concatenation of resultant

5

vectors. We can support |Ojemotion| =

t =1

(l)

where



specifies the number of emotions leveraged in l.

Moreover, we adopt NLP processes such as POS tagging

to take advantage of structural elements and syntactic pat-

terns. Accordingly, as Eq. 17 elucidates, we can designate

each short text with an alternative representation, POS tag-

based feature vectors.

Ojpos = (oj )

(17)

Here, :   Rµ is the function that receives a word oj as

input and returns the vector of the size µ with POS tags.

In a nutshell, the attention-based mechanisms [47] aim to

signify the words with higher impacts to foster classification

procedures. As Fig. 3 shows, we adopt an attention module

to nominate prominent focus words. Given each short text

si, we can use the weighted sum of word vectors to compute

the corresponding attention vector, Ojattention (Eq. 18).

Ojattention =

j,y .Oycontext

(18)

y=j

As verbalized in Eq. 19, j,y (j,y 0) is the attention

weight subjected to y j,y = 1 where "." denotes the element-wise multiplication.

1

j,y

=

( 2

exp(score(Ojcontext, Oycontext)) + y´ exp(score(Ojcontext, Oyc´ontext))

exp((Ojemotion, Oyemotion)) ) y´ exp((Ojemotion, Oye´motion))

(19)

The score(., .) function quantifies the degree of relevance

between the jth and yth words, and  is the similarity

function that determines the correlation ratio between the

word pairs according to the pertinent emotion-wise vectors. Eq. 20 explains how the score(., .) computes the relevance between the given pair of oj and oy. score(Ojcontext, Oycontext) = Wa[tanh(Wz [Ojcontext  Oycontext])]
(20) We randomly initialize the weights Wa and Wz and jointly learn them during the training process. The higher senti-

ment relevance between the given words in emotion clas-

sification, the larger inner-weights will be. To this end, we

employ the simple but effective cosine similarity to calculate the weights between vectors, (Ojemotion, Oyemotion). To attain the multichannel features, we utilize both lexicon

resources and POS tags. To collectively form the multichan-

nel features, on the one hand, we concatenate the emotion-

wise and context-wise word vectors, and on the other hand,

we combine the context-wise and POS-wise vector. Eq. 21

formulates how one can merge various vectors, including

emotion-wise, context-wise, and attention vectors.

ejmo = Ojattention  Ojcontext  Ojemotion

(21)

Where the  is the vector concatenation operator, we can

utilize Eq. 22 to obtain Mseimo  R|si|×(2d+

t =1

(l ))

as

the

matrix of vectors for si where |si| is the number of words.

Mseimo = e1mo  e2mo  ...  e|smi|o

(22)

We combine three vectors of POS, context, and attention in

Eq. 23 to further improve the accuracy.

pj os = Ojattention  Ojcontext  Ojpos

(23)

Also, Eq. 24 computes Mspios  R|si|×(2d+µ) as the vector

matrix for si. Mspios = p1os  p2os  ...  p|sois|

(24)

Given si  S comprising various number of vocabs, perti-

nent vectors of Mspios and Mseimo will follow |si|. Hence, we

6

adopt the zero padding and use  = maxi=1,...,m(|si|) as the fixed length for Msi to unify short-text matrices.

4.1.4 Cognitive ensemble
Given the dataset DE = {(si, Vsi )|i = [1, ..., m]} with m short texts, Vsi  {0, 1}k can represent a binary emotion
vector for si. Here, k denotes the number of emotion class labels. Moreover, where the jth label of emotion is not null in

VSi , we assign vi,j with 1 or zero otherwise. Since si can be concurrently involved with diverse emotions, neither single-

label classification models [48] nor regression algorithms

[43] can model such multiplexity [35]. Hence, we employ

multi-label classification by appointing each emotion label

with a single task and adopting a parallel multi-task learner.

An ensemble of convnet classifiers [48] can better learn

the emotion features where we designate each cognitive

category ci to a distinctive multi-task classifier hci . Finally, we aggregate the output of trained classifiers in H (Fig. 3).

Given the feature learning component, we appoint the

width of the filters by the dimension of word vectors,

denoted by 2d +

t =1

(l

).

We

further

alter

the

height

to acquire various sets for the encoded feature vectors.

To this end, we obtain the encoded set of feature vectors

Qemo = {Q1, Q2, ..., Q} for the embedding matrix Mseimo, by  various window sizes, each denoted by r  N. Here

Qr = [qr,j|qr,j  R and j  [1, ..., |si| + r - 1]] represents

the feature vectors for the rth window, Eq. 25.

qr,j = (Mseim{jo:j+r-1}.Wr + b)

(25)

Wr  Rr×(2d+

t =1

(l ))

is

the

filter

matrix,

b



Rr 1

is

a

Mbiasesimvoeoctfotrh,eansidzeMrsei.m{Tjoh:je+mr-ax1}laisyethr ecohnosruizmonestaolufrtpagumt feenattuforer

vectors Qemo to exploit the final encoded vector Q^emo (Eq.

26).

Q^emo = [q^r|r  [1, ..., ] and q^r =

max

(qr,j )] (26)

j[1,...,|si|-r +1]

As formalized in Eq. 27, we then use Q^emo and Q^pos in

embedding matrix Mspios to get the max layer output.

Q^ = Q^emo  Q^pos

(27)

Successively, the emotion learning component consumes Q^,

where we collectively utilize the inter-connected layers to

address the perceptual multi-label classification problem

and segregate tasks in the output layer. Let l  {1, .., L}

be the layer index of the network in the fully connected

component. Given L as the number of hidden layers, the

index zero can determine the input for the emotion learning

module. Fig. 4 shows the schema of a neuron in the hidden layer l. Where x0 equates to Q^, xl can specify the load for l.
Similarly, wl and zl can respectively indicate the weighting

matrix and the output of layer l, to be used in the next layer, l + 1. Eq. 28 attains the input of the kth neuron in l.

Nl -1

xlk = blk +

wil-k 1zil-1

Nl-i=1 1

xlk = blk +

(wil-k 1)zil-1

(28) (29)

i=1
Here, xlk and blk can indicate the input and the bias values for the kth neuron in l. Where the output of the ith neuron in l - 1 is zil-1, wilk-1 associates the weights of the ith neuron in l - 1 to the kth neuron in l. Eq. 29 neutralizes the effect of

non-essential features to avoid overfitting. As explained in Sec.4.1.5, the function (wilk-1) returns the

weights between a pair of neurons. So as shown in Fig. 4,

we can pass xlk through activation function f , formalized in

Eq.

30,

to

retrieve

the

intermediate output zlk = max(0, xlk)

zkl .

(30)

Fig. 4: Input and output of a neroun at hidden layer l

The output layer constitutes k output units, each dedicated

to a single task. The output of the last layer in hidden

layers, as the common feature representation learned for the

k tasks, can be fed to the output layer. The constraint can be

accommodated by Eq. 31, computing the network prediction

output for the jth emotion, denoted by v^j,i  [0, 1].

1

v^j,i = 1 + e-xlk

(31)

To reduce the error rate, we use the back-propagation algo-

rithm. We then employ a modified binary cross-entropy to

compute the joint loss function by the predicted labels.

L= 1 m

k
(- vj,i log(v^j,i) + (1 - vj,i) log(1 - v^j,i)) (32)

im j=1

Here v^j,i is the output of the prediction network, vj,i denotes the ground-truth for ei  E, associated with the short text

with index j. Moreover, k and m respectively count the

numbers of emotion labels and short texts. We update the

weights and bias by leveraging the loss function (Eq. 33).

w(t + 1) = w(t) + w(t)

(33)

Here, w(t) and w(t + 1) are current weights and new weights. To compute w(t), we use Adam optimizer [49] that benefits both from AdaGrad and RMSProp.

Algorithm 1 General DropConnect

Input: rate, w Output: w´

1: f = f latten(w) ,w´ = w

2: l = []

3: while len(l) < rate do

4: r = randint(0, | f |)

5: if not r in l then

6:

l.append(r)

7: end if

8: end while

9: for p in l do

10: w´p/|f|,p%|f| = 0

11: end for

12: return w´

4.1.5 Weight regularization As explained in Sec. 4.1.4, overfitting as a deep learning dilemma is caused by a contradiction where optimization aims to adjust the model to foster effectiveness, and generalization solely points toward inferring the unforeseen data. The dropout [50] is the most credible regularization approach to revoke the overfitting issue. However, resolving the tension between bias and variance is not a trivial task. To this end, the dropout approaches like DropConnect [51]

7

Fig. 3: Base classifier architecture

eliminate the arbitrary weights and ignores the selected efficient dropout technique to alter imperceptive arbitrary

nodes in the connected layer.

regularization with a distribution-aware model. We multi-

Algorithm 2 None Significant Weight reduction

Input: w, , ,  Output: w´

1: f = f latten(w), w´ = w

2:

µ=

1 |f |

|f | i=1

fi,



=

1 |f |

|f | i=1

(fi

-

µ)2

3: for i in | f | do

4: r = i/ | f | , c = i% | f |

5: if µ - 2 < fi < µ + 2 then

6:

if µ -  < fi < µ +  then

7:

w´r,c =  × wr,c

8:

else

9:

w´r,c =  × wr,c

10:

end if

11: else

12:

w´r,c =  × wr,c

13: end if

14: end for

ply the outputs of neurons, highlighted in Eq. 29, by the justified weights based on coefficients to acquire w´ new weights. Given the neuron inner weights, we specify the drop-rate using dataset-oriented parameters, the standard deviation and the mean, denoted by µ and . As shown in Fig. 6, the weights are of three categories: least (), minor (), and common (). Due to the subtle connection between the significance of the neurons and the dropout, we sufficiently reduce the weights for the least and minor sections in the curve. This not only leads to a faster convergence rate but also reduces the activation weights that cause overfitting. Similarly, we relatively increase the significance of weights in the minor and common regions, coefficients of µ and . The changes make our model more mature through subsequent epochs, avoiding the neuron outputs to excessively rely on the least and minor weights. Finally, the model will

15: return w´

utilize high-impact weights from the common section.

The DropConnect algorithm (Alg. 1) turns out to be Na¨ive in the elimination process. Because it arbitrarily zeros out the selected weights. From another perspective, even the fixed dropout rate in DropConnect can reduce the model expressiveness and increase manual tuning requirements. Hence, we must initially infer the statistical cues from the embedding weights and then adjust the dropout rate consciously. To this end, we enhance the flexibility by retrieving the dropout rate based on the weights drawn from a dataspecific uniform distribution.

Fig. 6: Distribution of coefficient weights
4.2 Online Phase In the online phase, given the cognitive vector Fsq of the input short text sq, the proposed method approximates the emotion vector, comprising two tasks: Detecting the cognitive factors and Estimating the emotions.

Fig. 5: Random dropout versus weight regularization In a tractable approach, we can refer to each weight in the bell curve to initialize the elimination procedure empirically. In other words, as depicted in Fig. 5, we can instantiate a weight matrix to preserve the value of the specified cell, removing or reducing the value in selected cells to adjust the activation process of the neurons. Here we can reduce the value of the given point in the matrix according to trilateral coefficients. As implemented in algorithm 2, we propose an

4.2.1 Cognitive factors detection

Social media supply our propositional datasets. Hence, our

framework needs to diligently handle millions of short text

contents in the Online phase. To meet efficacy requirements,

we train the model in Sec. 4.1.1 infrequently. Eq. 34 can

attain the cognitive vector Fsq of the input query sq.

Fsq = m(sq)

(34)

4.2.2 Cognitive aware aggregation method

In this step, given the cognitive vector corresponding to the

input short-text query, we firstly select a set of relevant base

classifiers to perform inference as parts of the same whole.

Algorithm 3 exemplifies how we collectively select the base

classifiers and combine them accordingly.

In algorithm 3, we firstly extract multi-channel features out

8

of the input query sq using the method in Sec. 4.1.3. Given cognitive vector Fsq , we can select either of the base classifiers, h2i or h2i-1. To this end, we compare each element fsq,i  Fsq to the splitter parameter i that divides the short text messages into various categories of low and high. By designating the whole corpus to the multi-task baseclassifier hq+1, we can disregard the cognitive factors in learning. We can subsequently predict the emotion vectors corresponding to sq through applying the selected baseclassifiers. This results in the consensus matrix A where each element Ai,j represents the predicted class by the base classifier j for an emotion i. Each column j depicts the binary opinion of model j about each of emotions in Vsq .
Algorithm 3 Cognitive Aware Aggregation method

Input: H, j(j  [1, ..., q]), Fsq

Output: Vsq
1: Mseimo, Mspios = F eatureExtraction(sq) 2: for i in [1, ..., q] do

3: if fsq,i < i then

4:

A:,i = h2i-1(Mseimo, Mspios)

5: else

6:

A:,i = h2i(Mseimo, Mspios)

7: end if

8: end for 9: A:,q+1 = hq+1(Mseimo, Mspios)

10: Vsq = aggregation(A)

11: return Vsq

Consequently, we combine the base classifiers to compute

the binary values from the given emotion classes, resulting

in better approximation and improving the overall perfor-

mance [52]. To continue, we adopt the simple but effective

majority voting method [53] to anticipate the outcomes.

Given the short text query sq, Eq. 35 formalizes our ap-

proach in the prediction of various sentiments.

k

q+1

Vsq = argmax( g(Aj,t, ci))
j=1 ci{0,1} t=0

(35)

Eq. 36 shows, Aj,t is the prediction of the base classifier t

using the indicator function g(y, c).

g(y, c) =

1 y=c 0 y=c

(36)

5 EXPERIMENT
We conducted extensive experiments on multiple datasets
[13][15] to compare our proposed unified framework to
other novel approaches in emotion detection. Taking advan-
tage of various Python libraries and interfaces for neural
networks, we ran the experiments on a server with a 4.20
GHz Intel Core i7-7700K CPU and 64GB of RAM. The codes are available to download 1. 5.1 Data We used three datasets to examine our method in detecting
personality and emotions from brief contents. - M yP ersonality [15]: The MyPersonality dataset, denoted by DP , predicts the cognitive labels for our target emotion
dataset [13] and comprises the cues for extraversion, agree-
ableness, conscientiousness, and neuroticism. We eliminate
the effect of openness due to minor significance. - SemEval2018 [13]: This dataset (DE) is annotated by 11
emotion tags. Like Ekman's standard [54], we include fear,
anger, joy, disgust, and sadness.

1. https://sites.google.com/view/EmoDNN

- W ASSA - 2017 [14]: is the destination dataset, denoted by DE, and includes fear, joy, sadness, and anger emotions. We utilize this emotion annotated dataset to evaluate the performance of our proposed framework in multi-class labeling. We enclose the statistics pertaining MyPersonality and SemEval2018 in Tables 3 and 4, respectively.

#Tweet Max Min Mean STD
Median

NEU

Low High

6200

3717

4.75

1.25

2.6

0.76

2.6

CON

Low High

5361

4556

5

1.45

3.47

0.74

3.4

EXT

Low High

5707

4210

5

1.33

3.35

0.85

3.4

AGR Low High 4649 5268
5 1.65 3.62 0.68 3.65

TABLE 3: Statistics pertaining MyPersonality dataset

#Tweet Max Min AVG STD
Median

Anger 2859
1 0 0.37 0.48 0.0

Disgust 2921 1 0 0.378 0.485 0.0

Fear 1363
1 0 0.18 0.38 0.0

Joy 2877
1 0 0.37 0.48 0.0

Sadness 2273 1 0 0.2943 0.455 0.0

TABLE 4: Statistics of SemEval2018 dataset Fig. 7 shows short text distribution for each given cognitive factor, where the x axis reports the weights and y counts the
frequency. The middle threshold differentiates the low and
high domains with respective light and dark colors.

(a) EXT

(b) NEU

(c) AGR

(d) CON

Fig. 7: Cognitive factors data distribution

5.2 Benchmark

Intuitively, we define hypothetic parameters to evaluate

the effectiveness of our proposed framework in emotion

recognition. The statistical parameters are as follows: True

positive is observed when a short text has emotion ei and the model predicts the same. False positive indicates that

the short-text doesn't relate to the emotion ei but the model

predicts oppositely. Applying similar logic can determine

True and False Negatives. We can calculate the metrics

of Accuracy, Precision, Recall, and F-measure using TP,

FP, TN, and FN. Accordingly, we can distinguish the best

performance by F-measure while we apply 10-fold cross-

validation in every evaluation process.

5.3 Baselines

We employ the benchmark in Sec. 5.2 to examine the perfor-

mance of the rival methods in emotion recognition:

· U unison: This baseline [10] leverages a variety of

deep learning modules, such as word and character-

based RNN and CNN, to improve traditional classi-

fiers including BOW and latent semantic indexing.

9

· SentiHC : This model is a hierarchical classification scheme that comprises three levels in the learning process: neutrality(neutrality versus emotionality), polarity, and emotions(five basic emotions) [7].
· SV M - Behavior: Similar to [8], it combines unigrams and emotion lexicons and uses SVM-Behavior to classify text contents according to emotion cues.
· lexiconbased: Instead of word embedding[28], this model is performed by emotion lexicon.
· EmoDN NSV M : This model is based on our proposed categorization method, but the learning component employs an SVM classifier on unigrams.
· EmoDN Nwd: This method replaces multichannel feature learning with text embedding [17][45].
· EmoDN N : Our proposed framework in Sec. 3.3.

5.4 Effectiveness
5.4.1 Impact of learning parameters on emotion recognition Given the importance of the batch size is in the dynamics of deep learning algorithms, we designate this section to measure the accuracy for each given emotion where the batch size varies. Table 5 shows where the batch size varies the accuracy fluctuates up to 5% with minimum and maximum for Disgust and Joy emotions. As a result, we select the best value of 128 tweets for the batch size in our method to maximize the performance. Similarly, we have attained the best batch size for other rivals. Similarly, Table 6 investigates the impact of the number of epochs on the accuracy. Excluding the fear and sadness emotions, where the epoch is set to 50, we gain the best effectiveness. Furthermore, we need to evaluate the embedding module. Hence, Table 7 reports the accuracy for various embedding dimensions where we opt for the value of 200 to get the best overall performance. In retrospect, the lower dimensions can better adjust to fewer data, like for fear and sadness. Because the higher the dimension in low sampling, the bigger the data sparsity will be.

batch size 30 50 80 100 128

Anger 79.85 80.06 80.4 80.16 81.73

Disgust 77.44 76.45 76.9 77.29 77.67

Accuracy Fear 92.32 92.24 91.99 91.77 89.39

Joy 77.28 78.01 77.42 77.91 83.05

Sadness 82.33 81.85 81.54 81.98 78.1

TABLE 5: Impact of batch-size on accuracy

epoch

Anger

Accuracy

Disgust

Fear

Joy

Sadness

40

80.51

76.67

92.01 77.27

81.7

50

81.73

77.67

89.39 83.05

78.1

80

80.32

76.27

92.02 77.49

81.53

100

80.35

76.79

91.76 77.79

81.88

TABLE 6: Impact of number of epoch on accuracy

glove

Anger

Accuracy

Disgust

Fear

Joy

Sadness

25

79.55

77.07

91.12 74.64 80.58

50

81.49

76.29

91.77 73.29 82.22

100

79.96

74.92

92

76.97 82.18

200

81.73

77.67

89.39 83.05 78.1

TABLE 7: Impact of text-embedding on accuracy The learning rate parameter can significantly affect the

robustness of the proposed model as it can directly influence the optimization weights. As for larger learning rates, the chance to exceed the extreme point will be bigger, causing an unstable system. Conversely, where the learning rate

decreases, the training time can exquisitely take longer. As observed in Table 8, the learning rate of 10-6 results in the
highest accuracies in the majority of emotions.

learning
rate 10-1 10-2 10-3 10-4 10-5 10-6

Anger 79.86 79.81 79.48 80.41 81.11 81.73

Disgust 75.74 77.1 75.94 76.94 77.15 77.67

Accuracy Fear 91.51 92.03 91.91 91.2 89.49 89.39

Joy 76.65 76.16 79.33 77.68 82.97 83.05

Sadness 80.28 81.82 80.86 81.84 76.7 78.1

TABLE 8: Impact of learning rateg on accuracy

5.4.2 Effectiveness of EmoDNN in multi-label dataset We employ the benchmark (Sec. 5.2) to compare the rivals (Section 5.3) in inferring the emotions from brief contents. We observe in Fig. 8 that the performance of all the methods is more than 40% which is even better for the neural network models. However, both versions of our proposed approach, including EmoDN NSV M and EmoDN Nwd, turn out to be the best classifiers with an improvement of up to 6.6% versus the best performing competitor, Unison. From another perspective, lack of training procedure justifies why the lexicon-based methods attain the lowest accuracy. Even though we integrated our framework with shallow machine learning methods, e.g., SVM, the modified solution was still capable of overcome other baselines, where applying deep learning modules assured better accuracy. To prevent overfitting, we introduced a new improved dropout mechanism to foster the classification task, with further improvement of 1% compared to the arbitrary dropout. We also adopted the values 1.5, 1, and 0, for ,, and  coefficients and utilized a modified emotionaware embedding approach instead of a pre-trained vector module, improving the accuracy by up to 1.07%.

Fig. 8: Compare baselines accuracy
Table 9 compares the performance based on emotions via 10-fold cross-validation where our cognitive-aware emotion detection approach overpasses other baselines. The reason is three-fold: We include cognitive inference, enhance the dropout, and equip the feature vectors with emotion-aware cues, making EmoDNN gain high F1-measure values of 0.75, 0.70, and 0.75 for anger, disgust, and joy.

Fig. 9: Compare accuracy between emotions Aiming to test out-of-samples in various folds, we study how the accuracy of our proposed method fluctuates in different emotions. We observe (Fig. 9) that fear and disgust

10

methods

Anger

Disgust

Fear

Joy

Sadness

Percision Recall

F1

Percision Recall

F1

Percision Recall

F1

Percision Recall

F1

Percision Recall

F1

Unison

0/84

0/3

0/41

0/93

0/27

0/42

0/84

0/29

0/42

0/8

0/68

0/73

0/84

0/23

0/34

Senti {HC}

0/54

0/54

0/53

0/53

0/52

0/52

0/66

0/66

0/66

0/5

0/58

0/5

0/55

0/56

0/55

SVM Behavior

0/68

0/68

0/68

0/65

0/66

0/65

0/72

0/78

0/75

0/68

0/69

0/68

0/52

0/71

0/6

Lexicon-based

0/33

0/4

0/36

0/34

0/4

0/37

0/54

0/6

0/56

0/33

0/48

0/39

0/6

0/4

0/48

EmoDNN {SVM}

0/77

0/61

0/68

0/7

0/57

0/63

0/78

0/4

0/53

0/81

0/63

0/71

0/68

0/41

0/51

EmoDNN {wd}

0/7

0/8

0/74

0/77

0/63

0/69

0/68

0/64

0/65

0/75

0/75

0/75

0/62

0/53

0/57

EmoDNN

0/75

0/75

0/75

0/7

0/7

0/7

0/75

0/6

0/67

0/83

0/69

0/75

0/64

0/61

0/62

TABLE 9: Precision, Recall, and F-measure(F1) of Each Emotion in Different Methods gain the best and the least accuracies. While recognition Hence, we examine the time requirement of our framework.

of fear and joy is convenient, the detection of sadness and Our proposed framework comprises offline and online com-

disgust is tedious in brief contents. We leverage the intuition ponents, where the latter is more complex than the former.

in Fig. 10 to compare the effect of the two highest accuracies In retrospect, we can calculate the complexity for the offline

based on fear and joy where EmoDNN surpasses other section by aggregating the times of including components.

rivals and the lexicon-based attains the least accuracy.

Given m as the number for training samples, the complexity

for the SVR-based module to infer the cognitive factors will be O(m3). The complexity pertaining to two other

(a) Fear

(b) Joy

Fig. 10: Compare baselines accuracy in fear and joy emotion

components, cognitive categorization, and multi-channel feature extraction can be respectively computed as O(m) and O(m.), with  denoting the number of words in each training samples. Let l and k be the respective index and the number of convolutional layers. In that case, the expected

5.4.3 Effectiveness of EmoDNN in multi-class dataset We choose the multi-class WASSA-2017 [14] emotion recognition dataset to evaluate mutual co-existed labels. We compare our method with unison and SVM-behavior methods that address the multi-class challenge. Table 10 shows that EmoDNN overcomes both competitors and unison, equipped with DL modules, can overpass SVM classifiers. Since we include the cognitive cues in emotion features, EmoDNN can upgrade unison by up to 2% in F1-measure.

Percision Recall F1

Accuracy

time for our network to run each category will thus yield

in O((

k l=1

nl-1.|wl|2.nl.Q2l ).m.e)

[55].

Where

nl

and

nl-1

will respectively represent the number of filters and input

channels for the lth layer, |wl| can signify the filter length,

Ql, the output feature spatial size, and e, the number of

epochs. Correspondingly, the time complexity for the cogni-

tive ensemble can be aggregated by all cognitive categories,

verbalized as O(2q.(

k l=1

nl-1.|wl|2.nl.Q2l ).m.e).

Also,

We

designate q with 5 as the number of cognitive cues that as a

small constant can be dismissed in time function. Where

Unison

84.7

83.4

84.1 85

SVM Behavior 80.3

82.2

81.2 80

EmoDNN

86

85.6

85.8 85.8

TABLE 10: Compare Baselines in MultiClass Dataset

the time complexity applies to both training and testing times, though with a different scale, the weights can differ in the attention feature vector and the canonical layers of the emotion recognition network. Suppose , , and  are

constant multipliers. Hence, Eq. 37 can formalize the overall

time complexity of our framework.

However, we further need to efficiently infer millions of

brief messages in the online phase. Depending on the

network structure, since the time complexity of the online

section is polynomial, our model can satisfy the efficacy

Fig. 11: Confusion matrix for emotion prediction

requirements for real-time processing. The time complexity

Fig. 11 illustrates the prediction confusion matrix for our model, where the weights show the percentage of the correctly predicted samples. EmoDNN has successfully recognized fear in 94.7% of the labeled tweets. Where the highest prediction performance is for Fear and Sadness is the least, 68.5% of the correct labels. Evidently, the sadness is mostly misclassified as fear in more than 18% of the cases where the least incorrect labels for Joy is 5.7%. We note that it is almost impossible to predict Fear or Anger by the joy emotion, 0.0%.
5.5 Efficiency

of the online section to exploit emotions from a single short

text is represented by O(

k kl=1

nl-1

.|wl|2

.nl

.Q2l

).

m3 + m. + m + ( nl-1.|wl|2.nl.Q2l ).m.e

l=1 k

(37)

m3 + ( nl-1.|wl|2.nl.Q2l ).m.e

6 CONCLUSION l=1

Our proposed unified framework in this paper leverages

individual cognitive cues to recognize emotions from short

text contents. Most previous efforts on emotion recognition

disregard user-specific characteristics. To fill the gap, we

5.5.1 Computational complexity analysis

firstly categorize short texts according to the cognitive cues.

Our proposed framework is useful in many real-time appli- Subsequently, we then utilize the emotion lexicons along-

cations. Emotion recognition from social contents can better side embedding models to obtain the emotion-aware short

explain the opinion of a community about a product. Also, text vectors. Consequently, we learn corresponding base

the recommendation systems can benefit from emotion classifiers and employ a novel ensemble learning approach

weights to improve final suggestions. Many applications to aggregate the classification outputs. The results from

need to process millions of brief contents that make the extensive experiments on real-world datasets confirm the

efficiency of the emotion-aware inference systems critical. superiority of our proposed framework over state-of-the-art

11

rivals in emotion recognition. However, we need to integrate transfer learning to make inner ensemble classifiers better collaborate. Moreover, we will have to empirically study the effect of various distributions on the proposed dropout module. We leave these tasks for future work.
REFERENCES
[1] D.-A. Phan, Y. Matsumoto, and H. Shindo, "Autoencoder for semisupervised multiple emotion detection of conversation transcripts," IEEE Transactions on Affective Computing, 2018.
[2] W. Budiharto and M. Meiliana, "Prediction and analysis of indonesia presidential election from twitter using sentiment analysis," Journal of Big data, pp. 1­10, 2018.
[3] M. Corazza, S. Menini, E. Cabrio, S. Tonelli, and S. Villata, "A multilingual evaluation for online hate speech detection," ACM Transactions on Internet Technology (TOIT), vol. 20, no. 2, pp. 1­22, 2020.
[4] B. Desmet and V. Hoste, "Emotion detection in suicide notes," Expert Systems with Applications, 2013.
[5] R. Ullah, N. Amblee, W. Kim, and H. Lee, "From valence to emotions: Exploring the distribution of emotions in online product reviews," Decision Support Systems, vol. 81, pp. 41­53, 2016.
[6] J. Bollen, H. Mao, and X. Zeng, "Twitter mood predicts the stock market," Journal of computational science, 2011.
[7] A. A. A. Esmin, R. L. De Oliveira Jr, and S. Matwin, "Hierarchical classification approach to emotion recognition in twitter," in 2012 11th International Conference on ML and Applications, vol. 2. IEEE, 2012, pp. 381­385.
[8] V. K. Jain, S. Kumar, and S. L. Fernandes, "Extraction of emotions from multilingual text using intelligent text processing and computational linguistics," Journal of computational science, vol. 21, pp. 316­326, 2017.
[9] H. Xu, W. Yang, and J. Wang, "Hierarchical emotion classification and emotion component analysis on chinese micro-blog posts," Expert systems with applications, vol. 42, no. 22, pp. 8745­8752, 2015.
[10] N. Colneric and J. Demsar, "Emotion recognition on twitter: Comparative study and training a unison model," IEEE transactions on affective computing, 2018.
[11] D. Watson and L. A. Clark, "On traits and temperament: General and specific factors of emotional experience and their relation to the five factors model," Journal of personality, vol. 60, no. 2, pp. 441­476, 1992.
[12] T. Holtgraves, "Text messaging, personality, and the social context," Journal of research in personality, 2011.
[13] S. Mohammad, F. Bravo-Marquez, M. Salameh, and S. Kiritchenko, "Semeval-2018: Affect in tweets," in Proc. of the 12th workshop on semantic evaluation, 2018.
[14] S. M. Mohammad and F. Bravo-Marquez, "Emotion intensities in tweets," in Proc. 6th Joint Conf. Lexical Comput. Semantics, Vancouver, BC,Canada, 2017.
[15] M. Kosinski, D. Stillwell, and T. Graepel, "Private traits and attributes are predictable from digital records of human behavior," Proceedings of the national academy of sciences, vol. 110, no. 15, pp. 5802­5805, 2013.
[16] S. Najafipour, S. Hosseini, W. Hua, M. R. Kangavari, and X. Zhou, "Soulmate: Short-text author linking through multi-aspect temporal-textual embedding," IEEE Trans. on Knowledge and Data Engineering, 2020.

[17] S. Hosseini, S. Najafipour, N.-M. Cheung, H. Yin, M. R. Kangavari, and X. Zhou, "Teags: time-aware text embedding approach to generate subgraphs," Data Mining and Knowledge Discovery, vol. 34, pp. 1136­1174, 2020.
[18] S. Hosseini, S. Unankard, X. Zhou, and S. Sadiq, "Location oriented phrase detection in microblogs," in International Conference on Database Systems for Advanced Applications. Springer, 2014, pp. 495­509.
[19] D. Xue, L. Wu, Z. Hong, S. Guo, L. Gao, Z. Wu, X. Zhong, and J. Sun, "Deep learning-based personality recognition from text posts of online social networks," Applied Intelligence, vol. 48, no. 11, pp. 4232­4246, 2018.
[20] J. Golbeck, C. Robles, M. Edmondson, and K. Turner, "Predicting personality from twitter," in Proc. 3rd IEEE Int. Conf. on Social Computing. IEEE, 2011, pp. 149­156.
[21] S. Hosseini, H. Yin, M. Zhang, Y. Elovici, and X. Zhou, "Mining subgraphs from propagation networks through temporal dynamic analysis," in 2018 19th IEEE International Conference on Mobile Data Management (MDM). IEEE, 2018, pp. 66­75.
[22] F. Alam, E. A. Stepanov, and G. Riccardi, "Personality traits recognition on social network-facebook," in Seventh Int. AAAI Conf. on Weblogs and Social Media, 2013.
[23] D. Quercia, M. Kosinski, D. Stillwell, and J. Crowcroft, "Our twitter profiles, our selves: Predicting personality with twitter," in Proc. 3rd IEEE International Conference on Social Computing, 2011.
[24] C. Yuan, J. Wu, H. Li, and L. Wang, "Personality recognition based on user generated content," in 2018 15th International Conference on Service Systems and Service Management (ICSSSM). IEEE, 2018, pp. 1­6.
[25] X. Sun, B. Liu, J. Cao, J. Luo, and X. Shen, "Who am i? personality detection based on deep learning for texts," in 2018 IEEE International Conference on Communications (ICC). IEEE, 2018, pp. 1­6.
[26] N. Majumder, S. Poria, A. Gelbukh, and E. Cambria, "Deep learning-based document modeling for personality detection from text," IEEE Intelligent Systems, 2017.
[27] S. M. Mohammad, "Word affect intensities," in Proceedings of the 11th Edition of the Language Re-sources and Evaluation Conference (LREC-2018),Miyazaki, Japan, 2018.
[28] O. Araque, L. Gatti, J. Staiano, and M. Guerini, "Depechemood++: a bilingual emotion lexicon built through simple yet powerful techniques," IEEE transactions on affective computing, 2019.
[29] W. Li and H. Xu, "Text-based emotion classification using emotion cause extraction," Expert Systems with Applications, vol. 41, no. 4, pp. 1742­1749, 2014.
[30] A. Bandhakavi, N. Wiratunga, D. Padmanabhan, and S. Massie, "Lexicon based feature extraction for emotion text classification," Pattern recognition letters, 2017.
[31] O. Udochukwu and Y. He, "A rule-based approach to implicit emotion detection in text," in International Conference on Applications of Natural Language to Information Systems. Springer, 2015, pp. 197­203.
[32] D. Ghazi, D. Inkpen, and S. Szpakowicz, "Prior and contextual emotion of words in sentential context," Computer Speech & Language, pp. 76­92, 2014.
[33] L. Canales, C. Strapparava, E. Boldrini, and P. Martinez-Barco, "Intensional learning to efficiently build up automatically annotated emotion corpora,"

12

IEEE Transactions on Affective Computing, 2017. [34] Z. Halim, M. Waqar, and M. Tahir, "A machine
learning-based investigation utilizing the in-text features for the identification of dominant emotion in an email," Knowledge-Based Systems, vol. 208, 2020. [35] J. Deng and F. Ren, "Multi-label emotion detection via emotion-specified feature extraction and emotion correlation learning," IEEE Transactions on Affective Computing, 2020. [36] E. Batbaatar, M. Li, and K. H. Ryu, "Semantic-emotion neural network for emotion recognition from text," IEEE Access, vol. 7, pp. 111 866­111 878, 2019. [37] S. Akhtar, D. Ghosal, A. Ekbal, P. Bhattacharyya, and S. Kurohashi, "All-in-one: Emotion, sentiment and intensity prediction using a multi-task ensemble framework," IEEE Transactions on Affective Computing, 2019. [38] L. Cai, Y. Hu, J. Dong, and S. Zhou, "Audio-textual emotion recognition based on improved neural networks," Mathematical Problems in Engineering, 2019. [39] X. Wang, L. Kou, V. Sugumaran, X. Luo, and H. Zhang, "Emotion correlation mining through deep learning models on natural language text," IEEE Transactions on Cybernetics, 2020. [40] H. Rong, T. Ma, J. Cao, Y. Tian, A. Al-Dhelaan, and M. Al-Rodhaan, "Deep rolling: A novel emotion prediction model for a multi-participant communication context," Information Sciences, vol. 488, 2019. [41] R. W. Picard, Affective computing. MIT press, 2000. [42] J. Deng and F. Ren, "A survey of textual emotion recognition and its challenges," IEEE Transactions on Affective Computing, 2021. [43] M. Awad and R. Khanna, "Support vector regression," in Efficient learning machines. Springer, 2015, pp. 67­80. [44] G. W. Milligan and M. C. Cooper, "Methodology review: Clustering methods," Applied psychological measurement, vol. 11, no. 4, pp. 329­354, 1987. [45] J. Pennington, R. Socher, and C. D. Manning, "Glove: Global vectors for word representation," in Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), 2014, pp. 1532­1543. [46] T. Mikolov, K. Chen, G. Corrado, and J. Dean, "Efficient estimation of word representations in vector space," in Proceedings of International Conference on Learning Representations (ICLR 2013), 2013. [47] Z. Zhao and Y. Wu, "Attention-based convolutional neural networks for sentence classification." in INTERSPEECH, 2016, pp. 705­709. [48] Y. Wei, W. Xia, M. Lin, J. Huang, B. Ni, J. Dong, Y. Zhao, and S. Yan, "Hcp: A flexible cnn framework for multilabel image classification," IEEE transactions on pattern analysis and machine intelligence, pp. 1901­1907, 2015. [49] D. P. Kingma and J. Ba, "Adam: A method for stochastic optimization," in Proceedings of International Conference on Learning Representations (ICLR 2015), 2015. [50] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, "Dropout: a simple way to prevent neural networks from overfitting," The journal of machine learning research, pp. 1929­1958, 2014. [51] L. Wan, M. Zeiler, S. Zhang, Y. Le Cun, and R. Fergus, "Regularization of neural networks using dropconnect," in Int. conf. on ML, 2013, pp. 1058­1066.

[52] R. Zall and M. R. Kangavari, "On the construction of multi-relational classifier based on canonical correlation analysis," International Journal of Artificial Intelligence, vol. 17, no. 2, pp. 23­43, 2019.
[53] R. Zall and M. R. Keyvanpour, "Semi-supervised multiview ensemble learning based on extracting cross-view correlation," Advances in Electrical and Computer Engineering, vol. 16, no. 2, pp. 111­125, 2016.
[54] P. Ekman, "Basic emotions," Handbook of cognition and emotion, vol. 98, no. 45-60, p. 16, 1999.
[55] K. He and J. Sun, "Convolutional neural networks at constrained time cost," in Proceedings of the IEEE conference on computer vision and pattern recognition, 2015.
Sara Kamran is a researcher in the Computational Cognitive laboratory of Iran University of Science and Technology (IUST). She received M.Sc. from IUST and B.S. from the Urmia University of Technology, Iran, in software engineering. Her research interests include affective and cognitive computing, Human-ComputerInteraction, NLP, machine learning, and data analysis.
Raziyeh Zall received the B.S degree from University of Shahid Beheshti of Iran, and M.Sc degree from the Alzahra university of Iran. She is currently working toward the PHD degree in computational cognitive models laboratory at Iran University of Science and Technology. Her research interests include affective and cognitive computing, NLP, and Multi view learning.
Mohammad Reza Kangavari received B.Sc. in computer science from the Sharif University of Technology, M.Sc. from Salford, and Ph.D. from the University of Manchester. He is an associate professor at the Iran University of Science and Technology. His research interests include Intelligent Systems, Human-Computer-Interaction, Cognitive Computing, Machine Learning, and Sensor Networks.
Saeid Hosseini currently works as an assistant professor at Sohar University. He won the Australian Postgraduate Award and received Ph.D. degree in Computer Science from the University of Queensland, Australia, in 2017. He has also completed two post docs in Singapore and Iran. His research interests include spatiotemporal database, dynamical processes, data and graph mining, big data analytics, recommendation systems, and machine learning.
Sana Rahmani is a researcher in the Computational Cognitive laboratory of Iran University of Science and Technology (IUST). She received M.Sc. from IUST and B.S. from the University of Kurdistan, Iran, in software engineering. Her research interests include multimodal affective analysis, Human-Computer-Interaction, machine learning, and data analysis.
Wen Hua currently works as a Lecturer at the University of Queensland. She received her doctoral and bachelor degrees in Computer Science from Renmin University. Her current research interests include natural language processing, information extraction and retrieval, text mining, social media analysis, and spatiotemporal data analytics. She has published articles in reputed venues including SIGMOD, TKDE, VLDBJ.

