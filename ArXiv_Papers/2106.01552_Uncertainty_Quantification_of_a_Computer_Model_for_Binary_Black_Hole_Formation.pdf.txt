arXiv:2106.01552v1 [astro-ph.IM] 3 Jun 2021

Submitted to the Annals of Applied Statistics
UNCERTAINTY QUANTIFICATION OF A COMPUTER MODEL FOR BINARY BLACK HOLE FORMATION
BY LUYAO LIN1, DEREK BINGHAM1, FLOOR BROEKGAARDEN2 AND ILYA MANDEL3,4,5
1Simon Fraser University, luyao_lin_2@sfu.ca; derek_bingham@sfu.ca
2Harvard-Smithsonian Center for Astrophysics, floor.broekgaarden@cfa.harvard.edu
3School of Physics and Astronomy, Monash University, Clayton, Victoria 3800, Australia, ilya.mandel@monash.edu
4The ARC Center of Excellence for Gravitational Wave Discovery ­ OzGrav, Australia
5Birmingham Institute for Gravitational Wave Astronomy and School of Physics and Astronomy, University of Birmingham, Birmingham, B15 2TT, United Kingdom
In this paper, a fast and parallelizable method based on Gaussian Processes (GPs) is introduced to emulate computer models that simulate the formation of binary black holes (BBHs) through the evolution of pairs of massive stars. Two obstacles that arise in this application are the a priori unknown conditions of BBH formation and the large scale of the simulation data. We address them by proposing a local emulator which combines a GP classifier and a GP regression model. The resulting emulator can also be utilized in planning future computer simulations through a proposed criterion for sequential design. By propagating uncertainties of simulation input through the emulator, we are able to obtain the distribution of BBH properties under the distribution of physical parameters.
1. Introduction. Scientists frequently explore complex phenomena by means of computer models that simulate the behavior of these systems. In some cases, the CPU time required to evaluate the model can take hours to months (e.g. Gramacy and Lee, 2008), while in others the model may be fast to evaluate on a super computer, but is not readily available to those who need it (e.g. Kaufman et al., 2011; Lawrence et al., 2017). In either case, Gaussian process emulators (Sacks et al., 1989) are often used to stand in for the computer model (or simulator). In this paper, we propose a new type of emulator where a large simulation design is available, but there are unknown constraints that specify where a model output will occur.
The application that motivated the proposed methodology was to construct a fast emulator for binary population synthesis simulation codes that study characteristics of binary black hole (BBH) mergers. Population synthesis codes typically begin with a binary star system at birth, and determine the system's evolutionary outcome. Figure 1 depicts an example of the binary evolution pathway modelled by such simulation codes. These computer models are quite fast, potentially yielding millions of model evaluations per day. However, given the high dimensionality of the input and complexity of binary stellar evolution, in practice many billions of binaries need to be simulated to perform an experiment that is sufficiently large to make scientific inferences. This can amount to computing times of years.
To address this issue, present-day simulation studies in these settings make compromises such as sacrificing accuracy for speed by adopting approximate/simplifying algorithms, or restricting the exploration of physical assumptions to limit the number of simulations. Here,
Keywords and phrases: Computer Experiments, Surrogate Model, local approximate GP, Sequential Design. 1

2

by introducing a fast statistical surrogate model for the simulation codes, we aim to preserve

both accuracy (with uncertainty measures) and free exploration of physical parameters.

The first challenge facing the emulation of popula-

tion synthesis is the large scale of these experiments,

which renders traditional GPs prohibitive due to com-

putational limitations resulting from the inversion of

the covariance matrix in the Gaussian likelihood (see

e.g. Kaufman et al., 2011; Barrett et al., 2017). There

are several approaches dealing with GP modeling

with large-scale data. Innovations to the full covari-

ance matrix are often proposed to alleviate the com-

putational burden (e.g. Kaufman et al., 2011; Cressie

and Johannesson, 2008; Quiñonero-Candela and Ras-

mussen, 2005). Gramacy and Apley (2015) side-step

the issue by using smaller, local GPs (laGP). Inspired

by the laGP, the approach proposed herein focuses on

building local models by choosing informative neigh-

boring designs for input locations of interest.

A second challenge in population synthesis emula-

tion is that the success rate of producing a BBH via

sampling from the input distribution of initial condi-

tions is extremely low. Typically, one BBH is formed

per  103 - 106 binaries simulated (e.g. Belczyn-

ski, Kalogera and Bulik, 2002; Taylor and Gerosa,

2018; Kruckow et al., 2018; Broekgaarden et al.,

2019), so the vast majority of computational time is

spent on simulations that do not produce an outcome.

Improvements to the success rate have been pro- Fig 1: Schematic view of the formation pathposed through Adaptive Importance Sampling (AIS) way of a BBH system through classical (Broekgaarden et al., 2019), or Markov Chain Monte isolated binary evolution via the common-

Carlo (MCMC) (Andrews, Zezas and Fragos, 2018), envelope phase. Panels from top to bottom

but in both cases it is challenging to scale to high dimensions and non-trivial to perform inference.
Lastly, since the input conditions that allow for BBH formation are not known in advance, it is desirable that the surrogate model addresses this issue. La-

show: initial stellar binary; mass transfer from the evolving and expanding more massive star (blue) onto its less massive companion (green); continued evolution of initially more massive star until it collapses into a black hole; mass transfer from the initially

tent variable models have been employed to provide a probabilistic quantification of the unknown constraints. For example, Gramacy and Lee (2010) and Gelbart, Snoek and Adams (2014) used a GP classifier in an attempt to optimize a system in the pres-

less massive star onto the black hole which leads to the formation of a common envelope of gas, significant drag, and rapid spiral-in; the ejection of the common envelope leaving behind a tighter binary; and the collapse of the companion into a black hole. Adapted

ence of unknown constraints. In our work, we take a from Mandel and Farmer (2018).

Bayesian approach to make inferences for the latent

variable model. However, when it comes to large data

sets, fully Bayesian inference in our setting becomes computationally intensive as all com-

ponents in the Markov Chain need to be updated and stored.

In this paper, new methodology is proposed for large-sample emulation for computer mod-

els with unknown constraints. The proposed emulator combines a fast-to-compute GP classi-

fier and a local GP model to provide predictions with uncertainty quantification for population

synthesis codes.

3

TABLE 1 Input/Output of COMPAS models

Input Initial conditions: x m1 : the mass of the initially more massive star m2: the mass of the initially less massive star a: the initial orbital separation vi : supernova natal kick vector for supernova i, i = 1, 2, including:
vi - magnitude of the supernova natal kick (km s-1)
i - polar angle defining the direction of the natal kick
i - azimuthal angle defining the direction of the natal kick
i - mean anomaly Hyperparameters: t Z: the metallicity  : the common envelope efficiency parameter  : 1D root-mean-square value representing a typical supernova kick flbv: multiplication factor for the mass loss rate during the luminous blue variable (LBV) phase Output
Success: indicates whether BBH is formed Mc: chirp mass of BBH

Range [8, 150] M (0.1 M , m1] [0.01, 1000] AU
[0, ) [0, ]
[0, 2] [0, 2] [0.0001, 0.03] [0, 10] [0, 1000] km s-1 [0, 10]
{0, 1} (0, 150) M or NA

Distribution Power law(-2.35)
Uniform Power law(-1)
Maxwellian Uniform Uniform Uniform

The paper is organized as follows. Section 2 details the population synthesis simulation model that motivated this work, namely the COMPAS model1. In Section 3, new methodology that combines a local GP classifier and a local GP emulator is proposed, followed by the introduction of a sequential design criterion for improving the emulator. Synthetic examples illustrating the proposed method are given in Section 4, and emulation results for BBH formation are presented in Section 5. The proposed methodology is fairly general and can easily be adapted to other population synthesis codes or models with unknown constraints. The paper concludes with comments and future work.
2. Population synthesis of BBH mergers. The COMPAS model that motivated this work is a rapid binary population synthesis code that focuses on gravitational-wave astrophysics. In particular, it is designed to study uncertainties in binary evolution and to optimize the information that can be obtained from simulations (Stevenson et al., 2017; Barrett et al., 2018; Vigna-Gómez et al., 2018; Neijssel et al., 2019).
There are two types of input in the COMPAS model. One is the set of initial conditions intrinsic to each binary, denoted by x. These provide the state of the binary at formation (top of Figure 1), such as the initial stellar masses and the distance between the stars. Another type of input is the set of population hyper-parameters, denoted by t, which is shared between all binaries in a population. These hyper-parameters can be thought of as parametrizations of the differential equations governing stellar and binary evolution. The true values of the hyperparameters t are unknown in advance. An important goal (not addressed here) is to infer their
1Compact Object Mergers: Population Astrophysics and Statistics (COMPAS, https://compas.science): a platform for the exploration and study of populations of compact binaries formed through isolated binary evolution.

4
values by comparing the BBH properties predicted by simulations with different choices of t with observations (Mandel and Farmer, 2017).
A key output for BBH population synthesis is the chirp mass of the BBH, which is a combination of the masses that are typically best measured from the gravitational-wave signal (Peters and Mathews, 1963). For the purpose of studying BBH formation, the COMPAS output is summarized by the chirp mass of the BBH, or if the binary does not evolve into a BBH, the output is "NA". A relevant list of COMPAS inputs is provided in Table 1. The initial conditions of a binary follow observationally constrained distributions; simplified versions of these are specified in the third column of the table. A key challenge is that the regions of input space that result in "NA" outputs are unknown - thus the unknown constraints.
The COMPAS model, like many other binary population synthesis codes, has a relatively high-dimensional input and, more importantly, a low success rate for BBH formation. Specifically, the COMPAS model used here requires a 15-dimensional input, and produces a success rate that is below 1% (Broekgaarden et al., 2019). In the next section, we introduce an emulator for COMPAS that addresses the large sample size (> 106) and also the unknown constraints that result in the low success rate for BBH formation in the simulations.

3. Methodology: local surrogate models with unknown constraints. In this section, new methodology for emulating large-sample computer experiments on simulators with unknown constraints is proposed. Before introducing the components of the approach, some notation is first introduced.
Denote the deterministic computer model as m(·) with inputs x that, without loss of generality, belong to the d-dimensional unit cube. The unknown constraints define the subset of input space, C, where the simulator returns a univariate, real-valued response (i.e., the constraint region). For the applications we consider, C is assumed to be the union of nonoverlapping, compact regions of the input space.
An indicator function, y(x), is used to identify whether or not an input results in a realvalued output. That is, y(x) = 1 if {x  C} and zero otherwise. The computer model output can then be expressed as

(1)

m(x) =

NA z(x)

if if

y(x) y(x)

= =

0 1

,

where m(x) = NA corresponds to x  C, and z(x) is the real-valued computer model response for {x  C}.
Let X = (x1, x2, . . . , xN ) be the N -run computer experiment design matrix, and m = (m1, m2, . . . , mN ) be the model outputs. The corresponding indicator labels are denoted y = (y1, y2, . . . , yN ) . We partition the design, matrix X, into the active set, {x : x  X and x  C}, and the null set, {x : x  X and x  C}.
As we shall see, the formulation in (1) will allow us to (i) obtain a probabilistic representation of the unknown constraints through y(x), and (ii) decompose prediction uncertainties into components that correspond to unknown constraints and emulation errors, respectively. In the COMPAS model, for example, the probability of producing a BBH at an unsampled input, x, can be quantified by P (y(x) = 1). This is useful since one can, for example, learn about the initial conditions that are likely to lead to BBH formation conditional on the observed simulator responses. Of course, one is also interested in predicting the chirp mass, and thus we are also interested in estimating m(x).
In the applications considered, N is large, and the computation involved in fitting a conventional GP is prohibitive. A two-step procedure is proposed to address the big N problem in the presence of unknown constraints. We take a similar approach as Gramacy and Lee (2010) where a classifier is used to identify whether or not an input is in the constraint region

5

and an independent GP is used to emulate z(x). First, the indicator function, or constraint function, is modelled using a local GP classifier. Second, when y(x) is predicted to be one, a local GP emulator is constructed to predict the simulator output m(x). If y(x) is predicted to be zero, m(x) is predicted as NA.
The proposed local classification model is presented in Section 3.1, followed by a local
response surface model in Section 3.2. A holistic view of the procedure is given in Section
3.3. Finally, we propose new sequential design methodology in Section 3.4 for the selection
of new simulation trials.

3.1. Classification. A logistic GP classifier (Williams and Rasmussen, 2006) is used to model the constraint function. Specifically,

(2)

P (yi = 1)  qi = (1 + e-fi )-1,

or equivalently,

fi

=

log

1

P -

(yi = P (yi

1) = 1)

,

where f = (f1, f2, . . . , fN ) is a vector of latent variables describing the log-odds of {yi = 1}. A mean-zero GP is used to model the latent variables f as a function of the inputs X.
That is,

(3)

f  N (0, f ) ,

where f is the N × N covariance matrix with elements determined by a stationary covariance function. Throughout, we use the squared-exponential covariance function (Sacks et al., 1989)

(4)

cov(fi, fj) = -1 · exp

-

d l=1

(xi,l

- xj,l)2 2l

,

where  denotes the precision parameter and l (l > 0) is the length-scale parameter for the l-th dimension.
When N is large, the time required to evaluate the Gaussian likelihood due to inverting
the covariance matrix can be exceedingly long. To address this, alternate methods have been
proposed to alleviate the computational burden by imposing simplifying assumptions on the
covariance matrix (e.g. Kaufman et al., 2011; Cressie and Johannesson, 2008; Quiñonero-
Candela and Rasmussen, 2005). Another approach is to construct smaller, local designs in the neighborhood of the unsampled input, x, to emulate m(x) (Gramacy and Apley, 2015).
Here, we propose to use some of the elements outlined in Gramacy and Apley (2015) for
inference on the models presented in Sections 3.1 and 3.2. For classification, we use the n nearest neighbors (n N ) to the input of interest, x. Denote the inputs, with their outputs, closest to x as B(x) = (Xb, mb). The computation for emulating y(x) can then be reduced from O(N 3) to O(n3). Let yb and f b denote the class label and latent log-odds variable at Xb. The joint distribution of yb and f b given the local GP classifier parameters, b and b, is

p(yb, f b|b, b)

= p(yb|f b) · p(f b|b, b)

n
=
i=1

efib 1 + efib

yib

1 1 + efib

1-yib

1 · 2n|bf |1/2 · exp

-

1 (f b)T 2

(bf

)-1(f b)

,

where bf is the n × n covariance matrix of f b, p(yb|f b) is joint probability mass function for yb (i.e., independent Bernoulli random variables), and p(f b|b, b) is a local GP in the

6

form of (3). The joint posterior distribution of f b, b and b can be expressed as

(5)

p(f b,

b,

b|yb)

=

p(f b, b, b, p(yb)

yb)

 p(yb, f b|b, b) · (b, b),

where (b, b) is the joint prior distribution for b and b. To draw posterior samples of f b, b and b, single site Metropolis-Hastings (MH) MCMC
can be employed (Hastings, 1970). However, since fib's are correlated, independent sampling
is inefficient. Instead, elliptical slice sampling (Murray, Prescott Adams and MacKay, 2010) is adopted for f b, with MH steps used for b and b. Elliptical slice sampling is practical in
this setting because (a) it has a 100% acceptance rate, (b) the simultaneous update of vector f b and (c) there are no algorithm parameters to tune. Details of the sampling procedure can
be found in Appendix A. Once posterior samples of f b, b and b are obtained, the latent log-odds variable at x,
denoted by f (x), can be predicted with

(6)

[f (x)|f b, b, b]  N rT (x)(bf )-1f b, 1/b - rT (x)(bf )-1r(x) ,

where r(x) is the the vector of covariances between f (x) and f b. To summarize, sampling of f (x) given B(x) starts with drawing a posterior sample of
(f b, b, b), with which the posterior mean and variance in (6) are computed. The procedure
is concluded by drawing a random sample from the resulting Gaussian process.

Algorithm 1: Classify y(x) with local GP classifier

Input: model input of interest x, local design size n, simulation data D = (X, m) Output: posterior sample of y(x) and log-odds f (x)

1 xb  n neighboring points to x in the simulation data;

2 yb  class labels for Xb ;

3 if Xb all in null set, i.e., yb = 0 then

4

predict y(x) to be 0 with probability 1.

5 else

6

if Xb all in active set, i.e., yb = 1 then

7

predict y(x) to be 1 with probability 1.

8

else

9

build GP classifier with Xb and yb ;

10

predict y(x) using the posterior distribution of the classification model parameters and f b.

11

end

12 end

A benefit of using B(x) instead of the full simulation data, aside from reduced computa-
tional complexity in the GP classifier, is the opportunity to forego the MCMC step altogether when all constraint function labels are the same in B(x). As illustrated in Algorithm 1, we start with the full simulation data, an input of interest x and a user-specified local design of size n. An n nearest neighbor design, Xb, is then constructed. If the corresponding class labels yb are identical, y(x) can be simply set to the common value of yb with probability 1. In cases where the class labels, yb, of the local design are not identical, the aforementioned MCMC procedure is carried out to make inferences about model parameters and y(x). The
choice of n involves a trade-off between computational burden and classification accuracy.

7

Algorithm 2: Emulating z(x) with local approximate GP

Input: model input x, initial neighboring design B(x) = (Xb, mb), maximum neighbor size nM ,

training data D Output: predictive distribution of z(x) 1 A(x)  active points in B(x) ; 2 T  points in D\A(x) that are the first nearest neighbors of A(x); 3 T a  active simulation data in T ;

4 while T a =  and size of A(x) is less than nM do

5

Add T a to A(x)

6

Update T and T a

7 end

;

// Expand neighboring points

8 if size of A(x) is larger than nM then

9

Remove from A(x) simulations with inputs that are furthest from x to maintain design size of nM

10 else

11

Keep A(x) as the final local design

12 end

13 ;

14 Build local approximate GP with A(x) = (Xab, zab) ; 15 Obtain predictive distribution of z(x)

For the classification problem, setting n as large as permitted by computing resources can help with prediction accuracy. On the other hand, the evaluation of the log-likelihood within the MCMC grows at O(n3), and there will be more latent variables to be sampled with larger n, thereby resulting in a slower MCMC runs. In the BBH application where emulation speed is important, we found n = 50 to be a satisfactory after trying different choices for n and examining the corresponding classification accuracy and runtime. The choice of the distance metric can be made based on the application of interest, and is discussed later in Section 5.1.

3.2. Response surface model. We propose to use a local GP emulator for the response surface z(x) on the active set. Let za = (z1a, z2a, . . . , zNa a) denote the subset of simulation outputs m that are real-valued, with corresponding design points Xa = (xa1, xa2, . . . , xaNa) .
Generally speaking, we can emulate z(x) with Xa and za by assuming a constant mean
GP model,

za  N (µ · 1Na , z),

where µ is the constant mean and z is the covariance matrix. We adopt the squaredexponential covariance function for z, with



2

(7)

d

cov(zia,

zja)

=

-1

·

exp

- 

l=1

xai,l - xaj,l l2

, 

where  is the precision parameter, l (l > 0) is the length-scale parameter for the l-th input
dimension, and  = (1, 2, . . . , d) .
For the reasons discussed in Section 3.1, evaluation of the Gaussian likelihood becomes infeasible with large N a. To address this, a local GP emulator is adopted instead of the global GP stated above. For an unsampled input of interest, x, a local design consisting of only active simulations is constructed to emulate z(x). One might be tempted to create this local design with nearest neighbors to x from the active set. However, some of these active neighbors might come from different compact subsets of the constraint region than that of x,

8

resulting in inclusion of simulation data that can represent very different behavior than the neighborhood of z(x). To construct this active local design, the set of active simulations in local data B(x), denoted by A(x), is used as the starting point in an iterative algorithm.
Recall that D = (X, m) represents the full simulation data. For each iteration, we first search
the remaining simulations for ones with inputs that are the nearest neighbors of the design points in A(x), and denote these simulation data by T = (Xt, mt). Next, the active simulations in T are included in A(x). The search continues until either the maximum design size nM for A(x) is reached or all first nearest neighbors to A(x) are from the null set. If the algorithm ended up with more than nM simulations after the last iteration, observations with inputs that are furthest from x will be removed. Denote the resulting local data with nab observations as A(x) = (Xab, zab) . This procedure is summarized in Algorithm 2.
The GP likelihood is

(8)

p(zab|b,

b, µb)

=

1

 2

nab

|bz

|1/2

exp

-

1 2

(zab

-

µb

·

1)

(bz )-1 (z ab

-

µb

·

1)

,

where bz is the covariance matrix for zab. The posterior of (b, b, µb) is then

p(b, b, µb|zab)

=

p(b, b, µb, zab) p(zab)

(9)

 p(zab|b, µb, b) · (b, µb, b),

where (b, µb, b) is the prior distribution of the parameters. The conditional distribution of z(x) is
(10) [z(x)|zab, b, b, µb]  N k (x)(bz)-1(zab -µb1)+µb1, (b)-1 -k (x)(bz)-1k(x) ,

where k(x) represents the covariance between z(x) and zab. To sample z(x) given A(x), we first draw samples of (b, b, µb) from the posterior distribution in (9) (with standard sin-
gle site Metropolis-Hastings, for example), and then compute the posterior mean and variance
of the above normal distribution. The last step is simply to draw sample from this distribution. Next, we move on to inference for m(·) at unsampled inputs x by putting together the
classifier introduced in Section 3.1 and the response surface model discussed in this section.

3.3. Combining local models. We now put together the pieces of the fast local emulator for simulators with unknown constraints. We are interested in emulating m(x), with simu-
lation data D = (X, m). The following steps are taken:
(i) Standardization:
Following the convention adopted in GP modeling (Higdon et al., 2008), the input region is mapped to the d-dimensional unit cube [0, 1]d.
(ii) Local classification: Algorithm 1 A n-run nearest neighbor design for x is constructed from D. If the outputs of this
design share the same class label, y(x) is predicted to be that label with probability 1. Otherwise, the model described in Section 3.1 is used to estimate y(x). Denote by f^(x) and y^(x) the resulting emulator for f (x) and y(x), respectively.
(iii) Response surface model: Algorithm 2 When y^(x) = 1, we move on to the local response surface model. Another set of
local data consisting of active points, denoted by A(x), is constructed as described in Algorithm 2. With A(x) in hand, the predictive distribution of z(x) can be obtained as in (10), with the prediction denoted z^(x).

9

(iv) Putting everything together: The resulting emulator for m(x), denoted by m^ (x), has two components: y^(x) and
z^(x):

(11)

m^ (x) =

NA z^(x)

if if

y^(x) y^(x)

= =

0 1

.

Up until now, we have been somewhat vague about how to predict y(x) after sampling

f^(x) from its posterior distribution. In practice, several approaches can be taken to generate a prediction of y(x). One way, for example, is to set y^(x) = 1 if its posterior mean is

larger than a user specified threshold (we use 0.5 in examples later) and zero otherwise.

Alternatively, one could use the MAP (maximum a posteriori) estimate. A third way that

adopts the MAP estimate of binary classification outcome is used later in Section 4.

In some applications, an unsuccessful simulation corresponds to zero instead of NA as

output. To emulate m(x) in this setting, samples of f^(x) and z^(x) are drawn as outlined

after (6) and (10). A random sample of m^ (x) is set to the weighted average between zero

and

z^(x), with probabilities

ef^(x ) 1+ef^(x )

and

: 1
1+ef^(x )

(12)

m^ (x)

=

1

ef^(x) + ef^(x)

·

z^(x)

+

1

+

1 ef^(x)

·

0

=

1

ef^(x) + ef^(x)

·

z^(x).

By adopting local models, the argument is that far away points contribute negligibly little to the prediction at x relative to the neighboring points. The local classifier proposed extends the nearest neighbor classification method (Cover and Hart, 1967) with a GP classifier (Williams and Rasmussen, 2006) to consider anisotropic constraints and to offer a local assessment of uncertainty. The proposed response surface model attempts to address local anisotropic behavior in z(·), and it is also possible to incorporate more sophisticated selection criteria (Gramacy and Apley, 2015) if enough active local points are available.
An important aspect of the proposed method is that it is highly parallelizable. The emulation of individual points of interest x can be easily extended to a large number of points by employing multiple CPUs and distributing the points among the CPUs. If needed, the classification and response surface model step can also be parallelized in light of the independence assumption for y(x) and z(x). Another convenient feature of the model is that it allows us to tackle the sequential design problem for computer models with unknown constraints. In the next section, a design criterion is introduced to guide future simulations.

3.4. Sequential design. A practical problem of interest is to select new simulation runs to improve the emulator. In this section, we propose a design criterion, conventionally called an improvement function, that aims to reduce misclassification in y^(·) and also the predictive variance of z^(·) for computer models with unknown constraints. Let x~ be a candidate design point. Improvement functions, denoted by I(x~), have been used for sequential design to achieve various goals such as optimization (Jones, Schonlau and Welch, 1998) and contour estimation (Bingham, Ranjan and Welch, 2014).
Since m(x~) is labeled as `NA' when y(x~) = 0, the variability of m^ (x~) can not be derived directly. Here, we redefine the predictive variance of m^ (x~), Var[m^ (x~)], as the generalized predictive variance of (y^(x~), z^(x~)) , written as

(13)

Var[m^ (x~)] = Var

y^(x~) z^(x~)

=

Var[y^(x~)] 0 0 Var[z^(x~)]

= Var[y^(x~)] · Var[z^(x~)]

An intuitive sequential design procedure is to minimize the maximum predictive variance by assigning new simulations where Var(m^ (x~)) is the largest. Note that Var(y^(x~)) is largest

10

when P(y^(x~) = 1) = 0.5, which means that any sequential strategy that attempts to reduce Var(y^(x~)) will tend to place new simulations near the constraint boundary. On the other hand, Var(z^(x~)) is larger in the case of extrapolation, meaning that x~ with larger Var(z^(x~)) resides far from the center of the local design. Therefore, larger Var(m^ (x~)) corresponds to x~ that is near the boundary of C. The end result is overemphasizing the improvement of y^(x~), and placing little emphasis on improving predictions of z^(x~).
Alternatively, for computer models that produce zero as an output when x  C, the computer model can be written as m(x) = y(x) · z(x). Here, we standardize the simulation output to the unit interval to prevent the variance of m^ (x~) from being dominated by the scale of z^(x~), and to put y^(x~) and z^(x~) on a similar scale. The predictive variance of m^ (x~) = y^(x~) · z^(x~) can be written as

Var(m^ (x~)) = E(Var(m^ (x~)|y^(x~))) + Var(E(m^ (x~)|y^(x~)))

= E(y^2(x~)) · Var(z^(x~)) + Var(y^(x~)) · E2(z^(x~))

(14)

= E(y^(x~)) · Var(z^(x~)) + Var(y^(x~)) · E2(z^(x~)) .

variation of response surface

classification variation

By conditioning on y^(x~), the predictive variance of m^ (x~) contains two components, either carrying the predictive variance of the classifier y^(x~) or that of the emulator z^(x~). Both Var(z^(x~)) and E2(z^(x~)) are always between 0 and 1. In our experience, Var(y^(x~)) quickly becomes the dominant term in the sum in Equation (14) for x~ with large Var(m^ (x~)) as more simulations are performed. This leads to the majority of new simulations being placed near the constraint boundaries with relatively little consideration for improving predictions of z(x~). We omit the demonstration of this phenomenon, but we have found that improvement functions that address only the total variance of m^ (x~) will produce less favorable results for the variance of the emulator z^(x~).
We propose the following improvement function, which can be viewed as an adaptation of the first term to a type of contour estimation; the goal is to focus on improving the estimate of z, but only if there is some reasonable probability that y(x~) is non-zero, i.e., that x~ satisfies the constraint:

(15)

I(x~) = max(0, (x~) + q^(x~) - pthres) · Var(z^(x~)),

where

q^(x~)

=

, ef^(x~)
1+ef^(x~)

is

an

estimate

of

the

probability

of

successful

outcome

at

input

x~

given the simulation data, and pthres is a user-specific classification threshold. The difference

between a percentile (we choose the 95th for example) and the mean of q^(x~) is denoted

(x~). That is, P(q^(x~)  (x~) + E[q^(x~)]) = 0.95. The second term Var(z^(x~)) is the predic-

tive variance of z^(x~) given simulation data D, and reducing Var(z^(x~)) will lead to better

performance of z^(·). Recall from Sections 3.1 and 3.2 that the proposed method produces

the posterior samples of q^(x~) and Var(z^(x~)), which allows us to obtain E(I(x~)) directly. For

candidate simulation points (x~1, x~2, . . . , x~K), one can then choose the trial with the largest

E(I(x~i)) to perform future simulations. This improvement function combines the needs to

detect unknown constraints and to explore active regions at the same time. The user-specified

threshold pthres can be viewed as a tuning constant that trades-off having more predicted

successful simulations (BBH mergers) with reducing output uncertainty within the constraint

regions (the chirp mass of BBH mergers). A detailed illustration will be given later in Section

4.2.

4. Numerical Illustrations . In this section, two synthetic examples are used to illustrate
the proposed emulation method, that we call lcGP for local constrained GP. To compare with existing emulation methods, we use models where the output m(x)  R+ for x  C,

11
and m(x) = 0 otherwise. The performance of the proposed approach is compared with the traditional GP, laGP (Gramacy and Apley, 2015), and a global GP classifier coupled with a global GP. Section 4.1 provides a simple and intuitive example of a top hat function (Dunlop et al., 2018) to demonstrate the benefits of coupling the classification model y(x) with the traditional GP z(x). The second example (Section 4.2) illustrates in detail how to implement the proposed methodology for emulation along with sequential design.
Denote by X the set of inputs to emulate. For each xi  X, Algorithm 1 is adopted to find n neighboring points to xi in D, and to predict y(xi ). If y^(xi ) = 0, we predict m^ (xi ) = 0. Otherwise, a local active design as described in Algorithm 2 is constructed, and local emulator z(·) is used to predict m^ (xi ) = z^(xi ). For different xi 's, emulation can be conducted in parallel since the local models are independent. If fast emulation is the goal, one need only estimates (e.g., using the MAP estimate) for y^(xi ) and z^(xi ), respectively, to obtain m^ (xi ) = y^(xi )·z^(xi ). On the other hand, if uncertainty quantification of the computer model is of interest (as in the sequential design problem for example), posterior sampling of f^(xi ) (Section 3.1) and z^(xi ) (Section 3.2) should be done. To provide a detailed illustration, the latter approach is taken for the two examples.
4.1. The top hat function. To provide intuition for the performance of the proposed method, we start by emulating the simple function (Dunlop et al., 2018) shown in Figure 2. The true function (black lines) and simulation responses (red dots) are shown in Figure 2a. Two different predictive approaches for lcGP are considered. The first, referred to as the binary classification approach from here on, sets y^(x) to one when q^(x) > 0.5 (Figure 2d), and zero otherwise. The other sets y^(x) equal to q^(x), which is the expected value of y^(x) given q^(x) (Figure 2e).

(a) The top hat function

(b) GP

(c) laGP

(d) lcGP (binary)

(e) lcGP (expected)

Fig 2: Emulation of the top hat function with different methods. Black lines represent the true function and red dots are the observed simulation data. Point-wise predictive intervals with 95% confidence are highlighted with light blue color and dashed blue curves depict the predicted response. The predictions adopt the predictive means for the traditional GP method and the laGP method, and combine the maximum a posteriori (MAP) estimates for y^(·) and z^(·) for the lcGP method.

For each of the emulation methods, we predict the model output at 100 evenly spaced points on the unit interval. Our goal is to make predictions with associated predictive inter-

12

vals based on the 12-run simulation shown as red dots in Figure 2a. For laGP, a local design
of size 4 is used. For the proposed lcGP method, emulation with both binary classification for y^(x) as in (11) (Figure 2d) and the expected valueof y^(x) (x  X) as in (12) (Figure 2e) are produced. A uniform prior distribution, U (0, 10), is chosen for the GP classifier length-scale parameter, , and this corresponds to a maximum correlation of 0.9048 between log-odds at the two extremes x = 0 and x = 1. The prior distribution for the inverse of the precision parameter, -1, is chosen as U (0, 4). With -1 = 4, the three-standard-deviation limits, (-6, 6), for the log-odds are equivalent to the log-odds of (0.0025, 0.9975) for the classification probabilities. This suggests that U (0, 4) is a relatively uninformative prior distribution for -1. Elliptical slice sampling is used to sample the latent log-odds, and single site Metropolis-Hastings is used to sample the GP parameters,  and -1. Python code used
to for this example can be found in the supplemental materials (Lin et al., 2021). To construct prediction intervals with lcGP, posterior samples of m^ (x) are drawn by
(i) sampling the classification probability q^(x) = (1+exp(-f^(x)))-1 as described in Sec-
tion 3.1; (ii) generating posterior samples of y^(x) (0's and 1's) based on q^(x) (Figure 2d), or, setting
y^(x) to q^(x) (Figure 2e); (iii) drawing posterior samples of z^(x) as described in Section 3.2; (iv) obtaining the posterior samples for m^ (x) = y^(x) · z^(x).
Pointwise 95% prediction intervals are constructed directly with the resulting posterior samples of m^ (x). Figure 2 illustrates that the traditional GP and laGP attempt to smooth out
the discontinuity, thereby causing the emulator to perform relatively poorly on the constant
regions. The proposed lcGP methods are able to more closely emulate the true behavior of the
computer model within the constraint region, and identify the uncertainty near the constraint
boundaries. It is worth-noting that the uncertainty captured by the confidence interval of the lcGP method (Figures 2d and 2e) does not include that of the Bernoulli distribution of y^(x). Rather, it addresses the posterior uncertainty of the latent log-odds variable f^(x).

4.2. A Two-dimensional Example. Consider an example model from Gramacy and Apley (2015) that was presented without constraints:
(x1, x2) = e-(x1-1)2 + e-0.8(x1+1)2 - 0.1 sin(8(x1 + 0.1))
· e-(x2-1)2 + e-0.8(x2+1)2 - 0.1 sin(8(x2 + 0.1)) ,
where (x1, x2)  [-2, 2]2. Three constraint regions (highlighted areas in Figure 3b) are imposed on (·) so that the input space has three regions with positive output and the rest of the input space results in zero output. We also elevate or lower the response surface for different regions by three constants to generate greater model variability amongst the regions (see Figure 3a). The resulting computer model is:

(16)

 

-0.5

+

(x1

,

x2)

when 10(x1 - 1)2 + (x2 - 1)2/0.3 < 0.8 (the red region),

m(x1,

x2)

=

 


0.2 1.8

+ +

(x1, (x1,

x2) x2)

when (x1 + x2 + 3)2/1.6 + (x1 - x2)2 < 0.8 (the blue region), when x21/0.9 + x22 < 0.6 (the yellow region),

 

0

otherwise.

A randomly generated 121-run orthogonal array based Latin hypercube design (Tang,
1993) (black dots in Figure 3b) is chosen for simulation inputs, and a 71 × 71 grid is placed on the input domain [-2, 2]2 to construct a validation set to assess the performance of different emulation approaches. For lcGP, the local design sizes are n = nM = 12.

13

(a) True function output with constraints

(b) Input space and design

Fig 3: A 2D example with unknown constraints

(a) Inactive neighborhood

(b) Active neighborhood

(c) Mixed neighborhood

Fig 4: Local designs for different inputs. The red stars represent the points to emulate, blue diamonds are local designs used for classification and red dots are local designs used for response surface model.

Figure 4 shows the local designs constructed for different inputs. To get an idea of how
the local designs are selected in practice, there are three scenarios considered for emulation at an input x:
(i) when x (red star) is surrounded entirely by design points (blue diamonds) that result in a zero output (Figure 4a), the classifier will predict y^(x) = 0 and m^ (x) = 0 with
probability one; (ii) when all neighboring design points of x are active (Figure 4b), q^(x) = 1 and z(x) is
emulated with an expanded active design (red dots). (iii) when x is in a mixed neighborhood (Figure 4c), the classification of y(x) with the
local design (blue diamonds) is followed by the emulation of z(x) with the expanded
active design (red dots). 
Similar to the previous example, a uniform prior distribution, U (0, 10), is chosen for
the length-scale parameter, , of the local GP classifier, and a U (0, 4) is used for the prior distribution on -1. Elliptical slice sampling is used for the latent log-odds, and single site
Metropolis-Hastings is used to sample the GP parameters. We found 3000 MCMC iterations,
with 1000 steps serving as burn-in, to be successful for this example. The average time to emulate each m(x) is roughly 1.2 seconds on an Intel Core i7 processor and 16GB of memory.

14

(a) Traditional GP

(b) laGP

(c) Global GP&GPC

(d) lcGP

(e) Traditional GP

(f) laGP

(g) Global GP&GPC

(h) lcGP

Fig 5: Heatmap of absolute prediction error (first row) and predictive standard deviation (second row) for different models trained with data collected from a 121-run orthogonal array based Latin hypercube design. Brighter colors indicate larger errors and greater predictive standard deviations. Figures 5a and 5e are produced with the traditional GP model; Figures 5b and 5f are produced with local approximate GP (laGP) method; Figures 5d and 5h are produced with the proposed lcGP method; Figures 5c and 5g adopt a model that combines a global GP classifier with a global GP model. Each row shares the same color bar as given in the plots of the first (left) column.

Implementation details and MCMC diagnostics can be found in the supplemental materials (Lin et al., 2021).
In this example, the binary classification implementation of lcGP is used. The prediction for y^(x) is chosen to be the MAP estimate based on posterior samples of y^(x). Absolute prediction errors and predictive standard deviations are compared in Figure 5 among different methods: the traditional GP (first column), laGP (second column), the combination of a global GP classifier and a global GP (third column) and lcGP (last column). In the heatmaps brighter/hotter color corresponds to larger absolute prediction error and larger predictive standard deviation. In the presence of unknown constraints, ignoring the constraints as in the traditional GP method (Figure 5a and 5e) results in a considerable level of error and predictive uncertainty even at input locations that are far from the constraint boundaries. This phenomenon is likely caused by the fact that GP models attempt to explain the local sudden changes between zero and positive output with a small length-scale parameter and large GP variance. The laGP model (Figures 5b and 5f) can help reduce the errors at locations that are far enough from the constraint boundaries, but it faces the same challenge as the traditional GP method for input locations that have both zeros and positive outputs in their local designs. For the proposed methods that combine a classifier and an emulator (Figures 5d,5c, 5h and 5g), it is evident that the local model (Figures 5d and 5h ) outperforms the global one (Figures 5c and 5g) by providing higher prediction accuracy and lower predictive uncertainty.
To further compare the methods, performance metrics including the Nash­Sutcliffe efficiency (NSE), the root-mean-square error (RMSE) and the maximum absolute error (MAE) are computed and displayed in Table 2. Similar to the coefficient of determination, the NSE (Nash and Sutcliffe, 1970) attempts to measure the proportion of variation that can be explained by a predictive model. Here, NSEs for correctly classified active points and all data (correctly classified or not) are reported separately (columns 'NSE (active)' and 'NSE (all)')

15

Method traditional GP laGP Global GP&GPC lcGP

TABLE 2 Prediction accuracy for different methods

Misclassification NSE

NSE

active na na
10.91% 8.77%

inactive na na
3.65% 1.86%

active 91.45% 93.80% 97.28% 98.35%

all 78.92% 81.38% 68.42% 81.44%

RMSE
active 0.4601 0.3915 0.1486 0.1167

MAE
active 2.0316 1.8211 0.8222 0.8170

Fig 6: Sequential design construction, every 20 iterations. Black dots represent the initial design, blue x's are previously added simulations and red numbers represent the order in which new simulations are added.
to examine the performance of z^(x) and m^ (x) separately. For RMSE and MAE, results are reported on z^(x).
It can be seen that the lcGP model outperforms the other three models across most predictive accuracy measurements. In this simple example with a small data set, the global model (classifier and emulator) does perform comparably well. However in problems with large data, the global model is often unattainable due to the computational burden discussed earlier.
Sequential Design. Finally, the two-dimensional example is used to demonstrate how additional trials may be added to improve the model based on the improvement function introduced in Section 3.4. A 64-run orthogonal array based Latin hypercube design (first panel in Figure 6) is used to conduct an initial set of simulations. An lcGP model is then constructed based on this initial design and corresponding outputs. To sequentially add new simulation runs, the following steps are taken at iteration k, k = 1, 2, . . . , 57:
(i) divide the input space [-2, 2]2 into a 20 × 20 grid and draw one random sample within each grid cell to form a candidate set of size 400, (x~1, x~2, . . . , x~400), for new simulations.
(ii) calculate E(I(x~i)) for each candidate point and find the best candidate x~k to perform the next simulation; obtain m~ k = m(x~k).
(iii) update the lcGP model with the newly simulated data point (x~k, m~ k) added.
To compare the sequential design with the 121-run design in Figure 4, the search for new design points continues until a total run size of 121 is obtained. Figure 6 shows the updated design for every 20 iterations, with the final design plotted in the fourth panel. New points are labeled (in red) according to the order in which they are added. Previously added points are labeled by blue x's. The sequential criterion mostly chooses points near the boundary of the constraint regions, while also jumping to sparsely sampled regions (e.g., points 15 and 33), and points within the constraint region (e.g., points 1 and 32) in an explore-and-exploit manner.
Next, we emulate, with lcGP, the computer model on the same 71 × 71 grid, with simulation data from the sequential design. The prediction accuracy is compared in Table 3 to that

16
of the orthogonal array based Latin hypercube design with the same simulation size (Figure 4 and Table 2). By running more simulations on active regions, the sequential design is able to further reduce the RMSE for active points while maintaining similar classification accuracy.

TABLE 3 Prediction accuracy for different designs

Misclassification NSE NSE

Method

active inactive active

all

Latin hypercube design

8.77% 1.86% 98.35% 81.44%

Sequential design E(I(x)) 9.05% 1.99% 99.71% 76.10%

RMSE
active 0.1167 0.0488

MAE
active 0.8170 0.4093

5. Results for the COMPAS model. We now return to the COMPAS model and apply the proposed emulation method to computer model runs produced using the STROOPWAFEL procedure2 (Broekgaarden et al., 2019). In total, one million simulations of BBH formation were performed. For these runs, the hyper-parameters t of the COMPAS model were kept constant (Z = 0.001,  = 1,  = 265km/s, flbv = 1.5) and initial conditions x were drawn using adaptive importance sampling. These modifications made it possible to increase the BBH yield to approximately 27%, as samples are placed more densely in constraintsatisfying regions. In this example, the input dimension was reduced to 11 (the dimensionality of initial conditions x) since t is fixed. For illustration of the emulation method proposed in Section 5.1, we do not consider the distribution of x until later (Section 5.2) when we propagate the input distributions through the emulator in order to obtain the chirp mass distribution.
Figure 7 and Figure 8 provide a visualization of the simulation data standardized to the unit hypercube [0, 1]11. Histograms of selected standardized input variables from all simulations (Figure 7a) and scatter plots of the BBH chirp mass against individual input variables (Figure 7b) for successful simulations are shown. Heatmaps of the chirp mass against pairs of input parameters are shown in Figure 8. The histograms show that x is non-uniform across the input space. The resulting space filling might be unsatisfactory and could bring considerable uncertainty into emulation. For the scatter plots, we observe some trends between the chirp mass and the initial component masses m1, m2, and separation, while the kick variables seem to have little impact on the value of the chirp mass. However, the kick parameters can impact the outcome of the model, i.e., whether a merging BBH is formed. Next, we illustrate in detail how emulation of the COMPAS data is performed and evaluated.
5.1. Emulation. For computer models like COMPAS, where the input variables differ largely in scale and physical meaning (Table 1), a stretching and compressing procedure (Hsu, 2019) is added to step i of the procedure described in Section 3.3. This procedure aims to modify the definition of distance in the input space, based on the correlation between simulation outputs, so that the concept of `neighborhood' in lcGP can incorporate informative local points. More specifically for this example, 1000 active simulations are randomly selected and modeled using an anisotropic GP with squared-exponential covariance. This procedure is repeated 100 times, and the average estimated length-scale, , is used to scale x by setting x = x/. The construction of local designs in the lcGP method (as in Algorithms 1 and 2) is based on x , while the emulator model itself takes the standardized input x. For
2Available online at https://zenodo.org/record/3627403. The simulation data used here is a combination of the exploration and refinement phase for BH-BH mergers.

17

(a) Histogram of selected COMPAS design inputs from the STROOPWAFEL simulations after standardization.

(b) Scatter plots of the chirp mass versus each input. Opaque regions correspond to high concentration of active simulations in the data, while transparent regions correspond to few active simulations.

Fig 7: Visualization of COMPAS simulation data

Fig 8: Heatmaps of the chirp mass against pairs of inputs.

model input x = (m1, m2, log(a), v1, v2, 1, 2, 1, 2, 1, 2), the value for  is chosen as (0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 1, 1, 1). This choice of value for  implies that for chirp mass the spatial correlations with respect to the initial masses and separation are larger than those of other input dimensions.
Since the chirp mass of a BBH is always positive, we introduce a left truncation to step iii in Section 3.3 for z^(x) as

(17)

p(z^(x)|z^(x)

>

0,

zab)

=

p(z^(x)|zab) P (z^(x) > 0|zab) ,

where p(z^(x)|zab) is as in Equation (10). We choose to apply the truncation after building z^(·) for speedy emulation. Similar to the examples in Section 4, the MAP estimate is used for y^(x) and z^(x).
To evaluate the performance of the method proposed, we performed 100 independent cross validations with a holdout size of 1000 drawn by simple random sampling. The local design size n and nM are chosen to be 50. To achieve fast emulation, we also estimate beforehand
and fix the GP length-scale parameters for both the classification and the response surface model here.This procedure requires in total 100,000 individual emulations which required 3.25 hours when parallelized on 10 nodes of Intel E5-2683 v4 "Broadwell" at 2.1Ghz with

18 8GB memory. Thus, one emulation required an average of only  0.1s in this regime. It is worth-noting that larger choice of n has also been investigated. With n is raised to 100, the computation time triples on the same machine while the misclassification is similar. Therefore n = 50 is considered appropriate for this demonstration.
For the 100,000 input conditions in this cross validation, 41,104 led to successful simulations (58,896 NAs), out of which 24,419 are correctly classified by the proposed emulator. Compared to the two-dimensional example in Section 4.2, this is a larger misclassification rate. We attribute this performance of the classifier to (1) the higher dimensional input space of the COMPAS model; (2) the complexity of population synthesis codes with very low success rate, and (3) input design constructed from simulating x instead of any space-filling. Emulation results show that for active points that are correctly classified by y^(x), the NashSutcliffe efficiency of all cross validations are above 99%, meaning that the emulator can explain more than 99% of the variability in chirp mass among successful simulations that are also classified as successful by the emulator. The emulation errors (for z(x) - z^(x)) together with relative percentage errors (lower) are plotted in Figure 9 against the true chirp mass. Out of the aforementioned 24,419 successful classifications, only 107 cases show absolute error above 2M . A closer investigation into cases with large absolute errors revealed that the errors were caused by the sparsity of the local design Xab. This issue can be addressed by applying the sequential design procedure in planning future simulations.
Fig 9: Emulation error (upper) and relative (percentage) emulation error (lower) against the true chirp mass from cross validation. This plot combines the results of 100 out-of-sample tests with a holdout size of 1000. Only successful simulations that are classified correctly are included, to assess the performance of z^(·). Points are colored by the magnitude of the error.

19
Fig 10: Confidence intervals (grey lines) and mean (grey dots) of percentiles for the chirp mass distribution, emulated with the lcGP method. Red crosses depict the corresponding percentile from an independent set of simulations (Broekgaarden et al., 2019).
5.2. Estimating the chirp mass distribution through emulation. We have so far treated the model output m(x) as a scalar ­ the chirp mass of merging binary black holes. In reality, however, two further complications arise in this context: (i) the initial conditions x of a BBH cannot be observed, and are only known up to a distri-
bution; (ii) we may be interested in emulating other properties of the merging binaries that are pre-
dicted by COMPAS population synthesis models, such as the mass ratios mf,2/mf,1 or the delay time between star formation and merger. We therefore consider reconstructing the distribution of m(x) given the distribution of x, rather than emulating m(x) for a given input x. That is, we aim to propagate the uncertainty in x through the emulator m^ (x). We assume that x follows an initial conditions distribution (x), and evaluate the resulting distribution of m^ (x) by convolving this with the emulator. By drawing random samples from (x), and building independent lcGP models in parallel for each x in the sample, the distribution of m(x) can be emulated. Furthermore, as a proxy for a bivariate output, we expand the model output to a twodimensional vector (mf,1, mf,2), representing the vector of final masses of the two black holes at the end of a simulation. By adopting a separable covariance structure (Conti and O'Hagan, 2010), lcGP can easily be extended to computer models with multivariate output. This, in particular, allows us to model the detectability of a gravitational-wave signal by the Laser Interferometer Gravitational-wave Observatory (LIGO), which depends on both component masses (e.g., Fishbach and Holz, 2017; Barrett et al., 2018). Using the same simulation data in Section 5.1 as input, the distribution of chirp masses for the given set of population parameters t is emulated with the above techniques. In Figures 10 and 11, the emulated distribution is compared against the chirp mass distribution from an independent set of simulations conducted by sampling x  (x) in Broekgaarden et al. (2019)3. The percentiles (red crosses) in Figure 10 and the kernel density estimate shown with the red line in Figure 11 is produced with the 5163 successful BBH mergers (out of 1,000,000 simulations) obtained from the later data set. A full Bayesian approach is taken for m^ (x), so that the emulated distributions take into account uncertainties from both GP
3This is the COMPAS data produced with the traditional sampling method in Broekgaarden et al. (2019), labeled as 'Traditional'. It contains 1, 000, 000 COMPAS simulations with 5163 successful BBHs.

20
(a) Kernel density estimate of the chirp mass distribution without accounting for LIGO sensitivity
(b) Kernel density estimate of the chirp mass distribution of mergers observable by LIGO Fig 11: Confidence band of kernel density estimate of the chirp mass obtained through emulation (grey shades), compared to the kernel density estimate of a second set of COMPAS data (solid red curve) that is independent of the modeling data. The bandwidth of the kernel is set to 0.5 M .
parameters (such as , , µ,  and  discussed in Section 3) and the emulators (y^(x) and z^(x) given the GP parameters). The same set of uniform prior distributions as in Section 4 are chosen for the GP classifier. For length-scale parameters, U (0, 10) is used, and U (0, 4) is used for the inverse of precision parameters. The correlation between mf,1 and mf,2 is chosen to have a U [-1, 1] prior distribution. The emulation procedure starts with drawing a sample of size 25,000 from (x), denoted by Xr, to represent the distribution of x. Next, for each xj  Xr, j = 1, 2, . . . , 25000, we draw a single sample of the emulation output m^ (xj). As a result, a sample for m^ (Xr) of size 25,000 is obtained.
In practice, only positive/successful outputs (BBH formations) can be detected through gravitational waves. Therefore only positive values of the above samples are kept to produce the percentiles and a kernel density estimate to emulate the distribution of m(x). By independently repeating the emulation and kernel density estimation steps, confidence intervals (95% confidence level) of percentiles for the emulated chirp mass distribution are obtained (Figure 10), and compared against corresponding percentiles from the independent simulation (red crosses). It can be seen that, with the percentiles considered, the emulated confidence intervals always contain the corresponding percentile from the independent simulation. Confidence bands of the kernel density of m^ (x) are generated and shown in Figure 11. The grey areas in Figure 11a indicate the 68% (dark) and 95% (light) confidence bands for the emulated kernel density. The `observable' distribution of the chirp mass shown in Figure 11b takes LIGO sensitivity into account (we approximate the LIGO sensitivity to be proportional to max(mf,1, mf,2)2.2 in this example). In both plots, the 95% confidence band

21
of the emulated kernel density encloses that of the independent set of COMPAS data (solid red curve).
6. Discussion. In this paper, a new approach for fast emulation of computer models with unknown constraints was proposed. When emulating the COMPAS model of BBH mergers, the proposed method enables efficient emulation through parallel computation while providing uncertainty quantification. The new sequential design criterion guides the selection of future runs to improve the exploration of the input space. By propagating the randomness of initial conditions of binary systems, the probability distribution of the BBH chirp mass was obtained. In future work, we aim to
(i) incorporate the sequential design criterion into COMPAS to improve the planning of simulations, and
(ii) compare the emulated distribution of the chirp mass at various parameter settings (e.g., Z, ,  and flbv in Table 1) to observations from LIGO/Virgo, and infer the true value of these physical parameters (i.e., computer model calibration).
It is worth noting that the computational resources needed by the proposed emulator are largely driven by the size of the local designs in Algorithms 1 and 2. The trade-off between computational efficiency and prediction accuracy should be carefully examined to choose n and nM . In general, the local emulator is more accurate when a larger local design is adopted, i.e., more information is available for emulating m(x). Of course, in the presence of unknown constraints, making nM arbitrarily large for example, may result in the inclusion of many points from a different constraint region, thereby decreasing the quality of the inference. We suggest performing a preliminary analysis to find a suitable local design size for the desired accuracy and computational efficiency.
APPENDIX A: MCMC PROCEDURE TO SAMPLE GP PARAMETERS
Algorithm 3 describes in detail the MCMC procedure that is applied to collect posterior samples for the GP classifier introduced in Equation (5).
Acknowledgments. We thank Jim Barrett and Simon Stevenson for contributions to early testing data and discussions. Simulations in this paper made use of the COMPAS rapid binary population synthesis code, which is freely available at http://github.com/ TeamCOMPAS/COMPAS. The authors would like to thank the Isaac Newton Institute for Mathematical Sciences, for support and hospitality during the program "Uncertainty quantification for complex systems: theory and methodologies" and also the Statistical and Applied Mathematical Sciences Institute's program on Statistical, Mathematical and Computational Methods for Astronomy where work on this paper was initially undertaken.
Funding. IM is a recipient of the Australian Research Council Future Fellowship FT190100574. IM acknowledges support from the Australian Research Council Centre of Excellence for Gravitational Wave Discovery (OzGrav), through project number CE17010000. This work was also supported by EPSRC grant no. EP/R014604/1 and a Natural Sciences and Engineering Research Council of Canada Discovery Grant.
SUPPLEMENTARY MATERIAL
Python scripts and Jupyter notebooks for numerical examples This set of complementary materials includes Python scripts and Jupyter notebooks that allow readers to reproduce the emulation results shown in Section 4. The two Jupyter notebooks illustrate the emulations performed with different methods in Sections 4.1 and 4.2, respectively, with all helper functions, data and results included and directly importable.

22

Algorithm 3: MCMC procedure for GP classifier

Input: input design X, class label y, number of MCMC steps nMCMC, initial value for  and  denoted by (0) and (0).

Output: posterior sample of f ,  and 

1 i  0;

2 f (0)  0;

3 l(0)  log-likelihood of (f (0), (0), (0));

4 while i < nMCMC do 5 i = i + 1;

6 for j = 1  d do

7

Update (ji) with a Metropolis-Hastings step;

8

Update j(i) with a Metropolis-Hastings step;

9

Update log-likelihood l(i) and covariance matrix (i) with (f (i-1), (i), (i));

10

Sample   N (0, (i)) and u  Uniform(0, 1);

11

Set the acceptance threshold  = l(i) + log(u);

12 Sample a random angle   Uniform(0, 2);

13 14

Set min =  - while proposal

2 f

and max = ; is not accepted

do

15

Propose f  = f (i-1) cos() +  sin();

16

l  log-likelihood with (f , (i), (i));

17

if l >  then

18

Accept f  as f (i);

19

else

20

if  > 0 then

21

Set max = ;

22

else

23

Set min = ;

24

end

25

Draw   Uniform(min, max);

26

end

27

end

28 end

29 ;

References.
ANDREWS, J. J., ZEZAS, A. and FRAGOS, T. (2018). dart_board: Binary Population Synthesis with Markov Chain Monte Carlo. ApJS 237 1.
BARRETT, J. W., MANDEL, I., NEIJSSEL, C. J., STEVENSON, S. and VIGNA-GÓMEZ, A. (2017). Exploring the Parameter Space of Compact Binary Population Synthesis. In Astroinformatics (M. BRESCIA, S. G. DJORGOVSKI, E. D. FEIGELSON, G. LONGO and S. CAVUOTI, eds.). IAU Symposium 325 46-50.
BARRETT, J. W., GAEBEL, S. M., NEIJSSEL, C. J., VIGNA-GÓMEZ, A., STEVENSON, S., BERRY, C. P. L., FARR, W. M. and MANDEL, I. (2018). Accuracy of inference on the physics of binary evolution from gravitational-wave observations. MNRAS 477 46854695.
BELCZYNSKI, K., KALOGERA, V. and BULIK, T. (2002). A Comprehensive Study of Binary Compact Objects as Gravitational Wave Sources: Evolutionary Channels, Rates, and Physical Properties. ApJ 572 407-431.

23
BINGHAM, D., RANJAN, P. and WELCH, W. J. (2014). Design of computer experiments for optimization, estimation of function contours, and related objectives. Statistics in Action: A Canadian Outlook 109.
BROEKGAARDEN, F. S., JUSTHAM, S., DE MINK, S. E., GAIR, J., MANDEL, I., STEVENSON, S., BARRETT, J. W., VIGNA-GÓMEZ, A. and NEIJSSEL, C. J. (2019). STROOPWAFEL: simulating rare outcomes from astrophysical populations, with application to gravitational-wave sources. MNRAS 490 5228-5248.
CONTI, S. and O'HAGAN, A. (2010). Bayesian emulation of complex multi-output and dynamic computer models. Journal of statistical planning and inference 140 640­651.
COVER, T. and HART, P. (1967). Nearest neighbor pattern classification. IEEE transactions on information theory 13 21­27.
CRESSIE, N. and JOHANNESSON, G. (2008). Fixed rank kriging for very large spatial data sets. Journal of the Royal Statistical Society: Series B (Statistical Methodology) 70 209­ 226.
DUNLOP, M. M., GIROLAMI, M. A., STUART, A. M. and TECKENTRUP, A. L. (2018). How deep are deep Gaussian processes? The Journal of Machine Learning Research 19 2100­2145.
FISHBACH, M. and HOLZ, D. E. (2017). Where are LIGO's big black holes? The Astrophysical Journal Letters 851 L25.
GELBART, M. A., SNOEK, J. and ADAMS, R. P. (2014). Bayesian optimization with unknown constraints. arXiv preprint arXiv:1403.5607.
GRAMACY, R. B. and APLEY, D. W. (2015). Local Gaussian process approximation for large computer experiments. Journal of Computational and Graphical Statistics 24 561­ 578.
GRAMACY, R. B. and LEE, H. K. H. (2008). Bayesian treed Gaussian process models with an application to computer modeling. Journal of the American Statistical Association 103 1119­1130.
GRAMACY, R. B. and LEE, H. K. H. (2010). Optimization Under Unknown Constraints. HASTINGS, W. K. (1970). Monte Carlo sampling methods using Markov chains and their
applications. HIGDON, D., GATTIKER, J., WILLIAMS, B. and RIGHTLEY, M. (2008). Computer model
calibration using high-dimensional output. Journal of the American Statistical Association 103 570­583. HSU, G. (2019). Fast emulation and calibration of large computer experiments with multivariate output. Unpublished M.Sc. Thesis, Department of Statistics and Actuarial Science, Simon Fraser University. JONES, D. R., SCHONLAU, M. and WELCH, W. J. (1998). Efficient global optimization of expensive black-box functions. Journal of Global optimization 13 455­492. KAUFMAN, C. G., BINGHAM, D., HABIB, S., HEITMANN, K., FRIEMAN, J. A. et al. (2011). Efficient emulators of computer experiments using compactly supported correlation functions, with an application to cosmology. The Annals of Applied Statistics 5 2470­2492. KRUCKOW, M. U., TAURIS, T. M., LANGER, N., KRAMER, M. and IZZARD, R. G. (2018). Progenitors of gravitational wave mergers: binary evolution with the stellar grid-based code COMBINE. MNRAS 481 1908-1949. LAWRENCE, E., HEITMANN, K., KWAN, J., UPADHYE, A., BINGHAM, D., HABIB, S., HIGDON, D., POPE, A., FINKEL, H. and FRONTIERE, N. (2017). The Mira-Titan universe. II. Matter power spectrum emulation. The Astrophysical Journal 847 50. LIN, L., BINGHAM, D., BROEKGAARDEN, F. and MANDEL, I. (2021). Supplement to "Uncertainty quantification of a computer model for binary black hole formation".

24
MANDEL, I. and FARMER, A. (2017). Gravitational waves: Stellar palaeontology. Nature 547 284-285.
MANDEL, I. and FARMER, A. (2018). Merging stellar-mass binary black holes. ArXiv eprints.
MURRAY, I., PRESCOTT ADAMS, R. and MACKAY, D. J. (2010). Elliptical slice sampling. NASH, J. E. and SUTCLIFFE, J. V. (1970). River flow forecasting through conceptual models
part I -- A discussion of principles. Journal of Hydrology 10 282 - 290. NEIJSSEL, C. J., VIGNA-GÓMEZ, A., STEVENSON, S., BARRETT, J. W., GAEBEL, S. M.,
BROEKGAARDEN, F. S., DE MINK, S. E., SZÉCSI, D., VINCIGUERRA, S. and MANDEL, I. (2019). The effect of the metallicity-specific star formation history on double compact object mergers. MNRAS 490 3740-3759. PETERS, P. C. and MATHEWS, J. (1963). Gravitational Radiation from Point Masses in a Keplerian Orbit. Physical Review 131 435-440. QUIÑONERO-CANDELA, J. and RASMUSSEN, C. E. (2005). A unifying view of sparse approximate Gaussian process regression. Journal of Machine Learning Research 6 1939­ 1959. SACKS, J., WELCH, W. J., MITCHELL, T. J. and WYNN, H. P. (1989). Design and analysis of computer experiments. Statistical science 409­423. STEVENSON, S., VIGNA-GÓMEZ, A., MANDEL, I., BARRETT, J. W., NEIJSSEL, C. J., PERKINS, D. and DE MINK, S. E. (2017). Formation of the first three gravitationalwave observations through isolated binary evolution. Nature Communications 8. TANG, B. (1993). Orthogonal array-based Latin hypercubes. Journal of the American statistical association 88 1392­1397. TAYLOR, S. R. and GEROSA, D. (2018). Mining gravitational-wave catalogs to understand binary stellar evolution: A new hierarchical Bayesian framework. Phys. Rev. D 98 083017. VIGNA-GÓMEZ, A., NEIJSSEL, C. J., STEVENSON, S., BARRETT, J. W., BELCZYNSKI, K., JUSTHAM, S., DE MINK, S. E., MÜLLER, B., PODSIADLOWSKI, P., RENZO, M., SZÉCSI, D. and MANDEL, I. (2018). On the formation history of Galactic double neutron stars. MNRAS 481 4009-4029. WILLIAMS, C. K. and RASMUSSEN, C. E. (2006). Gaussian processes for machine learning 2. MIT press Cambridge, MA.

