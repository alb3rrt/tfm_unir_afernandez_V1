Efficient Explanations With Relevant Sets

arXiv:2106.00546v1 [cs.LG] 1 Jun 2021

Yacine Izza Université de Toulouse, Toulouse, France
yacine.izza@univ-toulouse.fr

Alexey Ignatiev Monash University, Melbourne, Australia
alexey.ignatiev@monash.edu

Nina Narodytska VMware Research, CA, USA nnarodytska@vmware.com

Martin C. Cooper Université Paul Sabatier, IRIT, Toulouse, France
martin.cooper@irit.fr

Joao Marques-Silva IRIT, CNRS, Toulouse, France joao.marques-silva@irit.fr

Abstract
Recent work proposed -relevant inputs (or sets) as a probabilistic explanation for the predictions made by a classifier on a given input. -relevant sets are significant because they serve to relate (model-agnostic) Anchors with (model-accurate) PI-explanations, among other explanation approaches. Unfortunately, the computation of smallest size -relevant sets is complete for NPPP, rendering their computation largely infeasible in practice. This paper investigates solutions for tackling the practical limitations of -relevant sets. First, the paper alternatively considers the computation of subset-minimal sets. Second, the paper studies concrete families of classifiers, including decision trees among others. For these cases, the paper shows that the computation of subset-minimal -relevant sets is in NP, and can be solved with a polynomial number of calls to an NP oracle. The experimental evaluation compares the proposed approach with heuristic explainers for the concrete case of the classifiers studied in the paper, and confirms the advantage of the proposed solution over the state of the art.

1 Introduction
Recent work proposed -relevant inputs (or sets) [42], which represent probabilistic explanations for the predictions made by a classifier given some input. -relevant sets were shown to generalize both Anchors [33] and PI-explanations [36], thus revealing a connection between model-agnostic explanations (e.g. Anchors) and model-accurate explanations (e.g. PI-explanations). Moreover, relevant sets offer a natural solution for increasing the interpretability of PI-explanations, at the cost of obtaining intuitive explanations that hold in most, but not all, points in feature space. A formidable downside of -relevant sets is that their computation is hard for NPPP. This signifies that for most practical examples, the time for computing minimum -relevant sets will be prohibitive in practice. To address the computational complexity of finding minimum -relevant sets, a number of solutions can be envisioned. A first solution is the approximate computation of -relevant sets. However, for this solution, the formal guarantees offered by -relevant sets may no longer hold. A second solution is to identify which ML models allow for the efficient computation of -relevant sets. Finally, a third solution is to investigate possible ways of relaxing the original definition of -relevant sets [42].
This paper addresses the second and third solutions listed above. First, the paper proposes alternative definitions of -relevant sets. Second, the paper analyzes the computation of (different variants of) -relevant sets in the case of decision trees (DTs).
Preprint. Under review.

Although generally regarded as interpretable [7, 34, 25], recent work showed that DTs can exhibit explanation redundancy [3, 17], i.e. there exist DTs containing paths that are (possibly arbitrarily) longer than a PI-explanation [36]. Furthermore, existing experimental evidence confirms that explanation redundancy is observed in DTs learned with state of the art DT learners [17]. Thus, even in the case of DTs, the computation of -relevant sets is of interest when the goal is to improve the interpretability of ML models.
The main results of the paper can thus be summarized as follows. First, the paper shows that, for the decision version of computing a minimum size -relevant set (i.e. the problem studied in recent work [42]), is in NP in the case of DTs. The proof of this result offers a solution for computing a minimum-size -relevant set, in the case of DTs, by using maximum satisfiability modulo theories (MaxSMT) [4, 6]. Second, the paper shows that, in the case of DTs, a relaxed definition of -relevant set enables the computation of (relaxed) subset-minimal -relevant sets in polynomial time. Third, the paper shows that ML models based on knowledge compilation (KC) languages [11], including those studied in recent papers on XAI for KC languages [36, 37, 10, 2, 1], the computation of (relaxed) subset-minimal -relevant sets is also in polynomial time. Fourth, the paper shows that recently proposed duality results for explanations [15, 13], which in practice enable the enumeration of explanations, can be extended to the setting of -relevant sets.
Related work. The growing adoption of ML in different settings motivates the recent interest in explainability [27, 12, 35, 20, 43, 26]. Well-known approaches for explaining ML-models are model-agnostic and based on heuristic solutions [32, 21, 33]. These approaches offer no formal guarantees of rigor, and practical limitations have been reported in recent years [8, 28, 38, 19]. More recently, model-accurate non-heuristic approaches to explainability have been investigated [36, 15, 10, 13, 2, 1, 22]. These non-heuristic approaches are characterized by formal guarantees of rigor, e.g. explanations are valid in any point in feature space. Unfortunately, non-heuristic methods also exhibit a number of drawbacks, including for example scalability, explanation size, and the inability to compute explanations with probabilistic guarantees. Recent work [42] revealed ways of relating heuristic and non-heuristic explanations. Our paper builds on this recent work.
Organization. The paper is organized as follows. Section 2 introduces the notation and definitions used in the rest of the paper. Section 3 discusses -relevant sets and a number of alternative definitions. Section 4 delves into duality between different kinds of explanations when -relevant sets are considered. Section 5 discusses the computation of cardinality-minimal and subset-minimal -relevant sets in the case of decision trees. Section 6 presents experimental results for computing -relevant sets in the case of DTs. Finally, Section 7 concludes the paper.

2 Preliminaries

Classification problems & formal explanations. This paper considers classification problems, which are defined on a set of features (or attributes) F = {1, . . . , m} and a set of classes K = {c1, c2, . . . , cK }. Each feature i  F takes values from a domain Di. In general, domains can be boolean, integer or real-valued. Feature space is defined as F = D1 × D2 × . . . × Dm = {0, 1}m. For boolean domains, Di = {0, 1} = B, i = 1, . . . , m, and F = Bm. The notation x = (x1, . . . , xm) denotes an arbitrary point in feature space, where each xi is a variable taking values from Di. The set of variables associated with features is X = {x1, . . . , xm}. Moreover, the notation v = (v1, . . . , vm) represents a specific point in feature space, where each vi is a constant representing one concrete value from Di = {0, 1}. An instance (or example) denotes a pair (v, c), where v  F and c  K. (We also use the term instance to refer to v, leaving c implicit.) An ML classifier M is characterized by a classification function  that maps feature space F into the set of classes K, i.e.  : F  K.
We now define formal explanations. Prime implicant (PI) explanations [36] denote a minimal set of literals (relating a feature value xi and a constant vi  Di that are sufficient for the prediction1. Formally, given v = (v1, . . . , vm)  F with (v) = c, a PI-explanation (AXp) is any minimal subset X  F such that,

(x  F). iX (xi = vi) ((x) = c)

(1)

1PI-explanations are related with abduction, and so are also referred to as abductive explanations (AXp) [14]. More recently, PI-explanations have been studied from a knowledge compilation perspective [2, 1], but also in terms of their computational complexity [3].

2

AXps can be viewed as answering a `Why?' question, i.e. why is some prediction made given some point in feature space. A different view of explanations is a contrastive explanation [24], which answers a `Why Not?' question, i.e. which features can be changed to change the prediction. A formal definition of contrastive explanation is proposed in recent work [13]. Given v = (v1, . . . , vm)  F with (v) = c, a CXp is any minimal subset Y  F such that,

(x  F). jF\Y (xj = vj)  ((x) = c)

(2)

Building on the results of R. Reiter in model-based diagnosis [31], [13] proves a minimal hitting
set (MHS, or hypergraph transversal [5]) duality relation between AXps and CXps, i.e. AXps are MHSes of CXps and vice-versa. Throughout the paper, (M)HS(Z) denote the set of (minimal) hitting sets of Z.

Relevant sets. -relevant sets were recently proposed [42] as a formalization of explanation that enables relating different types of explanation [42]. We briefly overview the definition of relevant
set and associated definitions. The assumptions regarding the probabilities of logical propositions are those made in earlier work [42]. Let Prx(A(x)) denote the probability of some proposition A defined on the vector of variables x = (x1, . . . , xm), i.e.

Prx(A(x))

=

|{xF:A(x)=1}| |{xF}|

,

Prx(A(x) | B(x))

=

|{xF:A(x)=1B(x)=1}| |{xF:B(x)=1)}|

(3)

Definition 1 (-relevant set [42]). Let  : Bm  K = B, v  Bm, (v) = c  B, and   [0, 1]. S  F is a -relevant set for  and v if,

Prx((x) = c | xS = vS )  

(4)

(where the restriction of x to the variables with indices in S is represented by xS = (xi)iS ).

(Observe that Prx((x) = c | xS = vS) is often referred to as the precision of S [33, 28].) Thus, a -relevant set represents a set of features which, if fixed to some pre-defined value (taken from a reference vector v) ensure that the probability of the prediction being the same as the one for v is no less than .
Definition 2 (Min--relevant set). Given , v  Bm, and   [0, 1], find the smallest k, such that there exists S  F , with |S|  k, and S is a -relevant set for  and v.

With the goal of proving the computational complexity of finding a minimum-size set of features that is a -relevant set, earlier work [42] restricted the definition to the case where  is represented as a boolean circuit. (Boolean circuits were restricted to propositional formulas defined using the operators ,  and ¬, and using a set of variables representing the inputs; this explains the choice of inputs over sets in earlier work [42].) Observe that Definition 2 imposes no such restriction on the representation of the classifier, i.e. the logical representation of  need not be a boolean circuit.
Decision trees. A decision tree T is a directed acyclic graph having at most one path between every pair of nodes. T has a root node, characterized by having no incoming edges. All other nodes have one incoming edge. We consider univariate decision trees where each non-terminal node is associated with a single feature xi. Each edge is labeled with a literal, relating a feature (associated with the edge's starting node) with some values (or range of values) from the feature's domain. We will consider literals to be of the form xi  Ei. xi is a variable that denotes the value taken by feature i, whereas Ei  Di is a subset of the domain of feature i. The type of literals used to label the edges of a DT allows the representation of the DTs generated by a wide range of decision tree learners (e.g. [41]). It is assumed that for any v  F there exists exactly one path in T that is consistent with v. By consistent we mean that the literals associated with the path are satisfied (or
consistent) with the feature values in v.

Running example. Throughout the paper, we will consider the decision tree shown in Figure 1 as the running example2.
Example 1. We consider the example DT from Figure 1. For this example and for simplicity, all features are binary with Di = {0, 1}. It is also assumed that Pr(xi = 0) = Pr(xi = 1) = 1/2, which we represent respectively by  and , to allow other values to be considered. . Some of the paths
2Although the running example considers boolean features (with Di = {0, 1}) and boolean classification, similar conclusions would be obtained if we were to consider instead real-valued features, e.g. having Di = [0, 1].

3

x1
p(1) 1 ¬p(1)

0

x2

2 p(2)

3

¬p(2)

Domains

Feature

Range

i = 1, . . . , 9 Di = {0, 1}

x5
p(5) 4 ¬p(5)

x3

p(3)

5

¬p(3)

x6
¬p(6) 6 p(6)

1

x5

7 p(5) 8 ¬p(5)

x4
p(4) 9 ¬p(4)

x7

1

x6

1

x5

x9

p(7) 10 ¬p(7) 11 p(6) 12 ¬p(6) 13 ¬p(5) 14 p(5) p(9) 15 ¬p(9)

x8

1

x7

1

x6

10 1

p(8) 16 ¬p(8) 17 ¬p(7) 18 p(7) 19 p(6) 20 ¬p(6) 21

22

23

01

24

25

x8
p(8) 26 ¬p(8)

1

x7

1

27 p(7) 28 ¬p(7) 29

01

30

31

x8

1

33 p(8) 32 ¬p(8)

Predicates

Pred. Def.

Pr(·)

p(i) xi = 0 Pr(p(i)) = 1/2 =  ¬p(i) xi = 1 Pr(¬p(i)) = 1/2 = 

Paths in DT
Q1 = {1, 2} Q2 = {1, 3, 4, 6, 10, 16, 24} ··· Q5 = {1, 3, 5, 9, 15, 22} P1 = {1, 3, 4, 6, 10, 16, 25} ··· P13 = {1, 3, 5, 9, 15, 23}

01

34

35

Figure 1: DT used as running example
in the DT are also shown. Moreover, let the instance be v = (v1, v2, v3, v4, v5, v6, v7, v8, v9) = (1, 1, 1, 1, 0, 0, 0, 0, 1) with prediction c = 1. Since v is consistent with the path ending at node 23, by inspection, we can conclude that a possible explanation is X = {1, 2, 3, 4, 9}, i.e. the features listed in the path. It can be shown that this corresponds to a PI-explanation.
3 Complementary Definitions of Relevant Sets
Given the prohibitive complexity of solving the Min--Relevant-Set problem, this section proposes alternative definitions of minimal relevant sets, which are shown to yield efficient algorithms for some concrete ML models. First, we consider subset-minimal relevant sets instead of cardinalityminimal sets. However, we relax the restrictions that features are boolean and the classification problem is restricted to two classes.
Min-C-Relevant-Sets. Following earlier work on PI-explanations [36], we consider subsetminimal relevant sets.
Definition 3 (C-relevant set). Let  : F  K,   [0, 1], and instance (v  F, c  K). S  F is a C-relevant set for the classifier-instance pair,  and (v, c), if (4) holds.
(The difference of C to plain  relevant sets is that F and K become unrestricted.) As noted in earlier work, a (smallest) PI-explanation is a 1-relevant set for a given pair  and (v, c). Furthermore, the main difference with respect to Anchors [33] is the assumptions made with respect to sampling. As noted in earlier work [42], -relevant sets can be related with different efforts for computing explanations [33, 36, 18].
Definition 4 (Min-C-Relevant-Set). Let  : F  K,   [0, 1], and instance (v  F, c  K). A Min-C-Relevant-Set is a (subset-)minimal subset S  F that is C-relevant for  and (v, c).
(Observe that, in contrast with the definition of Min--Relevant-Set [42], where the objective is to compute a cardinality-minimal set, the objective of the definition of Min-C-Relevant-Set it to compute a subset-minimal set.) For the case where  is implemented as a boolean circuit (propositional formula defined on the operators ,  and ¬), Min--Relevant-Set is hard for NPPP, with the decision problem in NPPP [42]. Although the complexity of Min-C-Relevant-Set is unknown, we conjecture that it is similar to the one of Min--Relevant-Set. Moreover, we have the following result,
Proposition 1. Deciding whether a set S  F is a C-relevant set is PP-hard.

4

(The proof in included in the supplementary materials.) It should be underlined that the high complexity of exactly solving Min--Relevant-Set (and Min-C-Relevant-Set) in the general case represents a key practical limitation. One additional difficulty with computing a subset-minimal C-
relevant set is that its definition is non-monotone. (4) can be written as follows,

Prx((x)

=

c | xS

=

vS )

=

|{x

F: |{x

(x) = c  (xS = vS )}|  F : (xS = vS )}|

As the size of set S is reduced (e.g. as we search for a minimal set), both the numerator and the denominator can change. Hence, the value of Prx((x) = c | xS = vS ) is not guaranteed to shrink, and in some settings this value can grow.

Min-I-Relevant-Sets. We show later in the paper that, by considering the probability of the conjunction of two events instead of the conditional probability, the resulting monotone definition of relevant set enables more efficient computation of subset-minimal relevant sets. One has four possible outcomes when considering two events. In our case that means we can have: [(x) = (v), xS = vS ], [(x) = (v), xS = vS ], [(x) = (v), xS = vS ], and [(x) = (v), xS = vS ]. We are interest in picking sets S that minimize the odds of picking an assignment consistent with S and obtaining a different prediction. Hence, our concern will be to identify sets S that minimize Pr((x) = (v), xS = vS ).
Definition 5 (I-relevant set). Let  : F  K,   [0, 1], and instance (v  F, c  K). S  F is a I-relevant set for the classifier-instance pair,  and (v, c), if (5) holds:

Prx((x) = (v), xS = vS )  

(5)

From the definition of conditional probability (see above in this section), it is immediate to observe

that,

Prx((x)

=

(v), xS

=

vS )

=

|{x



F

:

(x) = c  (xS |{x  F}|

=

vS )}|

Definition 6 (Min-I-Relevant-Set). Let  : F  K,   [0, 1], and instance (v  F, c  K). A Min-I-Relevant-Set is a minimal subset S  F that is I-relevant for  and (v, c).

By observing that for larger sets we can only increase the likelihood of the function differing from the value of (v), we have the following result. Proposition 2. I-relevant sets are monotone, i.e. for S1  S2, it is the case that,
Prx((x) = (v), xS1 = vS1 )  Prx((x) = (v), xS2 = vS2 )

4 Duality Results for Relevant Sets

Duality results between different types of explanation enable the implementation of explanation enumeration algorithms [15, 13]3 This section proves one initial duality result between -relevant sets. Given earlier work [15, 13], additional results can be envisioned. Let C be a predicate, C : 2F  {0, 1}, such that,
C(S) = [Prx((x) = c, xS = vS )  ] We associate with C a set of subsets of F,
C = {S  F | C(S)}
In addition, we define a set of minimal sets,
Cmin = {S  F | C(S)  (U S).¬C(U )}
Next, we introduce the dual predicate D, D : 2F  {0, 1}, such that,
D(T ) = ¬C(F \ T ) = [Prx((x) = c, xF\T = vF\T ) > ] The dual of -relevant sets are sets T of features which if changed entail a change of class with a probability >  and are thus probabilistic analogues of contrastive explanations [13]. As done above,
3These recent duality results about explanations build on the work of Reiter [31]. In this section, we follow loosely a recent overview [39].

5

Path Rj Q1 Q2 Q3 Q4 Q5 P1 P2 P3 P4 P5 P6 P7 P8 P9 P10 P11 P12 P13 Pr(Rj ) 1 42 43 44 14 33 23 31 12 43 42 32 13 35 24 15 23 5
Table 1: Path probabilities for running example

we can define the following sets:
D = {T  F | D(T )} Dmin = {T  F | D(T )  (V

T ).¬D(V)}

Given the above, monotonicity of the predicates C and D (see Proposition 2), allows us to prove the following results,
Proposition 3. C = HS(D), D = HS(C), Cmin = MHS(D), and Dmin = MHS(C).

Proof. First, we consider C = HS(D). Suppose, there exists S such that it is not a hitting set of sets in D. Namely, S does not hit some set T  D, S  T = . By definition, S  F \ T . We recall that a predicate P is monotone if for all S, S  F ,
S  S  P (S)  P (S).
Hence, as S  F \ T and C(S) holds, C(F \ T ) must hold. This leads to a contradiction as D(T ) = ¬C(F \ T ) by definition. The reverse direction, D = HS(C), is similar.
Second, we consider Cmin = MHS(D). The proof that S  Cmin is a hitting set of D follows from the argument above as Cmin  C. Next, we suppose S  Cmin is not a minimal hitting set of D. Let G  S be the minimal hitting set. By definition of minimality of S, ¬C(G) must hold. Consider W such that G = F \ W. We have that ¬C(G) = ¬C(F \ W) = D(W). Therefore, W  D. As G  W =  by construction, G does not hit W  D and it is not a hitting set. The reverse direction, Dmin = MHS(C), is similar.

5 Relevant Sets for DTs & Other Classifiers
This section shows that the decision problem for -relevant (and so C-relevant) sets is in NP when  is represented by a decision tree4. Thus, Min-C-Relevant-Set can be solved with at most a logarithmic number of calls to an NP oracle. (This is true since we minimize on the number of features.) This section also shows the decision problem for I-relevant sets is in P. Thus, the Min-IRelevant-Set can be solved in polynomial time in the case of DTs. Furthermore, the section extends the previous results to the case of knowledge compilation (KC) languages [11].
Path probabilities for DTs. Let v  F and suppose that (v) = c  K. For a DT T , let P = {P1, . . . , PM } denote the paths with prediction c, and let Q = {Q1, . . . , QN } denote the paths with a prediction in K \ {c}. Let R = P  Q denote the set of all paths in the DT T . For Rj  R, let ||Rj|| denote the number of points in F consistent with Rj. Thus, the path probability of any path Rj  R is, Pr(Rj) = ||Rj||/||F||. (The path probability of some tree path Rj is the empirical probability of a point in feature space chosen at random being consistent with the path Rj.) As a result, we get,
RjP Pr(Rj ) + RjQ Pr(Rj ) = 1
Moreover, ||F|| = ||D1|| × · · · × ||Dm||. For each path Rj, let di denote the number of values in Di that is consistent with the literals defined on xi in path Rj. Thus, ||Rj || = d1 × · · · × dm.
Example 2. For the example in Figure 1, Table 1 shows the path probability for each path in the DT, computed using the above definition of path probability.
Min-C-Relevant-Sets for DTs. Whereas in the general case, deciding whether there exists a relevant set of size no greater than k is complete for NPPP [42], in the the case of DTs, one can prove that this decision problem is in NP (and the same applies in the case of a subset-minimal C-relevant set).
Proposition 4. For DTs, given v  F, with (v) = c  K, deciding the existence of min--relevant set of size at most k is in NP.
4For simplicity, the paper considers the case of non-continuous features. However, in the case of DTs, the results generalize to continuous features.

6

Proof. We reduce the problem of deciding the existence of a min--relevant set of size at most k to the decision version of the maximum satisfiability modulo theories (SMT) problem [4, 6] (assuming a suitable quantifier-free theory).
Let si be a boolean variable such that si = 1 iff i  F is included in the -relevant set. Moreover, let tj be a boolean variable, such that tj = 1 iff path Rj  P  Q is inconsistent, i.e. some feature i added to the -relevant set makes Rj inconsistent. Thus, if path Rj is inconsistent with the value given to feature i, then it must be the case that,
si  tj
Also, if Rj is deemed inconsistent, then it must be the case that,

tj  iIj si
where i ranges over the set of features Ij that make Rj inconsistent, given v. The set of picked features S , (i.e. S is the set of features having si = 1), ensures that

From which we get,

Prx((x) = (v)|xS = vS )  

Prx((x) = (v)  xS = vS )   × Prx(xS = vS )  j,RjP ¬tj × Pr(Rj )   × j,RjPQ ¬tj × Pr(Rj )

which is a linear inequality on the tj variables, since the probabilities are constant. An additional constraint is that the number of si variables assigned value 1 cannot exceed k, i.e. the bound on the size of the relevant set S:

iF si  k

which is another linear inequality, this one on the si variables. By conjoining all the constraints,

and assignment to the si and tj variables that satisfies the constraints picks a -relevant set whose

size does not exceed k.



Clearly, since the decision problem is in NP, it is immediate how to compute a cardinality minimal -relevant set by binary search on the number of si variables included in the set. Since the number of variables equals the size of F , then we are guaranteed to need (in the worst-case) a logarithmic number of calls to an NP oracle. Furthermore, since the decision problem for the min--relevant problem is in NP, it is also the case that the decision problem for the min-C-relevant problem is also in NP. Finally, we conjecture that the min--relevant set, but also the min-C-relevant problem are both hard for NP. These conjectures are further justified below.
Min-I-Relevant-Sets for DTs. One apparent reason to the conjectured complexity is the fact that the conditional probability used for defining -relevant and C-relevant sets is non-monotone. As a result, earlier in the paper we introduced I-relevant sets, which were shown to be monotone in Proposition 2. We now show that, in the case of DTs, computing a subset-minimal I-relevant set is in P. The criterion for a set of features to be I-relevant is:
Prx((x) = (v), xS = vS )  
Observe that this constraint holds when S = F and, by Proposition 2 I-relevant sets are monotone. As a result, we can compute a subset minimal I-relevant set, as proposed inAlgorithm 1. (The algorithm is standard, and can be traced to at least the work of Chinneck & Dravnieks [9]. The novelty is its use for computing min-I-relevant sets.) The algorithm maintains an invariant representing the assertion that the set S is a I-relevant set. Initially, all features are included in set S, i.e. S = F , and so S is a I-relevant set. The algorithm then iteratively removes one feature at a time, and checks whether the invariant is broken. If it is, then the feature is added back to set S. Otherwise, we are guaranteed, by monotonicity, that for any superset of set S, the invariant holds.
Example 3. We consider the running example (see Figure 1, with instance (v, c) given by v = (v1, v2, v3, v4, v5, v6, v7, v8, v9) = (1, 1, 1, 1, 0, 0, 0, 0, 1) and c = (v) = 1. As argued earlier, by setting  = 0, one AXp is X = {1, 2, 3, 4, 9}. Let (S) = Prx((x) = (v), xS = xS ), denoting the error associated with some set of features S. With the purpose of improving the interpretability of the explanation, we set  = 0.03, and work towards finding an explanation with fewer literals. To illustrate the execution of the algorithm, we assume that the features are analyzed in the order
1, 2, 3, 4, 9 . Table 2 summarizes the execution of the algorithm. The algorithm first analyzes

7

Algorithm 1 Finding one min-I-relevant set (IDRS)

Input: Classifier , instance v, value  Output: IDRS S

1: procedure findIDRS(, v, )

2: S  {1, . . . , m}

3: for i  {1, . . . , m} do

4:

S  S \ {i}

 Invariant: Prx((x) = (v), xS = vS )  

5:

if Prx((x) = (v), xS = vS ) >  then

6:

S  S  {i}

7: return S

S

i R = S \ {i} Q paths consistent with R (R) Decision

{1, 2, 3, 4, 9} 1

{1, 2, 3, 4, 9} 2

{1, 3, 4, 9} 3

{1, 4, 9} 4

{1, 9}

9

{2, 3, 4, 9} {1, 3, 4, 9} {1, 4, 9}
{1, 9} {1}

Q1 Q2 Q2, Q3 Q2, Q3, Q4 Q2, Q3, Q4, Q5

0.5 0.0157 0.0234 0.0273 > 0.03

Keep 1 Drop 2 Drop 3 Drop 4 Keep 9

Table 2: Execution of Algorithm 1
dropping feature 1 from the explanation X . In this case, only path Q1 can be made consistent. Given that the probability of picking an assignment consistent with Q1 is 0.5, then feature 1 cannot be dropped from the explanation, as that would put the error about the target threshold. Next, the algorithm considers dropping feature 2 from the explanation. In this case, only path Q2 can be made consistent. Given that the probability of picking an assignment consistent with Q2 is (1/2)6 = 0.015625, then are still below the target absolute fraction of error of  = 0.03. Hence, we remove feature 2 from the explanation. For feature 3, and since feature 2 is already dropped, then both paths Q2 and Q3 can be made consistent. In this case, the error raises to 0.0234, but it is still below 0.3, and so feature 3 is also dropped from the explanation. A similar analysis allows concluding that feature 4 can also be dropped from the explanation. In contrast, after removing features 2, 3 and 4, feature 9 cannot be dropped form the explanation. The resulting approximate explanation (i.e. a I-relevant set) is thus {1, 9}. Moreover, the explanation {1, 9} ensures that, in more than 97% of the points in feature space consistent with the values of features 1 and 9, the prediction will be the intended one, i.e. 1.

KC languages [11]. Knowledge compilation (KC) languages [11] aim at simplifying queries and transformations in knowledge bases, and have recently been used as ML models. Concrete examples include binary decision diagrams [36, 37], among others [2, 3, 1]. By noting that the explanation algorithm proposed for DTs exploits counting of models after conditioning (i.e. fixing to a value) a set of selected features, then we can conclude that, for KC languages that implement conditioning and model counting in polynomial time, one min-I-relevant set can also be computed in polynomial time.

6 Experimental Results
This section summarizes the experimental results, which aim at demonstrating the efficiency of minI-relevant sets if computed as explanations for DT models trained for various well-known datasets, over heuristic explanations of Anchor [33], both in terms of runtime performance and explanation precision.
Implementation and benchmarks. Min-I-relevant sets are computed following the ideas of Section 5 and utilizing the polynomial-time Algorithm 1. The prototype implementation of the algorithm (IDRS) is written in Perl while the overall experiment is set up and run in Python.5 The precision of the resulting explanations is then assessed using the generic (and non-monotone) precision metric of Anchor [33]. The experiments are conducted on a MacBook Pro with a Dual-Core Intel Core i5 2.3GHz CPU with 8GByte RAM running macOS Catalina.
The benchmarks used in the experiment include publicly available and widely used datasets. The datasets originate from UCI ML Repository [40] and Penn ML Benchmarks [29]. The number of
5The prototype implementation, benchmarks, instructions and log files of the experiment will be made publicly available in the final version of the paper.

8

Dataset

#F #I

IDRS

Length Precision (%)

Runtime (s)

Anchor Length Precision (%) Runtime (s)

M avg avg dev m M avg M avg avg dev m M avg

adult

0.0 10 5.1 100 0.0 0.04 0.07 0.05

12

1766

0.01 0.02

6 6

3.3 85.7 2.8 83.0

20.8 16.4

0.04 0.04

0.08 0.08

0.04 0.05

12

5.3

87.8

16.7

0.14 2.99 1.20

0.05 5 1.9 77.7 21.0 0.04 0.11 0.06

allhyper

0.0 7 4.4 100 0.0 0.05 0.05 0.05

29

1113

0.01 0.02

6 6

3.0 98.4 1.0 97.7

4.3 6.3

0.04 0.05

0.08 0.07

0.05 0.05

29

1.2

89.5

7.0

0.28 5.75 0.35

0.05 4 1.0 97.7 6.3 0.04 0.10 0.05

0.0 10 3.9 100 0.0 0.08 0.10 0.08

ann-thyroid

21

2139

0.01 0.02

6 6

1.4 96.9 1.0 96.8

11.4 11.2

0.07 0.08

0.13 0.12

0.08 0.08

21

1.3

96.4

8.7

0.22 8.63 0.48

0.05 5 0.1 95.2 9.9 0.07 0.17 0.10

0.0 15 5.9 100 0.0 0.67 0.92 0.69

fars

29

2790

0.01 0.02

6 6

2.0 75.2 2.1 70.2

30.9 35.5

0.58 0.67

0.81 0.98

0.69 0.71

29

9.0

73.5

40.3

0.30 57.43 7.54

0.05 5 1.7 58.6 38.0 0.63 0.89 0.70

kddcup

0.0 14 11.4 100 0.0 0.44 4.14 0.46

41

4368

0.01 0.02

8 7

4.4 53.7 4.2 51.8

42.9 22.0

0.42 0.45

0.84 0.61

0.45 0.46

39

2.6

23.1

19.0

0.42 137.3 10.59

0.05 6 2.8 38.7 22.0 0.41 0.54 0.44

Table 3: Assessing explanations of I-relevant sets (IDRS) and comparison with Anchor's explanations. Columns #F and #I report, resp., the number of features and the number of tested instances, in the dataset. (Note that for a dataset containing less (resp. more) than 10.000 instances, 30% (resp. 3%) of its instances, randomly selected, are used to be explained. Moreover, duplicate rows in the datasets are filtered.) Sub-Columns M and avg of column Length show, resp., the maximum and average size of an explanation. Sub-columns avg and dev of column Precision show, resp., the average and standard deviation of the explanation's precision. Sub-columns m, M and avg of column Runtime report, resp., minimal, maximal and average time in seconds to compute an explanation.

training instances (resp. features) in the target datasets varies from 3710 to 145585 (resp. 12 to 41). All the decision tree models are trained using the learning tool ITI (Incremental Tree Induction) [41, 16]. Note that the accuracy of all the models is above 73%, the maximum depth of the trees varies from 14 to 60 and the total number of nodes varies from 49 to 9969.
The experiment was set to iterate over some of the unique (see below) instances of a dataset and to compute an explanation for each such instance: either a min-I-relevant set or an anchor. As the baseline, we ran Anchor with the default explanation precision of 0.95. The prototype implementation IDRS was run for the values of  from {0.05, 0.02, 0.01, 0.0}. It should be observed that the proposed experiment gives an advantage to Anchor, as Anchor is allowed to computes explanations guided by its own metric, whereas I-relevant sets know nothing about this metric (which they will be assessed with).
Results. Table 3 details the results of our experiment. First of all, observe that I-relevant sets are extremely simple to compute. Concretely, the runtime of our prototype explainer IDRS normally takes just a fraction of a second per data instance (and never exceeds a second) to get a subsetminimal I-relevant set. This means that it is at least 1­2 orders of magnitude faster than Anchor, which can take up to 138 seconds to get a single explanation, with the average explanation time being up to 10 seconds. Also observe that the runtime of the proposed approach is not affected by the value of  and tends to be negligible overall.
Second, length-wise I-relevant sets also outperform Anchor. In particular, it is not surprising that the largest I-relevant sets correspond to =0 and these on average include up to 11.4 features. Explanation size gets further improved when  is 0.01, 0.02 or 0.05. Concretely, it is reduced to a few literals per explanation (on average below 5). (Also, please refer to the value of standard deviation shown in the tables.) On the contrary, Anchor's explanations utilize up to 39 literals, with the average explanation containing 9 literals. These results show an important difference between IDRS and Anchor in terms of interpretability [23].
Finally and somewhat unexpectedly, IDRS outperforms Anchor in terms of explanation precision. Clearly, the precision of I0-relevant sets (i.e. =0) is 100%, which demonstrates a significant improvement over anchors. What is more interesting, however, is that the average precision of IDRS does not significantly drop down in case of   {0.05, 0.02, 0.01}. In particular, its precision is on par with (or better than) the explanations provided by Anchor. All the points above confirm that Irelevant sets if computed for DT models provide a viable alternative to Anchor's explanations from all the considered perspectives, including runtime performance, explanation size, and precision.

9

7 Conclusions
-relevant sets [42] enable the computation of approximate (i.e. non-universally true) explanations, and reveal connections between heuristic explanations and non-heuristic explanations. A major drawback of -relevant sets is their computational complexity. This paper shows that for DTs, deciding whether there exists a set of at most k features that -relevant is in NP. Furthermore, the paper proposes relaxed alternative definitions of -relevant sets, and shows that such alternative definitions enable the computation of minimal approximate explanations in polynomial time. The paper also derives a first result on the duality between sets of features representing different kinds of (relaxed)  relevant sets. The experimental results, obtained on large DTs learned with a state of the art tree learner, confirm the practical efficiency and the quality of explanations when compared with the well-known Anchor heuristic explainer [33].
Acknowledgments. This work was supported by the AI Interdisciplinary Institute ANITI, funded by the French program "Investing for the Future ­ PIA3" under Grant agreement no. ANR-19-PI3A0004, and by the H2020-ICT38 project COALA "Cognitive Assisted agile manufacturing for a Labor force supported by trustworthy Artificial intelligence".
References
[1] G. Audemard, S. Bellart, L. Bounia, F. Koriche, J. Lagniez, and P. Marquis. On the computational intelligibility of boolean classifiers. CoRR, abs/2104.06172, 2021.
[2] G. Audemard, F. Koriche, and P. Marquis. On tractable XAI queries based on compiled representations. In KR, pages 838­849, 2020.
[3] P. Barceló, M. Monet, J. Pérez, and B. Subercaseaux. Model interpretability through the lens of computational complexity. In NeurIPS, 2020.
[4] C. W. Barrett and C. Tinelli. Satisfiability modulo theories. In E. M. Clarke, T. A. Henzinger, H. Veith, and R. Bloem, editors, Handbook of Model Checking, pages 305­343. Springer, 2018.
[5] C. Berge. Hypergraphs: combinatorics of finite sets. Elsevier, 1984. [6] N. Bjørner, A. Phan, and L. Fleckenstein. z - an optimizing SMT solver. In C. Baier and
C. Tinelli, editors, TACAS, pages 194­199, 2015.
[7] L. Breiman. Statistical modeling: The two cultures. Statistical science, 16(3):199­231, 2001.
[8] O. Camburu, E. Giunchiglia, J. Foerster, T. Lukasiewicz, and P. Blunsom. Can I trust the explainer? verifying post-hoc explanatory methods. CoRR, abs/1910.02065, 2019.
[9] J. W. Chinneck and E. W. Dravnieks. Locating minimal infeasible constraint sets in linear programs. INFORMS J. Comput., 3(2):157­168, 1991.
[10] A. Darwiche and A. Hirth. On the reasons behind decisions. In ECAI, pages 712­720, 2020.
[11] A. Darwiche and P. Marquis. A knowledge compilation map. J. Artif. Intell. Res., 17:229­264, 2002.
[12] R. Guidotti, A. Monreale, S. Ruggieri, F. Turini, F. Giannotti, and D. Pedreschi. A survey of methods for explaining black box models. ACM Comput. Surv., 51(5):93:1­93:42, 2019.
[13] A. Ignatiev, N. Narodytska, N. Asher, and J. Marques-Silva. From contrastive to abductive explanations and back again. In AI*IA, 2020.
[14] A. Ignatiev, N. Narodytska, and J. Marques-Silva. Abduction-based explanations for machine learning models. In AAAI, pages 1511­1519, 2019.
[15] A. Ignatiev, N. Narodytska, and J. Marques-Silva. On relating explanations and adversarial examples. In NeurIPS, pages 15857­15867, 2019.
[16] Incremental Decision Tree Induction. https://www-lrn.cs.umass.edu/iti/, 2020.
[17] Y. Izza, A. Ignatiev, and J. Marques-Silva. On explaining decision trees. CoRR, abs/2010.11034, 2020.
[18] P. Khosravi, Y. Liang, Y. Choi, and G. Van den Broeck. What to expect of classifiers? reasoning about logistic regression with missing features. In IJCAI, pages 2716­2724, 2019.
[19] H. Lakkaraju and O. Bastani. "how do I fool you?": Manipulating user trust via misleading black box explanations. In AIES, pages 79­85, 2020.
[20] Z. C. Lipton. The mythos of model interpretability. Commun. ACM, 61(10):36­43, 2018.
10

[21] S. M. Lundberg and S. Lee. A unified approach to interpreting model predictions. In NIPS, pages 4765­4774, 2017.
[22] E. L. Malfa, A. Zbrzezny, R. Michelmore, N. Paoletti, and M. Kwiatkowska. On guaranteed optimal robust explanations for NLP models. In IJCAI, 2021. In press, available from https://arxiv.org/abs/2105.03640.
[23] G. A. Miller. The magical number seven, plus or minus two: Some limits on our capacity for processing information. Psychological review, 63(2):81, 1956.
[24] T. Miller. Explanation in artificial intelligence: Insights from the social sciences. Artif. Intell., 267:1­38, 2019.
[25] C. Molnar. Interpretable Machine Learning. 2020. http://tiny.cc/6c76tz. [26] D. Monroe. Deceiving AI. Commun. ACM, 64, 2021. [27] G. Montavon, W. Samek, and K. Müller. Methods for interpreting and understanding deep
neural networks. Digital Signal Processing, 73:1­15, 2018. [28] N. Narodytska, A. A. Shrotri, K. S. Meel, A. Ignatiev, and J. Marques-Silva. Assessing heuris-
tic machine learning explanations with model counting. In SAT, pages 267­278, 2019.
[29] R. S. Olson, W. La Cava, P. Orzechowski, R. J. Urbanowicz, and J. H. Moore. PMLB: a large benchmark suite for machine learning evaluation and comparison. BioData Mining, 10(1):36, 2017.
[30] C. H. Papadimitriou. Computational complexity. Addison-Wesley, 1994.
[31] R. Reiter. A theory of diagnosis from first principles. Artif. Intell., 32(1):57­95, 1987. [32] M. T. Ribeiro, S. Singh, and C. Guestrin. "Why should I trust you?": Explaining the predictions
of any classifier. In KDD, pages 1135­1144, 2016.
[33] M. T. Ribeiro, S. Singh, and C. Guestrin. Anchors: High-precision model-agnostic explanations. In AAAI, 2018.
[34] C. Rudin. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature Machine Intelligence, 1(5):206­215, 2019.
[35] W. Samek, G. Montavon, A. Vedaldi, L. K. Hansen, and K. Müller, editors. Explainable AI: Interpreting, Explaining and Visualizing Deep Learning. Springer, 2019.
[36] A. Shih, A. Choi, and A. Darwiche. A symbolic approach to explaining bayesian network classifiers. In IJCAI, pages 5103­5111, 2018.
[37] A. Shih, A. Choi, and A. Darwiche. Compiling bayesian network classifiers into decision graphs. In AAAI, pages 7966­7974, 2019.
[38] D. Slack, S. Hilgard, E. Jia, S. Singh, and H. Lakkaraju. Fooling LIME and SHAP: adversarial attacks on post hoc explanation methods. In AIES, pages 180­186, 2020.
[39] J. Slaney. Set-theoretic duality: A fundamental feature of combinatorial optimisation. In ECAI, pages 843­848, 2014.
[40] UCI Machine Learning Repository. https://archive.ics.uci.edu/ml, 2020. [41] P. E. Utgoff, N. C. Berkman, and J. A. Clouse. Decision tree induction based on efficient tree
restructuring. Mach. Learn., 29(1):5­44, 1997. [42] S. Wäldchen, J. MacDonald, S. Hauch, and G. Kutyniok. The computational complexity of
understanding binary classifier decisions. J. Artif. Intell. Res., 70:351­387, 2021.
[43] D. S. Weld and G. Bansal. The challenge of crafting intelligible intelligence. Commun. ACM, 62(6):70­79, 2019.
Supplementary Material
Proofs
Deciding -relevancy. Definition 7 (MajSAT[30]). Given a boolean function f : {0, 1}n  {0, 1}, the MajSAT problem is to decide whether the number of points x with f (x) = 1 exceeds the number of points with f (x) = 0.
It is well-known that MajSAT is PP-complete [30].
11

Proposition 5. Deciding whether a set S is a C-relevant set is PP-hard.

Proof. [Sketch]

We reduce MajSAT to deciding C-relevancy.

Let f : {0, 1}n  {0, 1} be a boolean function. The variables of f are X = {x1, . . . , xn}. We want to decide whether Pr(f (x) = 1) > Pr(f (x) = 0). We create another function F :

{0, 1}n × {0, 1}2  {0, 1}, such that the variables of F are X and P = {p1, p2}. Moreover, F is

defined as follows:

F (x, p) =

1 f (x)

if p1 = p2 = 1 otherwise

Set (xa, pa) = ((0, . . . , 0), (1, 1)). Clearly, F (xa, pa) = 1.

Moreover, set  = 0.75 and pick S = {p1}.

Now, if Pr(F (xb, pb) = 1|(xb, pb)S = (xa, pa)S ) >  iff the number of points with f (x) = 1

exceeds the number of points with f (x) = 0.



12

