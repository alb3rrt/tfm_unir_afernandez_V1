Sparse matrices: convergence of the characteristic polynomial seen from infinity
Simon Coste June ,

arXiv:2106.00593v1 [math.PR] 1 Jun 2021

Abstract
We prove that the reverse characteristic polynomial det(In - zAn) of a random n × n matrix An with iid Bernoulli(d/n) entries converges in distribution towards the random infinite product

(1 - z )Y
=1
where Y are independent Poisson(d / ) random variables. We show that this random function is a Poisson analog of the Gaussian holomorphic chaos and give some of its properties. As a byproduct, we obtain new simple proofs of previous results on the asymptotic behaviour of extremal eigenvalues of sparse Erds-Rényi digraphs.

Introduction

Let An be a square n × n matrix whose n2 entries are independent Bernoulli(dn/n) random variables. This non-Hermitian matrix arises, for example, as the adjacency matrix of a directed Erds-Rényi graph with mean in-degree and mean out-degree dn. Its empirical spectral distribution is the atomic measure defined by

µn

=

1 n

n

i (An )

(.)

i=1

where |i(An)| · · · |n(An)| are the complex eigenvalues of An ordered by decreasing modulus. It is a striking result that when dn  , the random measure µn suitably rescaled converges towards the circular law, a uniform distribution on a disk ([BR+ , RT ]). This phenomenon cannot hold when dn is bounded independently of n, because in this case, any potential limit should have an atom at zero, as noted for example in [RT ]. In this dn = O(1) regime called sparse, the existence of a weak limit for ( . ) is not known. If this limit exists, there are no conjectures on its shape. This is in contrast with the same problem when An is the adjacency matrix of a random directed d-regular graph (when d 3 is an integer); there, the limiting distribution is conjectured to have a closed-form expression, the oriented Kesten-McKay density. In the Erds-Rényi model, there
are reasons to think that no closed-form expressions will exist; more generally, the spectral behaviour of An in the sparse regime is still largely unknown and we refer to the physics-oriented survey [LMNR ] for insights on spectra of sparse, non-Hermitian matrices. Recently, [BCN ] showed that when dn = d, all the eigenvalues of An are asymptotically contained close to the disk D(0, d) except one which is close to d -- this is a Ramanujan-like property for sparse digraphs. It notably implies the tightness of the sequence of random measures (µn), and the fact that all limit points are supported in D(0, d), but the existence of a unique limit point is not guaranteed.

In this paper, the main result is that when dn = d > 1, the sequence of random polynomials
n
qn : z  det(In - zAn) = (1 - zi),
i=1
restricted to the disk D(0, d-1/2), weakly converges towards an explicit random analytic function F . This is inspired by a recent advance in [BCGZ ]. As a corollary, we draw a simple proof of the aforementioned result from [BCN ]. The limiting function F seems to be new; it is a Poisson analog of the Gaussian holomorphic chaos [NPS ], and has connections with the combinatorics of multiset-partitions. In this paper, we only sketch some of its elementary properties, but a deeper study might be of independent interest. Since this object arises as the limit of the polynomials qn which are themselves linked with the i, a better understanding of F might be useful for understanding the asymptotic spectral properties of An.

Results
In all the paper, we fix d > 1 and we consider a random n × n matrix An whose n2 entries are independent zero-one random variables with Bernoulli(d/n) distribution.

. Convergence of the secular polynomials and eigenvalue asymptotics

The main result of this paper is the convergence of the reverse characteristic polynomial of An, which is defined as

qn(z) = det(I - zAn).

( .)

This is a sequence of random polynomials. They can explicitly be written in terms of the eigenvalues of An, namely qn(z) =

n i=1

(1

-

iz),

or

alternatively

they

can

be

expressed

through

their

coefficients,

that

is:

qn(z)

=

1

+

n k=1

(-1)k

zk

k

(A),

where

k(A) =

det((ai,j )i,jI).

I[n] |I|=k

These coefficients are known in the litterature under the name secular coefficients, see for instance [DG ] in the context of circular
-ensembles, and sometimes we will refer to qn as the secular polynomials. Since they are symmetric functions in the i, they can be expressed through Newton's formulas as polynomials in the power sums k1 + · · · + kn = tr(Ak): more precisely, there is a polynomial Pk with degree k and real coefficients such that

k (An )

=

(-1)k

Pk(tr(A1n), . . k!

.

,

tr(Akn))

,

this will be recalled in Subsection . . The traces of Akn can be studied using classical methods in combinatorics, and their limit is identified by the following definition and the theorem after.

Definition . . Let d > 1, and let (Y :  N) be a family of independent random variables, with Y  Poi(d / ). We define a family of (non-independent) random variables by

Xk := Y

(k  N)

(.)

|k

where a|b means that b is a nonzero multiple of a.

Theorem . (trace asymptotics). For every integer k, the following joint weak convergence holds:

(tr(A1n),

.

.

.

,

tr(Akn))

--l-aw-
n

(X1,

.

.

.

,

Xk ).

(.)

In particular, their joint convergence in distribution implies the convergence in distribution of any polynomial in the tr(Akn), and in particular of the coefficients k(An) towards (-1)kPk(X1, . . . , Xk)/k!, or equivalently, the finite-dimensional convergence of qn towards the random analytic function

F (z) := 1 +

(-1)k

Pk

(X1

,

.

.

.

,

Xk

)

zk k!

.

(.)

k=1

To upgrade this result to functional weak convergence, we need to introduce some tools. Let Hr the space of analytic functions on the open disk D(0, r), for r > 0. This set is endowed with the topology of uniform convergence on compact subsets, and with

the corresponding Borel sigma-algebra (all the technical details regarding random analytic functions will be recalled in Section ).

The sum representation in ( . ) is not very informative, and some effort will be deployed for getting more explicit representations

of F in the next subsection, including infinite product representations such as in terms of the Y . For the moment, we will only

need that

almost surely, F is in Hd-1/2 and has a unique simple root located at z = 1/d.

(.)

These properties will follow from the thorough analysis in Theorem . thereafter. We can now state our main result, where for completeness all the definitions are recalled.

Theorem . (weak convergence). Let d > 1 and let An be a random n × n matrix whose n2 entries are independent Bernoulli random variables with parameter d/n, and let qn(z) = det(In - zAn). Then,

qn

--l-aw-
n

F

(.)

where the convergence is the weak convergence of probability measures on Hd-1/2 , and F is the random element in Hd-1/2 defined in ( . ).

Figure : An illustration of Theorem . . The color scheme used for these domain colourings is depicted in the small inset of the right picture. Left is the domain colouring of z  det(I - zA), where A is an n × n random matrix with independent entries equal to with probability d/nand otherwise (n = 500 and d = 2). The inverse eigenvalues of A are in white and the two circles have radius 1/d and 1/ d. Right is the colouring of the random analytic function F in ( . ). What we see inside D(0, 1/ d) in the left picture converges in distribution towards what we see in the right picture.

. Eigenvalue asymptotics

The zeros of analytic functions are continuous with respect to the uniform convergence of compact sets (Hurwitz's theorem).
With ( . ) and the simple probabilistic analysis of the weak convergence on Hd-1/2 done in the inspiring papers [BZ , BCGZ ], we will almost effortlessly show the following result which was already proved in [BCN , CS ] using a different, ad hoc method.

Theorem . . Let |1| · · · |n| be the eigenvalues of the random matrix An defined in the preceding theorem. Then, for any  > 0 the following holds:

lim P(|1 - d| > ) = 0
n



lim P(|2| > d + ) = 0.

(.)

n

 It is supposed that |2| actually converges in probability towards d, but to the knowledge of the author this has not been proved yet; we refer to the related work section on this topic.

. The Poisson multiplicative function and its Secular Coefficients

We finally turn to a closer inspection of the random analytic function F . The results in this section will notably imply ( . ). The log-generating function of the random variables Xk will play a central role in this paper, as well as its centered version:

f (z) =



zk Xk k ,

k=1

P(z) =



(k

-

Xk

)

zk k

n=1

where

k = E[Xk] = d .

(.)

|k

Theorem . (limiting object). The following statements are almost surely true.

(i) The radius of convergence of f is 1/d, and for every z  D(0, 1/d)

F (z) = e-f(z)

(.)

and


F (z) = (1 - z )Y .
=1

(. )





(ii) The radius of convergence of P is 1/ d, and for every z  D(0, 1/ d)



F (z) = eP(z) × (1 - dz ) 1 .

(. )

=1

Let cn be the (random) coefficients of F = e-f , so that F (z) =

 n=0

cnzn.

The

cn

are

also

called

the

secular

coefficients

of

F ; with the definition in ( . ) they are given by cn = Pk(X1, . . . , Xk)/k! but this expression will not be very useful. The cn are

random variables, and since F is analytic inside D(0, 1/ d), Hadamard's formula says that lim sup |cn|1/n = d almost surely,

and it is natural to ask what happens at the border of the radius of convergence, a question similar to the construction of the

Gaussian Multiplicative Chaos on the circle, see [RV ] for a survey (as a side note, we will also see that f is itself a log-correlated

field). Now, Cauchy's formula says that for any m  Z and r < d-1/2,

1 2

2
F (reit)r-me-imtdt =
0

cm if m 0 0 if m < 0.

.

Consequently, the limit

lim

1

2
F (reit)(reit)dt

rd-1/2 2 0

exists for every (z) =

d2 k=d1

ak z k

with

d1, d2



Z,

ie

for

trigonometric

polynomial



on

the

circle

Td-1/2

=

{|z|

=

d-1/2}.

This provides us with a simple construction of F extended to Td-1/2 : we see it as a random distribution, that is, a continuous

linear function on the set of trigonometric polynomials on Td-1/2 .

Definition . . The Poisson Holomorphic Chaos of index d, noted PHCd, is the random distribution on Td-1/2 almost surely

defined by

(PHCd,

)

=

lim
rd-1/2

1 2

2
F (reit)(reit)dt.
0

(. )

A distribution D on Td-1/2 is entirely characterized by its Fourier coefficients D^ (m) := (D, em) where em(t) = d-1/2e-imt. Consequently, we can define the s-Sobolev norm (s  R) by

D

2 s

=

(1 + n2)s|D^ (n)|2.

(. )

mZ

A distribution is s-Sobolev when the sum above is finite. Since the Fourier coefficients of the Poisson holomorphic chaos are given by PHCd(m) = d-m/2cm if m 0 and 0 if m < 0, the Sobolev norm is simply given by mN(1 + n2)sd-n/2|cn|2. Proposition . . Let d > 1. Almost surely, the random distribution PHCd is s-Sobolev for every s < -1/2.

Future work will be devoted to a wider analysis of the Sobolev-regularity of F . Studying the Sobolev norms of F requires a
good understanding of the integrability properties of the secular coefficients cn. We saw that these coefficients are polynomials in the Xk (hence of the Y ), but this expression is difficult to manipulate; however, we have access to their moments by means of a combinatorial analysis. For every integer k > 0, we note Oddk the set of nonempty subsets of [k] = {1, . . . , k} with an odd number of elements, and Evenk the set of nonempty subsets of [k] = {1, . . . , k} with an even number of elements.

Theorem . . For any z1, . . . , zk, one one has

E[F (z1) · · · F (zk)] =

SOddk (1 - d sS zs) . SEvenk (1 - d sS zs)

(. )

To give a few examples,

E[F (z)] = 1 - zd

E[F (y)F (z)]

=

(1

- dy)(1 - 1 - dyz

dz)

E[F (x)F (y)F (z)]

=

(1

- dx)(1 - dy)(1 - dz)(1 (1 - dxy)(1 - dxz)(1 -

- dxyz) dyz)

.

In particular, we see the cn are centered random variables except c0 and c1, and the analytic series (1 - z)-1 = zn gives E[|cn|2] = dn(d + 1) -- in particular E[|cn|2] = O(dn).
The formula given above is our analog of the generating-function formula for the Gaussian Holomorphic Chaos in [NPS ]. Therein, the combinatorial interpretation of the secular coefficients was easily linked with the enumeration of magic squares. A similar simple interpretation of the coefficients of ( . ) is not clear for the moment, but some thoughts are gathered in Subsection . at page .

. Plan of the paper
In Section , we give an overview of the origins of our method and various related work. We mention a set of questions and possible extensions. Section is a summary of classical notions on random analytic functions; the specific properties of the Poisson multiplicative function which are stated in Subsection . are proved in Section . The core results of the paper, namely Theorem . and . , are proved in Section as consequences of Theorem . , which identifies the limits of the traces. This theorem is proved in Section .
Related work and comments
Convergence of the reverse characteristic polynomial. Our work is inspired by the recent paper [BCGZ ]. There, the authors prove the convergence of det(In - zXn/ n), where Xn is a random matrix whose entries are iid random variables, with mean and variance , and whose law does not depend on n; for instance, Ginibre matrices. The circular law phenomenon holds for this model; that is, the empirical spectral distribution of Xn/ n converges weakly towards the uniformdistribution over D(0, 1). The goal of [BCGZ ] was to prove the `no outliers phenomenon': that the greatest eigenvalue of Xn/ n, noted n, converges in probability towards , with no extra assumptions on the moments of the entries of X. We refer to the introduction of [BCC+ ] and references therein for some history on this theorem. In our paper we closely follow the method introduced in [BCGZ ]. This method is itself inspired by [BZ ] and Appendix A therein. The crucial addition of [BCGZ ] was a truncation procedure and the identification of a trace CLT, which allowed to identify the limiting distribution. However, the model studied in [BZ ] is completely different (perturbations of banded matrices).
Eigenvalue asymptotics for sparse matrices and trace methods. Theorem . was already proved in [BCN ], following a long line of research initiated in [Bor , BLM ] and continued, for example, in [Cos , BC , BDH ]. These papers reach results like ( . ) by using a very sophisticated high-trace method, namely, they study the asymptotics of tr(Aknn ), with kn allowed to grow to . This technique dates back at least to [FK ]. In our method, ( . ) is a direct consequence of Theorem . , which is itself proved using the classical trace method with k fixed as in Theorem . . It is considerably simpler. Trace asymptotics are standard in random matrix theory, even for non-Hermitian random matrices; however, we could not find Theorem . in the litterature and to the knowledge of the authors, there are very few similar results for other models of sparse matrices. The closest result can be seen in [DJPP ] (or in its bipartite version [Zhu ]) for traces of non-backtracking matrices on regular graphs: see the definition of CNBW k at page in [DJPP ].
Sparse models: extension to regular graphs. Our paper only treats the case of Erds-Rényi directed graphs, whose edges are independent. The other main model for sparse non-Hermitian matrices is the random regular digraph model mentioned in the introduction. For an integer d 3, one samples A uniformly from the set of adjacency matrices of d-regular directed graphs. A statement similar to Theorem . for this model was proven in [Cos ] using the high-trace method, but the method in our paper should also provide a simpler proof. In fact, the limits of the traces as in Theorem . is thought to be the same for random regular, with a similar proof; but the main difficulty lies in the tension of the polynomials qn, where our method and Proposition . are not easily generalized.
Similarly, one can be interested in applying this model to random undirected regular graphs. The asymptotics of the second eigenvalue, in this case, is given by the Alon-Friedman theorem and the proofs relied on delicate subgraphs asymptotics [Fri ], or the use of the non-backtracking matrix B, see [Bor ]. The asymptotics of the traces of B are known, see [DJPP ], but here again the tension of the family of polynomials det(I - zB) on H1/2d-1 is not proved for the moment.
Sparse models: extensions to inhomogeneous graphs. The inhomogeneous random digraph is defined as follows: instead of appearing with probability p = d/n, an edge (i, j) appears with probability pi,j depending on i and j. When the mean matrix P has low rank and has delocalized entries, a theorem similar to Theorem . was proved in [CS ]. Since this model encompasses popular generative models in network science (such as the directed Stochastic Block-Model, its weighted, labelled or degree-corrected variants, or the rank- inhomogeneous random graph), our method could provide an interesting alternative to [BLM ] and the high-trace methods; however, as it is now our method cannot provide information on the eigenvectors of An, and it could be interesting to see if any refinement can achieve this.
From sparse matrices to dense matrices. We restricted to the sparse case where the mean degree of the graph dn = d is constant, independently of n. As mentioned in the introduction, when dn  , the ESD of the matrix A/ dn converges towards the semi-circle distribution, see [BR+ , RT ]. There is no doubt that our method will apply to this setting. The trace asymptotics as in Theorem . will not be Poisson mixtures, but Gaussian random variables, thanks to the Lindeberg-Feller

theorem; the tension of the sequence (qn) follows the same proof. We leave this for future work. One advantage of this method is that it provides a unified point of view which is valid for every sparsity regime.

Alon-Boppana for non-normal matrices. In the theory of sparse non-Hermitian matrices, there is still a crucial lack of
lower bounds for the second eigenvalue. For instance, our result in Theorem . states that the second eigenvalue of Erds-Rényi graphs satisfies |2| d + oP(1). However, the matching lower bound, namely that |2| d + oP(1), is only conjectured; in fact, it is generally believed that for any fixed k, |k| d + oP(1). We call this kind of upper bounds `Alon-Boppana bounds', in reference of the famous lower bound for 2 in [Nil ] in the context of regular graphs. For Hermitian or normal matrices, they are easily reachable thanks to the min-max characterizations of eigenvalues, but this tool is not available for non-normal matrices
such as adjacency matrices of random digraphs. In many models of sparse random matrices such as [CS ], Alon-Boppana bounds
are conjectured, but at the moment they are not proved. Onepossible way to prove these bounds is to directly prove that the ESD of A converges towards a limiting measure supported
in D(0, d), but as mentioned in the introduction this seems much more difficult in our setting. The method developed in [BR+ , BCGZ ] and this paper suggests another strategy. The limiting function F has a radius
of convergence of 1/ d. If we had lim sup |2| < c for some c < d on an event with positive probability, then on this event all the roots of qn except 1/1 would be outside the circle of radius 1/c. It seems reasonnable to say that this should imply that the radius of convergence of F would then be greater than 1/c on this event, a contradiction. We could not formalize this idea.

The Poisson analog of the GHC. Exponentials of Gaussian fields have a very rich history, see the survey [RV ]. Of special interest is the the Gaussian holomorphic chaos, ie

C(z) = exp



zk

Nk 

( .)

k=0

k

where the Nk are iid standard complex Gaussian variables. This random analytic function on D(0, 1) was proved to be the limit of the secular polynomials in the circular -ensemble for  = 2 in [DS ], and then for every  > 0 in [JM ]. This link between characteristic polynomials and Gaussian functions was also central in a series of conjectures in [FK ] and subsequent work. The remarkable paper [NPS ] thoroughly studies more refined properties of the GHC linked with the circular ensembles; therein, the very clear combinatorial interpretation of the moments of the GHC already seen in [DG ] is proven by elementary means ( [NPS , Theorem . ]). For the moment, we could not reach such an elegant description for our Poisson analog, see Theorem . .
Subsequent work should be devoted to a less shallow study of the Poisson multiplicative function F and its extension to the circle Td-1/2 as in Definition ( . ). One can transpose virtually every question that arose in the theory of Gaussian Multiplicative Chaos:

. Proposition . only gives a tiny information on the regularity of PHC. Can we fully characterize the Sobolev regularity of this object? As noted in Subsection . , the answer could depend on the limit of |F (reit)|2dt -- the total mass of a putative random measure on {|z| = d-1/2} defined by limrd-1/2 e2Re(f(reit))dt.
. Is there a simple combinatorial interpretation of the generating functions for the moments of PHCd in ( . )?
. What can be said about the convergence of the secular coefficients k(An) when k is allowed to go to infinity with n?

General facts about random analytic functions

In this section, we recall some basic facts on random analytic functions.

Let Hr be the set of analytic functions on the open disk D(0, r). A textbook treatment of the properties of Hr is in [S+ , vol. a, ch. ]. A classical consequence of Cauchy's formula is that the elements in Hr can be represented as power series



ak z k

( .)

k=0

with lim sup |ak|1/k 1/r (Hadamard's formula). The space Hr is endowed with the compact-convergence topology: we say that a sequence fn converges to f if, for every compact set K  D(0, r),

fn - f K = sup |fn(z) - f (z)|  0.
zK

Endowed with this topology, H (D) is topolish -- it is separable, complete and there is a metric distance generating the topology.

We now turn to random variables in Hr. We endow this space with the Borel sigma-algebra. Random variables in Hr are random analytic functions; equivalently, they are series as in ( . ), where the ai are random variables satisfying Hadamard's limsup condition. The law of two random functions akzk and bkzk are equal if and only the finite-dimensional distributions of (ai) and (bi) agree, that is, if (a1, . . . , ak) l=aw (b1, . . . , bk) for every k. The classical text on random analytic functions is [Kah ], especially Chapter .
We endow the space of probability distributions on Hr with the topology of weak convergence of measures, that is: the law of fn converges weakly towards the law of f if and only if E[(fn)]  E[(f )] for every continuous bounded function  : Hr  [0, [. With a common abuse of language, when we say that random variables converge in law, we mean that their distributions converge in law as described above. The following theorem summarizes the results in [Shi ]. See also [BCGZ ,
Lemma . ].

Theorem . . Let f, f1, f2, . . . be random variables in Hr. Then, fn converges weakly towards f if and only if (i) The sequence of random variables fn Ki is tight for every i, where Ki is a sequence of compacts exhausting D(0, r).

(ii) The finite-dimensional laws of fn converge in law towards those of f .

Proving the tightness of fn K when fn is a random sequence of analytic function can be simplified by the following device, a statement close to [Shi ], Lemma . and the remark just after.

Lemma . (Hardy-type criterion). Let fn(z) = an,kzk be a sequence of random analytic functions on D(0, r). If there is a sequence (an) such that supn E[|an,k|2] ak for every k and such that lim sup |ak|1/2k 1/r, then (fn) is tight in Hr.
Proof. Let K  D(0, r) be a compact set and let s < r be the radius of a disk containing it. By Cauchy's formula,

2

|fn(z)|2 =

1 2i

fn(w) dw |z|=s w - z

=

1 (2)2

2 0

fn(seit)sieit seit - z

dt

2

s2 22

2
|fn(seit)|2dt
0

where we used Cauchy-Schwarz's inequality and we set  = s - maxxK |x| > 0. Using Parseval's formula, we obtain

|fn(z)|2

s2 2


|an,k |2 s2k

k=0

and this is valid for all z  K. The expectation of the RHS is by hypothesis smaller than (s2/2) k aks2k, a continuous function in s  [0, r) because we supposed that lim sup |ak|1/2k 1/r. Consequently, E[supzK |fn(z)|2] cK for some constant cK depending on K. It readily implies the tightness of the sequence.

Remark . . The 2-Hardy norm on a disk D(0, s) is |ak|2s2k 1/2. The preceding statement says that if (fn) has a uniformly
bounded 2-Hardy norm in every D(0, s) for s < r then the sequence is tight. This is slightly more specific than the criterion in [Shi ], in which one directly proves that E[|fn(z)|2] is bounded by a continuous function. The reason why we do this is the following: if we directly want to study E[|fn(z)|2], we obtain

E[|fn(z)|2] = zkz¯ E[an,kan, ]
k,

and often, the random variables an, and an,k are independent or decorrelated for k = , as in [BCGZ ]. This will not the case for us, see the examples in Subsection . .

Proof of Theorem .
. Proof of the finite-dimensional convergence
To prove Theorem . , namely that qn converges weakly towards F , we use Theorem . . The key for the finite-dimensional convergence is the identification of the distributional limits of the traces of Ak in Theorem . . Given this theorem which will be proved in Section , we can classically link the traces of Ak with the secular coefficients, the coefficients of det(I - zA).

To do this we introduce a family of polynomials Pk, each Pk having k variables. We note Sk the group of permutations of [k]; each permutation  can be uniquely written as a composition of cycles with disjoint support, say  = c1  · · ·  c ; the length of a cycle c is noted |c|. Then, we define Pk as

Pk(z1, . . . , zk) =

(-1) z|c1| . . . z|c |.

(.)

Sk

Proposition . . For any f (z) = anzn analytic in some disk D(0, r),

e-

 k=1

ak

zk k

=1+



zk Pk(a1, . . . , ak) k! .

(.)

k=1

Moreover, for any n × n matrix B, for any z,

det(I - zB) = 1 +

n

Pk

(tr(B),

.

.

.

,

tr(Bk))

zk k!

.

(.)

k=1

Proof. Part ( . ) can be found in [Aig , Corollary . ]. For the second statement, we note C(z) the matrix logarithm of I - zB,
which exists if |z| < 1/ B and is defined by C(z) = -  Bk zk. k
k=1

Then det(I - zB) = det(eC(z)) = etr(C(z)) = e-

 1

. tr(Ak k

)

zk

This

proves

(

.

)

(we

can

truncate

the

sum

at

n

since

it

is

a

polynomial of degree n) for |z| < 1/ B , and it extends analytically for all z.

The coefficients of qn are k(An) = Pk(tr(A), . . . , tr(Ak))/k! and polynomials are continuous with respect to weak convergence, so Theorem . implies that

(1(An), . . . , k(An)) -l-aw (P1(X1), . . . , Pk(X1, . . . , Xk)/k!).
Thanks to ( . ) and the definition of F in ( . ), this is exactly the finite-dimensional convergence of qn towards F = e-f , ie the second point in Theorem . . To complete the proof, we need to check the first point of this theorem.

. Proof of the tightness
We now have to prove the first point on Theorem . , that is, the tightness of (qn), and to do this we use the Hardy-type criterion in Lemma . . We recall that qn(z) = det(I - zA) = 1 + nk=1(-1)kzkk(A) where the k(A) are the secular coefficients; from now on, we'll simply note them k, and they are given by

k = det(A(I))
I[n] |I|=k

with A(I) = (ai,j)i,jI. Our goal for Lemma . is to give an upper bound for

E[|k|2] = E[det(A(I)) det(A(J))]

(. )

|I|=k |J|=k

which does not depend on n. For any finite set E, we note S(E) the group of its bijections and  : S (E)  {-1, +1} the signature (the unique nonconstant group morphism). If I, J are fixed, then





E[det(A(I)) det(A(J))] =

()( )E  

ai,(i)aj,

 (j)

(.)

S(I)

iI

 S(J)

jJ

and when the entries ai,j are centered and have a common variance, the former expression is easy to study: if I = J, the expectation is the sum is always zero by independence, so the whole expression is nonzero iff I = J and the only nonzero

contribution in the sum comes from  =  . This is the situation studied in [BZ ] or [BCN ]. It is not the case for us since we deal with non-centered entries. For instance, let us take n = 2, I = {1} and J = {1, 2}, so that

E[det(A(I)) det(A(J))] = E[a21,1a2,2 - a1,1a1,2a2,1].
If the ai,j are standard real Gaussian random variables, this is zero. But if they are Ber(p), this is p2 - p3. Fortunately, the computations are accessible.

Proposition . . Set p = d/n. With the preceding notations,

E[|k|2] = (n)kpk(1 - p)k-1(1 - kp - p + nkp - k2p).

(. )

The proof will be in Section . . We did not succeed in finding a simpler proof. Now, since p 1 and kp d for all k n, we can bound E[|k|2] by ak := dk(2 + d + kd), which does not depend on n; we also have
 lim sup |ak|1/2k = d.

Lemma . applies and shows that (qn) is a tight sequence in Hd-1/2 .

. Proof of Proposition .
For any two nonempty subsets I, J  [n], we will note

(I, J) = E[det(A(I)) det(A(J))].

(. )

Proposition . is a direct consequence of the following theorem which could be of independent interest.

Theorem . . If I has k elements and J has h elements (wlog, k h), then the followings holds for any matrix A with independent Ber(p) entries.

(i) If J \ I or I \ J has more than two elements, then (I, J) = 0.

(ii) If I = J, then

(I, J) = k!pk(1 - p)k-1(1 - p + kp).

(.)

(iii) If I  J and J \ I has only one element, then (I, J) = (k - 1)!pk(1 - p)k-1. (iv) If |I| = |J| and if |I  J| = k - 1, then (I, J) = k!pk+1(1 - p)k-1.

We now prove Proposition . , and we will only need the cases (i), (ii), (iv) -- case (iii) is only included for completeness. We

have

E[|k|2] =

(I, J)

|I|=|J|=k

and in this sum, the only non-zero contributions come from couples I = J and couples I, J with |I  J| = k - 1, so

E[|k|2] =

(I, J) +

(I, J)

|I|=|J|=k I=J

|I|=|J|=k |IJ|=k-1

=

n k!pk(1 - p)k-1(1 - p + kp) + k

n k+1

(k + 1)kk!pk+1(1 - p)k-1

= (n)kpk(1 - p)k-1(1 - p + kp) + (n)k+1kpk+1(1 - p)k-1

= (n)kpk(1 - p)k-1(1 - kp - p + nkp - k2p).

Before jumping to the proof of Theorem . , let us illustrate the 3 × 3 case for which computations can be checked by hand.

Example . . We study

a1,1 a1,2 a1,3 A = a2,1 a2,2 a2,3 .
a3,1 a3,2 a3,3

Case (i): let us take for instance I = {1} and J = {1, 2, 3}, so
(I, J) = E[a1,1 det(A)] = E[a1,1(a1,1a2,2a3,3 + a1,2a2,3a3,1 + a1,3a2,1a3,2 - a1,1a2,3a3,2 - a1,2a2,1a3,3 - a1,3a2,2a3,1)] = E[a1,1a2,2a3,3 + a1,1a1,2a2,3a3,1 + a1,1a1,3a2,1a3,2 - a1,1a2,3a3,2 - a1,1a1,2a2,1a3,3 - a1,1a1,3a2,2a3,1] = p3 + p4 + p4 - p3 - p4 - p4 = 0.
For case (ii) let us take I = J = {1, 2}, so that
(I, J) = E[(a1,1a2,2 - a1,2a2,1)2] = E[a1,1a2,2 + a1,2a2,1 - 2a1,1a2,2a1,2a2,1] = 2p2 - 2p4.
For case (iii) we take I = {1, 2} and J = {1, 2, 3}, we obtain

(I, J) = E[(a1,1a2,2 - a1,2a2,1)× (a1,1a2,2a3,3 + a1,2a2,3a3,1 + a1,3a2,1a3,2 - a1,1a2,3a3,2 - a1,2a2,1a3,3 - a1,3a2,2a3,1)]
and this is equal to 2p5 - 4p4 + 2p3. Finally for case (iv) we take I = {1, 2} and J = {2, 3} and we obtain

(I, J) = E[(a1,1a2,2 - a1,2a2,1)(a2,2a3,3 - a2,3a3,2)] = E[a1,1a2,2a3,3 - a1,1a2,2a2,3a3,2 - a1,2a2,1a2,2a3,3 + a2,1a1,2a2,3a3,2] = 2p3 - 2p4

For the proof, we will settle some notations. We will denote I  J =: K. Remember that I has less elements than J; we can choose some fixed one-to-one mapping  : I  J, and we choose it such that if fixes K, ie (i) = i for every i  K. For any discrete set D  [n], the set of permutations of D is noted S(D). If   S(I) and   S(J), we introduce

cpK(,  ) = {i  K : (i) =  (i)} fpK() = {i  K : (i) = i}
the sets of (respectively) common points of ,  in K, and fixed points of  in K. We will need the following observation.
Lemma . . |fpK(    -1)| = |cpK(,  )|. Proof. For any i  K, we note that if  (i) = (i) then     -1  (i) = (i) and vice-versa, so (i) is a fixed point of     -1 in K if and only if i is a common point of  and  in K.

Proof of the theorem. By the definition of the determinant,





(I, J) = E [det(A(I)) det(A(J))] =

()( )E  ai,(i) aj,(j) .

(. )

S(I)  S(J)

iI

jJ

In ( . ), we note that for fixed ,  , the expectation inside the sums is equal to pk+h-|cpK(,)|. Since (    -1) = ( )(-1) = ( )() and       -1 is a bijection of S(J), we obtain

E [det(A(I)) det(A(J))] = pk+h

()( )p-|fpK( -1)|

S(I)  S(J)

= pk+h

(    -1)p-|fpK( -1)|

S(I)  S(J)

= pk+h

( )p-|fpK( )|

S(I)  S(J)

= pk+hh!

( )p-|fpK( )|.

 S(J)

Let M = MJ,K(p) be the matrix whose rows and columns are indexed by J, and with all entries equal to 1 except the diagonal entries mi,i with i  K, which are equal to p-1. Then,

( )p-|fpK()| = det MJ,K(p).
 S(J)

(. )

Thanks to this representation we can finish the proof of the theorem, case by case.

Case (i). Here, we immediately see that if J\K = J\I has more than elements, then the matrix M has two identical columns and its determinant is zero.

To treat the other cases, we introduce some final notations. We note E the × matrix with ones everywhere, and we
denote by  its characteristic polynomial  (z) = det(E - z). Since the eigenvalues of E are and - 1 zeroes, we have  (z) = ( - z)(-z) -1. Finally, we set w = 1 - p-1.

Case (ii). Here I = J = K, and by definition, ( . ) is nothing but the characteristic polynomial of Ek evaluated at w, so (I, J) = p2kk!k(w) = p2kk!(k - 1 + p-1)(p-1 - 1)k-1
which simplifies to the expression in the theorem.

Cases (iii-iv). Otherwise, J \ K only has one element, say i; without loss of generality we can suppose that i is the last element in J, so that we can do the following manipulations:

p-1 1 . . . . . . 1

p-1 1 . . . . . .

1

 

1

p-1 . . .

...

 

 

1

p-1 . . .

...

 

 det 


...

...

...

...

...

  

=

det

  

...

... ... ...

...

  

  

...

...

...

 p-1 1

  

...

. . . . . . p-1



1

 

1 ... ... 1 1

1 . . . . . . 1 p-1 + w

p-1 1 . . . . . . 1 

p-1 1 . . . 1 0 

 

1

p-1 . . .

...

 

 

1

p-1 . . .

...

...

 

 = det 


...

... ... ...

...

  + det  

...

... ...

1

...

  

  

...

...

. . . p-1



1

 

  

...

...

...

p-1



0

 

1 . . . . . . 1 p-1

1 ... ... 1 w

p-1 1 . . . . . . 1 

 

1

 = det 


...

  

...

p-1 . . . ... ... ... . . . . . . p-1

...

 

p-1

...







+

(-1)i+i

w

det

 











1 ...

1
p-1 ...

... ... ...

1

...

 



1

 

1

1 . . . 1 p-1

1 . . . . . . 1 p-1

and this is equal to k(w)+wk-1(w) = (-1)k-1wk-1. Overall, we obtain that in case (iii) where k = h, (I, J) = k!pk+1(1- p)k-1, and in case (iv) where k = h + 1, (I, J) = (k - 1)!pk(1 - p)k-1.

Proof of Theorem .
Once we have a sequence of converging random analytic functions, we obtain that the zero set of these functions converge towards the zero set of the limiting function. A complete statement can be seen in [Shi , Theorem . ]; we only state a minor result which matches our needs and we provide the proof, which is essentially the one in [Shi ].
Theorem . . Let fn be a sequence of random elements in Hr converging in law towards f . Let   D(0, r) (deterministic). We suppose that almost surely,  is the unique root of f inside D(0, r) and that it is simple. Then, for every small  > 0, the following statement holds almost surely: when n is large enough, fn has a unique zero n in D(0, r - ), it is simple, and |n - | < .

Proof. By Skorokhod's representation theorem, on a possibly enlarged probability space, we can find random analytic functions g, g1, g2, . . . such that g has the same law as f and gn has the same law as fn for every n, and such that gn  g in Hr almost surely on an event 0 with probability . On 0, we can apply Hurwitz's continuity theorem as in [S+ ], Theorem . . , cases (b)-(c): for every   0, for every  > 0, there is an N such that n > N, the function gn has exactly one zero in D(, ), and has no other zeroes in D(0, r - ).
Given this result, we note that Theorem . is a direct consequence of Theorem . and Theorem . .

Properties of the Poisson multiplicative function

. Radii of convergence of f and P

The radius of convergence rg of a series g(z) =

ak z k

is

given

by

Hadamard's

formula,

rg

=

(lim

sup

|ak

|

1 k

)-1.

For

Theorem

. , we first want to check that rf = 1/d and that rP 1/ d, where we recall that f, P were defined in ( . ). Since k1/k  1,

it will be enough te prove that

lim sup Xk1/k = d

( .)

and that



lim sup |Xk - k|1/k

d.

(.)

These two statements follow from elementary concentration results. The Chernoff bound for Poisson variables (see [BLM ] section . ) can be written as follows: if Z  Poi(), then

P(|Z - | t) exp -h t

+ exp

-h

t -

(.)





where h(x) We set t =

= (1+x) ln(1+x)-x. Let 2 ln( )  ; the right-hand

us apply side of (

this to our family of Poisson random . ) is then O( -2), and in particular

variables Y  it is summable.

Poi( ), where  = d / . The Borel-Cantelli lemma

ensures that

almost surely there is an 0 1 such that

d Y-

2 ln( ) d

for all > 0.

(.)

From this, we obtain a crucial point on the concentration of the random variables Xk.

Lemma . . Almost surely, there is a constant C such that for all k,

|Xk - k| ck2dk/2.

( .)

Moreover, k = dk(1 + o(1)).

Proof. The statement about k is trivial. For the first statement, note

Xk - d
|k

k

d

Y- .

=1

Statement ( . ) shows that almost surely, |Y - d / | is smaller than 2 ln( ) d / for 2 ln(k) dk/k, so

0, and this is again smaller than

|Xk - k|

0

d Y-

+ 2k2 ln(k)

dk .

k

(.)

=1

If we note c the first term, the LHS is smaller than (c + 1) × 2k2dk/2, a crude bound but which is largely enough for our needs.

Proof of ( . ). By the preceding lemma, |Xk| = dk(1 + o(1)) almost surely so ( . ) holds.

Proof of ( . ). By the preceding lemma, |Xk -  k|

2ck2

k d

almost surely so (

.

) holds.

. Infinite product representations

We now prove ( . ), ( . ) and ( . ). In all the sequel, log will refer to the principal branch of the complex logarithm, ie the one defined on C \ R-. We first see that for every z  D(0, 1),


f (z) =

Y

zk k

1

|k

=



Y

 (z )j j

k, =1

=1 j=1



= - Y log(1 - z ).

=1

The series inversions performed in these equalities are justified by the uniform convergence of f on compact subsets of D(0, 1/d), but they do not hold outside this set. As a consequence, e-f is itself well-defined in D(0, 1/d), analytic, and

N

e-f(z) =

lim e

N =1

Y

log(1-z

)=

lim

(1 - z )Y = ( . ).

N 

N 

=1

Now, we introduce L(z) = E[f (z)], which can be written as



zk

d.

k

k=1 |k

This is almost a Lambert function, but the presence of a k in the denominator actually makes it closer to a `log-Lambert' function. Since the series above is uniformly convergent on compact subsets of D(0, 1/d), we can reorder like we just did for f ,but in a slightly different way:


L(z) =

 zj d

j

=1 j=1


=

 (dzj )

j

=1 j=1

=  1  (dzj ) j
j=1 =1

=-



log(1 - dzj) .

(.)

j

j=1

By definition, -f (z) = P(z) - L(z), so the formula ( . ) in Theorem . is a consequence of the following proposition, whose main point is to extend the convergence of the preceding sum (minus the first term) to D(0, 1/ d).

Proposition . . For every |z| < 1/d,



e-L(z) =

1 - dz

=1
 and the infinite product is uniformly convergent on compact subsets of D(0, 1/ d).

Proof. The fact that this identity holds for |z| < 1/d follows from ( . ), since





J

exp(-L(z)) = exp  lim j-1 log(1 - dzj)
J j=1





J

= lim exp  j-1 log(1 - dzj)
J j=1

= lim (1 - dz) 2 1 - dz2 3 1 - dz3 · · · J 1 - dzJ
J



=

1 - dz .

=1

 To upgrade this convergence in D(0, 1/d) to uniform convergence on D(0, 1/ d), we note that



1 - dz

= (1 - dz)e

 j=2

j -1

log(1-dzj )

=1

 so it is sufficient to prove that the series of logs started at j = 2 is uniformly convergent on compact subsets of D(0, 1/ d). This is done by noting that if K is a compact in D(0, s) for some s < 1/ d, then for z  K one has |dzj| < ds2 < 1.

Note r = ds2 < 1. There is a constant cr such that for every |z| < r one has | log(1 + z)| < cr|z|, and consequently

 j=2

|j-1

log(1

-

dzj

)|

cr d

j-1rj so uniform convergence on K follows.

Remark . . By the same argument one can extend the uniform convergence of the infinite product to the set of z  D(0, 1) such that for every j 2, dzj / R- since we use the principal logarithm. This set can be described as D(0, 1) deprived of every segment semi-infinite line
{td-1/j j : t 1}
where j is a j-th root of unity and j spans {2, 3, . . . }.

. Secular moments and generating function

In the representation


F (z) = e-f(z) = (1 - z )Y ,
=1

the product is uniformly convergent on compact subsets of D(0, 1/d). We now seek the secular coefficients, ie the coefficient of zn in this series, noted cn = [zn]F (z). Clearly, cn1 · · · cnr = [z1n1 · · · zrnr ]F (z1) · · · F (zr). We note F (z) = F (z1) · · · F (zr).
Our goal is to express this as simply as possible to extract the coefficients. We have

r

Y

F (z) =

(1 - zs) .

=1 s=1

We recall that if X  Poi(), then E[zX ] = e(z-1). By independence,





r

Y

E[F (z)] = E  (1 - zs) 

=1

s=1



=

ed [

r s=1

(1-zs

)-1]

=1

= exp  d

r
(1 - zs) - 1

.

=1

s=1

With the convention that a product over an empty set is equal to 1, we have

r

(1 - zs) =

(-1)|S| zs =

(-1)|S|

s=1

S[r]

sS

S[r]

zs
sS

and consequently the sum inside the integral is equal to

d
=1

r
(1 - zs) - 1
s=1

=


(-1)|S|

d

S[r],S=

=1

sS zs

=

(-1)|S|-1 log 1 - d zs

S[r],S=

sS

=

log 1 - d zs -

log 1 - d zs

SOddr

sS

SEvenr

sS

where Oddr, Evenr denote the sets of nonempty subsets of [r] with an odd number of elements or with an even number of

elements. We obtain

E[f (z)] =

SOddr (1 - d sS zs) SEvenr (1 - d sS zs)

(.)

which is Theorem . . We gather some remarks on the combinatorics of set-partitions of multisets in Subsection . . When r = 1, there is only one nonempty subset of {1}, so

EF (z) = 1 - zd.

(.)

Equivalently, E[c0] = 1, E[c1] = -d and E[ck] = 0 for k > 1. When r = 2, the formula says that

E[F (z)F (w)]

=

(1

- zd)(1 - wd) (1 - zwd) .

This is also equal to

 k=0

dk

z

k

wk

(1

-

zd

-

wd

+

d2zw),

so

E[c2n] = dn + dn+1.

(. ) (. )

. Sobolev regularity

Remember that the Sobolev norm was defined in ( . ) as

F

2 s

=

(1

+

n2)s

|cn|2 dn

.

nZ

Since F is analytic, the sum only spans n 0, and by the preceding section, E[|cn|2] = dn(d + 1). As long as s < -1/2, we

have E[ F

2s] <  and consequently

F

2 s

<



almost

surely,

as

requested

in

Theorem

..

One can ask if the PHCd is not s-Sobolev for s > -1/2. The trick used in [NPS ], Section . can indeed be applied to our

setting: therein, it is proved by elementary means that for s < 0, there is a constant cs > 0 such that for r < 1,

F

2 s

cs | log r|2s



r2n|cn|2

=

cs | log r|2s

1 2

n=0

2 0

|F (reit)|2dt

=

cs | log r|2s

1 2

2
e2Re(f (z))dt
0

(. )

where the middle equality is Parseval's identity and the last one is the definition of F . Now, when f is a Gaussian analytic

function, the limit of this last integral with a suitable normalization term exists, and it is a real random variable representing the

total mass of the Gaussian Multiplicative Chaos. The existence of a limit is not trivial, and the identification of the distribution

of the limit (the Fyodorov-Bouchaud-Lie formula) was proved recently, see [R+ ] and [NPS ]. Given these, [NPS ] saw that

in the Gaussian case, the right-hand side of ( .

) converges to a random number times | log 0|, hence

F

2 s

=



and

F

is

not

s-Sobolev for s  [-1/2, 0). In our case where f is the Poisson function given by ( . ), the existence of a limit when r  d-1/2

of

1 2

2
e2
0

dt 
k=1

Xk

rk

cos(kt) k

is not known.

. The correlation of the Poisson Field

We close this section by a small remark which strenghthens the analogy between F and the Gaussian holomorphic chaos. 
Proposition . . f is log-correlated in the following sense: for every z, w  D(0, 1/ d),



Cov(f (z), f (w)) =

log

1 1 - dzw¯

1. 

(. )

=1 =1

Proof. Let us note Z = Y - d / . Since the Yi are independent, so are the Zi, and in particular E[ZiZj] = 0 if i = j, and E[Zi2] = Var(Yi) = di/i, and so





E[P(z)P(w)] =



zk

w¯h

E

 

kh 

ij

ZiZj

 



k,h=1

i|k

j|h

=  zkw¯h kh

i2E[Zi2]

k,h=1

idiv(h,k)

=  zkw¯h

d.

kh

k,h=1

div(h,k)

where div(a, b) denotes the set of common divisors of a and b. We can reorder the sum, and we get

E[P(z)P(w)] =

 za w¯b d

a ×b

=1 a,b=1


=

1

za w¯b d

ab

a,b=1

=1

=-



log(1 - dzaw¯b) .

ab

a,b=1

. Set-partitions of multisets

In this informal section, we give some remarks on the combinatorics of the generating function ( . ).
Let r 1 be an integer. We follow the terminology by Bender [Ben ]: given a multiset M on r elements, that is, M = {{1n1 , . . . , rnr }}, a set-partition of M is a multiset B = {{B1, . . . , Br}} of nonempty indistinguishable sets B1, . . . , Bh  [r], possibly repeated, such that their multiset-union is M . In other words, the Bj are subsets of [r] such that for every i  [r],

h
1iBj = ni.
j=0

The number of blocks in the multiset B will be noted |B|.

Example . . If M = {1, . . . , r} is a set, then this corresponds to the classical set-partitions of [r], counted by the Bell numbers Br. If M = {1n} (1 repeated n times) then the only set-partition of M is {1}, {1}, . . . , {1}. If M = {{14, 21, 32, 42}}, then a possible set-partition of M is
{1, 2, 3}, {1, 3, 4}, {1}, {1}, {3, 4}

and another one is

{1, 2, 3, 4}, {1, 3}, {1, 4}, {1}.

Now, let z1, . . . , zr be complex variables and q 1 a parameter. The multivariable function

G(z1, . . . , zr) =

1-q

S[r]

1 sS zs

is the generating function of set-partitions of multisets in the following sense; let us note

where the B

par(M , q) =

q|B|

BM

M means that the sum runs over all the set-partitions of the multiset M . Then,

G(z) =

par({{1n1 , . . . , rnr }}, q) × z1n1 . . . zrnr .

{{1n1 ,...,rnr }}

(. )

For instance, the coefficient of z1 . . . zr in G, when q = 1, is nothing but the classical number of partitions of [r], which is counted by the Bell numbers. Then, the generating function ( . ) is a weighted sum of set-partitions of multisets, such that the blocks with odd cardinality are all distincts. The weight is (-1)kd|B|, where k is the number of blocks with odd cardinality.
Remark . . A celebrated formula in combinatorics states that i 0(1 - z2i+1) = (-1)nps(n)zn, with ps(n) the number of self-conjugate partitions of n, see for instance [Aig , eqn. ( ) page ]. There is a chance that products like the SVrodd (1-dzS) appearing in ( . ) have a similar simple interpretation, but for the moment it is not clear for the author.

Proof of Theorem .
The goal of this section is to prove Theorem . . We chose to follow standard methods in path-counting combinatorics, but an alternative proof could use the Stein method to get a convergence speed.

. Usual preliminaries

Notations. When a is a positive integer, [a] is the set {1, . . . , a}. The falling factorials of a are (a)1 = a, (a)2 = a(a -

1), . . . , (a)k = a(a - 1) . . . (a - k + 1) and the binomial numbers

a k

= (a)k/k!. When E is a set, #E is the number of its

elements. A k-tuple of elements in a set E is a sequence (i1, . . . , ik) where the ik are elements of E , while a k-set of elements in

E is a set of k distincts elements in E . We note Ek the set of k-tuples of elements in [n] = {1, . . . , n}, that is:

Ek = {i = (i1, . . . , ik) : is  [n]}.

We will never indicate the dependencies in n, the size of the matrix A. However, every object encountered in the sequel depends on n, and every limit is with respect to n  .

In general, we will adopt the following notational rules: (i) Calligraphic letters are for sets. (ii) Boldface letters are for tuples, for instance i = (i1, . . . , ik).

Directed graphs. The matrix A is an n × n matrix with / entries. It represents the adjacency matrix of a digraph, on the vertex set V = [n]. The edge set is E = {(i, j)  [n] × [n] : Ai,j = 1}. We insist on the fact that G = (V, E) is directed and possibly has loops. We say that a digraph G = (V , E ) is weakly connected if, for any pair of distinct vertices i, j, there is a (weak) path from i to j, ie a sequence i0 = i, i1, . . . , ik = j such that for each s, (is-1, is)  E or (is, is-1)  E or both. Naturally, if this is the case one has #E - #V -1, with equality if ond only if G has no cycle, that is, G is an arborescence.

A-sub notation. For any tuple i = (i1, . . . , ik)  Ek, the shorthand Ai stands for:

Ai := Ai1,i2 × · · · × Aik-1,ik Aik,i1 .

( .)

It is the indicator that the cycle induced by i is present in G. With this notation,

tr(Ak) = Ai.
iEk

. Reduction to cycle count
For every i = (i1, . . . , ik)  Ek, we note

V (i) = {i1, . . . , ik} E(i) = {(i1, i2), (i2, i3), . . . , (ik-1, ik), (ik, i1)}

v(i) = #V (i) e(i) = #E(i).

Here are simple examples with a graphical representations. If an edge (i, j) is crossed twice or more in i, we represent it as many times, but it counts as one edge in E(i), see the middle figure.

9

7

5

3

8

3

2

4

1

1

3

i = (3, 5, 7, 7, 8)

j = (1, 9, 1, 9, 3)

k = (1, 2, 3, 4, 3, 2)

v(i) = 4 e(i) = 5

v(j) = 3 e(j) = 4

v(k) = 4 e(k) = 6

One can interpret v(i) as the number of `vertices' of [n] that are visited by i, and e(i) as the number of distinct `edges' of i. The digraph (V (i), E(i)) contains a loop, so necessarily v(i) e(i). On the other hand, there can be no more edges than the length of i, that is, e(i) k when i  Ek. Since the entries of A are independent / random variables, for every fixed i we have

E[Ai] =

d e(i) .
n

(.)

For every v e k, we set Ek(v, e) = {i  Ek, v(i) = v, e(i) = e}, and

Tk =

Ai,

ek v=e

iEk

(v,e)

Rk =

Ai

(.)

e k iEk(v,e) v<e

so that naturally tr(Ak) = Tk + Rk. Before stating a few technical lemmas, we recall the fact that k is a fixed integer.

Lemma . . #Ek(v, e) kknv.

Proof. We first choose which v vertices will be used, which gives

n v

nv. Then, we organize them them in a k-tuple so that

exactly e edges appear, but the number of ways to do this is certainly smaller than vk kk.

Lemma . . E[Rk] dkkk+2/n. Consequently, Rk  0 in probability and in distribution.

Proof. We use ( . ):
By the preceding lemma, E[Rk] inequality.

E[Rk] =

#Ek(v, e) ×

de .
n

v<e k

v<e kkdenv/ne. It is crudely bounded by dkkk+2n-1. The rest follows from the Markov

Lemma . . Ek(v, v) is empty if v is not a divisor of k. Otherwise, if k = vq, then the elements of Ek(v, v) are exactly the sequences

(i1, i2, . . . , iv, i1, . . . , iv, . . . , i1, . . . , iv)

(.)

where i1, . . . , iv are all distinct, and the subsequence i = (i1, . . . , iv) is repeated q times. Proof. Let i be in Ek(v, v). In the sequel, we will note s  [k + 1] the first time a vertex is revisited, that is:

s = min{t  {2, . . . , k + 1} : it  {i1, . . . , it-1}}.

If s = k + 1, then each it is present exactly once in i, so i is a cycle on k distinct vertices and v(i) = e(i) = k. Otherwise, s k, and i := (i1, . . . , is) has v(i ) = e(i ) = s.
If v(i) > v(i ), then i visits a `new' vertex j / i after s; but then, there will be a second cycle in i, and (V (i), E(i)) will have at least two cycles; if this was true, then we should have e(i) v(i) + 1, a contradiction.
No other vertices than the s vertices of i will thus be present in i; but since e(i) = v(i) = v(i ) = s, it also means that no other edge than E(i ) will be present in E(i). From this, it is easily seen that i consists in q repetitions of i for some q, and consequently that qs = k.

We now make a crucial observation. Let us fixe some integer . Let k = q be a multiple of , and let i  Ek( , ); by the lemma above, i is just some i = (i1, . . . , i ) repeated q times. But then, since A has only zero/one entries,
Ai = (Ai1,i2 × · · · × Ai ,i1 )q = Ai .
On the other hand, the lemma also shows that the elements in Ek( , ) are fully determined by their first terms, and thus #Ek( , ) = #E ( , ). Consequently, for every multiple k of ,

Ai =

Aj.

(.)

iEk( , )

jE ( , )

In other words, the preceding sum does not depend on k, but only on . But one can go further into simplifying this expression: the set E ( , ) is nothing but the set of -tuples of distinct elements, say (i1, . . . , i ); but if j is another such tuple, obtained from i by a cyclic permutation, say j = (i1+a, i2+a, . . . , ia), then Ai = Aj. For each i, there are exactly cyclic permutations of i; noting C the set of ordered -tuples of distinct elements of [n] up to cyclic permutation, it is now clear that for every k multiple

of ,

Ai =

Ai.

iEk( , )

iC

This is why we introduce the k-free notation S :

S := Ai.

(.)

iC

With this notation and the discussion above,

Tk = S .

|k

We now show that the random variables S are asymptotically Poisson independent random variables with paremeters d / , using the method of falling factorial moments.

Proposition . . Let m, 1, p1, . . . , m, pm be positive integers, with the i all distinct. Then,

d 1 p1

d m pm

lim E [(S
n

1 )p1

×

···

×

(S

m )pm ]

=

1

×···×
m

.

(.)

The proof of Proposition . will be the content of the next subsection; before that, we show how it directly implies the main result in Theorem . . We recall from Definition . that Y is a family if independent Poisson random variables, with parameter d/.

Proof of Theorem . . The Poisson distribution Z  Poi() is the unique probability distribution on nonnegative integers such that E[(Z)k] = k for all k 0. Consequently, the RHS of ( . ) is nothing but
E[(Y 1 )p1 × · · · × (Y m )pm ].
The joint convergence of the factorial moments described in ( . ) implies the convergence

(S 1 , . . . , S m ) -l-aw (Y 1 , . . . , Y m )

and in particular (S1, . . . , Sk) -l-aw (Y1, . . . , Yk) for any k. Since Tk = such that (T1, . . . , Tk) = g(S1, . . . , Sk); more precisely,

|k S , there is a fixed linear function g : Rk  Rk





g(x1, . . . , xk) = x1, x1 + 2x2, x1 + 3x3, x1 + 2x2 + 4x4, . . . , ixi .
i|k

Since tr(Ak) = Tk + Rk, we obtain (tr(A1, . . . , tr(Ak)) = g(S1, . . . , Sk) + (R1, . . . , Rk).
Lemma . says that Ri  0 in probability for every fixed i, so (R1, . . . , Rk)  (0, · · · , 0) in probability for every fixed k. Since g is continuous, Slutsky's lemma implies that

(T1, . . . , Tk) -l-aw g(Y1, . . . , Yk) = (X1, . . . , Xk)

which is the claim in Theorem . .

. Proof of Proposition .

For all the proof, we definitely fix the integer m 1, as well as the lengths 1, . . . , m and the powers p1, . . . , pm; all these numbers are assumed to be nonzero integers.

Definition . . Let , p be two integers. The ( , p)-loopsoup, noted S ,p, is the collection of ordered p-tuples of distinct cycles of length , that is, elements in C . The ( , p) loopsoup associated with = ( 1, . . . , m), p = (p1, . . . , pm) if the set S ,p = S 1,p1 × · · · × S m,pm , whose elements are m-tuples (c1, . . . , cm), with ci  S i,pi . The total number of cycles in a loopsoup is p1 + · · · + pm. The maximum number of i  [n] that appear in an element of S ,p is

M = M ( , p) = 1p1 + · · · + mpm.

(.)

Example . . A typical element of S ,p is a tuple of tuples. Let us take for instance = (2, 4) and p = (3, 6). An element of S ,p is (c1, c2) where c1 = (i1, i2, i3) and is are distinct 2-cycles, and c2 = (j1, j2, j3, j4, j5, j6) where the js are distinct 4-cycles.

If c = (c1, . . . , cm)  S ,p, we refer to the j-th element of ci as ci,j and we note

e(c) =

E(ci,j : i  [m], j  [pi])

i[m]

e(c) = #E(c).

It is the set of `edges' appearing in one of the p1 + · · · + pm cycles appearing in c. Since each ci,j is a cycle and thus has the same number of vertices and edges, we have e(c) M .

Lemma . . For any m 1 and = ( 1, . . . , m), p = (p1, . . . , pm), one has

m

E

(S i )pi =

d e(c) .
n

(.)

i=1

cS ,p

Proof. Sk is the number of k-cycles that appear in the graph induced by A, so (Sk)h is the number of ways to choose an h-tuple

of k-cycles that appear in the graph induced by A, that is: (Sk)k = (i1,...,ih)Sk,h Ai1 · · · Aih . We develop the product and

take the expectation:

m

E

(S i )pi

i=1

m pi

=

E

Aci,j =

cS ,p i=1 j=1

cS ,p

d e(c) .
n

In ( . ), we are going to split the sum according to the value of e(c)  [M ]: for every k M , we set S ,c(k) = {c  S ,p, e(c) = k}. It is clear that when we sort the summands in ( . ) according to this value of e, we obtain that it is equal to Z1 + · · · + ZM , where

Zk =

d n

k
#(S ,c(k)).

As expected, the dominant term in ( . ) is ZM . This is the content of the following proposition, which, considering the above discussion, finishes the proof of Theorem . .

Proposition . . There is a constant c = c( , p, d) > 0 such that for any n and k < M ,

#(S ,c(k)) cnk

(. )

Moreover,

m n i pi

#(S ,c(M )) = (1 + o(1))

.

(. )

i=1

i

Proof of ( . ). Let S be the subset of S ,c(M ) composed of those c which are completely vertex-disjoint, ie V (ci,k)V (cj,h) =  when (i, h) = (j, k). By elementary counting,

#S

=

(n)M

p1 1

×

·

··

×

pm .
m

Since M is fixed, this expression is equivalent to nM /

pi i

when

n



.

We

shall

now

prove

that

the

number

of

elements

in

S = S ,c(M ) \ S is o(nM ), which is well enough for our needs since #S ,c(M ) = #S + #S . If c is in S , it means

that two among the M distinct cycles of c visit one common vertex, and consequently that v(c) M - 1. Since and c are

fixed, for every set V  [n], there is a constant c such that there are less than c elements c  S ,c such that V (c) = V (one can take c = M M for instance), and so the number of elements in S is smaller than

c+c

n 2

+···+c

n M -1

,

an extremely crude bound, but still smaller than cnM-1 upon adjusting the constant c.

Proof of ( . ). The same argument applies. Consider an element c  S ,c(k) for k < M . The number of vertices v(c) present in c cannot be greater than k, since there are no more than k edges in c and at least one cycle. But for any subset V  [n] with v(c) elements, there is a constant c such that there are no more than c elements in S ,c with V (c) = V . Consequently,

#S ,c(k)

c+c

n 2

+···+c n . k

This is smaller than cnk for some (other) constant c, depending only on and c.

Acknowledgements
The author thanks the three authors of [BCGZ ] as well as Yizhe Zhu and Ludovic Stephan for various discussions on this method and comments on the paper. The author is supported by ERC NEMO, under the European Union's Horizon research and innovation programme grant agreement number .

References

[Aig ] Martin Aigner. A course in enumeration, volume . Springer Science & Business Media, .

[BC ]

Charles Bordenave and Benoît Collins. Eigenvalues of random lifts and polynomials of random permutation matrices. Ann. of Math. ( ), ( ): ­ , .

[BCC+ ] Charles Bordenave, Pietro Caputo, Djalil Chafaï, Konstantin Tikhomirov, et al. On the spectral radius of a random matrix: An upper bound without fourth moment. Annals of Probability, ( ): ­ , .

[BCGZ ] Charles Bordenave, Djalil Chafaï, and David García-Zelada. Convergence of the spectral radius of a random matrix through its characteristic polynomial, .

[BCN ] Charles Bordenave, Simon Coste, and Raj Rao Nadakuditi. Detection thresholds in very sparse matrix completion. arXiv preprint arXiv: . , .

[BDH ] Gerandy Brito, Ioana Dumitriu, and Kameron Decker Harris. Spectral gap in random bipartite biregular graphs and applications, .

[Ben ] Edward A. Bender. Partitions of multisets. Discrete Mathematics, ( ): ­ , .

[BLM ] Stéphane Boucheron, Gábor Lugosi, and Pascal Massart. Concentration inequalities: A nonasymptotic theory of independence. Oxford university press, .

[BLM ]

Charles Bordenave, Marc Lelarge, and Laurent Massoulié. Non-backtracking spectrum of random graphs: community detection and non-regular ramanujan graphs. In IEEE th Annual Symposium on Foundations of Computer Science, pages ­ . IEEE,
.

[Bor ] [BR+ ]

Charles Bordenave. A new proof of friedman's second eigenvalue theorem and its extension to random lifts. arXiv preprint arXiv: . , .
Anirban Basak, Mark Rudelson, et al. The circular law for sparse non-hermitian matrices. Annals of Probability, ( ): ­ , .

[BZ ]

Anirban Basak and Ofer Zeitouni. Outliers of random perturbations of toeplitz matrices with finite symbols. Probability Theory and Related Fields, ( ): ­ , .

[Cos ] Simon Coste. The spectral gap of sparse random digraphs. In Annales de l'Institut Henri Poincaré, Probabilités et Statistiques, volume , pages ­ . Institut Henri Poincaré, .

[CS ] Simon Coste and Ludovic Stephan. A simpler spectral approach for clustering in directed networks, .

[DG ] Persi Diaconis and Alex Gamburd. Random matrices, magic squares and matching polynomials. Electron. J. Combin., ( ):Research Paper , , / .

[DJPP ] Ioana Dumitriu, Tobias Johnson, Soumik Pal, and Elliot Paquette. Functional limit theorems for random regular graphs. Probability Theory and Related Fields, ( - ): ­ , .

[DS ]

Persi Diaconis and Mehrdad Shahshahani. On the eigenvalues of random matrices. volume A, pages ­ . . Studies in applied probability.

[FK ] Z. Füredi and J. Komlós. The eigenvalues of random symmetric matrices. Combinatorica, ( ): ­ , .

[FK ]

Yan V Fyodorov and Jonathan P Keating. Freezing transitions and extreme values: random matrix theory, and disordered landscapes.

Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, ( ):

,.

[Fri ] Joel Friedman. A proof of Alon's second eigenvalue conjecture and related problems. American Mathematical Soc., .

[ JM ] Tiefeng Jiang and Sho Matsumoto. Moments of traces of circular beta-ensembles. The Annals of Probability, ( ): ­ , .

[Kah ] Jean-Pierre Kahane. Some random series of functions, volume . Cambridge University Press, .

[LMNR ] Fernando Lucas Metz, Izaak Neri, and Tim Rogers. Spectral theory of sparse non-hermitian random matrices. Journal of Physics A:

Mathematical and Theoretical, ( ):

, Oct .

[Nil ] Alon Nilli. On the second eigenvalue of a graph. Discrete Mathematics, ( ): ­ , .

[NPS ] [R+ ]

Joseph Najnudel, Elliot Paquette, and Nick Simm. Secular coefficients and the holomorphic multiplicative chaos, .
Guillaume Remy et al. The fyodorov­bouchaud formula and liouville conformal field theory. Duke Mathematical Journal, ,.

( ): ­

[RT ]

Mark Rudelson and Konstantin Tikhomirov. The sparse circular law under minimal assumptions. Geometric and Functional Analysis, ( ): ­ , .

[RV ] [S+ ]

Rémi Rhodes and Vincent Vargas. Gaussian multiplicative chaos and applications: a review, . Barry Simon et al. A comprehensive course in analysis. American Mathematical Society Providence, Rhode Island, .

[Shi ]

Tomoyuki Shirai. Limit theorems for random analytic functions and their zeros: Dedicated to the late professor yasunori okabe (functions in number theory and their probabilistic aspects). RIMS Kokyuroku Bessatsu, : ­ , .

[Zhu ] Yizhe Zhu. On the second eigenvalue of random bipartite biregular graphs. arXiv preprint arXiv: . , .

