
# Evidential Turing Processes

[arXiv](https://arxiv.org/abs/2106.01216), [PDF](https://arxiv.org/pdf/2106.01216.pdf)

## Authors

- Melih Kandemir
- Abdullah Akgül
- Manuel Haussmann
- Gozde Unal

## Abstract

A probabilistic classifier with reliable predictive uncertainties i) fits successfully to the target domain data, ii) provides calibrated class probabilities in difficult regions of the target domain (e.g. class overlap), and iii) accurately identifies queries coming out of the target domain and reject them. We introduce an original combination of evidential deep learning, neural processes, and neural Turing machines capable of providing all three essential properties mentioned above for total uncertainty quantification. We observe our method on three image classification benchmarks and two neural net architectures to consistently give competitive or superior scores with respect to multiple uncertainty quantification metrics against state-of-the-art methods explicitly tailored to one or a few of them. Our unified solution delivers an implementation-friendly and computationally efficient recipe for safety clearance and provides intellectual economy to an investigation of algorithmic roots of epistemic awareness in deep neural nets.

## Comments



## Source Code

Official Code

- [https://github.com/ituvisionlab/EvidentialCalibration](https://github.com/ituvisionlab/EvidentialCalibration)

Community Code

- [https://paperswithcode.com/paper/evidential-turing-processes](https://paperswithcode.com/paper/evidential-turing-processes)

## Bibtex

```tex
@misc{kandemir2021evidential,
      title={Evidential Turing Processes}, 
      author={Melih Kandemir and Abdullah Akgül and Manuel Haussmann and Gozde Unal},
      year={2021},
      eprint={2106.01216},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```

## Notes

Type your reading notes here...

