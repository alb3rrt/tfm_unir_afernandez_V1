
# Statistical embedding: Beyond principal components

[arXiv](https://arxiv.org/abs/2106.01858), [PDF](https://arxiv.org/pdf/2106.01858.pdf)

## Authors

- Dag Tjøstheim
- Martin Jullum
- Anders Løland

## Abstract

There has been an intense recent activity in embedding of very high dimensional and nonlinear data structures, much of it in the data science and machine learning literature. We survey this activity in four parts. In the first part we cover nonlinear methods such as principal curves, multidimensional scaling, local linear methods, ISOMAP, graph based methods and kernel based methods. The second part is concerned with topological embedding methods, in particular mapping topological properties into persistence diagrams. Another type of data sets with a tremendous growth is very high-dimensional network data. The task considered in part three is how to embed such data in a vector space of moderate dimension to make the data amenable to traditional techniques such as cluster and classification techniques. The final part of the survey deals with embedding in $\mathbb{R}^2$, which is visualization. Three methods are presented: $t$-SNE, UMAP and LargeVis based on methods in parts one, two and three, respectively. The methods are illustrated and compared on two simulated data sets; one consisting of a triple of noisy Ranunculoid curves, and one consisting of networks of increasing complexity and with two types of nodes.

## Comments



## Source Code

Official Code



Community Code

- [https://paperswithcode.com/paper/statistical-embedding-beyond-principal](https://paperswithcode.com/paper/statistical-embedding-beyond-principal)

## Bibtex

```tex
@misc{tjøstheim2021statistical,
      title={Statistical embedding: Beyond principal components}, 
      author={Dag Tjøstheim and Martin Jullum and Anders Løland},
      year={2021},
      eprint={2106.01858},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
```

## Notes

Type your reading notes here...

