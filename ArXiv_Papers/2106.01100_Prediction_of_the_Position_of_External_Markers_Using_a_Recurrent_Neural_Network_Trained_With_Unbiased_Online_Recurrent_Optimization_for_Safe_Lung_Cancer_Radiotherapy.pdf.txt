Preprint submitted to Artificial Intelligence in Medicine

arXiv:2106.01100v1 [eess.IV] 2 Jun 2021

Prediction of the Position of External Markers Using a Recurrent Neural Network Trained With Unbiased Online Recurrent Optimization for Safe Lung Cancer Radiotherapy
Michel Pohl · Mitsuru Uesaka · Hiroyuki Takahashi · Kazuyuki Demachi · Ritu Bhusal Chhatkuli

Abstract During lung cancer radiotherapy, the position of infrared reflective objects on the chest can be recorded to estimate the tumor location. However, radiotherapy systems usually have a latency inherent to robot control limitations that impedes the radiation delivery precision. Not taking this phenomenon into account may cause unwanted damage to healthy tissues and lead to side effects such as radiation pneumonitis. In this research, we use nine observation records of the three-dimensional position of three external markers on the chest and abdomen of healthy individuals breathing during intervals from 73s to 222s. The sampling frequency is equal to 10Hz and the amplitudes of the recorded trajectories range from 6mm to 40mm in the superior-inferior direction. We forecast the location of each marker simultaneously with a horizon value (the time interval in advance for which the prediction is made) between 0.1s and 2.0s, using a recurrent neural network (RNN) trained with unbiased online recurrent optimization (UORO). We compare its performance with an RNN trained with real-time recurrent learning, least mean squares (LMS), and offline linear regression. Training and cross-validation are performed during the first minute of each sequence. On average, UORO achieves the lowest root-mean-square (RMS)
Michel Pohl The University of Tokyo, 113-8654 Tokyo, Japan E-mail: michel-pohl@g.ecc.u-tokyo.ac.jp, michel.pohl@centrale-marseille.fr
Mitsuru Uesaka Japan Atomic Energy Commission, 100-8914 Tokyo, Japan
Hiroyuki Takahashi · Kazuyuki Demachi The University of Tokyo, 113-8654 Tokyo, Japan
Ritu Bhusal Chhatkuli National Institutes for Quantum and Radiological Science and Technology, 263-8555 Chiba, Japan

and maximum error, equal respectively to 1.3mm and 8.8mm, with a prediction time per time step lower than 2.8ms (Dell Intel core i9-9900K 3.60Ghz). Linear regression has the lowest RMS error for the horizon values 0.1s and 0.2s, followed by LMS for horizon values between 0.3s and 0.5s, and UORO for horizon values greater than 0.6s.
Keywords Radiotherapy · Respiratory motion management · External markers · Recurrent neural network · Online training
1 Introduction
1.1 External markers in lung cancer radiotherapy
The National Cancer Institute estimates that 236,000 new cases of lung and bronchus cancer will appear in the United States in 2021. Furthermore, it estimates that 132,000 deaths will occur in 2021, making up 21.7% of all cancer deaths [30].
During lung cancer radiotherapy, respiratory motion makes tumor targeting difficult. Indeed, tumors can move up to 5cm within the same treatment fraction due to breathing [3]. Respiratory motion is largely cyclic but exhibits changes in frequency and amplitude, shifts and drifts, and varies across patients and fractions [41, 5]. The term "shift" designates abrupt changes of the respiratory signal, whereas "drift" designates continuous variations of the mean tumor position. Baseline drifts of 1.65±5.95 mm (mean position ± standard deviation) in the craniocaudal direction have been observed in [38]. To overcome this problem, the position of external markers placed on the chest and abdomen can be recorded by infrared cameras (e.g. Cyberknife system [14] in Fig. 1). By using an appropriate correspondence

2

Michel Pohl et al.

model, these positions may be correlated to the threedimensional (3D) position and shape of the tumor for accurate irradiation [5, 25].
Fig. 1: Radiotherapy treatment system (Cyberknife) using external markers to guide the irradiation beam1.
1.2 Compensation of treatment system latency via prediction
Radiotherapy treatment machines are subject to a time latency due to communication delays, robot control, and radiation system delivery preparation. Verma et al. reported that "for most radiation treatments, the latency will be more than 100ms, and can be up to two seconds" [41]. Delay compensation is necessary to minimize excessive damage to healthy tissues (Fig. 2), and to achieve this, various prediction methods have been proposed [41, 18, 11]. Among those methods, artificial neural networks (ANNs) with different architectures and training algorithms have been studied in the context of radiotherapy [28, 36, 9, 13, 26, 6, 27, 19, 15, 20, 4, 37, 12, 43, 40, 21, 46, 22, 45, 17, 42, 32]. ANNs are efficient for performing prediction with a high response time, which is the time interval in advance for which the prediction is made, also called the look-ahead time or horizon, and for non-stationary and complex signals. However, they are heavily computer resource intensive and have high processing times [41]. Furthermore, deep ANNs need large amounts of data for training which can be practically difficult because of patient data regulations, and the prediction results are strongly dependent on the database chosen. Tumor motion is essentially three-dimensional, but most of the previous works about ANNs applied to respiratory motion man-
1 Adapted from [35] with permission from Wiley, Copyright 2004 American Association of Physicists in Medicine.

agement in radiotherapy focused on one-dimensional time-series forecasting.
Recurrent neural networks (RNNs) are characterized by a feedback loop that acts as a memory and enables the retention of information over time. They are able to efficiently learn features and long-term dependencies from sequential and time-series data [34]. As a result, almost all of the recent research about ANNs applied to time series forecasting for motion management in radiotherapy focuses on RNNs [12, 43, 46, 21, 22, 45, 17, 42, 32]. RNN models such as long short term memory (LSTM) networks have also been used in related medical data processing problems such as cardiorespiratory motion prediction from X-ray angiography sequences [1] and next-frame prediction in medical image sequences, including chest dynamic imaging [29, 33].
Our research investigates the feasibility to predict breathing motion with online training algorithms for RNNs. In contrast to offline methods, online methods update the synaptic weights with each new training example. That enables the neural network to adapt to the continuously changing breathing patterns of the patient (section 1.1), therefore providing robustness to complex motion. Because online learning enables adaptation to examples unseen in the training set, it can be viewed as a way to compensate for the difficulty of acquiring and using large training databases for medical applications. Adaptive or dynamic learning has been applied many times to radiotherapy, and several studies demonstrated the benefit of that approach in comparison with static models [15, 40, 22]. Real-time recurrent learning (RTRL) [44, 8] is one of these dynamic approaches that has already been used for predicting tumor motion from the Cyberknife Synchrony system [22] and the position of internal points in the chest [32].
Many techniques for online training of RNNs have recently emerged [23], such as unbiased online recurrent optimization (UORO) [39]. Most of these seek to approximate RTRL, which suffers from a large computational complexity. They also aim to provide an unbiased estimation of the gradient estimates, that truncated back-propagation through time (truncated BPTT) [10, 8] cannot compute, therefore guaranteeing theoretical convergence and appropriate balance between shortterm and long-term temporal dependencies. The theoretical convergence of RTRL and UORO, which could not be proved by standard stochastic gradient descent theory, has recently been established [24].
2 Reprinted from [32], Copyright 2021, with permission from Elsevier.

Prediction of the Position of External Markers With UORO for Safe Radiotherapy

3

motion is normal and in the four remaining sequences, the individuals were asked to perform actions such as talking or laughing. More details concerning the dataset can be found in [16].

output vector yn+1

2.2 The RTRL and UORO algorithms for training RNNs

Fig. 2: Excessive irradiation of healthy lung tissue due to an overall system delay t not compensated. The area irradiated, represented here using diagonal stripes, is larger than the tumor size, to take into consideration effects such as the variation of the tumor shape during the treatment2.
1.3 Content of this study
This is the first study to evaluate the capabilities of RNNs trained online with UORO to predict the 3D position of external markers on the chest and abdomen for safety in radiotherapy. The proposed RNN model does not perform prediction for each marker separately but instead learns patterns about the correlation between their motion to potentially increase its forecasting accuracy. We compare UORO with different forecasting algorithms, namely RTRL, least mean squares (LMS), and linear regression, for different look-ahead values h, ranging from hmin = 0.1s to hmax = 2.0s, by observing different prediction metrics as h varies. We divide the subjects' data into two groups: regular and irregular breathing, to quantify the robustness of each prediction algorithm. We analyze the influence of the hyperparameters on the prediction accuracy of UORO as the horizon value changes and discuss the selection of the best hyper-parameters.
2 Materials and Methods
2.1 Marker position data
In this study, we use 9 records of the 3D position of 3 external markers on the chest and abdomen of individuals lying on a treatment couch (HexaPOD), acquired by an infrared camera (NDI Polaris). The duration of each sequence is between 73s and 320s and the sampling rate is 10Hz. The superior-inferior, left-right, and anteroposterior trajectories respectively range between 6mm and 40mm, between 2mm and 10mm, and between 18 mm and 45mm. In five of the sequences, the breathing

input vector un

state vector xn

In this study, we train an RNN with one hidden layer to predict the position of the 3 markers in the future. RNNs with one hidden layer are characterized by the state equation, which describes the dynamics of the internal states, and the measurement equation, which describes how the RNN output is influenced by the hidden states (Eq. 1). In the following, we denote by un  Rm+1, xn  Rq, yn  Rp, and n the input, state, output, and synaptic weight vectors at time tn. Fig. 3 gives a graphical representation of these two equations.
xn+1 = Fst(xn, un, n) yn = Fout(xn, n) (1)

1
xn xkn xqn
1
un

1
xn+1 xkn+1
q
xn+1

yn1+1
p
yn+1

umn +1
hidden layer output layer
Fig. 3: Structure of the RNN predicting the position of the markers. The input vector un corresponds to the positions in the past and the output vector yn+1 corresponds to the predicted positions3.

The instantaneous square loss Ln of the network can
be calculated from the instantaneous error en between the correct output yn and predicted output yn (Eq. 2).

en = yn - yn

1 Ln = 2

en

2 2

(2)

3 Reprinted from [32], Copyright 2021, with permission from Elsevier.

4
By using the chain rule, one can derive Eqs. 3 and 4, which describe how changes of the parameter vector n affect the instantaneous loss Ln+1 and state vector xn+1. Computation of the gradient of Ln+1 with respect to the parameter vector using Eq. 3, followed by recursive computation of the influence matrix xn/ using Eq. 4 constitutes the RTRL algorithm. RTRL is computationally expensive, and UORO attempts to solve that problem by approximating the influence matrix with an unbiased rank-one estimator. In UORO, two random column vectors x~n and ~n are recursively updated at each time step so that E(x~n~nT ) = xn/ (cf Appendix A).

Ln+1 

=



Ln+1 y

(yn+1

)



Fout x

(xn,

n)

xn 

+

Fout 

(xn,

n

)

(3)

xn+1 

=

Fst x

(xn

,

un

,

n)

xn 

+

Fst 

(xn,

un,

n)

(4)

position
Past

Michel Pohl et al.
Future
horizon

time

tn

tn+L-1 tn+L+h-1

Fig. 4: Forecasting a 1D position signal. The signal history length L is the time interval in the past, the information of which is used for performing one prediction. The horizon h, also called response time or look-ahead time, is the time interval in advance for which the prediction is made (cf Eq. 5).

and Wc,n of respective size q × q, q × (m + 1), and p × q.  is the nonlinear activation function and we use here the hyperbolic tangent function (Eq. 8).

Fst(xn, un, n) = (Wa,nxn + Wb,nun)

(6)

2.3 Online prediction of the position of the markers with a vanilla RNN
If we denote by uj(tk) = [uxj (tk), uyj (tk), uzj (tk)] the normalized 3D displacement of marker j at time tk, the input un of the RNN consists of the concatenation of the vectors uj(tn), ..., uj(tn+L-1) for each marker j, where L designates the signal history length (SHL), expressed here in number of time steps. The prediction of the displacement of the 3 markers is performed simultaneously to use information about the correlation between each of them. The output vector yn+1 consists of the position of these 3 points at time tn+L+h-1, where h refers to the horizon value, expressed also in number of time steps (Eq. 5).

1

 ux1 (tn) 

 

uy1 (tn )

 

 

uz1 (tn )

 

un

=

 

...

 

 

uz3 (tn )

 

  

ux1 (tn+1)

  

 ... 

uz3 (tn+L-1 )

ux1 (tn+L+h-1)

uy1 (tn+L+h-1)

yn+1 = uz1(tn+L+h-1) (5)





 ... 

uz3 (tn+L+h-1 )

In this work, we use a vanilla RNN structure, described by Eqs. 6 and 7, where the parameter vector n consists of the elements of the matrices Wa,n, Wb,n,

Fout(xn, n) = Wc,nxn

(7)

z1 tanh(z1)

 ... =  ... 

(8)

zq

tanh(zq )

RNNs updated by the gradient rule may be unstable. We prevent large weight updates by clipping the gradient norm to avoid numerical instability [31]. The optimizer is stochastic gradient descent. The implementation of the UORO algorithm in the case of the vanilla model described above is detailed in Appendix A. The RNN characteristics are summarized in Table 1.

2.4 Experimental design
We compare RNNs trained with UORO with other prediction methods: RNNs trained with RTRL, LMS [7], and multivariate linear regression (Table 2). We clipped the gradient estimate of the instantaneous loss (Eq. 2) with respect to the parameter vector (Ln) for UORO, RTRL, and LMS when (Ln) 2 >  with the same threshold value  = 2.0 for these three algorithms.
Learning is performed using only information from the sequence that is used for testing. Each time series is split into a training and development set of 1 min and the remaining test set. The training set comprises

Prediction of the Position of External Markers With UORO for Safe Radiotherapy

5

RNN characteristic Output layer size Input layer size Number of hidden layers Size of the hidden layer Activation function  Training algorithm Optimization method
Weights initialization Input data normalization Cross-validation metric Nb. of runs for cross-val. Nb. of runs for evaluation

p = 3nM m = 3nM L 1 q Hyperbolic tangent RTRL or UORO Stochastic grad. descent with gradient clipping Gaussian Yes (online) RMSE (Eq. 10) ncv = 50 ntest = 300

Table 1: Configuration of the RNN forecasting the motion of the external markers. nM refers to the number of external markers and L to the SHL.

1

kmax 3

M AE

=

3(kmax

-

kmin

+

1)

k=kmin

j (tk)
j=1

(12)

emax =

max

max j(tk)

k=kmin ,...,kmax j =1,2,3

(13)

Furthermore, we examine the jitter of the test set, which evaluates the amplitude of the predicted signal oscillations (Eq. 14). High fluctuations of the prediction signal result in difficulties concerning robot control during the treatment. The jitter J is minimized when the prediction is constant, thus there is a trade-off between accuracy and jitter [16].

the data between 0s and 30s except in the case of linear regression as using more data is beneficial to offline methods. The hyper-parameters that minimize the root-mean-square error (Eq. 10) of the cross-validation set during the grid search process are selected for evaluation. The term j(tk) in Eq. 10 designates the instantaneous prediction error at time tk due to marker j, defined in Eq. 9.

j (tk) = upjred(tk) - utjrue(tk) 2

(9)

RM SE =

3(kmax

1 - kmin

+

1)

kmax k=kmin

3 j=1

j (tk)2

(10)

To analyze the forecasting performance of each algo-

rithm, we compute the RMSE, but also the normalized

RMSE (Eq. 11), mean average error (Eq. 12), and maximum error (Eq. 13) of the test set. In Eq. 11, µtjrue designates the mean 3D position of marker j on the test

set. Because the weights of the RNNs are initialized

randomly, given each set of hyper-parameters, we aver-

age the RMSE of the cross-validation set over ncv = 50 successive runs. Then, during performance evaluation,

each metric is averaged over ntest = 300 runs.

nRM SE =

kmax k=kmin

3 j=1

j (tk)2

kmax k=kmin

3 j=1

µtjrue - utjrue(tk)

2 2

(11)

1

kmax-1 3

J=

3(kmax - kmin) k=kmin j=1

upj red(tk+1) - upj red(tk)

2

(14)

We assume that given an RNN training method,
each associated error measure ei,h (the MAE, RMSE,
nRMSE, maximum error, or jitter) corresponding to
sequence i and horizon h follows a Gaussian distribution N (µi,h, i2,h). Indeed, each realization of the random variable ei,h depends on the run index r  [[1, ..., ntest]], and we denote that value e(i,rh). This enables calculating the 95% confidence interval [µi,h - µi,h, µi,h + µi,h] for µi,h, where µi,h is defined in Eq. 16. 4

2i,h

=

1 ntest - 1

ntest r=1

e(i,rh) - µi,h

2

(15)

µi,h

=

1.96 i,h ntest

(16)

The mean of the error ei,h over a subset I  [[1, ..., 9]] of the 9 sequences5and h  H = {hmin, ..., hmax}, denoted by eI , follows a Gaussian distribution with mean µI . The half-range of the 95% confidence interval for µI , denoted by µI , can be calculated according to Eq. 17.

1 µI = |I| |H|

hmax
(µi,h)2
iI h=hmin

(17)

6

Michel Pohl et al.

Prediction method RNN UORO
RNN RTRL
LMS
Linear regression

Mathematical model xn+1 = (Wa,nxn + Wb,nun) yn = Wc,nxn
xn+1 = (Wa,nxn + Wb,nun) yn = Wc,nxn
yn+1 = Wnun
yn+1 = W un

Development set partition Training 30s Cross-validation 30s
Training 30s Cross-validation 30s
Training 30s Cross-validation 30s
Training 54s Cross-validation 6s

Range of hyper-parameters for cross-validation
  {0.05, 0.1, 0.2} init  {0.02, 0.05} L  {10, 30, 50, 70, 90} q  {10, 30, 50, 70, 90}   {0.02, 0.05, 0.1, 0.2} init  {0.01, 0.02, 0.05} L  {10, 25, 40, 55} q  {10, 25, 40, 55}   {0.002, 0.005, 0.01,
0.02, 0.05, 0.1, 0.2} L  {10, 30, 50, 70, 90} L  {10, 20, 30, 40, 50,
60, 70, 80, 90}

Table 2: Overview of the different forecasting methods compared in this study. The input vector un, corresponding to the positions in the past, and the output vector yn+1, corresponding to the predicted positions, which appear in the second column, are defined in Eq. 5. The fourth column describes the hyper-parameter range for crossvalidation with grid search.  refers to the learning rate, init to the standard deviation of the initial Gaussian distribution of the synaptic weights, L to the SHL (expressed in number of time steps), and q to the number of hidden units. Wn and W are matrices used respectively in LMS and linear regression, and their size is p × (m + 1).

3 Results and Discussion
3.1 Prediction accuracy and oscillatory behavior of the predicted signal
UORO achieves the lowest RMSE, nRMSE and maximum error averaged over all the sequences and horizons (cf Table 3). It is relatively robust to irregular motion, as its nRMSE only increases by 10.6% between regular and irregular breathing. LMS is subject to high jitter values (cf also Fig. 5, Fig. 6, Fig. 7, and Fig. 11). The high maximum errors corresponding to RTRL, relative to UORO and LMS, can be observed in Fig. 12. The narrow 95% confidence intervals associated with the performance measures reported in Table 3 indicate that selecting ntest = 300 runs is sufficient for providing accurate results.
4 We write µi,h instead of µi,h and i,h instead of i,h to designate estimators of these parameters given the ntest runs.
5 When I is the set [[1, ..., 9]], the confidence intervals calculated are those associated with the 9 records. Otherwise, we select I as the set of indexes associated with the regular or irregular breathing sequences.
6 Sequence 201205111057-LACLARUAR-3-O-72 (cf [16]) has been removed from the sequences with abnormal respiratory motion when reporting performance measures in the last column, as it does not contain abrupt or sudden motion that typically makes forecasting difficult. In particular, this is why the nRMSE of UORO averaged over the 9 sequences is lower than nRMSE of UORO averaged over the regular or irregular breathing sequences.

The graphs representing the performance of each algorithm as a function of the horizon value h appear to have irregular and changing local variations, especially in the case of RTRL and LMS, because the set of hyperparameters automatically selected by cross-validation is different for each horizon value (Fig. 5). These instabilities may also be caused by the relatively low number of breathing records in our dataset. However, it can be observed that the prediction errors and jitter of the test set corresponding to each algorithm globally tend to increase with h.
Linear regression achieves the lowest RMSE and nRMSE for h  0.2s as well as the lowest MAE and maximum error for h = 0.1s. The RMSE corresponding to linear regression for h = 0.2s is equal to 0.92mm. LMS gives the lowest RMSE for 0.3s  h  0.5s, the lowest MAE for 0.2s  h  0.4s, the lowest nRMSE for h = 0.3s and h = 0.4s, and the lowest maximum error for 0.4s  h  0.6s. The RMSE corresponding to LMS for h = 0.5s is equal to 1.23mm. UORO outperforms the other algorithms in terms of RMSE for h  0.6s and maximum error for h  0.7s. The RMSE given by UORO is rather constant and stays below 1.33mm across all the horizon values considered. RTRL and UORO both have a lower prediction MAE than LMS for h  0.5s. Our analysis of the influence of the latency on the relative performance of linear filters, adaptive filters, and ANNs agrees with the review of Verma et al. [41] (cf section 1.2).

Prediction of the Position of External Markers With UORO for Safe Radiotherapy

7

Error measure MAE (in mm)
RMSE (in mm)
nRMSE (no unit)
Max error (in mm)
Jitter (in mm)

Prediction method
RNN UORO RNN RTRL LMS Lin. regression No prediction RNN UORO RNN RTRL LMS Lin. regression No prediction RNN UORO RNN RTRL LMS Lin. regression No prediction RNN UORO RNN RTRL LMS Lin. regression No prediction RNN UORO RNN RTRL LMS Lin. regression No prediction

Average over the 9 sequences
0.845 ± 0.001 0.834 ± 0.002 0.957 4.45 3.27 1.275 ± 0.001 1.419 ± 0.005 1.370 6.089 4.243 0.2824 ± 0.0002 0.3027 ± 0.0007 0.3116 1.411 0.9312 8.81 ± 0.01 11.68 ± 0.04 9.31 30.6 14.8 0.9672 ± 0.0004 0.7532 ± 0.0015 1.596 0.7767 0.4395

Regular breathing
0.674 ± 0.001 0.684 ± 0.002 0.907 3.23 2.89 1.030 ± 0.001 1.119 ± 0.004 1.247 4.454 3.952 0.2868 ± 0.0004 0.2914 ± 0.0008 0.2987 1.181 1.006 7.20 ± 0.02 10.01 ± 0.04 8.59 23.2 13.9 0.7778 ± 0.0002 0.6494 ± 0.0012 1.646 0.6011 0.3877

Irregular breathing6
0.916 ± 0.001 0.973 ± 0.003 1.18 6.57 3.43 1.505 ± 0.002 1.721 ± 0.005 1.818 9.164 4.461 0.3211 ± 0.0004 0.3688 ± 0.0010 0.4198 2.132 0.9833 12.34 ± 0.02 14.56 ± 0.06 12.9 49.0 18.2 0.9973 ± 0.0007 0.8735 ± 0.0014 1.724 1.078 0.5045

Table 3: Comparison of the forecasting performance of each algorithm. Each error value corresponds to the average of a given performance measure of the test set over the sequences considered and the horizon values between 0.1s and 2.0s. The 95% mean confidence intervals associated with the RNNs are calculated assuming that the error distribution is Gaussian (Eq. 17).

The jitter associated with RTRL and UORO respectively increases from 0.71mm and 0.94mm for h = 0.1s to 0.78mm and 0.96mm for h = 2.0s. However, the jitter associated with linear regression and LMS increases more significantly with h. The jitter corresponding to linear regression is the lowest among the four prediction methods for h  0.6s.
The performance of each algorithm as a function of the horizon in the cases of normal breathing and abnormal breathing is detailed in Appendix D. The local unsteadiness of the variations of each performance measure with h in Figs. 13 and 14 is more pronounced than in Fig. 5 because both situations involve averaging results over fewer respiratory traces. However, it still appears that the prediction errors globally tend to increase with h in both cases. UORO performs better than the other algorithms for lower horizon values in the scenario of abnormal breathing. Indeed, it achieves the lowest RMSE and nRMSE for h  0.3s, and the

lowest MAE for h  0.2s (RTRL and UORO achieve comparable performance for higher horizons in terms of MAE).
3.2 Influence of the hyper-parameters on prediction accuracy
The prediction nRMSE of the cross-validation set tends to increase as the horizon value h increases (Fig. 8). On average over the 9 sequences and all the horizon values,  = 0.1 and L = 7.0s give the best prediction results. However, for h = 2.0s, a higher learning rate  = 0.2 and a lower value of the SHL L = 5.0s give better results (Figs. 8a, 8c). In other words, when performing prediction with a high look-ahead time, it is better to make the RNN more dependent on the recent inputs, and quickly correct the synaptic weights when large prediction errors occur. In our experimental set-

8

Michel Pohl et al.

Fig. 5: Forecasting performance of each algorithm as a function of the prediction horizon. Each point corresponds to the average of one performance measure of the test set across the 9 sequences.

ting, init = 0.02 and q = 90 hidden units correspond to the lowest nRMSE of the cross-validation set (Figs. 8b, 8d). The nRMSE of the cross-validation set decreases as the number of hidden units increases, therefore we may

achieve higher accuracy with more hidden units. However, that would consequently increase the computing time (Fig. 10). Similarly, it has been reported in [32] that increasing the number of hidden units of a vanilla

Prediction of the Position of External Markers With UORO for Safe Radiotherapy

9

computing time of RTRL is the reason why we performed cross-validation for RTRL with fewer hidden units and lower SHL values than UORO, which has a complexity O(q(q + L)) (Table 2).

3.4 Significance of our results relative to the dataset used

Fig. 6: Prediction performance of each algorithm in terms of nRMSE and jitter. Each point corresponds to the mean of the nRMSE and jitter of a given algorithm of the test set over the regular or irregular breathing sequences for a single value of the horizon. Datapoints corresponding to linear regression with high horizon values have not been displayed for readability as they correspond to high nRMSE values.
RNN with a single hidden layer trained with RTRL to predict breathing signals led to a decrease of the prediction MAE. Fig. 8 displays the nRMSE averaged over the 9 sequences, and the general aforementioned recommendations are not optimal for each sequence. Therefore, we recommend using cross-validation to determine the best hyper-parameter set for each breathing record. The learning rate and SHL appear to be the most important hyper-parameters to tune (Fig. 9). Appropriately selecting them resulted in a decrease of the mean cross-validation nRMSE of 18.2% (from 0.395 to 0.323) and 21.3% (from 0.417 to 0.329), respectively.
3.3 Time performance
UORO has a prediction time per time step equal to 2.8ms for 90 hidden neurons and an SHL of 9.0s, whereas RTRL requires 55ms to perform a single prediction using 55 hidden units with an SHL of 5.5s (Dell Intel Core i9-9900K 3.60GHz CPU 32Gb RAM with Matlab, Fig. 10). The complexity O(q3(q + L)) and resulting high

One drawback of our study is the number of sequences used and their duration, which are low in comparison with some other studies related to forecasting in radiotherapy (cf section 1.2 and Table 4). Therefore, our numerical results might appear to lack a certain degree of confidence. However, the dataset used is representative of a large variety of breathing patterns including shifts, drifts, slow motion, sudden irregularities, as well as resting and non-perturbed motion. In addition, our results are consistent with previous studies that claim that linear prediction, linear adaptive filters, and ANNs achieve high performance respectively for low, intermediate, and high horizon values (cf section 3.1). The algorithms studied in our work are online algorithms that do not need a high amount of prior data for making accurate predictions, as demonstrated by the high performance that we achieved with only one minute of training. Because of the reasons mentioned above, we think that the results presented in our study have a significantly high level of confidence and would generalize well to larger datasets.
The online availability of the dataset used is a particular strength of our study, as it enables reproducibility of our results. Most of the previous studies about the prediction of breathing signals for radiotherapy rely on datasets that are not publicly available (cf section 1.2 and Table 4), which makes performance comparison difficult.
Laughing and talking are situations where prediction is difficult and they do not happen in a clinical setting. However, evaluating performance with such difficult scenarios gives information about other situations that will sometimes happen during treatment, such as yawning, hiccuping, and coughing. Detecting these anomalies and turning off the irradiation beam when they occur is currently the standard clinical approach. Distinguishing between normal and irregular breathing enabled us to objectively study and quantify the robustness of the algorithms compared (cf Table 3 and Appendix D). Since irregular breathing sequences comprise almost half of our entire dataset, the numerical error measures averaged over the nine sequences should be higher than one can expect in more realistic scenarios.

10

Michel Pohl et al.

(a) Prediction with an RNN trained with UORO

(b) Prediction with an RNN trained with RTRL

(c) Prediction with LMS
Fig. 7: Comparison between RTRL, UORO, and LMS regarding the prediction of the position of the z coordinate (spine axis) of marker 3 in sequence 1 (person talking)

3.5 Comparison with previous works
Table 4 compares the performance of UORO in our study with the results previously reported in the literature. Comparison with previous studies is complex because the datasets are different. In particular, the

frequency, amplitude, and regularity of the signals vary from study to study. Furthermore, the response time, as well as the partition of the data into development and test set are usually arbitrarily selected, thus they also differ between the studies.

Prediction of the Position of External Markers With UORO for Safe Radiotherapy

11

(a) Prediction nRMSE of the cross-validation set as a function of the learning rate

(b) Prediction nRMSE of the cross-validation set as a function of the standard deviation of the Gaussian distribution of the initial synaptic weights

(c) Prediction nRMSE of the cross-validation (d) Prediction nRMSE of the cross-validation set as a function of the signal history length set as a function of the number of hidden units
Fig. 8: Prediction nRMSE of the cross-validation set as a function of each RNN hyper-parameter, for different horizon values. Given one hyper-parameter, each color point of the associated graph corresponds to the minimum of the nRMSE over every possible combination of the other hyper-parameters in the cross-validation range (Table 2). Each nRMSE measure is averaged over the 9 sequences and 50 runs. The black dotted curves correspond to the nRMSE minimum averaged over the horizon values between 0.1s and 2.0s, and the associated error bars correspond to its standard deviation over these horizon values.

The prediction errors in our research might appear relatively large, but this is due to the low sampling frequency (10Hz), the high amplitude of the breathing signals, and the high proportion of irregular patterns in

our dataset (cf section 3.4). Furthermore, the breathing records that we use have a relatively low duration and therefore the RNNs have fewer data available for training. When taking these circumstances into account, it

12

Michel Pohl et al.

Fig. 9: Standard deviation of the nRMSE of the crossvalidation set (black dotted curves in Fig. 8) for each hyper-parameter. A hyper-parameter corresponding to a high standard deviation value has a high influence on the prediction error.

RNN-based models reported in Table 4 may benefit from adaptive retraining with UORO.
Teo et al. studied breathing records with a frequency of 7.5 Hz and reported lower errors using an MLP with one hidden layer trained first with backpropagation and retrained online [40]. Our higher errors are partly due to the amplitude of the breathing signals in our dataset, which are approximately 3 times higher. Mafi et al. also reported similar but lower prediction errors for a signal sampled at 7.5 Hz using RTRL [22]. However, they do not provide information concerning signal amplitude, and our results demonstrate that UORO has more benefits than RTRL in practice. The RMSE error that we achieved is approximately 2 to 4 times lower than the RMSEs reported by Sharp et al., who used a multilayer perceptron (MLP) with one hidden layer and breathing records of the same frequency (10Hz) with similar amplitudes [36]. The RMSE that we found is within the range reported by Kai et al., who predicted the position of an internal marker using an RNN with 1 hidden layer trained with BPTT with a much higher frequency (30 Hz) [12].

4 Conclusion

Fig. 10: Calculation time (Dell Intel Core i9-9900K 3.60GHz CPU 32Gb RAM with Matlab)
appears that the errors reported in our study are consistent with the findings of the previous related works.
Our purpose is to examine the extent to which RNNs can efficiently learn to adaptively predict respiratory motion with little data. We do not aim to build a generalized model with a high amount of data. All the

This is the first study of RNNs trained with UORO for forecasting the position of external markers on the chest and abdomen for safe radiotherapy, to the extent of our knowledge. This method can mitigate the latency of treatment systems due to robot control and radiation delivery preparation. This will in turn help decrease irradiation to healthy tissues and avoid lung radiation therapy side effects such as radiation pneumonitis or pulmonary fibrosis.
Online processing is suitable for breathing motion prediction during the radiotherapy treatment as it enables adaptation to each patient's individual respiratory patterns varying over time. We could efficiently train RNNs using only one minute of breathing data per sequence, as dynamic training can be implemented with limited data. Prediction was performed simultaneously for the three markers so that the RNN discovers and uses information from the correlation between their motion.
UORO achieved the lowest prediction RMSE for horizon values h  0.6s, with an average value over
7 MLP, FCL, and RPM respectively stand for "multilayer perceptron", "fully connected layer" and "real-time position management". By abuse of language, the number of layers mentioned actually refers to the number of hidden layers. For instance, a "1-layer MLP" architecture refers to an MLP with 1 hidden layer.

Prediction of the Position of External Markers With UORO for Safe Radiotherapy

13

First author

Network Training method

Breathing data

Sampling Amount of Signal

Response Prediction

rate

data

amplitude time

error

Sharp [36] 1-layer MLP
Sun [37] 1-layer MLP

-

1 implanted

marker

Levenberg-Marq. RPM data

& adapt. boosting (Varian)

10 Hz 30 Hz

Kai [12] Teo [40]

1-layer RNN 1-layer MLP

BPTT
Backprop. & adapt. training

1 implanted marker Cyberknife Synchrony

30 Hz 7.5 Hz

Yun [46] Lin [21]

3-layer LSTM 3-layer LSTM

adapt. training -

tumor 3D 25 Hz center of mass RPM data 30 Hz (Varian)

Mafi [22]
Lee [17]
Our work

RNN -FCL LSTM -FCL 1-layer RNN

RTRL BPTT UORO

Cyberknife Synchrony RPM data (Varian) 3 external markers (Polaris)

7.5 Hz 30 Hz 10 Hz

14 records 9.1mm

1) 200ms RMSE 2.6mm

48s to 352s to 31.6mm 2) 1s RMSE 5.3mm

data from Rescaling 500ms Max error 0.65

138 scans between -1

RMSE 0.17

and 1

nRMSE 0.28

7 records of -

1.0s

RMSE from

40s to 70s

0.48mm to 1.37mm

27 records 2mm

650

MAE 0.65mm

of 1 min

to 16mm

RMSE 0.95mm

(dvlpmt set)

Max error 3.94mm

158 records 0.6mm

280ms RMSE 0.9mm

of 8 min

to 51.2mm

1703 records Rescaling 280ms MAE 0.112

of 2 to 5 min between -1 500ms RMSE 0.139

and 1

Max error 1.811

43 records of -

665ms MAE 0.54mm

2.2s to 6.4s

RMSE 0.57mm

550 records 11.9mm 210ms RMSE 0.28mm

91s to 188s to 25.9mm

9 records 6mm

0.1s

MAE 0.85mm

73s to 222s to 40mm to 2.0s Max error 8.8mm

(S-I

RMSE 1.28mm

direction)

nRMSE 0.28

Table 4: Comparison of our work with previous studies about time-series forecasting with ANNs for respiratory motion compensation in radiotherapy (cf Section 1.2). In this table, the term "RNN" designates a vanilla RNN, as opposed to LSTMs. "LSTM-FCL" designates a combination of LSTM layers and fully connected layers. A field with " - " indicates that the information is not available in the corresponding research article. The results corresponding to our study are the performance measures averaged over the horizon values between 0.1s and 2.0s in Table 3. 7

9 breathing sequences not exceeding 1.4mm. These sequences last from 73s to 222s, correspond to a sampling rate of 10Hz and marker position amplitudes varying from 6mm to 40mm in the superior-inferior direction. Moreover, UORO achieved the lowest maximum error for h  0.7s with an average value over the 9 sequences not exceeding 9.1mm. The average of the RMSE and maximum error over the sequences corresponding to regular breathing were respectively lower than 1.1mm and 7.7mm. The nRMSE of UORO only increased by 10.6% when performing the evaluation with the sequences corresponding to irregular breathing instead of regular breathing, which indicates good robustness to sudden changes in respiratory patterns. The calculation time per time step of UORO is equal to 2.8ms for 90 hidden units and an SHL of 9.0s (Dell Intel Core i9-9900K 3.60GHz CPU 32Gb RAM with Matlab). UORO has a much better time performance than RTRL, whose calculation time per time step is equal to 55.2s for 55 hidden units and an SHL of 5.5s.
Linear regression was the most efficient prediction algorithm for low look-ahead time values, with an RMSE lower than 0.9mm for h  0.2s. LMS gave the best prediction results for intermediate look-ahead values, with

an RMSE lower than 1.2mm for h  0.5s. These observations regarding the influence of the horizon agree with those in [41]. The errors reported in our study may be higher than in clinical scenarios due to the high proportion of records corresponding to irregular breathing in our dataset.
Gradient clipping was used to ensure numerical stability and we selected a clipping threshold  = 2.0. The learning rate and SHL were the hyper-parameters with the strongest influence on the prediction performance. We found that a learning rate  = 0.1 and SHL of 7.0s gave the best results on average, except with high horizon values close to h = 2.0s, for which a higher learning rate  = 0.2 and lower SHL of 5.0s led to better performance. The prediction error decreased as the number of hidden units increased. That fact has previously been observed in the case of RTRL [32].
LSTM networks or gated recurrent units (GRUs) could be used instead of a vanilla RNN structure, as that could lead to higher prediction accuracy. Furthermore, UORO could be used to dynamically retrain in real-time the last hidden layer of a deep RNN that predicts respiratory waveform signals, as a form of transfer learning. This could improve the robustness of that

14

Michel Pohl et al.

RNN to unseen examples corresponding to irregular breathing patterns.
Conflict of interest
The authors declare that they have no conflict of interest.
Availability of data and material
The dataset used is accessible online [2].
References
1. Azizmohammadi F, Martin R, Miro J, Duong L (2019) Model-free cardiorespiratory motion prediction from x-ray angiography sequence with lstm network. In: 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), IEEE, pp 7014­7018
2. Baltic Institute of Advanced Technology (Last update in 2015) Datasets - radiotherapy. http:// datasets.bpti.lt/radiotherapy/, [Online; accessed 26-April-2021]
3. Chen QS, Weinhous MS, Deibel FC, Ciezki JP, Macklis RM (2001) Fluoroscopic study of tumor motion due to breathing: facilitating precise radiation therapy for lung cancer patients. Medical physics 28(9):1850­1856
4. Choi S, Chang Y, Kim N, Park SH, Song SY, Kang HS (2014) Performance enhancement of respiratory tumor motion prediction using adaptive support vector regression: Comparison with adaptive neural network method. International journal of imaging systems and technology 24(1):8­15
5. Ehrhardt J, Lorenz C, et al. (2013) 4D modeling and estimation of respiratory motion for radiation therapy, vol 10. Springer
6. Goodband JH, Haas OC, Mills J (2008) A comparison of neural network approaches for on-line prediction in IGRT. Medical physics 35(3):1113­1122
7. Haykin SS (2008) Adaptive filter theory. Pearson 8. Haykin SS, et al. (2009) Neural networks and learn-
ing machines. Pearson 9. Isaksson M, Jalden J, Murphy MJ (2005) On using
an adaptive neural network to predict lung tumor motion during respiration for radiotherapy applications. Medical physics 32(12):3801­3809 10. Jaeger H (2002) Tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the "echo state network" approach, vol 5. GMDForschungszentrum Informationstechnik Bonn

11. J¨ohl A, Ehrbar S, Guckenberger M, Kl¨ock S, Meboldt M, Zeilinger M, Tanadini-Lang S, Schmid Daners M (2020) Performance comparison of prediction filters for respiratory motion tracking in radiotherapy. Medical physics 47(2):643­650
12. Kai J, Fujii F, Shiinoki T (2018) Prediction of lung tumor motion based on recurrent neural network. In: 2018 IEEE International Conference on Mechatronics and Automation (ICMA), IEEE, pp 1093­ 1099
13. Kakar M, Nystr¨om H, Aarup LR, Nøttrup TJ, Olsen DR (2005) Respiratory motion prediction by using the adaptive neuro fuzzy inference system (anfis). Physics in Medicine & Biology 50(19):4721
14. Khankan A, Althaqfi S, et al. (2017) Demystifying Cyberknife stereotactic body radiation therapy for interventional radiologists. The Arab Journal of Interventional Radiology 1(2):55
15. Krauss A, Nill S, Oelfke U (2011) The comparative performance of four respiratory motion predictors for real-time tumour tracking. Physics in Medicine & Biology 56(16):5303
16. Krilavicius T, Zliobaite I, Simonavicius H, Jaruevicius L (2016) Predicting respiratory motion for real-time tumour tracking in radiotherapy. In: 2016 IEEE 29th International Symposium on ComputerBased Medical Systems (CBMS), IEEE, pp 7­12
17. Lee M, Cho MS, Lee H, Jeong C, Kwak J, Jung J, Kim SS, Yoon SM, Song SY, Lee Sw, et al. (2021) Geometric and dosimetric verification of a recurrent neural network algorithm to compensate for respiratory motion using an articulated robotic couch. Journal of the Korean Physical Society 78(1):64­72
18. Lee SJ, Motai Y (2014) Prediction and classification of respiratory motion. Springer
19. Lee SJ, Motai Y, Murphy M (2011) Respiratory motion estimation with hybrid implementation of extended Kalman filter. IEEE Transactions on Industrial Electronics 59(11):4421­4432
20. Lee SJ, Motai Y, Weiss E, Sun SS (2013) Customized prediction of respiratory motion with clustering from multiple patient interaction. ACM Transactions on Intelligent Systems and Technology (TIST) 4(4):1­17
21. Lin H, Shi C, Wang B, Chan MF, Tang X, Ji W (2019) Towards real-time respiratory motion prediction based on long short-term memory neural networks. Physics in Medicine & Biology 64(8):085010
22. Mafi M, Moghadam SM (2020) Real-time prediction of tumor motion using a dynamic neural network. Medical & biological engineering & computing 58(3):529­539

Prediction of the Position of External Markers With UORO for Safe Radiotherapy

15

23. Marschall O, Cho K, Savin C (2020) A unified

framework of online learning algorithms for train-

ing recurrent neural networks. Journal of Machine

Learning Research 21(135):1­34

24. Mass´e PY, Ollivier Y (2020) Convergence of online

adaptive and recurrent optimization algorithms.

arXiv preprint arXiv:200505645

25. McClelland JR, Hawkes DJ, Schaeffter T, King AP

(2013) Respiratory motion models: a review. Med-

ical image analysis 17(1):19­42

26. Murphy MJ, Dieterich S (2006) Comparative per-

formance of linear and nonlinear neural networks

to predict irregular breathing. Physics in Medicine

& Biology 51(22):5903

27. Murphy MJ, Pokhrel D (2009) Optimization of an

adaptive neural network to predict breathing. Med-

ical physics 36(1):40­47

28. Murphy MJ, Isaakson M, Jalden J (2002) Adap-

tive filtering to predict lung tumor motion during

free breathing. In: CARS 2002 computer assisted

radiology and surgery, Springer, pp 539­544

29. Nabavi S, Abdoos M, Moghaddam ME, Moham-

madi M (2020) Respiratory motion prediction us-

ing deep convolutional long short-term memory

network. Journal of Medical Signals and Sensors

10(2):69

30. National Cancer Institute - Surveillance, Epidemi-

ology and End Results Program (2021) Cancer stat

facts: Lung and bronchus cancer. https://seer.

cancer.gov/statfacts/html/lungb.html, [On-

line; accessed 26-April-2021]

31. Pascanu R, Mikolov T, Bengio Y (2013) On the

difficulty of training recurrent neural networks. In:

International conference on machine learning, pp

1310­1318

32. Pohl M, Uesaka M, Demachi K, Chhatkuli

RB (2021) Prediction of the motion of chest

internal points using a recurrent neural net-

work trained with real-time recurrent learn-

ing for latency compensation in lung cancer

radiotherapy. Computerized Medical Imag-

ing and Graphics p 101941, DOI https:

//doi.org/10.1016/j.compmedimag.2021.101941,

URL

https://www.sciencedirect.com/

science/article/pii/S0895611121000902

33. Romaguera LV, Plantef`eve R, Romero FP, H´ebert

F, Carrier JF, Kadoury S (2020) Prediction of in-

plane organ deformation during free-breathing ra-

diotherapy via discriminative spatial transformer

networks. Medical image analysis 64:101754

34. Salehinejad H, Sankar S, Barfett J, Colak E, Valaee

S (2017) Recent advances in recurrent neural net-

works. arXiv preprint arXiv:180101078

35. Schweikard A, Shiomi H, Adler J (2004) Respiration tracking in radiosurgery. Medical physics 31(10):2738­2741
36. Sharp GC, Jiang SB, Shimizu S, Shirato H (2004) Prediction of respiratory tumour motion for real-time image-guided radiotherapy. Physics in Medicine & Biology 49(3):425
37. Sun W, Jiang M, Ren L, Dang J, You T, Yin F (2017) Respiratory signal prediction based on adaptive boosting and multi-layer perceptron neural network. Physics in Medicine & Biology 62(17):6822
38. Takao S, Miyamoto N, Matsuura T, Onimaru R, Katoh N, Inoue T, Sutherland KL, Suzuki R, Shirato H, Shimizu S (2016) Intrafractional baseline shift or drift of lung tumor motion during gated radiation therapy with a real-time tumor-tracking system. International Journal of Radiation Oncology* Biology* Physics 94(1):172­180
39. Tallec C, Ollivier Y (2017) Unbiased online recurrent optimization. arXiv preprint arXiv:170205043
40. Teo TP, Ahmed SB, Kawalec P, Alayoubi N, Bruce N, Lyn E, Pistorius S (2018) Feasibility of predicting tumor motion using online data acquired during treatment and a generalized neural network optimized with offline patient tumor trajectories. Medical physics 45(2):830­845
41. Verma P, Wu H, Langer M, Das I, Sandison G (2010) Survey: real-time tumor motion prediction for image-guided radiation treatment. Computing in Science & Engineering 13(5):24­35
42. Wang G, Li Z, Li G, Dai G, Xiao Q, Bai L, He Y, Liu Y, Bai S (2021) Real-time liver tracking algorithm based on lstm and svr networks for use in surface-guided radiation therapy. Radiation Oncology 16(1):1­12
43. Wang R, Liang X, Zhu X, Xie Y (2018) A feasibility of respiration prediction based on deep bi-lstm for real-time tumor tracking. IEEE Access 6:51262­ 51268
44. Williams RJ, Zipser D (1989) A learning algorithm for continually running fully recurrent neural networks. Neural computation 1(2):270­280
45. Yu S, Wang J, Liu J, Sun R, Kuang S, Sun L (2020) Rapid prediction of respiratory motion based on bidirectional gated recurrent unit network. IEEE Access 8:49424­49435
46. Yun J, Rathee S, Fallone B (2019) A deeplearning based 3D tumor motion prediction algorithm for non-invasive intra-fractional tumortracked radiotherapy (nifteRT) on Linac-MR. International Journal of Radiation Oncology, Biology, Physics 105(1):S28

16 A Appendix : UORO with gradient clipping for a vanilla RNN

Michel Pohl et al.

Algorithm 1 UORO
Parameters : L  N : signal history length, nM = 3 : number of external markers considered m = 3nM L, q  N and p = 3nM dimension of the RNN input, RNN state and RNN output   R>0 and   R>0 : learning rate and gradient threshold init  R>0 : standard deviation of the Gaussian distribution of the initial weights norm = 1.10-7, prop = 1.10-7

Initialization

Wa,n=1, Wb,n=1, Wc,n=1 synaptic weight matrices of respective sizes q × q, q × (m + 1) and p × q,

initialized randomly according to a Gaussian distribution with std. deviation init.

Notation : |Wa| = q2, |Wb| = q(m + 1), |Wc| = pq, and |W | = q(p + q + m + 1)

xn=1 := 0q×1 : state vector

x~n=1 := 0q×1, ~n=1 := 01×|W | : vectors such that xn/  x~n~n

 := 01×|W |, g

= 01×|W |

vectors defined by

 =

Lt+1 Fout yn+1 

and

g

= T Fst 

Learning and prediction
for n = 1, 2, ... do
zn := Wa,nxn + Wb,nun xn+1 := (zn) (hidden state update)
yn+1 := Wc,nxn+1 (prediction) en+1 := yn+1 - yn+1 (error vector update) [1+|Wa|+|Wb|, ..., |W |] := -[(en+1xTn )1,1, ..., (en+1xTn )p,q]  := -eTn+1Wc,nx~n~n +  (gradient estimate)  : column vector of size q with random values in {-1, 1}
x~n+1 := [Wa,n(xn + propx~n) + Wb,nun] - xn+1 (tangent forward propagation)
prop
gaux :=    (zn) (element-wise or scalar product) [(g)1, ..., (g)|Wa|] := [(gauxxTn )1,1, ..., (gauxxTn )q,q] [(g)|Wa|+1, ..., (g)|Wa|+|Wb|] := [(gauxuTn )1,1, ..., (gauxuTn )q,m+1]

0 :=

x~

~ 2

+

2 + norm

norm,

1 :=



~g 2+

2

+

norm

norm

x~n+1 := 0x~n+1 + 1 ~n+1 := ~n/0 + (g)/1

n := [(Wa,n)1,1, ..., (Wa,n)q,q, (Wb,n)1,1, ..., (Wb,n)q,m+1, (Wc,n)1,1, ..., (Wc,n)p,q]
if  2 >  then  :=   (gradient clipping)  2
end if

n+1 := n -  (weights update)

(n+1)1 ... (n+1)q(q-1)+1

(n+1)|Wa|+1 ... (n+1)|Wa|+qm+1

Wa,n+1 :=  ... ...

...

 Wb,n+1 := 

...

...

...



(n+1)q ... (n+1)|Wa|

(n+1)|Wa|+q ... (n+1)|Wa|+|Wb|

(n+1)|Wa|+|Wb|+1 ... (n+1)|Wa|+|Wb|+p(q-1)+1

Wc,n+1 := 

...

...

...



end for

(n+1)|Wa|+|Wb|+p ... (n+1)|Wa|+|Wb|+|Wc|

Convention : for A  RM × RN we note [A1,1, ..., AM,N ] = [A1,1, ..., AM,1, A1,2, ..., AM,N ]

Prediction of the Position of External Markers With UORO for Safe Radiotherapy

17

B Appendix : Predicted motion for sequence 5 (regular breathing)

(a) Prediction with an RNN trained with UORO
(b) Prediction with an RNN trained with RTRL
(c) Prediction with LMS Fig. 11: Comparison between RTRL, UORO, and LMS regarding the prediction of the position of the z coordinate (spine axis) of marker 3 in sequence 5 (normal breathing)

18

Michel Pohl et al.

C Appendix : Loss functions for sequence 1 (irregular breathing) and 5 (regular breathing)

(a) Sequence 1 - UORO

(b) Sequence 5 - UORO

(c) Sequence 1 - RTRL

(d) Sequence 5 - RTRL

(e) Sequence 1 - LMS

(f) Sequence 5 - LMS

Fig. 12: Prediction instantaneous square loss (cf Eq. 2) for sequence 1 (person talking) and sequence 5 (normal breathing). The horizon value is h=2.0s and the loss is averaged over 300 runs.

Prediction of the Position of External Markers With UORO for Safe Radiotherapy

19

D Appendix : Prediction performance for regular and irregular breathing sequences

Fig. 13: Forecasting performance of each algorithm as a function of the prediction horizon. Each point corresponds to the average of one performance measure of the test set across the sequences corresponding to regular breathing.

20

Michel Pohl et al.

Fig. 14: Forecasting performance of each algorithm as a function of the prediction horizon. Each point corresponds to the average of one performance measure of the test set across the records corresponding to irregular breathing. 8
8 Sequence 201205111057-LACLARUAR-3-O-72 (cf [16]) has been removed from the sequences associated with abnormal respiratory motion for plotting the performance graphs, as that sequence does not contain abrupt or sudden motion that typically makes forecasting difficult.

