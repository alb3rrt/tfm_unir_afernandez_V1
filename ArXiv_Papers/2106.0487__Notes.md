
# Dense Nested Attention Network for Infrared Small Target Detection

[arXiv](https://arxiv.org/abs/2106.0487), [PDF](https://arxiv.org/pdf/2106.0487.pdf)

## Authors

- Boyang Li
- Chao Xiao
- Longguang Wang
- Yingqian Wang
- Zaiping Lin
- Miao Li
- Wei An
- Yulan Guo

## Abstract

Single-frame infrared small target (SIRST) detection aims at separating small targets from clutter backgrounds. With the advances of deep learning, CNN-based methods have yielded promising results in generic object detection due to their powerful modeling capability. However, existing CNN-based methods cannot be directly applied for infrared small targets since pooling layers in their networks could lead to the loss of targets in deep layers. To handle this problem, we propose a dense nested attention network (DNANet) in this paper. Specifically, we design a dense nested interactive module (DNIM) to achieve progressive interaction among high-level and low-level features. With the repeated interaction in DNIM, infrared small targets in deep layers can be maintained. Based on DNIM, we further propose a cascaded channel and spatial attention module (CSAM) to adaptively enhance multi-level features. With our DNANet, contextual information of small targets can be well incorporated and fully exploited by repeated fusion and enhancement. Moreover, we develop an infrared small target dataset (namely, NUDT-SIRST) and propose a set of evaluation metrics to conduct comprehensive performance evaluation. Experiments on both public and our self-developed datasets demonstrate the effectiveness of our method. Compared to other state-of-the-art methods, our method achieves better performance in terms of probability of detection (Pd), false-alarm rate (Fa), and intersection of union (IoU).

## Comments



## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{li2021dense,
      title={Dense Nested Attention Network for Infrared Small Target Detection}, 
      author={Boyang Li and Chao Xiao and Longguang Wang and Yingqian Wang and Zaiping Lin and Miao Li and Wei An and Yulan Guo},
      year={2021},
      eprint={2106.00487},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

## Notes

Type your reading notes here...

