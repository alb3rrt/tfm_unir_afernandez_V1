
# Fair-Net: A Network Architecture For Reducing Performance Disparity Between Identifiable Sub-Populations

[arXiv](https://arxiv.org/abs/2106.0720), [PDF](https://arxiv.org/pdf/2106.0720.pdf)

## Authors

- Arghya Datta
- S. Joshua Swamidass

## Abstract

In real world datasets, particular groups are under-represented, much rarer than others, and machine learning classifiers will often preform worse on under-represented populations. This problem is aggravated across many domains where datasets are class imbalanced, with a minority class far rarer than the majority class. Naive approaches to handle under-representation and class imbalance include training sub-population specific classifiers that handle class imbalance or training a global classifier that overlooks sub-population disparities and aims to achieve high overall accuracy by handling class imbalance. In this study, we find that these approaches are vulnerable in class imbalanced datasets with minority sub-populations. We introduced Fair-Net, a branched multitask neural network architecture that improves both classification accuracy and probability calibration across identifiable sub-populations in class imbalanced datasets. Fair-Nets is a straightforward extension to the output layer and error function of a network, so can be incorporated in far more complex architectures. Empirical studies with three real world benchmark datasets demonstrate that Fair-Net improves classification and calibration performance, substantially reducing performance disparity between gender and racial sub-populations.

## Comments



## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{datta2021fairnet,
      title={Fair-Net: A Network Architecture For Reducing Performance Disparity Between Identifiable Sub-Populations}, 
      author={Arghya Datta and S. Joshua Swamidass},
      year={2021},
      eprint={2106.00720},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```

## Notes

Type your reading notes here...

