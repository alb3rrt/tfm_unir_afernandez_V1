Noname manuscript No. (will be inserted by the editor)

The moment-generating function of the log-normal distribution, how zero-entropy principle unveils an asymmetry under the reciprocal of an action.
Yuri Heymann

arXiv:2106.00625v2 [math.GM] 3 Jun 2021

Received: date / Accepted: date
Abstract The present manuscript is about application of Ito^'s calculus to the moment-generating function of the lognormal distribution. While Taylor expansion fails when applied to the moments of the lognormal due to divergence, various methods based on saddle-point approximation conjointly employed with integration methods have been proposed. By the Jensen's inequality, the MGF of the lognormal involves some convexity adjustment, which is one of the aspects under consideration thereof. A method based on zero-entropy principle is proposed part of this study, which deviations from the benchmark by infinitesimal epsilons is attributed to an asymmetry of the reciprocal. As applied to systems carrying vibrating variables, the partial offset by the reciprocal of an action, is a principle meant to explain a variety of phenomena in fields such as quantum physics.
Keywords moment-generating function · lognormal · zero-entropy principle

1 Introduction

The moment-generating function (MGF) of a random variable X is commonly expressed as M () = E(eX ) by definition. By Taylor expansion of eX centered on

zero, we get E(eX ) = E

1+

X 1!

+

2X2 2!

+ ... +

nXn n!

. Taylor expansion method

fails when applied to the MGF of the lognormal distribution of finite multiplicity.

Its expression M () =

 n=0

n n!

enµ+n2 2

/2

diverges

for

all



-

mainly

because

the lognormal distribution is skewed to the right. This skew increases the like-

lihood of occurrences departing from the central point of the Taylor expansion.

These occurrences produce moments of higher order, which are not offset by the

factorial of n in the denominator, resulting in Taylor series to diverge. Some of

the specificities of the lognormal distribution are enumerated below, namely that

the lognormal distribution is not uniquely determined by its moments as seen in

[8] for some undefined multiplicity. Though it was reported in [11] that MGF of

Yuri Heymann Address in der Schweiz: 3 rue Chandieu, 1202 Geneva, Switzerland E-mail: y.heymann@yahoo.com

2

Yuri Heymann

the lognormal does not exist when  is positive due to the integral form of the MGF being undefined for such  values; other methods under consideration yield consistent values in a portion of the domain having positive  values, e.g. Monte Carlo simulation, etc.
Saddle points and their representations are worth considering, though not as accurate in all domains. Expressions for the characteristic function of the lognormal distribution based on some classical saddle-point representations are described in [6, 9], and other representations involving asymptotic series in [3, 10]. The evaluation of the characteristic function by integration method such as the HermiteGauss quadrature as in [7] appears to be the preferred choice. It was reported in [4], that due to oscillatory integrand and slow decay rate at the right tail of the lognormal density function, numerical integration was combersome. Other numerical methods including the work of [13] employing a contour integral passing through the saddle point at steepest descent was proposed to overcome the aforementioned issues. A closed-form approximation of the Laplace transform of the lognormal distribution pretty accurate over its domain of definition was obtained by [2]. This equation is handy to backtest present study results, by its simplicity and because the Laplace transform of the density function and MGF are interconnected by sign interchange of variable  in the argument. An accurate and efficient method to compute the value of the lognormal MGF, referred to as thin-tile integration is proposed in section 4.0. This method benefits from the symmetry of the Gaussian distribution and is based on a non-uniform grid spacing.
The approach consisting at using a stochastic process as a proxy of the MGF, is built on the application of Ito^'s lemma with function f (x) = eY (x) to base process dxt = µdt + dWt, where µ and  are respectively the timeless mean and volatility parameters, Wt a Wiener process, and Y (x) the random variable of the process expressed as a function of some normal random variable x. The MGF is obtained from computation of E(ft) = E(f (xt)). In the context of the MGF of the lognormal, the stochastic approach leads to a skew explained by the partial offset of the reciprocal of an action, resulting from an asymmetry for systems carrying vibrating variables. This is a principle with potential applications in other fields such as in quantum theory, e.g. asymmetries of harmonic oscillators [5, 1]. For example, the Heisenberg uncertainty principle implies the energy of a system described by harmonic oscillators cannot have zero energy [12]. Such ground state also referred to as zero-point vibration is commonly invoked as a founding principle preventing liquid helium from freezing at atmospheric pressure regardless of temperature.

2 Theoretical background
2.1 The epsilon probability measure as a transform of zero convexity
By formal definition, a probability space is a measurable space satisfying measure properties such as countable additivity, further equipped with some probability measure assigning values to events of the probability space, e.g. value 0 is assigned to the empty set and 1 to the entire space. In field of stochastic calculus as applied

Title Suppressed Due to Excessive Length

3

to actuarial sciences, a probability measure is a mean to characterise a process as a drift applied to a base process resulting in an equivalence under the new measure satisfying some desirable properties e.g. is a martingale, etc. As such the epsilon probability measure belonging to probability space E· is equipped with a linear operator E as defined further down.
Say f : R  R is a continuous function and X a random variable, where F is the primitive of f . Suppose there exists some measure in relation to F (X) such that:

E(F (X)) = F (E(X)) ,

(1)

where E is an operator for statistical expectation of a variable in a probability space EQ referring to such measure, and where E is the corresponding operator in the natural probability measure.

As statistical expectation of a random variable can be expressed by its integral times density function over codomain in R, the probability measure as defined in (1) expresses a kind of homeomorphism of the initial random variable by some dense function. Without specifications of higher moments, the primitive of f as a diffeomorphism of multiplicity one i.e. stemming from a singleton implies there is an infinity of such variations spanning an entire domain or the probability space itself is empty. As such the EQ probability space as a spectrum carrying operator E is generated by a one degree of freedom univariate, commonly characterised by mean of a class of functions or say a holomorphism expressing a multitude of moments of some multiplicity.
For example, if F (X) = X2 where X is a normally distributed variable centered in zero, then the above probability measure does not exist. As such for probability space EQ to be non empty, implies F is either monotonically increasing or decreasing over its domain, i.e. F is a bijective application.

As a corollary stemming from (1), we can write:

X

E(X )

E

f (x)dx =

f (x)dx ,

(2)

x0

x0

where x0 is a real number and X a random variable, yielding a new class of integrals represented as univariate functions, which integration domain is random on the right with hard limit on the left.

A straight-forward property of statistical expectation as an operator belonging to probability space EQ is linearity, yielding:

E(a + bX) = a + b E(X) ,

(3)

where a and b are real numbers and X a variable carrying some randomness. This relation is currently understood as a diffeomrphism of the density function by mean of variations spanning a quantised space, which is stemming from integral representation of statistical expectation by a dense function of X in new probability space EQ.

4

Yuri Heymann

Proposition 1 - applies to Gaussian scenerio: Given a probability measure Q in relation to function f which applies to time-sensitive variable Xt linked to a Wiener process on a one-by-one relation and where f (Xt) is Gaussian, we have:

E(f (Xt)) = E(f (Xt)) ,

(4)

where operator E belongs to an epsilon probability space EQ as defined earlier.

Proof Say we have univariate function f which applies to variable Xt of a random nature such that f (Xt) is Gaussian. For process f (Xt) as a Gaussian variable sensitive to t and equipped with a Wiener process Wt defining a bijective map between Xt and Wt, the latter implies the existence of two real numbers a and b such that f (Xt) = a + b Wt. As E(Wt) = 0 in E·, we have E(f (Xt)) = a = E(f (Xt)).

2.2 Fundamentals related to an action and reciprocal for systems carrying vibrating variables

Say we apply a function f : R  R to a vibrating variable xt, which action is projecting xt onto f (xt) in a measurable space expressing statistical expectations as linear operators. The action resulting from the application of Ito^'s lemma to variable xt of a base process with function f , is leading to its derived process ft = f (xt). The reciprocal as a reverse transform is aiming at projecting the statistical expectations of f (xt) onto xt by linear operator, which in context of the lognormal distribution and some normalization leads to a skew.

By the Jensen's inequality, the application of a function f : R  R to a vibrating variable xt yields a convexity adjustment ft, by relation E(f (xt)) = f (E(xt)) + ft expressing a projection of statistical expectations. The shifted process xt is an implied variable of xt which by value satisfies equality E(f (xt)) = f (E(xt)), as a link with epsilon probability measure introduced earlier.
For such a primary transform projecting the statistical expectation of xt onto f (xt) by a shift linked to measurable space epsilon, the reciprocal obtained from the application of the inverse function f -1 to process of f (xt) results in projection of f (xt) onto xt by some linear operator.
Given a base process dxt = µdt + dWt where µ and  are the timeless mean and volatility parameters and Wt a Wiener process, the Ito^'s process of ft is defined such that ft = f (xt) where f : R  R is a twice-differentiable continuous function, which is invertible. The Ito^'s process of ft is obtained by applying Ito^'s lemma to base process xt with function f , leading to:

dft =

µ f (xt) x

+

2 2

2f (xt) x2

f dt +  x (xt) dWt ,

(5)

where Wt is a Wiener process, µ and  are real numbers representing the timeless mean and volatility of base process xt, where t is time.

Title Suppressed Due to Excessive Length

5

When

normalizing

the

It^o

process

of

ft

by

dividing

both

sides

of

(5)

by

f (xt x

)

,

the derivative of the inverse of f , leads to a stochastic differential equation (SDE)

of the form:

[f -1] (ft)dft =

µ

+

1 2 2

2f (xt) x2

f (xt) x

dt +  dWt ,

(6)

as per expression [f -1] (a) = 1/f (f -1(a)) for the derivative of the inverse of f evaluated in a.

By applying Ito^'s lemma to the It^o's process of ft given by (5) with function f -1(x) yields:

d(f -1(ft)) = [f -1] (ft) dft - h(ft) dt ,

(7)

where h(ft) is expressed as follows:

h(ft)

=

h(f (xt))

=

12 f 2f

(xt) (xt)

.

(8)

The term h(ft)dt in (7) is due to some convexity adjustment resulting from the transform T : ft  f -1(ft) as a projection of statistical expectation by the application of Ito^'s lemma to base process and normalisation as seen above. In a
perfectly symmetrical world, we would expect the below to happen:

(i) By removing the vibrations in (7) conjointly with the application of linear operator E to the integral form of the stochastic process (6) as seen in (2), leads to a shift of ft towards ft under the action of T . More specifically, ft is the implied process of ft which by value satisfies equality d(f -1(ft)) = [f -1] (ft) dft also referred to as the zero-entropy condition. The combined action of the above leads to transform T : ft  f -1(ft) as a projection of statistical expectations.
(ii) As transform T : ft  f -1(ft) represents a projection of statistical expectations through a linear operator, by the symmetry of the reciprocal we have f -1 (E(ft)) = E f -1(ft) . The benefit sought by such symmetry is a simple ex-
pression for E(ft) which equals f (E(f -1(ft))) under perfect symmetry. Yet, this is not always accurate due to partial offsets of the shift resulting from zero-entropy principle, under the action of f -1 and reciprocal, which asymmetry is explained by non-offseting convexity adjustments.

From the linearity of statistical operators applicable to stochastic processes, we expect the reciprocal of an action to offset the action of the primary transform, which is generally true for MFG of Gaussian random variables, expressing a projection of statistical expectations from epsilon space to natural probabilities.
A variant of the above formulation is to say that xt  N (µ t, 2 t) is a Gaussian random variable, where µ t is the mean and 2 t the variance. Given a bijective function f of real codomain and Ito^ process ft defined as ft = f (xt), where f -1(ft) is Gaussian distribution N (µt, vt) having mean µt and variance vt, the problem is equivalent to finding the implied convexity of function f -1 as applied to ft for all t  0. The trivial case when f is linear leads to complete offset of the effect of the vibrations of xt by the reciprocal. This is a particular case where variances before

6

Yuri Heymann

applying transformation f -1 and after reciprocal f is applied are identical. Yet, the approach consisting at computing the implied convexity from the variance of the reciprocal of some transform remains difficult in practice. A more suitable method referred to as thin-tile integration, which is based on a non-uniform grid spacing is provided further down, see section 4.0. The proceeding is the continuation of the stochastic approach to the lognormal distribution.

2.3 The zero-entropy principle and Gaussianity of stochastic processes resulting from non-linear transformations of a normally distributed process
Consider a base process xt having distribution N (µ1 t, 12 t), stemming from stochastic differential equation:

dxt = µ1dt + 1 dWt ,

(9)

where Wt is a Wiener process, µ1 and 1 real numbers representing timeless mean and volatility parameters.

Say f is a twice-differentiable continuous function which is invertible such that:

x

f (x) = 2(s)ds ,

(10)

x0

Given

f (x) x

=

2(x)

and

2f (x)  x2

=

2(x),

by

applying

It^o's

lemma

to

the

base

process in (9) with the function in (10), leads to:

dft =

µ12(f -1(ft))

+

1 2

12

2(f

-1(ft

))

dt + 12(f -1(ft)) dWt ,

(11)

where f -1 is the inverse of f and ft the Ito^'s process defined as ft = f (xt), where 2(f -1(ft)) = 2(xt). By normalizing expression (11) with 2(xt), yields:

dft = 2(xt)

µ1

+

1 2

12

2(xt) 2(xt)

dt + 1 dWt ,

(12)

By the aggregation of the drift in (12) into a single expression µ2(xt), yields:

ft

df

f0 2(f -1(f )) =

t 0

µ2(f 2(f

-1(fs -1(fs

)) ))

ds

+

t
1dWt ,
0

(13)

as a representation in integral form. By the derivative of the inverse of a function, say in a zero-entropy universe, we have:

f -1() =



ds

f0 2(f -1(s)) ,

(14)

where  is a non-vibrating variable. The application of Ito^'s lemma to the process

of ft with some function f -1(), would violate equality f -1(ft) =

ft

dft

f0 2(f -1(ft))

as defined in (14) for zero-entropy, i.e. where  is a non-vibrating variable. Say ft

Title Suppressed Due to Excessive Length

7

is the shifted process of ft satisfying the equality for zero-entropy to hold. Thus,

we have:

f -1(ft) = t µ2(f -1(fs)) ds + 1Wt , 0 2(f -1(fs))

(15)

Proposition 2 - Gaussianity condition: If f -1 spans R on the image of f , then f -1(ft) is Gaussian with distribution N (mt, vt) where mt is the mean and vt the variance of the process. As a counterexample, if the function f (x) = x in
(10) where x  R+, then f -1(ft) is not Gaussian.

Proof By considering the stochastic process Xt defined in way such that Xt =

=

t 0

g(Xs)ds+Wt

where

Wt

is

a

Wiener

process,



a

timeless

volatility

parameter

and g : R  R a twice differentiable function, we have: dXt = g(Xt)dt + dWt. As

Xt can be decomposed into an infinite sum of infinitesimal independent Gaussian

random variables, means that Xt is Gaussian. By considering a discretization of

the process into infinitesimal time intervals t, we get Xt+1 - Xt = g(Xt)t +  tZt where Zt is a standard normal random variable. By the first iteration, X1 = X0 +g(X0)t +  tZ0. Its corresponding increment expressed as X0 = g(X0)t+ tZ0, is a Gaussian infinitesimal. By the second iteration, X2 = X1 + g(X0+X0)t+ tZ1, its respective increment is X1 = g(X0+X0)t+ tZ1.

As increment X0 Taylor expansion

is infinitesimal, the approximation of (i.e. higher order terms negligible),

gle(aXd0s+toXg0()Xb0y+firsXt o0r)de=.r

g(X0) + g (X0)X0. Hence X1 = g(X0) + g (X0)X0 t +  tZ1. Thus as

t  0, X1 tends to a Gaussian infinitesimal. By the third iteration, we have X3 = X2 + g(X0 + X0 + X1)t +  tZ2, with respective increment X2 = g(X0 +X0 +X1)t+ tZ2. Because X0 and X1 are infinitesimal increments,

we approximate g(X0 + X0 + X1) by the first order bivariate Taylor expansion

oXf f1u)n=c.tio(n0,0()x+, y)x=(0g, 0(X)0X+0

x +

+ y) in (x, y) = (X0, X1). y(0, 0)X1 =g(X0)+g (X0

We get g(X0 + ) (X0 + X1).

X0 + Hence,

X2 = g(X0) + g (X0) (X0 + X1) t +  tZ2. Thus as t  0, X2 tends to

a Gaussian infinitesimal. By successive application of these steps in a recursive

fashion, we get that for all integers i = 0, ..., n, Xi is a linear combination of

X0,..,Xi-1 and Zi. By substitution of the expression of X0 into X1 and so

on, yields an expression of Xi as a linear combination of Z0,..,Zi for all integers

i = 0, ..., n. By adding together all the Xi, leads to an expression of Xt as a

linear combination of Z0,...,Zn, which are independent standard normal random variables. Hence, we can say that Xt is Gaussian. In (15), Xt = f -1(ft). For Xt to be Gaussian, f -1 must span R on the image of f as ft = f (xt); otherwise Xt

could not take all values in R, a prerequisite to be Gaussian. This constitutes proof

of proposition 2.

If f -1(ft) is Gaussian (see proposition 2 ), then linear operator E of the epsilon probability measure EQ as defined in (1) can be applied to expression f -1(ft). By proposition 1, this leads to:

E(f -1(ft)) = E(f -1(ft)) = mt .

(16)

Eq. (16) requires E(Wt) = 0, which is true in well-defined probability spaces.

By perfect symmetry of the reciprocal under zero-entropy principle, we have E(f -1(ft)) = f -1(E(ft)) yielding:

8

Yuri Heymann

f -1(E(ft)) = mt .

(17)

Thus, we have:

E^(ft) = f (mt) ,

(18)

where E^(ft) = E(f (xt)) is an estimator of the statistical expectation of function f as applied to variable xt of base process.

3 Characterisation of stochastic processes related to the lognormal MGF by zero-entropy principle
Let's apply the above to the MGF of the lognormal. By definition the MGF of the lognormal distribution of parameter µ and  is expressed as M () = E(eex ), where x  N (µ, 2) and   R.

3.1 From A-level stochastic calculus

Consider the base process xt defined as:

dxt = µdt + dWt ,

(19)

where Wt is a Wiener process, µ the drift,  the volatility and initial value x0 = 0. This process has a Gaussian distribution xt  N (µt, 2t).
By applying Ito^'s lemma to (19) with f (x) = eex and normalisation as per (11-12), we get:

dft = ft ln ft

µ

+

1 2 2

+

1 2 2

ln

ft

dt + dWt ,

(20)

From zero-entropy principle, we say there exists a shifted process ft such that

equality d(ln ln ft) =

dft ft ln ft

holds,

leading to:

ft ds =
f0 s ln s

t 0

µ

+

1 2 2

+

1 2 2

ln

fs

ds + Wt .

(21)

When   R+, we have:

ln ln(ft) = ln  +

µ + 12 2

t + 12 2

t
ln(fs)ds + Wt ,
0

(22)

When   R-1, we have:

ln(- ln(ft)) = ln(-) +

µ + 12 2

t - 12 2

t
ln(fs)ds + Wt .
0

(23)

by sign interchange of  through complex logarithm and reflection.

As per proposition 2, we can say that for all   R-, ln(- ln(ft)) in (23) is Gaussian with distribution N (mt, vt) where mt is the first moment and vt the variance of

Title Suppressed Due to Excessive Length

9

the process. The same can be said about Gaussianity of ln(ln(ft)) in (22) when  positive. To handle both signs of  belonging to R into a single expression, the sign function denoted sign(x) (which returns 1 when x is positive and -1 when negative), is invoked in the remaining of the manuscript.

3.2 The underpinning structure between the real and imaginary parts of process yt when extended to complex numbers

By setting yt = ln(sign() ln ft), (22-23) can be rewritten as follows:

yt = ln(||) +

µ + 12 2

t + sign() 1 2 2

t
eys ds + Wt .
0

(24)

As an extention to the complex plane, the above process yt is split into real and imaginary components according to yt = yR,t + i yI,t, where yR,t and yI,t are the real and imaginary parts respectively. In most settings, the bivariate normal

distribution relies on law of large numbers, as a particular case of multivariate

analysis. As from (24), the dependence between the marginals of yt is as follows:

yR,t =

(ln ||) +

µ + 12 2

t + sign() 1 2 2

t
cos(yI,s)eyR,s ds + Wt ,
0

(25)

and

yI,t =

(ln ||) + sign() 1 2 2

t
sin(yI,s)eyR,s ds .
0

(26)

where the logarithm is extended to C by inversion of complex exponentiation,

carrying signs as per the complex quadrant, and where sign() has correspondance

with sign of () (see de Moivre).

While the real part of process yt denoted yR,t vibrates according to some Gaussian spread, imaginary part yI,t exhibits some correlation with real counterpart. Notwithstanding, the joint distribution of yR,t and yI,t is departing from multivariate Gaussian, due to the application of Euler's formula to ei yI,t . Though the
real part of the process yR,t is normally distributed as per (25), its imaginary counterpart yI,t is a non-linear diffusive function of yR,t over full filtration Ft by the Wiener process Wt (see in (25)). Thus, we can say yI,t is non-Gaussian by non-linearity with respect to Gaussian process yR,t under the same probability measure.

3.3 Expression to characterise the first moment of process yt

Rewriting (22-23) as:

yt = ln(||) +

µ + 12 2

t + sign() 1 2 2

t
eys ds + Wt ,
0

(27)

where yt = ln(sign() ln ft) and  is real. As per proposition 2, yt  N (mt, vt) is a Gaussian process with mean mt and variance vt.

10

Yuri Heymann

By applying the statistical expectation as a linear operator to stochastic differential

equation

(27)

and

using

the

fact

that

E(

t 0

h(s)ds)

=

t 0

E (h(s)) ds

by

linearity,

we get:

E (yt) = ln(||) +

µ + 12 2

t + sign() 1 2 2

t
E (eyt ) ds .
0

(28)

The expected value of a lognormal variable expressed as z = ex, where x 

N (µ, 2)

equals

E(z)

=

eµ+

1 2

2

,

thus

leading

to:

E

(eyt )

=

e(mt

+

1 2

vt )

.

(29)

Note that (29) holds when  is a real, say for the MGF of negative  values, or
positive  values by reflection. This equality is no longer true when  is extended
to complex domain, as only the real component of yt = yR,t + i yI,t is Gaussian. Due to non-Gaussianity of the imaginary part yI,t as seen in §3.2, process yt is non Gaussian. The linear combination of a Gaussian and non-Gaussian variables
yields a non-Gaussian process, implying that Gaussianity of yt cannot be invoked to evaluate the statistical expection E (eyt ).

We can rewrite (28) as follows:

mt = ln(||) +

µ + 12 2

t + sign() 1 2

t

e(ms

+

1 2

vs

)

ds

.

20

(30)

As mt and vt can be viewed as real-valued functions sensitive to time t, no rules prevents direct derivation of expression (30) by the /t operator, leading to:

mt

=µ+

1 2

+

sign()

1

2

e(mt

+

1 2

vt

)

,

t

2

2

(31)

with initial condition m0 = ln(||). Eq. (31) is a differential equation describing the first moment of the process yt, when  is real.

3.4 Expression to characterise the variance of process yt

When  is real, the process (27) is Gaussian with yt  N (mt, vt). Hence, we can write:



yt = mt + vtZ ,

(32)

where Z  N (0, 1). We use the notation yt to denote yt in Gaussian representation.

As process in (32) is expressed in pure Gaussian representation, we can directly apply operator /t as a partial derivative to component functions, leading to:

yt t

=

mt

+

1 vt Z , 2 vt

(33)

where mt and vt are the time derivatives of mt and vt as functions. The variance of (33) is as follows:

V ar yt = 1 vt2 .

(34)

t

4 vt

Title Suppressed Due to Excessive Length

11

By setting yt = ln(sign() ln ft), (27) in SDE form can be expressed as follows:

dyt =

µ + 1 2 + sign() 1 2eyt

2

2

dt + dWt ,

(35)

Time integration as an operator, applied to Ito^'s processes expressing a simple difference dyt on the left-hand side, is not convex sensitive. Therefore, integration of (35) with respect to time, leads to:

yt - y0 =

t 0

µ + 1 2 + sign() 1 2eyt

2

2

dt + Wt ,

(36)

The application of operator /t as a partial derivative to functions carrying vibrations in (36) where the Wiener process is in its aggregated form Wt = t Z with Z  N (0, 1) requires special attention. Say SDE in (36) is expressed as yt = f (yt) + xt, where xt =  tZ is the source of vibrations.

The relation between yt and xt is obainedfrom bilinearity between pure Gaussian representation yt = at + bt Z and xt =  tZ, leading to:

yt = at + bt xt .

(37)

t

By separation of the time dimension from the vibrating variable, yields correspondance f (yt) = f (t, yt) in bivariate representation, where yt is a linear application of xt as per (37). By applying bivariate Taylor expansion to function f (t, yt) having for support bilinear correspondance between vibrating variable yt and the source of vibrations xt (up to second order), leads to:

f (t, yt)

=

f (t, yt) t t

+



f (t, yt yt

)

yt

+



f 2(t, yt ytt

)

ytt

+

1 2

f

2(t, t2

yt)

t2

+

+

1 2



f

2(t, yt2

yt)



yt2

+

...

.

(38)

where

f (t, yt)

=

f (t + t, yt + yt) - f (t, yt)

and

yt

=

bt t

xt

by

bilinearity

between xt and yt.

Let us rewrite (38) by expanding yt, leading to:

f (t, yt) t

=

f (t, yt) t

+

bt t

f (t, yt) yt

Wt t

+

bt t



f 2(t, yt ytt

)

Wt

+

1 2

f

2(t, t2

yt

)

t+

+

1 2

b2t t

f 2(t, yt) yt2

Wt t

Wt

+

... .

(39)

where

 Wt t

is

the

partial

derivative

of a

Wiener

process

in

its

aggregated

form.

The

terms

in

Wt

and

t

in

(39)

vanish

and

by

expressing

 Wt t

=

Z 1
2t1/2

we

get:

f (t, yt) = f (t, yt) + 1 bt f (t, yt) Z .

(40)

t

t

2 t yt

12

Yuri Heymann

In context integral of

of eyt

(36), over

by

some

approximation

we

have

f (t,yt)  yt



t

f (t,yt) t

as

the

a time interval t is the average value of the function over that

interval multiplied by the width of the interval.

The application of the /t operator to non-homogeneous Ito^'s processes as in

(36),

results

in

an

additional

term



=

1 bt 2t

f (t,yt)  yt

Z

as

per

(40).

By

crossover

of

 with the other terms in (41) leads to additional covariances. As a simplification,

in

the

below

we

applied

a

single

adjustment

to



f

(t,yy t

)

,

expressed

as

a

factor

product G = 1 + 1/2 2.

As applied to SDE (36) with adjustment factor G = 1 + 1/2 2, leads to:

yt = µ + 1 2 + sign() 1 2 G eyt + 1 t-1/2Z .

(41)

t

2

2

2

 As from yt = mt + vt Z where Z  N (0, 1), the variance of (41) is as follows:

V ar

yt

= 1 4G2V ar


emt+ vtZ

1 2

1 3

+ +sign()

G Cov


emt+ vtZ , Z

.

t

4

4t

2 t1/2

(42)

The identity V ar(X + Y ) = V ar(X) + V ar(Y ) + 2Cov(X, Y ) was invoked in (42).

For a lognormal random variable u = ex where x  N (µ, 2), we have V ar(u) = e2 - 1 e2µ+2 , leading to:


V ar emt+ vtZ = (evt - 1) e2mt+vt .

(43)

The valuation of the covariance term in (42), invokes formula Cov(X, Y ) = E(XY )-

E(X)E(Y ). As E(Z) = 0, the covariance term equals I = E Zemt+ vtZ . We have:

We can write:

I=



xemt

 + vt

x

1

e-

1 2

x2

dx

.

-

2

(44)

leading to:

I = 1



xemt

 + vt

x-

1 2

x2

dx

,

2 -

(45)

I = - 1



 ( vt

-


x)emt+ vtx-

1 2

x2 dx

+

2 -

vt



emt

 + vt

x-

1 2

x2

dx

.

(46)

2 -

The first term of integral I is equals to zero, by asymptotic convergence as both branches tend to infinity, leading to:

I=

vt



emt

+vt

x-

1 2

x2

dx

.

2 -

As

we

have

mt

+

 vtx

-

1 2

x2

=

-

1 2

(x

-

vt)2

+

mt

+

1 2

vt

,

we

can

write:

(47)

Title Suppressed Due to Excessive Length

13

I

=

 vt

e(mt

+

1 2

vt

)

1 

e-

1 2

(x-vt

)2

dx

.

(48)

- 2



The integrant in (48) is the density function of a Gaussian variable with mean vt

and unit variance. Its integral over the real domain is equal to one. We get:

I

=

 vt

e(mt

+

1 2

vt

)

.

(49)

Hence:

V ar

yt t

=

1 G24 (evt 4

- 1) e2mt+vt

+

1 2 4t

+ sign()

1 3 2 t1/2

G

 vt

e(mt +

1 2

vt )

.

(50)

By coupling (34) with (50), i.e. yt and yt express the same SDE, we get:

vt = t

vt2 t

+ vt4G2 (evt

- 1) e2mt+vt

3 + sign() 2 t1/2

G

vt3/2

e(mt +

1 2

vt )

,

(51)

with initial conditions v0 = 0 and vt|t=0 = 2 and G = 1 + 1/22. Eq. (51) is a differential equation describing the variance of the process yt, where  is real.

4 The statistical expectation of f (x) with x  N (µ, 2) by thin-tile integration method
Thin-tile integration is an efficient method to compute the statistical expectation of a continuous function f : R  R of a Gaussian random variable x  N (µ, 2), where µ is the mean and  the standard deviation. This method consists of a non-uniform grid spacing built as a continuum of thin tiles (see figure 1), which further benefits from the symmetry of the Gaussian distribution.

Fig. 1 Thin tile connecting two points P1 and P2 of the density function of the Gaussian distribution, where h is the little height and x the width.
The rationale is to dynamically determine the width of grid elements from adjacent tiles, connecting points of the density function of the Gaussian distribution by their

14

Yuri Heymann

edges, and where the little height h is fixed. By considering squarish tiles of sides

h × h, the relation betwen the number of pairs of tiles N to cover the vault of the

curve (see figure 2) and h is expressed as h = 1/(2N ). The slope coefficient for a

tile

is

defined

as

s

=

h/x,

yielding

a

tile

area

expressed

as

A

=

h2 s

.

The

tiles

are

placed two-by-two in a symmetrical fashion on both sides of the Gaussian density

function, by order starting from the mode of the curve and prolonged to the tails.

As the overall area under the density function between both extremum spanned by

the

first

n

pairs

of

tiles

placed

on

the

bell

curve

is

expressed

as

An

=

1-2

(

µ-xn 

),

where  is the cumulative density function of the standard Gaussian distribution

N (0, 1). By the squared tile rule, the slope coefficient used to determine the area at the nth pair of tiles disposed on the curve, is set to be equal to the derivative

of the density function floored to one, leading to:

sn = max

1.0,

µ - xn-1 

(xn-1)

,

(52)

where (x) = 1 exp
 2

-

(x-µ)2 2 2

is the density function of the Gaussian dis-

tribution N (µ, 2) of mean µ and standard deviation , where xn-1 represents

the rightmost extremum of the nth - 1 pair of tiles and where x0 = µ. The slope

coefficient is used to determine the cumulative area An under the density function

by

tiny increments An

=

2

h2 sn

of

the

area

covered

by

the nth

pair of

tiles.

Fig. 2 Disposition of thin-tiles on the curve of a Gaussian density function forming a vault.

From the above, the coordinate referrring to the nth step on the right of the curve is as follows:

xn = µ -  -1

1 - An 2

,

(53)

where -1 is the inverse cumulative density function of the standard Gaussian distribution N (0, 1) and An the cumulative area under the density function.

For each step indexed by n = 1, ..., N - 1  N corresponding to a pair of tiles layed on the density function of the Gaussian distribution, yields an observable of the function of the Gaussian variable, which by arithmetic mean from points

disposed symmetrically around the mode of the distribution, leads to:

1

fn = 4 [f (xn) + f (xn-1) + f (µ - xn) + f (µ - xn-1)] ,

(54)

Title Suppressed Due to Excessive Length

15

as an observable of f (x) weighted by the incremental area An corresponding to the nth pair of tiles disposed on the curve. We finally compute the weighted averge
of the N - 1 observations of f (x) representing the statistical expectation of f (x) under natural probability measure, where x  N (µ, 2) as a Gaussian distribution
of mean µ and standard deviation .

5 Numerical results

The MGF of the lognormal distribution with parameter µ,  and where  is real, is expressed as M () = E(f1) where the shifted process ft is coming from the stochastic differential equations (22, 23). The parametric functions m1 and v1 are evaluated by integration of differential equations (31) and (51) over a unit time interval T = [0, 1].

We solve these integrals by discretisation over the domain of integration T ,

introducing small time increments t. We start the calculation from time t0 = 0

and

iteratively

compute

 mt t

and

 vt t

using piecewise

linear

segments,

leading to

the evaluation mt and vt at the next time step until reaching t1 = 1. The numerical

scheme consists of:

mi+1

= mi +

mt t

t ,
i

(55)

and

vi+1

= vi +

vt t

t ,
i

(56)

at each iteration.

The initial conditions are given by m0 = ln(||), v0 = 0 and vt|t=0 = 2. Once we get the endpoint m1, the estimator of the MGF of the lognormal distribution is given by M^ () = esign() em1 . This is the approach for the valuation of the MGF of
the lognormal under zero-entropy principle, i.e. ft shifted to ft under non-vibrating variable, and reciprocal by symmetry.

As a reference, the MGF of the lognormal distribution as given by the Laplace transform of the lognormal in [2], is expressed as follows:

exp M^ L() 

- W 2(-2eµ)+2W (-2eµ)
22
1 + W (-2eµ)

,

(57)

where W is the Lambert-W function defined as the inverse function of f (w) = w exp(w).
The valuation of the MGF of the lognormal are summarized in tables 1, 2 and 3 for a range of  values. Parameter µ was set to zero in all three tables, whereas standard deviation set to  = 0.1 for table 1,  = 0.0625 for table 2 and  = 1.0 for table 3. With regard to the zero-entropy stochastic approach, 2'000 equidistant time steps were used part of the discretisation algorithm. The accuracy was set to 1.0 × 10-6 for the Lambert function as part of the Asmussen, Jensen and Rojas-Nandayapa method. For thin-tile integration, the little height was set to

16

Yuri Heymann

h = 0.0025, i.e. N = 80, 000. In contrast, plain vanilla Monte Carlo simulation for

the estimation of the MGF lognormal required a sample size of about 100 millions

of observations to achieve commensurate accuracy level. Note that in table 1 where  is positive, the variance was initialised to v0 = 2 when using the approximate

factor G, which is a side effect for not using proper covariances of  with the other

terms in (41). As a

term

1 23/2

5

 vt

e2

hint,

the

approximation





1 2



f (t,yt) t

yields

mt+vt from its covariance with non-homogeneous

an additional

term

1 2

2

eyt

in (41). Whenever  is negative as in table 2 and 3, this variable was properly

initialised to v0 = 0.

Table 1 Table for MGF of the lognormal when  is positive with  = 0.1



0.1

0.3

0.5

1.0

Monte Carlo simulation Stochastic approach based on zero-entropy principle Thin-tile integration method Asmussen, Jensen and RojasNandayapa approximation

1.105779 1.105780
1.105781 1.105780

1.352510 1.352506
1.352509 1.352504

1.654955 1.654957
1.654966 1.654957

2.745936 2.745994
2.745978 2.745950

1.2 3.365014 3.365088
3.364940 3.364990

Table 2 Table for MGF of the lognormal when  is negative with  = 0.0625



-0.5

-1.0

-2.0

-4.0

Monte Carlo simulation Stochastic approach based on zero-entropy principle Thin-tile integration method Asmussen, Jensen and RojasNandayapa approximation

0.606235 0.606234
0.606235 0.606235

0.367884 0.367879
0.367880 0.367880

0.135863 0.135863
0.135862 0.135862

0.018744 0.018746
0.018744 0.018744

-8.0 0.000373 0.000373
0.000373 0.000373

Table 3 Table for MGF of the lognormal when  is negative with  = 1.0



-0.5

-1.0

-2.0

-4.0

Monte Carlo simulation Stochastic approach based on zero-entropy principle Thin-tile integration method Asmussen, Jensen and RojasNandayapa approximation

0.561707 0.560233
0.561708 0.561717

0.381729 0.367879
0.381755 0.381752

0.216326 0.238030
0.216305 0.216304

0.098069 0.159668
0.098046 0.098042

-8.0 0.034274 0.118724
0.034264 0.034267

6 Conclusion
Thin-tile integration and the Laplace transform of the logonormal by Asmussen, Jensen and Rojas-Nandayapa are in good agreement, giving values for the lognormal MGF in all three settings: positive  values, negative  values, and high

Title Suppressed Due to Excessive Length

17

volatilities, i.e.  = 1.0, at an accuracy of 5 to 6 digits after the decimal point, providing a valuable benchmark for the stochastic approach discussed below.
The stochastic approach by the application of Ito^'s calculus to the lognormal MGF, is based on the so-called zero-entropy principle and the symmetry of an action and reciprocal. While the stochastic approach yields lognormal MGF values in pretty good agreement with the aforementioned methods for negative  values, matching the benchmark with an accuracy of about 6 digits after the decimal (see table 2), tiny differences in the order of 0.1 to 1.0 basis points were obtained in table 1 for positive  values, and larger deviations in table 3 when applied to vibrations carrying higher volatilities, i.e.  set to one. Although variations observed in table 1 and 2 could be attributed to numerical imprecisions, the slight departures from the benchmark occuring at higher volatilities as seen in table 3 are of statistical significance. As an explanation for these small differences, present study provides support for the partial offset by the reciprocal of an action as applied to SDEs carrying vibrations, interpreted as an asymmetry under zero-entropy principle or non-linearity of the E operator of the probability space E· corresponding to the statistical expectation in epsilon probability measure. Notwithstanding, the foregoing does not preclude from other sources of inaccuracies such as covariances from the crossover of  with other terms in (41).
Moreover, non-Gaussianity of the underlying process when extended to the complex domain as seen in §3.2, is preventing the lognormal MGF from the stochastic approach to be applicable to complex numbers, a prerequisite for the characteristic function. As puzzling as this may be, non-Gaussianity of the underlying process when extended to complex numbers is an aspect having a connection with application of Euler's formula and the structure of the underlying stochastic differential equations. Finally, the asymmetry from the partial offset by the reciprocal of an action as applied to systems carrying vibrations, is a principle having applications in other fields such as quantum theory, e.g. asymmetries of harmonic oscillators, zero-point vibration preventing liquid helium from freezing at atmospheric pressure, etc.

References
1. J. Asad, P. Mallick, M. E. Samei, B. Rath, P. Mohapatra, H. Shanak, and R. Jarrar. Asymmetric variation of a finite mass harmonic like oscillator. Results in Physics, 19:1­7, 2020.
2. S. Asmussen, J.L. Jensen, and L. Rojas-Nandayapa. On the Laplace transform of the lognormal distribution. Methodology and Computing in Applied Probability, 18:441­458, 2016.
3. R. Barakat. Sums of independent lognormally distributed random variables. Journal of the Optical Society of America, 66:211­216, 1976.
4. N.C. Beaulieu and Q. Xie. An optimal lognormal approximation to lognormal sum distribution. IEEE Transactions on Vehicular Technology, 53:479­489, 2004.
5. B. Crosignani and P. Di Porto. Asymmetric linear oscillator and fine-structure constant. Physics Letters A, 127:395­398, 1988.
6. N.G. de Bruijn. Asymptotic methods in analysis, pages 584­599. Courier Dover Publications, 1970.
7. J.A. Gubner. A new formula for lognormal characteristic functions. IEEE Transactions on Vehicular Technology, 55:1668­1671, 2006.
8. C.C. Heyde. On a property of the lognormal distribution. The journal of the Royal Statistical Society Series B, 25:392­393, 1963.

18

Yuri Heymann

9. P. Holgate. The lognormal characteristic function. Communications in Statistics - Theory and Methods, 18:4539­4548, 1989.
10. R.B. Leipnik. On lognormal random variables: I-the characteristic function. Journal of Australian Mathematical Society Series B, 32:327­347, 1991.
11. J.P. Romano and A.F. Siegel. Counterexamples in Probability and Statistics, pages 46­47. Chapman & Hall/CRC, 1986.
12. D. W. Sciama. The Physical Signifiance of the Vacuum State of a Quantum Field. In Saunders, S. W. & Brown, H. R. eds, The Philosophy of Vacuum, Oxford University Press., 1991.
13. C. Tellambura and D. Senaratne. Accurate computation of the MGF of the lognormal distribution and its application to sum of lognormals. IEEE Transactions on Communications, 58:1568­1577, 2010.

