
# RAI-Net: Range-Adaptive LiDAR Point Cloud Frame Interpolation Network

[arXiv](https://arxiv.org/abs/2106.0496), [PDF](https://arxiv.org/pdf/2106.0496.pdf)

## Authors

- Lili Zhao
- Zezhi Zhu
- Xuhu Lin
- Xuezhou Guo
- Qian Yin
- Wenyi Wang
- Jianwen Chen

## Abstract

LiDAR point cloud frame interpolation, which synthesizes the intermediate frame between the captured frames, has emerged as an important issue for many applications. Especially for reducing the amounts of point cloud transmission, it is by predicting the intermediate frame based on the reference frames to upsample data to high frame rate ones. However, due to high-dimensional and sparse characteristics of point clouds, it is more difficult to predict the intermediate frame for LiDAR point clouds than videos. In this paper, we propose a novel LiDAR point cloud frame interpolation method, which exploits range images (RIs) as an intermediate representation with CNNs to conduct the frame interpolation process. Considering the inherited characteristics of RIs differ from that of color images, we introduce spatially adaptive convolutions to extract range features adaptively, while a high-efficient flow estimation method is presented to generate optical flows. The proposed model then warps the input frames and range features, based on the optical flows to synthesize the interpolated frame. Extensive experiments on the KITTI dataset have clearly demonstrated that our method consistently achieves superior frame interpolation results with better perceptual quality to that of using state-of-the-art video frame interpolation methods. The proposed method could be integrated into any LiDAR point cloud compression systems for inter prediction.

## Comments

Accepted by the IEEE International Symposium on Broadband Multimedia Systems and Broadcasting 2021

## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{zhao2021rainet,
      title={RAI-Net: Range-Adaptive LiDAR Point Cloud Frame Interpolation Network}, 
      author={Lili Zhao and Zezhi Zhu and Xuhu Lin and Xuezhou Guo and Qian Yin and Wenyi Wang and Jianwen Chen},
      year={2021},
      eprint={2106.00496},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
}
```

## Notes

Type your reading notes here...

