
# Hierarchical Representation Learning for Markov Decision Processes

[arXiv](https://arxiv.org/abs/2106.01655), [PDF](https://arxiv.org/pdf/2106.01655.pdf)

## Authors

- Lorenzo Steccanella
- Simone Totaro
- Anders Jonsson

## Abstract

In this paper we present a novel method for learning hierarchical representations of Markov decision processes. Our method works by partitioning the state space into subsets, and defines subtasks for performing transitions between the partitions. We formulate the problem of partitioning the state space as an optimization problem that can be solved using gradient descent given a set of sampled trajectories, making our method suitable for high-dimensional problems with large state spaces. We empirically validate the method, by showing that it can successfully learn a useful hierarchical representation in a navigation domain. Once learned, the hierarchical representation can be used to solve different tasks in the given domain, thus generalizing knowledge across tasks.

## Comments



## Source Code

Official Code



Community Code

- [https://paperswithcode.com/paper/hierarchical-representation-learning-for-1](https://paperswithcode.com/paper/hierarchical-representation-learning-for-1)

## Bibtex

```tex
@misc{steccanella2021hierarchical,
      title={Hierarchical Representation Learning for Markov Decision Processes}, 
      author={Lorenzo Steccanella and Simone Totaro and Anders Jonsson},
      year={2021},
      eprint={2106.01655},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```

## Notes

Type your reading notes here...

