
# BERT-Defense: A Probabilistic Model Based on BERT to Combat Cognitively Inspired Orthographic Adversarial Attacks

[arXiv](https://arxiv.org/abs/2106.01452), [PDF](https://arxiv.org/pdf/2106.01452.pdf)

## Authors

- Yannik Keller
- Jan Mackensen
- Steffen Eger

## Abstract

Adversarial attacks expose important blind spots of deep learning systems. While word- and sentence-level attack scenarios mostly deal with finding semantic paraphrases of the input that fool NLP models, character-level attacks typically insert typos into the input stream. It is commonly thought that these are easier to defend via spelling correction modules. In this work, we show that both a standard spellchecker and the approach of Pruthi et al. (2019), which trains to defend against insertions, deletions and swaps, perform poorly on the character-level benchmark recently proposed in Eger and Benz (2020) which includes more challenging attacks such as visual and phonetic perturbations and missing word segmentations. In contrast, we show that an untrained iterative approach which combines context-independent character-level information with context-dependent information from BERT's masked language modeling can perform on par with human crowd-workers from Amazon Mechanical Turk (AMT) supervised via 3-shot learning.

## Comments

Findings of ACL 2021

## Source Code

Official Code

- [https://github.com/yannikkellerde/BERT-Defense](https://github.com/yannikkellerde/BERT-Defense)

Community Code

- [https://paperswithcode.com/paper/bert-defense-a-probabilistic-model-based-on](https://paperswithcode.com/paper/bert-defense-a-probabilistic-model-based-on)

## Bibtex

```tex
@misc{keller2021bertdefense,
      title={BERT-Defense: A Probabilistic Model Based on BERT to Combat Cognitively Inspired Orthographic Adversarial Attacks}, 
      author={Yannik Keller and Jan Mackensen and Steffen Eger},
      year={2021},
      eprint={2106.01452},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

## Notes

Type your reading notes here...

