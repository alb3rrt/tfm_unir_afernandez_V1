JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

1

Towards Cost-Optimal Policies for DAGs to Utilize IaaS Clouds with Online Learning

Xiaohu Wu, Han Yu, Giuliano Casale, and Guanyu Gao

Abstract--Premier cloud service providers (CSPs) offer two types of purchase options, namely on-demand and spot instances, with time-varying features in availability and price. Users like startups have to operate on a limited budget and similarly others hope to reduce their costs. While interacting with a CSP, central to their concerns is the process of cost-effectively utilizing different purchase options possibly in addition to self-owned instances. A job in data intensive applications is typically represented by a directed acyclic graph which can further be transformed into a chain of tasks. The key to achieving cost efficiency is determining the allocation of a specific deadline to each task, as well as the allocation of different types of instances to the task. In this paper, we propose a framework that determines the optimal allocation of deadlines to tasks. The framework also features an optimal policy to determine the allocation of spot and on-demand instances in a predefined time window, and a near-optimal policy for allocating self-owned instances. The policies are designed to be parametric to support the usage of online learning to infer the optimal values against the dynamics of cloud markets. Finally, several intuitive heuristics are used as baselines to validate the cost improvement brought by the proposed solutions. We show that the cost improvement over the state-of-the-art is up to 24.87% when spot and on-demand instances are considered and up to 59.05% when self-owned instances are considered.
Index Terms--On-demand instances, spot instances, cost efficiency, online learning.
!

arXiv:2106.01847v1 [cs.PF] 3 Jun 2021

1 INTRODUCTION
The worldwide Infrastructure as a Service (IaaS) cloud market is attracting various users and grew 37.3% in 2019 to total $44.5 billion [1]. IaaS enables users to escape purchase and maintenance of servers whose capacity has to satisfy their peak demand to avoid unacceptable latency. Users can scale up or down their computing capacity by renting servers from IaaS providers to match the variation in demand over time. The dominant IaaS providers include Amazon Elastic Cloud Compute (EC2), Microsoft Azure, and Google Cloud, accounting for 45.0%, 17.9% and 5.3% of the global market share respectively. The ongoing COVID-19 pandemic also provides a further push for the adoption of IaaS as more enterprises move their applications to public clouds. To bridge the gap between IaaS providers and users, the key is to determine the process for users to cost-effectively use IaaS services, which enhances user engagement and satisfaction and long-term sustainability of cloud ecosystems [2].
On-demand and spot instances are two typical purchase options [36]. On-demand instances are always available at a fixed price once requested by users. Users pay only when instances are actually consumed. Differently from Amazon EC2, spot instances are called spot virtual machines (VMs) in Microsoft Azure [5] and preemptive VM instances in Google Cloud [6]. Spot instances have uncertain availability. Generally, CSPs may reclaim the resources of spot instances at any time point for other purposes. In
· Xiaohu Wu and Han Yu are with the School of Computer Science and Engineering, Nanyang Technological University, Singapore. E-mail: {xiaohu.wu, han.yu}@ntu.edu.sg
· Giuliano Casale is with the Department of Computing, Imperial College London, United Kingdom. E-mail: g.casale@imperial.ac.uk
· Guanyu Gao is with the School of Computer Science and Engineering, Nanjing University of Science and Technology, China. E-mail: gygao@njust.edu.cn
Manuscript received April 19, 2005; revised August 26, 2015.

Google Cloud, spot prices are fixed and the instance availability only depends on the dynamics of system resources. In Amazon EC2 and Microsoft Azure, spot prices vary over time and a user needs to bid a price for spot instances; the instance availability also depends on the relation of the spot and bid prices. Spot instances can reduce costs by up to 50-90% compared to on-demand instances [4]. On the other hand, a user can have its own instances, called self-owned instances, which, although insufficient at times, can be extended with additional IaaS instances purchased ondemand from the cloud. Also, some users may have no selfowned instances (e.g., in the case of startups) and need to buy all necessary computing resources.
Previous works [9], [10], [11], [12] have enabled costeffectively processing a special type of workloads, namely maponly tasks [8], [13], [14]; each task is partitioned into a large number of independent sub-tasks that can be executed on multiple instances simultaneously; there is also a parallelism bound specifying the maximum number of instances that the task can utilize simultaneously. However, such tasks are independent and can only cover a limited number of important applications. The workload is more generally described by a directed acyclic graph (DAG) whose nodes are tasks and whose edges represent precedence constraints among tasks [8], [15]; each DAG is referred to as a job. Examples of such jobs include the workloads of MapReduce and Spark's RDDs [19], [20], [21], which are fundamental programming paradigms for big-data processing. For a user, its jobs arrive over time, each with a specific timing requirement, i.e., a deadline by which to complete all its tasks. Each job will be allocated instances of different types (self-owned, on-demand and spot). Our problem is to find an allocation that minimizes cost while meeting the deadline requirement of the job and the precedence constraints among its tasks. Challenges. The costs of self-owned, spot and on-demand instances are increasing. To be cost-optimal, the objective of an

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015
allocation policy should be maximizing the utilization of selfowned and then spot instances and minimizing the utilization of costly on-demand instances. One component of our framework is the policy for allocating different types of instances to a single task to be executed in a predefined time window and it involves determining the proportions of different instances. Previous works [10], [12] consider a discrete allocation case where the allocation of spot and on-demand instances is updated on an hourly basis, which arises in a class of instances in Amazon EC2 where the billing of on-demand instances is done on an hourly basis. In this paper, we consider the continuous allocation case with a reformulated analysis; here, users pay for the exact period in which on-demand instances are consumed. The resulting framework applies to the other class of instances in Amazon EC2 and the instances of Microsoft Azure and Google Cloud.
The other new aspect is addressing the precedence constraints among the tasks of a job. A task can be executed only when all its preceding tasks have been finished. For analytical tractability, a DAG job is normally transformed into a job with a chain precedence constraint (i.e., a sequence of tasks) where one task can be executed only if its preceding task is completed [15]. Spot instances are available at irregular intervals. The minimum execution time needed to finish a single task is its workload divided by its parallelism bound. Suppose a user has no selfowned instances. An intuitive greedy strategy does not work well: it first requests to fully utilize spot instances to finish tasks one by one until some time point after which all remaining tasks have to fully utilize costly on-demand instances to meet the job deadline. In contrast, difference exists among tasks and the capacity of a task utilizing spot instances depends on its characteristics and the length of an associated time window in which it is executed. Given a job, its tasks can be executed from its arrival time until its deadline, and a proper allocation of time window sizes to its tasks is needed to maximize the total utilization of spot instances. Our Contributions. Technically, the main contribution of this paper is to propose a framework that enables utilizing a class of IaaS services to process jobs with chain precedence constraints cost-effectively, where on-demand instances are charged for the period in which they are exactly consumed:
· In the case that a single task is to be executed in a time window, we derive policies that allocate spot and ondemand instances cost-optimally and self-owned instances cost-effectively. This is the basis to derive the capacity that a task can achieve to utilize spot instances, given the time window length.
· A job has multiple tasks. We derive an optimal yet efficient allocation of time window sizes to the tasks, based on a formulation of the problem as an integer linear program to maximize the utilization of spot instances. The allocation algorithm can be used both when the tenant has self-owned resources and when it does not.
Leveraging existing techniques in combinatorial optimization, a DAG job can be transformed into a job with a chain precedence constraint [15]. Consequently, our technical framework can be used to cost-effectively utilize cloud services for the general DAG jobs. It applies to a significant class of instances in Amazon EC2 and the instances of Microsoft Azure and Google Cloud. Experimentally, several intuitive heuristics are used as baselines to validate the cost improvement brought by the proposed solutions. The cost saving is up to 24.87% when spot and on-

2
demand instances are considered and up to 59.05% when selfowned instances are considered. In our framework, the policies and algorithm are parametric, in terms of the availability of spot instances and the sufficiency of self-owned instances. Like [12], we leverage the online learning technique of [9], [10] to infer these parameters. We note that the sufficiency is indicated by a parameter 0 that controls the allocation of self-owned instances (see Section 4.2.1); the more self-owned instances a user has, the smaller the value of 0 and the more self-owned instances each task gets allocated. While a user requests spot instances, their availability is quantified as the averaged proportion of the period in which spot instances are available.
The rest of this paper is organized as follows. The related work is introduced in Section 2. We formally describe the problem in Section 3. In Section 4, we propose a technical framework for allocating deadlines and self-owned, on-demand and spot instances. In Section 5, we introduce the existing techniques for job transformation and online learning, which will be integrated into our framework. Experimental results are given in Section 6 to validate the effectiveness of the solutions of this paper. Finally, we conclude this paper in Section 7.
2 RELATED WORK
To date, multiple service and pricing models have been proposed [33], [35] and the spot and on-demand service model is a major service offering [32], [34], [36]. Jain et al. are the first to enable the application of an online learning approach to infer the cost-effective parametric policy for utilizing spot and on-demand instances [9], [10]. The key to achieving cost efficiency is the design of a parametric policy and another limitation of [9], [10] is that self-owned instances are not considered. Next, with this approach, Wu et al. formalize the instance allocation process and derive the expected optimal parametric policy for spot and on-demand instances and the near-optimal parametric policy for self-owned instances [11], [12]. The works [9], [10], [11], [12] simply consider the allocation to independent map-only tasks. Also, in their framework, on-demand instances are charged on an hourly basis, and users have to consider maximizing the usage of instances to integer hours to avoid extra charge. In our framework, users pay by the second and thus for what they exactly consume. Thus, our policies for a single task have different forms than the policies of [11], [12]. We will also propose an approach to deal with the precedence constraints among tasks. The online learning approach is interesting in that it does not need prior statistical workload characterization, compared to other techniques such as stochastic programming.
Also, there are other works that simply consider independent tasks and associate a specific deadline with each task to make the instance allocation process manageable. Specifically, Zafer et al. use a Markov model to characterize spot prices and derive an optimal bidding strategy to utilize spot instances [16]. Yao et al. formulate the problem of utilizing reserved and on-demand instances as an integer program, and propose heuristic algorithms that give approximate solutions [17].
Now, we briefly review other approaches to cost-effective use of cloud services. There is one class of works based on priori statistical knowledge of the workload or spot prices. For instance, Hong et al. and Chaisiri et al. apply stochastic programming for reserved and on-demand instances [18], [22]; Zheng et al. derive the optimal bidding strategy for spot instances [31]. However, the

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015
computational cost of deriving the related statistical knowledge is high [25]. Wang et al. apply the Bahncard problem for reserved and on-demand instances and the resulting algorithm is analyzed by competitive analysis [23]. Vintila et al. propose a genetic algorithm for spot and on-demand instances [24]. Shi et al. apply Lyapunov optimization and are among the first to jointly utilize the three common types of cloud instances [25]; yet, a large job delay is incurred [12]. Gao et al. consider the joint resource provisioning and task scheduling and propose a two-timescale markov decision process approach to maximize the profit of a multimedia service provider [26]. Dubois et al. propose a heuristic to help cloud users decide the right type of spot instances and the bid price, aiming to minimize the cost while maintaining an acceptable level of performance [27], [28].
3 PROBLEM DESCRIPTION AND MODEL
In this section, we introduce the cloud pricing models, define the operational space of a user to utilize various instances, and characterize the objective of this paper.

3
Fig. 1: Availability of Cloud Instances: the black (resp. grey) segments imply the corresponding instances are available (resp. unavailable) as time goes by.
To sum up, availability and price are two key features in cost management. From a user perspective, on-demand instances are always available as if the CSP has infinite on-demand instances to deliver. A user can also request multiple spot instances, which however are available occasionally. The availability of on-demand and spot instances is illustrated in Figure 1. If any, self-owned instances are finite and are always available; however, they may be insufficient at times to satisfy the user computing need. The costs of utilizing self-owned, spot, and on-demand instances are increasing.

3.1 Resource Availability and Pricing Structure
On-demand and spot instance services available at popular CSPs may be modelled as follows. First, the price p of an ondemand instance is fixed per unit of time and such instances are always available once requested by a user. For example, the price of utilizing an instance for one hour is posted to users that pay for computing capacity by the second. When a user utilizes an instance for x hours, it is charged p · x where x can be fractional. This is more convenient to users compared with other pricing where billing is done on an hourly basis; in the latter, users have to consider maximizing the usage of instances to integer hours to avoid extra charge.
Second, a user can also request spot instances at a lower price than on-demand instances. Their availability varies over time and users can only utilize spot instances occasionally. Factors affecting availability include the idleness of cloud systems generally and the bid price in some scenarios. The cloud can reclaim spot instances allocated to a user at any time whenever it needs to access to those resources for other high-priority jobs; the bid price is the maximum price that a user is willing to pay for spot instances. In Google cloud, spot instances are offered at a fixed price; they are delivered to a user when there are idle instances. In Amazon EC2 and Microsoft Azure, the price of spot instances varies over time; a user successfully gets the spot instances only if its bid price exceeds the spot price; spot instances are reclaimed by the cloud when either there are inadequate resources or the bid price is below the spot price. From a user perspective, spot service is a type of stochastic service. When a user persistently requests spot instances, the spot service commences at random time points and lasts for random durations. To facilitate analysis, we let  denote the average portion for which a user can spot instances per unit of time where   (0, 1).
Third, a user might have its own instances, i.e., self-owned instances, whose amount is limited or zero and denoted by r. If any, the (averaged) cost of utilizing self-owned instances is assumed to be the cheapest compared with cloud instances, which implies that a user always prefers to first utilize its own instances before purchasing instances from the cloud. Thus, without loss of generality, this cost is assumed to be zero.

3.2 DAG-Structured Jobs

As the time horizon expands, the job arrival of a tenant is

monitored at every moment. The tenant plans to rent instances

from IaaS clouds to process its jobs and aims to minimize the cost

of completing a set of jobs J (that arrive over a time horizon

T ) by their deadlines. Following [10], [12], [15], each job j is

characterized by a DAG. It has an arrival time aj and a deadline dj, that is, job j can be executed and has to be finished in a time window [aj, dj]. The main notation of this paper is summarized

in Table 1. The DAG nodes represent tasks and the directed edges

represent precedence relations. Each DAG job j has l tasks and

different jobs may have different values of l. We use i1  i2 to indicate the execution of task i2 can begin only after task i1 is completed. Thus, a task i can be executed when all its preceding

tasks are completed.

Each task of job j consists of a large number of negligible

sub-tasks that are independent and can be executed on multiple

instances simultaneously. Completing a task means completing

all its sub-tasks. Formally, each task i of job j has a workload

zi and an upper bound i of parallelism. While executing task i, the number of instances assigned to task i could change over

time; the parallelism bound i limits the maximum number of instances that can be used to execute task i simultaneously. zi is the instance time that task i has to consume in order to be finished.

For example, suppose zi = 2; to finish task i, it needs to consume

one instance for two units of time or two instances for one unit

of time. When the task i is always executed on the maximum

number i of instances, it has the minimum execution time, which

is denoted by

ei

=

zi . i

(1)

3.3 Problem Description
Each job j must be finished in a time window [aj, dj]. We first need to determine a time window [~i, i] in which each task i of job j is executed, while respecting the precedence constraints among the tasks. ~i is the earliest time at which all its preceding tasks i are finished where i  i and at which the execution of i can begin. i is the deadline by which task i has to be finished.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

4

TABLE 1: Main Notation

Symbol J
j and aj dj l i zi i ei i ~i ^i r
z~i
z~i(t) zio 
0
N (t)
N (t1, t2)
si and oi ri i

Explanation a set of jobs that arrive over time
a job of J and its arrival time the deadline: job j must be completed by time dj
the number of tasks in a job j a task i in job j where i  {1, 2, · · · , l} the size/workload of task i, measured in instance time the parallelism bound, i.e., the maximum number of instances that can be simultaneously used by task i the minimum execution time of task i, i.e., ei = zi/i the deadline by which task i has to be finished the earliest time at which the execution of task i can begin the time window size of task i where ^i = i - ~i
the number of self-owned instances at time ~i, the workload of task i to be processed by spot
and on-demand instances at time t  [~i, i], the workload of task i to be processed
by spot and on-demand instances the workload of task i processed by spot instances the availability of spot instances specifying the average duration of utilizing spot instances in each unit of time the sufficiency index of self-owned instances, used to control the allocation of self-owned instances via
Equation (12) the number of self-owned instances currently idle at time
t
the maximum number of self-owned instances that are always available in [t1, t2], i.e., mint[t1,t2] N (t)
the numbers of spot and on-demand instances requested for task i
the number of self-owned instances allocated to task i the deadline associated with task i

3.3.1 Principled Instance Allocation Process
While executed in [~i, i], each task i is assigned ri self-owned instances: ri  0 if a user possesses self-owned instances (i.e., r > 0), and ri = 0 otherwise. The amount of workload processed by self-owned instances is ri ·(i -~i). The remaining workload is to be processed by spot and on-demand instances and its amount is z~i = zi - ri · (i - ~i). If ri = 0, all the workload of task i will be processed by spot and on-demand instances. From time ~i on, task i requests oi on-demand instances and si spot instances from the cloud to process the remaining workload where

si + oi = i - ri

(2)

to satisfy the parallelism constraint. While task i is being executed at a time t  [~i, i], the expected workloads that have been processed by on-demand and spot instances are oi · (t - ~i) and  · si · (t - ~i) respectively. At time t, the remaining workload of i to be processed is denoted by z~i(t) whose expected value is as follows:

z~i(t) = z~i - oi · (t - ~i) -  · si · (t - ~i).

With

the

parallelism

constraint,

z~i (t) i -ri

is

the

minimum

time

needed

to finish the remaining z~i(t) workload.

Definition 3.1. For a task i with residual instance time z~i(t) > 0, we say that task i has flexibility to utilize unstable spot instances at a moment t  [~i, i] when the following condition holds:

z~i(t) i - ri

<

i - t.

(3)

Due to inherent uncertainty within spot service, a task i may reach a state where it has to totally utilize i -ri stable on-demand

(a) zi = 3.5

(b) zi = 5.5

Fig. 2: Both plots illustrate the instance allocation of a task: the diagonal stripe, diagonal brick, and horizonal stripes areas denote the workloads processed by self-owned, on-demand and spot instances respectively.

instances in order to finish by its deadline. Formally, as task i is executed, if there exists some time t satisfying
z~i(t) = (i - t) · (i - ri),
we call such time t as a turning point and denote it by ic. At time ic, we have to give up utilizing cheap spot instances to finish the remaining z~i(ic) workload by the deadline i. The instance allocation process may have two phases defined below:
Definition 3.2. If the turning point exists and ic = ~i, the instance allocation process has two phases:
(i) oi on-demand and si spot instances are requested in the period [~i, ic];
(ii) i - ri on-demand instances are utilized in [ic, i].
If the turning point exists and ic = ~i, i-ri on-demand instances are utilized in the period [~i, i]. If the turning point does not exist, oi on-demand instances and si spot instances are requested until some time t  [~i, i] such that z~i(t) = 0.
Example. Now, we give a toy example to illustrate the instance allocation process in Definition 3.2. Suppose task i has a parallelism bound i = 3 and is executed in [~i, i] = [0, 2]; the user has r = 1 self-owned instance. The availability of spot instances is  = 0.5. The scheduler allocates ri = 1 self-owned instance to task i in [0, 2]. The remaining workload to be processed is z~i(0) = zi - 1 × 2. The scheduler begins to request one spot and one on-demand instance at time 0 where oi = si = 1:
· If zi = 3.5, we have z~i(0) = 1.5. At time 1, task i gets enough execution time from spot and on-demand instances; we thus have z~i(1) = 0 and the turning point does not exist. This is illustrated in Fig. 2(a).
· If zi = 5.5, we have z~i(0) = 3.5. At time 1, the remaining workload is z~i(1) = 3.5 - 1.5 = 2; since z~i(1) = (i - 1) · (i - ri), the turning point exists and ic = 1; task i need turn to totally utilize i-ri = 2 on-demand instances to meet the deadline. This is illustrated in Fig. 2(b).
3.3.2 Decision Variables, and Objectives
Jobs arrive over time. Each job is represented as a DAG and has multiple tasks. Decision Variables. Given a job j, we need to determine (i) the deadline i by which each task i is finished and (ii) the numbers of spot and on-demand instances requested when there is flexibility for task i to utilize spot instances (i.e., when the turning point has not appeared; see the first and third cases of Definition 3.2). If a user possesses self-owned instances, we also need to determine

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015
its amount allocated to each task i. Thus, our decision variables include i, si, oi and ri for each task i of a job. Objective of Instance Allocation. We refer to the ratio of the total cost of utilizing a certain type of instances to the total workload processed by this type of instances as the average unit cost of this type of instances. As described in Section 3.1, we assume like [11], [12] that
Assumption 1. The average unit cost of self-owned instances is lower than the average unit cost of spot instances, which is lower than that of on-demand instances.

5
Fig. 3: Processing a Chain of 4 Tasks: the diagonal brick, and horizonal stripes areas denote the workloads processed by ondemand and spot instances respectively; in the blank areas, no workload is processed.

Due to Assumption 1, the overall objective of our instance allocation framework is to maximize the utilization of self-owned and then spot instances and minimize the utilization of costly on-demand instances. Achieving this objective involves properly determining the decision variables i, si, oi and ri for each task i of a job. The deadline i of a task i affects its instance allocation process by Definition 3.2 and thus its completion time; the later affects the time that other tasks can start being executed due to the precedence constraint.
While allocating various instances to a single task i in a specific time window [~i, i], we should consider allocating various instances to a task in the order of self-owned, spot and on-demand instances; the objectives here are the same as the ones in [11], [12] where only the allocation to a single task is considered. Differently, we consider the case of a DAG job where a user pays exactly for what it consumes. Now, we describe these objectives in Principles 3.1 and 3.2.
Principle 3.1. If a user possesses self-owned instances, the scheduler should make self-owned instances (i) fully utilized, and (ii) utilized in a way so as to maximize the opportunity that all tasks have to utilize spot instances.
Principle 3.2. After self-owned instances are used or if a user has no self-owned instances, the scheduler should utilize on-demand instances in a way so as to maximize the opportunity that a task has to utilize spot instances.
Realizing the above principles involves properly determining the decision variables si, oi and ri for each individual task i of a job. Last but not least, a job j has l tasks and has to be finished in a given time window [aj, dj]. We also need to maximize the aggregate utilization of self-owned and spot instances by all tasks within the job. Correspondingly, we need to realize the following objective.
Principle 3.3. Before allocating instances to the l tasks of a job, the scheduler needs to properly determine the deadlines 1, 2, · · · , l to maximize the overall utilization of self-owned instances, if any, and spot instances.
In the following, we will propose solutions for realizing the three principles above. The final result is an integrated framework for a user to cost-effectively process DAG jobs by renting typical cloud instances from major IaaS providers.
4 (NEAR-)OPTIMAL INSTANCE ALLOCATION
In this section, we consider a special case of jobs, i.e., each job is a chain of l tasks, where for all i  [2, l] the execution of the i-th task can begin if and only if the first l - 1 tasks have been finished. We propose a framework to design (near-)optimal

parametric policies that can effectively realize Principles 3.1-3.3. In the next section, we will use the technique of [15] to extend the framework to the case where the precedence constraints are present in a general DAG.

4.1 Spot and On-demand Instances
In this subsection, we consider the case that a user has no selfowned instances. We will derive a couple of optimal parametric policies in terms of the availability  of spot instances to maximize the utilization of spot instances and realize Principle 3.2 and 3.3 optimally.

4.1.1 Preliminaries
Consider a job j with a chain of l tasks to be processed in a time window [aj, dj]. While processing these tasks, one question is what deadline i is associated to each task i to ensure that the latter tasks have a large enough window [i, dj] in which they are finished. For all i  [1, l], it is expected that i is also the time point at which task i is finished. To respect the precedence constraints among the tasks, the execution of the i-th task can begin when the (i - 1)-th task is finished where ~i = i-1 for all i  [2, l]. Thus, task i is expected to be executed in [i-1, i] where 0 = aj trivially and we have

aj = 0 < 1 < · · · < l  dj.

(4)

The other question is that, given the time window [i-1, i] of task i, what is the optimal composition of instance types (i.e., the

values of oi and si) to maximize the amount of workload to be

processed by spot instances.

For example, let us consider a job j of l = 4 tasks with [aj, dj] = [0, 4]. The task sizes are z1 = 1.5, z2 = 0.5, z3 = 2.5, and z4 = 0.5. The parallelism bounds are 1 = 2, 2 = 1, 3 = 3, and 4 = 1. The availability of spot instances is specified as  = 0.5. We artificially set the deadline i of the i-th task to i where i  [1, 4]. Each task i is finished at time point i. In this setting,

the amount of workload processed by spot instances is 2, which is

illustrated in Fig. 3. However, as seen later, the optimal amount of

workload

processed

by

spot

instances

is

22 6

by

properly

setting

the

values of i, oi, and si for i  [1, 4]. In the rest of this subsection,

for an arbitrary job j, we will derive a computationally efficient

yet optimal allocation of deadlines 1, 2, · · · , l to its tasks.

Additionally, we also derive the expected optimal composition of

instance types to finish each task i, which is in fact one enabler of

the optimal deadline allocation. In this subsection, we have

oi + si = i

(5)

and the number of self-owned instances assigned to each task i is zero, i.e., ri = 0.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

4.1.2 Allocation to a Single Task
Suppose that the deadlines 1, 2, · · · , l are given in advance. In this subsection, we give the expected optimal composition of instance types for a single task i to utilize spot and on-demand instances in the predefined time window [i-1, i] where i  [1, l]. This will realize Principle 3.2 optimally.
The instance allocation process is described in Definition 3.2. Now, we give a condition under which task i can be expected to be finished by utilizing spot instances alone, without utilizing costly on-demand instances. We also derive the expected optimal strategy for task i to utilize different types of instances.

Proposition 4.1. A task i can be finished by utilizing spot in-

stances alone when the time window size ^i satisfies the following

condition:

^i

=

i

-

i-1



ei . 

(6)

The expected optimal strategy of utilizing spot and on-demand instances is as follows:

· if the condition (6) holds, then it is expected that the

turning point does not exist and we have si = i and

oi = 0;

·

if ^i 

ei,

ei 

, then the instance allocation process is

expected to have two phases and we have in the first phase

that si = i and oi = 0; · if ^i = ei, then it is expected that the turning point ic is
i-1 and we have oi = i and si = 0.

Proof. See Appendix A.1.

4.1.3 Optimal Deadline Allocation
In this subsection, we will realize Principle 3.3 optimally. A job j should be executed in the time window [aj, dj]. Our question is finding an optimal allocation of 1, 2, · · · , l to maximize the utilization of cheap spot instances and minimize the consumption of costly on-demand instances.
Formulation as an Integer Linear Program. We formulate the deadline allocation problem as an integer linear program. To ensure that each task i can be finished in its time window [i-1, i], we have

^i = i - i-1  ei for all i  [1, l]

(7)

where ei is the minimum execution time of task i by (1). ^i can be written:

^i = ei + xi,

(8)

where xi  0. With the strategies in Proposition 4.1, the total amount of
workload processed by spot instances has the following relation with the time window size ^i.

Proposition 4.2. Given the time window size ^i, the expected amount of workload processed by spot instances is


 zio =


 1-

·

i

·

xi

zi

if ^i 

ei,

ei 

if ^i 

ei 

,



(9)

Proof. See Appendix A.2.

Here,

zio

=

 1-

· i · xi



[0, zi]

when

^i



ei,

ei 

. For each

task i, Proposition 4.1 and 4.2 show (i) the minimum time window

6

Algorithm 1: Dealloc(x)

Input : the availability  of spot services, or the

sufficiency index 0 of self-owned instances

(x =  or 0)

Output: the time window sizes allocated to the l tasks:

^1, ^2, · · · , ^l

1 ^i  ei for all i  [1, l];

2   dj -

l i=1

ei;

3 for k  1 to l do

4 5

if

^>exikexi-k

^ik then - ^ik , ^ik



^ik

+ ^,







- ^;

6

if 0 <





eik x

- ^ik

then

7

^ik  ^ik + ,   0;

size needed to finish the task by only utilizing spot instances, and (ii) how the amount zio of workload processed by spot instances varies with the time window size and job characteristics.
Our objective is finding an allocation of deadlines 1, 2, · · · , h to maximize the utilization of spot instances. This is formulated
as an integer linear program below:

h

maximize zio,

(10)

k=1

where 1, 2, · · · , h satisfy (4), (7) and (8) and zio satisfies (9).

Solution. Now, we derive a computationally efficient yet optimal

solution to the integer linear program (10). By Proposition 4.2,

we have the following observation. While the time window size

^i

ranges

in

[ei,

ei 

],

the

workload

zio

of

task

i

processed

by

spot

instances is linearly proportional to xi; the larger the parallelism

bound

i,

the

larger

the

value

of

zio.

While

^i

exceeds

ei 

,

the

workload zio will not increase any more. We can thus propose a

greedy strategy to optimally determine the allocation of deadlines

to tasks, which is presented in Algorithm 1 with  as an input i.e.,

Dealloc(). Algorithm 1 gives the optimal values of ^1, ^2, · · · , ^l, and we can thus derive the optimal values of 1, 2, · · · , l by (4) and (7).

The idea of Dealloc() is as follows. Let {i1, i2, · · · , il} = {1, 2, · · · , l} be such that i1  i2  · · ·  il . It considers tasks in non-increasing order of their parallelism bounds (line 3)

and allocates as much time as possible to the tasks with the largest

parallelism bounds. Specifically,

· Each task i is initially allocated a time window of size

^i = ei to guarantee that it can be finished in the allocated

window (line 1).

·

The remaining time  = (dj - aj) -

l i=1

ei

is

allocated

to the first l tasks with the largest parallelism bounds

where l  [1, l].

­ if l  2, we have for k  [1, l - 1] that the task

ik

has a time window size ^ik

=

eik 

(lines 4-5)

­

a+ifnld(th=-e 1ta,stklkh=ei-l1fi1rh(sa^tisktaa-sktimehiaeks)w)ai(ntlidimnoeewsw6sii-zn7ed);o^iwl

= eil size ^i1

= ei1 +  (lines 6-7).

Proposition 4.3. Algorithm 1 gives an optimal solution to the integer linear program (10) with a time complexity of O(n).

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

7

Proof. See Appendix A.4.

Fig. 4: Optimal Processing of a Chain of Tasks: the diagonal brick, and horizonal stripe areas denote the workloads processed by ondemand and spot instances respectively.

Proof. See Appendix A.3.
Example. Now, we continue the example in Section 4.1.1 and show by Algorithm 1 and Proposition 4.1 the expected optimal deadline and instance allocation to the job j, which is illustrated rosisdtnhe2epfeqecomwFuo=tiatenoighnnsdr.itkd0srs4tdtl.aaoi5.onnsa,Tnrkscdeteheaqs3psenuoirmicenoo=nes-cppstdetsle0iysi53mnms,t,erha67aedralnqe76nbddue,idynee43iassntstdph4spsloietoinaotn=tfinnetiicrhennseae0sstlott.lipsaan5onehnn-c.cdaccaoTseeet2eni6mssh1odeoi,naisf4nnpfiiadh2s6r.l2aslaisoF.t1n6se1cistnaa,ftoaaotsf2inl6klo1llacyonler,wl;eaotiqsnhcnt:uhdeaeettias1wo43tmfsn,=oo;o1ut6ou1twrhn34tnohe-t;,

4.2 Incorporating Self-Owned Instances
In this section, we extend the framework of Section 4.1 to the case with additional self-owned instances.

4.2.1 Allocation of Self-owned Instances

In this subsubsection, we consider the allocation of self-owned instances to a single task i to be finished in [i-1, i]. We will give a policy that realizes Principle 3.1 effectively. Specifically, the policy needs to guarantee that (i) self-owned instances are fully utilized by tasks and (ii) in the meantime, the overall opportunity of all tasks utilizing spot instances is maximized. Like [10], [12], in the subsequent analysis, the issue of rounding the allocations of a job to integers is ignored temporarily for simplicity; in reality, we can round up the allocations to integers, without affecting the effectiveness of our conclusions much as shown by our experiments.
We will use a common parameter 0 to determine the amount ri of self-owned instances allocated to each task i. ri is defined by a function f (x) when x = 0. The function f (x) relates to the characteristics of task i and is defined as follows:

f (x) = max zi - i · ^i · x , 0 .

(11)

^i · (1 - x)

When given

x in

= 0, f (x) = (1). The value

zi ^i

;

when

x



ei ^i

,

of f (x) ranges in

f (x)

[0,

zi ^i

= 0, ]. We

where ei is refer to the

parameter 0 as the sufficiency index of self-owned instances. As

we will see, given a set of jobs arriving over time, the value of 0

is small if self-owned instances are sufficient and large otherwise.

Proposition 4.4. The function f (x) has the following properties:

· f () is the minimum number such that, after task i is allocated f () self-owned instances, it is expected that task i can be finished in [i-1, i] by only requesting to utilize i - f () spot instances without utilizing costly on-demand instances.
· f (x) is non-increasing in x.

Now, we introduce the policy. Let N (t) denote the number of self-owned instances available at time t and N (t1, t2) be the maximum number of self-owned instances that are available in the entire time interval [t1, t2], i.e.,

N (t1, t2) = min N (t).
t[t1 ,t2 ]
The number ri of self-owned instances allocated to task i is defined as follows:

ri = min{f (0), N (i-1, i), i}.

(12)

Task i can use these instances in the period [i-1, i]. We show by Proposition 4.4 that the policy (12) can effectively
realize Principle 3.1.  represents the availability of spot instances. f (x) is non-increasing in x. In the case that sufficient self-owned instances are available, we can set 0 to a value smaller than  and each task i is assigned more than f () self-owned instances; as a result, all tasks can be expected to be finished by utilizing spot instances alone, without consuming costly on-demand instances. In the meantime, by setting 0 to a properly small value, we can guarantee that self-owned instances are fully utilized by allocating a large number of self-owned instances to each task.
In the case that self-owned instances are insufficient, we can set 0 to a value larger than , and each task i is assigned less than f () self-owned instances; here, all tasks are expected to consume some costly on-demand instances. No tasks are assigned more than f () self-owned instances. Allocating more than f () self-owned instances to a task i can lead to a waste of selfowned instances since they can be allocated to other tasks for processing the workload that will otherwise be processed by costly on-demand instances. Finally, as shown in the two cases above, if the policy (12) is used, no tasks are overly allocated and a balanced-allocation is achieved to well realize Principle 3.1. This will further be validated in our third experiment of Section 6.

4.2.2 Deadline Allocation
In the last subsubsection, we have given an explicit form of the
policy for self-owned instances. Built on such a policy, we derive
in this subsubsection the expected optimal allocation of deadlines
under some mild assumptions. A task i is allocated to utilize ri self-owned instances in [i-1,
i]. Task i is divisible and afterwards task i can be viewed as a new task with a parallelism bound ~i = i - ri and a (remaining) workload/size z~i = zi - ri · ^i, which will be processed by spot and on-demand instances alone. The number ri is defined in (12). Within the parallelism bound, it is the minimum of f (0) and the maximum number N (i-1, i) of self-owned instances available in [i-1, i]. When a CSP has sufficient self-owned instances, 0 is set to a value smaller than  and a task i is expected to be assigned more than f () self-owned instances. When a CSP has insufficient self-owned instances, 0 is set to a value larger than  and a task i is expected to be assigned less than f () self-owned
instances. In any case, by choosing a properly large or small value for 0,
ri can equal or be close to f (0). Thus, for analytical tractability, we assume that each task i is assigned ri = f (0) self-owned tasks to be utilized in [i-1, i], although the policy that is actually used in our framework is defined by (12). This helps obtain an
informed policy to allocate deadlines to the tasks of a job. The

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

effectiveness of the resulting policy will further be validated by our experiments (see Experiments 2 and 3 in Section 6.2). Each job is assigned a specific 0. Depending on the relation between the availability  of spot instances and the sufficiency index 0 of self-owned instances, we have the following conclusion on the amount zio of workload processed by spot instances after each task i is allocated ri self-owned instances.
Proposition 4.5. Depending on the time window size ^i = ei +xi, in the case that 0  , we have

zio =

0 1-0

·

i

·

xi

zi

if ^i 

ei,

ei 0

if

^i

>

ei 0

.

(13)

In the case that  < 0, we have

zio =

 1-

·

i

·

xi

zi

if ^i 

ei,

ei 

if

^i

>

ei 

.

(14)

Proof. See Appendix A.5.

Proposition 4.5 has the following implications. In spite of the relation of 0 and , the workload zio processed by spot instances is linearly proportional to the parallelism bound i and the additional available time xi for executing task i until some threshold, after which the workload zio keeps constant and stops increasing with xi. This is the same as the case in Section 4.1
where only spot and on-demand instances are utilized. Thus, in
the case with self-owned instances (i.e., r > 0), we can still apply
Algorithm 1 to determine the optimal allocation of deadlines: the
specific way is presented in lines 1-5 of Algorithm 2.

8

Algorithm 2: Deadline and Instance Allocation

/* Check the possible events at time t

*/

1 if there exists some job j such that t = aj then

// Allocate deadlines to job j

2 if r = 0 or (r > 0 and  < 0) then

3

Call Dealloc(), presented in Algorithm 1;

4 if r > 0 and 0   then

5

Call Dealloc(0), presented in Algorithm 1;

6 if t = i-1 then // Allocate self-owned instances to task i,

if any

7 if r > 0 then

8

Allocate ri self-owned instances to task i where

ri is given in (12);

9 if r = 0 then

10

No self-owned instances are allocated to task i

where ri = 0;

11 if t  [i, i+1] and z~i(t) > 0 then // Determine the allocation action of spot

and on-demand instances

12 if by Definition 3.1, there is flexibility for task i to

utilize spot instances at time t then

13

Bid a price for i - ri spot instances;

14 else

// t is the turning point of task i

15

Request i - ri on-demand instances in the time

window [t, i];

4.3 Summarizing Deadline and Instance Allocation
In this subsection, we summarize the process of allocating instances to a chain of tasks.
As the time horizon expands, we check whether specific events are triggered at every moment t and take corresponding allocation actions, which are presented in Algorithm 2. Generally, when a job j arrives, we first determine its deadline allocation. For all i  [1, l], its i-th task can be executed when its preceding tasks have been finished if any. The l tasks are executed one by one. In particular, when t = aj, job j arrives and we first determine the allocation of deadlines 1, 2, · · · , l to its l tasks (lines 1-5): when only on-demand and spot instances are utilized, execute lines 1-3 since r = 0; otherwise, execute lines 1-5 since r > 0.
Recall that 0 = aj. For all i  [1, l], when t = i-1, it means that either job j just arrives if i = 1 or the (i - 1)-th task has been finished if i  2; then, the execution of the i-th task begins and we determine the instance allocation to task i (lines 6-15). In the case that there are self-owned instances (i.e., r > 0), when t = i-1, task i is first allocated ri self-owned instances in [i-1, i], where ri is given in (12) (lines 6-8); otherwise, ri = 0 (lines 9-10). If ri > 0, task i can be viewed as a new task with reduced parallelism bound and task size that will only be processed by spot and on-demand instances. Except the possible workload processed by self-owned instances, the remaining workload of task i to be processed at time t is denoted by z~i(t). While task i is being executed at time t  [i-1, i], if z~i(t) = 0, no actions are taken to request spot and on-demand instances since the current allocation of instances is enough to finish task i; otherwise, we have

· if there is flexibility for task i to utilize spot instances at time t by Definition 3.1, request to utilize i - ri spot instances (lines 12-13).
· otherwise, there is no such flexibility and t is the turning point of task i; by Definition 3.2, stop requesting spot instances and turn to utilize i - ri on-demand instances in [t, i] (lines 14-15).
5 ONLINE LEARNING FOR GENERALIZED CASE
In the last section, we propose a series of parametric policies for allocating instances to a chain of tasks, which are the core technical contribution of this paper. Supported by two existing techniques directly from [10], [15], we can further obtain an integrated framework to process general DAG jobs, which is of great interest in practice. In this section, we introduce the two techniques briefly, although they are not the main contribution of this paper. Their formal description is given in Appendix B.
Job Transformation. The technique of Nagarajan et al. [15] is used to transform a general DAG job j to a virtual job j with a chain precedence constraint, also called a pseudo-job. Any feasible schedule of the pseudo-job j is also a feasible schedule of the DAG job j, with their parallelism, precedence and deadline constraints respected. While transforming j to j , the high-level idea is as follows. Consider a virtual schedule of j, also called a pseudo-schedule: each task i of j is allocated i instances and executed as early as possible. Each pseudo-task of j consists of parts of the tasks of j that are executed in the same time

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015
interval. There are multiple time intervals between the starting and completion times of the pseudo-schedule. These intervals correspond to multiple pseudo-tasks that form a pseudo-job j with a chain precedence constraint.
Learning the Optimal Parameters. The online learning algorithm (TOLA) of Menache et al. [10] is adapted to learn the most cost-effective parametric policy.
Each job is associated with a particular parametric policy that is defined by a tuple of parameters {, 0, b}. The parameter  represents the availability of spot service while 0 indicates the sufficiency of self-owned instances. When a job j arrives,  and 0 are used to determine the deadline allocation via the lines 1-5 of Algorithm 2. The value of  may only depend on the system dynamics, independent of the behavior of an individual user; this is the case of Google Cloud. Besides the system dynamics, it may also relate to the bid price b of a user; this is the case of Amazon EC2 and Microsoft Azure. Then, a user needs to bid a price b to request spot instances; its jobs fail to get instances when either b is lower than the spot price at a moment or the system reclaims the allocated instances. In this case, we need to learn the best bid price b against the spot price dynamics. In the case of Google Cloud, no bid is required and we simply set b to a null value.
There is a set P of n tuples {, 0, b}, each representing one policy. The high-level idea of TOLA is as follows. This is an initial probability distribution over the n policies. Whenever a job j arrives at time t, a policy is randomly chosen from P according to the distribution and it determines the actual allocation of instances to the job j and the actual cost of completing j. On the other hand, given an arbitrary policy, the cost of completing an arbitrary job j depends on the fixed on-demand price and the variable spot prices in [aj , dj ]. At time t, for the past jobs whose deadlines are no larger than t, we can derive their costs under each policy of P since we know the spot prices in [0, t]. We can choose one of such jobs unexamined so far, and examine its cost under each policy; then the distribution is updated at time t such that the lower-cost (higher-cost) polices of this job are re-assigned the enlarged (resp. reduced) probabilities.
As the time horizon expands, the probability distribution is updated over and over and the most cost-effective policies of P will be identified gradually, i.e., the ones with the highest probabilities. In the meantime, as more and more jobs are processed, the actual cost of completing all jobs will be close to the cost of completing all jobs under the best policy of P.
6 EVALUATION
The main aim of our evaluations is to show the effectiveness of the proposed policies of this paper.
6.1 Simulation Setups
In alignment to best practices in prior art [10], [12], [15], jobs are generated as follows. The on-demand price p is normalized to be 1. The job arrival follows a poisson process with a mean of 4. The number l of tasks in a job is randomly set to 7 or 49. The order of generating tasks is also the topological order of tasks in the graph. For any two tasks i1 and i2, a precedence constraint is associated with a probability 0.5. To ensure connectivity, for all i  [1, l -1], a task i without successors is randomly connected to one of the latter tasks i+1, · · · , l, as its successor; for all i  [2, l], a task i without predecessors is randomly connected to one of its

9

former tasks 1, · · · , i - 1 as its predecesor. The parallelism bound

of a task is randomly set to 8 and 64. The minimum execution

time ei of every task i follows a bounded Pareto distribution [29]

with a shape parameter location parameter µ =

1 4

=

7 8

; the

, a scale parameter  = maximum and minimum

7 32

and

a

values of

x are set to 2 and 10. The task size zi is ei · i.

For each DAG job j, we compute its critical path and denote

its length by ecj, which is the minimum execution time needed to finish j [15]. The job's relative deadline dj - aj is set to x · ecj,

where x is uniformly distributed over [1, x0]. x represents jobs'

flexibility and determines their capability to utilize spot instances;

it is a main factor that determines the performance. In this paper,

we consider four types of jobs with different levels of time

flexibility, and the 1st, 2nd, 3rd and 4th types of jobs respectively

have x0 = 1.5, 2, 2.5, 3. Each DAG job is transformed into a

simpler job with chain-like precedence constraints, after which

various policies are applied to the simplified job for processing.

We can use an exponential distribution to model spot prices [31].

Specifically, each unit of time is divided into 12 equal time slots,

and spot prices are updated per slot; their values can follow a

bounded exponential distribution where its mean is set to 0.13; the

upper and lower bounds are set to 1 and 0.12.

Proposed Policies. The parametric policy {0, , b} is described

in Section 5. 0,  and b are chosen respectively from C1 =

2 12

,

4 14

,

6 16

,

8 18

,

1 2

,

0.6,

0.7

, C2 =

1,

1 1.3

,

1 1.6

,

1 1.9

,

1 2.2

, and B

= {0.18, 0.21, 0.24, 0.27, 0.3}. When only spot and on-demand

instances are considered, the set of policies is set to

P = {(, b) |   C2, b  B}.
When there are also self-owned instances, the set of policies is set to
P = {(, b, 0) | 0  C1,   C2, b  B}.

Benchmark Policies. The benchmark policy is used as a baseline to measure the performance of the proposed policy. Our analysis in Proposition 4.1 formalizes that an intuitive policy can achieve the expected optimal utilization of spot instances. For comparison, the benchmark policies include (i) the naive policy for allocating the time windows in which tasks are executed and (ii) the naive policy for self-owned instances. We evaluate two possible naive policies for time window allocation, where the first can only be applied to spot and on-demand instances and the other will also be applied to self-owned instances:

Greedy As the time horizon expands, a job simply bids

for i spot instances for each of its tasks until the length of the critical path for processing the remaining

workload of tasks is no less than the remaining time

window size; afterwards, we simply use i on-demand instances for processing the remaining workload of

each task i.

Even Upon arrival of a job, we specify a series of consec-

utive time windows in which its tasks are executed

and finished. Each task i has a time window size i =

ei + xi. The remaining time  = dj - aj -

l i=1

ei

is evenly allocated among the l tasks, and we set xi

to /l.

The naive policy for self-owned instances would be allocating as many self-owned instances as possible to each task in a first-comefirst-served discipline, taking into account the number of selfowned instances available. Specifically, upon arrival of a job, if

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015
the time windows of tasks are specified, we allocate as many selfowned instances as possible to each task i within its parallelism bound, i.e.,
ri = min{N (i-1, i), i}.
The set of benchmark policies are parameterized and defined as
P = {b | b  B}.

Performance Metric. The objective of this paper is minimizing

the cost of finishing a set of jobs J that arrive over time. Each job

j is processed under a proposed or benchmark policy, indexed by

. There are three types of jobs to be evaluated. Let Zj denote the

total workload of job j that consists of l tasks, i.e., Zj =

l i=1

zi.

Let cj() denote the cost of completing j under the policy .

When there are x1 self-owned instances and the x2-th type of jobs

are processed, the average unit cost of processing jobs under a

policy , denoted by x1,x2 (), is defined as the ratio of the total cost of utilizing various instances to the processed workload of

jobs:

x1,x2 () = cj ()/ Zj .

jJ

jJ

When a fixed policy  is applied to all jobs, we use x1,x2 (resp. x1,x2 ) to denote the minimum of the average unit costs of our proposed policies (resp. the benchmark policies):

x1 ,x2

=

min
P

x1,x2 ()

and

x1 ,x2

= min
P

x1,x2 ().

To measure the effectiveness of our proposed policies over the benchmark policies, we define a metric, called cost improvement, as follows:

 = 1 - x1,x2

; x1 ,x2
x1 ,x2

x1,x2 represents how much cost is saved by using our proposed policies, compared with the benchmark policies. For example,

when x1,x2 = 0.5, the cost of our proposed policies is only half the cost of the benchmark policies.

Furthermore, in this paper, the policies of a set are associated

with a probability distribution on which we base the selection

of a policy for each arriving job. The online learning algorithm

TOLA (i.e., Algorithm 4 in Appendix B.2) is run to update

the distribution, finally identifying the policy that generates the

lowest cost. When TOLA is applied, we use x1,x2 (P) (resp. x1,x2 (P )) to denote the average unit cost of processing all jobs if the set of policies is P (resp. P ), and the cost improvement is

defined as follows:

 = 1 - x1,x2

. x1,x2 (P)
x1,x2 (P )

x1,x2 represents the cost saving when online learning is applied.

6.2 Results
Our simulations are run over about 10000 jobs. We will show the cost improvement of our proposed policies over the benchmark policies.
Experiment 1. We evaluate the effectiveness of the proposed deadline allocation algorithm (i.e., Algorithm 1) in the case that a user does not have any self-owned instances (i.e., x1 = 0) and only utilizes spot and on-demand instances. This algorithm is compared with the greedy and even policies in Section 6.1. The corresponding results are listed in Table 2. The cost improvement of our algorithm is significant and ranges from 15.23% to 27.10%.

10
TABLE 2: Cost Improvement for Spot and On-Demand Instances

Greedy Even

0,1 27.10% 25.61%

0,2 20.90% 22.20%

0,3 16.53% 18.03%

0,4 15.23% 16.39%

TABLE 3: Overall Cost Improvement with Self-Owned Instances

 x2
x1 300 600 900 1200

1
37.22% 43.60% 50.57% 57.95%

2
41.28% 51.43% 58.80% 62.73%

3
39.57% 50.05% 55.06% 58.57%

4
37.26% 45.79% 50.81% 55.24%

The improvement is especially strong when the population of jobs has a tight time flexibility to be finished, e.g., the cost improvement can be up to 27.10%. Since our proposed policy is expected to be optimal, we can see in all cases that the cost of our policy is a lower bound of the cost of the other policies.
Experiment 2. We consider the case that a user also has some selfowned instances. In our proposed framework (i.e., Algorithm 2), there are policies for allocating deadlines and self-owned instances. We evaluate the overall effectiveness of this framework. The benchmark policies for comparison include the even policy for allocating deadlines and the naive policy for allocating selfowned instances. The corresponding results are listed in Table 3. The cost improvement is significant and ranges from 37.22% to 62.73%. As a user has more self-owned instances, less spot and on-demand instances will be consumed to complete all the jobs. The more self-owned instances a user has, the larger their effect on the cost. With our proposed policies, the cost improvement increases as the number of self-owned instances increases from 300 to 1200.
Experiment 3. We still consider the case with all the three types of instances, like Experiment 2. We evaluate the effectiveness of the proposed policy (12) for allocating self-owned instances, by comparison with the benchmark policy for self-owned instances. While evaluating these two policies, the same deadline allocation algorithm (i.e., lines 1-5 of Algorithm 2) is used. The corresponding results are listed in Table 4. The cost improvement is significant and ranges from 13.16% to 47.37%. Given the job type x2, the cost improvement increases with the amount of self-owned instances that a user possesses.
On the other hand, we are also interested in the utilization of self-owned instances and show the ratio of the utilization of our proposed policy to the utilization of the benchmark policy. We use µx1,x2 to denote this ratio under the x2-th type of jobs when there are x1 self-owned instances. The corresponding results are listed in Table 5. For example, when x1 = 900 and x2 = 1, the utilization ratio µx1,x2 is 0.9581. Overall, the benchmark policy can achieve a higher utilization of self-owned instances. It allocates as many self-owned instances as possible to the tasks of each job. However, jobs are differentiated by their capability to utilize spot instances. We should allocate more self-owned instances to the jobs that have poor capability to utilize spot instances, which can effectively reduce the unnecessary consumption of costly ondemand instances. This leads to that, although our proposed policy achieves a lower utilization, it can still achieve a lower cost than the benchmark policy. For example, when x1 = 900 and x2 = 1, the cost improvement x1,x2 is 30.64%.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015
TABLE 4: Cost Improvement for Self-Owned Instances

11
TABLE 6: Cost Improvement under Online Learning

 x2
x1 300 600 900 1200

1
13.16% 21.25% 30.64% 40.68%

2
18.30% 31.97% 42.14% 47.37%

3
20.14% 33.74% 40.13% 44.60%

4
20.51% 31.00% 37.04% 42.50%

TABLE 5: Utilization Ratio µx1,x2 for Self-Owned Instances

µ x2
x1 300 600 900 1200

1
97.01% 96.40% 95.81% 94.58%

2
93.02% 90.58% 82.13% 78.59%

3
88.46% 79.95% 73.08% 79.28%

4
81.68% 73.98% 76.64% 74.00%

Experiment 4. Finally, we show the performance when the online learning algorithm TOLA, is applied. When only spot and ondemand instances are considered, the experimental setting here is the same as Experiment 1. When self-owned instances are also considered, the experimental setting is the same as Experiment 2. We list in Table 6 the values of x1,x2 in the case that the job type x2 is 2 and the number x1 of self-owned instances is 0, 300, 600, 900 and 1200 respectively. The results still show a significant cost improvement, ranging from 24.87% to 59.05%.
7 CONCLUSION
The formation of cost-effectively using IaaS clouds opens the door for users to participate in cloud ecosystems. We consider DAG jobs that are an important extension to the independent tasks considered in the previous works. A job has a specific deadline and consists of multiple tasks with precedence constraints. Driven by the goal of maximizing the utilization of self-owned and spot instances, we identify that a key question is allocating deadlines to tasks. Thus, given the policies for allocating instances, we qualitatively characterize the capability that each task has to utilize spot instances in a predefined time window. Based on this, we formulate the deadline allocation problem as an integer program and derive in a computationally efficient fashion the optimal solution. These policies and algorithms are parametric and thus adaptive. Facing the dynamic of cloud market, we can leverage online learning to infer their optimal values. Several intuitive heuristics are used as baselines to validate the cost improvement brought by the proposed solutions. The cost improvement is up to 24.87% when spot and on-demand instances are considered and up to 59.05% when self-owned instances are considered.
REFERENCES
[1] "Gartner Says Worldwide IaaS Public Cloud Services Market Grew 29.5 Percent in 2017." https://www.gartner.com/en/newsroom/ pressreleases/2018-08-01-gartner-says-worldwide-iaas-public-cloud-servicesmarket-grew-30-percent-in-2017 (accessed on February 26, 2019).
[2] Rajkumar Buyya, Satish Narayana Srirama, Giuliano Casale, Rodrigo Calheiros, et al. "A Manifesto for Future Generation Cloud Computing: Research Directions for the Next Decade." ACM Computing Surveys 51, 5, Article 105 (January 2019), 38 pages.
[3] Dinesh Kumar, Gaurav Baranwal, Zahid Raza, Deo Prakash Vidyarthi. "A Survey on Spot Pricing in Cloud Computing." Journal of Network and Systems Management 26, no. 4 (2018): 809-856.
[4] "Amazon EC2 pricing." https://aws.amazon.com/ec2/pricing/ (accessed on February 26, 2019).

0,2 24.87%

300,2 36.91%

600,2 47.26%

900,2 54.71%

1200,2 59.05%

[5] "Azure Spot Virtual Machines." https://azure.microsoft.com/enus/pricing/spot/ (accessed on Febraury 25, 2020).
[6] "Preemptible Virtual Machines." https://cloud.google.com/preemptiblevms (accessed on Febraury 25, 2020).
[7] Thilina Gunarathne, Tak-Lon Wu, Judy Qiu, and Geoffrey Fox. "Cloud computing paradigms for pleasingly parallel biomedical applications." In Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing (HPDC'10), pp. 460-469. ACM, 2010.
[8] Geoffrey C. Fox. "Data intensive applications on clouds." In Proceedings of the second international workshop on Data intensive computing in the clouds, pp. 1-2. ACM, 2011.
[9] Navendu Jain, Ishai Menache, Ohad Shamir. "Allocation of Computational Resources with Policy Selection." U.S. Patent 9,652,288, issued May 16, 2017.
[10] Ishai Menache, Ohad Shamir, Navendu Jain. "On-demand, Spot, or Both: Dynamic Resource Allocation for Executing Batch Jobs in the Cloud." In 11th International Conference on Autonomic Computing (ICAC'14). USENIX Association, 2014.
[11] Xiaohu Wu, Patrick Loiseau, and Esa Hyytia¨. "Towards designing cost-optimal policies to utilize IaaS clouds with online learning." In Proceedings of 2017 International Conference on Cloud and Autonomic Computing (ICCAC'17), pp. 160-171. IEEE, 2017.
[12] X. Wu, P. Loiseau and E. Hyytia¨, "Toward Designing Cost-Optimal Policies to Utilize IaaS Clouds with Online Learning," IEEE Transactions on Parallel and Distributed Systems, vol. 31, no. 3, pp. 501-514, 1 March 2020.
[13] Navendu Jain, Ishai Menache, Joseph Naor, Jonathan Yaniv. "NearOptimal Scheduling Mechanisms for Deadline-Sensitive Jobs in Large Computing Clusters." ACM Transactions on Parallel Computing, 2015.
[14] Xiaohu Wu, Patrick Loiseau. "Algorithms for scheduling deadlinesensitive malleable tasks." In Proceedings of 2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton'15). IEEE, 2015.
[15] Viswanath Nagarajan, Joel Wolf, Andrey Balmin, Kirsten Hildrum. "Flowflex: Malleable scheduling for flows of mapreduce jobs." In Proceedings of the ACM/IFIP/USENIX International Conference on Distributed Systems Platforms and Open Distributed Processing (MiddleWare'13), pp. 103-122. Springer, 2013.
[16] Murtaza Zafer, Yang Song, Kang-Won Lee. "Optimal Bids for Spot VMs in a Cloud for Deadline Constrained Jobs." In Proceedings of the IEEE 8th International Conference on Cloud Computing (CLOUD'12). IEEE, 2012.
[17] Min Yao, Peng Zhang, Yin Li, Jie Hu, Chuang Lin, Xiang Yang Li. "Cutting Your Cloud Computing Cost for Deadline-Constrained Batch Jobs." In Proceedings of the IEEE International Conference on Web Services (ICWS'14). IEEE, 2014.
[18] Yu-Ju Hong, Jiachen Xue, Mithuna Thottethodi. "Dynamic Server Provisioning to Minimize Cost in an IaaS Cloud." In Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS'11). ACM, 2011.
[19] Jeffrey Dean and Sanjay Ghemawat. "MapReduce: simplified data processing on large clusters." Communications of the ACM 51, 1 (January 2008), 107­113.
[20] Matei Zaharia, Mosharaf Chowdhury, Tathagata Das, Ankur Dave, et al. "Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing." In 9th USENIX Symposium on Networked Systems Design and Implementation (NSDI 12), pp. 15-28. 2012.
[21] Ankush Verma, Ashik Hussain Mansuri, and Neelesh Jain. "Big data management processing with Hadoop MapReduce and spark technology: A comparison." In 2016 Symposium on Colossal Data Analysis and Networking (CDAN'16), pp. 1-4. IEEE, 2016.
[22] Sivadon Chaisiri, Bu-Sung Lee, Dusit Niyato. "Optimization of Resource Provisioning Cost in Cloud Computing." IEEE Transactions on Services Computing, 2012.
[23] Wei Wang, Baochun Li, Ben Liang. "Optimal Online Multi-Instance Acquisition in IaaS Clouds." IEEE Transactions on Parallel and Distributed Systems, 2015.
[24] Alexandra Vintila, Ana-Maria Oprescu, Thilo Kielmann. "Fast (Re-) Configuration of Mixed On-demand and Spot Instance Pools for HighThroughput Computing." In ACM Workshop on Optimization Techniques for Resources Management in Clouds, 2013.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015
[25] Shengkai Shi, Chuan Wu, Zongpeng Li. "Cost-Minimizing Online VM Purchasing for Application Service Providers with Arbitrary Demands." In Proceedings of the IEEE 8th International Conference on Cloud Computing (CLOUD'15). IEEE, 2015.
[26] Guanyu Gao, Han Hu, Yonggang Wen, and Cedric Westphal. "Resource provisioning and profit maximization for transcoding in clouds: A twotimescale approach." IEEE Transactions on Multimedia 19, no. 4 (2016): 836-848.
[27] Daniel J. Dubois, Giuliano Casale. "Autonomic provisioning and application mapping on spot cloud resources." In Proceedings of 2017 International Conference on Cloud and Autonomic Computing (ICCAC'15), pp. 57-68. IEEE, 2015.
[28] Daniel J. Dubois, Giuliano Casale. "OptiSpot: minimizing application deployment cost using spot cloud resources." Cluster Computing 19, no. 2 (2016): 893-909.
[29] Junliang Chen, Chen Wang, Bing Bing Zhou, Lei Sun, Young Choon Lee, and Albert Y. Zomaya. "Tradeoffs Between Profit and Customer Satisfaction for Service Provisioning in the Cloud." In Proceedings of the 20th ACM Symposium on High performance Distributed Computing (HPDC'11). ACM, 2011.
[30] Liang Zheng, Carlee Joe-Wong, Christopher G. Brinton, Chee Wei Tan, Sangtae Ha, Mung Chiang. "On the Viability of a Cloud Virtual Service Provider." In Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS'16). ACM, 2016.
[31] Liang Zheng, Carlee Joe-Wong, Chee Wei Tan, Mung Chiang, Xinyu Wang. "How to Bid the Cloud." In the Proceedings of the ACM Conference on Special Interest Group on Data Communication (SIGCOMM'15). ACM, 2015.
[32] Ludwig Dierks and Sven Seuken. 2019. "Cloud Pricing: The Spot Market Strikes Back." In Proceedings of the 2019 ACM Conference on Economics and Computation. ACM, 2019.
[33] Xiaohu Wu, Francesco De Pellegrini, and Giuliano Casale. "Delay and Price Differentiation in Cloud Computing: A Service Model, Supporting Architectures, and Performance." arXiv preprint arXiv:2007.15314 (2020).
[34] Jiayi Song, and Roch Gue´rin. "Pricing (and bidding) strategies for delay differentiated cloud services." ACM Transactions on Economics and Computation (TEAC) 8, no. 2 (2020): 1-58.
[35] Linquan Zhang, Zongpeng Li, and Chuan Wu. "Dynamic resource provisioning in cloud computing: A randomized auction approach." In Proceedings of the 33rd Annual IEEE International Conference on Computer Communications (INFOCOM'14), pp. 433-441. IEEE, 2014.
[36] Xiaohu Wu, Francesco De Pellegrini, Guanyu Gao, and Giuliano Casale. "A Framework for Allocating Server Time to Spot and On-Demand Services in Cloud Computing." ACM Trans. Model. Perform. Eval. Comput. Syst. 4, 4, Article 20 (December 2019), 31 pages.

APPENDIX A

A.1 Proof of Proposition 4.1

By Definition 3.2, if ^i > ei, we have that either there will be a turning point ic larger than i-1 or such a turning point does
not exist, since (3) holds at time t = i-1. Thus, from time i-1

on, oi on-demand instances and si spot instances are requested.

The duration of utilizing spot instances is denoted by i where

i  (0, ^i]. The amount of workload processed by spot instances

is si · i ·  and it achieves the maximum possible value when

si = i and i = ^i. Thus, a necessary condition under which task

i can be finished by simply utilizing spot instances is i·^i·  zi,

i.e., the condition (6). Under this condition, the corresponding

optimal strategy is to request i spot instances where si = i and

oi = 0 and it is expected that the turning point does not exist.

If ^i 

ei,

ei 

, there will be a turning point ic larger than

i-1 where i = ic - i-1 and the instance allocation process has

two phases by Definition 3.2; then, we have

i · si ·  + oi · i + i · (^i - i) = zi.

(15)

12

By (5) and (15), we can derive that the workload processed by spot instances is



i · si ·  = 1 -  · (i · ^i - zi).

(16)

The right side of Equation (16) is independent of the values of

si and i; here, i, ^i, and zi are known. Thus, if ^i 

ei,

ei 

,

the optimal strategy can be to request i spot instances in the first

phase and i on-demand instances in the second phase.

Finally, if ^i = ei, we have that the turning point exists and ic = i-1. By Definition 3.2, we have oi = i and si = 0.

A.2 Proof of Proposition 4.2

With different time window size, it is expected that task i

is finished by different composition of instances. We have the

following observations by Proposition 4.1. If ^i = ei, no workload

is processed by spot instances and zio = 0. If ^i 

ei,

ei 

, the

workload processed by spot instances is defined in (16) and we

have by (1) and (8) that zio

=

 1-

· i · xi. If ^i



ei 

,

it

is

expected that task i is completed by utilizing spot instances alone

and the workload processed by spot instances is zi. Specifically,

when

^i

=

ei 

,

we

have

by

(1)

and

(8)

that

zio

=

zi

=

 1-

· i · xi.

The proposition thus holds.

A.3 Proof of Proposition 4.3

We will prove by contradiction that any solution different from

the one of Algorithm 1 cannot lead to that more workload is

processed by spot instances. Suppose that in an optimal solution

there exists a task ik , where k  l, whose time window size is

smaller than such integer

^ik in

. With [1, l].

abuse of We can

notation, let k be the maximum find some latter tasks i, where

i > l, whose time window sizes are larger than ^i. Then, we reduce the allocated time window sizes of these tasks by ^ik -^ik while keeping their sizes  ei; correspondingly, we increase the

time window size ^ik to ^ik . By Proposition 4.2, this will lead to that the workload processed by spot instances is the same as or

larger than the workload before the re-allocation of time window

sizes, since the parallelism bound of task ik is no smaller than the

latter ones. Thus, the solution produced by Algorithm 1 can lead

to that the most workload is processed by spot instances.

A.4 Proof of Proposition 4.4

We also have f (x) = max

i

-

i ·^i -zi ^i ·(1-x)

,

0

. Since i ·

^i - zi  0, the proposition's second point holds. Next, we prove

the first point. Suppose task i is allocated ri self-owned instances.

In order to ensure that the remaining workload zi - ri · ^i of

task i can be finished by totally utilizing spot instances, we have

 · (i - ri) · ^i  zi - ri · ^i. We further have

ri



zi - i · ^i ·  . ^i · (1 - )

Since ri  0, the proposition's first point holds.

A.5 Proof of Proposition 4.5

First, we study the case that 0   and task i is allocated

ri = f (0) self-owned instances; then, task i is expected to

be finished by utilizing self-owned and spot instances alone by

Proposition

4.4, where f (0)



f ().

If

^i



ei 0

,

we

have

ri

=

0

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

since f (0) = 0 by (11); then, zio = zi. If ^i 

ei,

ei 0

, we have

ri

= f (0) =

zi -i ·^i ·0 ^i ·(1-0 )



0; then, the workload processed by

spot instances is

zio

=

zi

- ri

· ^i

=

0 1 - 0

· i

· xi.

(17)

Thus, the proposition's first point holds.

Second,

we

study

the

case

that

0

>

.

If

^i



ei 

,

we

have

by Proposition 4.1 that task i is expected to be finished by only

requesting spot instances in [i-1, i], without self-owned and on-

demand instances and that f () = 0. Thus, f (0) = 0 since 0 

f (0)  f () by Proposition 4.4. As a result, we have zio = zi. If

^i 

ei,

ei 

, we have the following observation where f () > 0

by (11). Task i is allocated f (0) self-owned instances where

0  f (0) < f (); then, task i is expected to utilize some on-

demand instances to be finished by its deadline. Suppose that the

duration for which task i can utilize spot instances is i where

i  [0, ^i). The workload of task i is processed respectively by

ri self-owned instances for a duration ^i, i - ri spot instances

for a duration i, and i - ri on-demand instances for a duration

^i - i, and have

zi - ri · ^i =  · i · (i - ri) + (^i - i) · (i - ri).

Further, we can derive i

=

i ·^i -zi (1- )·(i -ri

)

.

The

workload

pro-

cessed by spot instances is

zio

=

(i

-

ri) ·

i

·

=

 1-



· i

· xi.

(18)

Here,

when

^i

=

ei

+

xi

=

ei 

,

we

have

zio

=

zi

=

 1-

· i

· xi.

This completes the proof of the second point.

APPENDIX B
B.1 Job Transformation
In this subsection, we describe the technique of Nagarajan et al. [15] formally. Consider a DAG job j of l tasks where each task i has a size zi and a parallelism bound i. We first give a pseudoschedule on which we base the construction of the corresponding virtual pseudo-job:
· Allocate each task i the maximum number i of instances and execute i as early as possible; then, we can get the earliest possible start time qi for executing i such that qi  qi + ei for all i  i.
· Run task i on i instances in the time window [qi, qi + ei].
The pseudo-schedule processes the workload of tasks with their precedence constraints respected.
The arrival time of job j is aj. Let Tj = maxli=1{qi + ei} denote the completion time of j in the pseudo-schedule. For each task i of j, the pseudo-schedule defines a specific time window in which the task i runs on i instances. The pseudo-job is constructed as follows:
· Partition the interval [aj, Tj] into the minimum number of sub-intervals I1, I2, · · · , Il such that if a task runs in a sub-interval, it will run continuously in the entire subinterval.
· For k  [1, l ], let rk denotes the total number of instances allocated to all tasks running in Ik; the pseudo-task is defined to have a parallelism bound (k) = rk and a size

Algorithm 3: Job Structure Simplifying [15]
/* transform a DAG job j to a job j with
chain-like precedence constraints
1 if Job j is not a job with chain-like precedence constraints then
2 j  transform(j );
3 else 4 jj;

13 */

z(k) = rk · |Ik|, which is the total workload processed by the pseudo-schedule during Ik. · Each sub-interval Ik corresponds to a pseudo-task; we enforce the chain precedence constraints 1  2  · · ·  l
on the l pseudo-tasks.

These l pseudo-tasks constitute a pseudo-job j . A general DAG job j is transformed to a pseudo-job j with a
chain precedence constraint. The transforming process is denoted by

j  transform(j).

(19)

A feasible schedule of the pseudo job j (possibly different from the pseudo-schedule) is also a feasible schedule of the job j, which defines the order of executing different parts of the l tasks and still respects the precedence constraints of tasks.

B.2 The Online Learning Algorithm
In this subsection, we describe TOLA formally. There is a set of n parametric policies P. Each policy is represented as {0, , b} and indexed by  = 1, 2, · · · . Jobs arrive over time and constitute a set of jobs J , indexed by j = 1, 2, · · · . Let d = maxjJ {dj - aj}, i.e., the maximum relative deadline of all jobs. Let Jt  J denote all jobs j arriving at time t, i.e., aj = t. If Jt = , there are jobs arriving at time t. There is a weight distribution w over the n policies whose initial value is {1/n, · · · , 1/n}. At every moment t, TOLA operates as follows to determine the allocation of Jt and update the weight distribution w:
· If Jt = , it randomly picks for each job j  Jt a policy j from P according to the current distribution w and bases the allocation of instances to j on the policy j; the resulting cost of completing j is denoted by cj(j) (lines 4-10).
· The distribution w is updated when t  d and Jt-d = . At such moment t, we have the knowledge of spot prices in [t - d, t] and can derive the cost of completing each job j  Jt-d under every policy   P, denoted by cj() (lines 14-15); the distribution is updated such that the lower-cost (resp. higher-cost) polices of this job are re-assigned the enlarged (resp. reduced) weights (lines 1620).
Thus, as time goes by and more and more jobs are processed, the most cost-effective policies of P will be identified gradually, i.e., the ones with the highest weights.
As t becomes larger and larger, TOLA will choose for every arriving job j the most cost-effective policy j at a high probability. Finally, the actual total cost of completing all jobs is close

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

14

Algorithm 4: OptiLearning Input : a set P of n policies, each indexed by   {1, 2, · · · , n}; the set Jt of jobs that arrive at t;

/* as the time horizon expands, the algorithm operates as follows at every moment t

*/

1 if t = 0 then

2   1;

//  is used to track the number of times updating the weight distribution

3

initialize the weight vector of policies: w = {w,1, · · · , w,n} =

1 n

,

·

·

·

,

1 n

;

4 Jt  Jt; 5 while Jt =  do 6 Get a job j from Jt ; 7 Call Algorithm 3 and we get a job j with a chain precedence constraint;

8 Pick a policy j =  with a probability w,; 9 Apply the parametric policy j to j and execute the job j by Algorithm 2; 10 Jt  Jt - {j};

11 if t > d then

12

Jt-d  Jt-d;

13 while Jt-d =  do

14

Get a job j from Jt-d;

15

Compute the cost of completing j in the period [aj, dj] under every policy   P, denoted by cj();

16

t 

2 log n d(t-d)

;

17

for   1 to n do

18

w+1,  w, exp-tcj ();

19

for   1 to n do

20

w+1, 

; w+1,

n i=1

w+1,i

21

   + 1;

22

Jt-d  Jt-d - {j};

to the cost of completing all jobs under a specific policy   P that generates the lowest total cost, i.e.,





  = argmin

 cj() .

P t[d,T ] jJt



This is formalized as the following proposition. Let N = | Tt=d Jt|, i.e., the number of all jobs that arrive in [d, T ], and, as proved
in [10], we have that

Proposition B.1 ( [10, Theorem 1]). For all   (0, 1), it holds

with a probability at least 1- over the random of online learning

that

cj (j )-

cj ()

t[d,T ] jJt

t[d,T ] jJt
N

9

2d

log (n/) N

.

