Feedback Interconnected Mean-Field Estimation and Control
Tongjia Zheng1, Qing Han2 and Hai Lin1

arXiv:2106.00899v1 [eess.SY] 2 Jun 2021

Abstract-- Swarm robotic systems have foreseeable applications in the near future. Recently, there has been an increasing amount of literature that employs mean-field partial differential equations (PDEs) to model the time-evolution of the probability density of swarm robotic systems and uses mean-field feedback to design stable control laws that act on individuals such that their density converges to a target profile. However, it remains largely unexplored considering problems of how to estimate the mean-field density, how the density estimation algorithms affect the control performance, and whether the estimation performance in turn depends on the control algorithms. In this work, we focus on studying the interplay of these algorithms. Specially, we propose new mean-field control laws which use the real-time density and its gradient as feedback, and prove that they are globally input-to-state stable (ISS) to estimation errors. Then, we design filtering algorithms to obtain estimates of the density and its gradient, and prove that these estimates are convergent assuming the control laws are known. Finally, we show that the feedback interconnection of these estimation and control algorithms is still globally ISS, which is attributed to the bilinearity of the mean-field PDE system. An agent-based simulation is included to verify the stability of these algorithms and their feedback interconnection.
I. INTRODUCTION
Swarm robotic systems (such as drone swarms) have foreseeable applications in the near future. Compared with small-scale robotic systems, the dramatic increase in the number of involved robots provides numerous advantages such as robustness, efficiency, and flexibility, but also poses significant challenges to their estimation and control problems.
Many methods have been proposed for the control problem of swarm robotic systems, such as graph theoretic design [1] and game theoretic formulation (especially potential games [2] and mean-field games [3]). Our work is inspired by the mean-field based modelling and control strategy for swarm robotic systems [4]. One type of mean-field models partitions the spatial domain to obtain an abstracted Markov chain model [5], which suffers from the state explosion issues. The more promising mean-field model is based on partial differential equations (PDEs), in which individual robots are modelled by a family of stochastic differential equations and their mean-field density evolves according to a PDE. In this way, the problem of transporting a robotic swarm from one distribution to another can be posed as a control problem of the PDEs [4].
*This work was supported by the National Science Foundation under Grant No. IIS-1724070, CNS-1830335, IIS-2007949.
1Tongia Zheng and Hai Lin are with the Department of Electrical Engineering, University of Notre Dame, Notre Dame, IN 46556, USA. tzheng1@nd.edu, hlin1@nd.edu.
2Qing Han is with the Department of Mathematics, University of Notre Dame, Notre Dame, IN 46556, USA. Qing.Han.7@nd.edu.

Considering the control problem of mean-field PDEs, early efforts usually adopt an optimal control formulation to numerically solve for the control laws, which are computationally expensive and essentially open-loop [6], [7]. Recent efforts have sought to design control laws that use the realtime mean-field density as feedback to form a closed loop [8]­[11]. Mean-field feedback laws are able to guarantee closed-loop stability and can be efficiently implemented in individual robots. However, it remains largely unexplored considering problems of how to estimate the mean-field density, how the density estimation algorithm affects the control performance, and whether the estimation performance in turn depends on the mean-field control algorithms. These problems become more critical as it is observed that most of the existing mean-field feedback laws are more or less based on gradient flows [12], which use the gradient of density estimates as feedback. Since the gradient operator is an unbounded operator, a density estimation algorithm that produces estimates with small error may have arbitrarily large estimation error for the gradient. This brings significant concerns to the density estimation algorithms.
In this work, we aim to study the interplay of mean-field feedback laws and estimation algorithms. In our previous work [13], [14], we have proposed some mean-field feedback laws and obtained preliminary results on their robustness to density estimation errors. In this work, we extend these feedback laws so that they are less restrictive (e.g., the density estimates are no longer required to be positive) and have more verifiable robustness properties in the presence of estimation errors. We have also presented a density filtering algorithm in [15] which is particularly for largescale stochastic systems that can be modelled by mean-field PDEs. In this work, we will extend this algorithm to directly estimate the gradient of the mean-field density, a quantity required by almost all existing mean-field feedback control in the literature. Furthermore, we study the interconnection of these estimation and control algorithms and prove their closed-loop stability. Although the design of the feedback velocity field is in a centralized manner, the implementation can be fully distributed in the sense that each robot can independently derive its own low-level controller according to the feedback velocity command. Such a control strategy is suitable for scenarios when a communication center is available, such as UAV-based environment surveillance.
Our contribution includes three aspects. First, we propose new mean-field feedback laws and show their robustness using the notion of input-to-state stability (ISS). Second, we design infinite-dimensional filters to estimate the gradient of the mean-field density and study their stability and op-

timality. Third, we prove that the feedback interconnection of these estimation and control algorithms is still globally ISS.
The rest of the paper is organized as follow. Section II introduces some preliminaries. Problem formulation is given in Section III. Section IV is our main results in which we propose new mean-field estimation and control laws, and study their interconnected stability. Section V presents an agent-based simulation to verify the effectiveness.

II. PRELIMINARIES
A. Notations
Let E  Rn be a measurable set and k  N. Consider f : E  R. For p  [1, ), denote Lp(E) = {f | f Lp(E) := ( E |f (x)|pdx)1/p < }, endowed with the norm · Lp(E). Denote L(E) = {f | f L(E) := ess supxE |f (x)| < }, endowed with the norm f L(E). Given g(x) with infxE g(x) > 0 and supxE g(x) < , the weighted norm f Lp(E;g) := ( E |f (x)|pg(x)dx)1/p is equivalent to f Lp(E). Let Df be the weak derivatives of f for all multi-indices  of length ||. For p  [1, ), denote W k,p(E) = {f | f W k,p(E) := ||k Df Lp(E) < }, endowed with the norm · . W k,p(E) Analogously, W k,(E) is defined, equipped with the norm · . W k,(E) We also denote Hk = W k,2. We will omit E in the norms
when it is clear. The gradient and Laplacian of a scalar
function f are denoted by f and f , respectively The
divergence of a vector field F is denoted by  · F .
Lemma 1 (Weighted Poincare´ inequality [16]): Let   Rn be a bounded connected open set with a Lipschitz boundary. There exists a constant C > 0 such that for f  W 1,p(),

2

|f |2gdx  C f - f gdx gdx (1)







where g is a probability measure such that g = e-V (x) with D2V  In > 0.

B. Input-to-state stability

Input-to-state stability is a stability notion to study nonlinear control systems with external inputs [17]. We introduce its extension to infinite-dimensional systems [18]. Let (X, · X ) and (U, · U ) be the state space and the input space, endowed with norms · X and · U , respectively. Denote by P C(I; Y ) the space of piecewise right-continuous functions from I  R to Y , equipped with the sup-norm. Define the following classes of comparison functions:

K := { : R+  R+| is continuous and strictly increasing with (0) = 0}
K := {  K| is unbounded} L := { : R+  R+| is continuous and strictly decreasing with lim (t) = 0}
t
KL := { : R+ × R+  R+|(·, t)  K, t  0, (r, ·)  L, r > 0}.

Consider a control system  = (X, Uc, ) consisting of the state space X, the space of admissible input functions Uc = P C(R+; U ), and a transition map  : R+ × R+ × X × Uc  X.
Definition 1:  is called locally input-to-state stable (LISS), if x, u > 0,   KL and   K, such that
 (t, t0, 0, u) X   ( 0 X , t - t0)+ sup u(s) U ,
t0 st
holds 0 : 0 X  x, u  Uc : u Uc  u and t  t0. It is called input-to-state stable (ISS), if x =  and u = .
To verify the ISS property, Lyapunov functions can be exploited.
Definition 2: A continuous function V : R+ × D  R+, D  X is called an LISS-Lyapunov function for , if x, u > 0, 1, 2  K,   K, and a continuous positive definite function W , such that:
(i) 1 ( x X )  V (t, x)  2 ( x X ) , t  R+, x  D (ii) x  X : x X  x,   U :  U  u it holds:
x X  (  U )  Vu(t, x)  -W ( x X ), t  R+
for all u  Uc : u Uc  u with u(0) = . If D = X, x =  and u = , then the function V is called an ISS-Lyapunov function.
Theorem 1: Let  = (X, Uc, ) be a control system, and x  0 be its equilibrium point. If  possesses an (L)ISSLyapunov function, then it is (L)ISS.
C. Infinite-dimensional Kalman filters
We introduce the infinite-dimensional Kalman filters presented in [19]. Let H , K be real Hilbert spaces. Consider the following infinite-dimensional linear system:
du(t) = A (t)u(t)dt + B(t)dw(t), u(0) = u0 dz(t) = C (t)u(t)dt + F (t)dv(t), z(0) = 0,
where A (t) is a linear closed operator on H , B(·)  L([0, T ]; L (H )), C (·)  L([0, T ]; L (H , K )), and F (·), F (·)-1  L([0, T ]; L (K )). w(t) and v(t) are independent Wiener processes on H and K with covariance operators W and V , respectively. The infinite-dimensional Kalman filter is given by:
du^(t) = A (t)u^dt + K (t)(dz(t) - C (t)u(t)dt), u^(0) = 0
where K (t) = P(t)C (t) (F (t)V F (t))-1 is the Kalman gain, and P(t) is the solution of the operator Riccati equation:
dP(t) = A (t)P(t) + P(t)A (t) + B(t)W B(t) dt - P(t)C (t) (F (t)V F (t))-1 C (t)P(t) P(0) = P0.

III. PROBLEM FORMULATION

This work studies the transport problem of robotic swarms. Specifically, we want to design velocity commands for individual robots such that the swarm evolves to a desired distribution. Consider N robots in a bounded and connected domain   Rn. The robots are assumed to be homogeneous whose motions satisfy:

dXti = v(Xti, t)dt + 2(t)dBti, i = 1, . . . , N, (2)
where Xti   is a stochastic process representing the position of the i-th robot, v = (v1, . . . , vn)  Rn is the velocity field acting on the robots, {Bti} are standard Wiener processes assumed to be independent across the robots, and
2(t)  R is the standard deviation. In mean-field models, we are more interested in the macroscopic probability density p(x, t) of the robots than individual states. The evolution of p satisfies a mean-field PDE, known as the Fokker-Planck equation and given by:

tp = - · (vp) + (p) in  × (0, T ),

p = p0 on  × {0},

(3)

n · ((p) - vp) = 0 on  × (0, T ),

where n is the unit inner normal to the boundary , and p0(x) is the initial density. The last equation is the reflecting boundary condition to confine the robots within .
Remark 1: The relation of (2) and (3) holds regardless of the number of robots. However, if N is small, using the density to represent the swarm' global state doesn't make much sense. Hence, we usually assume N is large. Note that (2) and (3) share the same set of coefficients, which means that the macroscopic velocity field we design for (3) can be easily transmitted to individual robots (2). Then, individual robots need to derive their own low-level controller to track the reference velocity command, which can however be done in a distributed way. The velocity tracking problem has been widely studied in literature especially for mobile robots, and hence is not studied in this work.
The problems studied in this work are stated as follow. Problem 1 (Mean-field control): Given a target density p(x), we want to design the velocity field v such that the solution of (3) converges to p(x). Problem 2 (Mean-field estimation): Given the mean-field dynamics (3) and the collection of robots' states {Xti}Ni=1, we want to estimate the density p and its gradient. Problem 3 (Feedback interconnection): Given a target density p(x), let v in (3) be designed as a feedback function of certain mean-field estimates that are in turn computed based on (3). We want to show that the feedback interconnected system still converges to p(x).

IV. MAIN RESULTS A. Modified mean-field feedback laws

Given a smooth target density p(x) > c with c > 0 a constant, we propose the following mean-field feedback law:

v(x,

t)

=

-(x,

p(x, t) t)

+

(t)p(x)

(4)

p(x)

p(x)

where   0 is a design parameter for individuals to adjust their velocity magnitude.
Remark 2: Compared with the mean-field feedback laws proposed in [8], [10], [13], the most remarkable difference of (4) is that the feedback density p does not appear in any denominator, which provides several advantages. First, it relaxes the requirement for p to be strictly positive and avoids the phenomenon of producing large velocity when p is close to 0. In fact, it doesn't even require p to be positive, which is very useful because there exist density estimation algorithms that can generate negative estimates. Second, it will enable us to obtain ISS results with respect to estimation errors in L2 norm. (Such results are difficult to obtain for most of the existing mean-field feedback laws.) The significance of this property will become apparent when we study the interconnected stability of control and estimation algorithms.
In this section, we focus on the stability and robustness of (4). We define  = p - p as the convergence error. We require the following assumption.
Assumption 1: Assume p = e-V (x) where D2V  In > 0.
Remark 3: The reason for this assumption is that we need the weighted Poinca´re inequality (1) to prove exponential stability. However, we believe that this assumption is not necessary since the weighted Poinca´re inequality has been shown to hold for many circumstances [20]. We will study how to drop this assumption in future work.
Theorem 2: Consider system (3) with v given by (4). Under Assumption 1,  L2 converges to 0 exponentially.
Proof: Substituting (4) into (3), we obtain the closedloop system:

tp =  · =· =·

p p
p p p p p p p

-· -· +·

p p p + (p) p p p - (p)
p p p .

Consider a Lyapunov function V () =



2 L2

(1/p

)

.

Using

the divergence theorem and the boundary condition, we have

dV =
dt



p

- p p

tpdx

= p - p  ·  p

p p
p

+·

p p p

dx

p2

p2

= -p 



p

- p

 p

dx

p2

 -(1(t) + 2(t))

 p

L2

= -(1(t) + 2(t))

 p - p p

2
.
L2

By the weighted Poinca´re inequality (1) where we set f =

p-p p

and g = p,

dV dt

 -(1(t) + 2(t))C2

p - p p

2 L2

= -(1(t) + 2(t))C2



2 L2 (1/p2 )

where 1(t) and 2(t) are scalar functions of t satisfying

0  minx p  1(t)  maxx p and 0 < minx p 

2(t)  maxx p, and C > 0 is the constant in the Poinca´re

inequality. By the strong maximum principle [21], there exist

t1, a > 0 such that p(x, t)  a for t  t1. Hence, 1 = 0 if

and only if  = 0 for t  t1.

Remark 4: Notice that we allow  = 0 in (4). In this case,

(4)

is

reduced

to

v

=

p p

,

which

is

a

well-known

strategy

to drive stochastic particles towards a target distribution

in physics [16]. However, the convergence speed will be

extremely

slow

since



is

small

in

general.

The

term

-

p p

is added to provide extra and locally adjustable speed for the

convergence. This acceleration can been seen from the term

1 in the proof.

The density p in (4) is a probability density which cannot

be measured directly and needs to be estimated using some

estimation algorithms. We will introduce how to obtain the

estimates in the next section. We first establish some robust-

ness results to these estimates regardless of what estimation

algorithm to use. It is useful to rewrite (4) as:

v

=

-

pp

- p2

pp

+

(t)p . p

(5)

We will design algorithms to estimate p and p separately. The reason for estimating p separately is that the gradient operator  is an unbounded operator, i.e., any algorithm that produces estimates of p with small errors may have arbitrarily large estimation errors for p. Thus, we have to design additional algorithms to estimate p.
Let p^ and p be estimates of p and p, respectively. According to (5), the feedback law using estimates is given by:

v

=

-

pp

- p2

p^p

+

(t)p . p

(6)

Define = p^- p and g = p - p as the estimation errors. Substituting (4) into (3), we obtain the closed-loop system:

t = tp =  ·

p

pp

- p2

p^p

+

p p p

.

(7)

We have the following robustness result in terms of these

estimation errors.

Theorem 3 (ISS of mean-field feedback): If  > 0, then

 L2 is ISS with respect to L2 and g L2 .

Proof: Consider a Lyapunov function V () =



2 L2

(1/p

)

.

Using

the

divergence

theorem

and

the

boundary

condition, we have

dV =

p - p

dt

 p

·

p

p

p

- p2

p^p

+

p p p

dx

p

= -p ·



p

pp - pp + p g - p p2

p2

- p

 p

dx

=

p

-p ·



p

p1 +
p p

g

-

p p2

p2

- p

 p

dx

p2

 -(1(t) + 2(t))

 p

L2

p

+ 3(t)

 p

L2

1 p

g

-

p p2

L2

where 1 and 2 are defined in the same way as in the proof of Theorem 2, and 3(t) is a scalar function of t satisfying 0  minx p  3(t)  maxx p. Using a constant   (0, 1) to split the first term and applying the

weighted Poinca´re inequality, we have

dV dt

 -(1(t) + 2(t))(1 - )C2

p - p p

2 L2

- (1(t) + 2(t))C

p 
p L2

p - p p L2

+ 3(t)

+ g

L2 (

1 p

)

p L

L2 (

1 p2

)

 -(1(t) + 2(t))(1 - )C2



2 L2

(1/p2

)

,

p 
p L2

if

 L2(1/p2)  max

g L2(1/p) + p L

L2(1/p2) .

where

max

:=

max
t

3(t) (1(t) + 2(t))C

.

The ISS property follows from Theorem 1. By using feedback in the control law (4), we are able to
provide extra design flexibility for the convergence speed and individual velocity magnitude, which however brings potential robustness issue in terms of estimation errors. Nevertheless, the above theorem ensures that the convergence error is always bounded by a function of the L2 norm of estimation errors, and will approach 0 exponentially if the estimates are accurate.

B. Density and gradient estimation
In this section, we introduce estimation algorithms to obtain p^ and p. The corresponding algorithms will be referred to as density filters and gradient filters, respectively, and be referred to as mean-field filters collectively. The former has been studied in [15], which is included for completeness. In the estimation part, the system (3) is assumed known (including the velocity field v). We use kernel density

estimation (KDE) to construct noisy measurements of p and p and utilize two important properties: the dynamics governing p and p are linear; their measurement noises are approximately Gaussian. For this reason, we can take advantage of infinite-dimensional Kalman filters to design two filters to estimate them separately.
First, it is important to notice that if v is given as a function of p, the distribution of {Xti}, then the family of stochastic processes (2) are dependent of each other in general. Such stochastic processes are known as the McKeanVlasov processes. Nevertheless, it has been proved in [3] that {Xti} are asymptotically independent as N  . Essentially this is because their interaction becomes weaker and weaker in the sense that the contribution of a given particle i is of order 1/N . Hence, when N is sufficiently large, the agents' states {Xti}Ni=1 can be approximately treated as a set of N independent samples drawn from the common density function p(x, t). We use KDE to construct estimates pKDE and pKDE, which will be used as noisy measurements of p and p.
Using (3), we have
t(p) = (tp) = [- · (vp) + (p)]
= [- · (vI(p)) + (I(p))]

where I is an integration operator for a vector field F , defined as I(F ) := f such that

f = F and n · ((f ) - vf ) = 0 on . (8)

Note that this mapping is unique and invertible. Now define q = p, i.e., q :  × (0, T )  Rn. We obtain a partial-
integro-differential equation for q:

tq = tp = [- · (vI(q)) + (I(q))] (9)

which is a linear equation. We rewrite (3) and (9) as evolution equations in H = L2() and use KDE to construct noisy
measurements for their states:

p = A (t)p (10)
y = pKDE(t) = p + w(t)

and

q = Ag(t)q

(11)

yg = pKDE(t) = q + wg(t)

where A (t) and Ag(t) are linear operators defined in (3) and (9), pKDE is constructed using KDE, w(t) and wg(t) are approximately Gaussian noises with covariance operators R¯(t) = k¯ diag(p(t)) and R¯g(t) = k¯g diag(q(t)) respectively, where k, kg > 0 are constants depending on the kernels and N . (See Appendices for how to construct pKDE and why w and wg are approximately Gaussian.)
We can design an optimal density filter for (10) and
an optimal gradient filter for (11) according to infinitedimensional Kalman filters. However, we notice that R¯ and R¯g are unknown because they depend on p and q, the states that we want to estimate. Hence, we need to approximate R¯ and R¯g with R and Rg respectively. In particular, we let

R = k diag(pKDE(t)) and Rg = kg diag(pKDE(t)). In this way, the "suboptimal" density filter is given by:

p^ = A (t)p^ + P(t)R-1(t)(y(t) - p^),

(12)

P = A (t)P + PA (t) - PR-1(t)P, (13)

with p^(0) = pKDE(0) and P(0) = P0, and the "suboptimal" gradient filter is given by:

q^ = Ag(t)q^ + Q(t)Rg-1(t)(yg(t) - q^),

(14)

Q = Ag(t)Q + QAg(t) - QRg-1(t)Q,

(15)

with q^(0) = pKDE(0) and Q(0) = Q0, where p^ and q^ are our estimates for p and q (i.e., p).
Now we study the stability and optimality of the meanfield filters. Let P¯ and Q¯ be the corresponding solutions of (13) and (15) when R and Rg are replaced by R¯ and R¯g respectively, which represent the optimal flows of estimation error covariance. We denote L = PR-1 and Lg = QRg-1 to represent the suboptimal Kalman gains, and denote L¯ = P¯R¯-1 and L¯g = Q¯R¯g-1 to represent the optimal Kalman gains. Define = p^ - p and g = q^ - q as
the estimation errors. It is easy to see that and g satisfy
the follow equations:

 = (A (t) - P(t)R-1(t)) + P(t)R-1(t)w

(16)

g = (Ag(t) - Q(t)Rg-1(t)) g + Q(t)Rg-1(t)wg. (17)

It can be shown that the suboptimal filters are stable and remain close to the optimal ones. The following theorem is for the density filter (12) and (13), whose proof is given in [15].
Theorem 4: [15] Assume that P(t) and P¯(t) are uniformly bounded, and c1, c2 > 0 such that for t  0,
c1I  R-1(t), R¯-1(t), P-1(t), P¯-1(t)  c2I . (18)

Then we have the following conclusions:
(i) (Stability) L2 is ISS to w L2 (and is uniformly exponentially stable if w = 0);
(ii) P¯ - P is LISS to R¯-1 - R-1 ; (iii) (Optimality) L¯ - L is LISS to R¯-1 - R-1 .
Property (i) means that the suboptimal filter (12) is stable. Property (ii) means that the solution of the suboptimal operator Riccati equation (13) remains close to the solution of the optimal one. Property (iii) means that the suboptimal Kalman gain remains to the optimal Kalman gain. We have similar results for the gradient filter (14) and (15), whose proof is similar to the proof of Theorem 4 and thus omitted.
Theorem 5: Assume that Q(t) and Q¯(t) are uniformly bounded, and c3, c4 > 0 such that for t  0,
c3I  Rg-1(t), R¯g-1(t), Q-1(t), Q¯-1(t)  c4I . (19)
Then we have the following conclusions:
(i) (Stability) g L2 is ISS to wg L2 (and is uniformly exponentially stable if wg = 0);
(ii) Q¯ - Q is LISS to R¯g-1 - Rg-1 ; (iii) (Optimality) L¯g - Lg is LISS to R¯g-1 - Rg-1 .

C. Stability of feedback interconnection
Now we discuss the stability of the feedback interconnection of mean-field estimation and control. We collect the equations in the following for clarity:

t =  ·

p p(

g

+

p) - p2

(

+

p)p

+

p p p

,

 = (A (t; , , g) - P(t)R-1(t))p~ + P(t)R-1(t)w,

g = (Ag(t; , , g) - Q(t)Rg-1(t))p~ + Q(t)Rg-1(t)wg,

(20)

where we write A (t; , , g) and Ag(t; , , g) to emphasize their dependence on , and g through v.
A critical observation is that the ISS results we have established for and g are valid in spite of this dependence. This is because when we design the estimation algorithms, A (or v) is treated as a known system coefficient. The dependence of A on , and g can be simply seen as part of the time-varying nature of A . Since the theory of Kalman filters applies to linear time-varying systems, the stability results for our mean-field filters will not affected. In this regard, we have the following robustness result for the feedback interconnected system (20).
Theorem 6 (Interconnected stability): Under Assumption 1 and the assumptions in Theorems 4 and 5,  L2 , L2 and g L2 are all ISS to w L2 and wg L2 .
Proof: The ISS properties of L2 and g L2 have been proved before, and the ISS property of  L2 follows from the argument that the cascade connection of two ISS systems is still ISS [22].
This theorem has two implications. First, the stability results for the mean-field filters are independent of the meanfield control laws. Hence, they can be used for any control design when mean-field feedback is required. Second, the interconnected system is always ISS as long as the mean-field feedback laws are designed such that the closed-loop system is ISS to the L2 norm of estimation errors. Considering that norms of infinite-dimensional vectors are not equivalent in general, constructing an ISS result with respect to L2 norms is very critical. This in turn highlights the advantage of the modified feedback law (4), because it is very difficult to obtain such an ISS result for most of the existing mean-field feedback laws [8], [10], [13].

V. SIMULATION STUDIES
An agent-based simulation using 1024 robots is performed on Matlab to verify the proposed control law. We set  = (0, 1)2, 2 = 0.01 and  = 0.003. Each robot is simulated according to (2) where v is given by (6). The robots' initial positions are drawn from a uniform distribution on [0.15, 0.85]2. The desired density p(x) is illustrated in Fig. 1a. The implementation of the mean-field filters and the feedback controller is based on the finite difference method. We discretize  into a 30 × 30 grid, and the time difference is 0.01s. We use KDE (in which we set h = 0.04) to obtain pKDE and pKDE. The densities and the operators are approximated by finite-dimensional vectors and matrices.

(a) The desired density p(x). (b) The convergence error. Fig. 1

Simulation results are given in Fig. 2. It is seen that the swarm is able to evolve towards the desired density. The convergence error p^ - p L2() is given in Fig. 1b, which shows that the error converges exponentially to a small neighbourhood around 0 and remains bounded, which verifies the ISS property of the proposed algorithm.

VI. CONCLUSION
This paper studied the interplay of mean-field estimation and control algorithms. We proposed new mean-field feedback laws for robust transport of swarm robotic systems and filtering algorithms for estimating the real-time density and its gradient. We also proved that the interconnection of these algorithms is globally ISS. In implementation, we need a communication center to perform the estimation algorithms and broadcast the estimates to the robots who then independently derive their own low-level controller to follow the feedback velocity field. This is suitable for surveillance applications such as UAV-based environment surveillance. Our future work is to design a fully distributed control framework by combing the distributed density filter we recently proposed [23] and study the interconnected stability.

APPENDICES: KERNEL DENSITY ESTIMATION

KDE is a non-parametric way to estimate an unknown probability density function and its derivatives. Let X1, . . . , XN  Rn be independent identically distributed random variables having a common probability density f . The kernel density estimators for f and its gradient f are given by [24], [25]

1N

1

fN (x) = N hn K h (x - Xi) ,

(21)

i=1

and

1N

1

fN (x) = N hn K h (x - Xi) ,

(22)

i=1

respectively, where K(x) is a kernel function [26] and h is the bandwidth, usually chosen as a function of n such that limN h = 0 and limN N h = . The Gaussian kernel is frequently used due to its infinite order of smoothness, given by

1

1

K(x) =

exp - x x .

(2)n/2

2

Fig. 2: Evolution of the swarm (top), the density estimates p^(x, t) (middle) and the velocity fields v(x, t) (bottom). Each column represents a single time step.

It is known that the fN (x) is asymptotically normal and

that fN (xi) and fN (xj) are asymptotically uncorrelated for

xi = xj, as N  , which is summarized as follow.

Lemma 2 (Asymptotic normality [27]): Under conditions

limN h = 0 and limN N h = , if the bandwidth

h tends to zero faster than the optimal rate, i.e., h =

o

1 N

1/(n+4), then as N  , we have

 N hn(fN (x) - f (x))  N 0, f (x) [K(u)]2du . (23)

Lemma 3 (Asymptotic uncorrelatedness [27]): Let xi, xj be two distinct continuity points of f . Under limN h = 0, the covariance of fN (xi) and fN (xj) satisfies

N hp Cov[fN (xi), fN (xj)]  0, as N  . These two lemmas together implies that when N is large, fN - f is approximately Gaussian with zero mean and diagonal covariance. Similar results exist for f which are omitted here due to space limit.

REFERENCES
[1] R. Olfati-Saber, J. A. Fax, and R. M. Murray, "Consensus and cooperation in networked multi-agent systems," Proceedings of the IEEE, vol. 95, no. 1, pp. 215­233, 2007.
[2] J. R. Marden, G. Arslan, and J. S. Shamma, "Cooperative control and potential games," IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), vol. 39, no. 6, pp. 1393­1407, 2009.
[3] M. Huang, R. P. Malhame´, P. E. Caines et al., "Large population stochastic dynamic games: closed-loop mckean-vlasov systems and the nash certainty equivalence principle," Communications in Information & Systems, vol. 6, no. 3, pp. 221­252, 2006.
[4] K. Elamvazhuthi and S. Berman, "Mean-field models in swarm robotics: a survey," Bioinspiration & Biomimetics, vol. 15, no. 1, p. 015001, 2019.
[5] B. Ac¸ikmes¸e and D. S. Bayard, "A markov chain approach to probabilistic swarm guidance," in 2012 American Control Conference (ACC). IEEE, 2012, pp. 6300­6307.

[6] G. Foderaro, S. Ferrari, and T. A. Wettergren, "Distributed optimal control for multi-agent trajectory optimization," Automatica, vol. 50, no. 1, pp. 149­154, 2014.
[7] K. Elamvazhuthi and S. Berman, "Optimal control of stochastic coverage strategies for robotic swarms," in 2015 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2015, pp. 1822­1829.
[8] U. Eren and B. Ac¸ikmes¸e, "Velocity field generation for density control of swarms using heat equation and smoothing kernels," IFACPapersOnLine, vol. 50, no. 1, pp. 9405­9411, 2017.
[9] V. Krishnan and S. Mart´inez, "Distributed control for spatial selforganization of multi-agent swarms," SIAM Journal on Control and Optimization, vol. 56, no. 5, pp. 3642­3667, 2018.
[10] K. Elamvazhuthi, H. Kuiper, M. Kawski, and S. Berman, "Bilinear controllability of a class of advection­diffusion­reaction systems," IEEE Transactions on Automatic Control, vol. 64, no. 6, pp. 2282­ 2297, 2018.
[11] T. Zheng, Z. Liu, and H. Lin, "Complex pattern generation for swarm robotic systems using spatial-temporal logic and density feedback control," in 2020 American Control Conference (ACC). IEEE, 2020, pp. 5301­5306.
[12] C. Villani, Optimal transport: old and new. Springer Science & Business Media, 2008, vol. 338.
[13] T. Zheng, Q. Han, and H. Lin, "Transporting robotic swarms via meanfield feedback control," arXiv preprint arXiv:2006.11462, 2020.
[14] T. Zheng and H. Lin, "Field estimation using robotic swarms through bayesian regression and mean-field feedback," 2021 American Control Conference (ACC), to appear, 2021.
[15] T. Zheng, Q. Han, and H. Lin, "Pde-based dynamic density estimation for large-scale agent systems," IEEE Control Systems Letters, 2020.
[16] P. A. Markowich and C. Villani, "On the trend to equilibrium for the fokker-planck equation: an interplay between physics and functional analysis," Mat. Contemp, vol. 19, pp. 1­29, 2000.
[17] E. D. Sontag, "Smooth stabilization implies coprime factorization," IEEE transactions on automatic control, vol. 34, no. 4, pp. 435­443, 1989.
[18] S. Dashkovskiy and A. Mironchenko, "Input-to-state stability of infinite-dimensional control systems," Mathematics of Control, Signals, and Systems, vol. 25, no. 1, pp. 1­35, 2013.
[19] R. F. Curtain, "Infinite-dimensional filtering," SIAM Journal on Control, vol. 13, no. 1, pp. 89­104, 1975.
[20] C. Pechstein and R. Scheichl, "Weighted poincare´ inequalities," IMA Journal of Numerical Analysis, vol. 33, no. 2, pp. 652­686, 2013.

[21] G. M. Lieberman, Second order parabolic differential equations. World scientific, 1996.
[22] H. K. Khalil and J. W. Grizzle, Nonlinear systems. Prentice hall Upper Saddle River, NJ, 2002, vol. 3.
[23] T. Zheng and H. Lin, "Distributed density filtering for large-scale systems using mean-filed models," 2021 American Control Conference (ACC), to appear, 2021.
[24] E. Parzen, "On estimation of a probability density function and mode," The annals of mathematical statistics, vol. 33, no. 3, pp. 1065­1076, 1962.
[25] K. Fukunaga and L. Hostetler, "The estimation of the gradient of a density function, with applications in pattern recognition," IEEE Transactions on information theory, vol. 21, no. 1, pp. 32­40, 1975.
[26] B. W. Silverman, Density Estimation for Statistics and Data Analysis. CRC Press, 1986, vol. 26.
[27] T. Cacoullos, "Estimation of a multivariate density," Annals of the Institute of Statistical Mathematics, vol. 18, no. 1, pp. 179­189, 1966.

