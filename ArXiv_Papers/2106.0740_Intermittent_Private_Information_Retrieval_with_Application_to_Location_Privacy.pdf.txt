1
Intermittent Private Information Retrieval with Application to Location Privacy
Fangwei Ye, Salim El Rouayheb

arXiv:2106.00740v1 [cs.IT] 1 Jun 2021

Abstract--We study the problem of intermittent private information retrieval with multiple servers, in which a user consecutively requests one of K messages from N replicated databases such that part of requests need to be protected while others do not need privacy. Because of the correlation between requests, the user cannot simply ignore the privacy for the nonprivate requests.
We start by studying a basic two-requests system where one request is private and the other is non-private. We propose a scheme for any correlation structure between two requests, which concatenates an obfuscation scheme and a standard PIR scheme to prevent leakage when retrieving information for the nonprivate request. The general problem beyond two-requests would require a specification of the correlation structure. Motivated by the location privacy application, we study the Markov model as the correlation structure. To be concrete, we study the problem in the context of location privacy and we apply the basic tworequests intermittent private information retrieval scheme as a building block to design a location privacy protection mechanism that preserves privacy for locations in the trace level.
Index Terms--Information-theoretic privacy, private information retrieval, location privacy
I. INTRODUCTION
Privacy preserving mechanism [1]­[3] has been intensively studied because of the upsurge in privacy concerns. In particular, private information retrieval (PIR) [4], [5] has attracted significant attention recently due to its key roles to understand the privacy in downloading scenarios. The PIR capacity, that is the utility metric to measure download cost from databases, was characterized by Sun and Jafar [5], in which the canonical setting is that a user is interested in retrieving one of the K messages from N replicated database while hiding the identity of the desired message. Many variants of the ordinary PIR problem have been studied in [5]­[20].
The new variation to be studied in this paper, namely intermittent private information retrieval, is motivated by the fact that privacy usually comes at a cost so a user may not need privacy all the time. Privacy preserving mechanism typically incur higher overheads in terms of computation, memory, and delay etc. These incurred burden may motivate the user to choose whether he/she needs privacy or not at certain times. For example, people may switch between normal and
F. Ye is with the Broad Institute of MIT and Harvard, Cambridge, MA 02142, USA (email: fye@broadinstitute.org). The work was partially done when he was with the Department of Electrical and Computer Engineering, Rutgers, The State University of New Jersey, Piscataway, NJ 08854, USA.
S. El Rouayheb is with the Department of Electrical and Computer Engineering, Rutgers, The State University of New Jersey, Piscataway, NJ 08854, USA (email: salim.elrouayheb@rutgers.edu).
This work was supported by NSF Grant CCF 1817635.

incognito modes in browsers depending on network connection and sensitivity of contents etc.
Under the intermittent PIR setting, when a user needs privacy, he/she has to use a PIR scheme. The question is what should be done when the user does not need privacy. One natural answer is a straightforward scheme, i.e., a scheme without any concern of privacy, which suffers from the fact that the user's behavior is usually correlated over time and hence a careless downloading at the current time will leak information about the request at the time instance that needs privacy. Another natural answer is a PIR scheme, which surely preserves the privacy over time due to the one-shot nature of the PIR scheme [5]. However, this conservative strategy generally sacrifices the efficiency, i.e., increasing the download cost, since it over-protects a request that does not need privacy.
In this paper, we will study the intermittent private information retrieval problem by investigating the download cost for the time periods when the user does not need privacy. We will start from a basic two-requests problem, in which a user consecutively requests one of K messages from N replicated databases separately at two time periods, and one of the requests needs privacy while the other does not need privacy. The basic two-requests problem is the first step towards a understanding of the correlation in privacy, and we will see later that it serves as a key role to solve the general problem where the requests are modeled by some random process. As said, the private request has to be retrieved by a PIR scheme, and our focus is to study the download cost for the non-private request. We propose a solution that can be considered as a concatenation of an obfuscation scheme and a PIR scheme. In particular, the scheme can be viewed as a PIR scheme over a randomized subset of messages, where the subset is optimized according to the given correlation between the private and the non-private requests. The obfuscation scheme that optimizes the randomly chosen subsets first appeared as a primitive component in the ON-OFF privacy problem [21], [22] proposed by the authors, where the ON-OFF privacy problem can be regarded as an intermittent PIR problem with a single server in the language of this paper. Therefore, the proposed scheme in this paper can be considered as extending the obfuscation scheme for the intermittent PIR with a single server therein to the setting of the intermittent PIR with multiple servers.
The general intermittent PIR problem beyond two-requests would call for a specification of the correlation structure. Motivated by the application of location privacy [23]­[34], we are particularly interested in the case where the correlation is modeled by a Markov process. To be concrete, we will

2

study the general problem in the context of location privacy, where temporal correlation among locations is modeled by a first-order Markov chain, and a location privacy protection mechanism sends queries to each service providers to ask for service associated with a set of obfuscated locations. In particular, we will use the scheme from the basic two-requests intermittent PIR as a building block to design a location privacy protection mechanism that protects private locations in the trace level.
Contribution: To uncover the tension between privacy and correlation in PIR, we formulate the problem of intermittent private information retrieval with multiple servers, in which a user consecutively requests one of K message from N replicated databases such that part of requests need privacy on demand while others do not need privacy. For the basic two-requests case with arbitrary correlation structure between requests, we propose a scheme that concatenates an obfuscation scheme and a standard PIR scheme, and we bound the download cost of the concatenated scheme. Since the general problem beyond two-requests relies on the correlation structure, we study the Markov chain as the correlation model motivated by the location privacy applications. We extend the basic two-requests intermittent PIR scheme to the Markov correlation model, and we illustrate how the proposed scheme can be applied to design a location privacy protection mechanism in the location privacy problem.
Organization: The rest of the paper is organized as follows. In Section II, we formulate the problem of intermittent private information retrieval, and the main result is stated in Section III. In Section IV, we propose a privacy-preserving concatenation scheme. In Section V, we consider a particular Markov correlation model in location privacy, and apply the basic intermittent PIR scheme to design a location privacy protection mechanism. We conclude the paper in Section VI.
II. INTERMITTENT PRIVATE INFORMATION RETRIEVAL
We basically follow [5] to introduce the setting of intermittent private information retrieval with multiple servers accompanying with correlation between requests.
As in the classical setting, there are N servers and K messages W1, . . . , WK in the system and each of the servers stores a replica of all K messages. Assume that K messages are mutually independent and each of the messages consists of L independent bits that uniformly take values in the binary alphabet {0, 1}.
As mentioned in the Introduction, the correlation model of requests is an essential attribute in the problem, and the solution highly relies on the coupling of requests. In this section, we start from the basic setting of two requests, which serves as the first step to understand the correlation in the intermittent private information retrieval. Also, we will see later it indeed serves as the key role to solve a general problem where requests are supposed to be captured by some random process. Nevertheless, let S and X be two random variable taking values in [K] := {1, . . . , K}, representing two correlated retrieval requests whose correlation is specified by the joint distribution pS,X and we do not impose any structure

on pS,X here, but we adopt the conservative setting that the statistics pS,X is supposed to be known to both the user and servers. In the context of this paper, S and X may represent two consecutive requests from a user at different time periods.
As motivated in the Introduction, privacy is an option for the
user and he/she may not need it all the time. As such, we assume that S is a private request that needs privacy while X is a non-private request that does not need privacy.
Suppose that a user wants to consecutively retrieve messages WS and WX . To retrieve message WS, the user generates N queries Q(1S), . . . , Q(NS) and the query Q(iS) will be sent to the i-th server. Similarly, to retrieve message WX , the user also employs N queries Q(1X), . . . , Q(NX). To clarify, the user may generate queries for requests S and X cooperatively. More rigorously, the queries are supposed to be generated by the query functions that map S and X, together with some random keys F, to the queries Q(iS) and Q(iX), i.e.,
i : {1, . . . , K} × {1, . . . , K} × F  Q × Q, (1)

where Q is supposed to be a common alphabet of queries for
conciseness, and F denotes some random keys on the alphabet F .1
Upon receiving the queries Q(iS) and Q(iX), the i-th server generates answers A(iS) and A(iX) respectively to response to the queries. After receiving answers A(1S), . . . , A(NS), the user should be able to decode the desired message WS with zero
error probability. Separately, the user is also required to decode
the desired message WX perfectly from the corresponding answers A(1X), . . . , A(NX). It is worthy noting that although the queries for S and X are generated cooperatively, the answers

are not supposed to be compressed jointly. As we mentioned
earlier, S and X may represent requests at different time
periods and the messages may be time-varying in practice, so compression of A(iS) and A(iX) may not be option under such a situation. As such, we assume that answers cannot be

compressed. For simplicity, we assume that the answer is a deterministic
function of the query received for each server provided the

stored messages. As such, the length of the answer can be

determined through the query, i.e.,

(A(iS)) = (Q(iS)) and (A(iX)) = (Q(iX)),

where (·) denotes a length function and we assume that the
length function is universal among all N servers and two
requests S and X. We will simply write the length function by (iS) and (iX) for conciseness.
As said, the user should be able to decode the message of

interest, which is referred to as correctness requirement [5]. The correctness requirement is defined in the same way in this

paper, i.e.,

H(WS |S, F, Q1(S:N) , A(1S:N) ) = 0, H(WX |X, F, Q(1X:N), A(1X:N)) = 0,

(2)

1The key in this paper may be context-dependent, i.e., generated dependent of the input S and X, which is different from PIR literatures, e.g. [5], [14]. However, since the key rate is not a quantity of interest in this paper, so we will only present a coarse control of the key by omitting specifying a particular distribution of the key but the underlying distribution will be clear in the context when we need it.

3

where Q(1S:N) := {Q(iS) : i = 1, . . . , N }, A(1S:N) := {A(iS) : i = 1, . . . , N }, Q(1X:N) := {Q(iX) : i = 1, . . . , N } and A(1X:N) := {A(iX) : i = 1, . . . , N }.
The other requirement of the system is the privacy require-
ment, which is defined by

[Privacy] I(S; Q(iS), Q(iX)) = 0, i  [K],

(3)

i.e., any individual server cannot obtain any information about the private request S from queries for both private and nonprivate requests S and X.
Conventionally, the utility metric is defined by the normal-
ized download cost. In particular, the normalized download cost of the i-th server is given by

(iS)

:=

E[(iS)] L

and

(i X )

:=

E[(iX L

)]

,

that is the expected amount of downloaded data per bit desired

message from the i-th server, and the total download cost is

N

N

(S) =

i(S) and (X) =

(iX ) .

i=1

i=1

The difference between this problem and the ordinary PIR

problem is observed as follows. If two requests S and X are retrieved separately, i.e., the query Q(iS) = i(S, F) and Q(iX) = i(X, F), the problem reduces to the well-studied PIR problem, where Q(iS) has to be independent of the request S regardless of the prior PS , and Q(iX) also needs to be independent of the request X in general2 due to the correlation

between S and X, though WX does not need to be retrieved

privately. As a consequence, the time-sharing of a private

scheme and a non-private scheme is forbidden and the user

has to retrieve the message privately even for a non-private

request, which is generally costly. Hence, the question to ask

is that if there exists a better retrieval mechanism for the

non-private request X than retrieving WX privately, in the

sense of reducing download cost while preserving the privacy.

Intuitively, if S and X are loosely correlated, e.g., extreme

case where they are independent, then the message WX can

be retrieved freely without any concern of privacy. On the

other hand, if S and X are strongly correlated, e.g., extreme

case where one is deterministic by the other, one may need to

remain the private scheme for the non-private request. Nevertheless, the sub-problem of minimizing (S), satis-
fying I(S; Qi(S)) = 0, is exactly a PIR problem, and the
minimum download cost is known [5] to be

min (S) = C(N, K) := 1 + N -1 + N -2 + · · · + N -K+1,

which can be achieved by the PIR-capacity achieving scheme therein. Also, provided that Q(iS) is the query of the PIR capacity achieving scheme, i.e.,

I(S; Qi(S)) = 0 and I(Q(iX); Q(iS)|S) = 0,
where the latter one follows because the query Q(iS) of a PIR scheme only depends on S and some random key, the privacy

requirement (3) can be written by

[Privacy] I(S; Q(iX)) = 0, i  [K],

(4)

2Except for a few special cases of pS,X such as S and X are independent.

which is formally stated in the following proposition and the justification is deferred to the appendix.

Proposition 1. Given I(S; Q(iS)) = 0 and I(Q(iX); Q(iS)|S) = 0,
I(S; Q(iX), Q(iS)) = 0

if and only if

I(S; Q(iX)) = 0.

In the sequel, we will focus on the download cost (X) for the non-private request X under the requirement (4).

III. MAIN RESULT
Before stating the main result, let us introduce some necessary notations. Suppose the joint distribution pS,X is given. For any i  [K], suppose that

P {X = i|S = si,1}  · · ·  P {X = i|S = si,K } ,
i.e., ordering the likelihood probabilities of p (x|s), where si,1, . . . , si,K are K distinct elements of [K]. Let j be the summation of the j-th minimal likelihood probabilities for each possible value of X, i.e.,

j =

P {X = i|S = si,j} , j = 1, . . . , K.

i[K ]

Also, let  = max{j : j  1} and

 

j

-

j-1 ,



j = min{1, j}-min{1, j-1} = 1 - ,

 

0,

j  , j =  + 1, j >  + 1.

Theorem 1. For any given correlation structure pS,X, there exists an intermittent private information retrieval scheme with download cost

(X) = E

1

-

1 N

1

-

1 N |U|

-1

,

(5)

where U takes value in the power set of [K] and satisfies that

i

P {|U |  i}  j,  i = 1, . . . , K.

(6)

j=1

The direct consequences of the theorem are as follows:
1) If U = [K] with probability 1, then it is a standard PIR scheme, i.e., retrieving one of K messages, and the right-hand side of (5) is exactly the same as the inverse
of the capacity in [5]. 2) The download cost (X) depends on U only through
its cardinality |U |, which suggests that if the probability of U of small size is larger, then the download cost is generally smaller. However, due to the privacy requirement, it may not be possible to make |U | too small, e.g., the extreme case is that |U | = 1 with probability 1. Nevertheless, (6) guarantees the existence of a U such that P {|U |  i} is larger than some values for each i. It is worthy noting that the worst case of (6) is that

P {|U | = i} = i,

4

since the right-hand side of (5) is monotonically increasing with respect to |U |.
In the next section, we will describe a scheme achieving the download cost shown in (5).
IV. A CONCATENATION SCHEME
In this section, we consider a concatenation of an obfuscation scheme and a standard PIR capacity-achieving3 scheme [5], to achieve the download cost shown in Theorem 1.
A helpful observation on PIR capacity [5] is that the capacity is decreasing with the number of messages, so the general idea here is that we randomly choose a subset U  [K] of messages, and implement the PIR scheme over the selected subset of messages. Generally speaking, the download cost is smaller when the size of the subset is smaller. However, the privacy may not hold when the size of the subset is too small. For example, as we discussed in the Introduction, if choose |U | = 1, i.e., only download the message desired, the privacy corrupts. On the other hand, if choose |U | = K, i.e., using a standard PIR scheme over K messages, the privacy always holds but with a high download cost in general. Therefore, we have to optimize the randomized way of choosing such a subset U to reduce its size while preserving the privacy.
More precisely, we first obfuscate the request X to a set U  [K] that includes X, and then retrieve the message WX privately by taking the PIR capacity-achieving scheme over a subset of messages Wi for i  U . As such, the PIR scheme preserves the identity of X provided U , i.e., only information about U is leaked, and the obfuscation is designed to guarantee that no information about S can be obtained from U .

A. Example
Before describing the scheme in details, we study the simplest example N = K = 2 to illustrate the idea. The setting of servers is the same as the example in [5], i.e., each server stores a full copy two messages (a1, a2, a3, a4) and (b1, b2, b3, b4).
Suppose that the joint distribution of S and X is given in Table I. The obfuscation set U can be designed according to

X S

1

2

1

3/8 1/8

2

1/8 3/8

TABLE I: Joint probability distribution p (x, s)

the conditional probabilities in Table II.

(S, X)

U {1} {2} {1, 2}

(1, 1)

1/3 0

2/3

(1, 2)

0

1

0

(2, 1)

1

0

0

(2, 2)

0 1/3 2/3

TABLE II: Conditional probabilities p (u|x, s)

Assume

that

S

=

X

=

1.

With

probability

2 3

,

the

user

3Any capacity achieving PIR scheme works, and we choose the pioneering one [5] for concreteness.

Probability
2 3
1 3

DB1
a1, b1 a3 + b2
a1 a2

DB2
a2, b2 a4 + b1
a3 a4

TABLE III: Time-sharing of two schemes for S = X = 1 based on U

will request the first message via a standard N = K = 2

PIR scheme, e.g., querying for (a1, b1, a3 + b2) from the first

server and (a2, b2, a4 + b1) from the second server, i.e., totally

6 bits downloaded for a message of 4 bits. With probability

1 3

,

the

user

will

directly

request

the

message

1

as

desired,

e.g.,

directly querying for (a1, a2) from the first server and (a3, a4)

from the second server. For this case, although it leaks X

completely, the private S is still preserved due to the design

of U for the given correlation between S and X. Finally, we

can

check

that

16 3

bits

are

downloaded

on

average

to

retrieve

the first message when S = X = 1.

B. Description of the scheme

As said, the scheme is done by concatenating an obfuscation scheme and a standard PIR scheme, and we describe them separately as follows.
Obfuscation: Suppose that U is a subset of [K], i.e., U takes values in the power set of [K], denoted by PK . Choose U to be a solution to the following optimization problem:

minimize E [C(N, |U |)]

U PK

subject to X  U,

(7)

U is independent of S.

It is worthy noting that U is a random variable and the expectation in the objective function is over U . We defer the discussion on how to solve this optimization problem to
the end of this section. At this place, let us assume that the
problem is solvable and the solution can be obtained. Retrieval: Given the request X and the obfuscation set U ,
retrieve the message WX by using the standard PIR capacityachieving scheme [5] for |U | messages specified by U , i.e., constructing queries Q(iX) for i  [N ] from a PIR scheme with N servers and |U | messages.
Now, let us examine the correctness and the privacy of this
concatenated scheme. The correctness is immediate since the
retrieval scheme is just a private retrieval scheme to retrieve WX from |U | messages including the desired message WX .
For the privacy requirement, the obfuscation step constructs U that is independent of S as a constraint, so we have

I(U ; S) = 0.

(8)

For the ease for our proof, we interpret the indistinguishable requirement4 [5] by

I(Q(iX); X|U ) = 0, i  [N ].

(9)

4More precisely, the indistinguishable requirement is generally stronger,
where the requirement (9) can be thought as indistinguishable over a input
distribution pX|U . Moreover, the indistinguishable requirement therein does not require a prior of request X while the prior has to be existing here.

5

With (8) and (9), we claim that
I(Q(iX); S) = 0,
which is the privacy requirement to be justified. Towards this end, consider
I(Q(iX); S)  I(Q(iX), U ; S) = I(U ; S) + I(Q(iX); S|U )  I(U ; S) + I(Q(iX); S, X|U ) = I(U ; S) + I(Q(iX); X|U ) + I(Q(iX); S|X, U ) = 0,

where I(U ; S) = 0 and I(Q(iX); X|U ) = 0 follows from (8) and (9) respectively, and I(Q(iX); S|X, U ) = 0 follows because Q(iX) is only dependent of the random key given X and U for the private retrieval scheme, which implies
S  X, U  Q(iX),
and thus I(Q(iX); S|X, U ) = 0. Finally, let us evaluate the download cost of the scheme.
Direct from the capacity result in [5], the download cost for a given obfuscation set U is
C(N, |U |) = 1 + N -1 + N -2 + · · · + N -|U|+1,

i.e., the (inverse) PIR capacity for N servers and |U | messages. Hence, the download cost of this concatenation scheme is given by

(X) = E [C(N, |U |)] = E

1

-

1 N

1

-

1 N |U|

-1

,

and the probability distribution of U is specified by the solution to problem (7), which indeed explains why do we choose E [C(N, |U |)] as the objective function in (7). It is worthy noting that the right-hand side of the above equality depends on U only through the cardinality |U |, which suggests that the solution to the optimization problem (7) is maximizing the probability of U with smaller cardinality.
Therefore, we have justified that the concatenation scheme
satisfies the correctness and the privacy requirements. The download cost is (X) = E [C(N, |U |)], where U is a feasible solution to problem (7), and the optimal solution will minimize the download cost (X).

C. Linear programming interpretation of the obfuscation
As discussed in the last section, the scheme relies on solving problem (7). To find a solution to (7), we first interpret the problem (7) as a linear programming (LP), and then discuss on finding solutions of such a LP instance.
We claim that the problem (7) is a linear programming by viewing each conditional probability p(u|x, s) as a decision variable for given p (x, s) for x, s  [K] and u  PK . To see this, we first inspect the constraints. The first constraint X  T can be equivalently written by

p (u|x, s) = 0, x / u,

(10)

where x, s  [K] and u  PK . The second (independence) constraint can be written by
[p(u|x, s)p(x|s) - p(u|x, s)p(x|s)] = 0, (11)
x[K]
for any s, s  [K] and u  PK . For given p (x, s), both constraints are clearly linear with decision variables p(u|x, s). Lastly, let us examine on the objective function. Although C(N, |U |) seems a power function with |U |, E [C(N, |U |)] is indeed linear with decision variables p(u|x, s), i.e.,

E [C(N, |U |)] =

p (u) C(N, |u|)

uPK

=

p (s, x) p (u|s, x) C(N, |u|)

uPK s,x[K]


K

=

p (s, x) C(N, c) 

 p (u|s, x) ,

s,x[K ]

c=1

uPK :|u|=c

which is clearly linear with p (u|s, x) for given p (s, x). By these interpretations, we write the optimization problem
in a more explicit form:

minimize E [C(N, |U |)]
p(u|x,s)

subject to (10), (11)

p(u|x, s) = 1, x, s,

(12)

uPK
p(u|x, s)  0, x, s, u.

It is worthy noting that the problem is always feasible since

p(u|x, s) = 1, u = [K], 0, u = [K],

for any s, x  [K] is always a feasible solution for any given p(x, s). In the context of PIR, it indicates that using the private retrieval scheme over K messages for non-private requests X preserves the privacy all the time.
It should be noted that a similar LP formulation was first discussed in [21] when authors studied a so-called ON-OFF privacy problem that can also be considered as the problem of intermittent PIR with a single server, although in a slightly different setting where S may not have the same alphabet as X. Nevertheless, since it is a LP instance, the numerical solver may be appealing for considerately moderate size problem, i.e., K is not too large, which returns an optimal solution within the precision. However, the scale of this LP instance increases rapidly with K due to the fact that both the number of decision variables and the number of constraints grow exponentially with K, mainly because U is from the power set, which makes the numerical approach intractable when K is large. For this reason, we will also discuss about a tractable algorithm towards a solution for the LP instance in the next section. In particular, we will propose a Poly(K) algorithm to find a solution which may not be always optimal. Since the technical details of finding such a solution is essentially the same as the proof in [21], though in different context and notations, we will only briefly review the result therein and

6

U {1} {2} {3} {1, 2} {1, 3} {2, 3} {1, 2, 3} Pi,j

SX

1

1

2

3

1

2

2

3

1

3

2

3

0.1 0

0

0

0

0

0 0.3 0

0

0

0

0

0 0.1

0

0.1 + 0.2 0.1

0.1 0

0

0

0.1 + 0.2

0

0 0.3 0

0

0

0.1

0

0 0.1

0

0

0

0.1 0

0

0

0.1

0

0 0.3 0

0

0

0.1

0

0 0.1

0

0.2

0

0

0.1

0

0.3

0.1

0.6

0.1

0.5

0

0.4

0

0.1

0

0.2

0.1

0.5

0

0.3

TABLE IV: The constructed p (u, x|s) for the given p (x|s).

provide an illustrating example. The omitted proof details can be found in [21].
Finally, let us make a summary of the discussion in this section. In an operational sense, suppose that pU|X,S is a solution to the above problem (12), either solved numerically by standard LP solvers for small scale or solved by the
algorithm to be discussed in the next section. Since the user knows his/her requests S and X, he/she will generate the obfuscation set U according to the distribution pU|X,S by utilizing X, S and some local randomness.

D. Performance bounds on the obfuscation
As said, solving the optimization of the obfuscation was first discussed in [21] when authors studied the intermittent PIR with a single server, which is interpreted in the following lemma by invoking the notations defined in Section III.

Lemma 1 ( [21, Lemma 3]). For any given random variables S, X  [K], there exists a random variable U  PK satisfying that U is independent of S, p (u|x, s) = 0 for x / u, and

i

P {|U |  i}  j,  i = 1, . . . , K.

(13)

j=1

The lemma is established by a constructive proof, i.e., constructing an admissible p (u|x, s) for x, s  [K] and u  PK . Instead of showing the detailed proof that can be found in [21], we present an example to illustrate the basic
idea of the algorithmic proof.

Example 1. Suppose the conditional probabilities p (x|s) are

given by

0.1 0.3 0.6

P = 0.5 0.4 0.1 ,

0.2 0.5 0.3

where Pi,j = P {X = j|S = i}. The designed probabilities p (u, x|s) are represented in
Table IV, where the shaded cells of value 0 come immediately from the condition p (u|x, s) = 0 for x / u. Throughout this example, we will show how to fill in the values of other cells.
|U | = 1: For each i  [K], choose U = {i}, and let

P {U = {i}, X = i|S = s} = P {X = i|S = si,1}

for all s  [K], which are 0.1, 0.3 and 0.1 for i = 1, 2, 3, respectively.

|U | = 2: For each i  [K] and si,1, find a column index (of P ) li such that

P {X = li|S = si,1}  P {X = li|S = sli,2} + vi, where

vi = P {X = i|S = si,2} - P {X = i|S = si,1} .

Choose U = {i, li} and let

P {U = {i, li}, X = x|S = si,j}

(14)

= P {X = i|S = si,2} - P {X = i|S = si,1} ,

for j  2 and x = i or j < 2 and x = li. As in this example, for i = 1, we have vi = 0.1, i.e., the second minimal value minus the minimum value in the first column of P , where si,1 = 1 and si,2 = 3. Let li = 3. Then we can check that

0.6 = P {X = 3|S = 1}  P {X = 3|S = s3,2} + 0.1,

where s3,2 = 2 and hence P {X = 3|S = s3,2} = 0.1. The process for i = 1 finally configures the value 0.1 for U = {1, 3} in the table.
This generally explains why we call it an obfuscation scheme. For each i  [K], we carefully find an index li for si,1 and mix it with i to form a set U such that when observing U , there exists a pair (x, s) generating U for all s  [K]. Note that since for different i  [K], the set U may be the same, e.g., U = {1, 3} for both i = 1 and i = 3, so P {u, x|s}
is configured in an augment way, i.e., the right-hand side of
(14) is added to the left-hand side instead of being overwritten, such as 0.1 + 0.2 in the cell.
|U | = 3: Configure all remaining values constrained by p (x|s), i.e., the summation of each row in the table.

Remark 1. The general algorithm would basically extend the above process for |U | = 2. Roughly speaking, for |U | = c = 1, . . . ,  and each i  [K], find an index li,j for each si,j such that j  c - 1. Then choose U = {i, li,j : j  c - 1} and configure

P {U, X = x|S = si,j}
= P {X = i|S = si,c} - P {X = i|S = si,c-1} ,
for j  c and x = i or j < c and x = li,j. It is worthy noting that li,j may be the same for different j, so the size of U may be smaller than c. This observation indeed leverages the inequality (13) in the lemma, where the worst case is

P {|U | = i} = i,  i = 1, . . . , K,

7

as discussed.
A detailed proof of Lemma 1 can be found in [21], and we omit details here.

i-th Service Provider

V. APPLICATION TO LOCATION PRIVACY
In this section, we consider a general setting where requests are modeled by some random process. To be concrete, we will discuss the general setting in the context of location privacy, where the correlation is specified by a Markov process. In particular, we will use the previously introduced concatenation scheme as a building block to design an obfuscation-based location privacy protection mechanism. We start by briefly introducing the location privacy background.

Query

Yi(0)

Yi(1)

Yi(2)

Obfuscated locations

U (0)

U (1)

U (2)

True location

X (0)

Time t = 0

X (1) t=1

X (2) t=2

Yi(T ) U (T ) X (T ) t=T

A. Background of location privacy
In the location-based service, the user may want to share his/her location with some service providers (SPs), in order to receive location-based services from the service providers. In this section, we model the provided service by an information retrieval, i.e., the user sends his/her location to a SP and then the SP responds by sending some contents according to the location. Also, we assume that there are multiple service providers who can provide alternative services, which is motivated by the high competition on the market. Privacy is naturally a critical concern in these location-based services, as many personal information such as home/work addresses and history of visiting some particular spots may be inferred from the location trace. As such, SPs are considered to be untrusted which may motivate the user to send perturbed location to the SPs instead of the true location by sacrificing the service quality to some degree while preserving the privacy in some range. Many works [30]­[32] fall into the line of this direction that studies the privacy-utility tradeoff with different notions of privacy and utility metrics. The closest one to this paper is [31], where the privacy notion is information-theoretic, i.e., defined by the mutual information between true location trace and the released perturbation of locations, and the utility is defined by a non-specified distortion function.
A common setting of all these works is that the privacy metric is homogeneous, i.e., each individual location is considered equally important in terms of the privacy leakage. However, let us imagine the situation when driving on a highway, where the entrance and the exit surely contains more information of the location trace. Extremely, one may infer the whole path with a high accuracy by only knowing the entrance and the exit. This motivates us to consider a scenario where each location accounts for the privacy with different weights.
In this paper, we consider an extreme case where some locations in the trace require privacy while other locations can be released without any concern about the privacy. The essential difference between protecting a single location [34], is that the user has to be careful when sending the non-private locations as we motivated early in the Introduction, since the private one may be inferred due to the temporal correlation in the location trace. Instead of studying the privacy-utility tradeoff, we will focus on an operational point such that

Fig. 1: An obfuscation-based location privacy protection mechanism
privacy leakage is zero and the utility is maximized. Different from the distortion-based mechanism [31], [32], the location privacy protection mechanism in this paper is supposed to be an obfuscation-based mechanism, i.e., mixing the true location with certain perturbed locations together and requesting the obfuscation set from SPs.
Now, let us give a formal specification of the mobility model (modeling the correlation of locations), the privacy notion and the utility metric.
Mobility model: A commonly adopted mobility model of the location trace is the Markov model [26]­[29], [31], [32]. In particular, the location at time (discrete time-stamp) t is denoted by X(t) and {X(t)}Tt=0 forms a first-order Markov chain that may be time-variant or time-invariant. Suppose the initial probability distribution pX(0) is given and denoted by 0. Assume that each X(t) takes values in a common alphabet [K] = {1, . . . , K}. For the ease of definitions, we assume that the horizon T is finite. Then, let P  [0 : T ] := {0, 1, . . . , T } be the given set such that X(t) requires privacy if and only if t  P. The private locations set P is supposed to be determined by the user, which may depends on the sensitivity of a particular location or other factors such as private/public network connections etc. Conservatively, the set P is supposed to be known by SPs as well.
Threat model: Instead of releasing the true location X(t) at time t, the user releases a obfuscated version to each SP, where the released version to each SP may or may not be the same. Let Yi(t) denote the obfuscated query that is sent to the i-th SP. Assume that there are N SPs that are available to the user and can provide alternative services. Conventionally, we also assume that the full statistical knowledge of the location trace, i.e., the mobility model, the initial probability 0 and the privacy preserving mechanism, is known to SPs. As such, the obfuscated queries released to the i-th SP are {Yi(t)}Tt=0. The natural privacy measure should require that the released obfuscated queries leaks zero information about

8

p2,1

p1,1

x1

p1,2

x2

p2,2

p3,1 p1,3

p2,3 p3,2

x3

p3,3
Fig. 2: Mobility model: true locations are modeled by a Markov chain

the true private locations, i.e.,

I {X (t)}tP ; {Yi(t)}Tt=0 = 0, i  [N ],

(15)

where [N ] := {1, . . . , N }. A similar privacy metric was introduced in [31], in which the above privacy notion (left-
hand side of the above equation) is called offline privacy
metric and the authors clarified that the offline privacy is generally intractable to manage. More importantly, it does not
capture the online nature of the privacy preserving algorithm, i.e., the obfuscated query Yi(t) has to be generated at time t instantly and it does not allow offline algorithm by observing all {X(t)}Tt=0. Moreover, the offline privacy metric further corrupts in this paper under the stringent privacy requirement
of zero leakage with the online privacy preserving algorithm,
because there may not exist any better strategy other than choosing Yi(t) to be independent of X(t), which generally sacrifices the service quality too much.
Therefore, we borrow the concept from [31], namely online privacy metric, that is defined by

T
I {X (j)}jP[0:t]; Yi(t)|{Yi(j)}tj-=10 .
t=0
As the zero leakage is required in this paper, the privacy requirement is

I {X (j)}jP[0:t]; Yi(t)|{Yi(j)}tj-=10 = 0,

(16)

for all i  [N ] and t  [0 : T ], by the nonnegativity of the mutual information. Roughly speaking, the privacy notion in (16) means that given all previously released obfuscated queries, the current released obfuscated query leaks zero information of all previous true locations that need privacy.

Remark 2. Although the so-called online privacy is more consistent with the setting of this paper and we adopt it as the privacy metric, we have to admit that the so-called offline privacy is theoretically interesting itself, especially in a relaxed or general setting where we want to minimize the privacy leakage instead of forcing it to be zero. Indeed, [32] studied this notion of privacy in the framework of a Markov decision process with states X(t).

Utility metric: Since we model the provided service by an information retrieval process that accommodates the obfuscation-based mechanism, the service can be obtained perfectly by downloading more than necessary, which is different from the distortion-based mechanism that sacrifices the service quality. However, the obfuscation-based mechanism pays for the download cost additionally. In this sense, we consider the download cost as a utility metric to fit the obfuscation-based framework we are discussing here.
In particular, to accommodate the concepts in PIR, suppose that when receive a obfuscated query Yi(t), the i-th SP responds an answer A(it), that is a function of Yi(t) and all messages W1, . . . , WK , where each message corresponds to the content associated with a possible value of true location X(t), recalling that X(t) is a sample from the Markov process that takes value in the alphabet [K]. Correspondingly, the measure of the answer size and the download cost are defined exactly the same way as in Section II, so we skip the details here for the conciseness in notations, and the context should be clear when we invoke the terms in the sequel. Finally, the user is able to obtain the true message W associated with his/her true location X(t) =  from the responses A(1t), . . . , A(Nt) from N SPs.
Remark 3. We would like to slightly clarify the utility metric, as it looks differently from the conventional notion, e.g., [31], [32], where the utility is measure by a single-letter distortion function d(X(t), Yi(t)). We can easily see that d(·) implicitly requires the distance is well-defined over the alphabets of X(t) and Yi(t), and this is consistent with the privacy preserving mechanism therein that sacrifices the service quality by sharing a distorted location. However, the location privacy protection mechanism is operated from another perspective in this paper, where the location privacy protection mechanism would share an obfuscated version (containing the ground truth) of the true location that induces an overhead of the content downloaded from the SPs. A motivating example here is that the user may download the map information for a larger range than he/she needs to hide the true location in some situations. In this sense, the utility metric can be thought as a "distortion" between X(t) and Yi(t) that are from different domains, and it is concretized as the download cost for the obfuscation-based mechanism. Technically, the distortion-based mechanism generally does not work under the stringent privacy requirement such that no information is leaked, so we discuss about the obfuscation-based mechanism in this paper and the utility metric is customized to fit the obfuscation-based framework.
Therefore, the purpose of the remaining section is to propose a privacy preserving mechanism that minimizes the download cost while preserving the privacy defined in (16).
B. Application of the intermittent PIR scheme
From the formulation in the last section, the utility is naturally linked to the download cost of a PIR scheme according to the chosen utility metric, so the remaining task is to inspect the privacy requirement (16).

9

Analogous to the terminology in PIR, Yi(t) can be viewed as the query sent to the i-th server, X(t) is the current request, and while {X(j)}jP[0:t] can be viewed as a collection of private requests.
As we mentioned earlier, the basic scheme for intermittent
PIR in Section IV, is constructed under the setting of two-
requests system, i.e., a single private request instead of a
collection of private requests. Now, we show how to use the
building block therein to construct an admissible scheme over
time, by taking the advantage of the Markov structure of the location trace {X(t)}Tt=0. In particular, at time t, we can apply the scheme in Section IV to construct the obfuscated query Yi(t) for the i-th SP such that the constructed Yi(t) is independent of the latest time when the true location needs privacy, conditioning on all previously generated Yi(j) for j = 0, . . . , t - 1 during the past time periods.
Without loss of generality, assume that 0  P, i.e., X(0) is a location that requires privacy. Let  (t) be the latest private
location, i.e.,

 (t) := max{i : i  t, i  P}.

(17)

By viewing X((t)) and X(t) as the private request S and the non-private request X in Section IV respectively, we can see a direct connection to the scheme therein. In particular, by treating the private request S in Section IV as

S  p , X((t)) |{Yi(j) }jt- =10 and the non-private request X as

X  p , X(t) |{Yi(j) }jt- =10

we can construct the "query" Yi(t) for the i-th SP such that

I X ( (t)); Yi(t)|{Yi(j)}tj-=10 = 0.

(18)

A subtle difference from the basic scheme in Section IV is that the definition here involves conditioning on all previously generated {Yi(j)}tj-=10, which indicates that the user has to update the prior distribution of the X((t)) and X(t) according to the realizations of previously generated obfuscated queries.
Finally, we just need to verify that the above relaxed privacy requirement (18) indeed implies the desired privacy, i.e.,

I {X (j)}jP[0:t]; Yi(t)|{Yi(j)}tj-=10 = 0,

which is defined in (16). This holds mainly because of the Markovity. A formal statement is given in the following proposition and the proof is deferred to the appendix.
Proposition 2. Suppose that {X(t)}Tt=0 is a Markov process and 0  P. Each Yi(t) for i  [N ] and t  [0 : T ] is a stochastic function of X((t)), X(t) and {Yi(j)}tj-=10, then we have
I X ( (t)); Yi(t)|{Yi(j)}tj-=10 = 0

implies that

I {X (j)}jP[0:t]; Yi(t)|{Yi(j)}tj-=10 = 0.

To be precise, we will describe the privacy preserving mechanism in an algorithmic manner. For each time t = 0, . . . , T , the user takes steps:
· If t  P, then  (t) = t and do 1) Generate an obfuscation set U (t) = [K]. 2) Query for content by using a PIR scheme over K messages to download content for the true location X(t) that sends the query Yi(t) to the i-th SP. 3) Compute P X (t), X ( (t))|U [t] = u[t] by

P X (t), X ( (t))|U [t] = u[t] = P X (t), X ( (t))|U [t-1] = u[t-1] ,

(19)

because U (t) = [K] is a constant, where U [t] := {U (j)}tj=0. It is worthy noting that X((t)) is indeed X(t) since  (t) = t. 4) Compute P X (t+1), X ( (t+1))|U [t] = u[t] by

P X (t+1), X ( (t+1))|U [t] = u[t]

=

P X (t) = x|U [t] = u[t]

x[K]

P X (t+1), X ( (t+1))|X (t) = x ,

(20)

where  (t + 1) is either t or t + 1 by definition, i.e.,  (t + 1) = t if t + 1 / P, and  (t + 1) = t + 1 otherwise. · If t / P, then  (t) =  (t - 1) and do 1) Generate an obfuscation set U (t)  PK , that contains the true location X(t), from the true location X(t), the latest private location X((t)) and the previous obfuscation sets U [t-1] such that
I(X ( (t)); U (t)|U [t-1] = u[t-1]) = 0.
In particular, U (t) will be generated according to the distribution
P U (t)|X (t), X ( (t)), U [t-1] = u[t-1] ,

which is the solution to the optimization prob-
lem (12) discussed in Section IV, by treating P X (t), X ( (t))|U [t-1] = u[t-1] as the given input pS,X therein.
2) Query for content by using a PIR scheme over messages in U (t) for the true location X(t) that sends the query Yi(t) to the i-th SP.
3) Compute P X (t), X ( (t))|U [t] = u[t] by

P X (t), X ( (t))|U [t] = u[t]  P X (t), X ( (t)), U (t) = u(t)|U [t-1] = u[t-1] = P X (t), X ( (t))|U [t-1] = u[t-1]
P U (t) = u(t)|X (t), X ( (t)), U [t-1] = u[t-1] . (21)

10

Algorithm 1 Obfuscation-based Location Privacy Protection

Mechanism

Input: Location trace {X(t)}Tt=0 from a Markov mobility
model with known transition probabilities Output: Queries Yi(t) for i  [N ] to N SPs to download
contents for the true location X(t) at each time t 1: Initialize P X (t), X ( (t))|U [t-1] = u[t-1] for t = 0 to

be 0 that is pX(0) 2: for t = 0, . . . , T do

3: if t  P then

4:

Choose the obfuscation set U (t) to be [K]

5:

Implement a PIR scheme over all K messages and

sends Yi(t) to the i-th SP to download content for X (t)

6:

Compute probabilities P X(t), X((t))|U [t] = u[t]

from P X (t), X ( (t))|U [t-1] = u[t-1] according to

(19)

7:

Compute P X (t+1), X ( (t+1))|U [t] = u[t] from

P X(t), X( (t))|U [t] = u[t] according to (20)

8: else if t / P then

9:

Construct an obfuscation set U (t) from the distri-

bution P X (t), X ( (t))|U [t-1] = u[t-1] by solving

the LP (12)

10:

Implement a PIR scheme over messages in U (t) and

sends Yi(t) to the i-th SP to download content for X (t)

11:

Compute probabilities P X(t), X((t))|U [t] = u[t]

from P X (t), X ( (t))|U [t-1] = u[t-1] according to

(21)

12:

Compute P X (t+1), X ( (t+1))|U [t] = u[t] from

P X(t), X( (t))|U [t] = u[t] according to (22)

13: end if

14: end for

of the requests need privacy. We propose a scheme concatenating of an obfuscation and a standard PIR scheme to prevent leakage over correlation for those non-private requests. Motivated by the location privacy, we study a particular correlation structure, that is Markov chain. We apply the basic intermittent private information retrieval scheme to design a location privacy protection mechanism that preserves privacy of private locations in the trace level.
APPENDIX A PROOF OF PROPOSITION 1
Consider
I(S; Q(iX)) = I(S, Q(iS); Q(iX)) - I(Q(iS); Q(iX)|S) = I(S, Q(iS); Q(iX)) = I(Q(iS); Q(iX)) + I(S; Q(iX)|Q(iS)) = I(Q(iS); Q(iX)) + I(S; Q(iX), Q(iS)) - I(S; Q(iS)) = I(Q(iS); Q(iX)) + I(S; Q(iX), Q(iS)).
Since
I(Q(iS); Q(iX))  I(Q(iS); Q(iX), S) = I(Q(iS); , S) + I(Q(iS); Q(iX)|S) = 0,
we know that I(Q(iS); Q(iX)) = 0 by the nonnegativity of the mutual information, and hence
I(S; Q(iX)) = I(S; Q(iX), Q(iS)),

4) Compute P X (t+1), X ( (t+1))|U [t] = u[t] by P X (t+1), X ( (t+1))|U [t] = u[t]

which implies that I(S; Q(iX), Q(iS)) = 0 if and only if I(S; Q(iX)) = 0.

=

P X (t) = x, X ( (t))|U [t] = u[t]

x[K]

P X (t+1), X ( (t+1))|X (t) = x, X ( (t)) ,

(22) where  (t + 1) is either  (t) or t + 1 by definition, i.e.,  (t+1) =  (t) if t+1 / P, and  (t+1) = t+1 otherwise.

Remark 4. At each time period t, the term P X (t), X ( (t))|U [t-1] = u[t-1]

is tracked and updated, which is essentially the same process as in the standard forward algorithm [35].

For better illustration, we summarize the steps in Algorithm 1.

APPENDIX B PROOF OF PROPOSITION 2
The proof follows simply from the Markov structure. Consider
I {X (j)}jP[0:t]; Yi(t)|{Yi(j)}tj-=10 (=a) I X ( (t)); Yi(t)|{Yi(j)}tj-=10
+ I {X (j)}jP[0: (t)-1]; Yi(t)|{Yi(j)}tj-=10, X ( (t)) ,
where (a) follows because we know that
 (t) = max{i : i  t, i  P}

VI. CONCLUSION

by definition, so

In this paper, we study the problem of intermittent private

information retrieval with multiple servers, where only part

P  [0 : t]\{ (t)} = P  [0 :  (t) - 1].

11

For notational conciseness, denote P [0 :  (t)-1] by Pt-, and then we have
I {X (j)}jP[0:t]; Yi(t)|{Yi(j)}tj-=10
(=b) I {X (j)}jPt- ; Yi(t)|{Yi(j)}tj-=10, X ( (t))
 I {X (j)}jPt- ; X (t), Yi(t)|{Yi(j)}tj-=10, X ( (t))
= I {X (j)}jPt- ; X (t)|{Yi(j)}tj-=10, X ( (t))
+ I {X (j)}jPt- ; Yi(t)|{Yi(j)}tj-=10, X ( (t)), X (t)
(=c) I {X (j)}jPt- ; X (t)|{Yi(j)}tj-=10, X ( (t))
(=d) 0,
where (b) follows from the assumption that
I X ( (t)); Yi(t)|{Yi(j)}tj-=10 = 0;
(c) follows because Yi(t) is a stochastic function of X((t)), X(t) and {Yi(j)}tj-=10; (d) follows because the Markov structure of {X(t)}Tt=0 and t   (t)  max Pt-.
REFERENCES
[1] L. Sweeney, "k-anonymity: A model for protecting privacy," International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, vol. 10, no. 05, pp. 557­570, 2002.
[2] C. Dwork, "Differential privacy: A survey of results," in International conference on theory and applications of models of computation. Springer, 2008, pp. 1­19.
[3] M. Bezzi, "An information theoretic approach for privacy metrics." Trans. Data Priv., vol. 3, no. 3, pp. 199­215, 2010.
[4] B. Chor, O. Goldreich, E. Kushilevitz, and M. Sudan, "Private information retrieval," in Proceedings of IEEE 36th Annual Foundations of Computer Science. IEEE, 1995, pp. 41­50.
[5] H. Sun and S. A. Jafar, "The capacity of private information retrieval," IEEE Trans. Inf. Theory, vol. 63, no. 7, pp. 4075­4088, 2017.
[6] ----, "The capacity of symmetric private information retrieval," IEEE Trans. Inf. Theory, vol. 65, no. 1, pp. 322­329, 2018.
[7] ----, "The capacity of robust private information retrieval with colluding databases," IEEE Trans. Inf. Theory, vol. 64, no. 4, pp. 2361­2370, 2017.
[8] R. Tajeddine, O. W. Gnilke, and S. El Rouayheb, "Private information retrieval from mds coded data in distributed storage systems," IEEE Trans. Inf. Theory, vol. 64, no. 11, pp. 7081­7093, 2018.
[9] S. Kadhe, B. Garcia, A. Heidarzadeh, S. El Rouayheb, and A. Sprintson, "Private information retrieval with side information," IEEE Trans. Inf. Theory, vol. 66, no. 4, pp. 2032­2043, 2019.
[10] K. Banawan and S. Ulukus, "The capacity of private information retrieval from coded databases," IEEE Trans. Inf. Theory, vol. 64, no. 3, pp. 1945­1956, 2018.
[11] ----, "The capacity of private information retrieval from byzantine and colluding databases," IEEE Trans. Inf. Theory, vol. 65, no. 2, pp. 1206­ 1219, 2018.
[12] Y.-P. Wei, K. Banawan, and S. Ulukus, "The capacity of private information retrieval with partially known private side information," IEEE Trans. Inf. Theory, vol. 65, no. 12, pp. 8222­8231, 2019.
[13] M. A. Attia, D. Kumar, and R. Tandon, "The capacity of private information retrieval from uncoded storage constrained databases," IEEE Trans. Inf. Theory, vol. 66, no. 11, pp. 6617­6634, 2020.
[14] C. Tian, H. Sun, and J. Chen, "Capacity-achieving private information retrieval codes with optimal message size and upload cost," IEEE Trans. Inf. Theory, vol. 65, no. 11, pp. 7613­7627, 2019.
[15] C. Tian, "On the storage cost of private information retrieval," IEEE Trans. Inf. Theory, vol. 66, no. 12, pp. 7539­7549, 2020.
[16] S. Li and M. Gastpar, "Single-server multi-user private information retrieval with side information," in 2018 IEEE International Symposium on Information Theory (ISIT). IEEE, 2018, pp. 1954­1958.

[17] ----, "Single-server multi-message private information retrieval with side information: The general cases," in 2020 IEEE International Symposium on Information Theory (ISIT). IEEE, 2020, pp. 1083­1088.
[18] ----, "Converse for multi-server single-message pir with side information," in 2020 54th Annual Conference on Information Sciences and Systems (CISS). IEEE, 2020, pp. 1­6.
[19] R. Zhou, C. Tian, H. Sun, and T. Liu, "Capacity-achieving private information retrieval codes from mds-coded databases with minimum message size," IEEE Trans. Inf. Theory, vol. 66, no. 8, pp. 4904­4916, 2020.
[20] Q. Wang, H. Sun, and M. Skoglund, "The capacity of private information retrieval with eavesdroppers," IEEE Trans. Inf. Theory, vol. 65, no. 5, pp. 3198­3214, 2018.
[21] F. Ye, C. Naim, and S. E. Rouayheb, "On-off privacy in the presence of correlation," arXiv preprint arXiv:2004.04186, 2020.
[22] F. Ye, C. Naim, and S. El Rouayheb, "On-off privacy against correlation over time," IEEE Trans. Inf. Forensics Secur., vol. 16, pp. 2104­2117, 2021.
[23] R. Shokri, C. Troncoso, C. Diaz, J. Freudiger, and J.-P. Hubaux, "Unraveling an old cloak: k-anonymity for location privacy," in Proceedings of the 9th annual ACM workshop on Privacy in the electronic society, 2010, pp. 115­118.
[24] B. Gedik and L. Liu, "Protecting location privacy with personalized kanonymity: Architecture and algorithms," IEEE Transactions on Mobile Computing, vol. 7, no. 1, pp. 1­18, 2007.
[25] J. Hua, W. Tong, F. Xu, and S. Zhong, "A geo-indistinguishable location perturbation mechanism for location-based services supporting frequent queries," IEEE Trans. Inf. Forensics Secur., vol. 13, no. 5, pp. 1155­ 1168, 2017.
[26] K. Chatzikokolakis, C. Palamidessi, and M. Stronati, "A predictive differentially-private mechanism for mobility traces," in International Symposium on Privacy Enhancing Technologies Symposium. Springer, 2014, pp. 21­41.
[27] Y. Xiao and L. Xiong, "Protecting locations with differential privacy under temporal correlations," in Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, 2015, pp. 1298­1309.
[28] R. Shokri, G. Theodorakopoulos, J.-Y. Le Boudec, and J.-P. Hubaux, "Quantifying location privacy," in 2011 IEEE symposium on security and privacy. IEEE, 2011, pp. 247­262.
[29] R. Shokri, G. Theodorakopoulos, and C. Troncoso, "Privacy games along location traces: A game-theoretic framework for optimizing location privacy," ACM Transactions on Privacy and Security (TOPS), vol. 19, no. 4, pp. 1­31, 2016.
[30] S. Oya, C. Troncoso, and F. Pe´rez-Gonza´lez, "Back to the drawing board: Revisiting the design of optimal location privacy-preserving mechanisms," in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, 2017, pp. 1959­1972.
[31] W. Zhang, M. Li, R. Tandon, and H. Li, "Online location trace privacy: An information theoretic approach," IEEE Trans. Inf. Forensics Secur., vol. 14, no. 1, pp. 235­250, 2019.
[32] E. Erdemir, P. L. Dragotti, and D. Gu¨ndu¨z, "Privacy-Aware Time-Series Data Sharing with Deep Reinforcement Learning," IEEE Trans. Inf. Forensics Secur., vol. 16, pp. 389­401, 2021.
[33] V. Bindschaedler and R. Shokri, "Synthesizing plausible privacypreserving location traces," in 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 2016, pp. 546­563.
[34] R. Shokri, G. Theodorakopoulos, C. Troncoso, J.-P. Hubaux, and J.Y. Le Boudec, "Protecting location privacy: optimal strategy against localization attacks," in Proceedings of the 2012 ACM conference on Computer and communications security, 2012, pp. 617­627.
[35] L. R. Rabiner, "A tutorial on hidden markov models and selected applications in speech recognition," Proceedings of the IEEE, vol. 77, no. 2, pp. 257­286, 1989.

