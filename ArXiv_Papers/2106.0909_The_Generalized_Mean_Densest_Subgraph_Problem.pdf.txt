The Generalized Mean Densest Subgraph Problem

arXiv:2106.00909v2 [cs.DS] 4 Jun 2021

Nate Veldt
Cornell University Center for Applied Mathematics
nveldt@cornell.edu

Austin R. Benson
Cornell University Department of Computer Science
arb@cs.cornell.edu

Jon Kleinberg
Cornell University Department of Computer Science
kleinberg@cornell.edu

ABSTRACT
Finding dense subgraphs of a large graph is a standard problem in graph mining that has been studied extensively both for its theoretical richness and its many practical applications. In this paper we introduce a new family of dense subgraph objectives, parameterized by a single parameter , based on computing generalized means of degree sequences of a subgraph. Our objective captures both the standard densest subgraph problem and the maximum -core as special cases, and provides a way to interpolate between and extrapolate beyond these two objectives when searching for other notions of dense subgraphs. In terms of algorithmic contributions, we first show that our objective can be minimized in polynomial time for all   1 using repeated submodular minimization. A major contribution of our work is analyzing the performance of different types of peeling algorithms for dense subgraphs both in theory and practice. We prove that the standard peeling algorithm can perform arbitrarily poorly on our generalized objective, but we then design a more sophisticated peeling method which for   1 has an approximation guarantee that is always at least 1/2 and converges to 1 as   . In practice, we show that this algorithm obtains extremely good approximations to the optimal solution, scales to large graphs, and highlights a range of different meaningful notions of density on graphs coming from numerous domains. Furthermore, it is typically able to approximate the densest subgraph problem better than the standard peeling algorithm, by better accounting for how the removal of one node affects other nodes in its neighborhood.
1 INTRODUCTION
Detecting densely connected sets of nodes in a graph is a basic graph mining primitive [14, 22]. The problem is related to graph clustering, but differs in that it only consider the internal edge structure of a subgraph, and not the number of external edges connecting it to the rest of the graph. Algorithms and hardness results for dense subgraph discovery have been studied extensively in theory [2, 6, 22] and applied in a wide array of applications, including discovering DNA motifs [12], finding functional modules in gene co-expression networks [16] and communities in social networks [37], identifying trending topics in social media [3], classifying brain networks [21], and various other data mining tasks [30, 36, 39, 46].
The typical approach for detecting dense subgraphs is to set up and solve (or at least approximate) a combinatorial optimization problem that encodes some measure of density for each node set in a graph. One simple measure of density is the number of edges in a subgraph divided by the number of pairs of nodes. This density measure plays an important role in certain clustering objectives [43], but by itself it is not meaningful to optimize, since a single edge maximizes this ratio. If, however, one seeks a maximum sized subgraph such that this type of density is equal to one or

bounded below by a constant, this corresponds to the maximum clique and maximum quasiclique problem respectively, which are both NP-hard [17, 28]. There also exists a wealth of different dense subgraph optimization problems that are nontrivial yet polynomial time solvable. The most common is the densest subgraph problem, which seeks a subgraph maximizing the ratio between the number of induced edges and the number of nodes. Another common but seemingly quite different notion of density is to find a -core of a graph [33], which is a maximal connected subgraph in which all induced node degrees are at least . The maximum value of  for which the -core of a graph is non-empty is called the degeneracy of the graph. Throughout the text, we will use the term maxcore to refer to the -core of a graph when  is the degeneracy.
Given the wide variety of existing applications for dense subgraph discovery, it is no surprise that a plethora of different combinatorial objective functions have been considered in practice beyond the objectives mentioned above [10, 11, 14, 22, 29, 31, 32, 39­ 41]. However, as a result, it can be challenging to navigate the vast landscape of existing methods and evaluate tradeoffs between them in practice. In many cases, it is useful to uncover a range of different types of dense subgraphs in the same graph, but here again there is a challenge of knowing in which dimension or specific notion of density one would like to see variation.
In light of these challenges, we define a simple, single-parameter family of objective functions for dense subgraph discovery. Our framework lets us (i) evaluate the tradeoffs between existing methods and (ii) uncover a hierarchy of dense subgraphs in the same graph, specifically in terms of the degree distribution of nodes in an induced subgraph. The family of objectives is motivated by a simple observation: the maxcore of a graph is the subgraph of maximum smallest induced degree, while the standard densest subgraph is the one of maximum average induced degree. Given that both of these are well-known and oft-used, it is natural to ask what other functions of induced node degrees are meaningful to optimize.
To answer this, we introduce the generalized mean densest subgraph problem, which is parameterized by a single parameter   R  {-, }. We show that the maxcore and standard densest subgraph problems are obtained as special cases when  = - and  = 1, respectively. Another existing notion of dense subgraphs that places a higher emphasis on large degrees is recovered when  = 2 [10]. And the limiting case of  =  is solved by simply returning the entire graph. Other values of  lead to objectives that have not been considered previously, but correspond to natural alternative objectives for dense subgraph discovery. For example, in the case of  = 0, our problem is equivalent to finding a subgraph that maximizes the average logarithm of degree. Figure 1 summarizes the objective function landscape captured by our framework.
In addition to unifying a number of previous approaches, our framework is accompanied by several novel theoretical guarantees

polynomial-time solvable complexity unknown

min
i2S
<latexit sha1_base64="aqTUS4252iEp23IzJqUNynFqJVo=">AAAB/nicbVDLSsNAFJ34rPUVFVduBotQNyWpgi6LblxWah/QhDCZTNqhM5MwMxFKKPgrblwo4tbvcOffOG2z0NYDFw7n3Mu994Qpo0o7zre1srq2vrFZ2ipv7+zu7dsHhx2VZBKTNk5YInshUoRRQdqaakZ6qSSIh4x0w9Ht1O8+EqloIh70OCU+RwNBY4qRNlJgH3uciiCn0KMCtiYwCmi1dR7YFafmzACXiVuQCijQDOwvL0pwxonQmCGl+q6Taj9HUlPMyKTsZYqkCI/QgPQNFYgT5eez8yfwzCgRjBNpSmg4U39P5IgrNeah6eRID9WiNxX/8/qZjq/9nIo000Tg+aI4Y1AncJoFjKgkWLOxIQhLam6FeIgkwtokVjYhuIsvL5NOveZe1Or3l5XGTRFHCZyAU1AFLrgCDXAHmqANMMjBM3gFb9aT9WK9Wx/z1hWrmDkCf2B9/gCYVpSX</latexit>

di(S)

1X

|S|
<latexit sha1_base64="iV+dOHjovemablH0BX7/Rxj+prY=">AAACGXicbVDLSsNAFJ34rPUVdelmsAh1U5Iq6LLoxmWl9gFNCZPJpB06mYSZiRDS/IYbf8WNC0Vc6sq/cdpmoa0HLhzOuZd77/FiRqWyrG9jZXVtfWOztFXe3tnd2zcPDjsySgQmbRyxSPQ8JAmjnLQVVYz0YkFQ6DHS9cY3U7/7QISkEb9XaUwGIRpyGlCMlJZc03ICgXBm59mkNckdn8qYoVSqlJHMkUnoZhQ6lMNW7ru02jrLXbNi1awZ4DKxC1IBBZqu+en4EU5CwhVmSMq+bcVqkCGhKGYkLzuJJDHCYzQkfU05CokcZLPPcniqFR8GkdDFFZypvycyFEqZhp7uDJEayUVvKv7n9RMVXA0yyuNEEY7ni4KEQRXBaUzQp4JgxVJNEBZU3wrxCOmolA6zrEOwF19eJp16zT6v1e8uKo3rIo4SOAYnoApscAka4BY0QRtg8AiewSt4M56MF+Pd+Ji3rhjFzBH4A+PrB/D/oXU=</latexit>

i2S

di(S)

max
i2S
<latexit sha1_base64="Nhd8dvmFalR6vBCG3Ey/F8gnq0M=">AAAB/nicbVDLSsNAFJ3UV62vqLhyM1iEuilJFXRZdOOyUvuAJoTJZNoOnZmEmYlYQsFfceNCEbd+hzv/xmmbhbYeuHA4517uvSdMGFXacb6twsrq2vpGcbO0tb2zu2fvH7RVnEpMWjhmseyGSBFGBWlpqhnpJpIgHjLSCUc3U7/zQKSisbjX44T4HA0E7VOMtJEC+8jj6DHIKPSogM0JjAJaaZ4FdtmpOjPAZeLmpAxyNAL7y4tinHIiNGZIqZ7rJNrPkNQUMzIpeakiCcIjNCA9QwXiRPnZ7PwJPDVKBPuxNCU0nKm/JzLElRrz0HRypIdq0ZuK/3m9VPev/IyKJNVE4PmifsqgjuE0CxhRSbBmY0MQltTcCvEQSYS1SaxkQnAXX14m7VrVPa/W7i7K9es8jiI4BiegAlxwCergFjRAC2CQgWfwCt6sJ+vFerc+5q0FK585BH9gff4Am3iUmQ==</latexit>

di(S)

p=
<latexit sha1_base64="VXoj7oqw66bfws/WJT3g9mAx3bI=">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0mqoBeh6MVjBfsBbSib7aZdursJuxuhhP4FLx4U8eof8ua/cZPmoK0PBh7vzTAzL4g508Z1v53S2vrG5lZ5u7Kzu7d/UD086ugoUYS2ScQj1QuwppxJ2jbMcNqLFcUi4LQbTO8yv/tElWaRfDSzmPoCjyULGcEmk2J0g4bVmlt3c6BV4hWkBgVaw+rXYBSRRFBpCMda9z03Nn6KlWGE03llkGgaYzLFY9q3VGJBtZ/mt87RmVVGKIyULWlQrv6eSLHQeiYC2ymwmehlLxP/8/qJCa/9lMk4MVSSxaIw4chEKHscjZiixPCZJZgoZm9FZIIVJsbGU7EheMsvr5JOo+5d1BsPl7XmbRFHGU7gFM7Bgytowj20oA0EJvAMr/DmCOfFeXc+Fq0lp5g5hj9wPn8ACXiNkw==</latexit>

1
<latexit sha1_base64="cMP7UeSSM7aP8uEReIn7iV5aq/Y=">AAAB7nicbVBNS8NAEJ3Ur1q/qh69LBbBiyWpgh6LXjxWsB/QhrLZbtqlm03YnQih9Ed48aCIV3+PN/+N2zYHbX0w8Hhvhpl5QSKFQdf9dgpr6xubW8Xt0s7u3v5B+fCoZeJUM95ksYx1J6CGS6F4EwVK3kk0p1EgeTsY38389hPXRsTqEbOE+xEdKhEKRtFK7YueUCFm/XLFrbpzkFXi5aQCORr98ldvELM04gqZpMZ0PTdBf0I1Cib5tNRLDU8oG9Mh71qqaMSNP5mfOyVnVhmQMNa2FJK5+ntiQiNjsiiwnRHFkVn2ZuJ/XjfF8MafCJWkyBVbLApTSTAms9/JQGjOUGaWUKaFvZWwEdWUoU2oZEPwll9eJa1a1bus1h6uKvXbPI4inMApnIMH11CHe2hAExiM4Rle4c1JnBfn3flYtBacfOYY/sD5/AEtvI93</latexit>
maxcore

0011

<latexit sha1_base64="SX5yaKZVZjogP4lIhC2+QYb0pHQ=">AAAB7XicbVDLSgNBEOz1GeMr6tHLYBA8hd0oKHgJevEYwTwgWcLsZDYZM49lZlYIS/7BiwdFvPo/3vwbJ8keNLGgoajqprsrSjgz1ve/vZXVtfWNzcJWcXtnd2+/dHDYNCrVhDaI4kq3I2woZ5I2LLOcthNNsYg4bUWj26nfeqLaMCUf7DihocADyWJGsHVS00fdaxT0SmW/4s+AlkmQkzLkqPdKX92+Iqmg0hKOjekEfmLDDGvLCKeTYjc1NMFkhAe046jEgpowm107QadO6aNYaVfSopn6eyLDwpixiFynwHZoFr2p+J/XSW18FWZMJqmlkswXxSlHVqHp66jPNCWWjx3BRDN3KyJDrDGxLqCiCyFYfHmZNKuV4LxSvb8o127yOApwDCdwBgFcQg3uoA4NIPAIz/AKb57yXrx372PeuuLlM0fwB97nD8ZHjfI=</latexit>

<latexit sha1_base64="SX5yaKZVZjogP4lIhC2+QYb0pHQ=">AAAB7XicbVDLSgNBEOz1GeMr6tHLYBA8hd0oKHgJevEYwTwgWcLsZDYZM49lZlYIS/7BiwdFvPo/3vwbJ8keNLGgoajqprsrSjgz1ve/vZXVtfWNzcJWcXtnd2+/dHDYNCrVhDaI4kq3I2woZ5I2LLOcthNNsYg4bUWj26nfeqLaMCUf7DihocADyWJGsHVS00fdaxT0SmW/4s+AlkmQkzLkqPdKX92+Iqmg0hKOjekEfmLDDGvLCKeTYjc1NMFkhAe046jEgpowm107QadO6aNYaVfSopn6eyLDwpixiFynwHZoFr2p+J/XSW18FWZMJqmlkswXxSlHVqHp66jPNCWWjx3BRDN3KyJDrDGxLqCiCyFYfHmZNKuV4LxSvb8o127yOApwDCdwBgFcQg3uoA4NIPAIz/AKb57yXrx372PeuuLlM0fwB97nD8ZHjfI=</latexit>

densest subgraph

1
<latexit sha1_base64="cMP7UeSSM7aP8uEReIn7iV5aq/Y=">AAAB7nicbVBNS8NAEJ3Ur1q/qh69LBbBiyWpgh6LXjxWsB/QhrLZbtqlm03YnQih9Ed48aCIV3+PN/+N2zYHbX0w8Hhvhpl5QSKFQdf9dgpr6xubW8Xt0s7u3v5B+fCoZeJUM95ksYx1J6CGS6F4EwVK3kk0p1EgeTsY38389hPXRsTqEbOE+xEdKhEKRtFK7YueUCFm/XLFrbpzkFXi5aQCORr98ldvELM04gqZpMZ0PTdBf0I1Cib5tNRLDU8oG9Mh71qqaMSNP5mfOyVnVhmQMNa2FJK5+ntiQiNjsiiwnRHFkVn2ZuJ/XjfF8MafCJWkyBVbLApTSTAms9/JQGjOUGaWUKaFvZWwEdWUoU2oZEPwll9eJa1a1bus1h6uKvXbPI4inMApnIMH11CHe2hAExiM4Rle4c1JnBfn3flYtBacfOYY/sD5/AEtvI93</latexit>
G

Figure 1: Summary of the objective function landscape and

algorithmic results for our newly introduced generalized

mean densest subgraph problem. The maxcore and densest

subgraph problems are special cases of this simple parameterized objective. For   1, we give an optimal algorithm

based on submodular minimization, and a fast greedy algorithm returning a 1/( + 1)1/ -approximation.

and algorithmic techniques for finding dense subgraphs. We first prove that our objective is polynomial-time solvable when   1, giving an algorithm based on repeated submodular minimization. We then present a variety of theoretical and empirical results on peeling algorithms for dense subgraph discovery in the context of our objective. These algorithms are approximation algorithms but are much faster than submodular minimization. They rely on repeatedly removing a single vertex at a time in order to shrink a graph down into a denser subgraph. The standard approach for peeling iteratively removes the node of smallest degree [4]. Surprisingly, we prove that despite seeming like a natural approach, this well-known standard peeling algorithm, which optimally solves the  = - objective [25] and provides a 1/2-approximation for the  = 1 objective [6, 19], can yield arbitrarily bad results when  > 1. However, we then design a more sophisticated but still fast peeling algorithm that is guaranteed to return a 1/(1 +)1/ approximation for any   1. Although we prove that this bound is asymptotically tight, this approximation guarantee is always at least 1/2, and converges to 1 as   . When  = 1, both the method and its guarantee reduce to that of the standard peeling algorithm.
In order to greedily optimize the  > 1 version of our objective, our method must take into account not only how removing a node affects its own degree (i.e., it disappears), but also how this affects the node's neighbors in the graph and their contribution to the generalized objective. This gives our method a certain level of "foresight" when removing nodes, that is not present in the strategy of the standard peeling algorithm. In light of this observation, our framework contains both theoretical and empirical examples where our new peeling method can outperform the standard peeling algorithm in finding dense subgraphs. For example, on many real-world graphs, we find that running our method with a value of  slightly larger than 1 will typically produce sets with a better average degree than standard peeling, even though our method is technically greedily optimizing a different objective.
We apply our methods on a range of different sized graphs from various domains, including social networks, road networks, citation networks, and web networks. We show that for small graphs with up to 1000 nodes, we can optimally find -mean densest subgraphs using submodular minimization, and that on these graphs our approximation algorithm does a much better job approximating the optimal sets than its theory guarantees. Our greedy peeling algorithm is also fast and scales to large datasets, and is able to uncover

different meaningful notions of dense subgraphs in practice as we
change our parameter .
In summary, we present the following contributions. · We introduce the generalized mean densest subgraph problem
and show that the well-studied maxcore and densest subgraph
problems are special cases. · We give a polynomial-time algorithm for optimally solving the
objective for any   [1, ], by showing that the decision version of the problem can be solved via submodular minimization. Existing linear-time algorithms solve the  = - case, which reduces to maxcore. · We provide a faster greedy approximation algorithm that returns a 1/( + 1)1/ approximation for   1. We show a class of graphs for which this approximation is tight. As   , this approximation converges to 1. We also prove that for any  > 1,
the greedy algorithm for the standard densest subgraph problem
returns arbitrarily bad approximations on certain graph classes. · We use our framework and methods to identify a range of dif-
ferent types of dense subgraphs and compare the performance
of different peeling algorithms, on graphs coming from a wide
variety of domains.

2 TECHNICAL PRELIMINARIES
Let  = ( , ) be an undirected and unweighted graph. For    , let N () = {   : (, )  } denote the neighborhood of node , and  = |N ()| be its degree. For a set    , let  denote the set of edges joining nodes in  and  () = |N ()   | be the degree of  in the subgraph induced by . If   , then  () = 0.

Dense Subgraph Problems. The densest subgraph problem seeks a set of nodes  that maximizes the ratio between the number of edges and nodes in the subgraph induced by :

| |

maximize .

(1)

  | |

The numerator of this objective is equal to half the sum of induced node degrees in , and therefore this problem is equivalent to finding the maximum average degree subgraph:

max
 

   () | |

=

max
 

avg






(

)

.

(2)

This problem is known to have a polynomial-time solution [13, 15],
as well as a fast greedy peeling algorithm that is guaranteed to return a 1/2-approximation [6, 19].
Another well-studied dense subgraph problem is to find the -
core of a graph for a positive integer  [5, 9, 24, 35]. The -core of
a graph is a maximal connected subgraph in which all nodes have
degree at least . The maximum value of  for which the -core of a graph is non-empty is called the degeneracy of the graph. If  is the degeneracy of , we will refer to the -core of  as the maxcore. Finding the maxcore is equivalent to finding the subset  that maximizes the minimum induced degree:

max min  ().

(3)

   

For any value of , the -core of a graph can be found in linear time via a greedy peeling algorithm that repeatedly removes nodes with degree less than  [25].
2

Generalized Means. For a vector of positive real numbers x = 1 2 · · ·   R+, the generalized mean (power mean or -mean) with exponent  of x is defined to be



1/

1 

 (x) =

( ) .

(4)



 =1

For   {, -, 0}, the mean can be defined by taking limits, so that  (x) = min  , - = max  , and 0 (x) = (12 · · · )1/ (the  = 0 case is often called the geometric mean).

Submodularity and the power function. We review a few useful
preliminaries on submodular functions and properties of the power
function  () = | | for   0 that will be useful for our algorithmic results. For a discrete set , a function  :   R is submodular if for any subsets ,    it satisfies

 () +  ()   (  ) +  (  ).

(5)

If the above inequality is reversed,  is referred to as a supermodular function, and if we replace it with equality, the function is called modular. We have the following two simple observations about properties of the power function, which follow from the fact that  is concave when   [0, 1], and convex when   1.

Observation 1. The function () = || for    is submodular when   [0, 1] and supermodular when   1.

Observation 2. Let   1 and   1. Then

 (

- 1)-1

 

- (

- 1)



 -1
 .

3 THE -MEAN DENSEST SUBGRAPH

We now introduce a new single-parameter family of dense sub-

graph objectives based on generalized means of degree sequences. Abusing notation slightly, we define the -density of    to be

1/

1 

 () = | | [ ()] .

(6)

 

The generalized mean densest subgraph problem is then to find a set of node  that maximizes  (). We also refer to this as the
-mean densest subgraph problem to make the parameter  explicit.

It is worthwhile to note that this objective increases monotonically with , ranging from the minimum degree of  when  = - to the maximum degree of  when  = .

3.1 Equivalence Results and Special Cases
The definition of generalized mean, and the characterizations of the densest subgraph and max-core problem given in (2) and (3), immediately imply the following equivalence results.
Lemma 3.1. The standard densest subgraph problem (2) is equivalent to the 1-mean densest subgraph problem. The maxcore objective is equivalent to the --mean densest subgraph problem.
Although studied less extensively, an equivalent variant of the 2-mean densest subgraph has also been previously considered [10] as a way to find dense subgraphs that place a higher emphasis on the largest degrees. Our new objective therefore unifies existing dense subgraph problems, and suggests a natural way to interpolate them as well as find new meaningful notions of dense subgraphs.

For finite  > 0, maximizing  () is equivalent to maximizing [ ()] . In other words, the -mean densest subgraph problem
seeks a subgraph with the highest average th-power degree:



( )

=



 () | |

.

(7)

 

For  = , objective (7) is no longer meaningful, but from the standard definition of -mean we know that  () = lim  () is simply the maximum degree of the induced subgraph. This makes

intuitive sense given that objective (7) places higher and higher emphasis on large degrees as   . The  =  objective is

trivially solved by taking the entire graph , though this will not

necessarily be optimal for large but finite values of . When  = 0, the generalized mean coincides with the geometric

mean, which for our dense subgraph framework means that

1/| |

0 () =  ()

.

(8)

 

As long as  does not include zero degree nodes, maximizing this quantity is equivalent to maximizing log 0 (), which amounts to finding the subgraph with maximum average log-degree:

0 ()

=

log

0 ()

=



log  () | |

.

(9)

 

While natural, this objective has not been previously considered

for dense subgraph problems.
Finally, for finite  < 0, maximizing  () is equivalent to maximizing ( ())- , which equals

( ())- =

  [ ()] | |

-1
=

avg


[

(

)]

-1
.

(10)

In other words, while the  = 1 objective maximizes the average degree, the  = -1 objective seeks the to maximize one over the average inverse degree (corresponding to the harmonic mean of the degrees). For other  < 0 the goal is to maximize one over the average th power of the degrees.

3.2 Comparison with Existing Objectives
Before moving on we compare and contrast our -mean objective against similar generalizations of the densest subgraph problem. See Section 6 for more related work.
The -clique densest subgraph. Tsourakakis [39] previously introduced the -clique densest subgraph problem (-DS), which seeks a set of nodes  that minimizes the ratio between the number of -cliques and the number of nodes in . The standard densest subgraph problem is recovered when  = 2. The author showed that this objective can be maximized in polynomial time for any fixed value of , and also gave a 1/-approximate peeling algorithm by generalizing the standard greedy peeling algorithm [4, 6]. In practice, even when  = 3, maximizing this objective can produce subgraphs that are much closer to being near cliques than the standard densest subgraph solution.
F-density. An even more general objective called F-density was introduced by Faragó [10]. Given a family of graphs F, this objective seeks a set  that maximizes the ratio between the number
3

of instances of F-graphs in , and | |. The -DS problem is recovered when F includes only the clique on  nodes. Interestingly, Faragó [10] showed that when F = {2, 3}, where  is the path graph on  nodes, then the F-density is the following ratio:

1    ()2

.

(11)

2 | |

The maximizers of this objective are the same as those for the 2mean densest subgraph problem in our framework, although there are differences in terms of approximation guarantees of algorithms.
Discounted average degree and f-densest subgraph. The above objectives generalize the standard densest subgraph problem by changing the numerator of the objective. Generalizing in a different direction, Kawase and Miyauchi [18] introduced the  -densest subgraph problem, which seeks a set    maximizing | |/ (| |) for a convex or concave function  . This includes the special case  () = | | for  > 0, which generalizes the earlier notion of discounted average degree considered by Yanagisawa and Hara [45]. When  is concave, maximizing the objective will always produce output sets that are larger than or equal to optimizers for the densest subgraph problem. Convex  produces outputs sets that are always smaller than or equal to densest subgraph solutions [18].
Comparison with -mean densest subgraph. The -mean densest subgraph problem is similar to the above objectives in that they are all parameterized generalizations of the densest subgraph problem. However, each generalizes the objective in a different direction. The -clique densest subgraph problem parameterizes preferences for obtaining clique-like subgraphs, while F-density more generally controls the search for dense subgraphs that are rich in terms of specified subgraph patterns (graphlets). The discounted average degree and  -densest subgraph objectives reward set sizes differently, while keeping the same emphasis on counting edges in the induced subgraph. Meanwhile, our objective encapsulates different preferences in terms of induced node degrees. Many subcases amount to maximizing averages of different functions on node degrees. Importantly, the max-core problem is not captured as a special case of F-density, -DS, or the  -densest subgraph.
Our objective and the  -densest subgraph problem are tangentially similar in that they both can involve the power function  () = | | in some way. However, a major difference is that the latter objective shares the same numerator (the induced edge count | |) as the standard densest subgraph, which is not the case for our problem. This leads to substantial differences in terms of the computational complexity and the output sets that maximize these objectives. For example, the  -densest subgraph with  () = | | is NP-hard when  > 1 and is guaranteed produce smaller output sets than the standard densest subgraph in this case, and is also known to have trivial constant-sized optimal solutions when  > 2 [18]. In contrast,   1 is in fact the easier regime for our problem and will often, but not always, produce larger output sets. Finally, we note that the relationship between F-density and 2-mean density does not appear to generalize to other values of , even if we restrict to positive integer values of . In particular, by checking a few small examples, it is easy to confirm that the 3-mean density objective is not equivalent to F-density when F = {2, 3, 4}.

4 ALGORITHMS
We now present new algorithms for the -mean densest subgraph problem. We show that the objective can be solved in polynomial time for any   1 via submodular minimization. For the same parameter regime, we show that the standard greedy peeling algorithm [4, 6, 19] can return arbitrarily bad results, but a more sophisticated generalization yields a (1+)1/ approximation, which is also tight. Algorithms for   (-, 1) appear more challenging--both our submodular minimization technique and greedy approximation do not hold in this case. Improved algorithms or hardness results for this regime are a compelling avenue for future research.

4.1 An Optimal Algorithm for   1

For finite  > 0, argmax  () = argmax  (), so for simplicity
we focus on the latter objective. In the next section we will use the fact that a -approximate solution for  () provides a 1/ approximate solution for  ().
Given a fixed  > 0, the decision version of our problem asks whether there exists some  such that  ()  , or equivalently
   () -  | |  0. We can obtain a yes or no answer to this question by solving the following optimization problem



max  () =  () -  | |.

 

 

When  = 1, it is well known that this can be solved by solving a minimum - cut problem [15], which is itself a special case of submodular minimization (equivalently, supermodular function maximization). The following result guarantees that we can still get a polynomial time algorithm for the -mean densest subgraph when   1 by using general submodular minimization.

Lemma 4.1. If   1 and  > 0, the function () =    () -  | | is supermodular.

Proof. The function () = | | is modular, so it suffices to show that the function () =    () is supermodular whenever   1. For a node    and an arbitrary set    , if    then define  () = 0. This allows us to write () as a summation over
all nodes in  without loss of generality:
 () =  () .
 

We would like to show that for arbitrary sets  and  , we have





 () +  ( )   (   ) +  (   ),

 

 

which is true if we can show that for every    and   1,

 () +  ( )   (   ) +  (   ) .

(12)

To prove (12), let  be the set of edges adjacent to , and note that all of the terms in inequality (12) represent the number of edges in a certain subset of . Specifically, define
 = {(, )   :   ,    },  = {(, )   :    ,    },  = {(, )   :      ,      },  = {(, )   :      ,      }.

4

Consider the sets obtained by unions and intersections of  and :
   = {(, )   :      ,      } =     = {(, )   : ,    OR ,    }  .
These sets are related to sets of edges that contribute to degree counts for node    :
 () = ||,  ( ) = ||,  (   ) = | | = |  |,  (   ) = | |  |  |. Recall from Observation 1 that if  is a discrete set, then the function  () = || for    is supermodular whenever   1. Therefore, for these sets of edges,

Algorithm 1 Generalized Peeling Algorithm (GenPeel-)

Input:  = ( , ), parameter   1

Output: Set 

 ,

satisfying

1 ()



1  +1

max

1 ().

0  

for  = 1 to  do



=

argmin


(  (-1))

 = -1\{ }

end for

Return max  ( ).

1/2-approximation for the standard peeling algorithm is tight for the 1-mean objective [19].

 (   ) +  (   ) = | | + | |  |  | + |  |  || + || =  () +  ( ) .

So the desired inequality is shown.



Using submodular minimization algorithms as a black box [27],
we can perform binary search on  to find the maximum value of  such that  ()  0, which is equivalent to saying  ()  . The number of binary search steps necessary to exactly optimize  () can be easily bounded by a polynomial in . The number of different values that the numerator    () can take on is trivially bounded above by 2, as this is the number of distinct ways
to bipartition the graph. The denominator can take on  values.

We can use 0 and    as bounds for our binary search, and even for an extremely pessimistic case,  () binary search steps would be necessary, though typically it will be far less in practice.
We conclude the following result.
Theorem 4.2. For any graph  = ( , ) and   1, the -mean densest subgraph can be found in polynomial time.

Lemma 4.3. Let  > 1 and   (0, 1) be fixed constants. There exists a graph  such that applying SimplePeel on  will yield an approximation worse than  for the th power degree objective.

Proof. The proof is by construction. Let 1 = (1, 1) be a
complete bipartite graph with  nodes on one side and  nodes on the other, and 2 = (2, 2) be a disjoint union of  cliques of size  + 2. We treat  as a fixed constant and  as a value that will grow without bound. Define graph  = (1 2, 1  2) to be the union of 1 and 2. We have  (2) = ( + 1) , and

 +   (1) =  +  .
As   , 1 is the best -mean densest subgraph, with (1) behaving as -1. However, SimplePeel will start by removing

all of the nodes in 1, since on one side of the bipartite graph, all nodes have degree , whereas all nodes 2 have degree  + 1. At
the outset of the algorithm, we start with all of  and note that

 ( ) =

 +  +  ( + 2) ( + 1)  +  +  ( + 2)

<

 -1


+

 -1


+

(

+

1)

.

This result is intended to serve mainly as a theoretical result confirming the polynomial-time solvability of the problem for   1. We next turn to more practical greedy approximation algorithms.
4.2 Failure of the Standard Peeling Algorithm

We see that as   , this provides only a 1/ approximation to  (1). As SimplePeel removes nodes from 1, the approximation
gets worse, until we are left with a subgraph with maximum average th power degree of ( + 1) . Since  was an arbitrary constant, we can choose  = 2/. Then, for large enough  we will have

The standard peeling algorithm for both the maxcore and densest subgraph problem is to start with the entire graph  and repeatedly remove the minimum degree node until no more nodes remain.

1  ( ) 2

<

< < .

  (1) 

We will refer to this algorithm generically as SimplePeel. This Therefore, the approximation is worse than .



algorithm produces a set of  subgraphs 1, 2, . . . , , one of which
is guaranteed to solve the maxcore problem [25], and another of which is guaranteed to provide at least a 1/2-approximation to the
standard densest subgraph problem [6]. Trivially, this method also yields and optimal solution for  = , since the entire graph  solves the -mean objective.
Given the success of this procedure for   {-, 1, }, it is
natural to wonder whether it can be used to obtain optimal or near optimal solutions for other values of . Focusing on the   0 case, we know that if  = min   () for a subset , then it is also true that  = min   () , again suggesting that this strategy might be effective. However, surprisingly, we are able to show that the

The above result means that for any   (0, 1) and  > 1 fixed, there exists a graph with an optimal -mean densest subgraph ,
such that the simple greedy method will return a set ^ satisfying

 (^) <   ()

=

 (^)

<

1/


max  ().

 

Since  is fixed and  is arbitrarily small, this means the simple greedy method can do arbitrarily badly when trying to approximate

the -mean densest subgraph problem.

4.3 Generalized Peeling Algorithm when   1
The failure of SimplePeel can be explained by noting that when

simple peeling algorithm can perform arbitrarily poorly for any  > 1. To show this, we consider the performance of the algorithm on the same class of graphs that has been used to show that the

 > 1, removing a minimum degree node from a subgraph  does
not in fact greedily improve -density. Consider a node set  and its average th power degree function  (). Removing any    will

5

change the denominator of  () in exactly the same way. Therefore, to greedily improve the objective by removing a single node, we

should choose the node that leads to the minimum decrease in the

numerator    () . Importantly, it is not necessarily the case

that



=

argmin




 ()

is

the

best

node

to

remove.

This

would

account only for the fact that the numerator decreases by   () ,

but ignores the fact that removing  will also affect the degree of all

other nodes that neighbor  in . For example, if  has a small degree

but neighbors a high degree node , then when  > 1, removing

node  and decreasing 's degree could substantially impact the

-density objective. For a graph , node set , and arbitrary node   , the following function reports the exact decrease in the numerator of  () resulting from removing :



 () =  () +

 () - [ () - 1] . (13)

 N ( )

In other words, note that    () is the numerator before removing , and after removing it we have a new numerator





 (\{  }) =  () -  ().

 \{  }

 

Observe that when  = 1,  () = 2  (), which explains why it suffices to remove the minimum degree node in order to greedily optimize the  = 1 variant of the objective. Based on these observations, we define a generalized peeling algorithm, which we call GenPeel-, or simply GenPeel when  is clear from context, based on iteratively removing nodes that minimize (13). Pseudocode is given in Algorithm 1. We prove the following result.
Theorem 4.4. Let  = ( , ) be a graph,   1, and  be the -mean densest subgraph of . Then GenPeel- returns a subgraph  satisfying ( + 1)  ()   ( ), i.e., ( + 1)1/  ()   ( ).

Proof. Define  =  ( ), which implies that    () - | | = 0. Since  is optimal, removing a node  will produce a set
with -density at most , and therefore, we have

   ( ) -  ( )   | | - 1
 =  ( ) -  ( )  | | -  =    ( ).
 

Observe that for any set    and    we have  ( )   (). This holds because   () is larger than   ( ) when we grow the subgraph, and also because the function  () - [ () - 1]
also monotonically grows as  gets bigger, as long as   1.

Let  denote the set maintained by the greedy algorithm right

before the first node    is removed by peeling. Since  is the first

node to be removed by the peeling algorithm, we know that   

and



( )



 ().

Because



=

argmin




 (),

we

know



( )

is smaller than the average value of  () across nodes in , so 1 
  ( )   ()  | |  ()
 

1 =
| |





 () +



 () - [ () - 1]

 

   N ()

1 
| |





 () +



 ()-1 .

 

   N ()

The last step follows from the bound in Observation 2. For every   , the value  ()-1 show up exactly  () times in the double summation in the second term--once for every    such that 

neighbors  in . Therefore:



   () +  | |

   () | |

= ( + 1)  ().



In the appendix, we provide an in-depth graph construction to
show that this approximation guarantee is asymptotically tight for all values of . Nevertheless, for   1, the quantity ( + 1)1/ decreases monotonically and has a limit of one, meaning that the
-density problem in fact becomes easier to approximate as we increase . In fact, the 1/2-approximation for the standard densest subgraph problem is the worst approximation that this method obtains for any   1. The fact that the approximation factor converges to 1 also intuitively matches the fact that when  = , the optimal solution is trivial to obtain by keeping all of .
Key differences between peeling algorithms. Before moving on, it is worth noting two key differences about removing nodes based on degree (SimplePeel) and removing nodes based on  (GenPeel). The first is purely practical: it is faster to keep track of node degrees than to keep track of changes to  for each node  when peeling. Removing a node  will change the degrees of nodes within a onehop neighborhood, but will change  values for every node within a two-hop neighborhood of . This additional detail complicates the runtime analysis and implementation of GenPeel. For  = ||, a naive runtime bound of  () can still be obtained by first realizing that as long as degrees are known, the value of  can be computed in  (  ) time, and so all  values can be computed in  (    ) =  () time. There are  rounds overall, and in each round it takes  () time to find the minimizer of  , plus  () time to update degrees after a node is removed, plus  () time to update  values in preparation for the next round.
Although this runtime bound is much worse than the linear
time guarantee for the best implementation of SimplePeel, it is
quite pessimistic, and in practice we can still scale up GenPeel
to large datasets in practice. Furthermore, although GenPeel is
slower, this difference in strategy is not without its advantages. The 1/2-approximation for SimplePeel is tight on certain graph classes made up of disjoint cliques and complete bipartite graphs [19].
This is also the same class of graphs we used to show that the
method does arbitrarily badly when  > 1. SimplePeel fails to
find the best subgraph on these instances because it considers the
degree of a node without sufficiently considering the effect on
its neighborhood. Meanwhile, GenPeel finds the optimal solution
6

(a) Polbooks,  = 105

(b) Adjnoun,  = 112

real-world graphs. To demonstrate this, we find a set of optimal solutions to our objective for  values in objs = {1.0, 1.5, 2.0, . . . , 5.0}. We solve our objective exactly on graphs with up to 1000 nodes
to within a small tolerance with a MATLAB implementation that
uses existing submodular minimization software as a black box [20]. We then run GenPeel for each   alg = {1.0, 2.0, 3.0, 4.0, 5.0}. This produces 5 dense subgraphs, and we evaluate how each one approximates the optimal solution for all   objs.
As expected, GenPeel-0 provides the best approximation for all  near 0. Rounded curves in Figure 2 show that each run of GenPeel optimizes a different regime of our problem. For three datasets, the   {4, 5} solutions are identical, both at optimality and for the sets returned by GenPeel. Otherwise, we see a clear
distinction between the output curves for each run of the algorithm,
indicating that we are finding different types of dense subgraphs.

(c) Jazz,  = 198

(d) Email,  = 1005

Figure 2: Quality of the fast GenPeel heuristic compared to

exact solution obtained with submodular minimization. Dif-

ferent runs of GenPeel for different values of  do a good job of approximating the objective. For plots (a)­(c), the  = 4 and  = 5 greedy solution are the same.

on these graph classes for all   1. In our next section, we will demonstrate empirically that running GenPeel with  > 1 actually outperforms SimplePeel in optimizing the  = 1 objective.

5 EXPERIMENTS
We now consider how our methods enable us to find a range of different meaningful notions of dense subgraphs in practice. We begin by showing that GenPeel does an excellent job of approximating the optimal -mean densest subgraph problem, scales to large datasets, and detects subgraphs with a range of different meaningful notions of density. Using GenPeel-0 with 0 > 1 can even be used to solve the  = 1 objective (standard densest subgraph) better than SimplePeel (which is equivalent to GenPeel-1) in many cases, even though SimplePeel greedily optimizes the  = 1 objective but GenPeel-0 with 0 > 1 does not. All of our experiments were performed on a laptop with 8GB of RAM and 2.2 GHz Intel Core i7 processor. We use public datasets from the SNAP repository [23] and the SuiteSparse Matrix collection [8]. We implement GenPeel and SimplePeel in Julia, both using a simple min-heap data structure for removing nodes, which works well in practice. We implement our optimal submodular minimization approach in MATLAB, in order to use existing submodular optimization software [20]. All algorithm implementations and code for our experiments are available at https://github.com/nveldt/GenMeanDSG.

5.1 GenPeel Approximation Performance
In practice, GenPeel can find a dense subgraph that approximates the optimal solution much better than its worst case guarantee. Furthermore, both the optimal -mean densest subgraphs for different , and the sets found by GenPeel using different , are meaningfully distinct from each other and highlight different notions of density in

5.2 Peeling Algorithms for Dense Subgraphs
Out next set of experiments places the standard greedy peeling algorithm for densest subgraph ( = 1) and the peeling algorithm for finding maxcore ( = -) within a broader context of parametric peeling algorithms for dense subgraph discovery. By comparing these outputs against GenPeel for different  values near 1, we can observe how each method emphasizes and favors different notions of density in the graph. We can also see how running GenPeel for values near but not equal to one provides an accuracy vs. runtime tradeoff when it comes to finding sets that satisfy the traditional  = 1 notion of density.
We run GenPeel for   {0.5, 1.0, 1.05, 1.5, 2.0}. Although our method provides no formal guarantees when  < 1, it nevertheless greedily optimizes the -mean density objective and produces meaningfully different subgraphs. When  = 1, our implementation defaults to running the faster SimplePeel algorithm, and also outputs the maxcore solution, as this is obtained by simple peeling with a different stopping point. We focus on the regime   [0.5, 2] in order to better understand how different desirable measures of density vary as we explore above and below the standard densest subgraph regime ( = 1). Additionally, restricting to   2 means we are interpolating between objectives that have previously been studied [6, 10, 25], and avoids placing too high of an emphasis on just finding a small number of very high degree nodes.
Table 1 displays runtimes and subgraph statistics for each peeling result on a range of familiar benchmark graphs from a variety of different domains. This includes two citation networks (ca-Astro, condmat2005), two road networks (road-CA, road-TX), two web graphs (web-Google, web-BerkStan), an email network (Enron), two social networks (BrightKite, YouTube), and a retail graph (Amazon). We report the edge density (number of edges divided by number of pairs of nodes), the size of the set returned, and the average degree (i.e., the  = 1 objective). There are clear trends in the output of each method: as  decreases, the subgraphs tend to be smaller and have a higher edge density. As  increases from 0.5 to 2, the average squared degree and the maximum degree increase significantly. What is perhaps most significant is that running GenPeel- with  > 1 tends to produce better sets than SimplePeel in terms of the standard densest subgraph objective. We conjecture that this is because GenPeel makes more strategic node removal decisions
7

Table 1: We compare our peeling algorithm for the -mean densest subgraph against SimplePeel (the  = 1 special case) and the maxcore of a graph (p = -) in terms of various measures of density on a range of graphs. With some exceptions, increasing  tends to produce larger sets with lower edge density. The  = 1 and maxcore case have the same runtime as they rely on finding the same ordering of nodes, with different stopping points. Simple peeling is faster, but our approach is still
fast, and for max degree, averaged squared degree, and average degree, one of our new approaches leads to the best results in
all cases. Our new methods in several cases also lead to the best results for edge density. We highlight in bold the best result
obtained for these four different notions of density. The fact that GenPeel-0 with 0 > 1 outperforms SimplePeel in terms of average degree is especially significant, since the latter is designed to greedily optimize average degree, the  = 1 objective.

| |

Metric

||

Astro CM05 BrKite Enron roadCA roadTX webG webBS Amaz YTube 17,903 36,458 58,228 36,692 1,971,281 1,393,383 916,428 685,230 334,863 1,134,890 196,972 171,734 21,4078 183,831 2,766,607 1,921,660 4,322,051 6,649,470 925,872 2,987,624

Size

maxcore 57

30

154 275 4568

1579

48

392

497 845

 = 0.5 165

30

200 469 4568

1579

229

392

497 1616

| |

 = 1.0 1151 563

219

548

11

3721

240

392

34

1863

 = 1.05 1317 565

220

556

6

26

240

392

3848 1900

 = 1.5 1564 742

242

713

12

91

243

5352

118 3085

 = 2.0 1491 938

273

1036 185

13

4429

34944 550 29639

Edge Density

| |/

| | 2

maxcore  = 0.5  = 1.0
 = 1.05  = 1.5  = 2.0

1.0 0.348 0.052 0.045 0.039 0.041

1.0 1.0 0.056 0.056 0.043 0.032

0.502 0.407 0.372 0.37 0.335 0.29

0.256 0.159 0.137 0.135 0.104 0.068

0.001 0.001 0.345 0.733 0.333 0.02

0.002 0.002 0.001 0.166 0.044 0.295

0.994 0.235 0.227 0.227 0.225 0.005

0.529 0.529 0.529 0.529 0.031 0.001

0.014 0.014 0.23 0.002 0.082 0.005

0.102 0.056 0.049 0.048 0.029 0.001

Avg

maxcore 56.0 29.0 76.87 70.06 3.32

3.34

46.71 206.81 6.77 86.07

Degree

 = 0.5 57.02 29.0

80.91 74.38 3.32

3.34

53.58 206.81 6.77 90.76

 = 1.0 59.28 31.57 81.11 74.68 3.45

3.49

54.36 206.81 7.59 91.16

avg  ()  = 1.05 59.25 31.58 81.12 74.69 3.67

4.15

54.36 206.81 8.7

91.18

 = 1.5 60.74 31.61 80.8 73.96 3.67

4.0

54.47 166.93 9.56 88.86

 = 2.0 60.92 30.32 78.99 70.35 3.62

3.54

20.39

44.04

2.65 19.88

Avg

maxcore 3136.0 841.0 6335.5 5685.5 11.3

11.7

2182.4 43840.3 47.4 9227.8

Squared  = 0.5 3297.6 841.0 7372.9 7002.2 11.3

11.7

2930.9 43840.3 47.4 11486.8

Degree

 = 1.0 4154.3 1265.8 7614.1 7301.6 12.2

12.7

3031.9 43840.3 59.2 12146.5

 = 1.05 4226.3 1269.0 7624.9 7336.1 13.7

19.2

3031.9 43840.3 189.3 12220.1

avg  ()2  = 1.5 4691.7 1356.1 7776.6 7691.7 13.7

17.3

3051.2 157225.3 372.9 14359.8

 = 2.0 5106.6 1384.1 7882.1 7918.9 13.9

18.6

9730.9 455975.9 552.3 33262.3

Max

maxcore 56

29

153 216 7

Degree

 = 0.5 108

29

196 302 7

 = 1.0 241

161

214

333

4

max  ()  = 1.05 281

163

215

338

4

 = 1.5 333

200

233

399

4

 = 2.0 392 257 260 513 9

12

47

391

13

447

12

82

391

13

844

12

84

391

10

954

8

84

391

161 978

8

86

5351

106 1428

12

2329 34943 549 28754

Runtime maxcore 0.03 0.03 0.06 0.04 1.37

0.96

2.4

11.27

0.45 2.51

 = 0.5 0.29 0.19 0.38 0.46 4.8

3.41

51.28

608.5

2.01 58.87

 = 1.0 0.03 0.03 0.06 0.04 1.37

0.96

2.4

11.27

0.45 2.51

 = 1.05 0.25 0.18 0.35 0.4

4.4

3.0

41.92 490.91 1.62 39.21

 = 1.5 0.26 0.17 0.32 0.37 4.29

3.14

39.64 324.67 1.67 30.26

 = 2.0 0.25 0.17 0.32 0.35 4.12

3.07

19.13 295.73 1.69 26.17

based not only on a node's degree, but also on the degree of its neighbor. This comes at the expense of a slower runtime, but we still find that our method is fast and scales up to very large graphs.
5.3 Dense Subgraphs in Social Networks
Finally, we use GenPeel to detect different types of dense subgraphs in social networks. We run our method for   {0.25, 0.5, . . . , 2.0},

on all graphs from the Facebook100 dataset [38]. Each graph is a snapshot of the Facebook network at a US university. The graphs have 700­42k nodes. For each of the 100 graphs, we plot curves indicating how the average degree, size, maximum degree, and edge density changes as  increases (Figure 4). In this parameter regime, the average degree of subgraphs returned hardly varies (Figure 4a). Increasing  tends to produce subgraphs that are larger and have
8

Figure 3: Runtime for Facebook100. GenPeel scales linearly on these datasets, and takes only a few seconds to run.
a higher maximum degree (Figures 4b and 4c), while decreasing  produces smaller sets with higher edge density (Figure 4d). We again find that running GenPeel with  > 1 can often find sets with higher average degree. This happens on six Facebook graphs when  = 1.25 (Figure 4a). We separately ran GenPeel with  = 1.05 on all graphs, and found that it returned sets with higher average degree than SimplePeel on 42 out of the 100 graphs.
Figure 3 is a scatter plot of points (,) where  is the number of nodes in a Facebook graph and  the the time in seconds for our algorithm. When  = 1, the method is much faster as it only considers node degree when greedily removing nodes. For the   1 case, runtime are still very fast and still scale roughly linearly, though with a steeper slope. For  < 1 and  > 1, the same exact procedure is applied. The  < 1 case nevertheless tends to take slightly longer, perhaps simply because greedy node removal in this regime can lead to more drastic changes in the function  that the algorithm must update at each iteration. Still, on even the largest graphs, GenPeel takes just a few seconds.
6 RELATED WORK
In order to situate our research within a broader context, we briefly review other related work on dense subgraph discovery. The standard densest subgraph problem is known to be polynomial time solvable via reduction to a maximum - flow problem [13, 15]. When the goal is to find the densest subgraph on  nodes, the problem becomes NP-hard [11]. A number of methods for finding dense subgraphs focus specifically on greedy peeling algorithms. The standard peeling algorithm for dense subgraph discovery was first proposed by Ashahiro et al. [4] as a means to approximate the latter task, but was later shown by Charikar [6] to provide a 1/2-approximation to the unrestricted objective. This approximation was later adapted by Khuller and Saha [19] to provide an approximation in the case of directed graphs, a variant that can also be solved in polynomial time. A number of generalizations of the objective have recently been considered, including the -clique densest subgraph [39], the F-density objective [10], the  -densest subgraph [18], and generalizations involving signed graphs [41], bipartite graphs [30], and fairness constraints [1]. Outside of direct variations on the densest subgraph problem that we generalized, other formalisms for similar dense subgraphs include nucleus decompositions [32], quasi-cliques [40], trusses [7], braces [42], DNgraphs [44], plexes [34], and clubs and clans [26]. For additional

(a) Average degree

(b) Size

(c) Max Degree

(d) Edge Density

Figure 4: We apply GenPeel on 100 subsets of Facebook for   [0.25, 2]. Each line corresponds to one of the 100 FB net-

works, the ten networks that change the most in size are

highlighted in color to illustrate key trends. There is signif-

icant overlap in sets; typically the subgraph obtained for a

value  contains most of the subgraph for 0 < . In this

way our method is effectively uncovering a nested hierar-

chy of dense subgraphs that are related but whose proper-

ties change depending on the desired notion of density. (a)

In general average degree changes very little, but the sub-

graphs vary in size (b), maximum degree (c), and edge density | |/(||) (d), as we vary . In several cases, we obtain a
2
slightly higher average degree with GenPeel when  = 1.25 ( marks in top left plot) than when  = 1, the case where

our method reduces to the standard peeling algorithm.

related work, we refer to the survey by Lee et al. [22] and a tutorial from Gionis and Tsourakakis [14].

7 CONCLUSION AND DISCUSSION
Our -mean densest subgraph objective unifies the standard densest subgraph and maxcore problems, and provides a general framework for capturing different notions of density in the same graph. We have presented several new algorithmic guarantees, including an optimal polynomial time solution based on submodular minimization, and a fast approximation algorithm based on a more sophisticated variant of the standard peeling method. The most compelling direction for future work is to develop computational complexity results and algorithms for   (-, 1). Experimental results using the greedy approximation for   (0, 1) indicate that this regime favors smaller clusters with a higher edge density, which is a particularly attractive property in dense subgraph discovery. A question that remains open even for   1 is whether a single peeling algorithm or alternative ordering method on the nodes can be used to define a nested set of dense subgraphs that can well approximate our objective for a wide range of  values, simply by adding or subtracting additional nodes from the ordering as  changes. In many of our experiments, the greedy method return subgraphs that
9

were often nested or at least nearly nested. This therefore seems
like a promising avenue for future theoretical results, or at least
new practical techniques that provide a range of dense subgraphs
without re-running an algorithm for each value of .
ACKNOWLEDGMENTS
This research was supported by NSF Award DMS-1830274, ARO
Award W911NF19-1-0057, ARO MURI, JPMorgan Chase & Co, a
Vannevar Bush Faculty Fellowship, and a Simons Investigator grant.
REFERENCES
[1] Aris Anagnostopoulos, Luca Becchetti, Adriano Fazzone, Cristina Menghini, and Chris Schwiegelshohn. 2020. Spectral Relaxations and Fair Densest Subgraphs. In CIKM.
[2] Reid Andersen and Kumar Chellapilla. 2009. Finding dense subgraphs with size bounds. In WAW.
[3] Albert Angel, Nick Koudas, Nikos Sarkas, and Divesh Srivastava. 2012. Dense Subgraph Maintenance under Streaming Edge Weight Updates for Real-time Story Identification. VLDB (2012).
[4] Yuichi Asahiro, Kazuo Iwama, Hisao Tamaki, and Takeshi Tokuyama. 2000. Greedily Finding a Dense Subgraph. J Algorithm (2000).
[5] Shai Carmi, Shlomo Havlin, Scott Kirkpatrick, Yuval Shavitt, and Eran Shir. 2007. A model of Internet topology using k-shell decomposition. PNAS U.S.A (2007).
[6] Moses Charikar. 2000. Greedy approximation algorithms for finding dense components in a graph. In APPROX.
[7] Jonathan Cohen. 2008. Trusses: Cohesive subgraphs for social network analysis. Technical Report. National Security Agency.
[8] Timothy A. Davis and Yifan Hu. 2011. The University of Florida Sparse Matrix Collection. ACM Trans. Math. Softw. (2011).
[9] Sergey N Dorogovtsev, Alexander V Goltsev, and Jose Ferreira F Mendes. 2006. K-core organization of complex networks. Phys. Rev. Lett (2006).
[10] András Faragó. 2008. A general tractable density concept for graphs. Mathematics in Computer Science 1, 4 (2008), 689­699.
[11] Uriel Feige, David Peleg, and Guy Kortsarz. 2001. The dense k-subgraph problem. Algorithmica 29, 3 (2001), 410­421.
[12] Eugene Fratkin, Brian T Naughton, Douglas L Brutlag, and Serafim Batzoglou. 2006. MotifCut: regulatory motifs finding with maximum density subgraphs. Bioinformatics 22, 14 (2006), e150­e157.
[13] Giorgio Gallo, Michael D Grigoriadis, and Robert E Tarjan. 1989. A fast parametric maximum flow algorithm and applications. SIAM J. Comput. 18, 1 (1989), 30­55.
[14] Aristides Gionis and Charalampos E Tsourakakis. 2015. Dense subgraph discovery: KDD 2015 tutorial. In KDD.
[15] Andrew V Goldberg. 1984. Finding a maximum density subgraph. Technical Report. University of California, Berkeley.
[16] Haiyan Hu, Xifeng Yan, Yu Huang, Jiawei Han, and Xianghong Jasmine Zhou. 2005. Mining coherent dense subgraphs across massive biological networks for functional discovery. Bioinformatics 21 (2005), i213­i221.
[17] Richard M Karp. 1972. Reducibility among combinatorial problems. In Complexity of computer computations. Springer, 85­103.
[18] Yasushi Kawase and Atsushi Miyauchi. 2018. The Densest Subgraph Problem with a Convex/Concave Size Function. Algorithmica (2018).
[19] Samir Khuller and Barna Saha. 2009. On finding dense subgraphs. In International Colloquium on Automata, Languages, and Programming. Springer, 597­608.
[20] Andreas Krause. 2010. SFO: A Toolbox for Submodular Function Optimization. J. Mach. Learn. Res (2010).
[21] Tommaso Lanciano, Francesco Bonchi, and Aristides Gionis. 2020. Explainable Classification of Brain Networks via Contrast Subgraphs. In KDD.
[22] Victor E Lee, Ning Ruan, Ruoming Jin, and Charu Aggarwal. 2010. A survey of algorithms for dense subgraph discovery. In Managing and Mining Graph Data. Springer, 303­336.
[23] Jure Leskovec and Andrej Krevl. 2014. SNAP Datasets: Stanford Large Network Dataset Collection. http://snap.stanford.edu/data. (June 2014).
[24] Fragkiskos D Malliaros, Christos Giatsidis, Apostolos N Papadopoulos, and Michalis Vazirgiannis. 2020. The core decomposition of networks: Theory, algorithms and applications. VLDB (2020).
[25] David W. Matula and Leland L. Beck. 1983. Smallest-Last Ordering and Clustering and Graph Coloring Algorithms. J. ACM (1983).
[26] Robert J Mokken et al. 1979. Cliques, clubs and clans. Qual. Quant (1979). [27] James B. Orlin. 2009. A faster strongly polynomial time algorithm for submodular
function minimization. Math. Program (2009). [28] Jeffrey Pattillo, Alexander Veremyev, Sergiy Butenko, and Vladimir Boginski.
2013. On the maximum quasi-clique problem. Discret. Appl. Math. (2013).

[29] Lu Qin, Rong-Hua Li, Lijun Chang, and Chengqi Zhang. 2015. Locally Densest Subgraph Discovery. In KDD.
[30] Ahmet Erdem Sariyüce and Ali Pinar. 2018. Peeling Bipartite Networks for Dense Subgraph Discovery. In WSDM.
[31] Ahmet Erdem Sariyüce, C. Seshadhri, and Ali Pinar. 2018. Local Algorithms for Hierarchical Dense Subgraph Discovery. VLDB (2018).
[32] Ahmet Erdem Sariyuce, C Seshadhri, Ali Pinar, and Umit V Catalyurek. 2015. Finding the hierarchy of dense subgraphs using nucleus decompositions. In WWW.
[33] Stephen B. Seidman. 1983. Network structure and minimum degree. Social Networks 5, 3 (1983), 269­287.
[34] Stephen B Seidman and Brian L Foster. 1978. A graph-theoretic generalization of the clique concept. Journal of Mathematical sociology 6, 1 (1978), 139­154.
[35] Kijung Shin, Tina Eliassi-Rad, and Christos Faloutsos. 2016. Corescope: Graph mining using k-core analysis--patterns, anomalies and algorithms. In ICDM.
[36] Kijung Shin, Tina Eliassi-Rad, and Christos Faloutsos. 2018. Patterns and anomalies in k-cores of real-world graphs with applications. KAIS (2018).
[37] Mauro Sozio and Aristides Gionis. 2010. The community-search problem and how to plan a successful cocktail party. In KDD.
[38] Amanda L. Traud, Peter J. Mucha, and Mason A. Porter. 2012. Social structure of Facebook networks. Physica A (2012).
[39] Charalampos Tsourakakis. 2015. The k-clique densest subgraph problem. In WWW.
[40] Charalampos Tsourakakis, Francesco Bonchi, Aristides Gionis, Francesco Gullo, and Maria Tsiarli. 2013. Denser than the Densest Subgraph: Extracting Optimal Quasi-Cliques with Quality Guarantees. In KDD.
[41] Charalampos E Tsourakakis, Tianyi Chen, Naonori Kakimura, and Jakub Pachocki. 2019. Novel dense subgraph discovery primitives: Risk aversion and exclusion queries. In ECML PKDD.
[42] Johan Ugander, Lars Backstrom, Cameron Marlow, and Jon Kleinberg. 2012. Structural diversity in social contagion. Proc. Natl. Acad. Sci. U.S.A (2012).
[43] Nate Veldt, David F. Gleich, and Anthony Wirth. 2018. A Correlation Clustering Framework for Community Detection. In WWW.
[44] Nan Wang, Jingbo Zhang, Kian-Lee Tan, and Anthony KH Tung. 2010. On triangulation-based dense neighborhood graph discovery. VLDB (2010).
[45] Hiroki Yanagisawa and Satoshi Hara. 2018. Discounted average degree density metric and new algorithms for the densest subgraph problem. Networks (2018).
[46] Si Zhang, Dawei Zhou, Mehmet Yigit Yildirim, Scott Alcorn, Jingrui He, Hasan Davulcu, and Hanghang Tong. 2017. Hidden: hierarchical dense subgraph detection with application to financial fraud detection. In SDM.
10

A TIGHTNESS OF -GENPEEL
For a graph  = ( , ) and a fixed   1, define

 () = min
 

() +






-

(

-

1)

.

(14)

 N ()

This is the minimum change to the average th power degree of , and mirrors our definition of  () in (13). In order to find examples where the approximation guarantee of GenPeel- is
tight, we would like to find graphs 1 and 2 such that (i) the -mean densest subgraph of  is all of  for   {1, 2}, (ii)  =  (1)/ (2)  ( + 1), and (iii)  (1) <  (2).
If we can satisfy these three requirements, we can build a graph
for which GenPeel- returns an approximation that asymptotically approaches ( + 1). To construct such an example, combine a single copy of 1 with a large number of disjoint copies of 2 to form a new graph . The above properties guarantee that 1 is the maximum -densest subgraph of , but the peeling algorithm will
nevertheless remove all of its nodes before removing any node from
any copy of 2. As long as there are enough copies of 2 (which we can add to  without limit), the maximum -density returned by GenPeel- will be roughly  (2), for an overall approximation of  (2)/ (1) = 1/( + 1).

Specific Graph Construction. Let  be an integer we will choose later and 2 be a clique on ( + 1) nodes. Note that

 (2)

=




+



( 

-

(

-

1) )



(2)

=


.

Next, let 1 = 1 (, ) be a graph parameterized by integers  and  < /2, where  is the number of nodes in 1. For each node , introduce an edge from  to ( + 1), ( + 2), . . .  where  = max{ + , }. This means that most nodes will have degree
2, while nodes close to 1 and close to  will have slightly smaller

degree. Overall, as long as  is large compared to , we will have  (1)  (2) . More precisely, we can calculate that

 (1) =

  =1

(

+



-

1)

+

=+1 (2) +

  =- +1

(

+



-

1)



>

2 1-

(2) .



Importantly,  (1) is nearly the same as  (1), and in fact  (1) converges to  (1) if  is fixed and   . In detail, note that the
minimum degree node is node 1, and so

 +1



 (1)

=




+

( +  - 1) - ( +  - 2) = (2) .

 =2

Next, we need to choose a value of  so that the greedy algorithm

will opt to remove nodes from 1 before removing nodes from one of the copies of 2. This will happen as long as

 (2)

=




+  (

-

(

-

1) )

>

( 2 )

=

 (1).

Choosing  =

2 ( +1) 1/

+1

, we have

  2 + 1 = ( - 1)  (2)

( + 1)1/

 +1

= ( + 1) ( - 1)  (2) =  (1).

By Observation 2, we know that  ( - 1)-1   - ( - 1) , and so
( + 1) ( - 1) =  ( - 1) + ( - 1) <  ( - 1)-1 + 

<  ( - ( - 1) ) +  =  (2).

To compute the asymptotic approximation guarantee for GenPeel, note that  < 2/( + 1)1/ + 2 and so

 (1)

(1 - 2 ) (2)


>

>

2 1-

 (2)





( 2 )
2+2(+1)1/  ( +1) 1/

2 = 1-


( + 1) 1 + (+1)1/ 


Therefore, for any fixed finite   1, if  satisfies  =  () and
1  0, then this overall quantity converges to ( + 1). This means

that asymptotically, the average th power degree of 1 is ( + 1)

times better than the average th power degree of 2, so this is

the best approximation guarantee we can obtain after 1 has been

deleted. The set with the best density considered by GenPeel-

will be the entire graph , since the density will be slightly better

before we delete 1. However, we still have the same asymptotic

approximation guarantee, since we can include  copies of 2 when forming , making  () asymptotically close to  (2). For small

values of  (e.g., integers up to 10), it is not hard to numerically find

examples of graphs with approximation guarantees between  and  + 1, using this type of graph construction.

11

