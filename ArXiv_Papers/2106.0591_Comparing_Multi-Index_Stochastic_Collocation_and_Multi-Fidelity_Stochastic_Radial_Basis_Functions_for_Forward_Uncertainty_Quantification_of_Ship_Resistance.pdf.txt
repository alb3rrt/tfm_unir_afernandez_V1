Comparing Multi-Index Stochastic Collocation and Multi-Fidelity Stochastic Radial Basis Functions for Forward Uncertainty Quantification of
Ship Resistance
Chiara Piazzolaa,, Lorenzo Tamellinia, Riccardo Pellegrinib, Riccardo Brogliab, Andrea Seranib, Matteo Diezb
aConsiglio Nazionale delle Ricerche - Istituto di Matematica Applicata e Tecnologie Informatiche "E. Magenes" (CNR-IMATI), Via Ferrata 5/A, 27100 Pavia, Italy
bConsiglio Nazionale delle Ricerche - Istituto di Ingegneria del Mare (CNR-INM), Via di Vallerano 139, 00128, Roma, Italy

arXiv:2106.00591v1 [math.NA] 1 Jun 2021

Abstract
This paper presents a comparison of two multi-fidelity methods for the forward uncertainty quantification of a naval engineering problem. Specifically, we consider the problem of quantifying the uncertainty of the hydrodynamic resistance of a roll-on/roll-off passengers ferry advancing in calm water and subject to two operational uncertainties (ship speed and payload). The first four statistical moments (mean, variance, skewness, kurtosis), and the probability density function for such quantity of interest (QoI) are computed with two multi-fidelity methods, i.e., the Multi-Index Stochastic Collocation (MISC) method and an adaptive multi-fidelity Stochastic Radial Basis Functions (SRBF) algorithm. The QoI is evaluated via computational fluid dynamics simulations, which are performed with the in-house unsteady Reynolds-Averaged NavierStokes (RANS) multi-grid solver navis. The different fidelities employed by both methods are obtained by stopping the RANS solver at different grid levels of the multi-grid cycle. The performance of both methods are presented and discussed: in a nutshell, the findings suggest that, at least for the current implementations of both algorithms, MISC could be preferred whenever a limited computational budget is available, whereas for a larger computational budget SRBFs seem to be preferable, thanks to its robustness to the numerical noise in the evaluations of the QoI.
Keywords: Uncertainty Quantification, Computational Fluid Dynamics, Finite Volumes, Reynolds-Averaged Navier­Stokes Equations, Multi-Index Stochastic Collocation, Multi-Fidelity Stochastic Radial Basis Functions

1. Introduction
Ship performance depends on design and operational/environmental parameters. The accurate prediction of significant design metrics (such as resistance and powering requirements; seakeeping, maneuverability, and dynamic stability; structural response and failure) requires prime-principles-based high-fidelity computational tools (e.g., computational fluid/structural dynamics, CFD/CSD), especially for innovative configurations and off-design conditions. For instance, in [1, 2, 3] the uncertainty quantification (UQ) of a high-speed catamaran in irregular head waves was performed via both CFD computations and towing-tank experiments, while the application of several UQ methods to an airfoil benchmark problem were discussed in e.g. [4].
High-fidelity tools are, however, generally computationally expensive, making the exploration of the spaces of design and operational parameters, as done e.g. in optimization and UQ, a technological challenge.
In general, there is by now a large consensus in the UQ and computational sciences communities on the fact that large-scale UQ analyses can only be performed by leveraging on multi-fidelity methodologies, i.e., methodologies that explore the bulk of the variability of the quantities of interest (QoI) of the simulation over coarse meshes (or more generally, computationally inexpensive models with e.g. simplified physics), and resort to querying high-fidelity models (e.g., refined meshes or full-physics models) only sparingly, to correct
Corresponding author Email addresses: chiara.piazzola@imati.cnr.it (Chiara Piazzola), tamellini@imati.cnr.it (Lorenzo Tamellini),
riccardo.pellegrini@inm.cnr.it (Riccardo Pellegrini), riccardo.broglia@cnr.it (Riccardo Broglia), andrea.serani@cnr.it (Andrea Serani), matteo.diez@cnr.it (Matteo Diez)

Preprint submitted to Elsevier

June 2, 2021

the initial guess produced with the low-fidelity models, see e.g. [5]. Within this general framework, several approaches can be conceived, depending on the kind of fidelity models considered and on the strategy used to sample the parameter space (i.e., for what values of the uncertain parameters the different fidelity models should be queried/evaluated).
One large class of methods that has received increasing attention in this context is the family of multilevel/multi-index methods, due to its effectiveness and solid mathematical ground. The hierarchy of models considered by these methods is usually obtained by successive (most often ­ but not necessarily ­ dyadic) refinements of a computational mesh. The multi-level/multi-index distinction arises from the number of hyper-parameters that are considered to control the overall discretization of the problem, i.e., how many hyper-parameters are used to determine the computational meshes (e.g. one or multiple size parameters for the mesh elements and/or time-stepping) and the number of samples from the parameters space to be solved on each mesh (e.g. specified by a single number or by a tuple of different numbers along different directions in the parametric space). Combining these considerations with a specific sampling strategy over the parameter space results in the different variations of the method, such as Multi-Level Monte-Carlo [6, 7], Multi-Index Monte Carlo [8], Multi-Level/Multi-Index Quasi-Monte-Carlo [9], Multi-Level Stochastic Collocation [10], Multi-Index Stochastic Collocation [11, 12, 13, 14], Multi-Level Least-Squares polynomial approximation [15], etc. The wording "Stochastic Collocation" is to be understood as a synonym of "sampling in the parametric space": it refers to the fact that the parameters of the problem can be seen as random (stochastic) variables, and sampling the parametric space can be seen as "collocating the approximation problem at points of the stochastic domain". The multi-level/multi-index framework can also be extended to the more generic scenario of Monte-Carlo sampling of multiple fidelities (e.g. combining different physical models), see e.g. [16, 17, 18, 19, 20].
Another widely studied class of multi-fidelity methods employs kernel-based surrogates such as hierarchical kriging [21], co-kriging [22], Gaussian processes [23], and radial-basis functions [24]. Additive, multiplicative, or hybrid correction methods, also known as "bridge functions" or "scaling functions" [25], are used to build multi-fidelity surrogates. Further efficiency of multi-fidelity surrogates is gained using dynamic/adaptive sampling strategies, for which the multi-fidelity design of experiments for the surrogate training is not defined a priori but dynamically updated, exploiting the information that becomes available during the training process. Training points are dynamically added with automatic selection of both their location and the desired fidelity level, with the aim of reducing the computational cost required to properly represent the function [24].
The objective of the present work is to assess and compare the use of two methods, one from each methodological family, for the forward UQ analysis of a naval engineering problem. Specifically, the performances of the Multi-Index Stochastic Collocation (MISC) method and adaptive multi-fidelity Stochastic Radial Basis Functions (SRBF) algorithm are compared on the forward UQ analysis of a roll-on/roll-off passengers (RoPax) ferry sailing in calm water with two operational uncertainties, specifically ship speed and draught, the latter being directly linked to the payload. The estimation of expected value, variance, skewness, kurtosis, and of the probability density function of the hydrodynamic resistance, is presented and discussed. The hydrodynamic resistance for each value of speed and draught requested by MISC and SRBF is computed by the unsteady Reynolds Averaged Navier-Stokes (RANS) equation solver navis [26, 27, 28], developed at CNR-INM. navis embeds a multi-grid approach for iterations acceleration, based on a sequence of grids obtained by derefining an initial fine grid. More specifically, in this work four grids are used, and leveraged by both MISC and SRBF to vary the fidelity of the simulations. Therefore, both MISC and SRBF are used as multi-index methods with only one component controlling the spatial discretization. Another relevant aspect is that navis is an iterative solver, and as such it stops as soon as a suitable norm of the residual drops below a prescribed tolerance: the fact that the RANS equations are not solved at machine-precision introduces in practice some noise in the evaluation of the resistance, which needs to be dealt with during the computations of the UQ indicators (moments, pdf, etc).
The remainder of this paper is organized as follows. Section 2 introduces the general framework and notation for the UQ problem, and the two methodologies considered in this work; in particular, MISC is presented in Section 2.1, while SRBFs are presented in Section 2.2. Section 3 presents the numerical results: an analytical test, see Section 3.2 and then the naval problem, see Section 3.3. Finally, a summary of the findings of the numerical tests and an outlook on future work is presented in Section 4.
A preliminary version of this work is available as proceedings of the AIAA Aviation 2020 Forum, see [29]. With respect to that version, the manuscript was significantly improved in many ways. First, the discussion on MISC is now focused on the construction of the surrogate model rather than on computing statistical
2

moments, and in particular we added some (we believe) interesting considerations about the fact that the MISC surrogate model is not interpolatory, even when using nested points in the parametric space; to the best of the authors' knowledge, this fact was never mentioned in previous literature. Second, the SRBF method applied to the RoPax UQ analysis is now exclusively regressive, instead of starting interpolatory and then becoming regressive when the training set size is larger than a certain threshold. Finally, the numerical results section has been enriched by including an analytical test, by adding a reference solution for the naval problem (which is obtained by a sparse-grid sampling of the highest fidelity at our disposal), and by discussing a possible strategy to mitigate the impact of the RANS noise on the MISC framework.
2. Forward uncertainty quantification methods
Let us assume that we are interested in the outcome of a CFD simulation that depends on the value of one or more random/uncertain parameters, say N parameters collected in the vector y = [y1, y2, . . . , yN ]; we denote by   RN the set of all possible values of y, and by (y) the probability density function (PDF) of y over . The goal of a forward UQ analysis is to compute statistical indicators of the quantity of interest, G, of such CFD simulation, to quantify its variability due to the uncertainties on y. For instance, we might be interested in computing expected values and/or higher-order moments of G (in the numerical tests we will report on mean, variance, skewness, and kurtosis, denoted by E[G], Var[G], Skew[G], and Kurt[G], respectively), and ideally the PDF of G, which completely describes its statistical variability.
This analysis is often performed by a sampling approach, i.e., the CFD simulation is run for several possible values of y, and the corresponding results are post-processed to get the indicators of interest. For instance, the statistical moments can be approximated by weighted averages of the values obtained, while the PDF can be approximated by histograms or e.g. kernel density methods [30, 31]. Clearly, these analyses require large datasets of evaluations of G: if computing a single instance of G requires a significant amount of computational time, obtaining the dataset can become prohibitively expensive. A possible workaround is then to replace the evaluations of G with the evaluations of a surrogate model, which is ideally a good approximation of the original G, cheap to evaluate and obtained by suitably combining together a relative small number of evaluations of G (less than what would be needed to perform the UQ analysis of the full model). The two methods that we consider in this work and that we illustrate next are both methods to construct such surrogate model, and in particular they leverage the fact that CFD simulations can be performed over multiple mesh resolutions to further reduce the computational costs.
Before describing in the details each method, we need to introduce some notation. To this end, let us assume that the computational domain of our CFD simulation can be discretized by a mesh with non-cubic hexahedral elements of the same size1 and let us also assume for a moment that the level of refinement of the mesh along each physical direction can be specified by prescribing some integer values 1, 2, 3; to fix ideas, one can think e.g. that the size of each element of the mesh scales as 2-1 × 2-2 × 2-3 , but this is not necessary. The three values of i are collected in a multi-index  = [1, 2, 3]; prescribing the multi-index  thus prescribes the computational mesh to be generated. If this flexibility is not allowed by the mesh-generator (or by the problem itself), it is possible to set 1 = 2 = 3 = , i.e., controlling the mesh-generation by a single integer value  (this is actually the case for the RoPax ferry example considered in this work). The same philosophy applies both to single- and multi-patch meshes, where in principle there could be up to three values i for each patch. In general, we assume that  has d components,   Nd+. The QoI of the CFD simulation computed over the mesh specified by  is denoted by G; this could be e.g. the full velocity field or a scalar quantity associated to it.
2.1. Multi-Index Stochastic Collocation (MISC)
In this section, the MISC method is introduced. As already mentioned, the MISC method is a multi-fidelity method that falls under the umbrella of multi-index/multi-level methods: in particular, the single-fidelity models upon which MISC is built are global Lagrangian interpolants over .
2.1.1. Tensorized Lagrangian interpolant operators The first step to derive the MISC surrogate model is to select a sequence of collocation points for each
uncertain parameter yn, i.e., for each direction of n of . For computational efficiency, these points should
1The assumption that all elements must be of the same size can be relaxed, but it is kept for simplicity of exposition
3

be chosen according to (y), and they should be of nested type (i.e., collocation grids of increasing refinement should be subset of one another). In the RoPax ferry example considered in this work, the uncertain parameters y can be modeled as uniform and independent random variables (see Sect. 3.3) for which we choose to employ Clenshaw­Curtis (CC) points, see e.g. [32]. A set of K univariate CC points can be obtained as

t(Kj) = cos

(j - 1) K -1

,

1  j  K,

(1)

and two sets of CC points with K1 and K2 points are nested if (K2 - 1)/(K1 - 1) = 2 for some integer , see also below. Other nested alternatives for uniformly distributed parameters are Leja points [33, 34] and Gauss­Patterson points [35]. Next, we introduce the function

m(0) = 0, m(1) = 1, m(n) = 2n-1 + 1 for n  2,

(2)

and denote by Tn,n the set of m(n) CC points along yn, i.e.

Tn,n = yn(j,nm)(n) : jn = 1, . . . , m(n)

for n = 1, . . . , N.

Note that this choice of m guarantees nestedness of two sets of CC points, i.e., Tn,  Tn, if   .

An N -dimensional interpolation grid can then obtained by taking the Cartesian product of the N uni-

variate sets just introduced. The number of collocation points in this grid is specified by a multi-index

  NN+ : such multi-index plays thus a similar role for parametric domain  as the multi-index  for the

physical domain. We denote such tensor interpolation grid by T =

N n=1

Tn,n

and

its

number

of

points

by

M =

N n=1

m(n

):

using

standard

multi-index

notation,

they

can

be

written

as

T =

ym(j)()

,
jm()

with

ym(j)() = y1(j,m1)(1), . . . , yN(j,Nm)(N ) ,

where m() = [m(1), m(2), . . . , m(N )] and j  m() means that jn  m(n) for every n = 1, . . . , N . For fixed , the approximation of G(y) based on global Lagrangian polynomials collocated at these grid points (single-fidelity approximation) has the following form

G(y)  U,(y) :=

G ym(j)() L(mj)()(y),

(3)

jm()

where

L(mj)()(y)

are N -variate Lagrange basis polynomials, defined as tensor products of univariate
jm()

Lagrange polynomials, i.e.

N

L(mj)()(y) =

ln(j,nm)(n)(yn)

n=1

with

ln(j,nm)(n)(yn)

=

m(n ) k=1,k=jn

yn - yn(k,m) (n)

.

yn(k,m) (n) - yn(j,nm)(n)

(4)

Naturally, the single-fidelity approximation U, is more and more accurate the higher the number of collocations points in each direction. Hence, ideally one would choose both multi-indices  and  with large components, say  =  and  =  , i.e., to consider many CFD simulations over a refined computational mesh; however, this is typically infeasible due to the computational costs of a single CFD simulation.

2.1.2. MISC surrogate model
The above discussion on the costs of U , motivates the introduction of MISC. MISC is a multi-fidelity approximation that replaces U , with a linear combination of multiple coarser U,: as will be clearer later, the components of such linear combination are chosen obeying to the idea that whenever the spatial discretization  is refined, the order of the interpolation  is kept to a minimum and vice versa
To build a MISC approximation, the so-called "detail operators" (univariate and multivariate) on the physical and parametric domains have to be introduced. They are defined as follows, with the understanding that U,(y) = 0 when at least one component of  or  is zero. In the following the dependence of the interpolation operator on the parameters y is omitted for sake of compactness. Thus, we denote by ei the

4

canonical multi-index, i.e. (ei)k = 1 if i = k and 0 otherwise, and define

Univariate physical detail: Univariate parametric detail:

pi hys[U,] = U, - U-ei, with 1  i  d; pi aram[U,] = U, - U,-ei with 1  i  N ;

Multivariate physical detail:

d

phys[U,] =

pi hys[U,];

i=1

N
Multivariate parametric detail: param[U,] = pj aram[U,];
j=1

Mixed multivariate detail:

mix[U,] = param phys[U,] .

Observe that taking tensor products of univariate details amounts to composing their actions, i.e.

d

phys[U,] =

pi hys[U,] = p1hys · · · pdhys [U,] ,

i=1

and analogously for the multivariate parametric detail operators, param[U,]. By replacing the univariate details with their definitions, we can then see that this implies that the multivariate operators can be evaluated by evaluating certain full-tensor approximations U, introduced in the previous subsection, and then taking linear combinations:

phys[U,] = p1hys · · · pdhys [U,]

param[U,] =

(-1) j 1 U,-j.

j{0,1}N

=

(-1) j 1 U-j,;

j{0,1}d

The latter expressions are known as "combination-technique" formulations, and can be very useful for practical implementations. In particular, they allow to evaluate e.g. phys[U,] by calling pre-existing softwares on different meshes up to 2d times in a "black-box" fashion. Analogously, evaluating param[U,] requires evaluating up to 2N operators U, over different interpolation grids, and evaluating mix[U,] requires evaluating up to 2d+N operators U, over different parametric grids and physical meshes. Observe that by
introducing these detail operators a hierarchical decomposition of U, can be obtained; indeed, the following
telescopic identity holds true:

U, =

mix[Ui,j].

(5)

[i,j][,]

As an example, the case of d = N = 1 (i.e., one-dimensional physical and parametric spaces) can be considered. Recalling that by definition Ui,j = 0 when either i = 0 or j = 0, it can be seen that

mix[Ui,j ] = mix[U1,1] + mix[U1,2] + mix[U2,1] + mix[U2,2]
[i,j][2,2]
= U1,1 + (U1,2 - U1,1) + (U2,1 - U1,1) + (U2,2 - U2,1 - U1,2 + U1,1) = U2,2.

The crucial observation is that, under suitable regularity assumptions for G(y) (see e.g. [13, 14]), not all of

the details in the hierarchical decomposition in Eq. (5) contribute equally to the approximation, i.e., some of

them can be discarded and the resulting formula will retain good approximation properties at a fraction of

the computational cost (roughly, the multi-indices to be discarded are those corresponding to "high-order"

details, i.e., those for which  1 +  1 is sufficiently large). Upon collecting the multi-indices [, ] to

be

retained

in

the

sum

in

a

multi-index

set





d+N
N+

,

the

MISC

multi-fidelity

approximation

of

G

can

be

introduced as

G(y)  S(y) :=

mix [U, (y)],

(6)

[,]

To obtain a meaningful expression,  should be chosen as downward closed, i.e. (see Fig. 1a)

k  , k - ej   for every j = 1, . . . , d + N such that kj > 1.

5

(a)

(b)

Figure 1: Multi-index sets for the construction of the MISC approximation. (a): the gray set is downward closed, whereas adding the blue multi-index to it would result in a set not downward closed; (b): a downward closed set (in gray) and its margin (indices marked in red and blue). If Algorithm 1 reaches the gray set, it will next explore all indices marked in red (their addition to the gray set keeps the downward closedness property) but not those marked in blue. The red set is also known as "reduced margin".

Clearly, the MISC formula in Eq. (6) has a combination-technique expression as well, which can be written in compact form as

S(y) =

mix[U,(y)] =

(-1) [i,j] 1 U,(y).

(7)

[,]

[,] [i,j]{0,1}d+N [+i,+j]

This is the approximation formula which is used in our practical implementation of the MISC method, which shows our initial statement that the MISC evaluation is computed by evaluating full-tensor interpolation operators U, independently and combining them linearly, as specified by Eq. (7). Before going further, we remark a few important points:
1. The effectiveness of the MISC approximation depends on the choice of the multi-index set . The optimal choice of  depends on the above-mentioned regularity assumptions on G(y): in general, the result will be a method akin to classical multi-level schemes such as Multi-Level Monte Carlo, where most of the statistical variability of the QoI is explored by solving many CFD simulations with coarse meshes (large  1 with small  1) and then the result is corrected with a few CFD simulations with refined meshes (large  1 with small  1). A practical adaptive algorithm to construct  is presented in Sect. 2.1.4, following the discussion in e.g. [12]. Another option is to design  a-priori, by a careful analysis of the PDE at hand, see e.g. [11, 13, 14].
2. MISC works well only if the levels are sufficiently separated, i.e. if the number of degrees of freedom of the computational mesh (and the corresponding computational cost) grows significantly from one level to the next one: to fix ideas again, things will work well if the number of elements in the mesh scales e.g. as 21 × 22 × 23 , but not if e.g. increasing 1 to 1 + 1 adds only one element to the mesh. If this separation does not hold, the cost of computing all the components in Eq. (7) would exceed the cost of the construction of a highly-refined single-fidelity surrogate model U , .
3. The MISC surrogate model S(y) is not interpolatory, even though nested nodes are used in the parametric space. To illustrate this, let us consider as an example the case d = 1, N = 2, with  = [-1, 1]2. We construct the MISC approximation based on the multi-index set  = {[1, 1 1], [1, 2 1], [2, 1 1]}: formula (7) results in S(y) = -U[1,1 1](y) + U[2,1 1](y) + U[1,2 1](y),
where the first and the second operators are constant interpolants ( = [1 1]) whose value is equal to the first and second fidelity evaluated at the center of the parametric domain, y(C) = [0, 0], respectively; the third operator is instead is an interpolant of degree two based on the value of the first fidelity evaluated at the following three CC bivariate points: y(L) = [-1, 0], y(C) = [0, 0], and y(R) = [1, 0]. Then, evaluating the MISC approximation at e.g. y(R) results in

S(y(R)) = -G1(y(C)) + G2(y(C)) + G1(y(R)) = G1(y(R)),

6

i.e. the value of S at y(R) is different from the only model evaluation available at such point (which is G1(y(R))). This is in contrast with the well-known property of single-fidelity sparse-grid surrogate
models, for which the use of nested nodes over  guarantees that S(ySG) = G(ySG) at the sparse-grid
points ySG.

2.1.3. MISC quadrature By taking the integral of the MISC surrogate model defined in Eq. (7) it is straightforward to obtain a
quadrature formula R to approximate the expected value of G:

E[G]  E[S] =: R = S(y)(y) dy =

(-1) [i,j] 1 U,(y)(y) dy.



[,] [i,j]{0,1}d+N



[+i,+j]

By recalling the definitions of U, given in Eq. (3) and of the multivariate Lagrange polynomials in Eq. (4), each of the integrals at the right-hand side of the previous formula can be rewritten in compact form as tensor quadrature operators, i.e.

Q, := U,(y)(y) dy =

G ym(j)()



jm()

=

G ym(j)()

jm()

N
ln(j,nm)(n)(yn)(yn) dyn
n=1 n

N
n(j,nm)(n )
i=1

=

G ym(j)() m(j)(),

jm()

where n(j,nm)(n), are the standard quadrature weights obtained by computing the integrals of the associated univariate Lagrange polynomials (available as analytical or tabulated values for most families of collocation

points), and m(j)() are their multivariate counterparts. The quadrature formula R can then be understood as a linear combination of tensor quadrature operators, in complete analogy with the MISC surrogate model

construction:

R =

(-1) [i,j] 1 Q,.

(8)

[,] [i,j]{0,1}d+N [+i,+j]

Equivalently, one can also write

R =

mix [Q, ],

[,]

where the definition of mix[Q,] can be easily deduced by replacing the interpolation operators with quadrature operators in the definition of the detail operators given earlier in this section. Clearly, formula (8) easily generalizes to the computation of higher-order moments:

M

E[Gr] 

(-1) [i,j] 1

Gr ym(j)() m(j)().

(9)

[,] [i,j]{0,1}d+N

k=1

[+i,+j]

However, this formula might not be the most effective approach to approximate E[Gr], especially in case of noisy evaluations of G; this aspect is discussed in more detail in Sect. 3.3.2.
We close the discussion on the MISC quadrature by remarking that the collocation points have a twofold use, i.e., they are both interpolation and quadrature points. This aspect significantly differentiates the MISC method from the approach based on radial basis functions presented in Sect. 2.2, where two distinct sets of points are considered: one for constructing a surrogate models ("training points"), and one for obtaining sample values of the surrogate models and deriving an estimate of expected value and higher moments of G ("quadrature points").

2.1.4. An adaptive algorithm for the multi-index set  As already mentioned, the effectiveness of the MISC approximation depends on the choice of the multi-
index set : in this work such set is built with an adaptive algorithm, see [12]. We begin by introducing the

7

following decomposition of the quadrature error

|E[G] - R| = E[G] -

mix [Q, ]

[,]

=

mix[Q,] 

mix[Q,] =

ER, ,

[,]

[,]

[,]

where ER, := mix[Q,] . ER, thus represents the "error contribution" of [, ], i.e., the reduction in

the quadrature error due to having added [, ] to the current index-set . In practice, ER, can be more

conveniently computed by

ER, = |R[,] - R|;

(10)

for any  downward-closed such that   [, ] is also downward-closed. A similar quadrature-based error contribution is considered in [12], where a convex combination of the error in the computation of the mean and of the variance of the quantity of interest is used. Another possibility is to introduce an error decomposition based on the point-wise accuracy of the surrogate model, following the same arguments above. The "error contribution" of [, ] is then taken as

ES, =

S[,] - S

L



max
yH

S[,](y) - S(y)

,

(11)

where H   is a suitable set of "testing points". Note that a similar criterion has been proposed also in the context of sparse grid methods: different choices of H can be considered, depending whether nested or non-nested points are used (cf. e.g. [36, 37] and [38], respectively). In this work we consider a set of 10000 random points (note that this operation is not expensive since it does not require evaluations of the full model).
Similarly to the "error contribution", the "work contribution" W, of [, ] is defined as the work required to add [, ] to the current index-set . It is the product of the computational cost associated to the spatial grid identified by the multi-index , denoted by cost() (see details in Sect. 3.3.1, Eq. (27)), times the number of new evaluations of the PDE required by the multi-index , i.e.

N

W, = cost() (m(n) - m(n - 1)),

(12)

n=1

with m defined as in Eq. (2). Note that the expression above is based on the fact that the collocation points

used here are nested.

An effective strategy to build adaptively a MISC approximation can then be broadly described as follows:

given the MISC approximation associated to a multi-index set , a new MISC approximation is obtained by

adding

to



the

multi-index

[, ]





with

the

largest

profit

PF,

=

, EF,
W,

with

F

=

S, R

depending

on

the selected error metric, such that   {[, ]} is downward closed. In practice the implementation reported

in Algorithm 1 is used: it makes use of an auxiliary multi-index set, i.e. the margin of a multi-index set

, Mar(), which is defined as the set of multi-indices that can be reached "within one step" from  (see

Fig. 1b)

Mar() = {i  Nd+N s.t. i = j + ek for some j   and some k  {1, . . . , d + N }}.

This algorithm was first proposed in the context of sparse-grids quadrature in [39] and its MISC implementa-
tion was first proposed in [12]. It is an a-posteriori algorithm and as such it determines the error contribution EF, of [, ] after having added [, ] to the grid. Therefore, at the end of the algorithm we do not have S, but actually SJ , where J is the set of all indices whose profit has been computed, and clearly   J: the richer approximation SJ is thus actually returned in practical implementations instead of S. Finally, note that many stopping criteria can be considered (and possibly used simultaneously), which typically check that
computational work, error contributions or profit estimator are below a desired threshold.

2.2. Adaptive multi-fidelity Stochastic Radial Basis Functions (SRBF)
In this section each of the components of the adaptive multi-fidelity SRBF surrogate model are discussed. In particular, we emphasize that here the word "stochastic" denotes not only the fact that we are sampling parameters that are affected by uncertainty, but also to the fact that the SRBF method treats one of its hyper-parameters as a random variable, as will be clear later on.

8

Algorithm 1: MISC implementation

Multi-Index Stochastic Collocation

 = {[1, 1]};

J = {[1, 1]};

// set of multi-indices whose profit has been computed,   J

L = ;

// set of candidate multi-indices to be added to 

Compute MISC estimate SJ as in Eq. (7); while stopping criteria are not met do

for j  Mar() and   {j} downward closed do

// for short, j = [, ]

if j  J then

Compute MISC estimate SJ{j} as in (7); Compute error contribution EjR (or EjS ) as in Eq. (10) (or Eq. (11)); Compute work contribution Wj as in Eq. (12); Compute profit PjS = EjS /Wj (or PjR = EjR/Wj); J = J  {j};

L = L  {j};

end

end

Choose i  L with the highest profit;

 =   {i};

L = L \ {i};

end

end

return , J, SJ

2.2.1. SRBF surrogate model
Given a training set T = {(yi, G(yi))}Ji=1 and normalizing the uncertain parameters domain into a unit hypercube, the RBF prediction is (here) based on a power function kernel and reads

K

f (y,  ) = wj||y - cj|| ,

(13)

j=1

where wj are unknown coefficients, cj are K points in  called RBF centers, and   unif[min, max] is a stochastic tuning parameter that follows a uniform distribution. RBF models have been widely applied in engineering problems using both linear kernels ( = 1, providing a polyharmonic spline of first order [40]) and cubic ones ( = 3, providing a polyharmonic spline of third order [41]). This suggests the range of  to be defined within min = 1 and max = 3. Note that the choice of the distribution for  is arbitrary and, from a Bayesian viewpoint, this represents the degree of belief in the definition of the tuning parameter. The SRBF surrogate model F (y) is computed as the expected value (approximated by Monte Carlo) of f over  [42]:

1

G(y)  F (y) = E [f (y,  )]   f (y, i) ,

(14)

i=1

where  is the number of samples for  , here set equal to 1000. To give more flexibility to the method,
the coordinates of the RBF centers cj are not a-priori set to be coincident with the training points, but rather chosen by a k-means clustering algorithm applied to the training points, see [43]. Several values of the number of centers K are tested and their optimal number K is chosen by minimizing a leave-one-out
cross-validation (LOOCV) metric, see [44]. In details, letting gi,K(y), i = 1, . . . , J be the surrogate models with K centers trained on the whole training set T but the i-th point, K is defined as:

K = argmin RMSE(K),

(15)

KC

9

Figure 2: SRBF example with least-squares regression.

where C  N and RMSE(K) is the root mean square error of the J leave-one-out models g1,K, . . . , gJ ,K at the point that is being left out for each gi,K:

RMSE(K) =

1 J

J

(G(yi) - gi,K(yi))2,

yj  T .

(16)

i=1

Clearly, once the optimal number of centers K is chosen, the whole set of points is used for the construction of the final surrogate model. Whenever the number of RBF centers is lower than the training set size (K < J ), the coefficients wj in Eq. (13) are determined through a least-squares regression by solving

w = ATA -1 ATb,

(17)

with w = [w1, . . . , wK]T, Aij = ||yi -cj|| and b = [G(y1), . . . , G(yJ )]T; otherwise when the optimal number of RBF centers equals the training set size, exact interpolation at the training points (f (yi,  ) = G(yi)) is

imposed and Eq. (17) reduces to

Aw = b,

(18)

with cj = yj. Having less RBF centers than training points and employing the least-squares approximation in Eq. (17) to determine the coefficients wj is particularly helpful when the training data are affected by noise. An example of least-squares regression is shown in Fig. 2.
The uncertainty UF (y) associated with the SRBF surrogate model prediction is quantified by the 95%confidence band of the cumulative density function (CDF) of f (y,  ) with respect to  for fixed y as follows

UF (y) = CDF-1(0.975; y) - CDF-1(0.025; y),

(19)

with

1

CDF(; y)  

H[ - f (y, i)],

i=1

where H(·) is the Heaviside step function.

2.2.2. Multi-fidelity approach
In this section we restrict to the case of the CFD mesh generation being controlled by a scalar value , i.e., the QoI computed with the -th grid is denoted by G,  = 1, . . . , M . The multi-fidelity approximation of G, introduced in [45] and extended to noisy data in [46], is then adaptively built as follows. Extending the definition of the surrogate model training set to an arbitrary number of M fidelity levels as {T}M =1, with each T = {(yj, G(yj))}Jj=1, the multi-fidelity approximation S(y) of G(y) reads

-1

S(y) := F1(y) + i(y),

(20)

i=1

where F1 is the single-fidelity surrogate model associated to the lowest-fidelity training set (constructed as in Eq. (14)), and i(y) is the inter-level error surrogate with associated training set Ei = {(y, Gi+1(y) - Fi(y)) | y  Ti+1  Ti}. It can be noted that Eq. (20) does not strictly require nested training sets. An example of the multi-fidelity approximation with two fidelities is shown in Fig. 3.

10

Figure 3: Example of multi-fidelity surrogate with M = 2 and exact interpolation at the training points.

Assuming that the uncertainty associated to the prediction of the lowest-fidelity UF1 and inter-level errors U i as uncorrelated, the multi-fidelity approximation SM (y) of G(y) and its uncertainty USM read

M -1

M -1

G(y)  SM (y) = F1(y) +

i(y) and USM (y) = UF21 (y) +

U 2 (y). i

i=1

i=1

(21)

2.2.3. Adaptive sampling approach
Upon having evaluated USM the multi-fidelity surrogate is then updated adding a new training point following a two-steps procedure: firstly, the coordinates of the new training point y are identified based on the SRBF maximum uncertainty, see [24], solving the maximization problem:

y = argmax[USM (y)].

(22)

y

An example (with one fidelity only) is shown in Fig. 4. Secondly, once y is identified, the training set/sets to be updated with the new training point {(y , G(y ))} are T with  = 1, . . . , k, where k is defined as

k = maxloc [U(y )] and U(y )  {UF1 (y )/1, U 1 (y )/2, ..., U M-1 (y )/M },

(23)

with  being the computational cost associated to the -th level. In the present work, the adaptive sampling procedure starts with five training points (for each fidelity
level) located at the domain center and at the centers of each boundary of . Furthermore, to avoid abrupt
changes in the SRBF prediction from one iteration to the next one, the search for the optimal number of centers for the -th fidelity K can be constrained. Herein, at every adaptive sampling iteration, the problem in Eq. (15) is solved assuming K to be either equal to the number of centers at the previous iteration or incremented by 1, i.e. C = [K,t-1, K,t-1 + 1], except for the first iteration where no constraint is imposed.
A deterministic version of the particle swarm optimization algorithm [47] is used for the solution of the
optimization problem in Eq. (22).

(a)

(b)

Figure 4: Example of the adaptive sampling method using one fidelity without noise: (a) shows the initial SRBF with the associated prediction uncertainty and training set; (b) shows the position of the new training point, the new SRBF prediction, and its uncertainty.

11

Algorithm 2: Adaptive multi-fidelity SRBF implementation

Multi-Fidelity SRBF for numerical quadrature Define the initial training sets {T}M =1, with T = {(yj, G(yj))}Jj=01 ;
t=1;

for  = 1, . . . , M do Find K,1 as in Eq. (15) with C = [1, J0] ;
end

// initialize the number of RBF centers

while stopping criteria are not met do

// t-th iteration of the adaptive sampling

for  = 1, . . . , M do Find K,t as in Eq. (15) with C = [K,t-1, K,t-1 + 1] ;
end

Construct the SRBF surrogate F1(y) as in Eq. (14) ;

// low-fidelity approximation

Compute the prediction uncertainty UF1 (y) as in Eq. (19) ;

for  = 2, . . . , M - 1 do

// evaluate surrogates of the inter-level errors

Compute the inter-level errors ;

Construct the SRBF surrogates of the inter-level errors  as in Eq. (14) ; Compute the prediction uncertainty U  as in Eq. (19) ; end

Construct the multi-fidelity approximation SM (y) as in Eq. (21) ; // MF approximation

Compute the multi-fidelity prediction uncertainty USM as in Eq. (21) ;

for j = 1, . . . , p do

// perform parallel infill

Find y = argmax[USM (y)] ;
y

Find kj = maxloc [U(y )] as in Eq. (23) ; Update the training sets {T}kj=1  { yj , S(yj ) }kj=1 ; // consider exact prediction Update the training sets size {Jt+j }kj=1 = {Jt}kj=1 + 1 ;
end

for j = 1, . . . , p do
Evaluate {yj , G(yj )}kj=1 ; Update the training sets {T}kj=1  {(y , G(y ))}kj=1; Update the training sets size {Jt+j }kj=1 = {Jt}kj=1 + 1;
end

// perform new simulations

t=t+1 ;

// move to the next adaptive sampling iteration

end

end

The adaptive sampling is therefore inherently sequential (the uncertainty changes every time a new point is added), but this is sub-optimal whenever the numerical simulations can be performed with an hardware capable of running p simulations simultaneously. In this case, it would be ideal to identify p training points where the models G can be run in parallel, instead of running them one after the other. To this end, we follow a parallel-infill procedure, i.e. we perform p "guessing steps": the adaptive sampling procedure is repeated p times replacing the evaluations of the actual model G with the evaluations of the multi-fidelity models S. This replacement significantly speeds up the p steps, since the true models G are not evaluated at this stage. Upon doing these p guessing steps, the actual G are evaluated all at once (i.e. in parallel) at the p training points just obtained and these evaluations replace the corresponding multi-fidelity evaluations in the training set.
Finally, numerical quadrature is used on the SRBF surrogate model to estimate the statistical moments of the QoI. The approximation is performed with sparse-grid quadrature rules [39] with samples selected according to Eq. (1) with K = 215 + 1. The calculations have been done using the Sparse Grids Matlab Kit2 [48], which is developed by some of the authors of this manuscript.
2https://sites.google.com/view/sparse-grids-kit

12

3. Numerical tests
In this section two numerical tests are considered. First, the performances of the MISC and SRBF method are compared on an analytical test, and then the main problem of this work, i.e., the RoPax ferry problem mentioned in the introduction, is discussed. In the analytic example, Taylor expansions of increasing order are considered as different fidelities to be employed, while in the RoPax problem the fidelities are obtained by using different grid refinements, as will be clearer later. Both problems consider uniformly distributed uncertain parameters. Before entering the detailed discussion of the two tests, an overview of the error metrics used to carry out the comparison is given in the following.

3.1. Error metrics
The performance of MISC and SRBF are assessed by comparing the convergence of both methods to a reference solution according to several error metrics, listed below. The specific choice of the reference solution for each test will be detailed in the corresponding sections and below is denoted by Gref. In the list below, we will use the symbol S for both the MISC and SRBF surrogate models for sake of compactness, i.e. S = S for MISC (cf. Eq. (7)) and S = SM for SRBF (cf. Eq. (21)).
1. Normalized difference between the first four centered moments (mean, variance, skewness, kurtosis) of the MISC/SRBF approximations and those of the reference solution:

erri

=

|Momi[S] - Momi[Gref]| , |Momi[Gref]|

i = 1, . . . , 4,

(24)

where Momi[S] denotes the MISC/SRBF approximation of the i-th centered moment (computed by the quadrature rule associated to MISC/SRBF) and Momi[Gref] the approximation of the i-th centered moment of the reference solution computed by a suitable quadrature rule (more details will be given later).
2. Normalized discrete L2 and L norm of the difference between the MISC/SRBF surrogates and the reference solution, i.e., sample mean square error and largest point-wise prediction error, respectively; the differences are evaluated at a set of n = 10000 random points y  . In formulas,

errL2 =

1 n

n i=1

[S (yi )

-

Gref(yi)]2

,

1 n

n i=1

Gref

(yi

)2

errL

=

maxi=1,...,n (|S(yi) - Gref(yi)|) . maxi=1,...,n Gref(yi)

(25)

3. A visual comparison of the PDFs obtained by Matlab's ksdensity function, using again as input the 10000 points used before.

4. Convergence of the CDF approximated by MISC/SRBF to the CDF of the reference solution, as

measured by the Kolmogorov­Smirnov (KS) test statistic. In details, we evaluate an approximation of

the quantity

T = sup |CDFS (t) - CDFGref (t)|,

(26)

trange[S ,Gref ]

where range[S, Gref] is the largest common range of values taken by S and Gref, CDFS and CDFGref are the empirical CDFs obtained by the set used before of 10000 random samples of the MISC/SRBF surrogate models and reference model, respectively. We then check that T converges to zero as the surrogate models get more and more accurate. The values of T reported in the next sections are obtained with the Matlab's kstest2 function.

3.2. Analytical problem
3.2.1. Formulation As analytical test, a two-dimensional function is chosen. This function is designed to be representative
of the RoPax problem: the input parameters y are independent and have a uniform distribution, and the function is non-linear, non-polynomial and monotonic. In details, the function is defined as

G(y) = G(y1, y2) = sin

exp(y1 + y2) 5

,

13

(a) True function

(b) Highest-fidelity function G6(y) (c) Lowest-fidelity function G1(y)

Figure 5: Analytical problem, true function and highest- and lowest-fidelity approximations.

with y  [0, 1]2 . To provide a range of fidelities G(y) for G(y), Taylor expansions of G(y) of order  are performed for  = 1, . . . , 6 in the neighborhood of y = (0, 0). The sixth-order Taylor expansion G6(y) is then considered as the highest-fidelity and the first order G1(y) as the lowest-fidelity. Figure 5 shows the true function G(y) and the approximations G6(y) and G1(y). The sixth order Taylor expansion is almost indistinguishable from the true function whereas the low-fidelity function is significantly different and does not show any change in curvature.
A normalized computational cost is associated to each evaluation of the -th Taylor expansion G(y) as
cost() = 8-1.
This choice is done to keep the analogy with the RoPax problem and will become clear later.
3.2.2. Numerical results We start the discussion with the comparison of the MISC/SRBF estimates of the moments with the
reference values. The reference values are computed by an accurate sparse-grids quadrature rule with 215 + 1 points where the reference surrogate model/function Gref(y) is the highest-fidelity approximation G6(y).
In Fig. 6 the convergence of the MISC estimates of the first four centered moments and their relative errors as defined in Eq. (24) are reported. The two variants of MISC introduced in Sect. 2.1 are tested, i.e. two type of profits, P R based on the quadrature error (see Eq. (10)) and P S based on the point-wise accuracy of the surrogate model (see Eq. (11)), are considered. The results for the case of a quadrature-based profit P R are displayed in the first set of plots (see Fig. 6a-left). All the moments converge to the reference results marked with the black dashed line. In Fig. 6a-right one can observe that the error is larger the higher the order of the moment. Remarkably, even if the adaptivity of the MISC algorithm is driven by the improvement in the first order moment, all the moments are estimated very well. The second set of plots (see Fig. 6b) suggests that also the version of MISC driven by the accuracy of the surrogate model P S is effective in the estimation of the moments. By comparing the two methods, one can observe that the latter one brings better results, as the error for all the moments is about two order of magnitude smaller.
Similar observations can be done also for SRBF, whose results for the convergence of the moments are shown in Fig. 7: all moments converge towards their reference values, and the errors are lower for lower-order moments, with the only exception of the variance. Note that for this problem the SRBF method is based on interpolation at the training points (i.e. the weights are computed by solving Eq. (18)), whereas in the following RoPax example the regressive approach (i.e. solving (17)) is used, for reasons that will be clear later on.
The adaptive sampling procedure used by SRBF requires the inversion of a matrix whose size increases at each iteration, since the size of the training set is increasing at each iteration as well. In particular, if low fidelities are mainly used, the computational budget is fractionated into several intermediate steps, each of which increases the training set size: thus we quickly end up with a large training set, and therefore it becomes more and more expensive in terms of CPU time to perform the operations requested to build the multi-fidelity surrogate model (computation of the weights of the SRBF and adaptive sampling procedure). Thus, while the computational cost reported in the plots considers only the cost of evaluating the different fidelities, there is also a "hidden computational cost" proportional to the CPU time, which grows faster for

14

(a) Results for the MISC method with profit P R
(b) Results for the MISC method with profit P S . The results for the MISC method with profit P R are displayed in grey in the plot on right for ease of comparison. Figure 6: Analytical problem, results for the MISC method. Left: convergence of the values of the first four centered moments. The black dashed line marks the reference value of the moments. Right: relative error of the moments (see Eq. (24)).
Figure 7: Analytical problem, results for the SRBF method. Left: convergence of the values of the first four centered moments. The black dashed line marks the reference value of the moments. Right: relative error of the moments (see Eq. (24)).
15

Figure 8: Analytical problem, comparison of MISC and SRBF methods: relative errors of the moments. It is a compact visualization of the results of Fig. 6 and 7, where the results of MISC are reported only until a computational cost comparable with the one reached by the SRBF method.
(a) Convergence over the full range of available computational costs.
(b) Zoom in the range of comparable computational costs of MISC and SRBF. Figure 9: Analytical problem, comparison of MISC and SRBF methods: relative error of the approximation G in L2 (left) and L norm (right) (see Eq. (25)).
SRBF than for MISC (whose hidden CPU costs are instead related to the update of the multi-index set and the evaluation of multivariate Lagrange polynomials). This explains why in Fig. 6 and 7 the results of MISC and SRBF are reported for different ranges of computational cost. Figure 8 shows the convergence of the relative errors of the two methods for the centered moments at a comparable computational cost. In such window of costs, MISC and SRBF methods achieve comparable results. Specifically, MISC-P S performs slightly better in the evaluation of E[G], whereas SRBF performs slightly better in the evaluation of Var[G] and Kurt[G]. It is also worth noting that SRBF starts with an already significant computational cost in comparison with MISC, due to the fact that the initialization strategy requires to sample all available fidelities.
The results for the L2 and L norms of the MISC error (see Eq. (25)) of Fig. 9a are in agreement with the previous findings for the estimation of the moments. An improvement of about two orders of magnitude is observed in favor of the surrogate-based method MISC-P S with respect to MISC-P R. When comparing these results with the convergence of the SRBF one can observe that both methods reach similar accuracy within the range of comparable computational costs, see Fig. 9b.
The comparison of the PDFs given in Fig. 10a shows a very good agreement of the MISC and SRBF results with the reference ones. In Fig. 10b the results of the KS test statistics (cf. Eq. (26)) are reported:
16

(a) PDFs at the final iteration (obtained by Matlab's ksdensity enforcing positive support since G takes positive values only)

(b) KS test statistic (see Eq. (26))

Figure 10: Analytical problem, comparison of MISC and SRBF methods.

(a) MISC with profit P S

(b) SRBF

Figure 11: Analytical problem, results for the MISC and SRBF method. Sampling points at the last iteration.

the MISC-P S shows a slightly better convergence of the test statistic. Finally, it is worth looking at the sampling performed by the two methods. In Fig. 11 the samples selected
by MISC-P S and SRBF are displayed. In the first case (see Fig. 11a) the samples are well distributed over the domain in a symmetric way, with no preferential directions. The SRBF sampling is instead slightly more clustered in the regions where the high-fidelity function shows a greater curvature (cf. Fig. 11b). The sampling performed by MISC-P R is not shown for brevity, as it is very similar to the one for MISC-P S .
3.3. RoPax resistance problem
3.3.1. Formulation and CFD method The main problem addressed in this work is the forward UQ analysis of the model-scale resistance (RT )
of a RoPax ferry in straight ahead advancement, subject to two operational uncertainties y = [U, T ], namely the advancement speed (U ) and the draught (T ), uniformly distributed within the ranges in Tab. 1.
The RoPax ferry is characterized by a length between perpendicular at nominal draught (LPP) of 162.85 m and a block coefficient CB = 0.5677 (see Fig. 12). The parametric geometry of the RoPax is produced with the computer-aided design environment integrated in the CAESES® software, developed by FRIENDSHIP SYSTEMS AG, and made available in the framework of the H2020 EU Project Holiship3. The analysis is performed at model scale with a scale factor equal to 27.14. The main dimensions and the operative conditions are summarized in Tab. 1. The advancement speed ranges from 12 to 26 knots at full scale and the draught variation is ±10% of the nominal draught, which corresponds to a variation of about ±15% of the nominal displacement. The corresponding range in Froude number Fr = U/ gLPP is [0.154, 0.335], whereas the variation in Reynolds number (at model scale) is Re = U LPP/µ = U LPP/  [6.423 · 106, 1.392 · 107],

3www.holiship.eu

17

Figure 12: RoPax ferry, hull form. Free surface level is reported for the nominal draught.

Table 1: Main geometrical details and operative conditions of the RoPax ferry (model scale 1 : 27.14).

Description
Length between perpendiculars Beam Block coefficient Nominal displacement Nominal draught Draught range Speed range Froude range Reynolds range

Symbol
LPP B CB  Tn T U Fr Re

Full Scale
162.85 29.84 0.5677 19584.04 7.10 [6.391, 7.812] [6.173, 13.376] [0.154, 0.335] [9.081 · 108, 1.968 · 109]

Model Scale
6.0 1.0993 0.5677 0.9996 0.261660 [0.2355, 0.2878] [1.185, 2.567] [0.154, 0.335] [6.423 · 106, 1.392 · 107]

Unit
m m ­ m3 m m m/s ­ ­

where  = 998.2 kg/m3 is the water density,  = µ/ = 1.105·10-6 m2/s the kinematic viscosity and g = 9.81 m/s2 the gravitational acceleration.
The hydrodynamics performance of the RoPax ferry is assessed by the RANS code navis developed at CNR-INM. The mean features of the solver are summarized here; for more details the interested reader is referred to [26, 27, 49, 28] and the references therein. navis is based on a finite volume discretization of the RANS equations, with variables collocated at the cell centers. Turbulent stresses are related to the mean velocity gradients by the Boussinesq hypothesis; the turbulent viscosity is estimated by the Spalart-Allmaras turbulence model [50]. Wall-functions are not adopted, therefore the wall distance y+ = 1 is ensured on the no-slip wall. Free-surface effects are taken into account by a reliable single-phase level-set approach.
The computational domain extends to 2LPP in front of the hull, 3LPP behind, and 1.5LPP on each side; a depth of 2LPP is imposed (see Fig. 13a). On the solid walls (in red in the figure), the velocity is set equal to zero, whereas zero normal gradient is enforced on the pressure field; at the (fictitious) inflow boundary (in blue in Fig. 13a), the velocity is set to the undisturbed flow value and the pressure is extrapolated from inside; the dynamic pressure is set to zero at the outflow (in yellow), whereas the velocity is extrapolated from inner points. On the top boundary, which remains always in the air region, fluid dynamic quantities are extrapolated from inside (in purple). Taking advantage of the symmetry of the flow relative to the y = 0 plane, computations are performed for half ship only, and the usual symmetry boundary conditions are enforced on the symmetry longitudinal plane (in green).
The computational grid is composed by 60 adjacent and partially overlapped blocks; Fig. 13b shows a particular of the block structures in the region around the ship hull and the computational mesh on the symmetry plane. Taking the advantage of a Chimera overlapping approach, the meshes around the skeg and around the bow are generated separately from the mesh around the hull; a background Cartesian grid is then built and the whole grid is assembled by means of an in-house overlapping grid pre-processor. The final mesh counts for a total of about 5.5M of control volumes for half the domain. The numerical solutions are computed by means of a full multi-grid­full approximation scheme (FMG­FAS), with four grid levels (from coarser to finer: M1, M2, M3, and M4), each obtained from the next finer grid with a coarsening ratio equal to 2, along each curvilinear direction. In the FMG­FAS approximation procedure, the solution is first computed on the coarsest grid level and then approximated on the next finer grid by exploiting all
18

(a) Boundary conditions

(b) Computational mesh

Figure 13: RoPax ferry, numerical setup. Boundary conditions and computational grid.

Figure 14: RoPax grids, detail of the bow region, left to right: M4, M3, M2, M1.

Figure 15: RoPax ferry, M4 CFD results in terms of non-dimensional wave pattern (left) and surface pressure (right) for: Fr = 0.193, T = 3.9249 · 10-2LPP and T = 4.7971 · 10-2LPP, top row left and right; Fr = 0.335, T = 3.9249 · 10-2LPP and T = 4.7971 · 10-2LPP, bottom row left and right.
19

Figure 16: RoPax ferry, enlarged view of the bow region as in Fig. 16.

the coarser grid levels available with a V-Cycle. The process is repeated up to the finest grid level. For

the present UQ problem the number of grid volumes is 5.5M for M4, 699K for M3, 87K for M2, and 11K

for M1. To provide an idea about the different mesh resolutions between the grid levels, Fig. 14 shows a

particular of the grid at the bow region for M4, M3, M2 and M1 grids. Since the grids are obtained by a dyadic derefinement, the following normalized computational costs can

be assigned to each grid:

cost() = 8-1

(27)

with  = 1, . . . , 4. In the FMG-FAS scheme the computation on the -th grid level involves computations on all the coarser meshes M1 . . . M-1. However, with the estimation in Eq. (27), only the cost of the highest-fidelity level samples is taken into account, i.e. the computations on the coarser grids are considered negligible.
Fig. 15 shows an overview of the numerical solutions obtained for different conditions in terms of wave pattern and pressure on the hull surface; wave height (as elevation with respect to the unperturbed level) and surface pressure are reported in non-dimensional values, making the height non dimensional with LPP and the pressure with U 2L2PP, as usual. A clear, and obvious, Froude number dependency is seen for the wave patterns; at the lower speed shown, the free surface is weakly perturbed (note that the same color range has been used for all the panels), whereas, at higher Froude, a clear Kelvin pattern is seen. Also, at higher speed, the formation of a well-defined transom wave system is observed, including the presence of the classical rooster tail. It is also worth to observe the influence of the draught on the wave system; in particular at the lowest speed and smaller draught reported, the rear part of the bulbous is partially dry (better seen in the enlarged views presented in Fig. 16). The region of very low pressure caused by the flow acceleration around the bow is obviously the cause. For all cases, the high pressure in the stagnation point at the bow prevents the bow to be outside the water, as it is at the rest conditions at least for the nominal and the smaller draughts (see Fig. 12). At the higher speed, the larger draught condition causes a stronger rooster tail system at the stern, with higher crest and trough.
Figure 17 shows the complete FMG­FAS cycle for the minimum and the maximum Froude numbers. The final evaluation of the RT for each grid is performed averaging the RT value among the last 100 iterations of the cycle. These are highlighted by the gray areas. Even if a general second order convergence has been verified (not shown here for the sake of conciseness), it is evident that, although the FMG­FAS switches to a finer grid when the solver residual are lower than the defined convergence threshold (not shown here), the

20

(a) Complete FMG­FAS cycle

(b) Detail of the shift from M1 (c) Detail of the shift from M2 (d) Detail of the shift from M3 (e) Detail of the last iterations

to M2

to M3

to M4

on M4

Figure 17: RoPax problem, FMG­FAS cycle and highlight (grey areas) of the iterations considered to evaluate the RT for each grid for the minimum and maximum Froude numbers.

value of RT is clearly not converged yet, at least for the coarsest grid level. This has been observed mostly for low Froude numbers. Therefore, the final value of RT can significantly deviate for simulations performed on the same grid but with slightly different conditions, thus producing evaluations affected by numerical noise. This will have an impact on the following UQ analysis.
3.3.2. Numerical results Hereafter a detailed comparison of the performance of the MISC and SRBF methods is provided. The ref-
erence surrogate model Gref(y) is obtained considering high-fidelity simulations only. In details, an isotropic tensor grid consisting of 9 × 9 CC points (see Eq. (1)) is constructed over  and the corresponding simulations on the mesh M4 are performed. The resulting surrogate model is an interpolatory model, based on global tensor Lagrange polynomials, which is shown in Fig. 18b. Figure 18a shows instead the surrogate obtained with M1, at the same CC points. Notice that both surrogates are affected by the noise, and more specifically, the noise is more evident in the lowest-fidelity surface which is significantly less smooth than the highest-fidelity surrogate. Reference values for the centered moments are then computed applying the tensor quadrature formula associated to the CC points to the highest fidelity.
First, the performance of the MISC method is discussed. Only the results for the version of MISC with quadrature-based profits P R are reported here, since this approach outperforms the version of MISC with surrogate-based profits P S , for reasons related with the presence of the numerical noise that will be clarified in a moment. In Fig. 19 the values of the approximations of the first four centered moments of RT obtained with MISC at different computational costs are displayed on the left, while the relative errors are shown on the right. Upon inspection of these plots, we can conclude that the quality of the estimates decreases with increasing order of the moments. In particular, the expected value and the variance seem to converge reasonably well (although the estimate of the expected value seems to hit a temporary plateau, after having obtained a good estimate at a low computational cost), whereas the kurtosis is strongly underestimated and its approximation results to be very poor.
To explain this behavior, we have a closer look at the MISC quadrature formula (9). In particular, let us recall that the computation of the first four centered moments implicitly uses surrogate models for rth

21

(a) Lowest-fidelity model

(b) Highest-fidelity model

(c) MISC model

(d) SRBF model

Figure 18: RoPax problem, surrogate models.

Figure 19: RoPax problem, results for the MISC method. Left: convergence of the values of the first four centered moments. The black dashed line marks the reference value of the moments. Right: relative error of the moments (see Eq. (24)).
22

powers of the quantity of interest RTr , r = 1, . . . , 4, (see Sect. 2.1). These models are displayed in Fig. 20. The first one, corresponding to r = 1, is quite rough: the surface shows an oscillatory behavior and the expected monotonicity of RT with respect to U and T is destroyed. This is due to the already discussed presence of numerical noise, which particularly affects the low-fidelity simulations. Indeed, MISC intensively samples low-fidelities by construction, see Fig. 21a, where we report the evaluations allocated on each fidelity as the iterations proceed. In particular, most of the low-fidelity simulations are added from iteration 13 on (see Fig. 21b): this explains the fact that the estimate of E[RT ] reaches reasonable values at early iterations, i.e. when there is still a balance of low- and higher- fidelity simulations, and its convergence deteriorates later, i.e. when low-fidelity simulations are the majority. Given that the numerical noise introduces spurious oscillations in the surrogate model already for r = 1, such oscillations can only be amplified for r > 1, as can be observed in Fig. 20b,c,d. Hence, the computation of moments suffers more from the noise the higher the order.
This observation then suggests that a way to mitigate the impact of such oscillations in the computation of statistical moments is to employ a method that does not require higher order surrogate models. In this work, we propose to compute such moments by taking Monte Carlo samples of the surrogate of RT , and approximating the moments from these values, with the usual sample formulas. The results reported in Fig. 22 have been obtained taking the average of 10 repetitions with 10000 samples (again, note that this computation is not expensive since it only requires evaluations of the MISC surrogate model) and are quite promising: the benefits increase for higher and higher order moments, and in particular, the improvement in the estimate of the kurtosis is quite impressive; the results of MISC and Monte-Carlo quadrature in the case r = 1 are instead substantially equivalent, which is to be expected since they both work with the same surrogate model. This strategy thus mitigates the impact of the noise on the computation of moments. However, it is not entirely satisfactory, since the choice of the number of samples to be employed is non trivial: on the one hand, we need a sufficiently large number of samples to ensure accuracy of the estimates, on the other hand, taking too many samples results in resolving the spurious oscillations. In other words, the chosen number of samples should give the best compromise between these two aspects, and some trialand-error tuning, or some accurate a-priori analysis should be carried out. Deeper studies of this matter will be subject of future work.
Further, at this point it is also clear why the version of MISC with profit P R, i.e. based on the quadrature, gives better results than the version with profit P S , i.e. based on the quality of the surrogate model. Indeed, in case of noisy simulations, the selection criterion for the multi-indices based on the evaluation of the pointwise difference between two surrogate models, as it is the case of MISC based on the profit P S , results in capturing even more the spurious oscillations due to the numerical noise. In other words, this approach results to be more sensitive to the presence of the noise than the approach with profit P R.
Next, we move to SRBF. As already mentioned, in this application we use a regression approach to compute the weights of the surrogate model (i.e. solving (17)), motivated by the fact that the evaluations of the CFD solver are noisy as just discussed. The SRBF surrogate model at the last iteration of the adaptive sampling procedure is shown in Fig. 18d. The surface is smoother than the one produced by MISC (cf. Fig. 18b), although a small bump is present in the bottom part. This figure thus shows that SRBF is in general effective in filtering-out the numerical noise in the training set.
Figure 23 shows that SRBF spent about 50% of the final computational cost at the first iteration, then requiring simulations on the finest grids only at iterations 5 and 6. In all the other iterations mainly lowfidelity simulations are performed. This sampling behavior is due to the high values of prediction uncertainty that are found in the corners of the parametric domain, because the topology of the initial training leads to extrapolation in those zones. Such corner regions are those with the highest estimated prediction uncertainty, and the adaptive sampling procedure requires all the fidelities before exploring other regions.
Figure 24 shows the convergence of the first four centered moments of the resistance and their relative errors obtained with SRBF. The method initially converges rapidly to the reference values but then the metrics start oscillating. This is particularly evident in the last iterations of the adaptive sampling process, see Fig. 24a. Figure 24b shows the detail of the last iterations of the adaptive sampling. The oscillatory behavior is evident and mostly associated with the intensive sampling of the lowest fidelity happening in correspondence with computational costs between 4638 and 4655. In this range the expected value and the skewness oscillates more than the other moments, indicating that the surrogate model is oscillating around the training data.
To conclude the discussion on the convergence of the moments, in Fig. 25 the convergence of the relative errors of the moments obtained with the two methods is compared (of course MISC uses MC quadrature).
23

(a) Surrogate model for RT

(b) Surrogate model for RT2

(c) Surrogate model for RT3

(d) Surrogate model for RT4

Figure 20: RoPax problem, surrogate models obtained with the MISC method.

(a) Total number of simulations

(b) Number of new simulations

Figure 21: RoPax problem, number of simulations per mesh selected by the MISC method at each iteration.

24

Figure 22: RoPax problem, results for the MISC method: relative error of the moments (see Eq. (24)). A comparison between the results obtained with the MISC quadrature formula (9) and the Monte-Carlo quadrature.

(a) Total number of simulations

(b) Number of new simulations

Figure 23: RoPax problem, number of simulations per mesh selected by the SRBF method at each iteration.

(a) Convergence over the full range of available computational costs.
(b) Zoom on the final part of the convergence. Figure 24: RoPax problem, results for the SRBF method. Left: values of the first four centered moments. The black dashed line marks the reference value of the moments. Right: relative error of the moments (see Eq. (24)).
25

Figure 25: RoPax problem, comparison of MISC and SRBF results: relative error of the moments. It is a compact visualization of the results of Fig. 19 and 24.
Figure 26: RoPax problem, comparison of MISC and SRBF methods: relative error of the approximation RT in L2 (left) and L norm (right) (see Eq. (25)).
Both MISC and SRBF achieve similar values: SRBF reaches smaller errors in all moments but the kurtosis, but the convergence trend is bumpier than for MISC, and has a larger initial computational cost.
In Fig. 26 the relative error in L2 and L norms of the estimates of the advancement resistance are plotted. These metrics confirm that the MISC method reaches reasonable estimates with a low computational cost, whereas the SRBF method returns slightly better results but requires an higher computational cost. In the case of SRBF, it is worth noting that in the last iterations the relative errors of variance, skewness, and kurtosis increase whereas the L2 metric decreases. This apparent contradiction is discussed comparing the convergence of the variance and the L2 metric. Figure 27 shows the convergence of the difference of the variances between the multi-fidelity surrogate model prediction RT and the reference value RT , i.e. of Var[RT ] = Var[RT ] - Var[RT ], and of the L22 metric, along with the summands of their decompositions:
Var[RT ] = E[RT2 ] - E[RT2] - (E[RT ]2 - E[RT ]2), L22 = E[(RT - RT )2] = E[RT2 ] + E[RT2] - 2E[RT RT ]. In order to have Var[RT ] going to zero it should happen that its two components, E[RT2 ] - E[RT2] and E[RT ]2 - E[RT ]2, go to zero remaining equal in size; however, this does not happen, see Fig. 27b. Conversely, the two components of the L22 metric, i.e. E[RT2 ] + E[RT2] and 2E[RT RT ], are always almost equal in size, therefore the L22 metric goes to zero. Figure 27e shows a zoom on the last iterations of the Var[RT ] convergence: the component E[RT ]2 - E[RT2 ]2 is converging to zero faster than E[RT2 ] - E[RT2], therefore their difference Var[RT ] does not converge to zero.
Finally, in Fig. 28 the PDFs obtained with both methods and with the reference surrogate, as well as the results of the KS test statistic (cf. Eq. (26)), are plotted. Both MISC and SRBF predict well the position of the mode of the PDF and its magnitude and the tails of the distribution, with good agreement with the reference solution. In the range [40 70]N, the PDF obtained by the MISC method is more "wobbly", again due to the presence of noise in the evaluations of the solver, which corrupts the surrogate. Finally, the KS test statistic is seen to be convergent for both methods, implying convergence towards the reference CDF. Both convergences are not monotonic due to the influence of the noisy simulations.
26

(a) Variance difference and L22 metrics (b) Variance difference components

(c) L22 metric components

(d) Variance difference and L22 met- (e) Variance difference components, (f) L22 metric components, detail

rics, detail

detail

Figure 27: RoPax problem, results for the SRBF method. Convergence of the variance difference and L22 metrics and their components.

(a) PDF of RT at the final iteration (obtained by Matlab's ksdensity enforcing positive support since RT takes positive values only)

(b) KS test statistic (see Eq. (26))

Figure 28: RoPax problem, comparison of MISC and SRBF methods.

27

4. Conclusions and future work
In this work, two multi-fidelity methods for forward UQ applications, MISC and SRBF, have been presented and applied to two examples to highlight their strengths and critical points. In details, we have considered the a-posteriori adaptive MISC algorithm already presented in [12], with slight modifications on the profit computation, and we have highlighted in passing that MISC is not an interpolatory method, contrary to its single-fidelity counterpart (i.e., sparse grids); this detail was never previously discussed (up to the authors' knowledge) in the MISC literature. SBRF has been used as an interpolatory surrogate model for the analytical test problem and as a regressive surrogate model [23] for the RoPax problem.
The first numerical test considered in this work is an analytical example, whereas the second test consists of a realistic application in naval engineering and it is more demanding for a number of reasons (noisy evaluations of the quantity of interest, large computational costs). For the former, the different fidelities considered are Taylor expansions of increasing order of a given function, while for the latter fidelities are obtained by stopping the multi-grid computations in the RANS solver at different grid levels.
For both tests, we have computed a number of error metrics for the quantity of interest of each test (value of the function for the analytic test / advancement resistance for the ferry problem): convergence of the approximation of the first four centered moments, mean squared and maximum prediction errors over a set of samples, and convergence of the CDF (as measured by the Kolmogorov­Smirnov test statistic).
Overall, both MISC and SRBF proved to be viable multi-fidelity approaches to forward UQ problems. MISC has an edge in providing reasonable estimates of most statistical quantities at reduced computational costs, but is more sensitive to the noise in the evaluations of the quantities of interest, which can corrupt the estimates e.g. of higher-order moments (skewness, kurtosis) and introduce artefacts in the estimation of the PDF of the quantities of interest. A possible strategy to mitigate these issues, that consists in computing higher-order statistical moments by taking Monte Carlo samples of the MISC surrogate model and then computing the moments from such set of values by sample formulas (sample variance/skweness/kurtosis), has been proposed but it is not entirely satisfactory, since it is not clear how to choose an appropriate number of samples (enough to be accurate, not too many to avoid resolving the scale of the noise). This aspect deserves more investigations and is one of the subjects of future work. Another practical issue is caused by the non-monotonic behavior of the profits, where some indices with low profits shade useful neighbors, thus delaying the convergence of MISC. More robust strategies to explore the set of multi-indices, that blend the profit-based selection of indices with other criteria are also subject of future work; see e.g. [36, 39], where this problem was discussed in the context of adaptive sparse-grids quadrature/interpolation.
Conversely, SRBF is less prone to issue of noisy evaluations but on the other hand its initialization strategy needs to sample all available fidelities, which results in a significantly larger initialization cost. Different initialization strategies are under investigation to reduce this gap: a possible approach would be e.g. to build the initial training set using only one evaluation for each fidelity other than the lowest one, instead of 2N + 1 as in the current implementation, see [51]. This would allow the adaptive sampling method to freely define the best training set for the higher-fidelities. The second limitation that needs to be addressed is the high computational cost of evaluating the SRBF surrogate model for large training sets.
Another aspect worth investigating for both methods is how to incorporate soft information (monotonicity, multimodality, etc.) available on the physical nature of the problem in the construction of the surrogate models. In the particular RoPax problem considered here, the resistance is expected to be monotone increasing with respect to advancement speed and draught: such property could be preserved by employing, e.g., least-squares regressions with appropriate polynomial degrees and/or monotonic smoothing, see e.g. [52].
Concerning the application to naval UQ, once fixed the current limitations of both methods, future research will address more complex test cases, such as a larger number of uncertain parameters and more realistic conditions, to take e.g. regular/irregular waves into account.
Acknowledgments
CNR-INM is grateful to Dr. Woei-Min Lin, Dr. Elena McCarthy, and Dr. Salahuddin Ahmed of the Office of Naval Research and Office of Naval Research Global, for their support through NICOP grant N62909-18-12033. Dr. Riccardo Pellegrini is partially supported through CNR-INM project OPTIMAE. The HOLISHIP project (HOLIstic optimisation of SHIP design and operation for life cycle, www.holiship.eu) is also acknowledged, funded by the European Union's Horizon 2020 research and innovation program under grant agreement N. 689074. Lorenzo Tamellini and Chiara Piazzola have been supported by the PRIN 2017 project
28

201752HKH8 "Numerical Analysis for Full and Reduced Order Methods for the efficient and accurate solution of complex systems governed by Partial Differential Equations (NA-FROM-PDEs)". Lorenzo Tamellini also acknowledges the support of GNCS-INdAM (Gruppo Nazionale Calcolo Scientifico - Istituto Nazionale di Alta Matematica). Finally, the authors are grateful to CINECA for providing HPC capabilities through the ISCRA-C grant HP10CRM564 "Enabling high-fidelity Shape Optimization by Design-space Augmented Dimensionality Reduction (ESODADR)".
References
[1] W. He, M. Diez, Z. Zou, E. F. Campana, F. Stern, URANS study of Delft catamaran total/added resistance, motions and slamming loads in head sea including irregular wave and uncertainty quantification for variable regular wave and geometry, Ocean Engineering 74 (2013) 189­217.
[2] M. Diez, R. Broglia, D. Durante, A. Olivieri, E. F. Campana, F. Stern, Statistical assessment and validation of experimental and computational ship response in irregular waves, Journal of Verification, Validation and Uncertainty Quantification 3 (2) (2018) 021004.
[3] D. Durante, R. Broglia, M. Diez, A. Olivieri, E. Campana, F. Stern, Accurate experimental benchmark study of a catamaran in regular and irregular head waves including uncertainty quantification, Ocean Engineering 195 (2020) 106685.
[4] D. Quagliarella, A. Serani, M. Diez, M. Pisaroni, P. Leyland, L. Montagliani, U. Iemma, N. J. Gaul, J. Shin, D. Wunsch, C. Hirsch, K. Choi, F. Stern, Benchmarking uncertainty quantification methods using the NACA 2412 airfoil with geometrical and operational uncertainties, in: 57th AIAA Aerospace Sciences Meeting, SciTech 2019, 2019, p. 3555.
[5] P. S. Beran, D. E. Bryson, A. S. Thelen, M. Diez, A. Serani, Comparison of multi-fidelity approaches for military vehicle design, in: 21th AIAA/ISSMO Multidisciplinary Analysis and Optimization Conference (MA&O), AVIATION 2020, Virtual Event, June 15-19, 2020.
[6] M. B. Giles, Multilevel Monte Carlo path simulation, Operations Research 56 (3) (2008) 607­617.
[7] K. Cliffe, M. Giles, R. Scheichl, A. Teckentrup, Multilevel Monte Carlo methods and applications to elliptic PDEs with random coefficients, Computing and Visualization in Science 14 (1) (2011) 3­15.
[8] A.-L. Haji-Ali, F. Nobile, R. Tempone, Multi-index Monte Carlo: when sparsity meets sampling, Numerische Mathematik (2015) 1­40.
[9] F. Y. Kuo, C. Schwab, I. Sloan, Multi-level Quasi-Monte Carlo Finite Element Methods for a Class of Elliptic PDEs with Random Coefficients, Foundations of Computational Mathematics 15 (2) (2015) 411­449.
[10] A. L. Teckentrup, P. Jantsch, C. G. Webster, M. Gunzburger, A Multilevel Stochastic Collocation Method for Partial Differential Equations with Random Input Data, SIAM/ASA Journal on Uncertainty Quantification 3 (1) (2015) 1046­1074.
[11] J. Beck, L. Tamellini, R. Tempone, IGA-based Multi-Index Stochastic Collocation for random PDEs on arbitrary domains, Computer Methods in Applied Mechanics and Engineering 351 (2019) 330­350.
[12] J. D. Jakeman, M. Eldred, G. Geraci, A. Gorodetsky, Adaptive multi-index collocation for uncertainty quantification and sensitivity analysis, International Journal for Numerical Methods in Engineering 121 (6) (2020) 1314­1343.
[13] A. Haji-Ali, F. Nobile, L. Tamellini, R. Tempone, Multi-index stochastic collocation for random PDEs, Computer Methods in Applied Mechanics and Engineering 306 (2016) 95­122.
[14] A.-L. Haji-Ali, F. Nobile, L. Tamellini, R. Tempone, Multi-index Stochastic Collocation convergence rates for random PDEs with parametric regularity, Foundations of Computational Mathematics 16 (6) (2016) 1555­1605.
[15] A.-L. Haji-Ali, F. Nobile, R. Tempone, S. Wolfers, Multilevel weighted least squares polynomial approximation, ESAIM: M2AN 54 (2) (2020) 649­677.
29

[16] B. Peherstorfer, K. Willcox, M. Gunzburger, Survey of multifidelity methods in uncertainty propagation, inference, and optimization, SIAM Review 60 (3) (2018) 550­591.
[17] A. Gorodetsky, G. Geraci, M. S. Eldred, J. Jakeman, A generalized approximate control variate framework for multifidelity uncertainty quantification, Journal of Computational Physics 408 (2020) 109257.
[18] M. Pisaroni, F. Nobile, P. Leyland, A multilevel Monte Carlo evolutionary algorithm for robust aerodynamic shape design, in: 18th AIAA/ISSMO Multidisciplinary Analysis and Optimization Conference. Denver, Colorado, 2017.
[19] M. Pisaroni, F. Nobile, P. Leyland, A continuation multi level Monte Carlo (C-MLMC) method for uncertainty quantification in compressible inviscid aerodynamics, Computer Methods in Applied Mechanics and Engineering 326 (2017) 20­50.
[20] G. Geraci, M. S. Eldred, A. Gorodetsky, J. Jakeman, Recent advancements in Multilevel-Multifidelity techniques for forward UQ in the DARPA sequoia project, in: 57th AIAA Aerospace Sciences Meeting, SciTech 2019, 2019, p. 0722.
[21] Z.-H. Han, S. G¨ortz, Hierarchical kriging model for variable-fidelity surrogate modeling, AIAA journal 50 (9) (2012) 1885­1896.
[22] J. d. Baar, S. Roberts, R. Dwight, B. Mallol, Uncertainty quantification for a sailing yacht hull, using multi-fidelity kriging, Computers & Fluids 123 (2015) 185­201.
[23] J. Wackers, M. Visonneau, R. Pellegrini, S. Ficini, A. Serani, M. Diez, Adaptive n-fidelity metamodels for noisy CFD data, in: 21th AIAA/ISSMO Multidisciplinary Analysis and Optimization Conference (MA&O), AVIATION 2020, Virtual Event, June 15-19, 2020.
[24] A. Serani, R. Pellegrini, J. Wackers, C.-J. Jeanson, P. Queutey, M. Visonneau, M. Diez, Adaptive multifidelity sampling for CFD-based optimization via radial basis functions metamodel, International Journal of Computational Fluid Dynamics 33 (6-7) (2019) 237­255.
[25] Z.-H. Han, S. G¨ortz, R. Zimmermann, Improving variable-fidelity surrogate modeling via gradientenhanced kriging and a generalized hybrid bridge function, Aerospace Science and Technology 25 (1) (2013) 177­189.
[26] A. Di Mascio, R. Broglia, R. Muscari, On the application of the single-phase level set method to naval hydrodynamic flows, Computers & fluids 36 (5) (2007) 868­886.
[27] A. Di Mascio, R. Broglia, R. Muscari, Prediction of hydrodynamic coefficients of ship hulls by high-order godunov-type methods, Journal of Marine Science and Technology 14 (1) (2009) 19­29.
[28] R. Broglia, D. Durante, Accurate prediction of complex free surface flow around a high speed craft using a single-phase level set method, Computational Mechanics 62 (3) (2018) 421­437.
[29] C. Piazzola, L. Tamellini, R. Pellegrini, R. Broglia, A. Serani, M. Diez, Uncertainty quantification of ship resistance via multi-index stochastic collocation and radial basis function surrogates: A comparison, in: 21th AIAA/ISSMO Multidisciplinary Analysis and Optimization Conference (MA&O), AVIATION 2020, Virtual Event, June 15-19, 2020.
[30] M. Rosenblatt, Remarks on some nonparametric estimates of a density function, The Annals of Mathematical Statistics 27 (3) (1956) 832­837.
[31] E. Parzen, On estimation of a probability density function and mode, The Annals of Mathematical Statistics 33 (3) (1962) 1065­1076.
[32] L. N. Trefethen, Is Gauss quadrature better than Clenshaw-Curtis?, SIAM Rev. 50 (1) (2008) 67­87.
[33] A. Narayan, J. D. Jakeman, Adaptive Leja Sparse Grid Constructions for Stochastic Collocation and High-Dimensional Approximation, SIAM Journal on Scientific Computing 36 (6) (2014) A2952­A2983.
30

[34] F. Nobile, L. Tamellini, R. Tempone, Comparison of Clenshaw­Curtis and Leja Quasi-Optimal Sparse Grids for the Approximation of Random PDEs, in: R. M. Kirby, M. Berzins, J. S. Hesthaven (Eds.), Spectral and High Order Methods for Partial Differential Equations - ICOSAHOM '14, Vol. 106 of Lecture Notes in Computational Science and Engineering, Springer International Publishing, 2015, pp. 475­482.
[35] T. N. L. Patterson, The optimum addition of points to quadrature formulae, Math. Comp. 22 (1968), 847­856; addendum, ibid. 22 (104) (1968) C1­C11.
[36] A. Chkifa, A. Cohen, C. Schwab, High-dimensional adaptive sparse polynomial interpolation and applications to parametric PDEs, Foundations of Computational Mathematics 14 (4) (2014) 601­633.
[37] C. Schillings, C. Schwab, Sparse, adaptive Smolyak quadratures for Bayesian inverse problems, Inverse Problems 29 (6) (2013) 065011.
[38] F. Nobile, L. Tamellini, F. Tesei, R. Tempone, An adaptive sparse grid algorithm for elliptic PDEs with lognormal diffusion coefficient, in: J. Garcke, D. Pflu¨ger (Eds.), Sparse Grids and Applications ­ Stuttgart 2014, Vol. 109 of Lecture Notes in Computational Science and Engineering, Springer International Publishing Switzerland, 2016, pp. 191­220.
[39] T. Gerstner, M. Griebel, Dimension-adaptive tensor-product quadrature, Computing 71 (1) (2003) 65­ 87.
[40] H. M. Gutmann, A radial basis function method for global optimization, Journal of global optimization 19 (3) (2001) 201­227.
[41] A. I. J. Forrester, A. J. Keane, Recent advances in surrogate-based optimization, Progress in aerospace sciences 45 (1-3) (2009) 50­79.
[42] S. Volpi, M. Diez, N. J. Gaul, H. Song, U. Iemma, K. K. Choi, E. F. Campana, F. Stern, Development and validation of a dynamic metamodel based on stochastic radial basis functions and uncertainty quantification, Structural and Multidisciplinary Optimization 51 (2) (2015) 347­368.
[43] S. Lloyd, Least squares quantization in PCM, IEEE transactions on information theory 28 (2) (1982) 129­137.
[44] X. Li, W. Gao, L. Gu, C. Gong, Z. Jing, H. Su, A cooperative radial basis function method for variablefidelity surrogate modeling, Structural and Multidisciplinary Optimization 56 (5) (2017) 1077­1092.
[45] A. Serani, R. Pellegrini, R. Broglia, J. Wackers, M. Visonneau, M. Diez, An adaptive n-fidelity metamodel for design and operational-uncertainty space exploration of complex industrail problems, in: Proceedings of the 8th International Conference on Computational Methods in Marine Engineering (Marine 2019), 2019, pp. 177­188.
[46] J. Wackers, M. Visonneau, A. Serani, R. Pellegrini, R. Broglia, M. Diez, Multi-fidelity machine learning from adaptive- and multi-grid RANS simulations, in: Proceedings of the 33rd Symposium on Naval Hydrodynamics, Osaka, Japan, 2020.
[47] A. Serani, C. Leotardi, U. Iemma, E. F. Campana, G. Fasano, M. Diez, Parameter selection in synchronous and asynchronous deterministic particle swarm optimization for ship hydrodynamics problems, Applied Soft Computing 49 (2016) 313­334.
[48] J. B¨ack, F. Nobile, L. Tamellini, R. Tempone, Stochastic spectral Galerkin and collocation methods for PDEs with random coefficients: a numerical comparison, in: J. Hesthaven, E. Ronquist (Eds.), Spectral and High Order Methods for Partial Differential Equations, Vol. 76 of Lecture Notes in Computational Science and Engineering, Springer, 2011, pp. 43­62, selected papers from the ICOSAHOM '09 conference, June 22-26, Trondheim, Norway.
[49] R. Broglia, S. Zaghi, R. Muscari, F. Salvadore, Enabling hydrodynamics solver for efficient parallel simulations, in: 2014 International Conference on High Performance Computing & Simulation (HPCS), IEEE, 2014, pp. 803­810.
31

[50] P. Spalart, S. Allmaras, A one-equation turbulence model for aerodynamic flows, in: 30th aerospace sciences meeting and exhibit, 1992, p. 439.
[51] R. Pellegrini, A. Serani, M. Diez, M. Visonneau, J. Wackers, Towards automatic parameter selection for multifidelity metamodels, in: To be presented in 9th Conference on Computational Methods in Marine Engineering (Marine 2021), Virtual conference, 2-4 June, 2021.
[52] R. L. Dykstra, T. Robertson, An algorithm for isotonic regression for two or more independent variables, The Annals of Statistics 10 (3) (1982) 708­716.
32

