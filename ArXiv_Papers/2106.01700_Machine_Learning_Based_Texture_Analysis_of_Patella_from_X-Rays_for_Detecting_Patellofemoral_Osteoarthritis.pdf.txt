Bayramoglu et al.

arXiv:2106.01700v2 [eess.IV] 4 Jun 2021

Machine Learning Based Texture Analysis of Patella from X-Rays for Detecting Patellofemoral Osteoarthritis
Neslihan Bayramoglu1*, Miika T. Nieminen1,2,3 and Simo Saarakkala1,2,3

* Correspondence: name.surname@oulu.fi 1Research Unit of Medical Imaging, Physics and Technology, University of Oulu, Oulu, Finland Full list of author information is available at the end of the article

Abstract
Objective: To assess the ability of texture features for detecting radiographic patellofemoral osteoarthritis (PFOA) from knee lateral view radiographs.
Design: We used lateral view knee radiographs from The Multicenter Osteoarthritis Study (MOST) public use datasets (n = 5507 knees). Patellar region-of-interest (ROI) was automatically detected using landmark detection tool (BoneFinder), and subsequently, these anatomical landmarks were used to extract three different texture ROIs. Hand-crafted features, based on Local Binary Patterns (LBP), were then extracted to describe the patellar texture. First, a machine learning model (Gradient Boosting Machine) was trained to detect radiographic PFOA from the LBP features. Furthermore, we used end-to-end trained deep convolutional neural networks (CNNs) directly on the texture patches for detecting the PFOA. The proposed classification models were eventually compared with more conventional reference models that use clinical assessments and participant characteristics such as age, sex, body mass index (BMI), the total Western Ontario and McMaster Universities Arthritis Index (WOMAC) score, and tibiofemoral Kellgren­Lawrence (KL) grade. Atlas-guided visual assessment of PFOA status by expert readers provided in the MOST public use datasets was used as a classification outcome for the models. Performance of prediction models was assessed using the area under the receiver operating characteristic curve (ROC AUC), the area under the precision-recall (PR) curve -average precision (AP)-, and Brier score in the stratified 5-fold cross validation setting.
Results: Of the 5507 knees, 953 (17.3%) had PFOA. AUC and AP for the strongest reference model including age, sex, BMI, WOMAC score, and tibiofemoral KL grade to predict PFOA were 0.817 and 0.487, respectively. Textural ROI classification using CNN significantly improved the prediction performance (ROC AUC= 0.889, AP= 0.714).
Conclusion: We present the first study that analyses patellar bone texture for diagnosing PFOA. Our results demonstrates the potential of using texture features of patella to predict PFOA.
Keywords: Patellofemoral Osteoarthritis; Texture Analysis; Deep Learning

Bayramoglu et al.

Page 2 of 18

Patellofemoral Lateral View
joint
Tibiofemoral joint
Femur

Fibula

Tibia

Patella

Patella

Knee without PFOA

Knee with PFOA

Figure 1: Figure on the left demonstrates the anatomy of the knee and knee joint articulations. Middle and right figure illustrate examples of lateral view X-ray images of normal knee and patellofemoral OA knee. On the right, joint space narrowing (JSN) and osteophytes - characteristic features of OA - are demonstrated on the patellofemoral joint.

Introduction
Osteoarthritis (OA) is the most common degenerative joint disease causing disability. Knee is the most frequently affected of all joints. Although the etiology of OA is not fully known yet, it is a complex disease resulting from combinations of risk factors including aging, female sex, obesity, past injury, and inflammation [1]. The disease has a profound effect on quality of life affecting both physical function and well-being. Moreover, prevalence of knee OA is increasing due to aging population and increasing rates of obesity [1]. Overall, the costs of knee OA are substantial.
There is no known cure for OA, and the disease is often progressive characterized with pain and loss of joint function. Therefore, more research is needed to better understand the disease. Imaging biomarkers is one of the exciting areas that can advance our understanding. Together with the developments in artificial intelligence, particularly deep learning, there is an increasing number of studies based on medical imaging of knee OA [2]. Most of these studies, however, focuses on tibiofemoral joint of the knee that consists of two condyloid articulation in which the femur has a rolling and sliding motion over the tibia [2]. However, there is a third articulation called patellofemoral (PF) joint (Figure 1). Osteoarthritis that occur at the PF joint, patellofemoral osteoarthritis (PFOA), is highly prevalent and clinically important yet still under-investigated [3]. For instance, there are clear diagnostic guidelines for tibiofemoral (TF) joint OA ([4, 5, 6, 7]). Often these guidelines involve the use of well-validated radiographic grading systems for evaluating the severity of TFOA, such as Kellgren and Lawrence (KL) grading system [8] and Osteoarthritis Research Society International (OARSI) standardized atlas [4]. However, there are no similar diagnostic guidelines explicitly developed for PF joint. Moreover, in clinical setting, radiographic TF joint is often evaluated with a posterior-anterior (PA) view radiograph from which the PF joint can not be evaluated at all. In addition, clinical assessments and participant characteristics alone cannot be used to diagnose patellofemoral OA [9, 10, 11]. Since it has been reported that, at least in some phenotypes of knee OA, PF joint changes even precede TF joint changes

Bayramoglu et al.

Page 3 of 18

([12, 13, 14]), there is a strong need to consider also PF joint when developing new imaging biomarkers to diagnose and monitor knee OA .
In the OA research field, several studies have demonstrated the use of texture analysis for knee radiographs to distinguish knees with OA and without OA [15, 16, 17, 18]. However, these studies are all focusing on TFOA. With regard to PFOA, we showed recently that it can be detected using deep convolutional neural networks (CNNs) [11]. However, such deep learning based models are "black-boxes" and it is uncertain whether the model decisions are based on texture or some other imaging features such as shape or alignment. Therefore, in this study we investigated automated texture analysis of patella from lateral view radiographs. Specifically, we studied whether texture features can be used to distinguish the knees with definite radiographic PFOA from healthy knee radiographs. We proposed a framework based on machine learninJSg2 Daensdcripptoerrformed extensive experiments to demonstrate the influence of texture features on the diagnostic performance. Different region of interests (ROIs) from patellar region from lateral view radiographs (X-rays) were explored. Subsequently, we compared the performances of hand-crafted features, deep CNN features, and clinical features. Finally, we propose a stacked model where both patellar texture and clinical feature predictions are combined with a second level machine learning model - Gradient Boosting Machine (GBM) [19]. To the best of our knowledge, this is the first study to evaluate patellar bone texture in OA research.

Conv BN MaxPool ReLU
Concat FC
Dropout FC
Label OA vs Non-OA

Landmark Detection ROI Localization

Deep CNN

PFOA Probability

Texture Feature Extraction
Clinical Variables Age, Sex, BMI, WOMAC, KL

Model Training

GBM

PFOA Probability

Model Training

GBM

PFOA Probability

Figure 2: Illustration of the workflow of our approach. First, we localized patellar landmarks using BoneFinder software (see Materials and Methods for more details). Subsequently, we applied intensity normalization and resampled the data to have a 0.2 mm pixel spacing. Finally, each knee is rotated in order to have an aligned patella. Three different regions of interest (ROIs) were located using patellar bone landmarks, after which a deep convolutional neural network (CNN) model was employed to predict the patellofemoral osteoarthritis (PFOA). Furthermore, we also trained a gradient boosting machine (GBM) model using handcrafted texture features (local binary patterns). To make a comparison of the proposed X-ray based methods, we trained another GBM model using clinical variables including age, sex, body mass index (BMI), the total Western Ontario and McMaster Universities Arthritis Index (WOMAC) score, and Kellgren and Lawrence (KL) score of the tibiofemoral joint. We used a stratified subject-wise 5-fold cross validation setting to measure the performance of all the methods. In addition to these individual models, we fused the predictions from these models in a second layer GBM model to improve the overall prediction performance.

Bayramoglu et al.

Page 4 of 18

Materials and Methods
The overall pipeline of our study is shown in Figure 2. In order to pre-process the data, we extracted anatomical landmark points [20] and applied intensity normalization using global contrast normalisation and a histogram truncation between the 5th and 99th percentiles. We then resampled the data to have a 0.2mm pixel spacing. Subsequently, we located ROIs using landmark points. Right knee images were then horizontally flipped to have a similar view with left knee images. Finally, we predicted PFOA using both handcrafted texture features using a machine learningbased approach and a deep CNN. We also trained a machine learning model (GBM [19]) on clinical features as a reference method to compare with the proposed approach.
Data In the study, we used data from the Multicenter Osteoarthritis Study public use datasets (MOST, http://most.ucsf.edu). The MOST study is a longitudinal observational study of adults who have or are at high risk for knee OA. At baseline, there were 3,026 individuals aged 50­79 years who either had radiographic knee OA or were at high risk for developing the disease. In MOST, semiflexed lateral view radiographs were acquired according to a standardized protocol. Knee radiographs were read from the baseline to 15, 30, 60 and 84-month follow-up visits. We employed radiographs taken at the baseline visit that includes 5507 knees after removing data which have missing information. Out of 5507 knees, 953 had PFOA(17.3%).
In the MOST public use datasets, radiographic PFOA is defined from lateral view radiographs as follows: Osteophyte score  2 or the joint space narrowing (JSN) score is  1 plus any osteophyte, sclerosis or cysts  1 in the PF joint (grades 0­3; 0=normal, 1=mild, 2=moderate, 3=severe) (Figure 3).
Assessment of Radiographic Patellofemoral (PF) Osteoarthritis Status (Lateral View X-Rays) in the MOST Public Use Datasets
0 No 1 Yes · [Any osteophyte  2 in the PF joint] OR
· [Joint space narrowing 1 PLUS any osteophyte, sclerosis, or cyst 1 in the PF joint]
Figure 3: Assessment of patellofemoral osteoarthritis in the MOST public use datasets.
Individual radiographic features in the MOST dataset were graded by two independent expert readers based on the atlases from the Osteoarthritis Research Society International (OARSI) [4] which refers to the previous OARSI atlas for the patellofemoral joint [21] and Framingham Osteoarthritis Study [22]. When there was a disagreement in film readings, a panel of three adjudicators resolved the discrepancies[23].
Patellar Landmark Localization In this study, we utilized BoneFinder® software [20] in order to locate the landmark points along the contours of the patella (Figure 4). BoneFinder® uses random forest

Bayramoglu et al.

Page 5 of 18

Figure 4: Anatomical patellar landmarks were detected from lateral view knee radiographs. BoneFinder® software [20] were used to locate 21 landmark points along the contours of the patella. Marginal landmarks were employed in order to align the patellar region. The line on the right between the marginal points were draw in order to illustrate the final alignment of patella.
regression voting with constrained local model approach to automatically locate 21 anatomical landmarks in patellar region from lateral knee X-rays. These points enabled us to locate ROIs within the patella with precision. Moreover, we used two marginal landmarks in order to align patella to obtain the same anatomical region among the knees in the ROI localization step (Figure 4).
Texture Descriptor - Local Binary Patterns (LBP) Previously in OA research, multiple texture descriptors have been applied to plain knee radiographs for several years, Fractal Signature Analysis (FSA) or fractal dimension (FD) being the most widely used ones [24, 25, 17, 26, 15]. However, FD method is susceptible to limited discrimination power due to its sensitivity to image artifacts and noise [27]. It was shown in [15] that Local Binary Patterns (LBP) [28] yields better performance in describing bone texture to detect OA for tibiofemoral joint. Therefore, in our study, we selected LBP as a handcrafted texture descriptor as well.
LBPs captures a local representation of texture. In order to compute LBP value of a pixel (c), p neighboring pixels that are evenly distributed in angle on a circle of radius r are sampled first. Then the LBP pattern is constructed by comparing the gray value of the center pixel (c) with its surrounding neighborhood of p pixels and a binary vector of p bits is extracted from this comparison. The decimal value of LBP pattern is then obtained from the binary sequence. For an N × M texture image, a LBP pattern can be the computed at each pixel -(N × M ) LBP patterns-,

Bayramoglu et al.

Page 6 of 18

then the image texture can be represented by the distribution of LBP values, by a LBP histogram vector. In this study, we used r = 2, p = 8 × r and a 256 bins histogram to obtain LBP descriptions of our texture patches.
Selection of Region of Interest (ROI) We explored three different ROIs within patellar region for texture analysis (Figure 5). It is known that along with the progression of OA, bone is subject to changes in its structure and composition [29, 30]. The radiographically most distinctive bony changes occur at the margins where osteophytes typically occur[15]. Therefore, we selected two ROIs from the inferior and superior region of patella . Their sizes are proportional to the height of the patella measured from the outermost points (20% of the patella height). To locate those ROIs, we used the marginal landmarks which were also utilized previously for alignment (Figure 4). As the third ROI, we utilized the whole patellar region. For segmenting patella from the background, we employed landmark points and obtained a smoothed spline that roughly approximates the contour (Figure 5).

a: Superior ROI

(b) Inferior ROI

(c) Whole Patella

Figure 5: Examples of region-of-interest (ROI) placement for texture analysis. Here, a) shows an example of superior ROI, b) shows inferior ROI, and c) whole patellar region.

In order to detect the most informative (optimal) ROI, we employed LBP descriptor. Here, we defined the most informative region as the subregion where the texture classifier (based on LBP features) performs best to distinguish OA samples from non-OA.
We used Gradient Boosting Machine (GBM) classifier based on decision tree algorithms [19] to predict PFOA using LBP features that were extracted from ROIs defined previously (Figure 5). We observed that superior ROI features yields better classification performance (See Results section). Therefore, we utilized superior ROI ( Figure 5a) in the subsequent experiments.

Bayramoglu et al.

Page 7 of 18

Machine Learning Models We employed both GBM and deep CNN methods to predict PFOA from the texture patches and clinical assessments and participant characteristics. GBM is a powerful decision trees based machine learning algorithm that rely on the concept of boosting "weak learners"[19]. GBM is an iterative process - in each iteration training set is re-weighted such that it compensates for the weaknesses of the previous model. In this study, we used an efficient implementation of GBM called LightGBM [31]. Table 1 summarises all the models developed in this study.
First, we extracted LBP texture features from superior ROI texture patches and trained a GBM model based on these features (Model1). Then, we used a deep CNN architecture that was trained from end-to-end to classify superior ROI texture (Model6). In this way, texture features were learned from the imaging data itself. CNNs captures both fine-level high spatial-frequency details such as edges, lines, texture, corners, etc and recognize more complex features as it gets deeper (as the number of convolutional layer increases). We refer reader to [32] and [33] for more information on the deep neural networks. We used a three layers' CNN model where the input patches are scaled to 64 × 64 images. Details of the CNN architecture and our training strategy can be found in the Supplementary Material. In this study, we also explored more conventional machine learning based prediction models using the clinical data and risk factors. These include age, sex, body-mass index (BMI), the total Western Ontario and McMaster Universities Arthritis Index (WOMAC) score, and the KL grade of the tibiofemoral joint (Model2,3,4,5). These reference methods were also built using the GBM classifier.
In all models, we employed subject-wise stratified 5-fold cross validation. Subjectwise splitting is used to eliminate the subject-dependent bias between training and validation. That is, all the data (imaging and/or clinical) coming from a particular subject is either put in the training or the test set. Moreover, we used stratified folds where each fold represents the actual class distribution of the data. The class distribution is the ratio between the positive and negative samples. The same folds were used for all the models to have fair comparisons. All the models were trained separately, thus reported performances were derived from the separate models.
Statistical Analyses The models were assessed using Receiver Operating Characteristics (ROC) curves, Precision-Recall (PR) curves, and Brier score [34]. In ROC curves, the true positive rate (TPR) against the false positive rate (FPR) are plotted, whereas PrecisionRecall (PR) curves are composed of the precision and the true positive rate. Therefore, PR analysis is more focused on the positive class. When data is imbalanced (i.e. more negative samples than positive samples), the ROC curve might not reflect the true performance of the classifier as false positive rate increases more slowly because of the large numbers of negatives. We used the area under the ROC curves (ROC AUC) and similarly area under the PR curves (Average Precision; AP) to summarize model performances. Brier score equals to the mean squared error of the prediction. In order to compare the differences between model AUCs, we applied DeLong's test [35].

Bayramoglu et al.

Page 8 of 18

Model1 Model2 Model3 Model4 Model5 Model6
Model7
Model8

Input
LBP Texture Features (extracted from superior ROI) Age, Sex, BMI Age, Sex, BMI, WOMAC Age, Sex, BMI, KL Age, Sex, BMI, WOMAC, KL Superior ROI (image patch) LBP, Age, Sex, BMI WOMAC, KL Predictions from Model5 and Model6

Method
GBM GBM GBM GBM GBM CNN
GBM
GBM

AUC
0.884 [0.871, 0.895] 0.647 [0.626, 0.666] 0.715 [0.696, 0.732] 0.812 [0.798, 0.826] 0.817 [0.802, 0.831] 0.889 [0.875, 0.9
0.904 [0.892, 0.913]
0.937 [0.929, 0.945]

AP
0.697 [0.669, 0.722] 0.294 [0.273, 0.317] 0.351 [0.325, 0.378] 0.47 [0.441, 0.5] 0.487 [0.457, 0.517] 0.714 [0.687, 0.739]
0.719 (0.693, 0.743)
0.791 [0.768, 0.813]

Brier Score 0.087 0.136 0.130 0.114 0.113 0.084
0.083
0.069

Texture Model Clinical Model Clinical Model Clinical Model Clinical Model CNN model
Fused Model
Stacked Model

Table 1: Comparison of the developed models

Results
Comparison of Region of Interest (ROI) Firstly, we compared the performance of the texture descriptor (LBP) on the superior ROI, inferior ROI, and also on the whole patella in subject-wise stratified 5-fold cross validation setting (Figure 6). Here, we used GBM models to predict PFOA. From Figure 6, it can be seen that the model employing superior ROI features performs best yielding an AUC of 0.884 (0871-0.895) and AP of 0.697 (0.669-0.722). We chose the superior ROI in our further comparisons because it performs with higher precision at most recall levels. We observed a lower performance when we used texture features extracted from the whole patella.
Comparison of Texture Features and Clinical Variables After testing the ROIs, we developed machine learning models based on clinical assessments and subject characteristics. In order to understand the value of texture features, we performed a thorough evaluation of age, sex, body-mass index (BMI), WOMAC and TFOA KL scores (Figure 7). Here, we utilised GBM models and trained them to predict the probability of PFOA using different combinations of the risk factors mentioned above. Figure 7 demonstrates that the best performed reference model is based on age, sex, body-mass index, WOMAC, and TFOA KL scores (Model5). It reached the AUC of 0.817 (0.802­0.831) and AP of 0.487 (0.457­0.517). When we compared our texture model (Model1) to the strongest reference method (Model5), we obtained a statistically significant difference between the AUC values (DeLong's p-value< 1e - 5).
Comparison of Texture Features and Deep Convolutional Neural Network Features Subsequently, we developed a CNN model, which directly works on texture patches in an automatic manner. Compared to the handcrafted texture model (Model1), our CNN model(Model6) yielded slightly higher performance with an AUC of 0.889(0.875-0.9) and AP of 0.714(0.687-0.739), however the performance difference in AUC was not statistically significant (DeLong's p-value=0.25) (Table 1). ROC and PR curves are shown in the Supplementary Material (Figure 10).

Bayramoglu et al.

Page 9 of 18

True positive rate Precision

1.0

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

ROI - Superior (AUC= 0.884 [0.871, 0.895]) ROI - Inferior (AUC= 0.873 [0.862, 0.884])

0.0

Patella (AUC= 0.819 [0.804, 0.832])

0.0 0.1 0.2 0.3 Fa0l.s4e po0s.i5tive0r.a6te 0.7 0.8 0.9 1.0

1.0

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

ROI - Superior (AP= 0.697 [0.669, 0.722]) ROI - Inferior (AP= 0.613 [0.584, 0.642])

0.0

Patella (AP= 0.513 [0.483, 0.542])

0.0 0.1 0.2 0.3 0.4 Re0c.5all 0.6 0.7 0.8 0.9 1.0

Figure 6: (a) ROC and (b) PR curves demonstrating the performance of the models operating on different region of interests (ROIs) - superior ROI, inferior ROI, and whole patella. Area under the curves and 95% confidence intervals in parentheses were given based on a 5-fold cross validation setting. Dashed lines in ROC indicate the performance of a random classifier and in case of PR it indicates the distributions of the labels of the dataset (PFOA vs non-PFOA).

Model Stacking and Early Feature Fusion Finally, in order to evaluate whether a combination of texture features and clinical assessments and participant characteristics would further increase the predictive accuracy, we utilised a second layer GBM model that fuses model predictions (model stacking). Here, we used predictions of our CNN model (Model6) and predictions of the strongest reference model (Model5) as input features for the second level GBM model (Figure 8). Same 5-fold stratified cross validation setup was used. This model (Model8) yielded the best AUC of 0.937 (0.929, 0.945) and AP of 0.791 (0.768, 0.813) and the Brier score of 0.069. This increase in AUC was also statistically significant (DeLong's p-value< 1e - 5) between the stacked model (Model8) and the CNN model (Model6).
For comprehensiveness, we also tested fusion of texture features (LBP) and clinical assessments and participant characteristics (age, sex, BMI, WOMAC, KL) in the same GBM model (See Supplementary Figure 11). ROC and PR curves of the fused model are shown in the Supplementary Material in Figure 12. Fused model yielded AUC of 0.904 (0.892, 0.913) and AP of 0.719 (0.693, 0.743). While fused model (Model7) performed significantly better than the texture model (Model1) in terms of AUC (DeLong's p-value< 1e - 5), it is still not better than the stacked model (Model8).
Discussions and Conclusions
In this study, we presented a machine learning method based on textural features of patella to detect PFOA from lateral view knee x-rays. Texture features were ex-

Bayramoglu et al.

Page 10 of 18

True positive rate Precision

1.0

0.9

0.8

0.7

0.6

0.5

0.4

0.3 0.2 0.1 0.0
0.0

Texture - LBP (AUC= 0.884 [0.871, 0.895]) AGE, SEX, BMI (AUC= 0.647 [0.626, 0.666]) AGE, SEX, BMI, WOMAC (AUC= 0.715 [0.696, 0.732]) AGE, SEX, BMI, KL (AUC= 0.812 [0.798, 0.826]) AGE, SEX, BMI, WOMAC, KL (AUC= 0.817 [0.802, 0.831]) 0.1 0.2 0.3 Fa0l.s4e po0s.i5tive0r.a6te 0.7 0.8 0.9 1.0

1.0

0.9

0.8

0.7

0.6

0.5

0.4

0.3 0.2 0.1 0.0
0.0

Texture - LBP (AP= 0.697 [0.669, 0.722]) AGE, SEX, BMI (AP= 0.294 [0.273, 0.317]) AGE, SEX, BMI, WOMAC (AP= 0.351 [0.325, 0.378]) AGE, SEX, BMI, KL (AP= 0.47 [0.441, 0.5]) AGE, SEX, BMI, WOMAC, KL (AP= 0.487 [0.457, 0.517]) 0.1 0.2 0.3 0.4 Re0c.5all 0.6 0.7 0.8 0.9 1.0

Figure 7: Comparison of texture features and clinical data. (a) ROC and (b) PR curves demonstrating the performance of the gradient boosting machine (GBM) models. Superior region of interest(ROI) with Local Binary Pattern (LBP) features were employed to train the texture model. Area under the curves and 95% confidence intervals in parentheses were given based on a 5-fold cross validation setting. Dashed lines in ROC indicate the performance of a random classifier and in case of PR it indicates the distributions of the labels of the dataset (PFOA vs non-PFOA).

PFOA Probability
Deep CNN

Imaging Data
Age, Sex, BMI, WOMAC, KL Clinical Data

GBM
PFOA Probability

GBM

Final Prediction
PFOA Probability

Figure 8: Schematic representation of model stacking.

tracted both by handcrafted descriptor (LBP) and also learned directly from texture patches using CNNs. We compared-texture based models with more conventional models that use clinical assessments and participant characteristics (age, sex, BMI, WOMAC,KL). The model that uses only texture features obtained from superior ROI from patellar region yielded statistically significant improvement over the clinical features (ROC AUC of 0.884 vs. 0.817). This finding suggests that patellar texture features can provide useful imaging biomarkers for OA diagnostics.

Bayramoglu et al.

Page 11 of 18

The highest ROC AUC and AP for classifying knees without and with PFOA were obtained when model predictions based on texture features and clinical data were combined into a second level machine learning model. This can be explained by the fact that the textural features of patellar bone and the clinical features are complementing each other. Model stacking outperformed early feature fusion because the former method allow each classifier to include their own benefits.
We tested three different ROIs for texture analysis. Texture features from the superior ROI had the highest classification performance to distinguish between knees with and without PFOA. We observed a performance decrease when we used the whole patellar region for predicting PFOA compared to superior and inferior ROI. These findings suggest that the area closest to the inferior margin of the patella, where osteophytes typically occur, experience the most significant bony changes in PFOA.
This study has also limitations. The most important one is the lack of external data for validating the performances of the models. Therefore, we adopted the cross fold validation strategy to evaluate them. However, the actual generalizability of the models could only be understood on a separate test data that comes from different sources (population, hospital, device, etc.). However, because the patellofemoral OA is not studied as much as tibiofemoral OA, the number of PFOA-focused dataset is limited. Second, PFOA is not only altering the bone structure but at the same time changes the morphology and the alignment of patella [36]. In future studies, models that consider patella morphology and alignment should be explored and the additional value of textural features on the diagnosis of PFOA should be studied. Third, other views of patella such as skyline view should be analysed to confirm the location of the bone alterations. Finally, in order to extract texture features, we employed rectangular ROIs. In some cases such ROI could overlap with the background that might slightly affect the results. In principle, adopting ROIs that adhere to the boundaries would be better, but this requires exact segmentation of the patellar region, and it might also lead to a non-constant ROI size further affecting the standardized comparisons between different subjects.
In conclusion, we present the first study that evaluates patellar bone texture for detecting PFOA. Our results show that texture features of patellar bone are different between knees with and without PFOA. Good classification performance values indicate that analyzed texture features contain useful information of patellar bone structure, which seems to change in PFOA. These texture features may be used in the future as novel imaging biomarkers in OA diagnostics.

Bayramoglu et al.

Page 12 of 18

Acknowledgements Multicenter Osteoarthritis Study (MOST) Funding Acknowledgment. MOST is com-
prised of four cooperative grants (Felson ­ AG18820; Torner ­ AG18832, Lewis ­ AG18947, and Nevitt ­ AG19069) funded by the National Institutes of Health, a branch of the Department of Health and Human Services, and conducted by MOST study investigators. This manuscript was prepared using MOST data and does not necessarily reflect the opinions or views of MOST investigators.
We would like to acknowledge the strategic funding of the University of Oulu, Infotech Oulu.
We gratefully acknowledge Claudia Lindner for providing the BoneFinder® tool and lateral knee active shape model, Aleksei Tiulpin for providing an interface to BoneFinder to fully leverage multiple processors, and the support of NVIDIA Corporation with the donation of the Quadro P6000 GPU used in this research.
Funding Funding sources are not associated with the scientific contents of the study.
Competing interests The authors declare that they have no competing interests.
Authors' contributions N.B. originated the idea of the study. N.B. performed the experiments and took major
part in writing of the manuscript. M.T.N, and S.S. supervised the project. All authors participated in producing the final manuscript draft and approved the final submitted version.
Summary Table · We present the first study that evaluates patellar bone texture for detecting patellofemoral osteoarthritis (PFOA). · We proposed a framework based on machine learning and performed extensive experiments to demonstrate the influence of texture features on the diagnostic performance. · Different region of interests (ROIs) from patellar region from lateral view radiographs (X-rays) were studied whether texture features can be used to distinguish the knees with definite radiographic PFOA from healthy knee radiographs. · We compared the performances of hand-crafted features, deep convolutional neural network features, and clinical variables including age, sex, body mass index (BMI), the total Western Ontario and McMaster Universities ArthritisIndex (WOMAC) score, and Kellgren and Lawrence (KL) score of the tibiofemoral joint. · Finally, we propose a stacked model where both patellar texture and clinical feature predictions are combined with a second level machine learning model - Gradient Boosting Machine (GBM). · Our results show that texture features of patellar bone are different between knees with and without PFOA. · Good classification performance values indicate that analyzed texture features contain useful information of patellar bone structure, which seems to change in PFOA. · Patellar bone texture features may be used in the future as novel imaging biomarkers in OA diagnostics.
Author details 1Research Unit of Medical Imaging, Physics and Technology, University of Oulu, Oulu, Finland. 2Department of Diagnostic Radiology, Oulu University Hospital, Oulu, Finland. 3Medical Research Center, University of Oulu and Oulu University Hospital, Oulu, Finland.

Bayramoglu et al.

Page 13 of 18

References 1. Bijlsma, J.W., Berenbaum, F., Lafeber, F.P.: Osteoarthritis: an update with relevance for clinical practice. The Lancet 377(9783), 2115­2126 (2011) 2. Kokkotis, C., Moustakidis, S., Papageorgiou, E., Giakas, G., Tsaopoulos, D.: Machine learning in knee osteoarthritis: A review. Osteoarthritis and Cartilage Open, 100069 (2020) 3. Hinman, R., Crossley, K.: Patellofemoral joint osteoarthritis: an important subgroup of knee osteoarthritis (2007) 4. Altman, R.D., Gold, G.: Atlas of individual radiographic features in osteoarthritis, revised. Osteoarthritis and cartilage 15, 1­56 (2007) 5. Kohn, M.D., Sassoon, A.A., Fernando, N.D.: Classifications in brief: Kellgrenlawrence classification of osteoarthritis. Clinical Orthopaedics and Related Research® 474(8), 1886­1893 (2016) 6. Altman, R., Asch, E., Bloch, D., Bole, G., Borenstein, D., Brandt, K., Christy, W., Cooke, T., Greenwald, R., Hochberg, M., et al.: Development of criteria for the classification and reporting of osteoarthritis: classification of osteoarthritis of the knee. Arthritis & Rheumatism: Official Journal of the American College of Rheumatology 29(8), 1039­1049 (1986) 7. Lee, L.S., Chan, P.K., Fung, W.C., Chan, V.W.K., Yan, C.H., Chiu, K.Y.: Imaging of knee osteoarthritis: A review of current evidence and clinical guidelines. Musculoskeletal Care (2020) 8. Kellgren, J., Lawrence, J.: Radiological assessment of osteo-arthrosis. Annals of the rheumatic diseases 16(4), 494 (1957) 9. Tan, J.M., Menz, H.B., Munteanu, S.E., Collins, N.J., Hart, H.F., Donnar, J.W., Cleary, G., O'Sullivan, I.C., Maclachlan, L.R., Derham, C.L., et al.: Can radiographic patellofemoral osteoarthritis be diagnosed using clinical assessments? Musculoskeletal Care (2020)
10. Stefanik, J., Duncan, R., Felson, D., Peat, G.: Diagnostic performance of clinical examination measures and pain presentation to identify patellofemoral joint osteoarthritis. Arthritis care & research 70(1), 157­161 (2018)
11. Bayramoglu, N., Nieminen, M.T., Saarakkala, S.: Automated detection of patellofemoral osteoarthritis from knee lateral view radiographs using deep learning: Data from the multicenter osteoarthritis study (MOST). CoRR abs/2101.04350 (2021). 2101.04350
12. Duncan, R., Peat, G., Thomas, E., Hay, E., Croft, P.: Incidence, progression and sequence of development of radiographic knee osteoarthritis in a symptomatic population. Annals of the rheumatic diseases 70(11), 1944­1948 (2011)
13. Stefanik, J.J., Guermazi, A., Roemer, F.W., Peat, G., Niu, J., Segal, N.A., Lewis, C.E., Nevitt, M., Felson, D.T.: Changes in patellofemoral and tibiofemoral joint cartilage damage and bone marrow lesions over 7 years: the multicenter osteoarthritis study. Osteoarthritis and cartilage 24(7), 1160­1166 (2016)
14. van Middelkoop, M., Bennell, K.L., Callaghan, M.J., Collins, N.J., Conaghan, P.G., Crossley, K.M., Eijkenboom, J.J., van der Heijden, R.A., Hinman, R.S., Hunter, D.J., et al.: International patellofemoral osteoarthritis consortium: consensus statement on the diagnosis, burden, outcome measures, prognosis, risk factors and treatment. In: Seminars in Arthritis and Rheumatism, vol. 47, pp. 666­675 (2018). Elsevier
15. Bayramoglu, N., Tiulpin, A., Hirvasniemi, J., Nieminen, M.T., Saarakkala, S.: Adaptive segmentation of knee radiographs for selecting the optimal roi in texture analysis. Osteoarthritis and Cartilage (2019). doi:10.1016/j.joca.2020.03.006
16. Bayramoglu, N., Nieminen, M.T., Saarakkala, S.: A lightweight CNN and joint shape-joint space (js2) descriptor for radiological osteoarthritis detection. In: Medical Image Understanding and Analysis - 24th Annual Conference, MIUA 2020, Oxford, UK, July 15-17, 2020, Proceedings. Communications in Computer and In-

Bayramoglu et al.

Page 14 of 18

formation Science, vol. 1248, pp. 331­345. Springer, ??? (2020) 17. Hirvasniemi, J., Thevenot, J., Guermazi, A., Podlipsk´a, J., Roemer, F.W., Niemi-
nen, M.T., Saarakkala, S.: Differences in tibial subchondral bone structure evaluated using plain radiographs between knees with and without cartilage damage or bone marrow lesions-the oulu knee osteoarthritis study. European radiology (2017) 18. Janvier, T., Toumi, H., Harrar, K., Lespessailles, E., Jennane, R.: Roi impact on the characterization of knee osteoarthritis using fractal analysis. In: IPTA, pp. 304­308 (2015). IEEE 19. Friedman, J.H.: Greedy function approximation: a gradient boosting machine. Annals of statistics, 1189­1232 (2001) 20. Lindner, C., Thiagarajah, S., Wilkinson, J.M., Wallis, G.A., Cootes, T.F., arcOGEN Consortium, et al.: Fully automatic segmentation of the proximal femur using random forest regression voting. IEEE transactions on medical imaging 32(8), 1462­1472 (2013) 21. Altman, R.D., Hochberg, M., Murphy Jr, W.A., Wolfe, F., Lequesne, M.: Atlas of individual radiographic features in osteoarthritis. Osteoarthritis and cartilage 3(SUPPL. A), 3­70 (1995) 22. Chaisson, C., Gale, D., Gale, E., Kazis, L., Skinner, K., Felson, D.: Detecting radiographic knee osteoarthritis: what combination of views is optimal? Rheumatology 39(11), 1218­1221 (2000) 23. Roemer, F., Guermazi, A., Hunter, D., Niu, J., Zhang, Y., Englund, M., Javaid, M., Lynch, J., Mohr, A., Torner, J., et al.: The association of meniscal damage with joint effusion in persons without radiographic osteoarthritis: the framingham and most osteoarthritis studies. Osteoarthritis and cartilage 17(6), 748­753 (2009) 24. Lynch, J., Hawkes, D., Buckland-Wright, J.: Analysis of texture in macroradiographs of osteoarthritic knees, using the fractal signature. Physics in Medicine & Biology 36(6), 709 (1991) 25. Janvier, T., Jennane, R., Toumi, H., Lespessailles, E.: Subchondral tibial bone texture predicts the incidence of radiographic knee osteoarthritis: data from the osteoarthritis initiative. Osteoarthritis and cartilage 25(12), 2047­2054 (2017) 26. Kraus, V.B., Collins, J.E., Charles, H.C., Pieper, C.F., Whitley, L., Losina, E., Nevitt, M., Hoffmann, S., Roemer, F., Guermazi, A., et al.: Predictive validity of radiographic trabecular bone texture in knee osteoarthritis: the osteoarthritis research society international/foundation for the national institutes of health osteoarthritis biomarkers consortium. Arthritis & Rheumatology (2018) 27. Veenland, J., Grashuis, J., van der Meer, F., Beckers, A., Gelsema, E.: Estimation of fractal dimension in radiographs. Medical physics 23(4), 585­594 (1996) 28. Ojala, T., Pietik¨ainen, M., M¨aenp¨a¨a, T.: Multiresolution gray-scale and rotation invariant texture classification with local binary patterns. IEEE Transactions on Pattern Analysis & Machine Intelligence (7), 971­987 (2002) 29. Buckland-Wright, C.: Subchondral bone changes in hand and knee osteoarthritis detected by radiography. Osteoarthritis and cartilage 12, 10­19 (2004) 30. Kamibayashi, L., Wyss, U., Cooke, T., Zee, B.: Trabecular microstructure in the medial condyle of the proximal tibia of patients with knee osteoarthritis. Bone 17(1), 27­35 (1995) 31. Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., Ye, Q., Liu, T.-Y.: Lightgbm: A highly efficient gradient boosting decision tree. In: Advances in Neural Information Processing Systems, pp. 3146­3154 (2017) 32. Goodfellow, I., Bengio, Y., Courville, A.: Deep Learning. MIT Press, ??? (2016).
http://www.deeplearningbook.org 33. Nielsen, M.A.: Neural Networks and Deep Learning vol. 25. Determination press
San Francisco, CA, ??? (2015) 34. Brier, G.W.: Verification of forecasts expressed in terms of probability. Monthly
weather review 78(1), 1­3 (1950)

Bayramoglu et al.

Page 15 of 18

35. DeLong, E.R., DeLong, D.M., Clarke-Pearson, D.L.: Comparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach. Biometrics, 837­845 (1988)
36. Macri, E.M.: Patellofemoral osteoarthritis: characterizing knee alignment and morphology. PhD thesis, University of British Columbia (2017)

Bayramoglu et al.

Page 16 of 18

Supplementary
Deep Convolutional Neural Network Architecture and Training Strategy
Conv 1 (3x3, stride =1, pad =1, input =1, filter_output = 32 ) Batch Norm 2D Max. Pooling ReLU
Conv 2 (3x3, stride =1, pad =1, input =32, filter_output = 64 ) Batch Norm 2D Max. Pooling ReLU
Conv 3 (3x3, stride =1, pad =1, input =64, filter_output = 128 ) Batch Norm 2D Max. Pooling ReLU
Linear (8192, 128) Dropout (0.5) Linear (128, 1)
Figure 9: Network Architecture
The CNN model consists of 3 convolutional layers dedicated to texture feature extraction. Each convolution layer (stride=1, padding =1) is followed by Batch normalization (BN), max pooling (2 × 2) and ReLU. After feature extraction, we used two fully connected layers to make the prediction. A dropout of 0.5 is inserted after the first fully connected layer.
In all the CNN based experiments, we used the same training strategy. We trained the models from scratch (end-to-end) using the random weight initialization. We adopted stochastic gradient descent training on a GPU. A mini-batch of 64 images were employed, and a momentum of 0.9 was used and trained without weight decay. We used a starting learning rate of 0.01 and decreased it by 10 every 8 epochs. The models were trained for 40 epochs and we selected the best performed model.

Bayramoglu et al.

Page 17 of 18

True positive rate Precision

1.0

1.0

0.9

0.9

0.8

0.8

0.7

0.7

0.6

0.6

0.5

0.5

0.4

0.4

0.3

0.3

0.2

0.2

0.1 0.0
0.0

Texture - LBP (AUC= 0.884 [0.871, 0.895]) Texture - CNN (AUC= 0.889 [0.875, 0.9])PFOA 0.1 0.2 0.3 Fa0l.s4e po0s.i5tDiveee0rp.a6teCN0N.7Pro0.b8abi0li.t9y 1.0

0.1

Texture - LBP (AP= 0.697 [0.669, 0.722])

0.0

Texture - CNN (AP= 0.714 [0.687, 0.739])

0.0

0.1 0.2 0.3
Final

0.4 Re0c.5all 0.6

0.7

0.8

0.9

1.0

Prediction

GBM

Figure 10: (a) ROC and (b) PR curves demonstrating the performance of the texture

Imaging Data

PFOA

models- CNN vs LBP. Area under the curves anPdro9b5ab%ilitcyonfidence intervals in

Age, Speaxr, eBnMtIh, WesOeMsAwCe, KreL givenGbBaMsed on a 5-fold cross validation setting. Dashed lines in

RCOlinCicailnDdaitcaate

the

performancePoFfOaA random
Probability

classifier

and

in

case

of

PR

it

indicates

the distributions of the labels of the dataset (PFOA vs non-PFOA).

Imaging Data Clinical Data

LBP Features Age Sex BMI
WOMAC KL

GBM

PFOA Probability

Figure 11: Schematic representation of feature fusion where texture features (LBP) and clinical data were combined in the same model. Performance of the fused model is shown in Figure 12.

Bayramoglu et al.

Page 18 of 18

True positive rate Precision

1.0

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2 0.1 0.0
0.0

Texture- LBP (AUC= 0.884 [0.871, 0.895]) Fusion (Texture + Clinical) (AUC= 0.904 [0.892, 0.913]) Stacking (AUC= 0.937 [0.929, 0.945]) 0.1 0.2 0.3 Fa0l.s4e po0s.i5tive0r.a6te 0.7 0.8 0.9 1.0

1.0

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2 0.1 0.0
0.0

Texture- LBP (AP= 0.697 [0.669, 0.722]) Fusion (Texture + Clinical) (AP= 0.719 [0.693, 0.743]) Stacking (AP= 0.791 [0.768, 0.813]) 0.1 0.2 0.3 0.4 Re0c.5all 0.6 0.7 0.8 0.9 1.0

Figure 12: (a) ROC and (b) PR curves demonstrating the performance of the texture (LBP) model, fused model (that combines texture features and clinical data in the same model as shown in Figure 11) and stacked model (Figure 8). Area under the curves and 95% confidence intervals in parentheses were given based on a 5-fold cross validation setting. Dashed lines in ROC indicate the performance of a random classifier and in case of PR it indicates the distributions of the labels of the dataset (PFOA vs non-PFOA).

