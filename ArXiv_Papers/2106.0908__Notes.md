
# TransMIL: Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classication

[arXiv](https://arxiv.org/abs/2106.0908), [PDF](https://arxiv.org/pdf/2106.0908.pdf)

## Authors

- Zhuchen Shao
- Hao Bian
- Yang Chen
- Yifeng Wang
- Jian Zhang
- Xiangyang Ji
- Yongbing Zhang

## Abstract

Multiple instance learning (MIL) is a powerful tool to solve the weakly supervised classification in whole slide image (WSI) based pathology diagnosis. However, the current MIL methods are usually based on independent and identical distribution hypothesis, thus neglect the correlation among different instances. To address this problem, we proposed a new framework, called correlated MIL, and provided a proof for convergence. Based on this framework, we devised a Transformer based MIL (TransMIL), which explored both morphological and spatial information. The proposed TransMIL can effectively deal with unbalanced/balanced and binary/multiple classification with great visualization and interpretability. We conducted various experiments for three different computational pathology problems and achieved better performance and faster convergence compared with state-of-the-art methods. The test AUC for the binary tumor classification can be up to 93.09% over CAMELYON16 dataset. And the AUC over the cancer subtypes classification can be up to 96.03% and 98.82% over TCGA-NSCLC dataset and TCGA-RCC dataset, respectively.

## Comments



## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{shao2021transmil,
      title={TransMIL: Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classication}, 
      author={Zhuchen Shao and Hao Bian and Yang Chen and Yifeng Wang and Jian Zhang and Xiangyang Ji and Yongbing Zhang},
      year={2021},
      eprint={2106.00908},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

## Notes

Type your reading notes here...

