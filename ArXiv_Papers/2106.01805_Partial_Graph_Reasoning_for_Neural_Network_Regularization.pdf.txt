Partial Graph Reasoning for Neural Network Regularization

arXiv:2106.01805v1 [cs.LG] 3 Jun 2021

Tiange Xiang

Chaoyi Zhang

Yang Song

University of Sydney

University of Sydney University of New South Wales

txia7609@uni.sydney.edu.au chaoyi.zhang@sydney.edu.au yang.song1@unsw.edu.au

Siqi Liu Paige AI lsqshr@gmail.com

Hongliang Yuan Tencent AI Lab haroldyuan@tencent.com

Weidong Cai University of Sydney tom.cai@sydney.edu.au

Abstract
Regularizers helped deep neural networks prevent feature co-adaptations. Dropout, as a commonly used regularization technique, stochastically disables neuron activations during network optimization. However, such complete feature disposal can affect the feature representation and network understanding. Toward better descriptions of latent representations, we present DropGraph that learns regularization function by constructing a stand-alone graph from the backbone features. DropGraph first samples stochastic spatial feature vectors and then incorporates graph reasoning methods to generate feature map distortions. This add-on graph regularizes the network during training and can be completely skipped during inference. We provide intuitions on the linkage between graph reasoning and Dropout with further discussions on how partial graph reasoning method reduces feature correlations. To this end, we extensively study the modeling of graph vertex dependencies and the utilization of the graph for distorting backbone feature maps. DropGraph was validated on four tasks with a total of 7 different datasets. The experimental results show that our method outperforms other state-of-the-art regularizers while leaving the base model structure unmodified during inference. Our project page is available at https://dropgraph.github.io/.

1 Introduction

Dropout [33] has been widely used for reducing feature co-adaptation in deep neural networks. With the success of using Dropout as a regularization technique, many recent works have studied the impact of allowing dropout in neural networks theoretically [1, 37] and empirically [32, 17]. In a classic paradigm, neurons are dropped randomly following the Bernoulli distribution with a specific dropout rate  during training, such that:

fDropout(X) =  · X,

(1)

where X is the incoming signals and   Bernoulli() is a gating 0-1 Bernoulli variable, with probability  for  to be 0 and thus dropping out neuron activations. However, this classic approach is primarily targeted on fully-connected linear layers and has little effect on multi-dimensional feature maps with strong spatial correlations.

Considering spatial tensors in image-oriented Convolutional Neural Networks (CNNs), Tompson et al. [35] experimented with dropping out the spatial feature vectors across all channels, which they called SpatialDropout. When neuron activations pass through such layers, spatial feature vectors are binary gated with only two possible states: identity or none. Several recent works [19, 11, 4, 34, 46, 26] followed the same intuition and applied dropout in more structured forms.

We argue that the gist of Dropout lies in distorting information propagation of co-adapted signals by random weakening inter-neuron dependencies. The neuron activation distribution varies during network optimization and ends up with information spreading over all neurons uniformly. To this end, applying appropriate distortions to the feature maps could accomplish the same regularization

Preprint.

effect. This has also been pointed out by [34]. Instead of zeroing out X directly, signals can also be obscured by binary gating an extra distortion term, which can thus be formulated as:

fregularization(X) =  · X + (1 - ) · R,

(2)

where R is the appended distortions and   Bernoulli(). This equation splits Eq. 1 into two parts: the origin term and the distortion term, which also generalizes dropout-based methods [33, 35] when there is no distortions i.e. R = 0.
In this paper, R in Eq. 2 is proposed to be input-sensitive and generated from additional functional modules. Inspired by graph reasoning approaches [5, 20], we build a stand-alone graph, which is separated from backbone network, to generate distortions R. In common graph reasoning practices [5, 20], image-space features are initially transformed into graph-space, which is computational inefficient. Towards an efficient implementation, we focus on randomly sampled feature vectors only, hence building up a compact graph with little overhead computations. The samples are subsequently propagated in the graph through basic graph message passing layers. During inference, we completely Drop the Graph, and the regularized backbone network obtains immediate performance improvement without any additional computations.
Our main contributions are two-fold: (1) We propose a learnable regularization scheme, namely DropGraph, which dynamically regularizes networks based on graph reasoning. The stand-alone regularizing graph generates distortions based on randomly sampled feature vectors, and is dropped during inference yet the regularized learning provides marked performance improvement. Motivations and intuitions are clearly clarified with preliminary trails and in-depth discussions. (2) The effectiveness of DropGraph is empirically validated on numerous benchmarks, including: image classification, image semantic segmentation, point cloud classification, and graph recognition. DropGraph outperforms its state-of-the-art counterparts numerically and statistically. Detailed ablative experiments were additionally conducted to provide a comprehensive analysis of our proposed method.

2 Related Works
Network Regularization. Regularization techniques in neural networks aim to reduce feature co-adaptation and, therefore, overcome data over-fitting. As one of the most commonly used regularization techniques, L2-norm regularizer adds weight decay terms to the loss function for penalizing model complexity. StochasticDepth [15] is another regularization technique in deep neural networks, which reduces the model complexity by skipping network layers stochastically. DropConnect [38] randomly samples a subset of the network and zeros out their weights. Instead of regularizing networks directly, there have been recent works which increased network generalization ability through advanced data augmentation. CutMix [44] combines Cutout [8] and Mixup [45] that fills randomly removed patches with unrelated contents. AutoAugment [6] searches augmentation policies in a specific search space. Recently, Li et al. [21] studied network regularization from a new perspective, which combined the biological activations in cortical visual areas of mice and neural networks. The networks were then regularized by the intermediate representation similarity. We revisit network regularization by enabling learnable distortion terms to be appended on randomly sampled spatial vectors.
Dropout-based Approaches. These methods have been tested to be effective in regularizing deep networks. Extending from the vanilla dropout [33], recent works have studied the feasibility of dropping out different signal types and proposed several structured dropout variants. DropPath [19] and ScheduledDropPath [46] drop layer-to-layer connections in multi-branch building blocks. DropBlock [11, 7], as a close extension to SpatialDropout [35], drops a block of spatial feature vectors simultaneously. Following DropBlock, AutoDropout [26] utilized an external controller to automatically search for the most suitable Dropout patterns for each individual architecture. Rather than wiping out neuron activations completely, Tang et al. [34] adopted a similar approach to ours that generates feature map distortions. However, their so-called distortion policy starts from reducing the intermediate Rademacher complexity, while we focus on modeling feature sample correlations through graph reasoning methods. Moreover, unlike most of these existing approaches, which were majorly evaluated on image classification tasks, our DropGraph is also verified on semantic segmentation, point cloud classification and graph recognition tasks.
2

high
low X

Top sampling V = TOPK(X, *||X||)

Random sampling V ~ Bernoulli(X, )


12.5% 25.0% 50.0% 100.0%

Top Train/Inf. Train

78.61 78.88 77.95 75.99

77.65 77.28 76.26 75.49

Random Train/Inf. Train

77.80 77.92 77.75 75.44

79.29 79.42 79.03 2.5

Figure 1: Left: Two sampling strategies to construct graph vertices V from feature map X. Right: CIFAR 100 validation accuracy on the two sampling strategies with different sampling rate . `Train/Inf.' denotes enabling the graph during both network training and inference while `Train' denotes during network training only. Highlighted cells represent results better than the plain ResNet-50 network.

3 Methods

Consider a graph G = (V, A) with vertex set V and adjacency matrix A, which is separated from the backbone network. We first depict the commonly adopted graph reasoning methods in imageprocessing networks and then discuss how such graphs can be used for regularization. Subsequently, we introduce DropGraph, a graph-based regularizer that utilizes G to learn dynamic distortions.

3.1 Graph Reasoning as Regularization

Graph Reasoning (GR) methods have been proved effective in learning spatial relationship [20, 5, 12]. In a classic paradigm, image-space feature maps X at a layer could be first projected into discrete graph node embeddings [20, 5] and are further transformed through consecutive GCN layers [16], which are then re-projected back to the original feature maps, such that:

fGR(X) = X + AXW,

(3)

where A is a valid adjacency matrix, and W is the learnable weight.

Towards better computational efficiency, we posit that the graph contains sufficient representative clues hidden inside X by constructing V with only a subset of its feature vectors. In this way, we set up a sampling ratio  to control the portion of feature vectors in X to be selected as the graph vertices such that V  X (V  X when  = 100% and V   when  = 0%). And the Partial Graph Reasoning (PGR) module can be extended from Eq. 3 as:

fP GR(X) = X \ V + AVW.

(4)

To validate our claim above, preliminary trials are conducted on incorporating Eq. 4 after the bottleneck convolution in last two building groups of a ResNet-50 backbone. In Figure 1, we investigate constructing V with either top activated or randomly sampled feature vectors in X. The impacts of enabling the constructed graph during network training and inference are demonstrated with following observations: (1) Additional graph reasoning module with sampling ratio  < 100% improves backbone network performance generally (highlighted cells). (2) Disabling randomly sampled PGR modules during network inference enhances performance the most.

Linking between graph reasoning and Dropout. Given the above observations, we find that additional graph reasoning module with random sampling ratio   (0, 1) analogizes to Dropout (Eq. 1). Inspired by which, we can easily reformulate Eq. 4 to the same form as Eq. 2 by specifying the distortion term R as the output of graph reasoning:

fregularization(X) =  · X \ V + (1 - ) · AVW,

(5)

where V  Bernoulli(X, ) and   Bernoulli(). By skipping the graph during network inference, the behaviour of such partial graph reasoning aligns to Dropout, and it therefore can be reformulated as another form of regularization. However, questions still remain on how to generate a valid adjacency matrix A and how to ensure the regularization effect, which will be discussed later.

Why partial graph reasoning regularizes networks? In CNNs, feature maps are generated by sliding fixed convolution kernels across each pixel with limited receptive field. Such paradigm enforces local correlations in the same neighborhood and easily leads to feature co-adaptations. Eq. 5 alleviates the co-adaptation from two perspectives: First, appended distortions break the conventional convolution pattern and disturb inter-pixel correlations at random positions, which has also been discussed in [34]; Second, local pixel responses are replaced by the enhanced graph vertices, enabling long-range dependencies to be established out of the convolution neighborhood.

3

!"# ! = !×
~() !
DropBlock

Training

!"#

 = expand(, )×(1 - )

 + !

 = avg((, ))
A=Eq. 6

! = !×

 = {$}

~()

$ ~()

!
DropGraph

Algorithm 1 DropGraph Input: X  Rw×h×c, mode, s,
, and . Output: X  Rw×h×c 1: if mode == Inference then 2: return X 3: end if
#########initialize######## 4: V = sample(, X) 5: M = sample(, X, s)
####generate distortions#### 6: A  Eq. 6 7: R = average((A, V)) !"# = ! 8: R = expand(R, M)
#####apply distortions##### Inference 9: X = X · M + R · (1 - M)
10: return X

Figure 2: Instead of dropping out randomly sampled feature vectors, our method learns distortions during network training. DropGraph is completely skipped during inference. `·' denotes broadcastly multiplication.

3.2 DropGraph: A Learnable Graph-based Neural Network Regularizer

In this subsection, we introduce DropGraph, a graph-based regularizer that learns to generate distortions from input feature maps. The regularization process (Figure 2 left) is achieved via two branches, namely mask branch and graph branch which are controlled by the distortion probability  and the sampling rate , respectively.

In the mask branch, a distortion map M is sampled by binarily gating neurons based on the Bernoulli variable . Instead of gating individual pixels [33, 35], we sample M as spatially contiguous square blocks with block size s following [11, 34].

In the graph branch, the graph vertices V = {v} are sampled according to . Then, an adjacency matrix A is constructed among all vertices {v} through a similarity measurement function sim(·, ·). A and V are subsequently fed into a distortion generator  to infer vertex-to-vertex distortions, which are then channel-wise average pooled, expanded and applied on the M masked input features. During network training, the graph weights W are jointly optimized with the backbone network by sharing the same gradient flows. To maintain the completeness of feature representations at an initial learning stage,  is adjusted from 0% to the target value following a predefined scheduler. We employ DropGraph modules after each activation layer at both feature extraction branch and skip shortcut branch. The DropGraph algorithm is presented in Figure 2 right.

Dependency modeling. Recall that the purpose of regularizers lies in reducing pixel-to-pixel dependencies. There are two kinds of pixel relationships modeled by the adjacency matrix A in our graph: intra-dependency (modeled as diagonal values of A) and inter-dependency (modeled as non-diagonal values of A). When A degrades to an all-zero matrix without modeling any dependencies, DropGraph instantiates to DropBlock.

To activate graph reasoning, certain dependencies have to be embedded in A to replace the local ones in a convolution window. To this end, strong connection is expected to be built for any pair of vs that are apart from each other in the feature space. Specifically, we delegate sim(·, ·)1 for constructing A. Semantically closer vertices are therefore assigned with lower values in A while the dissimilar ones
are allocated with higher values. To achieve this, we minus the softmax gated similarity scores from an all-one matrix and then normalize A  (0, 1) by scaling down with their cardinality:

A = 1 - softmax(sim(vi, vj)) ,

(6)

max(||V|| - 1, 1)

where ||·|| denotes cardinality and all arithmetic operations above are in vectorized form which leads to A  R||V||×||V||.
1We implement sim(·, ·) as pair-wise dot product similarity with temperature in practice.

4

Table 1: Comparison results on image classification tasks (%).

Methods

CIFAR CIFAR 10 CIFAR 100

ImageNet

Top-1

Top-5

ResNet-50 [14] + Dropout [33] + SpatialDropout [35] + DropBlock [11] + Disout [34] + DropGraph RegNetX-200MF [28] + Dropout [33] + DropBlock [11] + Disout [34] + DropGraph

93.67±0.11 94.81±0.09 94.92±0.11 95.14±0.11 95.25±0.13 95.35±0.14 93.10±0.10 92.77±0.08 93.05±0.13 93.15±0.11 93.76±0.13

77.73±0.18 77.96±0.13 78.27±0.10 78.71±0.13 78.91±0.15 79.58±0.14 71.57±0.10 71.19±0.12 71.21±0.10 71.66±0.13 71.94±0.15

76.51±0.07 76.80±0.04 77.41±0.04 78.13±0.05 78.33±0.06 78.43±0.04 67.54±0.08 67.59±0.06 67.94±0.05 68.25±0.06 68.77±0.06

93.20±0.05 93.41±0.04 93.74±0.02 94.02±0.02 93.98±0.04 94.05±0.04 88.29±0.05 88.28±0.04 88.44±0.04 88.56±0.04 88.65±0.03

Distortion generation. Given the sampled vertex set V and the adjacency matrix A, we utilize a set of basic graph message passing rules (V, A) to generate distortions. Towards better efficiency and less computation burdens during training, we incorporate two GCN bottlenecks at the ends of  with a channel reduction ratio of 4. Another residual GCN is adopted within the bottleneck for better information propagation. All GCN layers in our DropGraph share the same constructed A. After average pooling the distortions, following [34], we apply random multipliers within (0, 1) at all sampled units masked by M.
Comparison with state-of-the-arts. DropGraph resembles previous works with probability scheduling and block distortion, but distinguishes them by the novel re-formulation of graph reasoning as regularization. Such formulation generalizes other Dropout-based regularizers [33, 35, 11] as special cases, and is potentially capable of fitting any possible distortion function including Disout [34].
Compared to a recent work: AutoDropout [26] that also requires additional functional module for regularization, our plug-and-play DropGraph is able to function on various architectures universally. While AutoDropout demands highly customized controllers to adjust dropout patterns dynamically for different architectures. Moreover, AutoDropout needs pre-defined search spaces with carefully tuned parameters which puts many more manual efforts and exceeding run time cost than DropGraph and other counterparts. With close performances, DropGraph yields considerably better accessibility and extensibility during netwokr training.
Towards potential limitations, DropGraph still yields a bit more complex framework than the simplest DropBlock. First, same to Disout, DropGraph requires three hyper-parameters (, , s) which are one more than DropBlock. However, in Sec. 4.5, we demonstrate that DropGraph generally surpasses DropBlock without explicit tuning of the hyper-parameters. Second, DropGraph might put additional computations to the backbone network during training. Nevertheless, the computation overhead is trivial that DropGraph only imposes less than 1 × 10-3 G extra MACs on the ResNet-50 backbone.

4 Experiments
In this section, experimental results are firstly reported on four different tasks across seven datasets. We repeat three independent runs for image classification, semantic segmentation and point cloud classification tasks. For graph recognition task, 100 independent runs were repeated. Subsequently, we conducted extensive studies to analyze DropGraph under different ablative settings with a fixed random seed. All experiments were implemented in PyTorch framework [25] using Tesla V100 GPUs. Please see the supplemental materials for complete implementation and training details.
4.1 DropGraph for Image Classification
Two commonly adopted benchmarks are used to evaluate our method on image classification task. CIFAR 10/100 are comprised of 60000 images of size 32 × 32, with the training set comprised of 50000 images and the validation comprised of 10000 images. The images are evenly distributed into
5

Table 2: Comparison results on semantic segmentation tasks.

Methods

Pascal VOC mIoU (%) mAcc (%) Methods

MoNuSeg mIoU (%) DICE (%)

FCN-32S [23] + DropBlock [11] + Disout [34] + DropGraph DeepLabV3 [2] + DropBlock [11] + Disout [34] + DropGraph

47.1±0.4 50.6±0.3 50.7±0.4 51.0±0.4 53.8±0.3 56.9±0.4 57.2±0.4 58.0±0.2

81.2±0.3 82.1±0.2 82.0±0.3 82.4±0.2 83.5±0.3 83.7±0.3 84.0±0.4 84.6±0.3

U-Net [29] + DropBlock [11] + Disout [34] + DropGraph Att U-Net [24] + DropBlock [11] + Disout [34] + DropGraph

68.2±0.3 67.6±0.8 68.1±0.8 68.5±0.7 68.3±0.2 68.0±0.6 68.3±0.6 68.7±0.5

80.7±0.3 80.2±0.7 80.0±0.8 81.4±0.6 81.1±0.2 81.0±0.4 81.2±0.5 81.5±0.5

Pascal VOC

MoNuSeg

Input

Backbone

+ DropBlock

+ Disout

+ DropGraph

Reference

Figure 3: Qualitative segmentation results. Top: Pascal VOC results on FCN-32S w/ ResNet-50 backbone. Bottom: MoNuSeg results on U-Net.

10 and 100 classes, respectively. The ImageNet dataset is comprised of 1.2M high-resolution training images and 50K validation images, which are distributed into 1K different categories.
To have a comprehensive validation of our DropGraph on both standard and mobile network regimes, we experimented on two network backbones: ResNet-50 [14] and RegNetX-200MF [28]. Only the most basic training strategies are used without advanced tricks including AutoAugment [6] and Exponential Moving Average (EMA) of network weights. Note that Disout is originally trained for twice as many epochs as other methods and achieves slightly better results. For fair comparisons, we align the training procedures and reproduced all results.
For ResNet-50 backbone, we insert DropGraph at all building blocks of the last two building groups [11, 34]. For RegNetX-200MF, DropGraph is inserted at last 3 building blocks of the last building group only.  and  are set to 0.2 and 0.1 respectively in all related experiments. We directly utilize the block size studied in [11] with s = 3 for CIFAR and s = 7 for ImageNet.
Table 1 shows the image classification results on the two backbones comparing to state-of-the-art regularization methods. Compared to non-regularized baselines, the incorporation of DropGraph brings universal performance gains on both datasets without affecting network inference. By generating dynamic distortions, our graph-based regularizer learns the best regularization effects on both backbone networks that outperforms both DropBlock and Disout accordingly on all metrics.

4.2 DropGraph for Semantic Segmentation
DropGraph is then benchmarked on two semantic segmentation datasets: PASCAL VOC 2012 [10] and MoNuSeg [18]. The PASCAL VOC benchmark consists of 21 classes with 20 foreground object classes and one background class. There are 1464 training samples and 1449 validation samples in the original dataset. Following [13, 3], we used the extra annotations to enrich the dataset to contain 10582 training images. The regularization methods were evaluated on two of the most commonly used segmentation networks, FCN [23] and DeepLabV3 [3] with randomly initialized ResNet-50 backbone. The quantitative metrics include intersection-over-union (mIoU) and pixel accuracy (mAcc) averaged across the 21 classes are reported. The nuclei segmentation dataset MoNuSeg is comprised of 30 training and 14 testing microscopy images in size 10002. The scans were sampled from different whole slide images of multiple organs. Following [41], we enrich the

6

Table 3: Results on point cloud classification task.

Methods

M40 (%)

DGCNN [39] + Dropout [33] + SpatialDropout [35] + Disout [34] + DropGraph

92.6±0.3 81.1±0.4 92.9±0.2 93.0±0.3 93.2±0.2

Table 4: Results on graph recognition tasks.

Methods

Cora (%) Protein (%)

GCN [16] + Dropout [33] + SpatialDropout [35] + Disout [34] + DropGraph

82.9±0.5 83.1±0.5 83.2±0.6 82.7±0.6 83.3±0.5

81.5±0.9 80.8±2.1 81.6±1.3 81.7±1.5 82.1±1.7

dataset by extracting 5122 patches at 4 corners. mIoU along with Dice coefficient (DICE) scores are reported for this task. U-Net [29] and Attention U-Net [24] are adopted as the backbone networks for nuclei segmentation.
For FCN and DeepLabV3, regularizers are applied at the last two building groups of the ResNet50 backbone and retain the same hyper-parameters used in image classification tasks, such that  = 0.2,  = 0.1 and s = 7. For U-Net based networks, we insert the regularizers at the last encoder level only with  = 0.1,  = 0.1 and s = 7.
The segmentation results are presented in Table 2. Consistent performance improvements can be observed on both backbone networks and both datasets, hence proving the universal applicability of our DropGraph. Noteworthy, by zeroing out neuron activations, DropBlock leads to even poorer results on a lot of metrics. However, distortion-based methods appeared to be more suitable for such pixel-wise prediction task. Among all the competing methods, DropGraph provides the greatest performance improvements on the randomly initialized backbone networks and shrinks the gap to the ImageNet pre-trained ones. Qualitative comparison results are presented in Figure 3 to intuitively demonstrate the impacts of different regularization methods to the backbone networks.

4.3 DropGraph for Point Cloud Classification
Apart from studies on image data, we conducted subsequent evaluations of our DropGraph on graph-like data. Since DropBlock is not intrinsically applicable for graph signals, we thus compared DropGraph with Dropout, SpatialDropout and Disout. The ModelNet40 dataset [40] was first adopted to verify the potential of DropGraph on 3D point cloud classification task. This 40-class dataset is comprised of 9843 training samples and 2468 testing samples. We adopted the same pre-processing instructions as introduced in [27, 42] to uniformly sample 1024 points from each raw 3D model. The sampled coordinates are further normalized into unit spheres for better network understanding. We utilized DGCNN [39] as the backbone network for all experiments. All regularization methods are equipped after each EdgeConv module with  = 0.15,  = 0.1 and s = 1.
As demonstrated in Table 3, most of the regularizers impact the backbone network positively, except for the plain Dropout that hurts feature representations and leads to inferior results. Among all the competing methods, our DropGraph stands out with the greatest average accuracy improvement (0.6%) that even outperforms more advanced and complicate networks [22, 43].

4.4 DropGraph for Graph Recognition
Lastly, DropGraph was evaluated on the semi-supervised node classification task with the Cora dataset [31] and on the graph classification task with the Protein dataset [9]. Cora is a citation network dataset, consists of only one graph with 2708 nodes (documents) and 5429 undirected edges (citation links). The nodes are distributed into 7 classes with only 20 labeled nodes per class for training. We followed the same training and testing split as in [16]. The Protein dataset consists of 1113 graphs with an average of 39 nodes and 73 edges per graph. The graphs are binary labeled by their enzymatic activity with no particular testing dataset. We utilized a simple two-layer GCN [16] as the backbone network for both datasets and applied regularizers before the second GCN layer only.  is set to 0.15 for both tasks while  is set to 0.1 for Cora and 0.25 for Protein.
The results reported in Table 4 demonstrate that almost all regularizing methods except for Dropout are able to enhance the backbone network further. Among all competing methods, DropGraph yields the greatest average accuracy gains with 0.4% on the Cora dataset and 0.6% on the Protein dataset.

7

TODO
Figure 4: Left: Sampling rate  v.s. ImageNet validation accuracy. Right: Distortion probability  v.s. ImageNet validation accuracy.

Scheduler
f1 f2 f3 f4 f5

Top-1 (%)
78.40 77.36 77.94 77.86 78.43

Top-5 (%)
94.07 93.58 93.85 93.83 94.05

Figure 5: Left: Five candidate schedulers that adjust the distortion probability from 0 to . Right: ImageNet validation results on the five candidate schedulers.

4.5 Ablation Studies

We chose ResNet-50 as the backbone network in the studies, and all experiments were conducted on ImageNet dataset with the same training configures specified in Sec. 4.1. Unless explicitly specified, we used the linear distortion probability scheduler for all ablation studies.

Studies on different designs of A. Different dependency modeling strategies may impact the regu-

larization effect to different extents. To benchmark our design in Eq. 6, we study four alternatives of

A that models distinct intra- and inter-dependencies: (a) A is learned jointly with backbone network

and hence is independent to V. (b) Similar vertices are assigned with high values, such that A =

softmax(sim(V, V)). (c) Only intra-dependencies are modeled, such that A = I becomes an iden-

tity

matrix.

(d)

Both

intra-dependencies

and

inter-dependencies

are

equally

modeled

with

A

=

1
||V||

.

The ablative results of the 4 different designs are nu-

Table 5: ImageNet validation results with differ- merically compared in Table 5. DropGraph is able to

ent designs of the adjacency matrix A.

bring consistent performance gains to the backbone

network with all adjacency matrix designs. We obDesigns of A Top-1 (%) Top-5 (%) served from experiment (a) that by learning a static A

Backbone

76.51

93.20 that is insensitive to the incoming feature distributions

(a)

77.74

93.68 hurts the overall regularization effect provided by Drop-

(b)

78.13

93.88 Graph. Inferior performances are also obtained when

(c)

78.02

93.89 modelling stronger dependencies for similar vertices,

(d)

78.25

93.98 as indicated by experiments (b) and (c). Surprisingly,

Eq. 6

78.40

94.07 experiment (d) reveals that constructing equal connec-

tions between all pair vertices also leads to effective

regularization and ends up with even higher results than DropBlock.

Studies on  and . DropGraph is controlled by the sampling ratio  and the distortion probability . Higher  provides more complete descriptions to the current feature distribution and higher  imposes stronger regularizations. In Figure 4 left, we show that different selections of  bring consistent accuracy improvement to the backbone network that universally outperforms DropBlock. When  = 0.2, DropGraph reaches the highest top-1 accuracy of 78.4%. With the best  found, in Figure 4 right, we demonstrate that DropGraph consistently surpasses DropBlock on all possible  values.

8

P=0.676

P=0.185

P=0.422

P=0.347

Egyptian cat

P=0.927

P=0.085

P=0.263

P=0.154

Monitor

Input

Backbone

+ DropBlock

+ Disout

+ DropGraph

Figure 6: Grad-cam visualizations. Two randomly selected cases from the ImageNet validation set are shown. Gradients are collected toward their predicted classes.

ResNet-50

+ DropBlock

+ Disout

+ DropGraph

Figure 7: t-SNE visualizations on feature representations. Different classes are marked in different colors.

Studies on scheduler. As mentioned in [11, 46], increasing  while training proceeds helps network understanding at the initial learning stage. We here study 5 different  scheduling functions that are shown in Figure 5 left. According to the quantitative results reported in Figure 5 right, DropGraph achieves the best top-1 accuracy with scheduler f5 and the best top-5 accuracy with the linear scheduler. Note that with the same linear scheduler, DropGraph already outperforms DropBlock and Disout by a considerable margin.
Grad-Cam Visualizations. Grad-Cam [30] is widely used to visualize the focus of networks. We are curious whether the focus of backbone network would change when applying different regularization methods. The gradients flowed through last convolutional layer are collected for visualization. Figure 6 compares the network significance heatmaps on two input images with different regularizers. Without regularization, backbone network can be easily distracted and is therefore hard to focus on the primary object. The same problem still exists when employing DropBlock and Disout in the backbone network. However, our DropGraph greatly alleviates such distraction and forces the backbone network to apply more attention to the major object features.
Visualization of feature representations. Regularization methods enable the backbone network to better discriminate input samples. We here adopt t-SNE [36] to visualize the feature representations in CIFAR 10 validation set in Figure 7. The representations are collected before the last linear layer of the ResNet-50 model. Less false predictions are observed by applying DropGraph on the backbone network with all samples being better clustered based on their ground truth labels.

5 Conclusion and Discussion
In this paper, we introduced a learnable framework for neural network regularization, namely DropGraph. Instead of zeroing out information completely, we utilize a stand-alone graph to apply feature map distortions. DropGraph is developed by re-formulating partial graph reasoning modules to analogize Dropout-based regularization with dependency modeled via the adjacency matrix and distortion generated through a set of learnable graph reasoning layers. Our DropGraph outperforms other state-of-the-art regularizers on a variety of tasks and datasets.
Towards the potential negative societal impact, our method would accelerate the risk of information insecurity. By regularizing a hacker model with DropGraph, privacy data stealing and viruses delivery could be taking advantage of which due to the free network performance improvements without additional computation cost.

9

References
[1] Pierre Baldi and Peter J Sadowski. Understanding dropout. In Advances in Neural Information Processing Systems (NeurIPS), pages 2814­2822, 2013.
[2] Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam. Rethinking atrous convolution for semantic image segmentation. arXiv preprint arXiv:1706.05587, 2017.
[3] Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, and Hartwig Adam. Encoder-decoder with atrous separable convolution for semantic image segmentation. In Proceedings of the European conference on computer vision (ECCV), pages 801­818, 2018.
[4] Liyan Chen, Philip Gautier, and Sergul Aydore. Dropcluster: A structured dropout for convolutional networks. arXiv preprint arXiv:2002.02997, 2020.
[5] Yunpeng Chen, Marcus Rohrbach, Zhicheng Yan, Yan Shuicheng, Jiashi Feng, and Yannis Kalantidis. Graph-based global reasoning networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 433­442, 2019.
[6] Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le. Autoaugment: Learning augmentation strategies from data. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 113­123, 2019.
[7] Zuozhuo Dai, Mingqiang Chen, Xiaodong Gu, Siyu Zhu, and Ping Tan. Batch dropblock network for person re-identification and beyond. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), pages 3691­3701, 2019.
[8] Terrance DeVries and Graham W Taylor. Improved regularization of convolutional neural networks with cutout. arXiv preprint arXiv:1708.04552, 2017.
[9] Paul D Dobson and Andrew J Doig. Distinguishing enzyme structures from non-enzymes without alignments. Journal of molecular biology, 330(4):771­783, 2003.
[10] Mark Everingham, SM Ali Eslami, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman. The pascal visual object classes challenge: A retrospective. International journal of computer vision, 111(1):98­136, 2015.
[11] Golnaz Ghiasi, Tsung-Yi Lin, and Quoc V Le. Dropblock: A regularization method for convolutional networks. In Advances in Neural Information Processing Systems (NeurIPS), pages 10727­10737, 2018.
[12] Dalu Guo, Chang Xu, and Dacheng Tao. Graph reasoning networks for visual question answering. arXiv preprint arXiv:1907.09815, 2019.
[13] Bharath Hariharan, Pablo Arbeláez, Lubomir Bourdev, Subhransu Maji, and Jitendra Malik. Semantic contours from inverse detectors. In 2011 International Conference on Computer Vision, pages 991­998. IEEE, 2011.
[14] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770­778, 2016.
[15] Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, and Kilian Q Weinberger. Deep networks with stochastic depth. In European Conference on Computer Vision (ECCV), pages 646­661. Springer, 2016.
[16] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907, 2016.
[17] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems (NeurIPS), pages 1097­1105, 2012.
[18] Neeraj Kumar, Ruchika Verma, Sanuj Sharma, Surabhi Bhargava, Abhishek Vahadane, and Amit Sethi. A dataset and a technique for generalized nuclear segmentation for computational pathology. IEEE Transactions on Medical Imaging, 36(7):1550­1560, 2017.
[19] G Larsson, M Maire, and G Shakhnarovich. Ultra-deep neural networks without residuals. In International Conference on Learning Representations (ICLR), volume 1605, 2017.
[20] Yin Li and Abhinav Gupta. Beyond grids: Learning graph representations for visual recognition. In Advances in Neural Information Processing Systems (NeurIPS), pages 9225­9235, 2018.
10

[21] Zhe Li, Wieland Brendel, Edgar Walker, Erick Cobos, Taliah Muhammad, Jacob Reimer, Matthias Bethge, Fabian Sinz, Zachary Pitkow, and Andreas Tolias. Learning from brains how to regularize machines. In Advances in Neural Information Processing Systems (NeurIPS), pages 9525­9535, 2019.
[22] Yongcheng Liu, Bin Fan, Shiming Xiang, and Chunhong Pan. Relation-shape convolutional neural network for point cloud analysis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8895­8904, 2019.
[23] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3431­3440, 2015.
[24] Ozan Oktay, Jo Schlemper, Loic Le Folgoc, Matthew Lee, Mattias Heinrich, Kazunari Misawa, Kensaku Mori, Steven McDonagh, Nils Y Hammerla, Bernhard Kainz, et al. Attention u-net: Learning where to look for the pancreas. 1st Conference on Medical Imaging with Deep Learning (MIDL), 2018.
[25] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems (NeurIPS), pages 8024­8035, 2019.
[26] Hieu Pham and Quoc V. Le. Autodropout: Learning dropout patterns to regularize deep networks. 2021.
[27] Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 652­660, 2017.
[28] Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr Dollár. Designing network design spaces. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10428­10436, 2020.
[29] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention, pages 234­241. Springer, 2015.
[30] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based localization. In Proceedings of the IEEE international conference on computer vision, pages 618­626, 2017.
[31] Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. Collective classification in network data. AI magazine, 29(3):93­93, 2008.
[32] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. In International Conference on Learning Representations (ICLR), 2015.
[33] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research (JMLR), 15(1):1929­1958, 2014.
[34] Yehui Tang, Yunhe Wang, Yixing Xu, Boxin Shi, Chao Xu, Chunjing Xu, and Chang Xu. Beyond dropout: Feature map distortion to regularize deep neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence, 2020.
[35] Jonathan Tompson, Ross Goroshin, Arjun Jain, Yann LeCun, and Christoph Bregler. Efficient object localization using convolutional networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 648­656, 2015.
[36] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 9(11), 2008.
[37] Stefan Wager, Sida Wang, and Percy S Liang. Dropout training as adaptive regularization. In Advances in Neural Information Processing Systems (NeurIPS), pages 351­359, 2013.
[38] Li Wan, Matthew Zeiler, Sixin Zhang, Yann Le Cun, and Rob Fergus. Regularization of neural networks using dropconnect. In International conference on machine learning, pages 1058­1066, 2013.
[39] Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. Sarma, Michael M. Bronstein, and Justin M. Solomon. Dynamic graph cnn for learning on point clouds. ACM Transactions on Graphics (TOG), 2019.
11

[40] Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. 3d shapenets: A deep representation for volumetric shapes. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 1912­1920, 2015.
[41] Tiange Xiang, Chaoyi Zhang, Dongnan Liu, Yang Song, Heng Huang, and Weidong Cai. Bio-net: Learning recurrent bi-directional connections for encoder-decoder architecture. In International Conference on Medical Image Computing and Computer-Assisted Intervention, pages 74­84. Springer, 2020.
[42] Tiange Xiang, Chaoyi Zhang, Yang Song, Jianhui Yu, and Weidong Cai. Walk in the cloud: Learning curves for point clouds shape analysis. arXiv preprint arXiv:2105.01288, 2021.
[43] Xu Yan, Chaoda Zheng, Zhen Li, Sheng Wang, and Shuguang Cui. Pointasnl: Robust point clouds processing using nonlocal neural networks with adaptive sampling. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5589­5598, 2020.
[44] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo. Cutmix: Regularization strategy to train strong classifiers with localizable features. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 6023­6032, 2019.
[45] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412, 2017.
[46] Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V Le. Learning transferable architectures for scalable image recognition. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition (CVPR), pages 8697­8710, 2018.
12

