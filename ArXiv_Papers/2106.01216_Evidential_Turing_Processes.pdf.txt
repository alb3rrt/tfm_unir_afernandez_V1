arXiv:2106.01216v1 [cs.LG] 2 Jun 2021

Evidential Turing Processes
Melih Kandemir1,2 Abdullah Akgül2 Manuel Haußmann3 Gozde Unal2 1Bosch Center for Artificial Intelligence, Renningen, Germany 2Istanbul Technical University, Istanbul, Turkey 3Heidelberg University, Heidelberg, Germany
Abstract
A probabilistic classifier with reliable predictive uncertainties i) fits successfully to the target domain data, ii) provides calibrated class probabilities in difficult regions of the target domain (e.g. class overlap), and iii) accurately identifies queries coming out of the target domain and reject them. We introduce an original combination of evidential deep learning, neural processes, and neural Turing machines capable of providing all three essential properties mentioned above for total uncertainty quantification. We observe our method on three image classification benchmarks and two neural net architectures to consistently give competitive or superior scores with respect to multiple uncertainty quantification metrics against state-of-the-art methods explicitly tailored to one or a few of them. Our unified solution delivers an implementation-friendly and computationally efficient recipe for safety clearance and provides intellectual economy to an investigation of algorithmic roots of epistemic awareness in deep neural nets.
1 Introduction
Deep neural nets are the gold standard of modern machine learning in pattern classification. But, despite their groundbreaking success in accurate prediction, especially in problems where there is abundant training data, their applicability to safety-critical use cases such as autonomous driving or medical diagnostics is still a matter of fundamental research (Schwalbe and Schels, 2020). Key challenges in the development of total safety in deep learning are at least two-fold: i) reliable risk assessment in difficult regions of the target domain (e.g. class overlap) based on which safetypreserving fallback functions can be deployed, and ii) rejection of inputs that do not belong to the target domain, such as an image of a cat presented to a character recognition system.
The attention of the machine learning community on each of these critical safety elements is consistently increasing (Naeini et al., 2015; Guo et al., 2017; Kuleshov et al., 2018). However, the developments follow isolated directions and the proposed solutions are largely fragmented. Calibration of neural net probabilities focuses primarily on post-hoc adjustment algorithms trained on validation sets from in-domain data (Guo et al., 2017), ignoring the out-of-domain (OOD) detection aspect. On the other hand, recent advances in deep learning OOD detection build on strong regularization mechanisms that strongly penalize divergence from the probability mass observed in the target domain (Sensoy et al., 2018; Malinin and Gales, 2018). The overlooked aspect here is the severe distortion of the class probabilities in the target domain. Such fragmentation of best practices not only hinders their accessibility by real-world applications but also complicates the scientific inquiry of the underlying reasons of sub-optimality of neural net uncertainties.
We investigate which probabilistic deep learning model design could concurrently learn both to provide calibrated class probabilities in-domain and to accurately identify OOD samples after being trained only on data from the target domain towards a single objective. We take Evidential Deep
Correspondence to: Abdullah Akgül <akgula15@itu.edu.tr>
Preprint. Under review.

M

Z

n

xj yj
C

xn

yn

N

Figure 1: Evidential Turing Process. Evidential Deep Learning (EDL) (Sensoy et al., 2018) can be formulated as amortized inference of a latent variable model, corresponding to the right plate when the arrow from input xn to class probabilities n is interpreted to denote inference. Despite its high performance in out-of-domain detection, we observe it to underperform at in-domain calibration due to the uninformed regularization it applies to n. Keeping a differentiable associative memory M that accumulates information useful for in-domain calibration during training by treating a random-sized subset of a minibatch as a context set (left plate) significantly improves EDL's in-domain calibration while maintaining its success in OOD detection. The memory M is accessed through a global latent variable Z. The resultant design corresponds to a Neural Process (NP) (Garnelo et al., 2018b) that uses a Neural Turing Machine (NTM) (Graves et al., 2014) as a context aggregation variable implemented into the EDL framework, hence named as the Evidential Turing Process.

Learning (EDL) (Sensoy et al., 2018) as the starting point due to its reported empirical success in OOD detection (Amini et al., 2020; Haussmann et al., 2020). EDL characterizes the class probabilities of an input pattern as a Dirichlet distributed random variable with concentration parameters determined by a neural network. We build on the fact that the EDL training loss can be framed as the Evidence Lower Bound (ELBO) of amortized variational inference of a Latent Variable Model (LVM). Based on our empirical findings on the relationship between the training regularizer and in-domain calibration performance, we extend the prior distribution of the resulting LVM with an additional global latent variable whose sufficient statistics can be aggregated from an in-domain context set. Such a model amounts to a Neural Process (NP) (Garnelo et al., 2018b) employed on a conditional LVM derived from EDL. While the NP extension equips EDL with improved in-domain calibration performance, it necessitates an available context set also at test time. We lift this limitation and enrich the encoded context information by extending the aggregator variable of the NP to a Neural Turing Machine (NTM) (Graves et al., 2014) that can store multiple entries in an associate memory and retrieve them via an evidential adaptation of an attention mechanism. We name the resultant model as the Evidential Turing Process (ETP).
As depicted in Figure 1, ETP can be characterized as an EDL (right plate) that develops its prior belief on the class probabilities n by maintaining a long-term associative memory M on an in-domain context set (left plate) accessible via a random variable Z using an attention mechanism linked to the variational formulation of the core model. We observe in three image classification data sets and two deep learning architectures that when trained only on the target domain without augmentation or post-hoc calibration, ETP consistently ranks among top performers with respect to three different in-domain calibration scores, unsupervised OOD detection performance, and classification accuracy. ETP outperforms alternative holistic uncertainty quantification approaches, such as Bayesian Neural Nets inferred by stochastic variational inference (Molchanov et al., 2017), as well as non-evidential extensions of NPs to context-free prediction, such as the Functional Neural Process (Louizos et al., 2019). As ETP reuses the amortization network in both the memory embedding and the attention mechanism, it introduces a fixed computational overhead independent from the architecture depth, amounting to less than 50% for LeNet5 and less than 10% for ResNet18.
2 The Evidential Turing Process
We first show how one can formulate EDL as amortized inference of a latent variable model, and then extend it stepwise into a neural process with a differentiable memory.
2

2.1 Evidential Deep Learning as a Latent Variable Model

For a given set of N observations X = {x1, . . . , xN } and the corresponding categorical labels Y = {y1, . . . , yN } with yn  {1, . . . , K}, the commonplace deep learning approach to the supervised classification problem can be viewed as maximum likelihood estimation of the model below

K
n|xn   nk - soft(f(xn))k ,
k=1

yn|n  Cat yn|n1 , . . . , nK ,

n  {1, . . . , N },

where n = (n1 , . . . , nK ) is the K-dimensional vector of class probabilities, (·) is the Dirac measure, soft(·)k is the k-th output channel of a softmax function that maps the K-dimensional output of a neural net f(·) parameterized by  to the corresponding probability simplex. The
log-likelihood of this model amounts to the well-known cross-entropy loss.

Evidential Deep Learning (EDL) (Sensoy et al., 2018) extends the aforementioned established approach by replacing the originally deterministic mapping from inputs to class probabilities by a Dirichlet distribution, i.e. |x  Dir(|(x)), where (·) is a neural net with K-dimensional output parameterized by , such that (x)k  1, k  {1, . . . , K}. This additional source of randomness is integrated out in the data fit term of the training objective and regularized by a Kullback-Leibler (KL) divergence with respect to a flat prior. The training objective is then given as

N

LEDL :=

Enp(n|xn) ||yn - n||22 + KL p(n|xn) p0(n) ,

(1)

n=1

Brier Score

Entropy penalizer

where yn is the true class label in one-hot coding, p(n|xn) = Dir(n|(xn)) is the target evidence predictor, p0(n) = Dir(n|1, . . . , 1) is an uninformative prior on class probabilities, and   R+ is a regularizing coefficient.2 The first term fits the probabilistic predictor p(n|xn) to data, while the second induces inflated variance in case of a divergence from the target domain. Notably, the first term corresponds to the Brier score (Brier, 1950). However, for EDL to perform well in OOD detection, the entropy penalizer term needs to be dominant, which distorts the in-domain calibration of the class probability assignments. With the given choice of distributions, both the expectation and the divergence term can be solved analytically (see Appendix A.2). EDL has the intuitive interpretation that n represents the local evidence collected from observation xn in its meaning used in the subjective logic terminology (Josang, 2018). Such a neural net applied on the second level of the probabilistic hierarchy is also known as a Prior Network (Malinin and Gales, 2018).

The starting observation towards our target model is that one can equivalently formulate the EDL training objective as performing amortized variational inference of the latent variable model

n  Dir(n|1, . . . , 1), yn|n  N (yn|n, 0.5IK ), n,

(2)

where IK is a K × K-dimensional identity matrix. Defining an amortized variational posterior q(n; xn) = Dir(n|(xn)), the negative ELBO objective to be minimized then is given as

N
L~EDL := - Eq(n;xn) [log p(yn|n)] + KL q(n; xn) p(n) ,
n=1
which is identical to LEDL from (1) for  = 1 up to an additive constant due to the normalization factor of the normal distribution (see Appendix A.3 for further details). Relying instead on a  = 1 is similar to the modification of the ELBO studied e.g. in the -VAE model (Higgins et al., 2017).

2.2 Evidential Deep Learning with Neural Processes
While the EDL loss promotes calibrated class probability assignments due to the first term in its training objective, its entropy penalizer is known to be excessively strong after tuning  or inactive otherwise. Hence, EDL usually learns too flat distributions for accurate in-domain calibration. We address this problem by developing a long-term memory that keeps track of calibration errors during training and feeds the entropy penalizer with the incentives appropriate for correcting them on the fly.
2EDL uses a slight modification of the KL term in (1) that only regularizes the output of the non-target dimensions by using ~ = yn + (1 - yn)  (xn), where  refers to elementwise multiplication.

3

To this end, one can, as a first step, extend the deep generative model in (2) with a global random variable Z, the sufficient statistics of which are governed by a permutation-invariant mapping from an arbitrary-sized context set DC = {(x1, y1), . . . , (xC , yC )}, giving us

z|DC  N z|(µ, 2) = r({h(xj, yj) | (xj, yj)  DC })

n|z  Dir n|(Z) , n,

yn|n  Cat(yn|n),

n,

for a permutation invariant aggregation rule r(·) and the size of the context set (e.g. the mean function) applied on the embeddings provided by an encoder net h(·, ·), and some neural net (·) mapping the global variable z to the probability simplex, where we also apply this time to a categorical distribution for the yn.3 This amounts to an extension of the Neural Process (NP) model (Garnelo et al., 2018b), with an additional local variable  defined on the space of evidences. NPs rely on such a context set DC to learn to predict at a set of target points conditioned on these context observations. The resultant model is provably a stochastic process, i.e. exchangeable and consistent over marginalization. To prevent the NP from underfitting to its context set, one can further increase the flexibility of the model by replacing the fixed aggregation rule r with an attention mechanism, allowing the model to switch focus on different parts of the context sets depending on the current target as proposed by Kim et al. (2019) as the attentive NP (ANP). We will use such an attention-based approach, going one step further and additionally extend the context set with a more persistent memory mechanism, somewhat similar to the Neural Turing Machine (Graves et al., 2014), applied for the first time to a neural process like model. Compared to our proposal, ANP learns an attention mechanism but not a separate memory. Such a design would provide a relatively shorter-term memory, as knowledge accumulates only in the parameters of the attention networks. Furthermore, it cannot calculate attention without a context set at test time, which does not apply naturally to standard classification tasks.

2.3 The Evidential Turing Process

Combining the approaches of evidential deep learning and the neural process, as well as modern notions of memory and attention in deep learning, we introduce our proposed final model, the Evidential Turing Process (ETP), which assumes the data generating process below
R
Z|M  N (zr|mr, 2IK ),
r=1
n|Z; xn  Dir n exp(a(v(xn); Z)) , n,
yn|n  Cat(yn|n), n.
ETP consists of an associative memory M = (m1, . . . , mR) with R cells of K dimensions mr  RK , parameterizing the multivariate normal distribution over the global variable Z = (z1, . . . , zR) living in the log-evidence space, where  is a fixed hyperparameter. The input data xn is mapped to the same space via an encoding neural net v(·) where it parameterizes the Dirichlet distribution over the class probabilities n via an attention mechanism a(· ; ·). We continue to assume the targets yn to be categorically distributed. See Figure 1 for a visual summary of the model.

Attention. The memory is accessible via an attention function a(v; Z) :=

R r=1

wr (v ;

Z )zr

for

an arbitrary K-dimensional input v. We restrict ourselves to the scaled dot product as the similarity

metric wr (v ;

within Z) :=

this work to keep the exp(k(zr) v/ K)/

preRjs=e1netaxtpionks(imzjp)lev. /TheKwe, iwgihtth

function k(·) as

is the

then key

given as generator

network operating on the embedding space. Alternatives such as Laplace and cosine similarities, or

making use of multi-head attention (Vaswani et al., 2017) would be directly applicable in practice.

Learning the ETP model then consists of alternating two steps: (i) Updating the memory M given the rest of the model, and (ii) updating the model posterior given the current memory. We will discuss each of the two steps in turn and give a summarizing overview in Algorithm 1.

3We generically refer to the weights of the different neural nets used in this model and the baselines jointly via , despite them referencing different networks to keep the notation simple and drop them from the notation if clear from the context.

4

Updating the memory. To update the memory, we follow the NP approach and select a randomly sized context set of observations by choosing a random subset of observations {XC, YC} from the current training minibatch. Each of the R memory cells is then updated as

mr  tanh mr + (1 - ) wr(v(x); Z) onehot(y) + soft(v(x)) ,

(3)

(x,y)XC ×YC

where   (0, 1) is a fixed scaling factor, Z is a sample from p(Z|M ), and soft(·) and onehot(·) are the softmax and the one-hot encoding function respectively. The  parameter allows us to weigh in each update between remembering (first term) and updating the memory (second term). The second term adds new information to the cell as a weighted sum over all pairs (x, y), taking both the true label (via onehot(y)) as well as the uncertainty in the prediction (via soft(v(x))) into account. The final tanh(·) transformation ensures that the memory content remains in a fixed range across updates, as practised in (Hochreiter and Schmidhuber, 1997). Given our memory structure, the rest of the model is independent of the context set given the memory. We do not need to distinguish between it and the remaining observations of the minibatch (the target set in an NP). For simplicity, we will always predict the whole minibatch when updating the model posterior.

Updating the model posterior. As the computation of the true posterior p(1, . . . , N , Z|D) for some set of N observations D is not tractable, we rely instead on a variational inference (Blei
et al., 2017), approximating the true posterior with q(1, . . . , N , Z|M ) = p(Z|M ) n q(n|Z; xn) where we rely on an amortized variational posterior for the n by defining q(n|Z; xn) = Dir(n|h(v(x), a(v(x); Z))). Here h(·, ·) is a neural net combining the encoded data together with the information given by the attention. The evidence lower bound to be optimized is then

N

LELBO = Eq(1,...,N ,Z|M )

log p(yn|n)p(Z|M ) - log q(1, . . . , N , Z|M )

n=1

N

= Ep(Z|M) Eq(n|Z) [log p(yn|n)] - KL (q(n|Z) p(n|Z)) .

(4)

n=1

In this objective, the inner expectation and the KL divergence are by design tractable and can be

computed efficiently. The expectation is given as Eq(n|Z) [log p(yn|n)] =

K k=1

ynk

(nk) -

( jnj) , where  is the digamma function (see the Appendix A.4 for the KL expression). Approximating the sum over the whole data set with a mini-batch allows us to learn the parameters of

the individual neural nets governing our distributions via the common stochastic gradient approaches,

where we further approximate the expectation over Z via samples, relying on the reparameterization

trick (Kingma and Welling, 2014) to reduce the gradient variance caused by these samples.

In order to train the overall model we alternate between updating the memory and updating the variational approximation. This procedure is summarized in Algorithm 1.

Prediction. The posterior predictive for y given a new observation x can be computed as p(y = k|x, D)  Ep(Z|M) Eq(|x,Z) [p(y = k|)] = Ep(Z|M) hk k hk ,
where hk = h (v(x), a(v(x); Z))k. That is, we can compute it analytically up to a samplingbased evaluation of the expectation over p(Z|M ).

ETP as a stochastic process. Finally, as we are following the neural process (Garnelo et al., 2018b) framework, we can similarly show that our proposed model is a stochastic process. Relying on the Kolmogorov Extension Theorem, it is sufficient to show that the joint distribution is exchangeable and consistent. We show this in the following theorem.
Theorem 1. For any context set DC = {XC , YC } and target set DT = {XT , YT }, the following two identities hold for ETP: i) For any permutation  of the evaluations x~t and y~t of covariates XT and YT , respectively, p(XT = x~t, YT = y~t|XC , YC ) = p(XT = (x~t), YT = (y~t)|XC , YC ), and ii) for any S  T , p(XS, YS|XC , YC ) = p(XT , YT |XC , YC )dXT \SdYT \S.

5

Algorithm 1: One update step of the Evidential Turing Process.

Input: mini-batch (X, Y ) of size B, nets v(·), h(·), k(·), memory M , scaling factor 

function att(v, Z): //define the attention function w  soft k(zr) v/ K r  (1, . . . , R)

return

R r=1

wr

zr

end

// 1. Update the memory

C  U ({3, B}) // sample subset of points

m  zeros(R, K) // init temporary matrix for collecting memory updates

Z~|M 

R r=1

N

(zr |mr ,

2IK

)

//

sample

from

the

memory

for each (x, y)  (X1:C , Y1:C) do

w  soft k(z~r) v(x)/ K r  (1, . . . , R) // compute weights

mr  mr + wr onehot(y) + soft(v(x)) r // update each of the R temp cells end mr  mr + (1 - )mr r // update each of the R memory cells

// 2. Update the variational posterior loss  0 // initialize the loss for each (x, y)  (X, Y ) do
xemb  h v(x), att(v(x); Z~) // pass observation through net and attention loss  loss - k onehot(y)k (exp(xemb)k) - ( j exp(xemb)) // add nll loss  loss + KL Dir | exp(xemb) Dir | exp(att(xemb; Z~)) // add KL
end    - loss // update the network parameters

3 Related Work
Evidential Deep Learning. Follow-up work has extended EDL (Sensoy et al., 2018) in multiple directions, such as probabilistic weights (Haussmann et al., 2020), allowing for synthetic OOD data (Sensoy et al., 2020), or tailoring it to regression (Amini et al., 2020). Closely related are Prior Networks (PN) (Malinin and Gales, 2018), which minimize two KL divergences, one between the predictor and the true target domain, one between an OOD observation and a flat distribution. We compare against EDL (in the main paper), as well as the most recent PN variant PN-RKL (Malinin and Gales, 2019) that fits a reverse KL divergence on the target domain (see Appendix B.3).
Neural Processes. Neural Processes (NPs) are a latent variable model introduced by Garnelo et al. (2018a,b) to combine the strengths of neural networks with Gaussian processes. They have since been extended to allow for attention mechanisms (Kim et al., 2019), translation equivariance (Gordon et al., 2020; Foong et al., 2020), or the application area of temporal data (Singh et al., 2019; Yoon et al., 2020). Functional neural processes (FNPs) by Louizos et al. (2019) take a similar but different approach. They also employ neural networks to get flexible representations and construct a stochastic process, but they rely on the local structure of the given observations instead of global latent variables. The attentive NP has the limitation of requiring to a context set during test time, while ETP design goes beyond this restriction thanks to the Turing machine architecture of its memory. The FNP similarly does not require a context set at test time. Differently from ETP, it builds its memory as a differentiable graph. However, the local dependency of its graph design suffers from a significant computation burden, which resulted in sub-optimal results throughout our experiments.
Calibration and OOD detection. Calibration of modern neural network architectures is an emerging research topic in the deep learning community Guo et al. (2017). Among a wide range of proposed approaches, one can highlight post-hoc methods such as temperature scaling (Guo et al., 2017) or Dirichlet calibration (Kull et al., 2019), ensemble methods (Lakshminarayanan et al., 2017), and
6

Density

0.4

0.3

0.2

0.1

0.0

-4

-2

0

2

4

15

10 5

-4

-2

0

2

4

Input space

Memory Evidence

Figure 2: 1D Classification Task. The upper plot shows the underlying distributions of each of the two classes, as well as the observed data. The lower plot shows the regularizing evidence the generative model places on each of the two classes depending on location in space, that is, mean ± one standard deviation over ten samples from p(Z|M ).

Bayesian neural networks (BNN) (Gal and Ghahramani, 2016; Maddox et al., 2019). We address this high diversity in our experiments by choosing representative baselines. We compare against temperature scaling as a representative of post-hoc methods and two BNN variants: Monte Carlo (MC) Dropout (Gal and Ghahramani, 2016) and a mean-field variational inference (Kingma et al., 2015). Ovadia et al. (2019) provide a recent study evaluating the performance of a wide range of methods. We evaluate the calibration and OOD detection performance by a variety of performance scores introduced in the following section.
4 Results
We evaluate ETP in a series of experiments ranging from synthetic toy data sets for illustrative purposes to three image classification benchmarks for rigorous performance comparison. Details on the architectures and hyperparameters used in the experiments that are not mentioned in the main text on these experiments can be found in Appendix B. We also provide a reference implementation of the proposed model and the experimental pipeline.4
4.1 Toy experiments on low-dimensional classification tasks
We illustrate the qualitative behaviour of ETP on two simple data sets with a reduced version of the model that uses identity mappings for k(·) and h(·) and rescales the memory to improve transparency.
Synthetic 1d two-class classification. Our first experiment consists of a simple two-class classification task where the observations (20 for each class) are generated from two highly overlapping Gaussian distributions. The neural net, a simple one hidden layer architecture, can learn the task reasonably well. Figure 2 shows the raw data and underlying distributions as well as the learned memory evidence. The model learns to place more evidence on the correct class further away from the decision boundary while also becoming more varied with increasing distance. Within the high-density region, the asymmetry in how the specific observations are spread out leads to an asymmetry in the memory evidence. Above zero, the orange points are well separated, leading to a quick emphasis on that class as we move towards the right. Below zero, however, some observations in the blue region prevent the model from rapidly developing over-confidence.
Iris 2d three-class classification. As a second illustrative experiment, we consider a classic data set that consists of three species of the iris flower. The first two principal components of the data give an interpretable toy learning setup where one class is clearly separated from the other two overlapping classes. Figure 3 shows that the learned model encourages strong confidence in the clearly separated one, while it regularizes against over-confidence within the overlapping regions of the other two classes. See Figure 1 & 2 in the appendix for variants of this figure that give further details.
4See github.com/ituvisionlab/EvidentialCalibration

7

Memory Evidence

15 10
5

-4

-3

-2

-1

0

1

2

3

4

Input x1 (for x2 = 0)

Figure 3: 2D Classification Task. The three upper plots visualize the regularizing evidence that the model places on the location in space as the average over ten samples from p(Z|M ). The color scales are different across the three plots and vary in overall intensity. The lower plot visualizes a horizontal cut through the middle of these plots, putting them on a common scale. The solid lines in each color indicate the mean memory evidence, and the corresponding shaded areas indicate one standard deviation. Around the separable blue class, the memory strongly emphasizes the correct class with large confidence and suppresses the other two classes depicted in orange and green. While always preferring the correct class, the memory regularizes against overconfidence around the overlapping orange and green classes. See the appendix (Figure 1 & 2 there) for larger versions of these plots.

4.2 Large-scale image classification experiments
We evaluate ETP on three image classification benchmarks: FMNIST and CIFAR10 using a LeNet5 architecture and the more challenging CIFAR100 on the ResNet18 architecture. We focus in this work on the impact of our model design and leave a rigorous neural architecture search to future work. We compare ETP against i) Monte Carlo Dropout (Gal and Ghahramani, 2016) as a straightforward way to incorporate uncertainty into a vanilla neural net, denoted as MCDrop, ii) a BNN inferred by mean-field variational Bayes using the local reparameterization trick (Kingma et al., 2015) denoted as BNN-VB, iii) Temperature Scaling (TS) (Guo et al., 2017), an established representative of post-hoc calibration methods, iv) EDL (Sensoy et al., 2018) as the base model, and v) FNP (Louizos et al., 2019) as an NP variant that does not require explicit context data during test time.
Figure 4 gives a visualization of the results with respect to six performance scores. The upper row reports three in-domain calibration metrics: Brier score, Expected Calibration Error (ECE) (Naeini et al., 2015), and Negative Log-Likelihood (NLL). The lower row, in turn, reports the prediction error, Area Under ROC Curve (AUROC) for OOD detection, and the computational cost per-epoch as wall clock time. We performed the OOD detection task as suggested by Malinin and Gales (2018), who classify the test split of the target domain and a data set from another domain based on the the mutual information H[Ep(|x;^) [P (y|)]] - Ep(|x;^) [H[P (y|)]] of the predictive distribution of each model in comparison, where H denotes the entropy functional. ETP is the only method that consistently ranks among top performers in all three data sets with respect to all six performance scores, which is the desired outcome of our modeling premises. The computation cost of ETP is comparable to a standard neural net architecture, as visible in the TPE panel. See Appendix B for full details of the experiment setup, as well as an extended presentation of Figure 4 in table format.
PN-RKL uses OOD data for training, while ETP and the other baselines do not. Even though this access to additional data makes direct performance comparison incommensurate, we nevertheless provide a comparison against PN-RKL for completeness and report its outcome in Appendix B. While PN-RKL outperforms the other models in OOD detection in two of the three data sets, it falls behind in many in-domain calibration metrics. We performed the FNP experiments using the authors' source code, sticking to their suggested setup as much as possible with rigorous attempts to improve it. We attribute the dramatic drop in the performance of this baseline to the brittleness of the complex graph construction design amplified by the deeply parameterized binary random variables that govern its adjacency matrix. ETP's memory and attention-based, more straightforward solution to a context summarization enjoys improved robustness.
8

Score

0.8

Brier
MCDrop

0.7 BNN-VB

0.6 TS

0.5

EDL FNP

0.4 ETP (Ours)

0.3

0.2

0.1

0.0

60

Error (%)

50

40

30

20

10

0FMNIST C10 C100 Dataset

3.0

NLL

20.0

2.5

17.5

15.0

2.0

12.5

1.5

10.0

1.0

7.5

5.0

0.5

2.5

0.0

0.0

100

AUROC (%)

50

ECE (%) TPE

40

30 80
20

10

60FMNIST C10 C100 Dataset

0FMNIST C10 C100 Dataset

Score

Figure 4: Benchmarking results for image classification tasks on three data sets: Fashion MNIST, CIFAR-10, and CIFAR-100. (top row) In-domain calibration performance as Brier score, Negative Log-Likelihood (NLL), and Expected Calibration Error (ECE). (bottom row) Prediction error, Area Under ROC Curve (AUROC) for Out-of-distribution (OOD) detection, and computation cost as Time Per Epoch (TPE). ETP ranks among top performers in all three data sets with respect to all performance scores. The results are the average over ten runs, and the error bars give one standard deviation (see Appendix B.3 for a tabular version of these results).

5 Broad Impact and Limitations
We view the empirical outcome of this work as a proof-of-concept demonstrating that epistemic awareness of a deep neural net is indeed a capability learnable only from in-domain data, as appears in biological intelligence via closed-loop interactions of neuronal systems with stimuli. The implications of our work could follow up in interdisciplinary venues, with a particular focus on the relation of associative memory and attention to the neuroscientific and learning-theoretic roots, as well as algorithmic explanations of epistemic awareness (Lorenz, 1978).
Bayesian inference by perturbing neural net weights provides a strong alternative to ETP. While we observed ETP outperform BNN variants in our experiments, whether BNNs could bridge the gap after further improvements in the approximate inference remains to be researched. The attention mechanism of ETP could also be improved using more advanced attention methods. The explainability of the memory content of ETP is an open issue, which deserves further investigation. The generalizeability of our results to very deep architectures, such as ResNet 152 or DenseNet 161 could be a topic of a separate large-scale empirical study. While ETP proves to be tightly competitive with post-hoc methods in in-domain calibration, it lags behind PN-RKL in OOD detection for some use cases. Even though PN-RKL has the advantage of using OOD data during training time and ETP does not, there remains a large margin for improving the ETP methodology specifically towards more accurate OOD detection without sacrificing its present in-domain calibration performance.
ETP is meant mainly as a method to facilitate the safe use of deep neural nets. However, it does not improve the explainability and fairness of the decisions made by the underlying neural net architecture. Potential negative societal impacts of deep neural net classifiers stemming from these two factors need to be circumvented separately before the real-world deployment of our work.
9

References
Milton Abramowitz and Irene A. Stegun. Handbook of Mathematical Functions. Dover, 1965.
Alexander Amini, Wilko Schwarting, Ava Soleimany, and Daniela Rus. Deep Evidential Regression. In Advances in Neural Information Processing Systems, 2020.
David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. Variational Inference: A Review for Statisticians. Journal of the American statistical Association, 112(518):859­877, 2017.
Glenn W. Brier. Verification of Forecasts Expressed in Terms of Probability. Monthly Weather Review, 78(1):1­3, 1950.
Tarin Clanuwat, Mikel Bober-Irizar, Asanobu Kitamoto, Alex Lamb, Kazuaki Yamamoto, and David Ha. Deep learning for classical japanese literature. arXiv preprint arXiv:1812.01718, 2018.
Andrew Foong, Wessel Bruinsma, Jonathan Gordon, Yann Dubois, James Requeima, and Richard Turner. Meta-Learning Stationary Stochastic Process Prediction with Convolutional Neural Processes. In Advances in Neural Information Processing Systems, 2020.
Yarin Gal and Zoubin Ghahramani. Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning. In International Conference on Machine Learning, 2016.
Marta Garnelo, Dan Rosenbaum, Christopher Maddison, Tiago Ramalho, David Saxton, Murray Shanahan, Yee Whye Teh, Danilo Rezende, and S. M. Ali Eslami. Conditional Neural Processes. In International Conference on Machine Learning, 2018a.
Marta Garnelo, Jonathan Schwarz, Dan Rosenbaum, Fabio Viola, Danilo J Rezende, SM Eslami, and Yee Whye Teh. Neural Processes. Theoretical Foundations and Applications of Deep Generative Models workshop, 2018b.
Jonathan Gordon, Wessel P. Bruinsma, Andrew Y. K. Foong, James Requeima, Yann Dubois, and Richard E. Turner. Convolutional Conditional Neural Processes. In International Conference on Learning Representations, 2020.
Alex Graves, Greg Wayne, and Ivo Danihelka. Neural Turing Machines. arXiv preprint arXiv:1410.5401, 2014.
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On Calibration of Modern Neural Networks. In International Conference on Machine Learning, 2017.
Manuel Haussmann, Sebastian Gerwinn, and Melih Kandemir. Bayesian Evidential Deep Learning with PAC Regularization. In Advances in Approximate Bayesian Inference, 2020.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework. In Internationl Conference on Learning Representations, 2017.
Sepp Hochreiter and Jürgen Schmidhuber. Long Short-Term Memory. Neural Computation, 9(8): 1735­1780, 1997.
Audun Josang. Subjective Logic: A formalism for reasoning under uncertainty. Springer, 2018.
Hyunjik Kim, Andriy Mnih, Jonathan Schwarz, Marta Garnelo, Ali Eslami, Dan Rosenbaum, Oriol Vinyals, and Yee Whye Teh. Attentive Neural Processes. In International Conference on Learning Representations, 2019.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.
Diederik P. Kingma and Max Welling. Auto-encoding Variational Bayes. International Conference on Learning Representations, 2014.
Diederik P. Kingma, Tim Salimans, and Max Welling. Variational Dropout and the Local Reparameterization Trick. Advances in Neural Information Processing Systems, 2015.
10

Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
Volodymyr Kuleshov, Nathan Fenner, and Stefano Ermon. Accurate Uncertainties for Deep Learning using Calibrated Regression. In International Conference on Machine Learning, 2018.
Meelis Kull, Miquel Perello Nieto, Markus Kängsepp, Telmo Silva Filho, Hao Song, and Peter Flach. Beyond Temperature Scaling: Obtaining well-calibrated Multi-class Probabilities with Dirichlet Calibration. In Advances in Neural Information Processing Systems, 2019.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles. In Advances in Neural Information Processing Systems, 2017.
Yann LeCun, Corinna Cortes, and CJ Burges. MNIST handwritten digit database. ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist, 2, 2010.
Konrad Lorenz. Die Rückseite des Spiegels: Versuch einer Naturgeschichte menschlichen Erkennens. Piper, 1978.
Christos Louizos, Xiahan Shi, Klamer Schutte, and Max Welling. The Functional Neural Process. In Advances in Neural Information Processing Systems, 2019.
Wesley J Maddox, Pavel Izmailov, Timur Garipov, Dmitry P Vetrov, and Andrew Gordon Wilson. A Simple Baseline for Bayesian Uncertainty in Deep Learning. Advances in Neural Information Processing Systems, 2019.
Andrey Malinin and Mark Gales. Predictive Uncertainty Estimation via Prior Networks. In Advances in Neural Information Processing Systems, 2018.
Andrey Malinin and Mark Gales. Reverse KL-Divergence Training of Prior Networks: Improved Uncertainty and Adversarial Robustness. In Advances in Neural Information Processing Systems, 2019.
Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Variational Dropout Sparsifies Deep Neural Networks. In International Conference on Machine Learning, 2017.
Mahdi Pakdaman Naeini, Gregory Cooper, and Milos Hauskrecht. Obtaining well Calibrated Probabilities using Bayesian Binning. In AAAI Conference on Artificial Intelligence, 2015.
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y. Ng. Reading Digits in Natural Images with Unsupervised Feature Learning. 2011.
Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, D Sculley, Sebastian Nowozin, Joshua V. Dillon, Balaji Lakshminarayanan, and Jasper Snoek. Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift. In Advances in Neural Information Processing Systems, 2019.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An Imperative Style, High-Performance Deep Learning Library. In Advances in Neural Information Processing Systems 32. 2019.
Gesina Schwalbe and Martin Schels. A Survey on Methods for the Safety Assurance of Machine Learning Based Systems. In European Congress on Embedded Real Time Software and Systems, 2020.
Murat Sensoy, Lance Kaplan, and Melih Kandemir. Evidential Deep Learning to Quantify Classification Uncertainty. In Advances in Neural Information Processing Systems, 2018.
Murat Sensoy, Lance Kaplan, Federico Cerutti, and Maryam Saleki. Uncertainty-Aware Deep Classifiers using Generative Models. In AAAI Conference on Artificial Intelligence, 2020.
Gautam Singh, Jaesik Yoon, Youngsung Son, and Sungjin Ahn. Sequential Neural Processes. In Advances in Neural Information Processing Systems, 2019.
11

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, L ukasz Kaiser, and Illia Polosukhin. Attention is All you Need. In Advances in Neural Information Processing Systems, 2017.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. 2017.
Jaesik Yoon, Gautam Singh, and Sungjin Ahn. Robustifying Sequential Neural Processes. In International Conference on Machine Learning, 2020.
12

Appendix

A Further theoretical results and derivations

A.1 Kullback Leibler between two Dirichlet Distributions

As our objective and the EDL baseline rely on the Kullback-Leibler divergence between two Dirichlet
distributions, we repeat here for completeness the general form. Assuming two distributions over a K-dimensional probability , Dir(|) and Dir(|), parameterized by ,   RK+ , we have

KL Dir(|)

Dir(|) = log

( (

k k) k k)

k (k) k (k)

+ (k - k) (k) - (
k

k k) ,

where

(·)

and

(a)

:=

d da

log (a)

are

the

gamma

and

digamma

functions

(Abramowitz

and

Stegun,

1965).

A.2 The Evidential Deep Learning Objective

The analytical solutions for the Evidential Deep Learning (Sensoy et al., 2018) loss as defined in the main paper in (2) can be computed as follows. For a single K-dimensional observation y, dropping the n from the notation and instead using the index for the dimensionality throughout the following equations, we have that the expectation in the expectation terms are given as

Ep(|x) ||y - ||2 = Ep(|x) (y - ) (y - )
K
= Ep(|x) (yk - k)2
k=1 K
= Ep(|x) (yk - Ep(|x) [k] + Ep(|x) [k] - k)2
k=1 K
= (yk - Ep(|x) [k])2 + varp(|x) [k] ,
k=1
with the tractable expectation and variance of a Dirichlet distributed . The Kullback-Leibler term is between two Dirichlet distributions and given (see the general form in A.1) as

KL (Dir(|(x)) Dir(|1, . . . , 1))

= log

 (K )

k (x)k k ((x)k)

K
+ ((x)k - 1) ((x)k) - 
k=1

k (x)k .

A.3 Evidential Deep Learning as a latent variable model
As discussed in the main paper for a set of N observations D = {(x1, y1), . . . , (xN , yN )}, the objective EDL minimizes is given via (2) as
N
LEDL = Ep(n|xn) ||yn - n||22 + KL p(n|xn) Dir(n|1, . . . , 1) ,
n=1
where p(n|xn) = Dir(|(xn)). We can instead assume the following generative model
n  Dir(n|1, . . . , 1) n yn  N (yn|n, 0.5IK ) n,
i.e. latent variables n and K-dimensional observations yn following a multivariate normal prior. Approximating the intractable posterior p(|y), where  = (1, . . . , n), y = (y1, ..., yn), with an

13

amortized variational posterior q(n; xn) = Dir(n|(xn)), where (·) is the same architecture as in the EDL model, we have as the evidence lower bound (ELBO) to be maximized

N

Eq(n;xn) [log p(yn|n)] - KL q(n; xn) p(n)
n=1

N

1

K

=

Eq (n ;xn )

- log(2) + 2

2

log(2) - (yn - n)

(yn - n)

- KL

q(n; xn)

n=1

N

= const - Eq(n;xn) (yn - n) (yn - n) - KL q(n; xn) p(n)
n=1

= const - LEDL,

p(n)

that is the negative ELBO is equal to the EDL loss up to an additive constant.

A.4 Tractability of the ELBO objective in (5)

The ELBO objective of ETP repeated here for completeness

N

LELBO = Ep(1,...,N ,Z|M )

log p(yn|n)p(Z|M ) - log q(1, . . . , N , Z|M )

n=1

N
= Ep(Z|M) Eq(n|Z) [log p(yn|n)] - KL (q(n|Z) p(n|Z)) ,
n=1

consists of an outer expectation over Z which needs to be approximated as well as an expectation and a Kullback-Leibler divergence over  which are analytically tractable. Given a Dirichlet variational posterior, the expectation is given as

K
Eq(n|Z) [log p(yn|n)] = ynk (nk) - ( j nj ) ,
k=1

where

(a)

:=

d da

log (a),

is

known

as

the

digamma

function

and



is

the

gamma

function.

The

KL divergence term is

KL (q(n|Z) p(n|Z))

= KL Dir n h v(xn), a(v(xn); Z) Dir n exp(a(v(xn); Z)) ,

which is tractable as the KL divergence between two Dirichlet distributions as given in Section A.1.

A.5 Proof of Theorem 1
Theorem 1. For any context set DC = {XC , YC } and target set DT = {XT , YT }, the following two identities hold for ETP:
i) For any permutation  of the evaluations x~t and y~t of covariates XT and YT , respectively, p(XT = x~t, YT = y~t|XC , YC ) = p(XT = (x~t), YT = (y~t)|XC , YC )
ii) For any S  T ,

p(XS, YS|XC , YC ) = p(XT , YT |XC , YC )dXT \SdYT \S.

Proof: For the Evidential Neural Process we have the exchangeability and consistency constraints directly given via the fact that we have conditional independence of the individual (xn, yn, n) given the global latent Z. The exchangeability is given as

p(x1:n, y1:n|DC ) =

p(Z|DC ) p(xn|n, Z)p(yn|n)dndZ = p(x(1:n), y(1:n)|DC ),
n

14

for some permutation function . Consistency is given similarly as

pn+m(x1:n+m, y1:n+m|DC )dxn+1:n+mdyn+1:n+m

n+m

=

p(Z|DC ) p(xi|i, Z)p(yi|i)dxn+1:n+mdyn+1:n+mdidZ

i=1

n

n+m

= p(Z|DC ) p(xi|i, Z)p(yi|i)

p(xj|j, Z)p(yj|j)dxjdyjdidZ

i=1

j=n+1

n

= p(Z|DC ) p(xi|i, Z)p(yi|i)didZ = pn(x1:n, y1:n|DC ).

i=1

For our Evidential Turing Process model we have exactly the same line of reasoning to show consistency and exchangeability.

B Experimental Details
B.1 Synthetic 1d two-class classification
The data set used in this experiment is a synthetic data set consisting of two classes with 20 observations each sampled from standard normal distributions centered at ±1 respectively. The encoding function v(·) consists of a multi-layer perceptron with a single hidden layer consisting of 32 neurons and a ReLU activation function. It is optimized for 400 epochs with the Adam optimizer (Kingma and Ba, 2014) using the PyTorch (Paszke et al., 2019) default parameters and a learning rate of 1e - 3. In order to keep the model as simple as possible, the key generator function k(·) is constrained to being the identity function, while h v(x), a(v(x); Z) = v(x) + tanh(a(v(x); Z). The memory update is simplified to dropping the tanh(·) rescaling.
B.2 Iris 2d three-class classification
The data set used in this experiment is the classical Iris data set5 consisting of 150 samples of three iris species (50 per class), with four features measured per sample. We first map the data to the first two principal components for visualization and also use this modified version as the training data. The encoding function v(·) consists of an MLP with two hidden layers of 32 neurons each and ReLU activation functions. It is optimized for 400 epochs with the Adam optimizer using the PyTorch default parameters and a learning rate of 1e - 3. In order to keep the model as simple as possible, the key generator function k(·) is constrained to being the identity function, while h v(x), a(v(x); Z) = v(x) + tanh(a(v(x); Z). The memory update is simplified to dropping the tanh(·) rescaling.
Figure 3 in the main paper showed the varying importance the model assigns to different parts of the input space depending on the class under consideration. For the separate blue class, the model is a lot more confident in relative terms and absolute values. See Figure 5 for an enhanced set of plots showing the range for each of them. See Figure 6 for an enhanced plot of the horizontal cut through the input space at x2 = 0, while varying the first input dimension. It shows the certainty (although with a large variance) assigned to the separate blue class and the significantly more conservative regularization in the overlapping region starting around x1 = -1.
B.3 Image Classification Experiments
We provide the numerical values of the image classification experiment results corresponding to the bar chart in Figure 4 of the main paper in Tables 2, 3, and 4 for completeness and also include the PN-RKL results which requires OOD observations during training. All experiments are implemented
5Originally due to Fisher (1936) and Anderson (1935). We rely on the version provided by the scikit learn library, see https://scikit-learn.org/stable/modules/classes.html#module-sklearn. datasets.

15

2.0

1.5

10

1.0

0.5

8

0.0

-0.5

6

-1.0 4
-1.5

-2.0-4

-3

-2

-1

0

1

2

3

4

2

2.0

2.4

1.5 2.2
1.0

0.5

2.0

0.0

1.8

-0.5

1.6

-1.0 1.4
-1.5

-2.0-4

-3

-2

-1

0

1

2

3

1.2 4

2.0

2.6

1.5

2.4

1.0

2.2

0.5 2.0
0.0 1.8
-0.5
1.6 -1.0

-1.5

1.4

-2.0-4

-3

-2

-1

0

1

2

3

1.2 4

Figure 5: 2D Classification Enhanced. The enlarged version of the visualization in Figure 3. While the range of values between the memory evidence belonging to the orange and the green class is roughly similar, for the well separated blue class the model assigns a much larger absolute value.

16

Memory Evidence

16 14 12 10
8 6 4 2

-4

-3

-2

-1

0

1

2

3

4

Input x1 (for x2 = 0)

Figure 6: 2D Classification - Horizontal Cut. An overlay of Figure 5 at x2 = 0. It shows the mean memoevidence ± one standard deviation (over ten samples) for each of the three classes.

in PyTorch (Paszke et al., 2019) version 1.7.1 and trained on a TITAN RTX. All experiments have been replicated ten times over random initial seeds. The experimental details are as follows:
Fashion MNIST (FMNIST) (Xiao et al., 2017). Uses a LeNet5-sized architecture (see Table 1). The out-of-distribution data is the MNIST (LeCun et al., 2010) data set and PN-RKL gets the KMNIST (Clanuwat et al., 2018) data for training OOD observations. All data sets are z-score normalized given the in-domain mean and standard deviations. The training objective for each model is optimized via the Adam optimizer (Kingma and Ba, 2014) with a learning rate of 1e - 3. Each model is trained for 50 epochs.
CIFAR10 (C10) (Krizhevsky et al., 2009). Uses a LeNet5-sized architecture (see Table 1). The out-of-distribution data is the SVHN (Netzer et al., 2011) data set and PN-RKL gets the CIFAR100 data for training OOD observations. All data sets are z-score normalized given the in-domain mean and standard deviations. We further rely on data augmentation for the in domain data using random crops with 32 pixels and four pixel padding as well as horizontal flips. The training objective for each model is optimized via the Adam optimizer (Kingma and Ba, 2014) with a learning rate of 1e - 4. Each model is trained for 100 epochs.
CIFAR100 (C100) (Krizhevsky et al., 2009). Uses a ResNet18 architecture as provided by PyTorch and adapted to the 100 class classification task. The out-of-distribution data is the TinyImageNet6 data set and PN-RKL gets the CIFAR10 data for training OOD observations. All data sets are z-score normalized given the in-domain mean and standard deviations. We further rely on data augmentation for the in domain data using random crops with 32 pixels and four pixel padding as well as horizontal flips. The training objective for each model is optimized via stochastic gradient descent with a momentum of 0.9 and a learning rate of 0.05, except for PN-RKL which uses the Adam optimizer with a learning rate of 1e - 3. All models are further regularized via weight decay (with a scaling factor of 5e - 3 for PN-RKL and 5e - 4 for the other models). Each model is trained for 200 epochs.
Shared Details and Observations. In all experiments, we train the MCDrop, BNN-VB, and TS models with a cross-entropy loss, relying on the softmax for prediction. For out-of-domain prediction, these models use entropy. In the CIFAR10 and CIFAR100 experiments with TS, we realized that the temperature value is somehow negative in some replications and the model gives really bad results. Therefore, in favour of TS, we used the ADAM optimizer with a hundred epoch in the temperature scaling part. The initial value of the temperature value is set 2.5 in CIFAR10 and CIFAR100 experiments. In the FMNIST experiments, we used the LBFGS optimizer with fifty epochs, the initial value of the temperature value is set 1.5, and we close the dropout. The EDL model is trained with the original loss (Sensoy et al., 2018). We noticed that, in the CIFAR100 experiments,
6Source: http://cs231n.stanford.edu/tiny-imagenet-200.zip
17

Table 1: The neural network architectures used for the FMNIST and CIFAR10 data set with ReLU activations between the layers.

FMNIST

CIFAR10

Convolution (5 × 5) with 20 channels Convolution (5 × 5) with 192 channels

MaxPooling (2 × 2) with stride 2

Convolution (5 × 5) with 50 channels Convolution (5 × 5) with 192 channels

MaxPooling (2 × 2) with stride 2

Linear with 500 neurons

Linear with 1000 neurons

Linear with 10 neurons

this loss is not converged due to the KL divergence term. In favour of EDL, we changed anneal coefficient part to t/20000 instead of t/10 to normalize the KL divergence part. The prediction is made with the mean of the Dirichlet distribution like in the original work. Entropy is used for detecting OOD instances in the EDL baseline. The PN-RKL model is trained with the reverse KL loss (Malinin and Gales, 2019). While predicting, we rely on the softmax. As in the original work, we used mutual information for OOD detection. We follow the same loss and predict procedure in FNP baseline as in the original work by Louizos et al. (2019). The OOD detection for FNP baseline, uses the entropy.

Table 2: Quantitative results of models on the FMNIST target domain and MNIST out-of-domain using the LeNet5. The results shown mean ± one standard deviation.

Method
MCDrop BNN-VB TS EDL PN-RKL FNP
ETP

Err (%) ()
8.7±0.3 8.2±0.1 8.4±0.2 8.6±0.2 8.6±0.1 10.1±0.4
8.0±0.1

Brier ()
0.14±0.00 0.15±0.00 0.13±0.00 0.14±0.00 0.13±0.00 0.15±0.01
0.12±0.00

NLL ()
0.37±0.01 0.65±0.01 0.30±0.01 0.37±0.00 0.29±0.01 0.39±0.02
0.29±0.00

ECE (%) ()
5.3±0.2 6.9±0.1 4.2±0.2 3.8±0.2 2.8±0.1 4.0±0.3
2.7±0.1

AU-ROC (%) ()
70.0±3.3 74.5±2.8 75.3±1.4 76.8±2.0 100.0±0.0 77.2±3.2
84.9±3.4

TPE ()
4.6±0.1 4.4±0.1 4.0±0.1 5.8±0.1 6.8±0.2 33.6±0.2
6.6±0.2

Table 3: Quantitative results of models on the CIFAR10 target domain and SVHN out-of-domain using the LeNet5. The results shown mean ± one standard deviation.

Method
MCDrop BNN-VB TS EDL PN-RKL FNP
ETP

Err (%) ()
17.2±0.3 15.1±0.2 18.2±0.3 18.4±0.3 16.1±0.2 25.3±1.3
16.6±0.3

Brier ()
0.24±0.00 0.22±0.00 0.26±0.00 0.29±0.00 0.24±0.00 0.36±0.02
0.23±0.00

NLL ()
0.52±0.01 0.49±0.01 0.53±0.01 0.72±0.01 0.51±0.00 0.77±0.04
0.49±0.01

ECE (%) ()
4.0±0.2 5.4±0.1 2.7±0.1 9.0±0.3 4.7±0.2 6.5±1.5
2.4±0.2

AU-ROC (%) ()
82.0±1.0 84.2±0.5 80.9±1.1 78.3±0.9 93.2±1.1 72.6±6.2
83.3±2.5

TPE ()
6.4±0.1 7.2±0.1 5.6±0.1 8.0±0.1 11.0±0.0 38.2±0.5
8.6±0.1

C Computational Graph
See Figure 7 for a computational graph of the ETP algorithm.

18

Table 4: Quantitative results of models on the CIFAR100 target domain and TinyImageNet out-ofdomain using the ResNet18. The results shown mean ± one standard deviation.

Method
MCDrop BNN-VB TS EDL PN-RKL FNP
ETP

Err (%) ()
29.6±0.3 30.2±0.3 32.3±0.2 29.8±0.2 44.6±7.2 52.8±0.8
28.5±0.2

Brier ()
0.42±0.00 0.46±0.00 0.44±0.00 0.43±0.00 0.98±0.00 0.70±0.01
0.40±0.00

NLL ()
1.27±0.01 1.78±0.02 1.38±0.01 1.48±0.01 4.40±0.11 2.63±0.05
1.33±0.01

ECE (%) ()
7.9±0.3 15.1±0.3 6.6±0.5 7.2±0.3 54.0±7.2 16.7±0.7
7.5±0.4

AU-ROC (%) ()
97.4±0.8 97.2±0.5 97.1±0.7 99.4±0.3 83.9±8.7 67.2±0.5
99.2±0.2

TPE ()
15.6±0.2 16.1±0.2 13.2±0.2 16.4±0.2 28.4±0.4 54.8±0.5
16.4±0.2



Figure 7: Computational Graph. The diagram gives the graph for the ETP model. In it ·, · refers to the dot product, [·, ·] refers to a concatenation, and + refers to the weighted in place update of the memory cells. The E [·] is over the log-likelihood of yp. The enc, key, and out layer boxes refer to the three networks v(·), k(·), and h(·) discussed in the main text.
19

