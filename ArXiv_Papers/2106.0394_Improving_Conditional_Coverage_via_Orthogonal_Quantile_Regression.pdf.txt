Improving Conditional Coverage via Orthogonal Quantile Regression

arXiv:2106.00394v1 [cs.LG] 1 Jun 2021

Shai Feldman Department of Computer Science
Technion, Israel shai.feldman@cs.technion.ac.il

Stephen Bates Departments of Statistics and of EECS
UC Berkeley stephenbates@cs.berkeley.edu

Yaniv Romano Departments of Electrical Engineering
and of Computer Science Technion, Israel
yromano@cs.technion.ac.il

Abstract
We develop a method to generate prediction intervals that have a user-specified coverage level across all regions of feature-space, a property called conditional coverage. A typical approach to this task is to estimate the conditional quantiles with quantile regression--it is well-known that this leads to correct coverage in the large-sample limit, although it may not be accurate in finite samples. We find in experiments that traditional quantile regression can have poor conditional coverage. To remedy this, we modify the loss function to promote independence between the size of the intervals and the indicator of a miscoverage event. For the true conditional quantiles, these two quantities are independent (orthogonal), so the modified loss function continues to be valid. Moreover, we empirically show that the modified loss function leads to improved conditional coverage, as evaluated by several metrics. We also introduce two new metrics that check conditional coverage by looking at the strength of the dependence between the interval size and the indicator of miscoverage.
1 Introduction
Learning algorithms are increasingly prevalent within consequential real-world systems, where reliability is an essential consideration: confidently deploying learning algorithms requires more than high prediction accuracy in controlled testbeds [1, 2]. Consider, for example, estimating the effects of a drug for a specific person given their demographic information and medical measurements. In such a high-stakes setting, giving a point prediction for the drug's effect is insufficient; the decision-maker must know what the plausible range of effects for this specific individual. Instance-wise uncertainty quantification in such settings is critical [3­5]. One approach to this problem comes from the quantile regression and prediction interval literature [6­8]; instead of a point prediction, we can return a range of outcomes that represent the plausible response for a given input. We would like these prediction intervals to achieve a pre-specified coverage level (e.g., 90%) for all inputs--that is, across all regions of feature space. Training models to satisfy this validity guarantee is challenging, however, particularly with complex models like neural networks [9, 10]. In this work, we show how to generate prediction intervals that achieve coverage closer to the desired level evenly across all sub-populations. Technically, we achieve this by augmenting the quantile regression loss function with an additional term that promotes appropriately balanced coverage across the feature space.
Preprint. Under review.

Formally, consider a regression problem where we are given n training samples {(Xi, Yi)}ni=1, where X  Rp is a feature vector , and Y  R is a response variable. At test time, we observe a feature vector Xn+1 and our goal is to predict the unknown value of Yn+1 and--importantly--to report on its uncertainty. In this work, we represent this uncertainty by constructing a prediction interval C^(Xn+1)  R that is likely to contain the response Yn+1. In particular, we seek to produce intervals that contain the response with a user-specified probability 1 -  that are valid across all regions of

feature space:

P[Yn+1  C^(Xn+1) | Xn+1 = x]  1 - ,

(1)

a property known as conditional coverage. Notice that such prediction intervals are both correct in

that they satisfy a coverage guarantee and also are adaptive, in that the size of the prediction intervals

can change with the difficulty of the inputs: easy inputs give small intervals and hard inputs give large

intervals. Returning to our medical example, consider predicting the outcome of a drug from age,

gender, blood pressure, and so on. The conditional coverage requirement in (1) asks that intervals are

correct for any age, gender, and health status combination. That is, no matter what an individual's

value of the features x, the uncertainty quantification must be valid.

The conditional quantiles of Y | X = x are the natural way to produce intervals satisfying (1). Let lo = /2 and hi = 1 - /2.
Given the true conditional quantiles, qlo (x), qhi (x), we can build an oracle prediction interval satisfying (1) in the following way:

C(x) = [qlo (x), qhi (x)].

(2)

In practice, the conditional quantiles are unknown but can be estimated with quantile regression, yielding the interval C^(x) = [q^lo (x), q^hi (x)]. This approach is attractive because quantile regression yields intervals that are adaptive to heteroscedasticity without requiring parametric assumptions [11­
13], but these intervals might not satisfy the conditional coverage statement (1), since q^lo (x), q^hi (x) are merely estimations of the true quantiles [14]. Indeed, we observe in experiments 5 that traditional
quantile regression often gives intervals with poor conditional coverage, prompting the present
investigation.

In this work, we propose a novel regularization scheme to push quantile regression algorithms towards solutions that better satisfies the conditional coverage requirement (1). The core idea is to force the coverage and interval length to be approximately independent, since this independence must hold for the optimal oracle intervals in (2). A method that constructs intervals whose coverage and length are dependent is either sometimes too conservative (generating too wide intervals), sometimes too liberal (yeilding too short intervals), or both.

In addition to improved training schemes, we propose two new tools to check the validity of the resulting predictions in a meaningful way. Specifically, in Section 4, we present two new interpretable metrics to asses the violation of conditional coverage, taking advantage of the orthogonality property identified above. We use these (and other) metrics in Section 5 to study our proposal on simulated data and nine real benchmark data sets. We find that our training scheme yields improvements when used together with both a classic [6] and a more recent [15] quantile regression method.

A synthetic two-group example
We begin with a small synthetic experiment that demonstrates the challenges of constructing prediction intervals with accurate conditional coverage. We generate a dataset with two unbalanced subpopulations: 80% of the samples belong to a majority group and the remaining 20% to a minority group, where the conditional distribution Y | X of the minority group is more dispersed than the majority group. In our experiments, group membership is included as one of the features. See Section C.1 of the Supplementary Material for a full description of the distribution.
As a baseline method, we first fit a quantile neural network model (vanilla QR) by optimizing the pinball loss (see Section 2), attempting to estimate the low lo = 0.05 and high hi = 0.95 conditional quantiles. The left panel of Figure 1 shows the coverage obtained by the vanilla QR model across training epochs. The coverage on the test data is far lower than suggested by the training data, failing to reach the desired 90% level and increasing as the training progresses. In particular, this gap remains large at the epoch in which the model achieves the minimal loss evaluated on an independent validation set. Here, the empirical test coverage measured over the majority and minority

2

Figure 1: Coverage as a function of the training epochs obtained by quantile natural network model; target coverage rate is 90%. The vanilla QR model (left) is trained by optimizing the pinball loss whereas the orthogonal QR model (right) is fitted by combining the pinball loss with the proposed independence penalty. The purple vertical line marks the epoch that achieves the smallest empirical risk on a validation set.

groups is equal to 80% and 68%, and the empirical average lengths evaluated over them are 1.55, 6.45, respectively.
Next, we fit our proposed orthogonal QR model (which we will formally introduce in Section 3) on the same data. The coverage rate across epochs is illustrated in the right panel of Figure 1. In contrast to vanilla QR, the training and testing curves of the majority group overlap for the entire training epochs and both approximately reach the desired 90% level. The minority group coverage has similar behavior, with a significantly smaller gap between the two curves compared to vanilla QR. Here, the model that corresponds to the best epoch achieves 86% coverage rate with 1.62 average length on the majority group, and 83% coverage rate with 9.33 average length on the minority group. Importantly, here we are able to train for more epochs before overfitting, which leads to a better final model. To conclude, in this example orthogonal QR prevents overfitting and leads to better conditional coverage.

2 Preliminaries and related work

2.1 Quantile regression

The task of estimating the low and high conditional quantiles, q^lo (x), q^hi (x), can be expressed as a minimization problem taking the following form:

1n

(q^lo , q^hi ) = argmin
flo ,fhi F

n

(Yi, flo (Xi), fhi (Xi)).

i=1

(3)

Above,  is a loss function designed to fit quantiles; we discuss two examples next.

The most common loss function for estimating a conditional quantile q^ is called the pinball loss or check function [6, 9, 16], expressed as

(y - y^)

y - y^ > 0,

(y, y^) = (1 - )(y^ - y) otherwise.

(4)

3

Observe that for the choice  = 1/2 the above becomes the L1 norm that is known to estimate the

conditional median. By setting  = 1/2 we get a tilted version of the latter, with a degree controlled

by the value of . In the context of (3), we can set

pb 

(y,

flo

(x),

fhi

(x))

=

lo (y, flo (x))

+

hi (y, fhi (x)) to simultaneously estimate the low and high quantiles. Throughout this paper, we

will refer to this procedure as vanilla QR.

A recently-developed alternative to the pinball loss is the interval score loss [17], defined as:

int 

(y,

flo (x),

fhi (x))

=

(fhi (x)

-

flo (x))

+

2  (flo (x)

-

y)1[y

<

flo (x)]

+

2 (y


-

fhi (x))1[y

>

fhi (x)].

(5)

Note that the left-most term encourages short intervals and the two remaining components promote

intervals with the right coverage. To improve statistical efficiency, it is recommended by [15]

to simultaneously estimate all conditional quantiles by minimizing the following empirical risk function: EU[0,1][ int(·)].1 This is the approach we take in our experiments. Note that [15] proposed additional learning schemes for improving efficiency, such as group batching and ensemble

learning; see also [18]. These ideas are complementary to our proposal and may further improve the

performance of our proposed orthogonal QR.

Quantile regression is a large, active area of research, and we finish by pointing out a few representative strands of work in the literature. Estimates of conditional quantile functions using the pinball loss with specific models are proven to be asymptotically consistent under regularity conditions [16]. The work reported in [11­13] offer a non-parametric version of quantile regression. This line of research was further developed by [19] that presented a generalization to additive models that are non-parametric. The pinball loss and interval score loss can be also used to estimate conditional probability distribution [17, 20]. Nevertheless, quantiles can be estimated in other ways rather than minimizing these two loss functions. These include quantile random forest [8] and the method proposed in [21] that iteratively estimates the conditional quantile through the Majorize-Minimize algorithm. Besides the regularization term we propose, there are other suggested penalties that are useful in different situations, such as using sparse modeling in high dimensional response [22­24].

2.2 Conformal inference

Conformal inference [25] is a framework for building a prediction intervals that provably attain a weaker marginal coverage property:

P[Yn+1  C^(Xn+1)]  1 - .

(6)

Importantly, one can guarantee that this holds for any joint distribution PXY , sample size n, and predictive algorithm. In contrast to (1), the probability statement in (6) is marginal and taken over all the training and test samples {(Xi, Yi)}ni=+11. For example, in the context of the data from Figure 1, intervals that satisfy (6) would be allowed to undercover the minority group and overcover the majority group. Therefore, the statement in (6) is much weaker than that in (1). Yet, the former can be achieved for any distribution whereas the latter can not be achieved for badly-behaved distributions; see [14, 26]. While variants of the guarantee in (6) are possible [27­29], achieving coverage exactly balanced across a continuous feature cannot be done without further assumptions. Much recent work in conformal inference with quantile regression attempts to generate intervals that are adaptive to such heteroscedasticity so that they approximately achieve conditional coverage in (1), while ensuring that 1 -  marginal coverage in (6) is exactly achieved [7, 30­35]. The experiments we conduct show that our proposed Orthogonal QR method can be used in combination with conformal prediction to improve the conditional coverage property while attaining valid marginal coverage.

3 Proposed method: orthogonal quantile regression
3.1 Formulating the learning scheme
This section presents a modification of the pinball loss or interval score loss in order to fit models
with improved conditional coverage. Denote by V = 1[Y  C^(X)] the coverage identifier, and by
L = |C^(X)| the interval's length. 1The code is hosted at https://github.com/YoungseogChung/calibrated-quantile-uq

4

Our proposal is motivated by the following observation.
Proposition 1 (Independence of width and coverage). Let (X, Y ) be a sample drawn from PXY , and let X be the support of X. If the distribution of Y | X = x is continuous for all x  X , and its interval C^(X) satisfies P[Y  C^(X)|X = x] = 1 -  for all x  X and some   (0, 1), then the interval satisfies V  L.

In particular, the above implies that the length of an interval L = qhi (X) - qlo (X) constructed by the true low and high quantiles is independent of the coverage identifier V , as stated next.
Corollary 1. Under the assumptions of Proposition 1, an interval constructed by the true conditional quantiles satisfies V  L.

We note that an earlier, limited version of this observation appears in [36] in the context conditional coverage for classification problems. All proofs are presented in Section B of the Supplementary Material. Since intervals constructed by the true conditional quantiles obey the independence property, forcing the fitted model to approximately satisfy this property during training can result in better conditional coverage for future test points.

This leads us to our proposed orthogonal QR objective:

1n

(q^lo , q^hi ) = argmin
flo ,fhi F

n

(Yi, flo (Xi), fhi (Xi)) + R(L, V).

i=1

(7)

where

 is either

pb 

or

int, L  Rn is a vector that contains Li = fhi (Xi) - flo (Xi) = |C^(Xi)|

as its elements, and V  Rn is a vector with entries Vi = 1[Yi  C^(Xi)]. (To facilitate training with

gradient methods, in practice we use a smooth approximation to the indicator function; see Section A.1 of the Supplementary Material.) The function R(L, V)  R+ returns a real-valued score that

quantifies the strength of the dependence between L and V , where a large value indicates that the

two are more dependent; we discuss specific choices in Section 3.2. The regularization strength is

controlled by the hyperparameter .

Lastly, we point out that our proposal falls into the broader theme of fitting models while enforcing conditional independence properties, a goal that is important for algorithmic fairness [e.g., 37­39]. This work aims to achieve uncertainty estimates that are equally good across all feature space, a prediction interval analog to the goal of [40].

3.2 The orthogonality loss

We now turn to the question of choosing the specific dependence loss penalty, R in (7). In principle, we could use any dependence measure from the many in the literature: chi-squared tests [41], Pearson's correlation, distance correlation [42], Kolmogorov-Smirnov statistic [43], Randomized Dependence Coefficient [44], Hilbert-Schmidt independence criterion (HSIC) [45], and so on. In this work we focus on Pearson's correlation and HSIC which are described hereafter.

The Pearson's correlation measures the linear dependency between two random variables. Here, the

loss is defined as:

Cov(L, V )

Rcorr(L, V ) =

. Var(L) Var(V )

(8)

The advantages of this choice are its simplicity and the minimal computational burden.

Next, HSIC is a more sophisticated, nonlinear complement to the Pearson's correlation measure, which can detect arbitrary complex relationships between the coverage identifier and the interval length. It is an analog of the well-known Maximum Mean Discrepancy (MMD) distance [46], but is a measure of dependence. The idea is that while Rcorr(L, V ) = 0 does not necessarily imply that L and V are independent, having Rcorr(g(L), h(V )) = 0 for every continuous bounded functions g, h guarantees the independence property [47]. While it is impossible to sweep over all possible continuous bounded functions, HSIC offers a tractable solution, guaranteeing that HSIC(L, V ) = 0 if and only if L  V [45]. In our work, we utilize this measure, and define the orthogonality loss
as RHSIC(L, V ) = HSIC(L, V ) (taking the square root to magnify small values). This choice is similar to the one advocated in [48].

5

With these choices of R, we now show that the true conditional quantiles are a solution for the orthogonal QR problem.
Theorem 1 (Validity of orthogonal quantile regression). Suppose Y | X = x follows a continuous distribution for each x  X , and suppose that qlo (X), qhi (X)  F .
Consider the infinite-data version of the orthogonal QR optimization in (7):

argmin E (Y, flo (X), fhi (X)) + R |C^(X)|, I[Y  C^(X)] ,
flo ,fhi F

where C^(X) = [flo (X), fhi (X)],

 is either

pb 

or

int 

,

and

R

is

Rcorr

or RHSIC.

Then, true

conditional quantiles are solutions to the above optimization problem. Moreover, if the solution is

unique for  = 0 then the solution is unique for all  > 0.

The uniqueness part of the theorem means that whenever vanilla QR is guaranteed to give the correct quantiles in the large-sample limit, then orthogonal QR will give the same (correct) solution. The result continues to hold for any dependence measure R that achieves its minimum value for any two independent variables, a basic property that all dependence measures that we are aware of satisfy. See the proof in Section B of the Supplementary Material for further details.

4 Metrics for assessing conditional coverage

We next discuss several quantitative measures of conditional coverage. We will introduce two new metrics for conditional coverage, and then review one existing proposal from the literature. Lastly, we will discuss two ad-hoc metrics to help us compare orthogonal QR with vanilla QR in our upcoming simulation experiments.

4.1 Two new metrics for conditional coverage
Pearson's correlation: As previewed in the previous section, the Pearson correlation between the interval size and the indicator of coverage (i.e., Rcorr from (8)) is a simple, effective way to measure conditional coverage. However, to the best of our knowledge, we are the first to leverage it for this purpose.
HSIC: Similarly, we consider the HSIC measure of dependence between the interval size and the indicator of coverage (i.e., RHSIC above). We estimate this metric as described in [40].2 As before, to our knowledge this has never been leveraged as a metric to asses conditional coverage.

4.2 Other metrics for our empirical evaluations

WSC: As an additional measure of conditional coverage, we evaluate the coverage over the worstslab as proposed in [49].3 To avoid a case where an improvement in this quantity is obtained by naively enlarging all prediction intervals, we suggest a variant that we call WSC. This metric is defined as the absolute difference between the worst-slab coverage and the marginal coverage, both evaluated on test data I:
WSC = WSC {(Xi, Yi)}iI ; C^ - Coverage {(Xi, Yi)}iI ; C^ .

Above, Coverage

{(Xi, Yi)}iI ; C^

=

1 |I|

iI 1[Yi  C^(Xi)] where C^(x) is a prediction inter-

val method. Importantly, a uniform increase of the length of all intervals will not deceive the WSC

measure as it will remain fixed.

ILS-Coverage: We next consider a measure that checks whether the intervals made larger
by orthogonal QR compared to vanilla QR are necessary for improving the conditional
coverage. In general, suppose we are given two algorithms A1 and A2 for constructing prediction intervals. Let Li = |C^A1 (Xi)| - |C^A2 (Xi)| be the difference between the interval length |C^A(Xi)| obtained by A1 and A2, evaluated on the same test point Xi. Next, let q0.9({Li}iI) be the 90%

2The code is available at https://github.com/danielgreenfeld3/XIC 3We used the implementation from https://github.com/msesia/arc/

6

empirical quantile of {Li}iI. Then, let ILS be the 10% of samples whose length increased the most:
ILS = {i : Li  q0.9({Li}iI ), i  I}. With this notation in place, we propose the ILS-Coverage metric:
ILS-Coverage = Coverage {(Xi, Yi)}iILS ; C^Ak - Coverage {(Xi, Yi)}iI ; C^Ak .
In words, the above is the absolute difference between the coverage over the ILS samples and the marginal coverage, evaluated for each algorithm Ak, k = 1, 2. A smaller value for k = 1 indicates that the points with very different size under A1 and A2 are handled better by A1.
Node-Coverage: As a variant of ILS-Coverage, we identify a sub-population characterized by a small set of features such that the two algorithms A1 and A2 produce very different intervals, and check the coverage on this region. To this end, we label the ILS samples as the positive class and fit a binary classifier formulated as a decision tree, aiming to predict whether a sample X belongs to the ILS set. Denote the set of tree nodes in depth at most three that contain at least 5% of the samples by {Nodej}j, where Nodej  I. Next, let ND be the set of indices of the samples that belong to the node that maximizes the following ratio: |Nodej  ILS| / |Nodej \ ILS|.
Finally, given a method for constructing prediction intervals C^(·), compute the distance between the coverage over the ND samples and the marginal coverage, formulated as
Node-Coverage = Coverage {(Xi, Yi)}iND ; C^ - Coverage {(Xi, Yi)}iI ; C^ .
5 Experiments
Armed with the performance metrics described in Section 4, we now systematically quantify the effectiveness of the proposed independence penalty when combined with baseline quantile regression methods. In all experiments, we apply a deep neural network as a base model for constructing prediction intervals with 1 -  = 0.9 coverage level. Section D of the Supplementary Material gives the details about the network architecture, training strategy, and details about this experimental setup. Software implementing the proposed method and reproducing our experiments can be found at https://github.com/Shai128/oqr
5.1 A synthetic two-group setting
We return to the synthetic two-group setting previewed in Section 1, but first provide more details about the data. In this data set, the difference in distribution between the majority and minority groups is controlled by modifying the noise level of the conditional distribution Y | X of the minority group. Furthermore, X has 50 coordinates, the first of which indicates the group membership. Section C.1 of the Supplementary Material contains more details about the generation of this synthetic data. To analyze the performance of our method, we generate 7000 i.i.d. samples and repeat the following experiment for 30 random train/validation/test splits of the data. We fit a quantile regression model with pinball loss on 5040 training samples, where we tune the number of epochs on an independent validation set that contains 560 samples. The remaining 1400 samples are used to test the model's performance. We pre-processed the feature vector using z-score standardization, and normalized the features and response variables to have a zero mean and a unit variance.
In Table 1 we report the average coverage, length, and conditional coverage metrics for vanilla QR and orthogonal QR for two minority-group noise levels. (The ILS-Coverage, Node-Coverage metrics are not reported in this case, since they both essentially correspond to the minority group's coverage level, which is given in the table.) The intervals constructed by the baseline vanilla QR undercover both the majority and minority group but; this tendency is more severe for the latter. By contrast, the regularized model achieves similar coverage rates for the two groups, with levels that are closer to the nominal 90%. This is also reflected by the improvement in the Pearson's correlation, HSIC, and WSC metrics of conditional coverage. Overall, orthogonal QR gives wider intervals for the minority group, which is anticipated since the coverage of the baseline model is far below the nominal rate. As for the majority group, our proposed training gives intervals of about the same length compared to the baseline model, while achieving a considerably higher coverage rate. In fact, the regularized model constructs even shorter intervals in
7

Table 1: Simulated data experiments. Performance of neural network quantile regression, using either vanilla QR (baseline) or orthogonal QR (OQR) with penalty term Rcorr. The average coverage, length, and percent of improvement in the conditional coverage metrics described in Section 4 are evaluated over 30 independent trials. The standard errors for coverage and length are about 0.25, 0.06, respectively. The standard errors for the conditional coverage metrics are presented in Supplementary Table 10.

Minority Majority Coverage (%) Minority Coverage (%) Majority Lengths Minority Lengths Noise Level

Improvement (%)

baseline / OQR

baseline / OQR

baseline / OQR

baseline / OQR

corr HSIC WSC

Low High

79.64 / 87.24 81.07 / 86.97

66.34 / 82.55 68.74 / 83.74

1.59 / 1.62 1.88 / 1.71

6.45 / 9.18 22.05 / 30.11

+64.07 +53.76 -13.88 +72.21 +27.99 +17.96

the high noise level case. Lastly, we note that this performance continues to hold even when using interval score loss in place of the pinball loss; see Section E.1 of the Supplementary Material.

5.2 Real data

Next, we compare the performance of the proposed orthogonal QR to vanilla QR on nine benchmarks data sets as in [15, 30]: Facebook comment volume variants one and two (facebook_1, facebook_2), blog feedback (blog_data), physicochemical properties of protein tertiary structure (bio), forward kinematics of an 8 link robot arm (kin8nm), condition based maintenance of naval propulsion plants (naval), and medical expenditure panel survey number 19-21 (meps_19, meps_20, and meps_21). See Section C.2 of the Supplementary Material for details about these data sets. We follow the experimental protocol and training strategy described in Section 5.1. We randomly split each data set into disjoint training (54%), validation (6%), and testing sets (40%). We normalized the features and response variables to have a zero mean and a unit variance each, except for facebook_1, facebook_2, blog_data, and bio datasets in which we log transform Y before the standardization.

Table 2 summarizes the performance of

vanilla QR and orthogonal QR. Our

proposed method consistently improves the

conditional coverage, as measured by the

Pearson's correlation, HSIC, and

WSC metrics for conditional coverage, even

though the latter two are not optimized directly

by orthogonal QR. In Figure 2, we show the

coverage as a function of the interval's length

evaluated on the meps_21 data set, and find that

orthogonal QR (in orange) is closer to the

nominal 90% level when compared to the baseline method. Our penalty also improves the Node-Coverage in most data sets (see Table 2), indicating that the baseline model tends to undercover the response of at least one sub-

Figure 2: Length versus coverage for vanilla QR and orthogonal QR over the meps_21 data. In Section D.3 of the Supplementary Material we explain how the figure was constructed.

population. Turning to the statistical efficiency, observe that the intervals produced by the regularized

models tend to be wider than the ones of the baseline method, which is needed to better achieve

conditional coverage. We further probe this phenomenon by checking the ILS-Coverage which

shows that the regions with wider intervals now have better coverage.

In Section E.2 of the Supplementary Material we provide additional experiments by replacing the pinball loss with the recently-introduced interval score loss. The effect of the decorrelation penalty is similar to the one described above. Moreover, in Section E.2 we also compare between the decorrelation and HSIC penalties for independence, and show that in most data sets the decorrelation penalty achieves better performance over all metrics of conditional independence at the cost of producing wider intervals.

8

Table 2: Conditional coverage on real data. Performance of a neural network model for quantile regression, using either vanilla QR (baseline) or orthogonal QR (OQR) with penalty term Rcorr. The average coverage, length, and percent of improvement in the conditional coverage metrics described in Section 4 are evaluated over 30 independent trials. The standard errors for coverage and width are about 0.45 and 0.03, respectively. The standard errors for the conditional coverage metrics are presented in Supplementary Table 12.

Dataset Name Coverage (%)

Length

Improvement (%)

baseline OQR baseline OQR

corr

HSIC WSC ILS Node

facebook_1

88.10

90.48

1.09

facebook_2

87.38

91.13

1.07

blog_data

82.89

88.92

1.36

bio

88.42

89.08

1.88

kin8nm

84.63

88.62

0.98

naval

89.89

89.50

0.56

meps_19

82.44

85.16

0.84

meps_20

82.81

84.27

0.86

meps_21

82.50

84.07

0.86

1.44

+81.08 +76.75 +33.42 +65.81 +47.30

1.41

+91.27 +96.36 +33.86 +65.71 +55.63

1.64

+77.49 +2.27 +21.44 +89.94 +34.41

2.03

+53.49 +75.55 -44.73 +43.20 +7.25

1.28

+27.54 +48.47 +14.97 +57.38 -16.44

1.49

+75.19 +33.98 -57.52 +72.36 -14.34

1.00

+54.16 +22.25 +43.28 +88.05 +45.43

1.03

+43.51 +1.99 +24.06 +84.71 +46.88

0.99

+57.46 +13.62 +20.78 +85.02 +38.28

Table 3: Conditional coverage on real data, with conformalization. Performance of a neural network model for conformalized quantile regression, using either vanilla CQR (CQR) or orthogonal CQR (COQR) with penalty term Rcorr. Refer to the caption of Table 2 for further details. The standard errors for coverage and length are about 0.2 and 0.03, respectively. The standard errors for the conditional coverage metrics are presented in Supplementary Table 15.

Dataset Name Coverage (%)

Length

Improvement (%)

CQR

COQR

CQR

COQR

corr

HSIC WSC ILS Node

facebook_1

90.08

90.11

1.09

facebook_2

90.40

89.94

1.07

blog_data

89.93

90.15

1.41

bio

90.02

89.98

1.93

kin8nm

90.11

90.11

1.12

naval

89.84

90.06

0.55

meps_19

89.96

89.84

0.92

meps_20

90.08

90.19

0.95

meps_21

89.93

89.89

0.94

1.43

+58.28 +37.61 +34.86 +67.79 +29.46

1.39

+76.25 +52.16 +29.51 +53.33 +52.46

1.64

+13.77 -79.60 +24.38 +90.57 +39.38

2.05

+51.19 +71.55 -30.80 +39.18 -40.48

1.33

+18.16 +13.06 -69.52 +58.14 -1.44

1.51

+77.28 +36.78 -77.14 +68.24 -10.18

1.05

+50.59 +39.94 +58.85 +83.77 +36.84

1.09

+43.22 +39.66 +47.50 +84.13 +43.89

1.05

+41.88 +29.69 +33.46 +79.47 +37.33

Conformalized quantile regression results
In previous experiments the quantile regression methods tend to (marginally) undercover the response variables. This limitation is easily remedied by combining vanilla QR or orthogonal QR with conformalized quantile regression [30] that adjusts the estimated intervals to exactly achieve the marginal coverage property in (6). Table 3 summarizes the results, demonstrating that by conformalizing the intervals our proposed method precisely achieves the desired marginal coverage while improving the conditional coverage of the baseline model, as measured by the Pearson's correlation, HSIC, and WSC, Node-Coverage metrics. The two independence metrics indicate that even after after adjusting the intervals to achieve marginal coverage, our method still results in improved independence between the coverage event and length. We note that the WSC, and Node-Coverage metrics have a more muted improvement compared to the setting without conformalization, since the conformalization step smooths out the coverage to some extent. Further details regarding this conformalizing setting is given in Section D.4 of the Supplementary Material.
6 Conclusion
In this work we presented the orthogonal QR approach to achieve coverage closer to the desired level evenly across all sup-populations in the setting of quantile regression algorithms. A technical limitation of our method is the use of large batches during training, required to effectively detect the dependencies between the intervals length and coverage events. In our experiments we focus on i.i.d data, but we believe that the orthogonal loss can be beneficial beyond this, such as in time-series data, which we hope to investigate in future work. A related future direction is to encourage independence
9

between a coverage event and a function of the feature vector, other than that of interval length-- similar logic to that of our proposal means that this independence would hold for the true quanties. A clever choice may better capture the relationships between X and the coverage obtained by the model, and further improve conditional coverage. As a concluding remark, while empirical evidence shows that our orthogonal QR approach produces intervals that represent the uncertainty in subgroups more reliably than standard methods, it does not guarantee a valid coverage across all feature space with access to only a finite sample. This guarantee may be necessary for ensuring that predictions are unbiased against a minority group of interest, indexed by an individual's gender or race, for example. To alleviate this, one can combine our methods with the equalized coverage framework [28] that builds upon conformal inference to achieve the desired coverage for pre-defined sub-populations, which is a weaker but achievable demand compared to conditional coverage.
Acknowledgments and Disclosure of Funding
Y.R. thanks the Career Advancement Fellowship, Technion, for providing research support.
References
[1] Timothy John Sullivan. Introduction to uncertainty quantification, volume 63. Springer, 2015.
[2] Christian Soize. Uncertainty quantification. Springer, 2017.
[3] Lewis H. Mervin, Simon Johansson, Elizaveta Semenova, Kathryn A. Giblin, and Ola Engkvist. Uncertainty quantification in drug design. Drug Discovery Today, 26(2):474­489, 2021.
[4] Ryutaro Tanno, Daniel E. Worrall, Enrico Kaden, Aurobrata Ghosh, Francesco Grussu, Alberto Bizzi, Stamatios N. Sotiropoulos, Antonio Criminisi, and Daniel C. Alexander. Uncertainty modelling in deep learning for safer neuroimage enhancement: Demonstration in diffusion MRI. NeuroImage, 225:117366, 2021.
[5] Edmon Begoli, Tanmoy Bhattacharya, and Dimitri F. Kusnezov. The need for uncertainty quantification in machine-assisted medical decision making. Nature Machine Intelligence (Online), 1(1), 1 2019.
[6] Roger Koenker and Gilbert Bassett. Regression quantiles. Econometrica, 46(1):33­50, 1978.
[7] Rafael Izbicki, Gilson Shimizu, and Rafael Stern. Flexible distribution-free conditional predictive bands using density estimators. In Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics, volume 108, pages 3068­3077. PMLR, 26­28 Aug 2020.
[8] Nicolai Meinshausen. Quantile regression forests. J. Mach. Learn. Res., 7:983­999, December 2006.
[9] Roger Koenker and Kevin F. Hallock. Quantile regression. Journal of Economic Perspectives, 15(4):143­156, December 2001.
[10] Yichen Jia and Jong-Hyeon Jeong. Deep learning for quantile regression under right censoring: DeepQuantreg. arXiv preprint arXiv:2007.07056, 2021.
[11] Ichiro Takeuchi, Quoc V. Le, Timothy D. Sears, and Alexander J. Smola. Nonparametric quantile estimation. Journal of Machine Learning Research, 7(45):1231­1264, 2006.
[12] Kenneth Q. Zhou and Stephen L. Portnoy. Direct use of regression quantiles to construct confidence sets in linear models. The Annals of Statistics, 24(1):287 ­ 306, 1996.
[13] Kenneth Q. Zhou and Stephen L. Portnoy. Statistical inference on heteroscedastic models based on regression quantiles. Journal of Nonparametric Statistics, 9(3):239­260, 1998.
10

[14] Rina Foygel Barber, Emmanuel J Candès, Aaditya Ramdas, and Ryan J Tibshirani. The limits of distribution-free conditional predictive inference. Information and Inference: A Journal of the IMA, 2019.
[15] Youngseog Chung, Willie Neiswanger, Ian Char, and Jeff Schneider. Beyond pinball loss: Quantile methods for calibrated uncertainty quantification. arXiv preprint arXiv:2011.09588, 2020.
[16] Ingo Steinwart and Andreas Christmann. Estimating conditional quantiles with the help of the pinball loss. Bernoulli, 17(1), Feb 2011.
[17] Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association, 102(477):359­378, 2007.
[18] Taesup Kim, Rasool Fakoor, Jonas Mueller, Alexander J Smola, and Ryan J Tibshirani. Deep quantile aggregation. arXiv preprint arXiv:2103.00083, 2021.
[19] Roger Koenker. Additive models for quantile regression: Model selection and confidence bandaids. Brazilian Journal of Probability and Statistics, 25(3):239 ­ 262, 2011.
[20] James W. Taylor. A quantile regression neural network approach to estimating the conditional density of multiperiod returns. Journal of Forecasting, 19(4):299­311, 2000.
[21] David R. Hunter and Kenneth Lange. Quantile regression via an MM algorithm. Journal of Computational and Graphical Statistics, 9(1):60­77, 2000.
[22] Alexandre Belloni, Victor Chernozhukov, and Kengo Kato. Valid post-selection inference in high-dimensional approximately sparse quantile regression models. Journal of the American Statistical Association, 114(526):749­758, 2019.
[23] Vidyashankar Sivakumar and Arindam Banerjee. High-dimensional structured quantile regression. In Proceedings of the 34th International Conference on Machine Learning, volume 70, pages 3220­3229, 06­11 Aug 2017.
[24] Alexandre Belloni and Victor Chernozhukov. L1-penalized quantile regression in highdimensional sparse models. The Annals of Statistics, 39(1):82­130, 2011.
[25] Vladimir Vovk, Alex Gammerman, and Glenn Shafer. Algorithmic Learning in a Random World. Springer, 2005.
[26] Dhruv Medarametla and Emmanuel Candès. Distribution-free conditional median inference. arXiv preprint arXiv:2102.07967, 2021.
[27] Vladimir Vovk. Conditional validity of inductive conformal predictors. In Asian conference on machine learning, pages 475­490. PMLR, 2012.
[28] Yaniv Romano, Rina Foygel Barber, Chiara Sabatti, and Emmanuel Candès. With malice toward none: Assessing uncertainty via equalized coverage. Harvard Data Science Review, 2(2), 4 2020. https://hdsr.mitpress.mit.edu/pub/qedrwcz3.
[29] Stephen Bates, Anastasios Angelopoulos, Lihua Lei, Jitendra Malik, and Michael I. Jordan. Distribution-free, risk-controlling prediction sets. arXiv preprint, 2021. arXiv:2101.02703.
[30] Yaniv Romano, Evan Patterson, and Emmanuel Candes. Conformalized quantile regression. In Advances in Neural Information Processing Systems, volume 32, 2019.
[31] Matteo Sesia and Emmanuel J. Candès. A comparison of some conformal quantile regression methods. Stat, 9(1), Jan 2020.
[32] Danijel Kivaranovic, Kory D Johnson, and Hannes Leeb. Adaptive, distribution-free prediction intervals for deep networks. In International Conference on Artificial Intelligence and Statistics, pages 4346­4356. PMLR, 2020.
[33] Victor Chernozhukov, Kaspar Wüthrich, and Yinchu Zhu. Distributional conformal prediction. arXiv preprint arXiv:1909.07889, 2021.
11

[34] Chirag Gupta, Arun K. Kuchibhotla, and Aaditya K. Ramdas. Nested conformal prediction and quantile out-of-bag ensemble methods. arXiv preprint arXiv:1910.10562, 2021.

[35] Rafael Izbicki, Gilson Shimizu, and Rafael B. Stern. CD-split and HPD-split: efficient conformal regions in high dimensions. arXiv preprint arXiv:2007.12778, 2021.

[36] Anastasios Angelopoulos, Stephen Bates, Jitendra Malik, and Michael I. Jordan. Uncertainty sets for image classifiers using conformal prediction. arXiv preprint, 2020. arXiv:2009.14193.

[37] Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez-Rodriguez, and Krishna P. Gummadi. Fairness constraints: A flexible approach for fair classification. Journal of Machine Learning Research, 20(75):1­42, 2019.

[38] Michele Donini, Luca Oneto, Shai Ben-David, John Shawe-Taylor, and Massimiliano Pontil. Empirical risk minimization under fairness constraints. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, page 2796­2806, 2018.

[39] Yaniv Romano, Stephen Bates, and Emmanuel Candes. Achieving equalized odds by resampling sensitive attributes. In Advances in Neural Information Processing Systems, volume 33, pages 361­371, 2020.

[40] Daniel Greenfeld and Uri Shalit. Robust learning with the Hilbert-Schmidt independence criterion. In International Conference on Machine Learning, pages 3759­3768. PMLR, 2020.

[41] Karl Pearson. On the Criterion that a Given System of Deviations from the Probable in the Case of a Correlated System of Variables is Such that it Can be Reasonably Supposed to have Arisen from Random Sampling, pages 11­28. Springer New York, 1992.

[42] Gábor J. Székely, Maria L. Rizzo, and Nail K. Bakirov. Measuring and testing dependence by correlation of distances. The Annals of Statistics, 35(6), Dec 2007.

[43] Vladimir Ivanovich Smirnov. Kolmogorov­Smirnov Test, pages 283­287. Springer New York, New York, NY, 2008.

[44] David Lopez-Paz, Philipp Hennig, and Bernhard Schölkopf. The randomized dependence coefficient. In Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 1, page 1­9, Red Hook, NY, USA, 2013.

[45] Arthur Gretton, Olivier Bousquet, Alex Smola, and Bernhard Schölkopf. Measuring statistical dependence with Hilbert-Schmidt norms. In Algorithmic Learning Theory, pages 63­77, 2005.

[46] Arthur Gretton, Karsten M. Borgwardt, Malte J. Rasch, Bernhard Schölkopf, and Alexander Smola. A kernel two-sample test. Journal of Machine Learning Research, 13(25):723­773, 2012.

[47] Alfréd Rényi. On measures of dependence. Acta Mathematica Academiae Scientiarum Hungarica, 10(3):441­451, Sep 1959.

[48] Yujia Li, Kevin Swersky, and Rich Zemel. Generative moment matching networks. In International Conference on Machine Learning, pages 1718­1727. PMLR, 2015.

[49] Maxime Cauchois, Suyash Gupta, and John C. Duchi. Knowing what you know: valid and validated confidence sets in multiclass and multilabel prediction. Journal of Machine Learning Research, 22(81):1­42, 2021.

[50] Facebook comment volume data set. https://archive.ics.uci.edu/ml/ datasets/Facebook+Comment+Volume+Dataset. Accessed: January, 2019.

[51] Blogfeedback data set.

https://archive.ics.uci.edu/ml/datasets/

BlogFeedback. Accessed: January, 2019.

[52] Physicochemical properties of protein tertiary structure data set. https://archive. ics.uci.edu/ml/datasets/Physicochemical+Properties+of+Protein+ Tertiary+Structure. Accessed: January, 2019.

12

[53] Kinematics of an 8 link robot arm. http://ftp.cs.toronto.edu/pub/neuron/ delve/data/tarfiles/kin-family/. Accessed: May, 2021.
[54] Condition based maintenance of naval propulsion plants data set. http://archive. ics.uci.edu/ml/datasets/Condition+Based+Maintenance+of+Naval+ Propulsion+Plants. Accessed: May, 2021.
[55] Medical expenditure panel survey, panel 19. https://meps.ahrq.gov/mepsweb/ data_stats/download_data_files_detail.jsp?cboPufNumber=HC-181. Accessed: January, 2019.
[56] Medical expenditure panel survey, panel 20. https://meps.ahrq.gov/mepsweb/ data_stats/download_data_files_detail.jsp?cboPufNumber=HC-181. Accessed: January, 2019.
[57] Medical expenditure panel survey, panel 21. https://meps.ahrq.gov/mepsweb/ data_stats/download_data_files_detail.jsp?cboPufNumber=HC-192. Accessed: January, 2019.
[58] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In 3rd International Conference on Learning Representations, 2015.
13

Appendices

A Emperical estimations

A.1 A differentiable coverage identifier

Given a prediction interval C^(Xi) = [q^lo (Xi), q^lo (Xi)] for a point Xi, we approximate its coverage
indicator 1[Y  C^(Xi)] in the following way:

V~i = tanh (c min{Yi - q^lo (Xi), q^hi (Xi) - Yi})

V^i

=

1 2

V~i + 1

(9)

where c  R+ controls the slope of the step function. In the experiments, we set c to be equal to 5 · 103. This approximation is differentiable and used in practice.

B Theoretical results

B.1 Proof of proposition 1

Proof. Consider an l  R, and v  {0, 1}. To prove the theorem, it suffices to show that P(V = v | L = l) = P(V = v). Denote gX , gX|L the density functions of X and X|L respectively, and denote  = P(V = v | X = x). It is given that the interval constructed satisfies P(V = 1 | X = x) = 1 -  for all x  X , and therefore  is a constant and equals 1 -  if v = 1, or  if v = 0.
First, we show that P(V = v) = :

P(V = v) =

P(V = v | X = x)gX (x) dx = 

gX (x) dx = 

xX

xX

To conclude our proof, we show that P(V = v | L = l) =  as well.

P(V = v | L = l) =

P(V = v | L = l, X = x)gX|L(x | l) dx

{xX |L=l}

=

P(V = v | X = x)gX|L(x | l) dx

{xX |L=l}

=

gX|L(x | l) dx

{xX |L=l}

=  = P(V = v)

B.2 Proof of corollary

Proof. The interval constructed by true
P(Y  C(X)|X = x) = 1 -  for all

conditional quantiles C(X) = [qlo (X), x  X , and hence, from Proposition 1

qhi we

(X)] satisfies conclude that

L  V .

B.3 Proof of theorem 1
Proof. The true quantiles minimize the first term in the sum, by the properties of pinball loss or interval score loss. Moving to the next term. Assuming Y | X is continuous, from Corollary 1 the true conditional quantiles satisfy: V  L, and this implies that their correlation, denoted as CORR(L, V ), and HSIC are fixed and equal zero, and therefore:
CORR(L, V ) = 0  Rcorr(L, V ) = |CORR(L, V )| = |0| = 0, 
HSIC(L, V ) = 0  RHSIC(L, V ) = HSIC(L, V ) = 0 = 0.
14

This means that for either choice loss function, R(L, V ) = 0 which is the minimal value of the second term, as it is non-negative. Therefore, the true quantiles are a solution to the minimization problem, since they minimize both terms separately. Turning to the uniqueness, assume there is a unique solution for  = 0. Then, since the true quantiles minimize the the pinball loss or interval score loss, it follows that the true conditional quantiles are the unique solution. We proved that they attain R(L, V ) = 0, the minimum value this term could achieve. Thus, we conclude that there is only one solution for all  > 0.
C Datasets details
C.1 Synthetic datasets details
The synthetic dataset is determined by the parameter  which controls the variance of the response value of the minority group. The generation of the feature vector and the response variable is done in the following way:

^  Uniform(0, 1)50, ^  Uniform(0, 1)50,

^

^

=

^

,
2

=

, ^ 2

1,i  N (0, 1), 2,i  N (0, 1),

Xi,1-49  Uniform(0, 5)49,

0, w.p. 0.8 Xi,0 = 1, otherwise

Yi =

0.03T Xi1,i, 0.03T Xi1,i + 2,i,

Xi,0 = 0 Xi,0 = 1

1  i  n, 1  i  n, 1  i  n,
1  i  n,

where Uniform(a, b) is a uniform distribution on the interval (a, b), and N (0, 1) is the standard Gaussian distribution. The dataset with minority noise level set to low was created with  = 3, and the one with the High noise level with  = 10. Both datasets contain 7000 samples, and were generated with a seed value equals to 1.
C.2 Real dataset details
Table 4 shows the size of each data set and the feature dimension.

Table 4: Real datasets information. Number of samples and feature dimension of each real dataset we used in the experiments

Dataset Name Number of Samples Feature Dimension

facebook_1 [50] facebook_2 [50] blog_data [51]
bio [52] kin8nm [53] naval [54] meps_19 [55] meps_20 [56] meps_21 [57]

40948 81311 52397 45730 8192 11934 15785 17541 15656

53 53 2805 9 8 17 139 139 139

15

D Experimental setup
D.1 Setup
The network we used receives as an input a vector of size p + 1 (where the feature dimention is p). The first p variables in the input vector correspond to the elements of the feature vector, and the last variable is the quantile level of the desired quantile. We trained quantile regression with pinball loss over two quantile levels: 95% and 5% level quantiles, and trained quantile regression with interval score over all quantile levels. For each model, we built prediction intervals using the 95%-th and 5%-th quantiles it outputted, as explained in 2.1. The code we used is based on the implementation of [15]. The penalty multipliers for each dataset were chosen by an independent train-validation-test split (with seed=42), so the coefficient that achieved the best performance was taken. The multipliers tested for the real data are: 0.1, 0.5, for pinball loss, and 0.1, 0.5, 1, 3, for interval score loss. For the synthetic data we checked: 0.1, 0.5 for both losses. When combining our penalty with pinball loss, the coefficient given to the model is multiplied by 0.1.
D.2 Synthetic data experiments
We split the synthetic datasets into a training set (64%), a validation set (16%) for early stopping, and a test set (20%) to evaluate performance. After that, the feature vectors and the labels were preprocessed using z-score normalization. The neural network is made of 2 layers of 64 hidden units, and a ReLU activation function. The network does not contain a dropout layer. The learning rate used is 1e-3, the model's optimizer is Adam [58], and the batch size is 1024 for all methods. The maximum number of epochs is 10000, but the training is stopped early if the validation loss does not increase for 200 epochs, and in this case the model with the lowest loss is taken as the final model. The results were averaged over all seeds in the range between 0 and 29 (inclusive).
The decorrelation coefficients used in the experiments are: for pinball loss, 0.5 for both  = 3, and  = 10, and for interval score loss 3 for both  = 3, 10.
D.3 Real data experiments
First, the datasets: facebook_1, facebook_2, blog_data, and bio, were log scaled: y = log(y - min(y) + 1). We split each dataset it into a training set (54%), a validation set (6%) for early stopping, and a test set (40%) to evaluate performance. After that, the feature vectors and the labels were preprocessed using z-score normalization. The neural network is made of 3 layers of 64 hidden units, and ReLU activation function. The network contains a dropout layer with parameter 0.1. The learning rate, training strategy and batch size are the same as described in D.2. The maximum number of epochs is 10000, and we used the same early stopping technique described in D.2. The results were averaged over all seeds in the range between 0 and 29 (inclusive).
Figure 2 was produced by splitting all test's coverages and lengths over all seeds to hundred bins, and averaging each bin separately. Both vanilla QR and orthogonal QR used pinball loss as an objective function, and the penalty used by our method is Rcorr. Table 5 displays the multiplier used for each data set and method.
D.4 Conformalized quantile regression experiments
We used the same setting as in D.3, except for the following changes. The dataset was split into a training set (54%), a validation set (6%) for early stopping, a calibration set (20%) to achieve valid marginal coverage, and a test set (20%) to evaluate performance. The calibration method used is Conformalized Quantile Regression [30].
D.5 Machine's spec
The resources used for the experiments are:
· CPU: Intel(R) Core(TM) i5-10600K CPU 4.10GHz. · GPU: NVIDIA GeForce RTX 2060 SUPER.
16

Table 5: Penalty multipliers used for each dataset

Pinball Loss

Interval Score Loss

Dataset Name Decorr multiplier HSIC multiplier

Dataset Name Decorr multiplier

facebook_1

0.5

0.5

facebook_2

0.5

0.5

blog_data

0.5

0.5

bio

0.1

0.1

kin8nm

0.1

0.1

naval

0.1

0.1

meps_19

0.5

0.1

meps_20

0.5

0.1

meps_21

0.5

0.5

facebook_1

0.5

facebook_2

0.5

blog_data

1

bio

0.1

kin8nm

0.5

naval

0.1

meps_19

3

meps_20

3

meps_21

3

· OS: Windows 10.
E Additional results
E.1 Synthetic data As shown in Table 6, when combined with interval score loss, the suggested penalty consistently improves all metrics, and balances the coverage rates over the majority and minority subgroups.

Table 6: Simulated data experiments - using interval score loss with either QR (baseline) or orthogonal QR (OQR) with penalty term Rcorr. Refer to the caption of Table 1 for further details. The standard errors for coverage and width are about 0.45, 0.1, respectively. See Table 11 for

a full reporting of all standard errors.

Minority

Group Majority Coverage (%) Minority Coverage (%) Majority Lengths Minority Lengths

Improvement (%)

Uncertainty

baseline / OQR

baseline / OQR

baseline / OQR

baseline / OQR

corr HSIC WSC

Low High

84.38 / 88.56 85.99 / 89.89

72.77 / 78.41 74.08 / 80.05

1.73 / 1.89 2.22 / 2.53

7.46 / 8.70 24.99 / 29.07

+35.03 +27.91

+46.48 +49.80 +7.00 +17.62

E.2 Real data
The advantages of adding the suggested orthogonal loss to the interval score loss are summarized in Table 7. Similarly to pinball loss, our regularizer improves the baseline method over all metrics in most datasets.
Also, the improvement over WSC and Node-Coverage metrics suggest that our loss does help to better approximate conditional validity with interval score as well as pinball loss. Overall, we can conclude that our proposal is useful for various scoring rules.
HSIC results
Table 8 presents the results of vanilla QR and orthogonal QR using HSIC penalty. Similarly to the decorrelation penalty, the HSIC approach also improves the conditional coverage metrics in most data sets.
Table 9 compares the two proposed loss functions, and displays the improvement obtained by regularizing with decorrelation instead of HSIC. As expected, the method optimizing Pearson's corr consistently achieves better results over this metric compared to pinball loss combined with HSIC regularizer. Surprisingly, in most datasets the model that uses decorrelation penalty attains a better HSIC value than the one optimizing directly this metric. These empirical drawbacks of
17

Table 7: Real data experiments - using interval score loss with either QR (baseline) or orthogonal QR (OQR) with penalty term Rcorr. Refer to the caption of Table 2 for further details. The standard errors for coverage and width are about 0.6, 0.1, respectively. See Table 13 for a full reporting of all standard errors.

Dataset Name Coverage (%)

Length

Improvement (%)

baseline OQR baseline OQR

facebook_1

89.03

91.97

1.43

1.45

facebook_2

88.82

93.35

1.35

1.38

blog_data

82.94

87.25

1.58

1.65

bio

89.93

89.76

2.19

2.19

kin8nm

90.51

91.81

1.49

1.59

naval

91.95

92.36

1.95

1.98

meps_19

83.68

86.16

0.95

1.13

meps_20

84.86

86.81

1.04

1.21

meps_21

85.27

86.63

0.98

1.14

corr
+79.02 +90.96 +86.13 +22.89 +28.63 +14.18 +17.15 -10.31 +20.88

HSIC
+96.90 +98.71 +94.47 +37.16 +49.19 +30.95 +17.49 -9.51 -49.49

WSC
+15.91 +30.53 +2.79 -8.85 +13.67 +20.33 +24.28 +1.36 +17.14

ILS
+68.69 +69.23 +89.66 +48.56 +73.32 +59.16 +82.29 +77.66 +77.89

Node
+1.15 +5.81 +18.64 -15.18 +22.77 +26.28 +27.97 +24.69 +10.89

Table 8: Real data experiments - using pinball loss with either vanilla QR (baseline) or orthogonal QR (OQR) with penalty term RHSIC. Refer to the caption of Table 2 for further details. The standard errors for coverage and width are about 0.5, 0.06, respectively. See Table 14 for a full reporting of all standard errors.

Dataset Name Coverage (%)

Length

Improvement (%)

baseline OQR baseline OQR

facebook_1

88.10

93.86

1.09

1.43

facebook_2

87.38

94.77

1.07

1.37

blog_data

82.89

92.88

1.36

1.64

bio

88.42

89.47

1.88

2.03

kin8nm

84.63

88.22

0.98

1.20

naval

89.89

89.72

0.56

1.21

meps_19

82.44

85.47

0.84

0.94

meps_20

82.81

86.02

0.86

0.96

meps_21

82.50

82.51

0.86

0.94

corr
+73.51 +88.49 +63.79 +11.26 +9.00 +49.73 +9.21 -20.63 -19.50

HSIC
+88.41 +98.77 +35.79 +16.18 +25.34 +5.52 -8.17 -34.17 +10.39

WSC
+32.76 +42.68 +32.58 -42.33 -42.92 -51.05 +12.26 +2.57 +8.00

ILS
+76.86 +82.77 +89.66 +43.76 +52.75 +61.98 +78.54 +81.03 +84.43

Node
+38.15 +57.24 +41.74 -25.75 +27.39 +8.52 +19.16 +14.74 +24.41

HSIC regularization compared to our suggested penalty might have been caused by the fact that the latter receives twice as many samples in each gradient step, or its coefficients were more tuned. Nevertheless, the method using HSIC is able to achieve better statistical efficiency, which is probably due to its strength. Overall, we can conclude that thanks to the low computational burden, it is easier to fine tune the coefficients of the decorrelation loss and use more samples, but it might not be as strong as HSIC.
F Standard error results
F.1 Synthetic data
In the following tables we present the mean value and standard errors received for each metric in the synthetic data experiments.
F.2 Real data
In the following tables we present the mean value and standard errors received for each metric in the real data experiments.

18

Table 9: Real data experiments. Performance of a neural network model for quantile regression, orthogonal QR using either (RHSIC) penalty or (Rcorr) penalty. Refer to the caption of Table 2 for further details. The standard errors for coverage and width are about 0.5, 0.06, respectively. See Tables 12,14 for a full reporting of all standard errors.

Dataset Name Coverage (%)

Length

Improvement (%)

facebook_1 facebook_2 blog_data
bio kin8nm naval meps_19 meps_20 meps_21

RHSIC
93.86 94.77 92.88 89.47 88.22 89.72 85.47 86.02 82.51

Rcorr
90.48 91.13 88.92 89.08 88.62 89.50 85.16 84.27 84.07

RHSIC
1.43 1.37 1.64 2.03 1.20 1.21 0.94 0.96 0.94

Rcorr
1.44 1.41 1.64 2.03 1.28 1.49 1.00 1.03 0.99

corr
+28.59 +24.18 +37.84 +47.59 +20.38 +50.64 +49.51 +53.17 +64.40

HSIC
-100.51 -195.60 -52.21 +70.83 +30.98 +30.12 +28.12 +26.95 +3.60

WSC
+0.98 -15.38 -16.51 -1.69 +40.50 -4.28 +35.35 +22.05 +13.89

Table 10: Simulated data: Average metric value (standard error) - using pinball loss with either vanilla QR (QR) or orthogonal QR (OQR) with penalty term Rcorr.
Minority

Group

corr

HSIC

WSC

Uncertainty

QR

OQR

QR

OQR

QR

OQR

Low High

.105 (.005) .038 (.008) .001 (1e-4) 1e-3 (1e-4) 2.195 (.337) 2.500 (.373) .115 (.006) .032 (.006) 1e-3 (1e-4) 1e-3 (1e-3) 3.240 (.384) 2.658 (.335)

Table 11: Simulated data: Average metric value (standard error) - using interval score loss with either quantile regression (QR) or orthogonal QR (OQR) with penalty term Rcorr.
Minority

Group

corr

HSIC

WSC

Uncertainty

QR

OQR

QR

OQR

QR

OQR

Low High

.094 (.008) .061 (.008) 1e-3 (1e-3) 1e-3 (1e-4) 3.062 (.322) 1.537 (.339) .124 (.009) .089 (.014) 1e-3 (1e-4) 1e-3 (1e-3) 3.196 (.369) 2.633 (.359)

Table 12: Real data: Average metric value (standard error) - using pinball loss with either vanilla QR (QR) or orthogonal QR (OQR) with penalty term Rcorr.

Dataset Name

corr

HSIC

WSC

ILS

Node

QR

OQR

QR

OQR

QR

OQR

QR

OQR

QR

OQR

facebook_1 facebook_2 blog_data
bio kin8nm naval meps_19 meps_20 meps_21

.057 (.013) .099 (.028) .043 (.002) .084 (.002) .283 (.003) .269 (.006) .056 (.006) .048 (.005) .064 (.006)

.011 (.002) .009 (.002) .010 (.002) .039 (.002) .205 (.006) .067 (.006) .026 (.004) .027 (.005) .027 (.004)

1e-3 (1e-3) .002 (.001) 1e-4 (1e-4) 1e-3 (1e-4) .002 (1e-4) .001 (1e-4) 1e-3 (1e-5) 1e-4 (1e-5) 1e-3 (1e-4)

1e-4 (1e-5) 1e-4 (1e-5) 1e-4 (1e-4) 1e-4 (1e-5) .001 (1e-4) 1e-3 (1e-4) 1e-4 (1e-4) 1e-4 (1e-4) 1e-3 (1e-4)

6.371 (.731) 6.810 (1.239) 10.037 (.330) 1.218 (.192) 1.638 (.216) 2.824 (.394) 8.580 (.644) 7.269 (.697) 8.745 (.687)

4.242 (.399) 4.504 (.314) 7.885 (.306) 1.762 (.248) 1.393 (.205) 4.449 (.563) 4.866 (.496) 5.520 (.590) 6.927 (.738)

9.345 (.520) 10.104 (.986) 12.773 (.261) 8.461 (.263) 16.770 (.452) 8.674 (.633) 12.976 (.551) 11.351 (.459) 12.940 (.507)

3.195 (.185) 3.465 (.117) 1.285 (.178) 4.806 (.167) 7.148 (.283) 2.398 (.278) 1.550 (.204) 1.735 (.270) 1.938 (.236)

3.555 (.491) 4.654 (1.433) 4.823 (.386)
.912 (.153) 1.471 (.256) 2.410 (.312) 7.204 (1.066) 5.328 (.850) 6.043 (.911)

1.874 (.238) 2.065 (.284) 3.163 (.322) .846 (.116) 1.713 (.347) 2.756 (.427) 3.931 (.584) 2.830 (.494) 3.730 (.569)

19

Table 13: Real data: Average metric value (standard error) - using interval score loss with either quantile regression (QR) or orthogonal QR (OQR) with penalty term Rcorr.

Dataset Name

corr

HSIC

WSC

ILS

Node

QR

OQR

QR

OQR

QR

OQR

QR

OQR

QR

OQR

facebook_1 facebook_2 blog_data
bio kin8nm naval meps_19 meps_20 meps_21

.075 (.020) .083 (.028) .081 (.026) .089 (.004) .250 (.004) .157 (.003) .040 (.010) .028 (.005) .047 (.004)

.016 (.003) .007 (.002) .011 (.002) .069 (.004) .178 (.006) .135 (.005) .033 (.005) .031 (.005) .037 (.004)

.001 (.001) .002 (.002) .001 (1e-3) 1e-3 (1e-4) .001 (1e-4) 1e-3 (1e-4) 1e-3 (1e-4) 1e-3 (1e-4) 1e-3 (1e-4)

1e-4 (1e-5) 1e-4 (1e-5) 1e-4 (1e-5) 1e-3 (1e-4) 1e-3 (1e-4) 1e-3 (1e-4) 1e-3 (1e-4) 1e-3 (1e-4) 1e-3 (1e-4)

3.392 (1.079) 4.161 (1.483) 10.468 (.450) 1.761 (.167) 1.740 (.234) 4.189 (.601) 10.867 (1.001) 7.898 (.430) 9.295 (.668)

2.853 (.405) 2.891 (.227) 10.176 (.656) 1.917 (.204) 1.502 (.231) 3.337 (.560) 8.228 (1.018) 7.790 (.634) 7.702 (.789)

7.230 (.661) 6.707 (.660) 10.610 (.338) 7.853 (.684) 14.186 (.823) 9.506 (.937) 11.066 (1.220) 8.513 (.476) 9.743 (.459)

2.264 (.190) 2.063 (.131) 1.097 (.180) 4.040 (.290) 3.785 (.276) 3.883 (.378) 1.960 (.288) 1.902 (.222) 2.154 (.258)

1.189 (.190) 2.065 (.708) 4.875 (.657) .796 (.154) 1.775 (.286) 1.450 (.233) 6.720 (.917) 4.234 (.763) 5.771 (1.112)

1.175 (.168) 1.945 (.330) 3.966 (.670) .917 (.137) 1.371 (.212) 1.069 (.166) 4.841 (.659) 3.189 (.565) 5.143 (.820)

Table 14: Real data: Average metric value (standard error) - using pinball loss with either vanilla QR (QR) or orthogonal QR (OQR) with penalty term RHSIC.

Dataset Name

corr

HSIC

WSC

ILS

Node

QR

OQR

QR

OQR

QR

OQR

QR

OQR

QR

OQR

facebook_1 facebook_2 blog_data
bio kin8nm naval meps_19 meps_20 meps_21

.057 (.013) .099 (.028) .043 (.002) .084 (.002) .283 (.003) .269 (.006) .056 (.006) .048 (.005) .064 (.006)

.015 (.003) .011 (.002) .016 (.004) .075 (.002) .257 (.004) .135 (.006) .051 (.006) .057 (.008) .077 (.014)

1e-3 (1e-3) .002 (.001) 1e-4 (1e-4) 1e-3 (1e-4) .002 (1e-4) .001 (1e-4) 1e-3 (1e-5) 1e-4 (1e-5) 1e-3 (1e-4)

1e-4 (1e-5) 1e-4 (1e-5) 1e-4 (1e-5) 1e-3 (1e-4) .001 (1e-4) .001 (1e-4) 1e-3 (1e-4) 1e-3 (1e-4) 1e-3 (1e-4)

6.371 (.731) 6.810 (1.239) 10.037 (.330) 1.218 (.192) 1.638 (.216) 2.824 (.394) 8.580 (.644) 7.269 (.697) 8.745 (.687)

4.284 (.357) 3.904 (.247) 6.768 (.270) 1.733 (.239) 2.341 (.326) 4.266 (.513) 7.528 (.632) 7.082 (.655) 8.045 (.754)

9.620 (.521) 11.088 (1.170) 13.524 (.286)
8.530 (.210) 17.769 (.500) 6.480 (.640) 11.940 (.299) 11.128 (.468) 12.333 (.507)

2.226 (.141) 1.910 (.103) 1.399 (.102) 4.797 (.107) 8.396 (.189) 2.464 (.273) 2.563 (.273) 2.111 (.274) 1.920 (.283)

3.300 (.552) 5.849 (1.887) 4.851 (.467) .772 (.130) 1.813 (.327) 2.374 (.380) 6.736 (1.050) 4.979 (.916) 3.899 (.673)

2.041 (.346) 2.501 (.355) 2.826 (.403) .971 (.162) 1.317 (.212) 2.172 (.327) 5.446 (.854) 4.245 (.800) 2.947 (.528)

Table 15: Real data: Average metric value (standard error) - using pinball loss with conformalization and either vanilla CQR (CQR) or orthogonal CQR (COQR) with penalty term Rcorr.

Dataset Name

corr

HSIC

WSC

ILS

Node

CQR

COQR

CQR

COQR

CQR

COQR

CQR

COQR

CQR

COQR

facebook_1 facebook_2 blog_data
bio kin8nm naval meps_19 meps_20 meps_21

.039 (.009) .068 (.011) .018 (.003) .080 (.002) .231 (.003) .270 (.005) .122 (.007) .104 (.006) .118 (.008)

.016 (.003) .016 (.003) .016 (.003) .039 (.003) .189 (.007) .061 (.007) .060 (.007) .059 (.007) .069 (.006)

1e-3 (1e-4) 1e-3 (1e-4) 1e-4 (1e-5) 1e-3 (1e-5) 1e-3 (1e-4) .001 (1e-4) 1e-3 (1e-4) 1e-3 (1e-4) 1e-3 (1e-4)

1e-4 (1e-5) 1e-4 (1e-4) 1e-4 (1e-4) 1e-4 (1e-5) 1e-3 (1e-4) 1e-3 (1e-4) 1e-4 (1e-4) 1e-4 (1e-4) 1e-3 (1e-4)

5.187 (.408) 5.175 (.342) 9.658 (.318) 1.222 (.142) 1.708 (.265) 2.338 (.406) 11.942 (.708) 9.638 (.802) 10.310 (.926)

3.379 (.410) 3.648 (.317) 7.303 (.402) 1.598 (.206) 2.896 (.375) 4.142 (.632) 4.915 (.565) 5.060 (.606) 6.860 (.639)

10.395 (.376) 8.625 (.278) 14.131 (.348) 7.565 (.286) 14.443 (.509) 8.718 (.557) 14.824 (.563) 13.447 (.544) 14.119 (.578)

3.348 (.168) 4.026 (.153) 1.332 (.175) 4.601 (.114) 6.046 (.327) 2.769 (.332) 2.406 (.302) 2.134 (.297) 2.899 (.364)

2.945 (.534) 3.538 (.427) 6.216 (.677) .757 (.120) 1.833 (.322) 2.280 (.322) 8.570 (1.345) 7.278 (1.430) 7.204 (1.294)

2.078 (.334) 1.682 (.238) 3.768 (.344) 1.064 (.179) 1.859 (.218) 2.512 (.469) 5.413 (.969) 4.084 (.754) 4.515 (.858)

20

