arXiv:2106.00655v1 [cs.MA] 1 Jun 2021

The Impact of Network Connectivity on Collective Learning
Michael Crosscombe and Jonathan Lawry
Department of Engineering Mathematics, University of Bristol Bristol BS8 1UB, United Kingdom
{m.crosscombe,j.lawry}@bristol.ac.uk
Abstract. In decentralised autonomous systems it is the interactions between individual agents which govern the collective behaviours of the system. These local-level interactions are themselves often governed by an underlying network structure. These networks are particularly important for collective learning and decision-making whereby agents must gather evidence from their environment and propagate this information to other agents in the system. Models for collective behaviours may often rely upon the assumption of total connectivity between agents to provide effective information sharing within the system, but this assumption may be ill-advised. In this paper we investigate the impact that the underlying network has on performance in the context of collective learning. Through simulations we study small-world networks with varying levels of connectivity and randomness and conclude that totally-connected networks result in higher average error when compared to networks with less connectivity. Furthermore, we show that networks of high regularity outperform networks with increasing levels of random connectivity.
Keywords: collective learning, small-world networks, multi-agent systems
1 Introduction
Reasoning about collective behaviours in autonomous systems can be difficult when the system-level behaviour emerges from local-level interactions, i.e., between individual agents. Due to the complexity of such systems we often rely on a series of modelling assumptions to effectively reason about their resulting dynamics. One such assumption is the "well-stirred system" assumption, which we restate to be the following: In a well-stirred system each agent is equally likely to encounter any other agent in the system and, therefore, each interaction is regarded as an independent event [19]. In other words, in a well-stirred system we treat agents as nodes in a totally-connected network or complete graph and the stochastic interactions of agents can hence be modelled by selecting edges at random from the network. While this assumption captures the notion that agents conducting random walks are likely to encounter one another at random, e.g., whilst exploring an environment, the impact of this assumption is not wellunderstood. Alternative network structures, such as small-world networks [28],

2

M. Crosscombe and J. Lawry

have been studied in both artificial and biological systems [17,16] and provide a means of varying the connectivity of the network while preserving desirable properties such as short, consistent path-lengths.
In this paper we will study consensus formation in a collective learning setting, in which agents learn both from evidence gathered directly from the environment as well as indirectly from one another, through a process of belief fusion. In this context we shall investigate the impact of the underlying network structure on collective learning by studying small-world networks with varying degrees of connectivity and stochasticity. The rest of this paper is structured as follows: In Section 2 we provide an overview of the relevant literature on various formulations of collective learning as well as small-world networks. In Section 3 we describe a propositional approach to collective learning in which agents attempt to learn a full state description of the environment, followed by a brief overview of small-world networks in Section 4. Then, in Section 5 we detail simulation experiments in which we study small-world networks of varying degrees of connectivity and random rewiring. Finally, in Section 6 we close with some discussions and conclusions.

2 Related work
Consensus formation within a large group of individuals has long been studied in the form of `opinion pooling' since the works of Stone [24] and DeGroot [7]. These early works considered the (usually linear) weighted fusion of beliefs between `experts' initialised with prior beliefs and without considering the influence of external evidence. Instead of learning a description of the world, models of opinion dynamics are typically concerned with a single proposition of contention and beliefs are then denoted by a single real value that represents an agent's certainty in the truth or falsity of the proposition [13]. Agents simply conduct weighted combinations of their beliefs under interaction limitations imposed by concepts such as bounded confidence [12,6]. Three-valued representations of beliefs have also been studied in the context of opinion dynamics in [1], which thresholds the underlying real value into three states, and in the context of consensus formation in [21], which proposes a three-valued fusion operator that assigns the third truth state to resolve conflict between two strictly opposing opinions.
Collective learning is the combination of two distinct processes: belief fusion between agents; and the updating of beliefs based on evidence gathered from the environment. The interaction of these two processes in the context of social epistemology has been explored in [9], in which the argument is made that communication between agents not only acts to propagate information more effectively through the system but also provides an error-correcting effect when the evidence being gathered may be erroneous. Further studies of this effect in multi-agent systems and swarm robotics can be found in [4,15,8]. In a robotics setting this evidence may take the form of signals received by the robots' onboard sensors. For example, in [26] experiments are conducted in which Kilobots

The Impact of Network Connectivity on Collective Learning

3

use their ambient light sensors to determine the quality (i.e., light intensity) of a particular location [22].
Due to recent developments in multi-robot systems and swarm robotics, the increasing viability of their deployment outside of the lab has led to a surge of interest in the development and understanding of collective behaviours [3,23]. Many of the current solutions are based in nature, e.g., the house-hunting behaviours studied in ants and honeybees [11] are instances of the best-of-n problem [20,25]. It is in this context that [19] first proposed the adoption of the well-stirred system assumption which is to be found, implicitly or explicitly, in many recent models for collective learning [5,15,14]. However, there has been increasing effort to understand the impact of the underlying network topology on collective behaviours in multi-agent systems. In [18] the authors compare the effects that different network topologies, including small-world networks [28] and random networks [10], have on the consensus formation process. In the context of consensus formation, Baronchelli [2] investigates convergence dynamics for various network topologies.

3 A propositional model for collective learning

Consider a collective learning problem whereby a population of agents are at-

tempting to reach a consensus about the true state of their environment. Let us

suppose that such an environment can be described by a set of n propositional

variables P = {p1, . . . , pn} and that an agent's belief about the environment

(i.e., a possible world) is an assignment of truth values to each of the propo-

sitional

variables

denoted

by

b

:

P



{0,

1 2

,

1}n

.

Here

we

adopt

a

three-valued

propositional logic with the truth values 0 and 1 corresponding to false and

true,

respectively,

while

the

third

truth

value

1 2

denotes

unknown.

This

addi-

tional truth value allows for agents to express uncertainty in their beliefs about

the world. For notational convenience, let us represent an agent's belief B by

the n-tuple B(p1), . . . , B(pn) . Then an agent's belief may express uncertainty

about

the

world

by

the

assignment

of

the

truth

value

1 2

to

any

of

the

proposi-

tional variables in P. For example, for n = 2 propositional variables the belief

B = 1, 0 expresses an agent's belief that p1 is true while p2 is false. We can

say that this belief expresses absolute certainty in the state of the world. Al-

ternatively, the belief B

=

1 2

,

1 2

expresses an agent's uncertainty about both

of the propositions p1 and p2, thus indicating the agent's total lack of certainty

regarding the state of the world.

We propose to combine the beliefs of agents in a pairwise manner as follows:

the fusion operator

is

a

binary

operator

defined

on

{0,

1 2

,

1}

as

given

in

Table

1.

This operator is applied element-wise to all of the propositional variables pi in

P so that, given two beliefs B and B corresponding to the beliefs of two agents,

the fused belief is given by

B B = B(p1) B (p1), . . . , B(pn) B (pn) .

(1)

A pairwise consensus is thus formed by both agents adopting the fused belief B B.

4

M. Crosscombe and J. Lawry

Table 1: The fusion operator applied to beliefs B and B .

0 B(pi)
1 2
1

B (pi)

0

1 2

1

0

0

1 2

0

1 2

1

1 2

1

1

Evidential updating is the process by which an agent selects a proposition

(e.g., a feature of its environment) to investigate and, upon receiving evidence,

updates its belief to reflect this evidence. Firstly, to decide which proposition

to investigate an agent selects a single proposition at random from the set of

propositions

about

which

they

are

uncertain,

i.e.,

where

B(pi)

=

1 2

.

Having

selected a proposition pi to investigate, an agent then receives evidence with

probability r or learns nothing with probability 1 - r, where r is an evidence

rate quantifying the sparsity of evidence in the environment. Evidence takes the

form of an assertion about the truth value of the chosen proposition pi as follows:

E=

1 2

,

.

.

.

,

S(pi),

.

.

.

,

1 2

where S : P  {0, 1}n denotes the true state of the

world. Secondly, upon gathering evidence E, the agent then updates its belief B

to B|E using the same fusion operator given in Table 1 such that

B|E = B(p1) E(p1), . . . , B(pi) E(pi), . . . , B(pn) E(pn)

(2)

= B E.

Notice that we are also using the fusion operator to update beliefs based on

evidence and that updating in this manner does not therefore alter the truth

values

for

the

propositions

pj



P

where

pj

=

pi

because

E (pj )

=

1 2

.

An

agent repeats this process of gathering evidence until the set of propositions

about which it is uncertain is empty, or rather that it holds a belief of total

certainty, at which point it chooses to stop looking for evidence. Also notice

that while evidential updating in this manner can only lead to agents becoming

more certain in their beliefs, the process of agents combining their beliefs via

the fusion operator can also lead to agents becoming more uncertain when the

fusing agents disagree about the truth value of a given proposition. For example,

supposing that B1(pi) = 1 and B2(pi) = 0, then upon the agents fusing their

beliefs such that B1

B2(pi)

=

1 2

,

both

agents

will

attempt

to

seek

additional

evidence about proposition pi, either directly from the environment or indirectly

via fusion with other agents, having become uncertain about the truth value of

pi.

Let us now assume that the evidence gathering process may be noisy (e.g., due to sensor noise or a noisy environment). Evidence shall then take the following

The Impact of Network Connectivity on Collective Learning

5

form:

E(pi) =

S(pi)

: with probability 1 -

1 - S(pi) : with probability

(3)

where  [0, 0.5] is a noise parameter denoting the probability that the evidence is erroneous.
To measure the performance of a given population in the context of a collective learning problem we introduce a measure of the average error of the population.

Definition 1. Average error The average error of a population of m agents is the normalised difference between each agent's belief B and the true state of the world S averaged across the population as follows:

11 m mn

n
|Bj(pi) - S(pi)| .

j=1 i=1

As mentioned previously, we often adopt the well-stirred system assumption which states that an interaction between any two agents is an independent event and is therefore equally likely for any pair of agents in the population [19]. In the network agents are represented by nodes and the existence of edges between them represents the ability of the agents to communicate directly with one another. In networks with less-than-total connectivity the lack of an edge between two agents means that they cannot communicate directly, although information may still be shared via other agents in the population through the process of belief fusion. In the following section we introduce small-world networks to study the impact that the underlying network structure has on the collective learning process and to challenge the well-stirred system assumption.

4 Small-world networks
The network topology of many real-world systems often lies somewhere between total regularity and total randomness, as discussed by Watts and Strogatz in their seminal work introducing small-world networks [28,27]. Indeed the concept of a small-world network ­ in which nodes are connected to their k nearest neighbouring nodes ­ more accurately reflects the kinds of networks that emerge in both natural and artificial self-organising systems, with examples in social networks [17] and neural networks [16]. Many social systems, both biological and engineered, exhibit these small-world dynamics due to their spatial properties. For example in swarm robotics, where each embodied agent is typically composed of low-cost hardware and consequently possesses a limited radius within which it can communicate [22], the distance between agents determines the connectivity of the underlying communication network which will often resemble a smallworld network.

6

M. Crosscombe and J. Lawry

(a)

(b)

(c)

(d)

(e)

(f )

(g)

(h)

Fig. 1: The generation of a Watts-Strogatz small-world graph illustrated for m = 12, k = 4 and  = 0.2.

Small-world networks are parameterised by two variables k and , where k denotes the number of nearest neighbours to which each node in the graph is connected and  denotes the probability of rewiring an existing edge to a different agent. A small-world graph, as illustrated in Figure 1, is generated in the following way: (a) begin with n vertices ordered in a ring; (b) for each vertex in the graph, connect it to its k nearest neighbours until; (c) a regular smallworld graph is formed. (d) For each vertex (moving clockwise around the ring), select the edge connected to its clockwise-nearest neighbour; (e) with probability  reconnect that edge to another vertex selected uniformly at random, unless doing so produces a duplicate edge. (f) Continue this process clockwise for all vertices. (g) Repeat this process for their second-nearest clockwise neighbour until; (h) each original edge in the graph has been considered once. Notice that a small-world network with k = (m - 1) is equivalent to a totally-connected network in which each agent is connected to every other agent.
In the following section we describe simulation experiments applying the model in Section 3 to small-world networks with varying degrees of connectivity and regularity.

5 Agent-based simulations

We study a collective learning scenario in which the environment can be de-

scribed by n = 100 propositions. Without loss of generality we define the true

state of the world S to be 1, 1, 1, . . . , 1 . For each experiment we initialise a

population of k = 100 agents holding totally ignorant beliefs, i.e., at time step

t

=

0

each

agent

holds

the

belief

B(pi)

=

1 2

for

i

=

1, . . . , 100.

By

Definition

1

the average error of such a belief, representing complete uncertainty, is 0.5 and

therefore each population shall begin with an average error of 0.5. Furthermore,

The Impact of Network Connectivity on Collective Learning

7

Convergence time t Convergence time t

r = 0.001

r = 0.005

r = 0.01

10000

8000

6000

4000

2000

0 2 10 20 Nearest n5e0ighbours k

99

(a) Noise = 0.0.

r = 0.05

r = 0.1

r = 0.5

r = 1.0

10000

8000

6000

4000

2000

0 2 10 20 Nearest n5e0ighbours k

99

(b) Noise = 0.3.

Fig. 2: Average error of a population of 100 agents for nearest neighbours k. Each line depicts a different evidence rate r  [0.01, 1].

should a population converge on the true state of the world S then the aver-

age error shall be 0. A population-wide evidence rate r  (0, 1] determines the

frequency with which agents successfully obtain evidence from the environment.

In other words, during each time step every agent has an equal probability r of

updating their belief based on evidence. As described previously, each piece of

evidence pertains to a single proposition about which the investigating agent is

uncertain,

i.e.,

where

B(pi)

=

1 2

.

This

evidence

is

also

likely

to

be

noisy

with

 [0, 0.5] denoting the probability that a piece of evidence is incorrect. Notice

that for = 0.5 the evidence becomes random with an equal probability of learn-

ing that the investigated proposition is either true or false. Finally, in addition

to evidential updating, at each time step one edge in the graph is selected at

random and the connected pair of agents combine their beliefs using the fusion

operator defined in Table 1.

For a given set of parameter values we average the results over 100 inde-

pendent runs and each run takes a maximum of 10, 000 time steps, or until

convergence occurs. Here we define convergence as the beliefs of the population

remaining unchanged for 100 interactions, where an interaction is updating ei-

ther based on evidence or on the beliefs of other agents, i.e., via fusion. For line

plots, the shaded regions represent 10th and 90th percentiles.

5.1 Convergence results for regular small-world networks
In this section we show convergence results for regular small-world networks without random rewiring (i.e., where  = 0) as depicted in Figure 1c. Figure 2 shows the average convergence time across different networks with nearest neighbours k for different levels of noise . Each solid line represents a different evidence rate r between 0.001 and 1. For = 0 in Figure 2a we depict a noisefree scenario in which evidence is always accurate. Broadly, we see that time to convergence decreases as the network connectivity k increases and that a totallyconnected network results in the fastest convergence times for all evidence rates

8

M. Crosscombe and J. Lawry

Average error

r = 0.001

r = 0.005

r = 0.01

r = 0.05

r = 0.1

r = 0.5

r = 1.0

0.20 0.15

0.10

0.20

Average error

Average error

0.10

0.08

0.15

0.05

0.06

0.00

0.05

0.04

0.10

0.10

0.02

0.05

0.15 0.20 2 10 20 Nearest n5e0ighbours k

0.00

99

2 10 20 Nearest n5e0ighbours k

0.00

99

2 10 20 Nearest n5e0ighbours k

99

(a) Noise = 0.0.

(b) Noise = 0.1.

(c) Noise = 0.2.

0.30

0.4

0.5

Average error

Average error

0.25 0.3

0.4

0.20

0.3

0.15

0.2

0.10

0.2

0.05

0.1

0.1

0.00

0.0

0.0

2 10 20 Nearest n5e0ighbours k

99

2 10 20 Nearest n5e0ighbours k

99

2 10 20 Nearest n5e0ighbours k

99

(d) Noise = 0.3.

(e) Noise = 0.4.

(f) Noise = 0.5.

Fig. 3: Average error of a population of 100 agents for nearest neighbours k. Each solid line depicts a different evidence rate r  [0.01, 1], while the red dotted line depicts the noise level .

Average error

r. Additionally, we see that the average convergence time decreases as the evidence rate r increases. This is to be expected as the greater the frequency with which the population receives evidence, the faster the agents learn about their environment. In Figure 2b we see that for a moderately noisy environment with
= 0.3 and lower evidence rates r  0.01 the population no longer converges in under 10, 000 time steps for networks of connectivity k < 50. For networks with greater connectivity, i.e., k  50, the population once again reaches a steady state in under 3, 000 time steps on average. For higher evidence rates r  0.05 we see again that convergence time decreases as both the evidence rate r and network connectivity k increases. We also see that for these higher evidence rates, increasing network connectivity k to beyond 20 nearest neighbours does not lead to further reductions in convergence time. While Figure 2 demonstrates the ability of the model to reach a steady state under certain conditions, it does not demonstrate the learning accuracy of our model. To this end, we now present results showing the average error of the population according to Definition 1.
In Figure 3 we show the average error of the population at steady state against the number of nearest neighbours k in the network. Figure 3a shows that when the system is free from noise (i.e., when = 0) the model always converges on the true state of the world with 0 average error at steady state. This is true for all values of k and all evidence rates r including r = 0.001 which, for a population of 100 agents, corresponds to the population receiving a single piece of evidence once every 10 time steps on average. However, in a scenario

Evidence rate r Evidence rate r Evidence rate r

The Impact of Network Connectivity on Collective Learning

9

1.000 0.500 0.100 0.050 0.010 0.005 0.001
2 4 Nea6rest8neig1h0bou2r0s k 50 99
(a) Noise = 0.2.

0.0 0.1 0.2 0.3 0.4 0.5

1.000 0.500 0.100 0.050 0.010 0.005 0.001
2 4 Nea6rest8neig1h0bou2r0s k 50 99

1.000 0.500 0.100 0.050 0.010 0.005 0.001
2 4 Nea6rest8neig1h0bou2r0s k 50 99

(b) Noise = 0.3.

(c) Noise = 0.4.

Fig. 4: Average error of a population of 100 agents for both evidence rates r  [0.01, 1] and nearest neighbours k = 2, . . . , 99.

in which evidence is always accurate, these results are to be expected. Another edge case is when = 0.5, resulting in agents always receiving random evidence. Unsurprisingly, as shown in Figure 3f, the population always converges on an average error of around due to its inability to receive informative evidence for any particular proposition.
Figures 3b to 3e show the average error of the population for increasing levels of noise from 0.1 to 0.4. Compared with the noise-free scenario, the connectivity of the network has a clear impact on the learning accuracy of our model when agents encounter noisy evidence. For all noise levels in this range we see that the model performs well with respect to accuracy as the population consistently achieves an average error at or below for all evidence rates r. While the population does not always learn the true state of the world, the average error of the population can be significantly reduced below by adopting a less connected network. Indeed, for a totally-connected network, i.e., where k = 99, the average error is very often greater than networks with lower connectivity. In the extreme cases, with evidence rates r  0.5 the population always learns the true state of the world for < 0.5.
Alternatively, in Figure 4 we show heatmaps of the average error at steady state for evidence rate r and the number of nearest neighbours k. Focussing on a range of from 0.2 to 0.4 we see again that small-world networks with less connectivity outperform networks with greater connectivity, including totallyconnected networks. Broadly, given a noisy scenario and an environment with sparse evidence, there is a network with connectivity k that outperforms networks of both lesser and greater connectivity. For environments with higher evidence rates r, a less connected small-world network improves the accuracy of collective learning.

Average error Average error Average error

10

M. Crosscombe and J. Lawry

r = 0.001

r = 0.005

r = 0.01

r = 0.05

r = 0.1

r = 0.5

r = 1.0

0.20

0.20

0.20

0.15

0.15

0.15

0.10

0.10

0.10

0.05

0.05

0.05

0.00

0.00

0.00

0.0 0.1 Rewiring p0r.5obability p

1.0

0.0 0.1 Rewiring p0r.5obability p

1.0

0.0 0.1 Rewiring p0r.5obability p

1.0

(a) k = 2.

(b) k = 6.

(c) k = 10.

Fig. 5: Average error of a population of 100 agents against rewiring probability   [0, 1]. Each solid line depicts a different evidence rate r  [0.01, 1] with noise = 0.2, while the red dotted line depicts the noise level .

5.2 Convergence results for small-world networks with random rewiring
Having studied the primary parameter k of small-world networks in Section 5.1, we now study the secondary parameter associated with small-world networks: the rewiring probability . This randomising parameter reduces the regularity of small-world networks by rewiring connections between neighbouring nodes to agents of greater separation in the network. The purpose of this parameter is to introduce additional connections (or `paths') in the network that, for small values of k, are likely to improve information propagation in the network.
Figure 5 shows the average error of the population at steady state with moderate noise = 0.2 and for different rewiring probabilities  between 0 and 1. In Figure 5a we see that for k = 2, corresponding to a ring network in which agents are connected to their two nearest neighbours only, the average error of the population increases with  for r from 0.005 to 0.05 while remaining stable for very low and very high evidence rates, i.e., for r = 0.001 and r  0.1. For example, with r = 0.01, when the network is totally regular with  = 0, the average error is 0.081, while for  = 1, a network with totally random connectivity, the average error increases by 60% to 0.130. The same effect is broadly observed in Figures 5b and 5c for the same range of evidence rates, except that random rewiring increases the average error of the population to a greater extent in small-world networks with greater connectivity. For example, in Figure 5c with k = 10 and an evidence rate r = 0.01, when the network is totally regular (i.e., when  = 0) the average error of the population is 0.027. When  = 0.1, the average error increases to 0.085 while for total randomness (i.e., when  = 1) the average error is 0.162 which is a 600% increase in average error compared with the  = 0 case.
As the network connectivity is altered from total regularity to total randomness, i.e., from  = 0 to 1, respectively, the population consistently performs worse when attempting to learn the true state of the world, with the average error of the population increasing as  increases. It is clear, therefore, that irreg-

The Impact of Network Connectivity on Collective Learning

11

ularity in the network negatively impacts performance in a collective learning setting.

6 Discussion and Conclusion
In this paper we have investigated the importance of considering the connectivity of the underlying network for collective learning in autonomous systems. The environment is represented by a set of descriptors in the form of propositional variables and agents' beliefs are represented by an allocation of three-valued truth values to each of the propositions. Agents adopt a combined process of evidential updating, learning directly from the environment, and belief fusion, combining their beliefs with other agents to form a pairwise consensus while correcting for inconsistencies that have arisen from noisy evidence. In this context, we have studied how the structure of the underlying network impacts the dynamics of a system of 100 agents learning the state of the world for a range of scenarios with varying levels of evidence sparsity and noise.
We have shown that a less-connected small-world network leads to greater accuracy on a collective learning task when compared with a totally-connected network. Through simulation studies our results show that, when the evidence in the environment is both sparse and noisy, then a network with moderate connectivity k outperforms networks with lower or higher connectivity for some combination of evidence rate r and noise level . Broadly, the optimal level of connectivity is always lower than total connectivity when the underlying network retains high regularity, i.e.,   0. As the network connectivity becomes increasingly random, i.e., as   1, the accuracy of the system decreases.

Acknowledgements
This work was funded and delivered in partnership between Thales Group, University of Bristol and with the support of the UK Engineering and Physical Sciences Research Council, ref. EP/R004757/1 entitled "Thales-Bristol Partnership in Hybrid Autonomous Systems Engineering (T-B PHASE)."

References
1. Balenzuela, P., Pinasco, J.P., Semeshenko, V.: The undecided have the key: Interaction-driven opinion dynamics in a three state model. PLOS ONE 10(10), 1­21 (2015)
2. Baronchelli, A.: The emergence of consenus: a primer. Royal Society Open Science 5(2), 172,189 (2018)
3. Brambilla, M., Ferrante, E., Birattari, M., Dorigo, M.: Swarm robotics: a review from the swarm engineering perspective. Swarm Intelligence 7(1), 1­41 (2013)
4. Crosscombe, M., Lawry, J.: A model of multi-agent consensus for vague and uncertain beliefs. Adaptive Behavior 24(4), 249­260 (2016)

12

M. Crosscombe and J. Lawry

5. Crosscombe, M., Lawry, J., Hauert, S., Homer, M.: Robust distributed decisionmaking in robot swarms: Exploiting a third truth state. In: 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4326­4332 (2017)
6. Dabarera, R., Wickramarathne, T.L., Premaratne, K., Murthi, M.N.: Achieving consensus under bounded confidence in multi-agent distributed decision-making. In: 2019 22th International Conference on Information Fusion (FUSION), pp. 1­8 (2019)
7. DeGroot, M.H.: Reaching a consensus. Journal of the American Statistical Association 69(345), 118­121 (1974)
8. Douven, I.: Optimizing group learning: An evolutionary computing approach. Artificial Intelligence 275, 235 ­ 251 (2019)
9. Douven, I., Kelp, C.: Truth approximation, social epistemology, and opinion dynamics. Erkenntnis 75(2), 271 (2011)
10. Erd¨os, P., R´enyi, A.: On random graphs. Publicationes Mathematicae (Debrecen) 6, 290­297 (1959)
11. Franks, N., Pratt, S., Mallon, E., Britton, N., Sumpter, D.: Information flow, opinion-polling and collective intelligence in house-hunting social insects. Philosophical Transactions B: Biological Sciences 357 (1427), 1567 ­ 1583 (2002)
12. Hegselmann, R., Krause, U.: Opinion dynamics driven by various ways of averaging. Computational Economics 25(4), 381­405 (2005)
13. Hegselmann, R., Krause, U., et al.: Opinion dynamics and bounded confidence models, analysis, and simulation. Journal of artificial societies and social simulation 5(3) (2002)
14. Lawry, J., Crosscombe, M., Harvey, D.: Epistemic sets applied to best-of-n problems. In: G. Kern-Isberner, Z. Ognjanovi´c (eds.) Symbolic and Quantitative Approaches to Reasoning with Uncertainty, pp. 301­312. Springer International Publishing, Cham (2019)
15. Lee, C., Lawry, J., Winfield, A.: Negative updating combined with opinion pooling in the best-of-n problem in swarm robotics. In: Swarm Intelligence, pp. 97­108. Springer International Publishing, Cham (2018)
16. Masuda, N., Aihara, K.: Global and local synchrony of coupled neurons in smallworld networks. Biological cybernetics 90, 302­9 (2004)
17. Newman, M.E.J., Watts, D.J., Strogatz, S.H.: Random graph models of social networks. Proceedings of the National Academy of Sciences 99(suppl 1), 2566­ 2572 (2002)
18. Olfati-Saber, R., Fax, J.A., Murray, R.M.: Consensus and cooperation in networked multi-agent systems. Proceedings of the IEEE 95(1), 215­233 (2007)
19. Parker, C.A.C., Zhang, H.: Cooperative Decision-Making in Decentralized Multiple-Robot Systems: The Best-of-N Problem. IEEE/ASME Transactions on Mechatronics 14(2), 240­251 (2009)
20. Parker, C.A.C., Zhang, H.: Biologically inspired collective comparisons by robotic swarms. The International Journal of Robotics Research 30(5), 524­535 (2011)
21. Perron, E., Vasudevan, D., Vojnovi´c, M.: Using three states for binary consensus on complete graphs. Proceedings - IEEE INFOCOM pp. 2527­2535 (2009)
22. Rubenstein, M., Ahler, C., Nagpal, R.: Kilobot: A low cost scalable robot system for collective behaviors. In: 2012 IEEE International Conference on Robotics and Automation, pp. 3293­3298 (2012)
23. Schranz, M., Umlauft, M., Sende, M., Elmenreich, W.: Swarm robotic behaviors and current applications. Frontiers in Robotics and AI 7, 36 (2020)

The Impact of Network Connectivity on Collective Learning

13

24. Stone, M.: The opinion pool. The Annals of Mathematical Statistics 32(4), 1339­ 1342 (1961)
25. Valentini, G., Ferrante, E., Dorigo, M.: The best-of-n problem in robot swarms: Formalization, state of the art, and novel perspectives. Frontiers in Robotics and AI 4, 9 (2017)
26. Valentini, G., Hamann, H., Dorigo, M.: Efficient decision-making in a selforganizing robot swarm: On the speed versus accuracy trade-off. In: Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems, AAMAS '15, p. 1305­1314. International Foundation for Autonomous Agents and Multiagent Systems, Richland, SC (2015)
27. Watts, D.J.: Small Worlds: The Dynamics of Networks between Order and Randomness. Princeton University Press, USA (2003)
28. Watts, D.J., Strogatz, S.H.: Collective dynamics of `small-world' networks. Nature 393(June), 440­442 (1998)

