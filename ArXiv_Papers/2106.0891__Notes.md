
# High-Quality Diversification for Task-Oriented Dialogue Systems

[arXiv](https://arxiv.org/abs/2106.0891), [PDF](https://arxiv.org/pdf/2106.0891.pdf)

## Authors

- Zhiwen Tang
- Hrishikesh Kulkarni
- Grace Hui Yang

## Abstract

Many task-oriented dialogue systems use deep reinforcement learning (DRL) to learn policies that respond to the user appropriately and complete the tasks successfully. Training DRL agents with diverse dialogue trajectories prepare them well for rare user requests and unseen situations. One effective diversification method is to let the agent interact with a diverse set of learned user models. However, trajectories created by these artificial user models may contain generation errors, which can quickly propagate into the agent's policy. It is thus important to control the quality of the diversification and resist the noise. In this paper, we propose a novel dialogue diversification method for task-oriented dialogue systems trained in simulators. Our method, Intermittent Short Extension Ensemble (I-SEE), constrains the intensity to interact with an ensemble of diverse user models and effectively controls the quality of the diversification. Evaluations on the Multiwoz dataset show that I-SEE successfully boosts the performance of several state-of-the-art DRL dialogue agents.

## Comments

Accepted by ACL-IJCNLP 2021 (Findings of ACL)

## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{tang2021highquality,
      title={High-Quality Diversification for Task-Oriented Dialogue Systems}, 
      author={Zhiwen Tang and Hrishikesh Kulkarni and Grace Hui Yang},
      year={2021},
      eprint={2106.00891},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

## Notes

Type your reading notes here...

