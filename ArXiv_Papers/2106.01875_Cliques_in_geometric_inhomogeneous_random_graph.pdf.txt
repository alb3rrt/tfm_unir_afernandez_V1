arXiv:2106.01875v1 [math.PR] 3 Jun 2021

Cliques in geometric inhomogeneous random graphs
Riccardo Michielan1 and Clara Stegehuis1
1University of Twente - Faculty of Electrical Engineering, Mathematics and Computer Science
June 4, 2021
Abstract Many real-world networks were found to be highly clustered, and contain a large amount of small cliques. We here investigate the number of cliques of any size k contained in a geometric inhomogeneous random graph: a scale-free network model containing geometry. The interplay between scale-freeness and geometry ensures that connections are likely to form between either high-degree vertices, or between close by vertices. At the same time it is rare for a vertex to have a high degree, and most vertices are not close to one another. This trade-off makes cliques more likely to appear between specific vertices. In this paper, we formalize this trade-off and prove that there exists a predominant type of clique in terms of the degrees and the positions of the vertices that span the clique. Moreover, we show that the asymptotic number of cliques as well as the predominant clique type undergoes a phase transition, in which only k and the degree-exponent  are involved. Interestingly, this phase transition shows that for small values of  , the underlying geometry of the model is irrelevant: the number of cliques scales the same as in a non-geometric network model.
1 Introduction
Real-world networks often share common characteristics. For example, many large real-world networks are scale-free, that is, there exist a small number of individuals with a large amount of connections, whereas most of the individuals only have a small connectivity. This feature is mathematically often described by assuming that the degrees of the vertices in the network follow a power-law distribution. Another common feature is that real-world networks typically have large clustering coefficient. That is, there is a high probability that two neighbors of the same vertex are connected, and thus the network contains many triangles. This structural property is highly related to a possible underlying geometry of the network. Indeed, when any two close individuals are more likely to connect, the triangle inequality ensures that triangles are more likely to form between close groups of three vertices. In fact, in two examples of network models with an underlying geometry it has been proven that the presence of this underlying network geometry guarantees a high clustering coefficient, for hyperbolic random graphs [10], and geometric inhomogeneous random graphs [6].
While clustering is typically measured in terms of the number of triangles in the network, the presence of larger cliques inside a network is also informative on the amount of network clustering. Indeed, in clustered networks, one would expect the number of cliques of size larger than three to be high as well. Therefore, the number of cliques of general sizes have been extensively studied in
1

several types of random graph models without underlying geometry, such as dense inhomogeneous random graphs [8], scale free inhomogeneous random graphs [13, 2], general rank-1 inhomogeneous random graphs [5]. Results on the number of cliques in random graphs with underlying geometry are less well-studied, as the presence of geometry creates correlations between the presence of different edges, making it difficult to compute the probability that a given clique is present. Still, some results are known for high-dimensional geometric random graphs [1] and hyperbolic random graphs [4], showing that these types of random graphs typically contain a larger number of cliques than non-geometric models as long as the dimension of the underlying space is not too large. Particular attention has been given to the clique number: the largest clique in the network [4, 12, 7].
In this paper, we study general clique structures that can indicate network clustering inside a more general geometric network model, and investigate the relation between the presence of geometry and the presence of cliques. In particular, we analyze the Geometric Inhomogeneous random graph (GIRG) [6], a random graph model that includes scale-free vertex weights describing (roughly) the vertex degrees, and an underlying geometric space that makes nearby vertices more likely to be connected. We analyze the number of k-cliques contained in this random graph model, by deriving and solving an optimization method, similarly to [11]. This optimization method allows to overcome the difficulties posed by the dependence of the presence of edges in geometric models by studying the connections between different regions separately. Interestingly, we show that kcliques typically appear in specified regions of the network. We describe the specific properties satisfied by these most predominant cliques in terms of the vertex degrees and their geometric positions. Interestingly, our results show that geometry plays a central role in the number of cliques of any size when the degree-exponent of the power-law is at least 7/3. For smaller degree-exponents however, we show that the predominant clique does not depend on the underlying geometry, and that the number of cliques of all sizes scales the same as in scale-free configuration models [11], random graph models without any form of geometry. Thus, our results show that geometry does not always cause larger clique numbers or clustering coefficients in the scale-free regime, even when the dimension of the geometric space is low.
Specifically, we find that for any clique size, there is a threshold degree-exponent such that for scale-free networks with degree-exponent below the threshold, geometry does not influence the clique counts. When the degree exponent is above the threshold, the clique counts of that size are influenced by the underlying geometry of the model. Furthermore, for larger cliques, this threshold degree-exponent becomes higher, so that the geometry of the model becomes irrelevant for a larger range of the degree-exponent. Therefore, for small cliques, the range in which optimal subgraph structures depend significantly on the geometric features of the vertices is larger.
Organization of the paper. In Section 2 we describe our main result, concerning the characterization of the optimal clique structures in the GIRG and their scaling. Moreover, we provide simulations in support of our result, and we provide a short discussion. In Section 3 we formulate the problem we are analyzing as an optimization problem, where the feasible region is formed by the pairs of vectors (, ), which express the properties (weights and distances) of the vertices involved in a clique. Then in Section 4 we prove the solution structure of the optimization problem, and finally we provide the proof of the main theorem in Section 5.
Notation. We now describe the notation that will be used throughout this paper. A k-clique is a subset of vertices of size k such that they are all pairwise connected, and it is denoted by Kk. In
2

this paper, we analyze cliques contained in GIRGs where the number of vertices n tends to . We say that a sequence of events (En)n1 happens with high probability (w.h.p.) of limn P(En) = 1. We denote with Pn(E) the probability that the event E happens in a GIRG with n vertices, and with En[X] the mean value of the random variable X when the number of vertices is n. We write

· f (n) = o(g(n)) if limn f (n)/g(n) = 0

· f (n) = O(g(n)) if lim supn |f (n)|/g(n) <  · f (n) = (g(n)) if f (n) = O(g(n)) as well as g(n) = O(f (n))

Moreover, we write

·

Xn

=

oP(a(n))

if

limn

P(

Xn a(n)

 ) = 0 for all  > 0

· Xn = OP(a(n)) if for any  > 0 there exist M > 0 and N  N such that P(|Xn|/a(n)  M ) <  for all n > N .

· Xn = P(a(n)) if for any  > 0 there exist m, M > 0 and N  N such that P(|Xn|/a(n)  [m, M ]) <  for all n > N .

Geometric Inhomogeneous random graph. We now define the geometric inhomogeneous random graph [6]. Let n  N denote the number of vertices in the graph, and call V = [n] = {1, 2, ..., n} the set of vertices of the GIRG. In the GIRG, each vertex i is associated with a weight, wi and a position xi. The weights w1, ..., wn are independent and identically distributed random variables that follow a Pareto power law distribution with exponent   (2, 3). That is, for any

vV

P(wv > w) = cw-(-1),

(1)

for w  wmin, for some wmin  0, where c is a normalization constant. We denote by W :=

n v=1

wv

the sum of the weights.

As ground space for positions of the vertices, we consider the d-dimensional torus Td = Rd/Zd.

Then, the positions x1, ..., xn are independent and identically distributed random variables, with

uniform distribution on Td. That is, for any v  V

d

P(xv  [a1, b1] × · · · × [ad, bd]) = (bi - ai)

(2)

i=1

for any a1, ..., ad, b1, ..., bd in [0, 1] such that ai  bi for every i = 1, ..., d. We denote by E the set of edges in the GIRG. An edge between any two vertices u, v  V of the
GIRG appears with a probability puv determined by the weights and the positions of the vertices

puv := P((u, v)  E) = min

1 || xu - xv ||d

wu wv


,1

W

,

(3)

where the exponent  > 1 is a fixed parameter. Here we use the -norm to measure || xu - xv ||.

That is, for any x, y  Td

||x - y|| := max |xi - yi|C .

(4)

1id

3

Here | · |C denotes the distance on the circle T1, namely, for any a, b  T1

|a - b|C := min{|a - b|, 1 - |a - b|}

(5)

Equation (3) shows an interesting relation between the properties of the vertices and their connection probabilities: Two vertices with high weights are more likely to connect. However, vertices with high weights are rare due to (1). Moreover, two vertices are more likely to connect if their positions are close. However, again, the probability for two vertices to have close locations is small due to (2). In our main results, we will exploit this trade-off formally in the form of an optimization problem.

2 Main result

The aim of this paper is to study the emerging subgraph structures inside the GIRG, as the number

of vertices n goes to infinity. In particular we are interested in computing N (Kk), the number of

complete subgraphs (cliques) appearing in the GIRG. In our computations we assume that k is

small compared to n, in particular k = O(1).

Our results do not only investigate the number of cliques, but also show where in the GIRG these

cliques are most likely to be located in terms of their positions and their weights. In particular, we

will consider weights and distances between the vertices as quantities scaling with n, and show that

most cliques are found on vertices whose weights and distances scale as specific values of n. Indeed,

as the positions of the vertices enter in the edge probabilities introduced in (3) only through their

distances, we are not interested in the position of each vertex, but rather on their distances.

We now introduce some notation for our main theorem that introduces the number of cliques

in regions of GIRG(n) with specific vertex weights and distances. We say that x  I(n) if x 

[n ,

1 

n

]

for

some

0

<



<

1.

Fix

a

sequence



=

{1, ..., k}

of

non-negative

real

numbers

and

a

sequence  = {1, ..., k} of non-positive real vectors of length d, where d denotes the dimension of

the GIRG model. Moreover, set 1 := [-, ..., -], and define

M (,) = (v1, ..., vk) : wvi  I(ni ), | xvi - xv1 |  I(ni(1) ), ..., I(ni(d) ) , i  [k]

(6)

where |y - z| denotes the component-wise distance between the vectors y and z. The set M (,)
contains all the lists of k vertices such that their weights scale with n according to , and such that
their distances from v1 scale with n according to . Observe that in (6) we are setting the origin of the torus as the position of vertex v1, so that all the other vertices lie in some neighbourhood of the origin. This choice makes sense because the edge probability of the GIRG defined in (3)
depends on the distances between the vertices, and not on their absolute positions and the positions
are distributed uniformly. Thus, in order to study the number of k-cliques in the GIRG, we can
fix the position of any vertex v1 without loss of generality (by symmetry), and allow the position parameters 2, ..., k of the remaining k - 1 vertices to vary.
The number of k-cliques inside GIRG(n) with vertices in M (,) will be denoted by N (Kk, M (,)). Then our aim is to prove that there exists a specific set of values ,  such that the number of k-cliques N (Kk, M (,)) is predominant among all others. The next theorem states that such optimal values are explicitly determined, depending on k, the size of the clique, and on  , the power
law exponent for the weights of the vertices.

4

Figure

1:

Phase

transition

described

by

Theorem 1.

The

blue

region

corresponds

to

k>

2 3-

(non-

geometric case), where most of the cliques generate independently from the geometry of the system;

whereas, in the orange

region k <

2 3-

(geometric

case),

cliques appear most likely between vertices

at

distance

(n-

1 d

).

Theorem 1. Suppose  =  - 1. Then, there exist ,  such that

En[N (Kk, M (,))] En[N (Kk, M (,))]

=

0

w.h.p.,

(, ) = (, ).

(7)

Moreover,

N (Kk, M (,)) =

P(n)

P

(n

3- 2

k

)

if

k

<

2 3-

,

if

k

>

2 3-

.

(8)

and ,  are uniquely determined by

i =

0
1

2

i i

 

[k], [k],

if if

k k

< >

2 3-
2 3-

, .

,

(9)

i =

[-

1 d

,

...,

-

1 d

]

[0, ..., 0]

i i

 

[k] [k]

\ \

1, 1,

if if

k k

< >

2 3-
2 3-

, .

.

(10)

In particular, Theorem 1 shows that there exists a phase transition for the number of cliques

in the GIRG, depending on k and  .

When k <

2 3-

,

the

predominant

number

of

cliques

scales

as n. Furthermore, most cliques appear between vertices with small distances, proportional to

n

=

n-1/d,

and

low

degrees,

that

do

not

grow

in

n,

as

n

=

1.

On

the

contrary,

when

k

>

2 3-

the number of cliques on vertices with high

scales

as

n 3- 2

k

n.

weights, proportional

In to

this n

=case,nt,hbeumt oasrtbiptrraerdiolymdinisatnatntclifqroumes

are formed each other,

as n = 1, which is also the maximal distance in the GIRG model.

In the latter case the geometry does not influence the dominant clique structure. That is, the

number of cliques does not depend on geometric features (the positions of the vertices) anymore.

5

This is further illustrated by the fact that our result is equivalent to the analogous result (see Theorem 2.2 in [11]) for scale-free configuration models, in which geometry is not involved. For this reason, we call the two different cases geometric and non-geometric (see Figure 1).

2.1 Simulations

We provide here simulations of the GIRG model. For each sample of the GIRG we count the

number of triangles, and compare it to the expected asymptotic behaviour predicted by Theorem

1. In [3] Bläsius et al. provide an algorithm to sample GIRGs efficiently, with expected running

time (n + m) (where n, m denote the number of vertices and edges of the GIRG). We make use

of a C++ library which implements this algorithm [15, 9].

The required parameters for each sample of the GIRG model are: n,  , d and the temperature

1/. Moreover, in the code we add an additional parameter c, corresponding to the constant factor

in the weight distribution (1). This factor affects the edge probability in (3): the mean number of

edges in the graph increases as c increases.

To count the number of triangles in a GIRG, we use the forward algorithm [16, 14], which has a

running time of O(m3/2), where m denotes the number of edges. As in the GIRG model the number

of edges scales as the number of vertices [6], this is therefore equivalent to a running time of O(n3/2).

Figure 2 shows the number of triangles obtained from simulations, against the number of vertices

n for the two regimes of  distinguished by Theorem 1 for k = 3:  < 7/3 and  > 7/3. Indeed, for



=

2.1,

Figure

2a

and

Theorem

1

show

that

the

optimal

weights

and

distances

are



=

1 2

,



=

0,

and that the asymptotic behaviour of N (

,

M

(

1 2

,0)

)

is

P(n1.35).

Instead, in Figure 2b, 

= 2.7,

so

that

Theorem

1

predicts

that

the

optimal

values

are



=

0, 

=

-

1 d

,

and

the

asymptotic

behaviour of N (

,

M

(0,-

1 d

)

)

is

P(n).

These different asymptotic slopes are shown in Figures 2a

and 2b, and in both cases, our simulations follow these asymptotic slopes quite well. In particular,

while the results from Theorem 1 are asymptotic in n, our simulations show that these asymptotics

are visible for networks with sizes of only thousands of vertices, and even less.

(a) Non-geometric case:  = 2.1

(b) Geometric case:  = 2.7

Figure 2: The number of triangles against n for different values of  for d = 1, c = 0.4. Black curves show the asymptotic behaviour of N ( , M (,)) predicted by Theorem 1, colored dots indicate the average number of triangles over 100 samples of the GIRG. The colored regions contain 80% of all samples.

6

2.2 Discussion
In this paper, we analyze the number of cliques in a general model that incorporates power-law degrees as well as geometry. We also investigate the typical structure of a clique of any given size, and show that this structure depends on the clique size and the power-law exponent. We now discuss some implications of our main results.

Non-geometry for  < 7/3. We now analyze the phase-transition of Theorem 1 in more detail.

One

interesting

thing

is

that

when



<

7 3

the

most

common

k-cliques

are

non-geometric,

for

any

k  3. This can be observed, for instance, in Figure 2. Furthermore, Theorem 1 shows that in this

setting, the number of dominating cliques scales as nk(3-)/2 for all k, which is the same scaling

in n as in many non-geometric scale-free models, such as in the inhomogeneous random graph,

the erased configuration model and the uniform random graph [18, 17, 11]. This seems to imply

that that when  < 7/3, we cannot distinguish geometric and non-geometric scale-free networks by

counting the number of cliques, or by studying the clustering coefficient. Thus, in this regime of  ,

the added geometry of the GIRG model does not add any clustering.

On

the

other

hand,

when



>

7 3

,

then

small

cliques

and

large

cliques

behave

differently

(see

Figure 1). Indeed, cliques of small size k < 2/(3 -  ) are predominantly present on low-degree, close

by vertices of distances as low as n-1/d. Furthermore, the number of such small cliques scales as

n, which is larger than the clique scaling of nk/2(3-) in the inhomogeneous random graph without

geometry [18]. Thus, for  > 7/3, smaller cliques are influenced by geometry, whereas large cliques

are not. In this case, it is clearly possible to distinguish between geometric and non-geometric

inhomogeneous random graphs through small clique counts. Therefore, studying such statistical

tests that distinguish geometric and non-geometric random graphs in more detail would be an

interesting avenue for further research.

Insensitivity to . In the result of Theorem 1, the parameter  of the GIRG model does not contribute to the asymptotic behaviour of N (Kk), nor to the determination of the phase-transition. This may appear counterintuitive, as the edge probability defined in (3) decreases as  increases. Hence, for higher values of , we should expect fewer edges and therefore fewer cliques to appear. However, by direct computation, it is possible to see that any vertices in the optimal configuration (v1, ..., vk)  M (,) connect to each other with probability (1), regardless of the value of . This is the reason why asymptotically the presence of  is irrelevant. However, Theorem 1 only computes the asymptotic scaling of the number of cliques in terms of the number of vertices, whereas we do expect the parameter  to play a role for computing the leading-order constant. Indeed, from Figures 2a and 2b it is clear that if we increase , the leading-order constant decreases, and consequently the GIRG contains a lower number of triangles.

Total number of cliques. Lastly, we observe that Theorem 1 deals with the number of optimal cliques N (Kk, M (,)), not with the total number of cliques in the graph N (Kk). Indeed we only determine which kind of cliques appear most frequently, and we obtain the scaling of these dominant cliques. Nevertheless, our simulations suggest that the total number of cliques has the same asymptotic behaviour as the number of optimal cliques. As a consequence, this would imply that if we pick randomly a clique of the GIRG, then its vertices will be in M (,) with high probability (when n is large). Vice versa, this suggests that if we want to compute the number of k-cliques in large GIRGs, we just need to check the set of optimal vertices (v1, ..., vk), such that

7

(v1, ..., vk)  M (,). That is, we believe that the total number of cliques in the GIRG model has the same scaling as the dominant number of cliques in Theorem 1. Proving this however, needs the computation of the integral of the exact clique probability over all ,  in the optimal regime, as was done for a simpler model without geometry in [11], and remains an open direction for further research.

General heavy-tailed weight distributions. In (1), the weight of the vertices follows a Pareto distribution with power-law exponent   (2, 3). That is, the weights are independently sampled from a random variable w with probability density function

/w fw(w) = 0

if w  wmin if w < wmin

(11)

for some wmin > 0, with = ( - 1)wm-in1. However, since the results summarized in the current section hold asymptotically, it is worth nothing to prove that Theorem 1 still works with more general heavy-tailed weight distributions. Indeed, we can consider a probability density function whose behaviour at infinity is similar to the behaviour of a power law function. This is done replacing in (11) with a bounded slowly varying function (w), that is, a bounded measurable function : (wmin, )  (0, ) such that limw (aw)/ (w) = 1, for all a > 0, and fw(w) is a probability density function. If in (11) is replaced by a slowly varying function (w), then the computations done in Section 3 are unaffected. Indeed, we solve an optimization problem containing powers of n. The slowly varying function on the other hand, grows slower than any power of n, and therefore does not affect significantly this optimization problem, nor its solution. However, while the scaling in (7) of the total number of cliques would still have the same polynomial leading order term, it would contain an additional slowly varying factor as well. The relation between the slowly varying function and the correct asymptotic scaling of the number of cliques remains an open problem for future research.

Relation to hyperbolic random graphs. In the past decade, hyperbolic random graphs have

been studied widely, as random graph models that include both geometry and scale-free vertex

degrees. The downside of analyzing hyperbolic random graphs is that they come with hyperbolic

sine and cosine functions, which are typically difficult to work with. However, hyperbolic random

graphs can also be seen as a special case of GIRGs, when the dimension is d = 1 and the temperature

is 1/ = 0 ([6], section 4). In this threshold case,  = , the connection probability (3) of the

GIRG model becomes

1, puv =
0,

if || xu - xv || 

wu wv W

1/d ,

if || xu - xv || >

wu wv W

1/d .

(12)

As these connection probabilities are easy to determine when the weights of the vertices and their

positions are known, we believe that in the case  =  it is still possible to estimate asymptotically

the number of cliques, in a similar spirit as Theorem 1, by solving a slightly different optimization

problem. In turn, the methodology provided in this paper would work for estimating the number of

cliques in hyperbolic random graphs as well. In fact, it is interesting to observe that the result shown

by Bläsius, Friedrich, and Khromer in [4] for the expected number of cliques in hyperbolic random

graphs is very similar to Theorem 1 presented here. Indeed, they were able to prove that there

exists two different regimes for the number of cliques, depending on the size k, where the transition

8

point between the different regimes agrees with the one we here obtain for the more general GIRG model.

3 Optimization problem

We now describe how Theorem 1 can be proven though solving an optimization problem. First we estimate asymptotically the mean value of N (Kk, M (,)) as follows:

En[N (Kk, M (,))] = n|M (,)| · P (v1, ..., vk)  M (,) form a k-clique .

(13)

In order to prove Theorem 1, we will solve the maximization problem

max En[N (Kk, M (,))].

(14)

,

We will then show that the solution of (14) determines the features of the most predominant cliques
in the graph, as shown in (7) of Theorem 1. Using (13), we can split the mean value of N (Kk, M (,)) into the product of two terms. The
first term, |M (,)| defined in (6), is the number of vertices (v1, ..., vk)  M (,), which depends on w1, ..., wn and of x2, ..., xn. Note that |M (,)| does not depend on x1, as we fixed the origin
to the position of vertex 1. To adjust for this, we added an extra factor n to (13) as any of the n vertices can be defined as vertex 1. For   0,  = [(1), ..., (d)]  0 fixed, observe that the number of vertices v  V such that wv  I(n), | xv - xv1 |  I(n) is Binomial(n, p), with p = P(wv  I(n), | xv - xv1 |  I(n)), as all positions and weights are i.i.d.. In particular, p = (n(1-)+(1)+...+(d)), so that the number of vertices with prescribed weight and position wv  I(n), | xv - xv1 |  I(n) is P(n1+(1-)+(1)+...+(d) ). Consequently,

k

|M (,)| = n(1- )1

P(n1+(1- )i+i(1)+...+i(d) )

i=2

= P(nk-1+(1- ) i i+ ) i>1,j i(j)

(15)

Now we focus on the second term in (13), which describes the probability that k randomly chosen
vertices of given weights and position from a clique. The vertices v1, ..., vk form a k-clique if and only if every possible pair of vertices is connected. The connection probabilities of different vertices are independent, conditionally on their weights and positions. Then, for any (v1, ..., vk)  M (,) we have

P ((v1, ..., vk) form a k-clique) = P((vi, vj)  E)

i<j
= min
i<j

1

wvi wvj

|| xvi - xvj ||d W


,1

.

(16)

Let i, j

be fixed, and consider the probability of vi and vj

to connect.

First note that

wvi wvj W

=

P(ni+j-1), because W = P(n). Moreover, the distance between vi and vj can be rewritten as

|| xvi - xvj || = max1hd{| x(vhi ) - x(vhj) |C }, as we are considering the metric induced by the -norm.

For each h  [d] there are two possibilities.

9

· If i(h) = j(h), then | x(vhi ) - x(vhj ) |C = I ni(h) - I nj(h)

=  nmax{i(h),j(h)} .

(17)

· If i(h) = j(h) =: (h), the component-wise distance is more difficult to obtain, since

| x(vhi ) - x(vhj ) |C = I ni(h) - I nj(h) = (n(h) )

(18)

for some (h)  (h). However, we now show that (h) = (h) provides the dominant contribution to (13). For simplicity we consider the 1-dimensional case d = 1, but by using the same argument and introducing some additional notation, it is possible to prove the result for any dimension.
Let d = 1, and suppose i = j = , that is | xvi - xv1 |  I(n) and | xvj - xv1 |  I(n). As xi and xj are sampled uniformly within the interval xv1 ±[n, n/], the probability that the distance between vi and vj is proportional to n, with   , is
P(|| xvi - xvj || = (n)) = (n-).
The probability that vi and vj connect, given that their distance is proportional to n, is

P (vi, vj )  E | || xvi - xvj || = (n) = P(nmin{(i+j-1-),0}),

by (3). Thus, we have

P (vi, vj )  E, || xvi - xvj || = P(n) = P(n-+min{(i+j-1-),0}) = P(min{n(1-)-+(i+j-1-), n- ).

(19)

Since our aim is to solve the maximization problem in (14), we just need to determine for
which    the contribution of (19) to (13) is maximized. As  > 1, (19) is optimized for
 = . This proves that, we may assume that if the position of two vertices vi, vj are both in a neighborhood of v1 of size  n, then also their distance is  n in (14).

Then, (16) yields

P ((v1, ..., vk) form a k-clique) = min
i<j

maxh

P n(i+j -1) P max{ni(h) , nj(h) }

d

,1

= P n i<j  min{i+j -1-d maxh(max{i(h),j(h)}), 0} .

(20)

Combining this with (13) and (15) shows that the mean number of cliques with vertices in M (,) satisfies

En[N (Kk, M (,))] = P

nk+(1- )

i i+

i>1,j i(j)+

i<j  min{i+j -1-d maxh(max{i(h),j(h)}), 0} . (21)

10

For simplicity, we denote the exponent in the right hand side of (21) as

f (, ) := k + (1 -  ) i +

i(j) +  min{i + j - 1 - d mhax(max{i(h), j(h)}), 0}. (22)

i

i>1,j

i<j

At this point, we observe that the optima for max, f (, ) are the same as those of the maximization problem for En[N (Kk, M (,))] defined in (14). In the statement of the next proposition
we characterize its solution.

Proposition 2. Let f be defined as in (22), and consider the problem

max f (, ) ,

(23)

,

with the constraints   0,   0. The solution of the maximum problem is attained by one of the following two sets of parameters for (i)i[k] and (i)i[k]:

1 i = 2 i  [k],

i(j) = 0 i  [k] \ 1, j  [d],

(24)

i = 0 i  [k],

i(j)

=

1 -
d

i  [k] \ 1, j  [d].

(25)

Thus, to obtain the optimal ,  described in Theorem 1, we only need to investigate which of the two candidates listed in Proposition 2 attains the maximal value of f (, ), which we will do in Section 5. There, we will also prove Theorem 1 by showing that the number of cliques formed on the set of vertices in M (,) converges to its mean value:

N (Kk, M (,)) = En[N (Kk, M (,))](1 + o(1)).

(26)

4 Proof of Proposition 2

To prove Proposition 2, we need first some technical lemmas. The first lemma enables to simplify the exponent f (, ) in (22).

Lemma 3. In optimal solutions of (23) i(j1) = i(j2) for all j1, j2  [d], i  [k].

Proof. By contradiction. Suppose that ,  is an optimizer of (23) and that there exists i  [k]

and

j1, j2



[d]

such

that

 (j1 )
i

=

(j2).
i

We

can

assume

without

loss

of

generality

that

 (j2 )
i

>

(j1).
i

Then, we define the set of parameters ^ = {^i(j)}i,j as follows:

^i(j) =

 (j2 )
i
i(j)

if i = i and j = j1, otherwise.

(27)

Note that

mhax(max{i(h), j(h)}) = mhax(max{^i(h), ^j(h)}).

(28)

Then, using the definition of f (, ) in (22), we observe that

f (, ) - f (, ^ ) = (j1) - ^(j1) = (j1) - (j2) < 0.

i

i

i

i

(29)

Therefore f (, }) < f (, ^), which contradicts the optimality of , .

11

By applying Lemma 3, we can rewrite f (, ^) as

f (, ) = k + (1 -  ) i + d i +  min{i + j - 1 - d max{i, j}), 0}, (30)

i

i=1

i<j

where we replaced i(d) by i for all d. Thus, from now on the parameters 1, ..., k will denote the value of all the components of the d-dimensional vector, instead of the vector itself.
We now introduce some notation that will simplify the rest of the proof of Proposition 2. Let I1, I2  [k], J2  [d] be a selection of indices. Writing f ({i}iI1, {i(j)}iI2,jJ2) we indicate the exponent f where our attention is limited to the parameters in the argument. That is, the
contribution of all the terms in (30) which are independent from the argument will be omitted, and
encoded in a constant value C. For instance, if we focus on the contribution of only i or i we
write

f (i) = C + (1 -  )i +  min{i + j - 1 - d max{i, j}, 0}

(31)

j

f (i) = C + di +

 min{i + j - 1 - di, 0}.

(32)

j:j i

If we focus on the contribution of a single vertex vi we write

f (i, i) = C + (1 -  )i + i +  min{i + j - 1 - d max{i, j}, 0}.

(33)

j=i

Then, the next lemma provides a lower bound for 1, ..., k, and a relation to the optimal value of i for all i such that i attains the lower bound:
Lemma 4. Suppose , is an optimal solution of (23). Then:

(i)

there

is

no

i  [k] \ {1}

such

that

i

<

-

1 d

;

(ii)

if

i

=

-

1 d

for

some

i  [k] \ {1}

then

i

= 0.

Proof. We first prove (i) by contradiction. Let ,  be a maximizer of (23). We sort and rename

the

coefficients

of



in

increasing

order,

so

that

1

<

2



...



k .

Suppose

that

h

<

-

1 d

for

some

h > 1, and assume without loss of generality that either h < h+1 or h = k. Then we can rewrite

(31) as

f (h) = C + dh +  min{h + j - 1 - dh, 0}

j<h

= C + dh

(34)

where the constant C encodes all terms in f independent from h. The last step follows because

j<h  min{h + j

- 1 - dh,

0}

= 0,

as

h

<

-

1 d

and

the

parameters

i

are

non-negative.

Now

we

define

a

new

set

of

parameters

^i

such

that

^i

=

i

for

all

i

=

h

and

^h

=

min(h+1,

-

1 d

).

Since ^j  ^h, for all j > h, we have

f ^h = C + d^h +  min{h + j - 1 - d^h, 0}

j<h

= C + d^h,

(35)

12

where again

j<h  min{h

+ j

- 1 - d^h,

0}

=

0,

as

^h



-

1 d

.

Therefore

f (^h) - f (h) = d

min

1 h+1, - d

- h

> 0.

(36)

This contradicts the optimality of , and therefore proves (i).

We now prove (ii).

Suppose that ,  is an optimal solution of

(23)

and

i

=

-

1 d

for some

i  [k] \ {1}.

We

use

an

increasing

ordering

for

,

so

that

2, ..., s

=

-

1 d

,

s+1

>

-

1 d

for some

s  [k], and with 2  ...  s. Now we focus on the contribution given by s and s to f as in (33)

f (s, s) = C+(1- )s+ds+  min{s+j -1-ds, 0}+  min{s+j -1-dj, 0}. (37)

j<s

j>s

Note that, if s + j > 0 for all j < s, then the optimality of the solution is violated. Indeed,
in this case, we may define ^s := s + , where  > 0 is small enough such that ^s < s+1 and ^s  (s + j - 1)/d, for all j < s. Then, observe that

 min{s + j - 1 - ds, 0} = 0 =  min{s + j - 1 - d^s, 0}

j<s

j<s

where

the

first

equality

follows

by

the

fact

that

s + j



0

and

s

=

1 d

,

whereas

the

second

equality

follows from ^s  (s + j - 1)/d. Then,

f s, ^s - f (s, s) = d(^s - s) > 0

which contradicts the maximality assumption. Consequently, the only possibility is that there exists s < s such that s + s = 0. In this case,
since s, s  0, also s = s = 0. Then, also 2 = ... = s = 0, as from our initial assumption 2  ...  s.
The next lemma shows that in any optimal solution of (23), the values 1, ..., k and 1, ..., k can be ordered increasingly jointly, i.e., using the same index permutations:

Lemma 5. Suppose that  =  - 1. For any optimal solution of (23), there exists an ordering such that both  and  are ordered increasingly. That is, without loss of generality we may assume that

1 < 2  ...  k, 1  2  ...  k.

(38)

Furthermore, 1 = 2. Proof. Choose arbitrarily an index j = 1. Let   j, and consider the quantity

d(1 - N{k:k,k+j-1-d<0}).

(39)

(note that if  = j then (39) is equal to f (j): the contribution of the term j of (31), and for  < j it denotes the contribution of the term j to the function f when j is set to ). We prove the lemma by contradiction. Suppose there exists a  < j such that N{k:k,k+j-1-d<0} > 0. Since the number N{k:k,k+j-1-d<0} is increasing in , then the quantity (1 - N{k:k,k+j-1-d<0}) is negative for any   [, j], as  > 1. However, this contradicts the fact that j is optimal: indeed in this case, decreasing j to  yields a higher contribution in (39), as  is negative as well.

13

Thus, N{k:k,k+j-1-d<0} = 0 for any  < j. Now, suppose that there exists i = 1 such that i < j. By contradiction suppose that i > j. Then, also

for any  < j. In particular,

N{k:ki,k+i-1-di<0} = 0

(40)

f (i) = i(1 - N{k:ki,k+i-1-di<0}) = i.

(41)

But in this case, increasing i would give a higher value of f (, ), contradicting the hypothesis of optimality.
Therefore, it remains to prove that 1  i for all i  [k] \ {1}. From the proof above, we can order the parameters {i}i=1 in an increasing order such that also the {i}i=1 are increasingly ordered. Then we just need to prove that 1  2. Note that 1 and 2 are symmetric in the optimization problem (23), as their contributions to the exponent f are

f (1) = C + (1 -  )1 +  min{1 + 2 - 1 - d2, 0} +  min{1 + j - 1 - dj, 0}, (42)
j3
f (2) = C + (1 -  )2 +  min{2 + 1 - 1 - d2, 0} +  min{2 + j - 1 - dj, 0}. (43)
j3

Suppose that 1 = 2. Then swapping 1 with 2 gives the same value for (23). This means that 1 has multiple optima. However, the contribution of 1 to f is given by

f (1) = 1(1 -  + N{k:k+1-1-dk<0}).

(44)

This contribution can have multiple optima only when  - 1 = , as it is linear in 1. Therefore, 1  2

We now use Lemmas 3-5 to prove Proposition 2:

Proof of Proposition 2. In view of Lemma 3 we can solve (23) by maximizing (30). Suppose that ,  is an optimal solution of (23), and sort them in increasing order, that is an order as in (38), which is possible by Lemma 5. Moreover, denote max := maxi i. We split the proof in three parts:

(a) Proving that either max = 0, or max < 0 and i = 0 for all i  [k];

(b)

Proving

that

if

max

<0

then

i

=

-

1 d

for

all

i  [k] \ {1}

and

i

=0

for

all

i  k;

(c)

Proving

that

if

max

=0

then

i = 0

for

all

i  [k] \ {1}

and

i

=

1 2

for

all

i  k.

Proof of (a). The parameters ,  are ordered increasingly, so k = max and 1  ...  k. Suppose that k < 0. We focus on the contribution given by vertex vk to f (, ) as defined in (33):

f (k, k) = C + (1 -  )k + dk +  min{k + j - 1 - dk, 0},

(45)

j=k

14

where max(k, j) = k for all j, as we assumed that k is the largest value of . Now suppose that

k

>

0.

Then,

we

can

increase

k

while

decreasing

k

as

follow:

^k

:=

k

+

 d

,

^k

:=

k

- ,

with

 > 0 small enough such that ^k < 0 and ^k  0. After this change of parameters we obtain

f (^k,

^k)

=

C

+

(1

-

 )(k

-

)

+

d(k

+

 )
d

+

 min{k -  + j - 1 - d(k + /d), 0}

j=k

= C +   + (1 -  )k + dk +  min{k + j - 1 - dk, 0}.
j=k

Comparing (45) and (4) we deduce that

f (^ , ^) - f (, ) =   > 0,

(46)

which contradicts the optimality of , . Therefore, when max < 0 necessarily k = 0. Then, our assumption on the ordering of i shows that if max < 0 then i = 0 for all i  [k].
Proof of (b). Suppose that max < 0. Then it follows from (a) that i = 0 for all i  [k]. Denote the number of indices such that i = max with s, that is, k-s+1 = ... = k = max. We focus on the contribution to f (, ) by the term max:

f ({i}i>k-s) = C + dsmax + 

min{-1 - dmax, 0}

i>k-s,j<i

s-1 = C + dsmax + s k - s + 2 (-1 - dmax)

(47)

= C~ + dsmax 1 - 

s-1 k-s+
2

.

In the second equality of (47) we exploit the independence of min{-1 - dmax, 0} from the sum-

mation indices i and j, that is, s

k

-

s

+

s-1 2

is the number of terms of the summation and the

fact

that

max



-

1 d

(from

Lemma

4).

Lastly,

observe

that

in

the

last

equality

C

is

replaced

by

C~,

which encodes additional constant values.

Since s < k and  > 1 the quantity inside the square brackets in (47) is always negative.

Therefore,

decreasing

max

to

-

1 d

gives

a

higher

contribution

to

f,

contradicting

optimality.

Thus,

if

max

<

0

then

i

=

-

1 d

for

all

i



[k] \ {1}

and

i

=

0

for

all

i



k.

Proof of (c). Let i be such that i = max = 0. Then the contribution of i to (23) is

f (i) = C + (1 -  )i +  min{i + j - 1, 0}

(48)

j=i

The parameters  are increasingly ordered. Thus, observe that:

· if i > 1 - 1, then i + j - 1 > 0 for all j = i. Therefore (48) becomes

f (i) = C + (1 -  )i.

(49)

In particular, changing i to 1 - 1 yields a higher contribution: if ^i = 1 - 1, then

f (^i) - f (i) = (1 -  )(1 - 1 - i) > 0,

(50)

which violates the hypothesis of optimality for i. Thus, i  1 - 1 when i = 0.

15

· if i < 1 - 2, then i + j - 1 < 0 for all j  m, and i + j - 1  0 for all j > m (for some m  2). Therefore, (48) becomes

m

f (i) = C + (1 -  )i +  (i + j - 1)

(51)

j=1

Defining ^i = i + , where  is small enough such that ^i < 1 - 2, we have

f (^i) - f (i) = (1 -  + m) > 0.

(52)

As 1- > -2 and m > 2, this contradicts the hypothesis of optimality. Therefore, i  1-2 when i = 0.

Consequently, if i is optimal and i = 0, then 1 - 2  i  1 - 1. However, from Lemma 5 we

know

that

1

=

2.

Hence,

i

=

1 - 1,

and

1



1 2

(because

j



1

for

all

j

>

1).

Now let M := {j  [k] : j = 0} and suppose |M | = t. Let i  [k] be such that i = maxj[k]\M j. Then, the contribution of vertex vi to (23) is by (33)

f (i, i) = C + (1 -  )i + di +  min(i + j - 1, 0) + 

min(i + j - 1 - di, 0)

jM

jM {i}

= C + (1 -  )i + di + t min{i - 1, 0} + 

min{i + j - 1 - di, 0},

jM {i}

where

we

have

used

that

i

=

1 - 1

for

all

i



M.

Denote

^i

=

i +

 d

and

^i

=

i

- ,

where



is

a quantity small enough for which ^i < 0. Then,

f (^i, ^i) - f (i, i) = ( - 1) +  + t min(i - 1 - , 0) - t min{i - 1, 0}

(53)

= ( - t1{i1}).

If i > 1, then the quantity in the right hand side of equation (53) is positive, and the optimality hypothesis is violated. Therefore, i  1, and in particular i = 1 (because by hypothesis we assumed that  is increasingly ordered). Consequently,

j =

1 1 - 1

if j  M , if j  M .

(54)

Now, we consider any index i  M  {1}, and we look at the contribution of i to f using (31),

f (i) = C + di + 

min{21 - 1 - di, 0}.

(55)

j:j <i

Suppose that di > 21 - 1. Define ^i = i - , where  > 0 is small enough such that still d^i > 21 - 1 and j < ^i for all the indices j such that j < i. Then we have

f (^i) - f (i) = -d + dN{j:j<i} = d(Nj:j<i - 1),

(56)

16

where Nj:j<i denotes the number of indices j such that j < i. Note that d(Nj:j<i - 1) > 0,

because the term inside the parenthesis is always positive, since  > 1 and 1 = -. Thus, f (^i) - f (i) > 0, that is, whenever di > 21 - 1 we can always improve the contribution to the

exponent f by decreasing i. So having di > 21 - 1 is never optimal.

On the other hand, if di  21 - 1 the summation in (55) is equal to 0. Hence, in this case the

maximum

contribution

to

f

is

achieved

for

the

highest

possible

value

of

i,

i.e.,

for

i

=

21-1 d

.

Summing up, in an optimal solution to (23),

 -

if i = 1,





i = 0

if i  M ,

(57)

 

21

-1

d

otherwise.

Then (23) becomes a piecewise linear problem in the lone variable 1. Recalling that t = |M |,

f (, ) = (1 -  )((k - t)1 + t(1 - 1)) + (k - t - 1)(21 - 1)

= C + 1[(k - 2t)(1 -  ) + 2k - 2t - 2]

(58)

= C + 1(k(3 -  ) + t(2 - 4) - 2)

where C encodes the constant terms independent from 1. Note that the quantity k(3 -  ) + t(2 -

4)-2 is always positive, as k  3, t < k and   (2, 3). Therefore, f (, ) is maximized by choosing

1

as

large

as

possible,

which

is

1

=

1 2

.

5 Proof of Theorem 1

Before proving Theorem 1, we state one last lemma showing that the standard deviation of of the predominant number of cliques is significantly smaller than its mean. In particular, this condition is sufficient to prove that the number of predominant cliques converges to its mean value.

Lemma 6. The number of cliques formed on vertices in M (,) is a self-averaging random vari-

able. That is,

Varn(N (Kk, M (,))) En[N (Kk, M (,))]2

=

0,

w.h.p.

(59)

Proof. For any v = (v1, ..., vk) we denote by Ev the event Ev := "a clique is formed on(v1, ..., vk)". We write the variance of N (Kk, M (,)) as

Varn N (Kk, M (,)) = Varn

1Ev

vM (,)

=

Covn (1Ev , 1Eu )

v,uM (,)

=

Pn(Ev, Eu) - Pn(Ev)Pn(Eu)

v,uM (,)

(60)

If v  u = , then the events Ev and Eu are independent. Consequently the covariance between 1Ev and 1Eu is 0. Therefore, we can restrict ourselves to the case |v  u| = s  1. In this case, we

17

bound Pn(Ev, Eu)  1. Then the contribution of the set of vertices such that |v  u| = s  1 to (60) can be bounded by

Pn(Ev, Eu)  (v, u) 
v,uM (,) |vu|=s

M (,)

2
: |v  u| = s

.

(61)

Suppose that v and u overlap on vi1 = uj1, ..., vis = ujs, for some collection of indices I = {i1, ..., is}, J = {j1, ..., js}. Then,

Pn(Ev, Eu)  v  M (,) ·

uj  V : wuj  I(n ), | xuj - xu1 | = I(n )

v,uM (,)

jJ

|vu|=s

(62)

where

(, )

=

(

1 2

,

0),

or

(0,

-

1 d

).

We

observe

that

if

v

and

u

overlap,

without

loss

of

generality

we can assume that 1  J, that is, u1  (v  u). Indeed, if there exist indices i, j such that vi = uj,

then after fixing v  M (,) the vertex uj is fixed (and therefore also its position is fixed). Due to

the symmetry of the problem, we can permute the indices of the vector u, so that the first element

of u is the vertex uj. Since u  M (,), after this permutation all vertices in u that are not overlapping with v (i.e., whose position is not fixed after choosing v  M (,)) will have their

position in a neighborhood of size (n) of uj.

Then, we can rewrite (62) as

Pn(Ev, Eu)  |M (,)| · P
v,uM (,) |vu|=s

n1+(1- )+d

k-s
= P

n1+(1- )+d

2k-s

(63)

Finally, we recall that En[N (Kk, M (,))] = P nk+k(1-)+(k-1)d , from which we deduce

Varn(N (Kk, M (,))) = En[N (Kk, M (,))]2o(1).

(64)

We are now ready to prove our main result, Theorem 1:

Proof of Theorem 1. Plugging the solution ,  provided by Proposition 2 into (22) shows that the maximum value of f (, ) is

f (, ) = max

3- k, 1

.

(65)

2

For k >

2 3-

,

the maximum is attained at

3- 2

k,

and

(, )

is

as

in

(24).

For k <

2 3-

on the

other hand, it is attained at 1, and (, ) is defined as in (25). This provides two cases for k that

distinguish

the

two

possible

optima:

k

<

2 3-

,

or k

>

2 3-

.

In

particular,

except

for

the

threshold

case

k

=

2 3-

,

the

solution

to

(23)

is

unique.

Consequently, since En[N (Kk, M (,))] = P nf(,) ,

En[N (Kk, M (,))] =

P

n 3- 2

k

P (n)

if

k

>

2 3-

if

k

<

2 3-

(66)

18

If (, ) = (, ), then f (, ) < f (, ). Moreover,

En[N (Kk, M (,))] En[N (Kk, M (,))]

=

P P

nf (,) nf (,)

=0

w.h.p.,

(67)

proving the first part of Theorem 1, and showing that the mean number of cliques with vertices of weights and positions ,  is indeed predominant among the others.
Lastly, by Lemma 6 and Chebyshev's inequality, it follows that

N (Kk, M (,)) = En[N (Kk, M (,))](1 + o(1)),

(68)

which proves (8).

Acknowledgements. This work is supported by an NWO VENI grant 202.001.

References
[1] K. E. Avrachenkov and A. V. Bobu. Cliques in high-dimensional random geometric graphs. Applied Network Science, 5:92, 2020.
[2] G. Bianconi and M. Marsili. Number of cliques in random scale-free network ensembles. Physica D: Nonlinear Phenomena, 224(1):1­6, 2006. Dynamics on Complex Networks and Applications.
[3] T. Bläsius, T. Friedrich, M. Katzmann, U. Meyer, M. Penschuck, and C. Weyand. Efficiently generating geometric inhomogeneous and hyperbolic random graphs. In M. A. Bender, O. Svensson, and G. Herman, editors, 27th Annual European Symposium on Algorithms (ESA 2019), volume 144 of Leibniz International Proceedings in Informatics (LIPIcs), pages 21:1­21:14, Dagstuhl, Germany, 2019. Schloss Dagstuhl­Leibniz-Zentrum fuer Informatik.
[4] T. Bläsius, T. Friedrich, and A. Krohmer. Cliques in hyperbolic random graphs. Algorithmica, 80(8):2324­2344, 2018.
[5] K. Bogerd, R. M. Castro, and R. van der Hofstad. Cliques in rank-1 random graphs: The role of inhomogeneity. Bernoulli, 26(1):253 ­ 285, 2020.
[6] K. Bringmann, R. Keusch, and J. Lengler. Geometric inhomogeneous random graphs. Theoretical Computer Science, 760:35­54, 2019.
[7] L. Devroye, A. György, G. Lugosi, F. Udina, et al. High-dimensional random geometric graphs and their clique number. Electronic Journal of Probability, 16:2481­2508, 2011.
[8] M. Dolezal, J. Hladky`, and A. Máthé. Cliques in dense inhomogeneous random graphs. Random Structures & Algorithms, 51(2):275­314, 2017.
[9] T. Gavenciak. https://github.com/gavento/girg-sampling, 2020.
[10] L. Gugelmann, K. Panagiotou, and U. Peter. Random hyperbolic graphs: degree sequence and clustering. 39th International Colloquium on Automata, Languages, and Programming, ICALP, pages 573­585, 2012.

19

[11] R. van der Hofstad, J. S. H. van Leeuwaarden, and C. Stegehuis. Optimal subgraph structures in scale-free configuration models. The Annals of Applied Probability, 31(2):501 ­ 537, 2021.
[12] S. Janson, T. Luczak, and I. Norros. Large cliques in a power-law random graph. Journal of Applied Probability, 47(4):1124­1135, 2010.
[13] A. J. E. M. Janssen, J. S. H. van Leeuwaarden, and S. Shneer. Counting Cliques and Cycles in Scale-Free Inhomogeneous Random Graphs. Journal of Statistical Physics, 175:161­184, 2019.
[14] M. Latapy. Main-memory triangle computations for very large (sparse (power-law)) graphs. Theoretical Computer Science, 407(1):458­473, 2008.
[15] M. Penschuck, C. Weyand, and T. Bläsius. https://github.com/chistopher/girgs, 2019. [16] T. Schank and D. Wagner. Finding, counting and listing all triangles in large graphs, an
experimental study. In S. E. Nikoletseas, editor, Experimental and Efficient Algorithms, pages 606­609, Berlin, Heidelberg, 2005. Springer Berlin Heidelberg. [17] C. Stegehuis. Distinguishing power-law uniform random graphs from inhomogeneous random graphs through small subgraphs. arXiv:2102.09315, 2021. [18] C. Stegehuis, R. van der Hofstad, and J. S. van Leeuwaarden. Variational principle for scale-free network motifs. Scientific reports, 9(1):1­10, 2019.
20

