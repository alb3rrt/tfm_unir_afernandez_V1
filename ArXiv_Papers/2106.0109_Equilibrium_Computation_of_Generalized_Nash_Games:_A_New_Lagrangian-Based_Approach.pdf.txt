Equilibrium Computation of Generalized Nash Games: A New Lagrangian-Based Approach

arXiv:2106.00109v1 [cs.GT] 31 May 2021

JONG GWANG KIM, Purdue University
This paper presents a new primal-dual method for computing an equilibrium of generalized (continuous) Nash game (referred to as generalized Nash equilibrium problem (GNEP)) where each player's feasible strategy set depends on the other players' strategies. The method is based on a new form of Lagrangian function with a quadratic approximation. First, we reformulate a GNEP as a saddle point computation using the new Lagrangian and establish equivalence between a saddle point of the Lagrangian and an equilibrium of the GNEP. We then propose a simple algorithm that is convergent to the saddle point. Furthermore, we establish global convergence by assuming that the Lagrangian function satisfies the Kurdyka-Lojasiewicz property. A distinctive feature of our analysis is to make use of the new Lagrangian as a potential function to guide the iterate convergence, which is based on the idea of turning a descent method into a multiplier method. Our method has two novel features over existing approaches: (i) it requires neither boundedness assumptions on the strategy set and the set of multipliers of each player, nor any boundedness assumptions on the iterates generated by the algorithm; (ii) it leads to a Jacobi-type decomposition scheme, which, to the best of our knowledge, is the first development of a distributed algorithm to solve a general class of GNEPs. Numerical experiments are performed on benchmark test problems and the results demonstrate the effectiveness of the proposed method.

1 INTRODUCTION
We consider a generalized (continuous) Nash game (generalized Nash equilibrium problem (GNEP)) that describes a broad class of non-cooperative and simultaneous-move games, in which each player seeks to optimize her/his own objective function while subject to certain constraints that are affected by the other players' strategies. The standard Nash game [37] is a subclass of GNEPs, as the strategic interactions among players in a Nash game are only reflected in their objective functions, not in the constraints. More specifically, the game features a set of players denoted by N = {1, . . . , } where each player has its own strategy  R . Each player has an objective function ( , - ) and a finite set of "coupling constraints" ( , - )  0 ( = 1, . . . , ), both of which depend on player 's own strategy as well as other players' strategies - := ( )  . Denote all players' strategies by a vector x = ( , - ) := ( 1, . . . , , . . . , ) with dimension
= =1 . The GNEP can be formally defined as a problem of simultaneously finding a solution for each of the following problem. Given other players' strategies - , each player seeks to find a strategy that solves the optimization problem:
minimize ( , - )

P ( - ) subject to ( , - )  0, = 1, . . . , ,

(1)

X ,

where X  R represents the "private" strategy set of player that is nonempty, closed, and convex. The feasible strategy set of each player can be represented by the parametric inequalities:
F ( - ) :=  X | ( , - )  0, = 1, . . . ,  R .

Note that the private functional constraints ( )  0 for = 1, . . . , are not explicitly high-
lighted in the paper for notational simplicity. They can be easily treated by the same way to deal with ( , - )  0. The simple set X is defined by X := {  R |   }, where or may be unbounded; that is, = - or = + or both.
A Nash equilibrium of the GNEP can be defined as follows.

Jong Gwang Kim

1

Definition 1. A collection of strategies x = 1,, . . . , , is a (pure-strategy) generalized Nash equilibrium (GNE) if for every = 1, . . . , ,
( ,, - ,)  ( , - ,) ,   F ( - ,),
i.e., x = ( 1,, . . . , ,) is a GNE, if and only if no player has incentive to unilaterally deviate from , when other players choose - ,.

We make the following assumption on the functions throughout the paper.

Assumption 1. For every  N and fixed - , objective function ( , - ) and constraint functions ( , - ), = 1, . . . , , are continuously differentiable and convex with respect to only
.

Note that ( , - ) and ( , - ) are possibly nonconvex with respect to some other players' decisions   - , and ( , - ) are not necessarily shared by all players (called non-shared coupling constraints).
Under Assumption 1, Problem (1) is known as a very general form of GNEP [19] (We call it general GNEP in this work). In this paper, we aim to provide and analyze the first distributed primal-dual algorithm, based on a novel form of Lagrangian, to compute an equilibrium of the general GNEP, provided that equilibria of generalized Nash game exist.
We also make the following two standard assumptions needed for convergence analysis of the proposed algorithm; Lipschitz gradient continuity of the objective and constraint functions and coercivity of the objective functions.

Assumption 2 (Uniform Lipschtz gradient continuity). For every = 1, . . . , , the gradients of ( , - ) and ( , - ) are uniformly Lipschitz continuous with constants; that is, for any
fixed - ,  {1, . . . , }, there exist constants ( ) > 0 and ( ) > 0 such that

 ( 1, - ) -  ( 2, - )  ( ) 1 - 2 ,  1, 2  X ,

(2a)

 ( 1, - ) -  ( 2, - )  ( ) 1 - 2 ,  1, 2  X .

(2b)

In addition, for any fixed  X , there exist constants - ( ) > 0 and - ( ) > 0 such that



(

,

- 1

)

-

(

,

- 2

)



-(

)

- 1

-

- 2

,



- 1

,

- 2

 X- ,

(2c)



(

,

- 1

)-

(

,

- 2

)



-(

)

- 1

-

- 2

,



- 1

,

- 2

 X- .

(2d)

Here, X- :=  X .

Assumption 2 is natural in continuous game-theoretic settings since Assumption 2 implies that the values of the objective and constraint functions of each player do not change arbitrarily quickly to the changes in other players' strategies.

Assumption 3 (Coercivity of objective function). For every = 1, . . . , , the objective function ( , - ) is coercive with respect to x = ( , - ), i.e., lim x  (x) = .
We need to make some remarks on Assumption 3 as follows:
· It is well-known that coercivity assumption on the objective function is a standard assumption for convergence analysis of descent algorithms in nonconvex settings; see e.g., [12, 13, 32]. It is assumed to make sure that the sequence generated by the algorithm is bounded so that its limit points exist. It may be a difficult task for nonconvex analysis of descent methods without the coercive assumption.

Jong Gwang Kim

2

· Hence, Assumption 3 is needed to guarantee that the sequence of the iterates generated by our method is bounded for the general case, where ( , - ) is nonconvex in some other players strategies   - and some private strategy sets X are unbounded (see Example 1). Without this assumption, even if we can derive that all P-Lagrangian is decreasing and convergent to a finite value, we cannot claim the generated sequence is bounded. Thus, there is no way to guarantee the existence of limit points.
· However, Assumption 3 can be dropped if all private set X , = 1, . . . , are bounded, as Assumption 3 is trivially satisfied for any continuous objective function in this case (see Example 2). Indeed, this is reasonable from a practical perspective. In real-world economic and business problems, every agent (player) has its limited capacity due to economic limitations such as production limits or budget limits, or regulatory restrictions. In such problems we no longer require that each ( , - ) to be coercive.
· We do not impose the coercivity assumption on the feasible strategy sets, which is in contrast to the analysis of the interior-point algorithm for solving general GNEPs in [19]. In [19], the convergence analysis of the algorithm relies on the strong assumption that the feasible strategy sets are contained in the level sets of the constraints.

1.1 Motivating Examples We give two practical examples that illustrate the versatility of the general GNEP model (1) and motivate to develop an efficient algorithm. We refer the readers to [22] for more examples.
Example 1 (Power allocation in telecommunications). This model is described in detail in [41] and represents a realistic communication system subject to Quality-of-Service (QoS) constraints. There are links transmitting to different Base Stations by using different channels. Link transmits with power = ( 1 , . . . , ), and denote by x = ( 1, . . . , ) the power allocation of all links. The game-theoretical model is defined by

minimize

subject to log2 1 +

=1

=1


2+ 


 ,  0,

where  denotes the power gain between transmitter and receiver on the -th channel, 2 is the noise power of link on the -th channel, and is the minimum transmission rate (target rate) for link .
In this game-theoretical model, the QoS constraints are nonconvex in the other links' decision variables, and each link has different coupling QoS constraints. Thus, this problem can be viewed as a case of the general GNEP (1). Moreover, due to the complicated coupling constraints, it is hard to compute a Nash equilibrium of the model efficiently.
Example 2 (Arrow-Debreu general equilibrium model; see [3] and [22]). There are consumers, firms, and one market player (a fictitious player) in this equilibrium model. Both consumers and
firms deal with goods. The market player sets (normalized) prices  R+ for solving a market clearing problem. The -th firm maximizes its profit by deciding how much to produce  , where  R is a production set. The -th consumer decides how much of each good to buy
 to maximize its utility, where  R is a consumption set. The GNEP is defined as the

Jong Gwang Kim

3

following set of problems of the three types of players:

max ( ) max

max

-

-

=1

=1

=1

s.t.  ,

s.t.

+
=1

, ,

s.t.

= 1,  0.

=1

The first problem corresponds to firm 's production problem, the second problem corresponds to the consumption problem of consumer , and the last problem corresponds to the market player's problem. Here,  0 represents the fraction of the profit of the -th production owned by con-

sumer such that =1 = 1, and  R+ is an initial endowment of goods.

Definition 2 (Walrasian Equilibrium; see e.g., [27]). An equilibrium consists of a price vector ,

consumption vectors for = 1, . . . , , and production vectors for = 1, . . . , , such that

(E1) (Market Nontriviality).  0,  0,

(E2) (Utility Optimization). maximizes ( ) over  s.t.



+ =1

,

(E3) (Profit Optimization). maximizes over  ,

(E4) (Market Clearing). Supplies and demands are balanced in the sense that

 0 and · = 0 for =

-

-.

=1

=1

=1

For any , conditions ( 2) and ( 3) can be expressed in terms of



, 1, . . . ,

with 

,

where ( ) = argmax
 ()

and , 1, . . . , = argmax
 ()



+ =1

. Note

that (E4) comes out as a linear complimentarity condition on ¯ and ¯. The above expressions lead

to the idea of capturing all conditions for equilibrium, including (E4), in terms of a mapping from

to : ( ) = = =1 + =1 - =1

 ( ),  ( , 1, . . . , ) . Clearly, we have

¯  yields equilibrium  ¯  ( ¯) such that ¯  0, ¯ · ¯ = 0.

We thus see that the feasible strategy set of each player depends on the other players' selfish decisions. Furthermore, each player's feasible set does not depend on all other players' decisions (i.e., non-shared coupling constraints). Hence, the Arrow-Debreu equilibrium model is a case of the general GNEPs (1).
Notice that the set of prices := = ( 1, . . . , )  0, =1 = 1 is a simplex and so it bounded. Hence, we can observe from the above expressions that the production sets and consumption sets are also bounded. As a result, the coercivity assumption on the objective functions (Assumption 3) is not required for computing an equilibrium of this economic equilibrium model.

1.2 Literature Review
The concept of GNEP was originally addressed by Debreu [18] and Arrow and Debreu [3] in the early 1950s, where a GNEP was called a social equilibrium problem or abstract economy. An important subclass of GNEPs, known as jointly-convex GNEPs, was first investigated by Rosen [43] where all players share the same convex coupling constraints (i.e., 1 = · · · = ). Although early studies on GNEPs have been primarily concerned with economics, recent decades have witnessed

Jong Gwang Kim

4

a growing interest in the GNEP as a modeling framework and a solution concept in various application areas. Some examples include electricity market models [17, 25, 26], power allocation in telecommunications [41], environmental pollution applications [14, 29], transportation systems [45], and mobile cloud computing [15], to name a few.
Many approaches have been proposed to compute a GNE in the literature. A common approach is to transform a GNEP into a variational inequality (VI) and to apply algorithms designed to find a solution of a VI reformulation (see e.g., [20, 30, 36, 50]). Another approach is to reformulate a GNEP into a global optimization problem using Nikaido-Isoda (NI) function and then solve the resulting optimization problem by the so-called relaxation algorithms [46, 48] or gradient-based algorithms [47]. However, the theoretical and algorithmic properties of both approaches are only established for the class of jointly-convex GNEPs. In particular, VI-based methods require the monotonicity assumption on the variational mapping that generally does not hold in general GNEPs.
The equilibrium computation of GNEPs beyond the class of jointly-convex GNEPs remains a very challenging task. This is mainly due to interdependence between each player's strategy and some other players' strategies through coupling constraints and potential nonconvexity of each player's optimization problem with regard to the strategies chosen by other players. A few algorithms have indeed been proposed, including penalty-type methods [23, 40], interior point algorithm [19] and augmented Lagrangian method [28]. In all such methods, it is assumed that the extended Mangasarian-Fromovitz constraint qualification (EMFCQ), an extension of the MFCQ for infeasible points, holds with respect to x = ( , - ) for each player , at every limit point of the sequence x generated by the algorithms. This MFCQ is a restrictive assumption since it is equivalent to the boundedness of the multiplier set of each player, and it cannot be justified to hold for every player in the GNEP in general due to the nature of GNEPs. More specifically, x ( , - ) = 0 and the multipliers   might occur since it is possible that x ( , - ) = 0 from the strategic interactions among players through the coupling constraint. Thus, GNEPs may have an unbounded Lagrange multiplier set of each player.
Penalty-based algorithms reduce the GNEP to a standard Nash equilibrium problem (NEP) by penalizing coupling constraints and focus on updating the penalty parameter. In particular, the exact penalty method in [23] results in nonsmooth subproblems, so it obtains a GNE under various differentiability assumptions on the objective functions and constraints. This lack of differentiability is a serious problem for designing efficient algorithms. To address the drawbacks of penalty-based methods, Kanzow and Steck proposed an augmented Lagrangian method in [28]. This approach requires an algorithmic assumption that there exists a limit point of the primal sequence {x }. However, this assumption is not clear without the compactness of each player's private set.
Furthermore, it is noteworthy to point out that even with our coercivity assumption on the objective functions, the augmented Lagrangian (AL) algorithm [28] does not guarantee that the primal sequence and/or dual sequence remains bounded. To ensure the boundedness of the sequences with the coercivity assumption, the bounded level sets of the AL functions are required. However, these level sets are typically unbounded. This is mainly related to the behavior of the multiplier sequence { , , }. Specifically, the AL method in [28] is of min-max dynamics (due to the increase in the dual variable) and by nature, the AL function value alternatively increases and decreases, and the dual sequence { , } might be unbounded. Hence, the coercivity does not imply the boundedness of the primal and dual sequences in the AL algorithm. This can be illustrated by a simple example.

Jong Gwang Kim

5

Example 3. Consider the two players GNEP with 1 = 2 = 1:

min 1 2

P1 ( 2)

1 R

s. t.

2 1

+

2 2



1,

P2 ( 1)

min
2 R

2 2

s. t.

(

1 - 2)2 +

2 2



1,

where both players' objective functions are coercive. We see that at the unique equilibrium (and only feasible point) given by x = ( 1, 2) = (1, 0), the gradients of the constraints are linearly dependent, and hence the MFCQ does not hold. As a result, the AL algorithm in [28] may generate
an unbounded multiplier sequence, which results in an unbounded sequence of the AL function
values and thus failure to have limit points.

In a computational perspective, a major limitation of the methods in [21, 28] is that they cannot be implemented in a distributed way since they need to solve subproblems represented by a large system of nonlinear equations (variational inequality) at each iteration. Thus, they are computationally expensive.

1.3 Our Contributions

The objective of this paper is to propose a new algorithmic framework for computing an equilib-

rium of a general GNEP under general assumptions without imposing boundedness assumptions

on the generated primal and dual sequences and the (feasible) strategy sets of all players. To achieve

such a goal, we introduce a novel form of Lagrangian, termed as Proximal-Perturbed Lagrangian

(P-Lagrangian), and utilize a quadratic approximation of the P-Lagrangian.

The key ideas underlying our approach are as follows. First, perturbation variables are intro-

duced to form constraints ( , - ,)  and = 0, which can be relaxed into the objec-

tive function with Lagrange multipliers. This reformulation allows the use of 2

2 as simple

penalty terms and exploiting a proximal regularization on the Lagrange multipliers, which pro-

vides a strongly concave function in the multipliers. The next ingredient is to employ a quadratic

approximation that is strongly convex in all the players' strategies. This enables to simply deal with the nonconvexity of ( , - ) and ( , - ) in some   - , and further leads to a

Jacobi-type decomposition scheme for updating primal variables at each iteration.

This paper makes the following contributions to the literature:

· We introduce a new form of Lagrangian function that has a favorable structure; it is strongly concave with respect to the Lagrange multipliers, and it does not include penalty terms for handling coupling constraints. Consequently, the proposed algorithm guarantees to generate the bounded sequence of the Lagrange multipliers with the bounded primal sequence without requiring the MFCQ assumption. Moreover, this leads to an easy-to-implement algorithm by removing the computational effort in updating the penalty parameter as in [23] and [28].
· The proposed algorithm can deal with the nonconvexity of each player's functions in other players' decisions by employing a quadratic approximation of the original P-Lagrangian in x. More importantly, the use of the quadratic approximation offers a Jacobi-type decomposition scheme that allows distributed simultaneous updates of primal variables, which, to the best of our knowledge, leads to the first distributed algorithm to solve general GNEPs.
· We prove that our algorithm is convergent to a saddle point of P-Lagrangian under standard assumptions. In contrast to the existing methods for solving general GNEPs, our analysis does not impose any boundedness assumptions on the iterates generated by the algorithm. In particular, we do not make use of a priori assumption that a limit point of primal iterates

Jong Gwang Kim

6

x exists, and safeguarding technique [1, 2] to bound multiplier iterates as in [28]. In addition, we establish the global convergence under an additional assumption that the functions satisfy the Kurdyka-Lojasiewicz inequality.

1.4 Notation and Outline of the Paper

Notation. We use R and R to denote the -dimensional Euclidean vector space and -

dimensional Euclidean vector space, respectively. For two vectors ,  R , the inner product

is denoted by , and the standard Euclidean norm is denoted by =

. For a real scalar

 R, we define [ ]+ = max ( , 0). We use R+ to denote the nonnegative orthant of R .

Outline of the paper. This paper is organized as follows. In section 2, we introduce the P-Lagrangian function, describe its characteristics, and reformulate the GNEP as a saddle point problem using the P-Lagrangian. Section 3 presents a distributed primal-dual algorithm based on a quadratic approximation. In Section 4, we establish convergence of the proposed algorithm. Numerical results are presented in Section 5.

2 PROXIMAL-PERTURBED LAGRANGIAN FORMULATION
Before introducing Proximal-Perturbed Lagrangian (P-Lagrangian), we recall that under Assumption 1, a GNE x = 1,, . . . , , can be characterized by the Karush-Kuhn-Tucker (KKT) conditions (see e.g., Dreves et al. [19]):
The KKT conditions. If there exists a point x = ( 1,, . . . , ,) together with some Lagrange multipliers , satisfying the KKT conditions:

0   0 ( ,, - ,, ,) + NX ( ,) ,

,  X ,

,  0,

( ,, - ,)  0,

, ( ,, - ,) = 0,  = 1, . . . , ,

(3)

for every = 1, . . . , , then x = ( 1,, . . . , ,) is a generalized Nash equilibrium (GNE). Here, 0 ( , - , ) := ( , - ) + =1( ) ( , - ) is each player 's Lagrangian function, and
NX ( ,) := d  X | d ( - ,)  0,   X is the normal cone to X at x. It is well known [22, Theorem 4.6] that under the convexity assumption, the KKT system (3) is
a necessary and sufficient optimality condition for problem (1). In addition, convex optimization
problem (1) is equivalent to solving the dual formulation, i.e.,

(x) = max
0

0(

) := min
X

0(

, - ,,

).

(4)

In general GNEP model, the set of Lagrange multipliers of each player is possibly unbounded (assuming it is nonempty) even if it satisfies the KKT conditions (3). This is due to the interdependency between and - through the coupling constraints ( , - )  0, = 1, . . . , . This makes the computation of a GNE very hard, and thus boundedness of the multipliers is one of the key issues when solving GNEPs. Our motivation for modifying augmented Lagrangian and introducing a new Lagrangian is to address this challenge.
This section first introduces a new form of Lagrangian that has a desirable structure for equilibrium computation. We then present a reformulation of problem (1) as a P-Lagrangian dual problem and show that computing a saddle point of the P-Lagrangian is equivalent to finding an equilibrium of the GNEP (1).

2.1 The Proximal-Perturbed Lagrangian
Motivated by the reformulation techniques in [10, Chapter 3.4] and [9, Chapter 3.2], we start by transforming problem (1) into an equivalent extended formulation by introducing perturbation

Jong Gwang Kim

7

variables = ( 1 , . . . ,

) = 0 as additional constraints and letting ( , - ) 

EP ( - )

minimize
X , R
subject to

( , -) ( , - ) ,

given - : (5)

= 0.

Obviously, for = 0, the above extended formulation (5) is equal to problem (1).

Noting that the reformulation (5) allows the use of 2

2 as a penalty term, first consider the

following partially augmented Lagrangian for every = 1, . . . , :

( , - , , , )= ( , - )+( ) ( ( , - )- )+( ) + 2

2,

where = ( , . . . , )  R+ and = ( , . . . , )  R are the Lagrange multipliers associated with constraints ( , - ) -  0 and = 0, respectively. > 0 is a penalty parameter. Observe that given ( , ), minimizing with respect to gives

1 ( , ) = ( - ),

which implies that = at the unique solution , = 0. Based on this relation of and

from the optimality condition for , we add a proximal term - 2 Perturbed Lagrangian (P-Lagrangian) as

- 2 to define a Proximal-

L ( , - , , , ) := ( , - ) + ( ) ( ( , - ) - ) + ( )

(6)

+2

2- 2

- 2,

where > 0 is a proximal regularization parameter.

We observe that the structure of the P-Lagrangian L in (6) differs from the standard aug-

mented Lagrangian and its variants. First, it is characterized by the absence of penalty term for

handling the coupling constraint ( , - ) -  0. Only additional constraint = 0 is penal-

ized with a quadratic penalty term 2

2, while the constraint ( , - ) -  0 is merely

relaxed into the objective with the corresponding multiplier. Second, the P-Lagrangian is strongly

concave in (for fixed ) and (for fixed ) due to the presence of the negative quadratic

term - 2 - 2. Note that, as will be shown later, this quadratic term - 2 - 2 plays an important role that it does not allow for the next iterate , +1 to deviate far from , when

updating the multiplier via an exact maximization scheme.

2.2 Equivalence between a Saddle Point of P-Lagrangian and a GNE Now consider the following P-Lagrangian dual problem for given - :

max

D ( , ) := min L ( , - , , , ) .

(7)

R+ , R

X , R

Since L (·, - ,, , , ) is convex, the primal-dual solutions of problem (7), ( ,, - ,, ,)

and ( ,, ,) given - = - ,, can be characterized by the saddle point of the P-Lagrangian.

Definition 3. Given - ,, a point ( ,, - ,, ,, ,, ,) is said to be a (parametrized) saddle point of the Proximal-Perturbed Lagrangian for > 0 and > 0 if for every = 1, . . . , ,
L ( ,, - ,, ,, , )  L ( ,, - ,, ,, ,, ,)  L ( , - ,, , ,, ,), (8)

for all ( , , , )  X ( - ,) × R × R+ × R . Here, - , are viewed as parameters.

Jong Gwang Kim

8

We establish the equivalence between computing a saddle point of L and finding an equilibrium of the GNEP (1), by proving the following two theorems.

T

1. Let ( ,, - ,, ,, ,, ,) be a saddle point of L ( , - , , , ) for a given

- = - , and for some , > 0. Then, x = ( ,, - ,) is an equilibrium of the GNEP (1).

P . See Appendix A.1.

T

2. Assume that x = 1,, . . . , , is an equilibrium of the GNEP (1) satisfying a

suitable constraint qualification, at which the KKT conditions (3) hold with some Lagrange multipliers

, for all players' optimization problems, given - = - ,. Then, there exists Lagrange multipliers

( ,, ,) such that

L (x, ,, , )  L (x, ,, ,, ,)  L ( , - ,, , ,, ,) ,

(9)

for any ( , , , )  X ( - ,) × R × R+ × R . P . See Appendix A.2.

3 ALGORITHM In this section, we propose a distributed algorithm for computing a saddle point of L a quadratic approximation of L for every = 1, . . . , .

based on

3.1 Motivation for Approximation of Subproblems We begin by describing briefly why we need to consider an approximation scheme for updating x = ( , - ). To compute a saddle point of L (x, , , ) for every = 1, . . . , , we should be able to determine a point x = ( , - ) that satisfies the following first-order optimality (or simultaneous stationarity) condition of subproblems for fixed ( , , ):
 L (x, , , ) ( - )  0,   X for all = 1, . . . , .
It is well known (see Facchinei and Pang [24]) that for given ( , , , , , ), computing such a stationary point is equivalent to the variational inequality (VI) problem of finding x  X such that

L x, , , (x - x)  0, x  X,

where X := =1 X , the Cartesian product of the private strategy sets of all players, and the mapping L x, , , : X  R is given by

L x, , ,

=





1 L1 L

1, -1, 1, , 1, , 1,
... , - , ,, ,, ,

 ,

with = ( 1) , . . . , ( ) , = ( 1) , . . . , ( ) and = ( 1) , . . . , ( ) . However, it is difficult to compute the point x using descent methods. In the GNEP setting, the
monotonicity of the mapping L(x, , , ) with respect to x = ( , - ) does not hold (possibly nonmonotone) in general [22, Section 5.2] even if each component  L ( , - , , , ) is
convex in . The nonconvexity of each P-Lagrangian with respect to the other players' variables makes it hard to preserve a descent direction for the convergence to the stationary point x that satisfies all components of the variational inequality.

Jong Gwang Kim

9

3.2 Construction of adratic Approximation Model
To overcome such a computational difficulty, we consider a monotone approximation, denoted by L , to the nonmonotone mapping L in x. The monotone approximation L of the mapping L can be always chosen even if L is nonmonotone (see e.g., Chung and Fuller [16], Luna et al. [35]). Furthermore, strongly monotone approximation mapping can be derived by replacing each player's L by a simple approximate function and then constructing an approximation L .
To this end, inspired by Beck and Teboulle [7] and Bolte et al. [11], we first employ the following quadratic approximation L in only x, at a given point y:

L (x, , , ; y) := L (y, , , ) +  L (y, , , ) ( - ) + 2

-2

+  L


(y,

,

,

)(

-

) + 2 

-



2
,

(10)

namely, the linearized P-Lagrangian L at the point y combined with quadratic proximal terms

that measure the local error in the linear approximation. Here, > 0 is a proximal parameter.

The term    L (y, , , ) =  - L (y, , , ) represents the gradient at a given

point y  R in other players' strategies, and  L (y, , , ) denotes the gradient of L

with respect to at the point y.

Remark 1 (Properties of L ). The approximate function L has the following properties (see

e.g., [7, 42, 44]):

(P1) xL (y, , , ; y) = xL (y, , , ) for y  X.
(P2) L (·, , , ; y) is strongly convex in all the players' decisions x = ( stant > 0, i.e., for any x1, x2  X

, - ) with con-

xL (x1, , , ; y) - xL (x2, , , ; y) (x1 - x2)  x1 - x2 2 .

(P3) xL =  1 L , . . . ,  L

is Lipschitz continuous on X for every = 1, . . . , with

some constant  , i.e., for any x1, x2  X

xL (x1, , , ; y) - xL (x2, , , ; y)  x1 - x2 .

The property (P1) implies that L and L have the same first-order behavior at the given point y. The properties (P2) and (P3) are from the structure of L that is the first-order approximation of L in x at y with quadratic term 2 x - y 2.
Given the iterates y = x and ( , , , , , ), L (·, , , , , , ; x ) is strongly convex in x = ( , - ), there must exist a unique minimizer x = ( , , - , ) at each iteration such that

 L x , , , , , , ; x ( - , )  0, = 1, . . . , .

We can construct a monotone approximation mapping L : X  R given by

L

x,

,

,

;x

:=





1 L1 L

1, -1, 1, , 1, , 1, ; x ...
, - , , , , , , ;x

 .

Jong Gwang Kim

10

Let us now consider solving the following approximate variational inequality problem VI (X, L ) of finding a collection of approximate solutions x such that

L x , , , ; x x - x  0, x  X.

(11)

It is well known ([24, Proposition 1.5.8]) that x is also a solution to the system of fixed-point subproblem (or system of nonlinear projected equations) at iteration :

x - PX x - L x , , , ; x = 0,

(12)

where PX( ) = argmin { - |  X} denotes the Euclidean projection operator onto the set X and := ( 1, . . . , ) is a vector of positive constants.
For fixed (x , , , ) at iteration , we can use the following gradient projection to generate a sequence u , converging to x in inner iterations = 0, 1, 2, . . .

u , +1 = PX u , - L u , , , , ; x .

(13)

Notice that the structure of  L allows for the inner projection step (13) to be implemented in
a distributed way since each player can update its own , , while keeping the current primal iterate x = ( 1, , . . . , , ) fixed; that is,

1, , +1

PX1 1, , - 1  1 L1 x , 1, , 1, , 1, + 1 1, , - 1,

...

...

u , +1 = , , +1 =

PX , , -  L x , , , , , , +

,, - ,

.

...
, , +1

...

PX

,, -  L x, ,, ,, , +

,, - ,

We also note that when the private strategy set of each player includes functional constraints ( )  0, = 1, . . . , , they are treated in the same way to handle ( , - )  0 via the P-
Lagrangian. It follows that only the set X remains as a simple constraint, and hence the projection onto X is computationally cheap.

3.3 Description of Algorithm We are ready to formally present our distributed algorithm that exploits all the features discussed. The steps of the proposed algorithm are summarized in Algorithm 1.
The main computational effort of our algorithm is involved in Step 1 to update primal variables from x to x +1. In fact, we can find a point u , +1 that satisfies the fixed-point condition PX u , +1 - L u , +1, , , ; x - u , +1  with a sufficiently small precision > 0 (see Lemma 1), which is the condition for u , +1 to be solution x to VI (X, L ). Furthermore, noting that L (x , , , , , , ; x ) = L (x , , , , , , ), we can detect a point u , +1 such that
L (u , +1, , , , , , ; x ) < L (x , , , , , , ),   N,
by evaluating the value of L (u , +1, , , , , , ; x ), and comparing it with L (x , , , , , , ) at each inner iteration while the above fixed-point condition is satisfied. Then u , +1 is set to x +1. Consequently, the decrease in the value of L x , , , , , , during x-update is obtained.

Jong Gwang Kim

11

ALGORITHM 1: P-Lagrangian based Alternating Direction Algorithm (PL-ADA)

Set = 0 and define initial variables ,0, ,0, ,0, ,0 with ,0 = Set an initial vector of step sizes 0 = ( 10, . . . , 0 ). Set parameters > 0 and > 0.
Step 1. Let iteration be fixed, and let u ,0 = x . For every = 1, . . . , , and for fixed (x , , , , , , ), compute gradient projection step for inner iteration = 0, 1, 2, . . .
while PX u , +1 - L (u , +1, , , ; x ) - u , +1 > and

,0, = 1, . . . , . , , +1 according to the following

L u , +1, , , , , , ; x - L x , , , , , ,  0 do

, , +1 = PX , , -  L x , , , , , , +

,, - , .

end while Set x +1 = u , +1 := ( 1, , +1) , . . . , ( , , +1) , . . . , ( , , +1)

, and go to Step 2.

Step 2. For = 1, . . . , , compute , +1 by an exact minimization step on L

, +1 = arg min L x +1, , , , , = , - , / .
R

Step 3. For = 1, . . . , , update ( , +1, , +1) by exact maximization steps on L

, +1 = arg max L
R+
, +1 = arg max L
R

x +1, , +1, , , x +1, , +1, , +1,

=

, +1

+
(x +1) .

= , +1.

Step 4. Set  + 1 and go to Step 1.

The next step consists of each player updating by taking a simple minimization step (Step 2) on L . This update depends on only the current iterates of the Lagrange multipliers , and
, , but is independent of the primal variables x. After the minimization steps have been carried out, given (x +1, , +1), the multipliers are updated by exact maximization steps on L . The updates of and take the explicit forms:

, +1 =

, +1

+
(x +1) ,

, +1 = , +1,

which can be viewed as a proximal point scheme. The multipliers ( , ) are always updated whenever the corresponding x = ( , - ) is updated.

4 CONVERGENCE ANALYSIS
In this section, we establish the convergence results of Algorithm 1. We prove that the sequence generated by Algorithm 1 converges to a saddle point of L ( , - , , , ) for = 1, . . . , .
In particular, our analysis proceeds with the steps: (1) We first show that for the inner iterations , the sequence u , produced by the gradient
projection step converges to the solution x of the approximation subproblem at each iteration (Lemma 1). Next, we derive an important result that , +1 - , can be bounded by x +1 - x (Lemma 2).

Jong Gwang Kim

12

(2) The above results are exploited to show that the sequence {L } is monotonically decreasing
and convergent (Lemma 3). Then we establish the key results; the boundedness of x and lim  x +1 - x = 0, followed by the boundedness of , (Theorem 3). (3) With the bounded sequences, convergence to an equilibrium of the GNEP is proven; we show that any limit point of the sequence is a saddle point of L (Theorem 4).
(4) Finally, we establish the global convergence that the whole sequence generated by the algorithm converges to a saddle point of L by assuming that the P-Langangian satisfies the
Kurdyka-Lojasiewicz (KL) property (Theorem 5).

4.1 Key Properties of Algorithm 1
We first consider the sequence u , generated by the gradient projection scheme defined in Step 1. We have the following convergence result for the subproblems at each iteration . The inner problem is decomposed into | | decoupled subproblems, which enables a distributed computation.

L

1. Let x be the unique solution to the approximation subproblem VI (X, L ) (11) at each

iteration . Then, the sequence {u , } 1 generated by Step 1 of Algorithm 1 converges to x with

geometric convergence rate. In other word, for any constant

 ( 0,

] where 0 <

<

(2

2 min

)/

max,

we have

u , +1 - x  u , - x , 0 < < 1,

(14)

where

=

1 - 2 min

+

2 max, and

min =

min
=1,...,

and

max =

max
=1,...,

.

> 0 is the parameter

of proximal term 2 x - x 2 in L and > 0 is the Lipschitz constant of xL , respectively.

P . See Appendix B.1.

The above result, together with the fact that L (x , , , , , , ; x ) = L (x , , , , , , ), implies that at iteration , we can find a point u , +1 such that both conditions
PX , , +1 - L (u , +1, , , ; x ) - , , +1 
and L (u , +1, , , , , , ; x ) < L (x , , , , , , )
are satisfied for all = 1, . . . , in a finite number of inner iterations + 1. Then we can set x +1 = u , +1. Hence, we can have the decrease property of L x , , , , , , during x update.
Remark 2. For the choice of the parameter  , where is the Lipschitz constant of xL , the value of L is nonincreasing during x -update. Indeed, the following relations hold:
L (x +1, , , , , , )  L (x +1, , , , , , ; x )  L (x , , , , , , ; x ) = L (x , , , , , , ).
We next show that the sequence {L } can be a nonincreasing sequence. To this end, we first derive an important relation on the dual iterates , and , with the primal iterates x that the difference of two consecutive iterates of the multipliers can be bounded by that of the primal iterates.

Jong Gwang Kim

13

L

2. Let ( , , , , , , , ) =1 be the sequence generated by Algorithm 1. Then,

, +1 -

,

2


2 2

x +1 - x

2
,

(15)

where is the Lipschitz constant of and > 0 is the parameter of - 2 P . See Appendix B.2

- 2 in L .

Equipped with Lemmas 1 and 2, we prove that the sequence of function values {L } can be monotonically decreasing and convergent.

L 3 (S

D

C

{L }). Suppose that Assumptions 1 and

2 hold. Let we have

, , , , , , , =1 be the sequence generated by Algorithm 1. Then for = 1, . . . , ,

L

x +1, , +1, , +1, , +1  L

x,

,,

,,

,

-

1 2

32 --

x +1 - x

2
,

where =  +  is the Lipschitz gradient constant of L , > 0 is the parameter of proximal term 2 x - x 2 in L , and > 0 is the parameter of quadratic term - 2 - 2 in L . In
32
particular, if is chosen such that  + , then the sequence {L } is nonincreasing and
convergent.

P . See Appendix B.3

Next, we provide our key results that the generated sequence is bounded and asymptotic regular. The boundedness of the sequence follows by combining the above decrease property of the PLagrangian with the coercivity assumption on the only objective functions (Assumption 3).

T

3. Assume that there exists a GNE of the GNEP (1) satisfying the KKT conditions (3) for

every = 1, . . . , . Let , , , , , , ,

be the sequence generated by Algorithm 1 with the

=1

32

parameters set to  0 large enough so that  + . Then,

(a) the primal sequence x is bounded;

(b) the sequence of the multiplier , is bounded;

(c) it holds that

 =1

x +1 - x

2 <  and

 =1

, +1 -

, 2 < , and hence

lim x +1 - x = 0, lim , +1 - , = 0, and lim , +1 - , = 0. (16)







P . See Appendix B.4

4.2 Main Convergence Results
We are ready to establish our main convergence results. We first show that any limit point of the sequence produced by Algorithm 1 is a saddle point of L .

T

4 (S

C

). Let ( , , , , , , , ) =1 be the sequence gener-

ated by Algorithm 1. Then, the sequence , , , , , , , =1 converges to a limit point (x, , , ) that satisfies the saddle point condition (8).

P . See Appendix B.4

Jong Gwang Kim

14

We now strengthen the above subsequence convergence result, under an additional assumption that the functions satisfy the Kurdyka-Lojasiewicz (KL) property (see Lojasiewicz [34] and Kurdyka [31]): The KL property, along with the sufficient decrease of the P-Lagrangian and the boundedness of generated sequence, enables us to establish global convergence of the whole sequence
( , , , , , , , ) =1 to a saddle-point of L by showing that the sequence has finite length.
Definition 4 (KL Property & KL function). Let  (0, +]. Denote by  the class of all concave and continuous functions : [0, )  R+, which satisfy the following conditions:
(i) (0) = 0; (ii) is continuously differentiable ( 1) on [0, ) and continuous at 0; (iii) for all  (0, ) :  > 0.
A proper and lower semicontinuous function  : R  (-, +] is said to have the KurdykaLojasiewicz (KL) property at  dom  := {  R : ( ) = } if there exist  (0, +], a neighborhood of and a function   , such that
(( ) - ( )) · dist(0, ( ))  1
for all  ( )  { : ( ) < ( ) < ( ) + }. The function  satisfying the KL property at each point of dom  is called a KL function.

T

5 (G

C

). Suppose that and , = 1, . . . , , satisfy the KL prop-

erty. Let w , := (x , , , , , , ) =1 be the sequence generated by Algorithm 1. Then the sequence w , = (x , , , , , , ) =1 has finite length, i.e.,


w , +1 - w , < +,

=1

and the whole sequence ( , , , , , , , ) =1 converges to a saddle point (x, , , ) of L .

P . See Appendix C.1

We note that verifying the KL property of a function might be a difficult task. However, it is well-known that semi-algebraic and real-analytic functions, which capture many applications, are classes of functions that satisfy the KL property; see e.g., [4­6, 33, 49] for an in-depth study of the KL functions and illustrating examples.

5 COMPUTATIONAL RESULTS

In this section, we present computational results to demonstrate the effectiveness of the proposed
method. We conducted numerical experiments on test problems using Algorithm 1. The exper-
iments were carried out using MATLAB (R2018a) on a laptop with a Intel Core i5-6300U CPU
2.50GHz 8GB RAM. All the test problems were taken from a library of GNEPs used in the liter-
ature [19, 23, 28], and two classes of instances were considered; general GNEPs (A.1-A.10) and
jointly-convex GNEPs (A.11-A.18). We refer the readers to [21] for a detailed description of the
problems with data. In the numerical test, we used the starting points listed in [23], and the other variables' initial
points were set to ,0, ,0, ,0 = (0, 0, 0) for every = 1, . . . , . As for the parameters, we used fixed parameters set to = 10 and = 1 for each player's P-Lagrangian and for all test problems. In addition, diminishing step size was simply used for every player in each problem. The stopping criterion is set as

max
=1,...,

, +1 - , , , +1 - ,

 10-4.





Jong Gwang Kim

15

The computational results of our algorithm for the test problems are presented in Table 1, where we used the following notations; the number of players ` ', the number of variables ` ', the number of constraints ` ', starting point `x0', total (cumulative) number of inner iterations ` .', and
computation time of CPU seconds `Time(s)'. We summarize the computational results in the following:

(1) Algorithm 1 was able to solve all the test problems. The experimental results show that

Algorithm 1 comes out favorably in terms of the number of problems solved compared to

the other methods. In particular, the exact penalty algorithm in [23] was unable to find

solutions to the problems A.2, A.7, and A.8. In addition, the interior-point algorithm in [19]

and the augmented Lagrangian method in [28] were unable to find a GNE of the instance A.8 with starting points x0 = 10 and x0 = 0, respectively. On the other hand, Algorithm 1

converges to a GNE for the three problems A.2, A.7, and A.8, starting from those points.

(2) It is interesting to note that Algorithm 1 converges to the same GNE from different starting

points in each problem, while the exact penalty algorithm [23] converges to different equilib-

ria or generates unbounded sequences in some cases. This difference is because each player's

problem is convex in its own variables, and each player solves strongly convex subproblems

while keeping the other players' variables fixed. On the other hand, the exact penalty al-

gorithm [23] solves nondifferentiable (possible nonconvex) subproblems. This, along with

sensitivity to the penalty parameters and starting points, may lead to the convergence to

different equilibria or failure of convergence.

(3) Our distributed algorithm required very short CPU times to reach equilibrium for all test

instances. The results confirm the efficiency of our algorithm that the computation time per

iteration to solve each subproblem is significantly short for every instance. This advantage

is mainly due to the Jacobi decomposition scheme for the x-update with the cheap projection

onto the simple set X .

(4) For Arrow-Debreu equilibrium problems A.10 (a-e), it is noteworthy that our problem setting

is different from test problems in [21]. In our setting, the production variables are added to

the constraints of consumers' problems, that is



+ =1

, whereas the

constraints were set to  in the test setting in [21]. This reflects the original Arrow-

Debreu model better and computational results have shown that Algorithm 1 performs well

on the modified instances.

(5) The performance of Algorithm 1 can be improved with different choice of the step size for

updating the Lagrange multipliers. Specifically, the number of iterations required for the

convergence depends on the choice of the parameter . We can reduce the number of iter-

ations using line search methods for the step size 1/ to maximize L .

Jong Gwang Kim

16

Table 1. Computational results for Algorithm 1.

general GNEP

x0

. Time (s)

A.1

10 10 20 0.01 38 < 0.01

0.1 36 < 0.01

1 38 < 0.01

A.2

10 10 24 0.01 610 0.04

0.1 536 0.04

1 683 0.05

A.3

3 7 18 0 51 0.01

1 51 0.01

10 51 0.01

A.4

3 7 18 0 7 < 0.01

1 7 < 0.01

10 7 < 0.01

A.5

3 7 18 0 82 0.02

1 82 0.02

10 82 0.02

A.6

3 7 21 0 49 0.02

1 49 0.02

10 49 0.02

A.7

4 20 44 0 48 0.02

1 48 0.02

10 48 0.02

A.8

3 3 8 0 45 < 0.01

1 45 < 0.01

10 45 < 0.01

A.9 (a)

7 56 63 0 108 0.32

A.9 (b)

7 112 119 0 135 1.24

A.10 (a)

8 24 33 0 780 0.10

A.10 (b)

25 125 151 1 1374 0.67

A.10 (c)

37 222 260 0 2154 1.12

A.10 (d)

37 370 408 1 3251 1.35

A.10 (e)

48 576 625 1 4728 2.54

jointly-convex GNEP

x0

. Time (s)

A.11

2 2 2 0 12 < 0.01

A.12

2 2 4 (2,0) 10 < 0.01

A.13

3 3 9 0 15 < 0.01

A.14

10 10 20 0.01 38 < 0.01

A.15

3 6 12 0 145 < 0.01

A.16 (P=75)

5 5 10 10 52 0.02

A.16 (P=100)

5 5 10 10 52 0.02

A.16 (P=150)

5 5 10 10 52 0.02

A.16 (P=200)

5 5 10 10 52 0.02

A.17

2 3 7 0 9 < 0.01

A.18

2 12 28 0 114 0.02

Illustrative Examples
To see how well Algorithm 1 performs on GNEPs, we provide numerical results for three important and practical instances with graphical illustrations.

Jong Gwang Kim

17

Problem A.9 (a) (Example 1 revisited, Power allocation in telecommunications)
This instance sets = 0.3162 for all and , = 8, = 8 for all players, and the starting point was set to (0, . . . , 0). The data of coefficient  is given in [21]. As shown in Figure 1, the
P-Lagrangian function values L , = 1, . . . , 7, are monotonically decreasing and convergent,
as expected, and the iterates of , = 1, 3, 5, converge to a limit point satisfying the minimum target rate of 8.
Clearly, the computation time crucially depends on how the subproblems are solved efficiently. It is noteworthy that since the nonlinear coupling constraints are relaxed into the objective with the multipliers, the projection on the set X = {  R |  0} can be performed efficiently that lead to the convergence to a GNE within significantly short CPU time of 0.32 seconds.

Lagrangian function values

100

L1

90

L2

80

L3

L4

70

L5

60

L6

L7

50

40

30

20

10

0

1

2

3

4

5

6

7

8

Iteration k

(a) L values, = 1, . . . , 7.

rate trajectories

2

2

x31

x32

x33

x34

2

1.8

x11

x12

x13

x14

1.8

x35

x36

x37

x38

1.8

x51

x52

x53

x54

x15

x16

x17

x18

x55

x56

x57

x58

1.6

1.6

1.6

1.4

1.4

1.4

rate trajectories

rate trajectories

1.2

1.2

1.2

1

1

1

0.8

0.8

0.8

0.6

0.6

0.6

0.4

0.4

0.4

0.2

0.2

0.2

0

1

2

3

4

5

6

7

8

Iteration k

0

1

2

3

4

5

6

7

8

Iteration k

0

1

2

3

4

5

6

7

8

Iteration k

9

8

7

Information rate of x1 (log(SIR1(x)))

Target rate=8

6

5

4

3

2

1

0

1

2

3

4

5

6

7

8

Iteration k

(b) Link 1 1

9

8

7

Information rate of x3 (log(SIR3(x)))

Target rate=8

6

5

4

3

2

1

0

1

2

3

4

5

6

7

8

Iteration k

(c) Link 3 3

9

8

Information rate of x5 (log(SIR5(x)))

7

Target rate=8

6

5

4

3

2

1

0

1

2

3

4

5

6

7

8

Iteration k

(d) Link 5 5

Fig. 1. Trajectories of the P-Lagrangian values and variables 1, 3, and 5, = 1, . . . , 8, with information sum-rates.

Jong Gwang Kim

18

Problem A.10 (a) (Example 2 revisited, Arrow-Debreu general equilibrium model)

In this example, there are 8 players ( = 5, = 2 and one market player) and 3 goods ( = 3).

The utility functions

are quadratic and concave,

(

)

=

-

1 2

(

)

+ ( ) , and -th firm's

production set is defined by =

 0, =1( )2  10  . The detailed data is given in [21].

The convergence results are shown in Figures 2 and 3. We see that the numerical results on this

example also verifies our theoretical findings. Starting point is set to ,0 = 0, ,0 = 0, and 0 =

(1/3, 1/3, 1/3). Figure 2 demonstrates that all players' P-Langrangian values are decreasing and

convergent to finite values. It can be also seen in Figure 3 that the iterates generated by Algorithm

1 converge to the equilibrium price vector = (0.1441, 0.5270, 0.3289) that clears market as well

as to the equilibrium productions and consumptions.

Market player`s Lagrangian values

25

0

LP

20

-0.5

15

-1

10

-1.5

5

-2

0

-2.5

-5

-3

0

5

10

15

0

Iteration k

Firms` Lagrangian values

5

10

Iteration k

0

L1F

L2F

-100

-200

-300

-400

-500

-600

15

0

Consumer`s Lagrangian values

L1C

L2C

L3C

L4C

L5C

5

10

15

Iteration k

Fig. 2. Convergence of all players' P-Lagrangian values.

Price

0.6

3

0.5

p1

2.5

p2

0.4

p3

2

0.3

1.5

Production

0.2

1

0.1

0.5

0

0

5

10

Iteration k

(a) Market player

0

15

0

7

7

6

6

consumptions

5

5

4

x11

4

x12

3

x13

3

2

2

1

1

0

0

0

5

10

15

0

Iteration k

(d) Consumer 1

5

10

Iteration k

(b) Firm 1

5

10

Iteration k

(e) Consumer 3

y11 y12 y13
15

Production

4 3.5
3 2.5
2 1.5
1 0.5
0 0

7

6

5

consumptions

x31

4

x32

3

x33 2

1

0

15

0

y21 y22 y23

5

10

15

Iteration k

(c) Firm 2

x51 x52 x53

5

10

15

Iteration k

(f) Consumer 5

Fig. 3. The sequence of decision variables of each player.

consumptions

Jong Gwang Kim

19

Problem A.18 (Electricity market model).

This electricity market model originally proposed by [40], and further discussed in [36]. There are two companies. Each company has an electricity plant in two out of three possible regions which are represented by the nodes of a graph. The goal is to maximize the profit of the company. The model has 18 variables, but we only present the reduced formulation with 12 variables. The reduction comes from the fact that both companies have plants on only 2 of the 3 nodes. We use the following abbreviations:

1

= 40 -

40 500

(

1+

4+ 7+

10) ,

2

= 35 -

35 400

(

2+

5 + 8 + 11) ,

3 = 32 -

32 600

(

3+

6+

9 + 12) .

Player 1 has 6 variables ( 1, . . . , 6) = ( 11, . . . , 61) and minimizes the objective function

1 ( ) = (15 - 1) ( 1 + 4) + (15 - 2) ( 2 + 5) + (15 - 3) ( 3 + 6) ,

and player 1 has the nonnegativity constraints, 1, . . . , 6  0, capacity constraints

1 + 2 + 3  100, 4 + 5 + 6  50,

and coupling constraints -  1,  , = 1, 2, 3 with  . Player 2 has 6 variables ( 7, . . . , 12) = ( 12, . . . , 62) and minimizes its objective
2 ( ) = (15 - 1) ( 7 + 10) + (15 - 2) ( 8 + 11) + (15 - 3) ( 9 + 12) ,

and the nonnegativity constraints, 7, . . . , 12  0, capacity constraints

7 + 8 + 9  100, 10 + 11 + 12  50,

and coupling constraints -  1,  , = 1, 2, 3 with  . We only report numerical results for player 1 since player 2 has the same results. Figure 4 shows
that company 1's P-Lagrangian is convergent, and Algorithm 1 converges to a saddle-point that is a Nash equilibrium.

-1961 -1962

Lagrangian value L1

-1963

-1964

-1965

-1966

-1967

1

2

3

4

5

6

Iteration k

45.7
45.6
45.5 1
28.05 28.045
28.04
1
26.4 26.3 26.2
1
29 28.9 28.8
1 11.39
11.385
11.38 1
9.8 9.7 9.6
1

Player 1`s variables, x1i , i=1,...,6.

2

3

4

5

2

3

4

5

2

3

4

5

2

3

4

5

2

3

4

5

2

3

4

5

Iteration k

x

1 1

6

x

1 2

6

x

1 3

6

x

1 4

x

1 5

6

x

1 6

6

Fig. 4. x1,0 = 0 converges to x1, = (45.4976, 28.0478, 26.4547, 28.8309, 11.3811, 9.7880).

6 CONCLUSIONS
In this paper, we proposed a novel algorithmic framework for computing an equilibrium of generalized continuous Nash games (GNEPs) with theoretical guarantees based on the Proximal-Perturbed Lagrangian function. We have shown that the proposed method has significant advantages over existing approaches in both theoretical and computational perspectives; it does not require any boundedness assumptions and is the first development of an algorithm to solve general GNEPs in

Jong Gwang Kim

20

a distributed manner. The numerical results supported our theoretical findings. Possible future research is to extend our methodology to compute equilibria in stochastic Nash games with coupling constraints, which will result in a broader application domain.
ACKNOWLEDGMENTS
The author would like to express his deep gratitude to John Birge for numerous insightful discussions and thoughtful suggestions on this work. The author would also like to thank the three anonymous reviewers for their valuable comments and suggestions that helped improve the paper.
REFERENCES
[1] Roberto Andreani, Ernesto G Birgin, José Mario Martínez, and María Laura Schuverdt. 2007. On augmented Lagrangian methods with general lower-level constraints. SIAM Journal on Optimization 18, 4 (2007), 1286­1309.
[2] Roberto Andreani, Ernesto G Birgin, José Mario Martínez, and Maria Laura Schuverdt. 2008. Augmented Lagrangian methods under the constant positive linear dependence constraint qualification. Mathematical Programming 111, 1-2 (2008), 5­32.
[3] Kenneth J Arrow and Gerard Debreu. 1954. Existence of an equilibrium for a competitive economy. Econometrica 22 (1954), 265­290.
[4] Hedy Attouch and Jérôme Bolte. 2009. On the convergence of the proximal algorithm for nonsmooth functions involving analytic features. Mathematical Programming 116, 1-2 (2009), 5­16.
[5] Hédy Attouch, Jérôme Bolte, Patrick Redont, and Antoine Soubeyran. 2010. Proximal alternating minimization and projection methods for nonconvex problems: An approach based on the Kurdyka-Lojasiewicz inequality. Mathematics of Operations Research 35, 2 (2010), 438­457.
[6] Hedy Attouch, Jérôme Bolte, and Benar Fux Svaiter. 2013. Convergence of descent methods for semi-algebraic and tame problems: proximal algorithms, forward­backward splitting, and regularized Gauss­Seidel methods. Mathematical Programming 137, 1-2 (2013), 91­129.
[7] Amir Beck and Marc Teboulle. 2009. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM Journal on Imaging Sciences 2, 1 (2009), 183­202.
[8] Dimitri P Bertsekas. 1999. Nonlinear programming. Athena scientific Belmont. [9] Dimitri P. Bertsekas. 2014. Constrained optimization and Lagrange multiplier methods. Academic press. [10] Dimitri P. Bertsekas and John N Tsitsiklis. 1989. Parallel and distributed computation: numerical methods. Vol. 23.
Prentice hall Englewood Cliffs, NJ. [11] Jérôme Bolte, Shoham Sabach, and Marc Teboulle. 2014. Proximal alternating linearized minimization or nonconvex
and nonsmooth problems. Mathematical Programming 146, 1-2 (2014), 459­494. [12] Radu Ioan Bo, Erno Robert Csetnek, and Dang-Khoa Nguyen. 2019. A proximal minimization algorithm for structured
nonconvex and nonsmooth problems. SIAM Journal on Optimization 29, 2 (2019), 1300­1328. [13] Radu Ioan Bo and Dang-Khoa Nguyen. 2020. The proximal alternating direction method of multipliers in the non-
convex setting: convergence analysis and rates. Mathematics of Operations Research (2020). [14] Michele Breton, Georges Zaccour, and Mehdi Zahaf. 2006. A game-theoretic formulation of joint implementation of
environmental projects. European Journal of Operational Research 168, 1 (2006), 221­239. [15] Valeria Cardellini, Vittoria De Nitto Personé, Valerio Di Valerio, Francisco Facchinei, Vincenzo Grassi, Francesco Lo
Presti, and Veronica Piccialli. 2016. A game-theoretic approach to computation offloading in mobile cloud computing. Mathematical Programming 157, 2 (2016), 421­449. [16] William Chung and J David Fuller. 2010. Subproblem approximation in Dantzig-Wolfe decomposition of variational inequality models with an application to a multicommodity economic equilibrium model. Operations Research 58, 5 (2010), 1318­1327. [17] Javier Contreras, Matthias Klusch, and Jacek B Krawczyk. 2004. Numerical solutions to Nash-Cournot equilibria in coupled constraint electricity markets. IEEE Transactions on Power Systems 19, 1 (2004), 195­206. [18] Gerard Debreu. 1952. A social equilibrium existence theorem. Proceedings of the National Academy of Sciences 38, 10 (1952), 886­893. [19] Axel Dreves, Francisco Facchinei, Christian Kanzow, and Simone Sagratella. 2011. On the solution of the KKT conditions of generalized Nash equilibrium problems. SIAM Journal on Optimization 21, 3 (2011), 1082­1108. [20] Francisco Facchinei, Andreas Fischer, and Veronica Piccialli. 2007. On generalized Nash games and variational inequalities. Operations Research Letters 35, 2 (2007), 159­164. [21] Francisco Facchinei and Christian Kanzow. 2009. Penalty methods for the solution of generalized Nash equilibrium problems (with complete test problems). Sapienza University of Rome (2009).

Jong Gwang Kim

21

[22] Francisco Facchinei and Christian Kanzow. 2010. Generalized Nash equilibrium problems. Annals of Operations Research 175, 1 (2010), 177­211.
[23] Francisco Facchinei and Christian Kanzow. 2010. Penalty methods for the solution of generalized Nash equilibrium problems. SIAM Journal on Optimization 20, 5 (2010), 2228­2253.
[24] Francisco Facchinei and Jong-Shi Pang. 2007. Finite-dimensional variational inequalities and complementarity problems. Springer Science & Business Media.
[25] Benjamin F Hobbs and Jong-Shi Pang. 2007. Nash-Cournot equilibria in electric power markets with piecewise linear demand functions and joint constraints. Operations Research 55, 1 (2007), 113­127.
[26] Wei Jing-Yuan and Yves Smeers. 1999. Spatial oligopolistic electricity models with Cournot generators and regulated transmission prices. Operations Research 47, 1 (1999), 102­112.
[27] Alejandro Jofré, R Terry Rockafellar, and Roger JB Wets. 2007. Variational inequalities and economic equilibrium. Mathematics of Operations Research 32, 1 (2007), 32­50.
[28] Christian Kanzow and Daniel Steck. 2016. Augmented Lagrangian methods for the solution of generalized Nash equilibrium problems. SIAM Journal on Optimization 26, 4 (2016), 2034­2058.
[29] Jacek B Krawczyk and Stanislav Uryasev. 2000. Relaxation algorithms to find Nash equilibria with economic applications. Environmental Modeling & Assessment 5, 1 (2000), 63­73.
[30] Ankur A Kulkarni and Uday V Shanbhag. 2012. On the variational equilibrium as a refinement of the generalized Nash equilibrium. Automatica 48, 1 (2012), 45­55.
[31] Krzysztof Kurdyka. 1998. On gradients of functions definable in o-minimal structures. In Annales de l'institut Fourier, Vol. 48. 769­783.
[32] Guoyin Li and Ting Kei Pong. 2015. Global convergence of splitting methods for nonconvex composite optimization. SIAM Journal on Optimization 25, 4 (2015), 2434­2460.
[33] Guoyin Li and Ting Kei Pong. 2018. Calculus of the exponent of Kurdyka­Lojasiewicz inequality and its applications to linear convergence of first-order methods. Foundations of computational mathematics 18, 5 (2018), 1199­1232.
[34] Stanislaw Lojasiewicz. 1963. Une propriété topologique des sous-ensembles analytiques réels. Les équations aux dérivées partielles 117 (1963), 87­89.
[35] Juan Pablo Luna, Claudia Sagastizábal, and Mikhail Solodov. 2014. A class of Dantzig­Wolfe type decomposition methods for variational inequality problems. Mathematical Programming 143, 1-2 (2014), 177­209.
[36] Koichi Nabetani, Paul Tseng, and Masao Fukushima. 2011. Parametrized variational inequality approaches to generalized Nash equilibrium problems with shared constraints. Computational Optimization and Applications 48, 3 (2011), 423­452.
[37] John F Nash et al. 1950. Equilibrium points in n-person games. Proceedings of the national academy of sciences 36, 1 (1950), 48­49.
[38] Angelia Nedic, Asuman Ozdaglar, and Pablo A Parrilo. 2010. Constrained consensus and optimization in multi-agent networks. IEEE Trans. Automat. Control 55, 4 (2010), 922­938.
[39] Yurii Nesterov. 2012. Efficiency of coordinate descent methods on huge-scale optimization problems. SIAM Journal on Optimization 22, 2 (2012), 341­362.
[40] Jong-Shi Pang and Masao Fukushima. 2005. Quasi-variational inequalities, generalized Nash equilibria, and multileader-follower games. Computational Management Science 2, 1 (2005), 21­56.
[41] Jong-Shi Pang, Gesualdo Scutari, Francisco Facchinei, and Chaoxiong Wang. 2008. Distributed power allocation with rate constraints in Gaussian parallel interference channels. IEEE Transactions on Information Theory 54, 8 (2008), 3471­3489.
[42] Meisam Razaviyayn, Mingyi Hong, and Zhi-Quan Luo. 2013. A unified convergence analysis of block successive minimization methods for nonsmooth optimization. SIAM Journal on Optimization 23, 2 (2013), 1126­1153.
[43] J Ben Rosen. 1965. Existence and uniqueness of equilibrium points for concave n-person games. Econometrica 33 (1965), 520­534.
[44] Gesualdo Scutari, Francisco Facchinei, Peiran Song, Daniel P Palomar, and Jong-Shi Pang. 2014. Decomposition by partial linearization: Parallel optimization of multi-agent systems. IEEE Transactions on Signal Processing 62, 3 (2014), 641­656.
[45] Oliver Stein and Nathan Sudermann-Merx. 2018. The noncooperative transportation problem and linear generalized Nash games. European Journal of Operational Research 266, 2 (2018), 543­553.
[46] Stanislav Uryas'ev and Reuven Y Rubinstein. 1994. On relaxation algorithms in computation of noncooperative equilibria. IEEE Trans. Automat. Control 39, 6 (1994), 1263­1267.
[47] Anna Von Heusinger and Christian Kanzow. 2009. Optimization reformulations of the generalized Nash equilibrium problem using Nikaido-Isoda-type functions. Computational Optimization and Applications 43, 3 (2009), 353­377.
[48] Anna Von Heusinger and Christian Kanzow. 2009. Relaxation methods for generalized Nash equilibrium problems with inexact line search. Journal of Optimization Theory and Applications 143, 1 (2009), 159­183.

Jong Gwang Kim

22

[49] Yangyang Xu and Wotao Yin. 2013. A block coordinate descent method for regularized multiconvex optimization with applications to nonnegative tensor factorization and completion. SIAM Journal on Imaging Sciences 6, 3 (2013), 1758­1789.
[50] Huibing Yin, Uday V Shanbhag, and Prashant G Mehta. 2011. Nash equilibrium problems with scaled congestion costs and shared constraints. IEEE Trans. Automat. Control 56, 7 (2011), 1702­1708.

APPENDIX

A PROOFS OF THEOREMS IN SECTION 2
Before studying the relation between a saddle point of the P-Lagrangian (6) and an equilibrium of the GNEP (5), let us observe the following properties of L ( , - , , , ).

Observation 1. Notice that the inner minimization in (7) can be split into two parts as follows:

max { min

R+ , R

X

,- +

, - + min -
R

-

+2

= (,,)

2- 2

Denote by , ( , ) as a unique solution of the problem, min - ( - )
R

+2

for given ( , ). The minimization of ( , , ) with respect to gives

, ( , ) = -

= 

( , , )=( - )+

, = 0 .

- 2 }.
2

Recall that based on the above optimality condition for , we can add a quadratic (regularization)

term and

-2

-

( fixed

2 to make the Lagrangian strongly concave ) since it vanishes at the unique solution , =

in the multipliers 0. Substituting ,

(

(fixed ) , ) into

L ( , - , , , ), L reduces to

L

, - , , , , , =

,- +

,-

-

1

+ 2

- 2 . (17)

Then the P-Lagrangian dual problem can be expressed as

max

D

,

R+ , R

0

-

1

+ 2

- 2,

(18)

where

0(

) = min
X

( , - )+( )

( , - ) , which is identical to the standard dual

function associated with the original problem (1). Thus the P-Lagrangian dual function D ( , )

is maximized jointly in and , if and only if maximizes 0 ( ) and = . This implies that the multiplier , for the constraint ( , - ) -  0 in extended problem (5) is precisely to the multiplier , for the constraint ( , - )  0 in problem (1).

Observation 2. If we maximizing L ( , - , , , ) with respect to , we get

L

, -, , , = +

- , = 0,

which together with the fact , = , implies that = 0 for maximizers ( ,, ,) and > 0.

Using the Observations 1 and 2, we now establish the equivalence between a saddle point of L and an equilibrium of the GNEP (1).

Jong Gwang Kim

23

A.1 Proof of Theorem 1

P . Using the reduced form of P-Lagrangian (17), we have

L x, , , , , = x +

x

-

1

+ 2

-2

(19)

 L x, , ,, , , ,, , .

First, we prove that x = ( ,, - ,) is feasible for problem (1). Suppose by contradiction that x

is infeasible, i.e., (x) > 0 for some . Then there exist some such that

(x)   as

 . This implies L (x, ,, , )   if taking the limit as   with = to

maximize the left-hand side of the first inequality in (19), which is a contradiction with the first inequality in (8). Therefore (x)  0 for all = 1, . . . , . By the definition L (x, ,, ,, ,) =

sup 0, L (x, ,, , ) with the fact that (x)  0 and ,  0, we have ( ,) (x) = 0 and , = ,. It follows that

L x, ,, ,, , = x .

Next, let  ( - ,) be any feasible solution to problem (1). For any feasible and  0, since ( , - ,)  0, we have

,

- ,

-

1

+ 2

- 2

·

0

-

1

+ 2

- 2  0.

(20)

From Observation 2 that = 0 when , = , for any > 0, we have

- , - ,

+2

2 = 0.

(21)

The second inequality of the saddle point condition (8) yields

x  L

, - ,, , ,, ,

=

, - , + ,

, - , - 2

, - , 2 - , - ,

+2

2

0

=0



, - , ,

where the last inequality is from (20) and (21). Hence, x = ( ,, - ,) is a GNE of problem (1).

A.2 Proof of Theorem 2

P . First, we show that the first inequality in (9) holds. From the feasibility of an equilibrium

x, we have for any  R+ ,  R and , > 0

x

-

1+ 2

- 2  0,

(22)

implying that

(x) + ( )

(x)

-

1

+ 2

- 2 = L (x, , ( , ), , )  (x).

On the other hand, since there exists a pair of multipliers ( ,, ,) maximizing L (x, ,, , ),

we also have for = = 0

L x, , (0, 0) , 0, 0  L x, ,, ,, , = x + ,

x

-

1

+ 2

which together with the fact that L (x, , (0, 0) , 0, 0) = (x) gives

, - , 2 ,

,

x

1+ -2

, - , 2  0.

(23)

Jong Gwang Kim

24

Combining (22) and (23), we obtain

,

x

-

1

+ 2

, - , 2 = 0.

It thus follows that

L x, ,, ,, , = x .

Hence, the first inequality in (9) holds. Furthermore, by using the fact that (x)  0 and ,  0

with (23), we have that 0  ( ,)

(x)



1+ 2

, satisfies the complementarity slackness ( ,)

, - , 2  0, which implies the multiplier ( ,, - ,) = 0 and , = ,. Thus the

maximizer , is equivalent to the Lagrange multiplier , satisfying the KKT conditions (3) for

the original GNEP (1).

Next, we show that L (x, ,, ,, ,)  L ( , - ,, , ,, ,) in (9) holds. Noticing

that  ( , ,, ,) = - ( , - ,) + , = 0 and , = ,, we have a unique minimizer

, = 0 for some > 0. From the convexity ( , - ,) and ( , - ,) in , we have

( , - ,)  ( , - ,) 

(x) +  (x) + 

(x) ( - ,) , (x) ( - ,) .

Then we have

L

, - ,, , ,, ,  x + ,

x + 

x +

, 

x

=1

- , - ,

+2

2- 2

, - , 2

 x + ,

x + 2

2

 x = L (x, , = 0, ,, ,).

Hence, (x, , = 0) satisfies the second inequality of (9).

- ,

B PROOFS OF KEY RESULTS IN SECTION 4
Note first that the conditions (2a) and (2b) in Assumption 2 imply that there exist  and  such that

x (x1) - x (x2)   x1 - x2 , x1, x2  X, x (x1) - x (x2)   x1 - x2 , x1, x2  X,

(24a) (24b)

where x and x represent  1 , . . . , 

and  1 , . . . , 

, respectively.

Note that  = =1 ( ) and  = =1 ( ) (see Nesterov [39, Lemma 2]). Furthermore, (2a)­(2d) in Assumption 2 imply that there exist constants  and  such that

 (x1) -  (x2)   x1 - x2 , x1, x2  X,  (x1) -  (x2)   x1 - x2 , x1, x2  X,

(24c) (24d)

where  = ( ) + - ( ) and  = ( ) + - ( ). We need to recall the well-known descent lemma, which is a direct consequence of the uniform
Lipschitz gradient property of the functions (24a) and (24b).

L

B.1 ([8, P

A.24]). Let Assumptions 1 and 2 hold. Then, for = 1, . . . , and for

any fixed ( , , ), the gradient of L is Lipschitz continuous with constant =  +  > 0.

Jong Gwang Kim

25

We thus have
L (x1)  L (x2) + xL (x2) (x1 - x2) + 2 x1 - x2 2 , x1, x2  X. Here, we omit fixed ( , , ) for notational simplicity.

B.1 Proof of Lemma 1
P . Fix  0, and omit the iterates , , , , , for simplicity in the proof. Recall that since the subproblem VI (X, L ) is strongly monotone, there exists a unique solution x . Let , be th component of x . From the fixed-point characterization of ,

, = PX , -  L x , , , , , , , ; x

and the contraction property of projection operator PX [·], we have for all = 1, . . . ,

, , +1 -

,

2
=

PX

, , -  L u , ;x - , 2

= PX

, , -  L u , ; x - PX

, -  L x ;x

2
(26)



,, -  L

u , ;x - , -  L

x ;x

2
.

By expanding the last term on the right, the above inequality can be rewritten as

, , +1 -

,

2


,, -

,

2
-2

 L (u , ; x ) -  L

+ 2

L

(u , ; x ) - 

L

2
(x ; x ) .

(x ; x )

,, - , (27)

Since L is strongly convex in x = ( , - ) with constant and xL is Lipschitz continuous

with constant (see properties (P2) and (P3) in Remark 1), we can estimate the second term and third term on right-hand side of (27)

 L u , ;x - L x ;x

,, - , 

,, -

,

2
,

(28)

 L u , ;x - L x ;x 

,, - , .

(29)

Note that since L is a proximal linearized function with the quadratic term 2 x - x 2, we can take = . Substituting (28) with = and (29) into (27) yields

, , +1 -

,

2


1-2

+ 22

,, -

,

2
.

Notice that 1 - 2 + 2 2 > 0 is satisfied since  . Now, setting := for all =

1, . . . , and observing that 1 - 2

+ 22



1 - 2 min

+

2

2 max

, where

min =

min
=1,...,

and

max =

max
=1,...,

, it immediately follows that

, , +1 -

,

2


1 - 2 min

+

22 max

,, -

,

2
.

Thus, for 0 <

<

2

2 min

/

max implying that

1 - 2 min

+

22 max

< 1, we obtain

, , +1 - , 

, , - , , 0 < < 1,

(30)

Jong Gwang Kim

26

where = 1 - 2 min + 2 m2 ax. Therefore, by summing over the above inequality for all players from = 1 to , we deduce the desired result (14).

B.2 Proof of Lemma 2 P . Note that since L is strongly concave in for fixed (x, , ), there exists a unique
maximizer, denoted by (x, , ), such that L (x, , (x, , ), ) = max R+ L (x, , , ) . From the update of , defined (as maximizer) in Step 3, we have

 L x +1, , +1, , +1, ,

, - , +1  0,

 L x , , , , , , -1

, +1 - ,  0.

By the definition , +1 = , - , in Step 2 with , +1 = , +1 in Step 3, we have , +1 = , = 0
for the same starting point ,0 = ,0. Adding the above inequalities and a direct computation of  L give

 L x +1, , +1, , +1, , -  L x , , , , , , -1

, - , +1

=

x +1 - x -

, +1 - , +

, - , -1

=

x +1 - x

, - , +1 +

, +1 -

,

2
+

, - , +1 , - , -1

, - , +1  0,

 , +1- , 2

(31)

where, to bound the third term, we used Lemma 1(a) in Nedic et al. [38]; ( - ) ( - [ ]) 

[ ] - 2 with = , , = , -1, [ ] = , +1, and the fact , = , . Specifically, since

, +1 maximizes L (x +1, , +1, , , ) = (x +1) + ( ) (x +1) - 2

-

,

2
, we have

(x +1) + and , +1

, +1


(x +1) - 2

, +1 - , 2

(x +1) + (x +1, +1, , )

(x +1) - 2

(x +1,

+1,

, )-

,

2
,

(x +1) = x +1, +1, ,

(x +1). It thus follows that

, +1 - ,  (x +1, +1, , ) - , ,

which, by definition of projection [10, Section 3.4], means that , +1 can be viewed as the projection of onto the solution set (x +1, +1, , ). We thus see that

, - , -1

, - , +1 = , - , -1

, - , +1 

, +1 -

,

2
 0.

Note that using the Cauchy-Schwarz inequality, we also get that , - , -1  , +1 - , implying the stable sequence of the multipliers. Rearranging terms in (31), we obtain

, +1 -

,

2


(x +1) - (x )

, +1 - , ,

which leads to

, +1 -

,

()


1

(x +1) -

()
(x ) 

x +1 - x .

Jong Gwang Kim

27

where ( ) follows from the Cauchy-Schwarz inequality; ( ) is from the continuous differentiability of (x) (Assumption 1), implying that (x) is Lipschitz-continuous with constant . Squaring both sides of the inequality gives the desired result (15).

B.3 Proof of Lemma 3 P . Consider the difference of two consecutive sequences of L :

L x +1, , +1, , +1, , +1 - L x , , , , , ,

= L x +1, , +1, , , , - L x , , , , , ,

(32)

+ L x +1, , +1, , +1, , +1 - L x +1, , +1, , , , .

We estimate the two terms on the right-hand side of (32) one by one. For the first term, using the descent lemma (Lemma B.1), we have

L x +1  L x + xL x

x +1 - x

+2

x +1 - x

2
.

(33)

Here, we omitted , , , , , for simplicity. By Step 1 of Algorithm 1, we have

L x +1; x = L x + xL x

x +1 - x

+2

x +1 - x

2
L

Thus we obtain

xL x

x +1 - x

-2

x +1 - x

2
.

By substituting the above expression into (33) and using the definition of

x ;x = L x . , +1 in Step 2, we get

L

x +1, , +1, , , , - L

x, ,,

,,

,



-

1 2

(

-

) x +1 - x

2
.

(34)

Next, consider the second term:

L x +1, , +1, , +1, , +1 - L x +1, , +1, , , ,

= , +1 - ,

x +1 - 2

, +1 -

,

+1

2
+

2

,-

,

2
,

(35)

=0

=0

where it follows from Step 3 that the second and third terms on the right-hand side are zero.

We now focus on deriving an upper bound for the term , +1 - ,

x +1 . To this end,

we need to consider two cases: , + 1 (x +1)  0 and , + 1 (x +1) < 0.

Case 1. , + 1 (x +1)  0. By the definition of , +1 =

, +1

(x

+1 )

+
and

,=

,

from Step 3, we obtain

, +1 - ,

(x +1) =

, +1 -

,

2
.

(36)

Case 2. , + 1 (x +1) < 0. Note that in this case, , +1 = 0 and x +1 is feasible because (x +1) < 0. For convenience, we define
 := ( , +1) (x +1) - ( , ) (x ).

Jong Gwang Kim

28

Then, by subtracting and adding the term , fact that , +1 = 0, it follows that

(x +1) to the right-hand side and using the

=

, +1 - ,

(x +1) + ( , )

(x +1) - (x )



, +1 - ,

(x +1) - , - , +1

(x +1) - (x ) .

(37)

From the feasibility of x +1, we have that for any  R+ ,  R and > 0

( ) (x +1) - 2

-

Thus, we can get with = , +1 and = , that

2  0,

, +1

(x +1)  2

, +1 -

,

2
.

On the other hand, since ,  0 maximizes L (x , , , , , -1) = x + ( )

2

- , -1 2 for given x , , -1 and the third term,

-2

,-

,

-1

2

=

- 21 - 2

2
(x )
, -1 2

if , -1 + 1 otherwise,

(x )  0

is a given constant, we have that

,

x  0.

x-

Hence,

=

, +1

x +1 - ,

x 2

, +1 -

,

2
,

(38)

Combining (37) and (38) and invoking Lemma 2, we obtain

, +1 - ,

(x +1) 

, - , +1

(x +1) - (x ) + 2

, +1 - , 2



, +1 - ,

x +1 - x

2
+2

x +1 - x 2

(39)

32 2

x +1 - x

2
.

Notice that the above upper bound on , +1 - ,

(x +1) includes the upper bound in

Case 1. Therefore, by combining (34), (35) and (39), we obtain the desired result:

L

(x +1,

, +1,

, +1,

, +1)  L

(x ,

,,

,,

,

)-

1 2

-

32 -

x +1 - x

2
,

which implies that the sequence L x , , , , , , is monotonically decreasing if is
32
chosen such that > + with a suitable choice of > 0.
Next, we show that {L } is a convergent sequence. we know from Lemma 2 that a saddle point of L exists. Let (x, ,, ,, ,) be a saddle point of L (x, , , ). By the updating rules

Jong Gwang Kim

29

for , +1, , +1 defined as maximizers for updated x +1, +1 and the saddle point condition (8), we see that
L x +1, , +1, , +1, , +1  L x +1, , +1, , ,  L x, ,, ,, , > -, (40)

which implies that the sequence L x , , , , , , is lower bounded by a finite value

of L (x, ,, ,, ,). Thus, with the choice of such that



32
+ , the sequence

L x , , , , , , converges to a finite limit, denoted by L , as  .

B.4 Proof of Theorem 3 P . (a) Recall from Lemma 2 that a saddle point (x, ,, ,, ,) of L (x, , , ) exists.
From (40) in Lemma 3, we know that L (x , , , , , , ) is lower bounded by L (x, ,, ,, ,). Since L x , , , , , , is nonincreasing, it is also upper bounded by a finite value, i.e, L (x , , , , , .We thus have
- < L (x +1, , +1, , +1, , +1) = (x +1) + ( , +1) (x +1) < +.

Hence, the sequence x is bounded due to the coercivity of (x) (Assumption 3) with the facts that , +1  0 and , +1 (x +1)  0.

(b) Note that since the function  L (x, , , ) is strongly concave, there exists parameter > 0 such that for ,, , +1  R+ and for given (x +1, , +1, , )

L ( ,, , )  L ( , +1, , ) +  L ( , +1, , ) ( , - , +1) - 2

, +1 - , 2

L ( , +1, , )  L ( ,, , ) +  L ( ,, , ) ( , +1 - ,) - 2

, +1 -

,

2
,

where we omitted (x +1, , +1) for notational simplicity. Adding the above two inequalities yields

, +1 - , 2   L ( , +1, , ) -  L ( ,, , )

, - , +1 .

Using the Cauchy-Schwarz inequality and the triangle inequality, we obtain

, +1 - ,  1  L

, +1, , -  L ( ,, , )

1 =

, - , +1

() 1 

, - , - (x +1)



, - , + 1

(x +1) .

where the inequality ( ) comes from the definition of , +1 in Step 3, implying that , +1  , + 1 (x +1). Since {x } is bounded and (x) is continuous differentiable (Assumption 1),
there exists > 0 such that x +1  . From the update of , +1 = , +1 in Step 3, we have = for any  1. By taking = we have
, +1 - ,  , - , + .

Therefore, the sequence , is bounded on any subset of R+ .

Jong Gwang Kim

30

(c) Invoking Lemma 3, we have that for all  1

x +1 - x

2
L

x , , , , , , -L

x +1, , +1, , +1, , +1 ,

where

:=

1 2

32

--

 0. Summing the above inequality over = 1, . . . , , we obtain

x +1 - x

2


1

L

=1
1 L

x1, ,1, ,1, ,1 - L x +1, , +1, , +1, , +1 x1, ,1, ,1, ,1 - x ,

where the last inequality comes from (40) with the fact that L (x, ,, ,, ,) = (x).

Letting   yields



x +1 - x

2
< ,

=1

from which, along with Lemma 2, it also follows immediately that

 =1

, +1 -

,

2
<  and

 =1

, +1 -

,

2
< . Therefore, we can deduce the desired results in (16).

B.5 Proof of Theorem 4
P . Since the sequence (x , , , , , , ) is bounded, there exists at least one limit point. Let (x, , , ) be a limit point of (x , , , , , , ) , and let (x , , , , , , ) be a subsequence converging to (x, , , ) as  . From Theorem 3(c), it also follows that (x +1, , +1, , +1, , +1
(x, , , ) as  . First, we show that a limit point (x, , , ) satisfies the second inequality of the saddle point
condition (8). Because , +1  and ,  as  , we have from Step 1 that

The limit point

= PX -  L (x, , , ; x) . is equivalent to a solution of the VI [24, Prop. 1.5.8]:
 L (x, , , ; x) -  0,   X .

Using the fact that  L (x, , , ; x) =  L (x, , , ) and the convexity of L with respect to , we obtain the first-order optimality condition for L :

 L (x, , , ) -  0,   X .

Equivalently,

L ( , - , , , )  L ( , - , , , ),

which implies that (x, , , ) satisfies the second inequality of the saddle point condition (8).
Similarly, by the definitions of , +1 and , +1 (as maximizers) in Step 3, the limit points ( , ) maximize L (x, ( , ), , ). We thus see that

 L (x, , , ) ( - )  0,   R+ ,  L (x, , , ) ( - )  0,   R .

Consequently, (x, , , ) satisfies the first inequality of the saddle point condition (8).

Jong Gwang Kim

31

C GLOBAL CONVERGENCE UNDER THE KL PROPERTY
Before proceeding with global convergence, let us provide some preliminaries, which are central to our global convergence analysis.

L C.1 (U

KL P

[11, L

6]). Let  be a compact set and let  : R 

(-, ] be proper, lower semicontinuous function. Assume that  is constant on  and satisfies the

KL property at each point of . Then there exist > 0, and   such that for all in  and all

in the following intersection:

{  R : dist( , ) < }  [( ) < ( ) < ( ) + ]

(41)

one has,

(( ) - ( )) · dist(0, ( ))  1.

(42)

Note that if the function  is continuously differentiable and ( ) = 0, the inequality (42) can be rewritten as
(( ) - ( )) ( )  1.
With the uniformized KL property, we can prove that the generated sequence has finite length, and hence the whole sequence converges to a saddle point. The techniques developed in [11] are extended to our smooth constrained game setting with some modifications.
In order to exploit Lemma C.1 for proving global convergence, we need to use the size of the gradient of the P-Lagrangian, denoted by L , and derive an upper bound on the gradient. Noting that and are continuously differentiable,  X , and  R+ , we consider the following projected gradients of L in and for -component and -component of L :

 L (x, , , ) :=  L (x, , , ) :=

- PX -  L (x, , , ) ,
+
- +  L (x, , , ) .

Let us now define the projected gradient of L at (x +1, , +1, , +1, , +1) as

L (w , +1) :=

+1

, +1 - PX

, +1 -  L (x +1, , +1, , +1, , +1)

+1

 L (x +1, , +1, , +1, , +1)

=
+1

, +1 -

, +1 +  L (x +1, , +1, , +1, , +1) +

+1

 L (x +1, , +1, , +1, , +1)

. (43)

It is clear that if L (w , +1)  0, then a saddle point of L (w ) is obtained. In what follows, we derive an upper bound on L (w , +1) in terms of the generated iterates by Algorithm 1.

L

C.2. Let w , =1 be the sequence generated by Algorithm 1. Then, for every = 1, . . . , ,

there exist constant > 0 such that for all  0

L (w , +1)  x +1 - x .

(44)

P . We first estimate an upper bound for the norm of component +1 in L (w , +1). Recall that there exists a unique solution x of the approximation subproblem VI (X, L ) in (11)

Jong Gwang Kim

32

at each iteration (Lemma 1), and denote by , the th component of x . From the fixed-point characterization of , , we know that for every = 1, . . . , ,

, = PX = PX

, - L x , , , , , , ;x , -  (x ) +  (x ) , + ( , - , ) .

Hence,

+1 = =
()


, +1 - , +1 -

, + , - PX

, +1 -  L (x +1, , +1, , +1, , +1)

, + PX , -  (x ) -  (x ) , - ( , - , )

-PX , +1 -  (x +1) -  (x +1) , +1

, +1 - , + , -  (x ) -  (x ) , - ( , - , )

()
 (2 +

) x +1 - x

+

- , +1 -  (x +1) -  (x +1) , +1 (x +1) -  (x ) +  (x +1) , +1 -  (x ) , ,

where ( ) follows from the nonexpansive property of the projection operator, and ( ) is due to the facts that , +1 - ,  , +1 - , and , +1 - ,  x +1 - x . Then, by adding
and subtracting (x ) , +1 and using the triangle inequality, we obtain

+1  (2 + ) x +1 - x +  (x +1) -  (x )

+  (x +1) , +1 -  (x ) , +1 +  (x ) , +1 -  (x ) ,

 (2 + ) x +1 - x +  x +1 - x + 

x +1 - x +

, +1 - ,

 2+ +  + 

+

x +1 - x ,

(45)

where the second inequality follows from the Lipschitz continuity of  and  (see (24c)-

(24d)), and the boundedness of x and , implying that there exist constants := max N ,

and := max N (x ) ; in the last inequality we used that , +1 - , 

x +1 - x

(Lemma 2).

Next, notice that from the definition of , +1  R+ as a maximizer for given (x +1, , +1, , ), , +1 is also characterized by

, +1 =

, +1 + 

L

(x +1,

, +1,

, +1,

,

)

+
,

which, together with the nonexpansive property of the projection onto R+ and Lemma 2, yields

+1 =

, +1 + ( (x +1) - , +1) - ( , +1 - , ) +

- , +1 + ( (x +1) - , +1) - ( , +1 - , +1) +

 ( , +1 - , ) 

x +1 - x .

(46)

Jong Gwang Kim

33

In addition, recalling that the definitions of , +1 in Step 2 and , +1 in Step 3, we have

+1 = ( , +1 - , +1) +

, +1 = 0,

(47)

+1 = , +1 + ( , +1 - , +1) = 0.

(48)

Therefore, summing the inequalities (45) and (46), we deduce for all  0

L (w , +1) =
=,,,

, +1  x +1 - x

with the positive constant

=2+ +  + 

+

+.

This completes the proof.

C.1 Proof of Theorem 5
P . Let w := (x, , , ) be a limit point of the sequence w , = (x , , , , , , ) that is bounded for every = 1, . . . , . Then, by the continuity of L , we have

lim L (w , ) = L (w ).

(49)



In the following, we consider two cases: Case 1. Suppose that there exists an integer ¯ such that L (w ,¯) = L (w ) for = 1, . . . , .

Since the sequence L is nonincreasing, we have that L (w , ) = L (w ) for all  ¯. Then, we have from Lemma 3 that for any  0

x + -x

2
L

(w , ) - L

(w , + ) = 0,

which leads to

x +1 - x = 0,   ¯,

(50)

From Lemma 2, we also obtain that , +1 - , = 0 and , +1 - , = 0 for all  ¯. Therefore, w , = (x , , , , , , ) must be eventually constant (stationary), and it thus has finite length. Case 2. Consider now the case where such an integer ¯ does not exist (and every w , is
nonstationary) for = 1, . . . , . In this case, we first show that the P-Lagrangian L is finite and

constant on the set of all limit points (w0 ) of the sequence w , , and then apply Lemma C.1 to show that w , is a Cauchy sequence and convergent.
First, note that since the sequence {L } is nonincreasing, we have that L (w , ) > L (w )

for all . This, along with (49), implies that there exists an integer 0 large enough such that for any > 0 and > 0 in Lemma C.1

L (w ) < L (w , ) < L (w ) + and dist(w , , (w0 )) < for all  0,

(51)

where the second comes from the fact that lim dist(w , , (w0 )) = 0 (see Theorem 4). Thus w , belongs to the intersection in (41) with  = (w0 ) for all  0, and  = (w0 ) is nonempty and compact. Recall that {L } is bounded below by the value of L at a saddle point, and hence {L } converges to a finite limit, denoted by L . It then follows from (49) that L = L (w ), which shows that L is finite and constant on (w0 ).

Jong Gwang Kim

34

Thus, since L is a KL function, by applying Lemma C.1 with  = L (w , ), we get that for any > 0

(w0 ) and ( ) =

 L (w , ) - L (w ) · dist 0, L (w , )  1,

which combined with Lemma C.2 gives

 L (w , ) - L (w ) 

1



dist 0, L (w , )

x

1 - x -1

.

(52)

On the other hand, since is concave function, we know that

L (w , ) - L (w ) -

L (w , +1) - L (w )   L (w , ) - L (w ) L (w , ) - L (w , +1) .

For convenience, we define for any ,  N

 , := L (w , ) - L (w ) - L (w , ) - L (w ) .

Then we get

 , +1   L (w , ) - L (w ) L (w , ) - L (w , +1) .

(53)

Recalling from Lemma 3 that L to obtain

(w , ) - L  , +1 

(w , +1)  x +1 - x
x +1 - x 2 x - x -1 .

2
, we combine (52) and (53)

Multiplying the above inequality by x - x -1 gives

x +1 - x

2


 , +1 x - x -1

where

:=

,

 and hence 2 x +1 - x  2  , +1 x - x -1 . Using the inequality 2 with = x - x -1 and =  , +1, we have

 + for any ,  0

2 x +1 - x  x - x -1 +  , +1.

(54)

Now we show that for any > 0 the following inequality holds:

2

x +1 - x  x 0+1 - x 0 +

= 0+1

By summing (54) over = 0 + 1, . . . , , we have

 0+1, +1.

2

x +1 - x 

x - x -1 +

= 0+1

= 0+1

 , +1
= 0+1



x +1 - x + x 0+1 - x 0 +

 , +1

(55)

= 0+1

= 0+1

Jong Gwang Kim

35

and using fact that  , +  , =  , for all , ,  N, we get

 , +1 =  0+1, +1 =
= 0+1

L (w , 0+1) - L (w ) -

L (w , 0+2) - L (w )

 L (w , 0+1) - L (w ) < ,

(56)

where the last inequality follows from the fact that  0. Plugging (56) into (55) and rearranging terms, we obtain

x +1 - x  x 0+1 - x 0 +

L (w , 0+1) - L (w ) < .

(57)

= 0+1

Since the right-hand side of (57) does not depends , the sequence x has finite length, i.e.,


x +1 - x < .

=1

This implies x is a Cauchy sequence and thus a convergent sequence. By Lemma 2, the multiplier sequences { , } and { , } are also Cauchy. Therefore, we conclude that the whole sequence
(x , , , , , , ) converges to a saddle point (x, , , ) of L , = 1, . . . , .

We end by noting that convergence rate of the generated sequence described in Theorem 5 can be easily derived by applying the generic rate of convergence result in [4].

T

6 (C

R ). Suppose that every and satisfy the KL property, where

the desingularizing function of L is of the form: ( ) = 1- , > 0,  [0, 1). Let w :=

(x, , , ) be the limit point of w , := ( , , , , , , , ) . Then the following convergence
=1
rates hold:

(a) If (b) If (c) If

= 0, then w , N converges to w in a finite number of steps.

 (0, 1/2], then w , - w  for all  0, for certain 0 > 0.

 (1/2, 1). then w , - w 

. -

(1- ) (2 -1)

