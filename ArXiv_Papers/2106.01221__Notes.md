
# Differential Privacy for Text Analytics via Natural Text Sanitization

[arXiv](https://arxiv.org/abs/2106.01221), [PDF](https://arxiv.org/pdf/2106.01221.pdf)

## Authors

- Xiang Yue
- Minxin Du
- Tianhao Wang
- Yaliang Li
- Huan Sun
- Sherman S. M. Chow

## Abstract

Texts convey sophisticated knowledge. However, texts also convey sensitive information. Despite the success of general-purpose language models and domain-specific mechanisms with differential privacy (DP), existing text sanitization mechanisms still provide low utility, as cursed by the high-dimensional text representation. The companion issue of utilizing sanitized texts for downstream analytics is also under-explored. This paper takes a direct approach to text sanitization. Our insight is to consider both sensitivity and similarity via our new local DP notion. The sanitized texts also contribute to our sanitization-aware pretraining and fine-tuning, enabling privacy-preserving natural language processing over the BERT language model with promising utility. Surprisingly, the high utility does not boost up the success rate of inference attacks.

## Comments

ACL-ICJNLP'21 Findings; The first two authors contributed equally

## Source Code

Official Code

- [https://github.com/xiangyue9607/SanText](https://github.com/xiangyue9607/SanText)

Community Code

- [https://paperswithcode.com/paper/differential-privacy-for-text-analytics-via](https://paperswithcode.com/paper/differential-privacy-for-text-analytics-via)

## Bibtex

```tex
@misc{yue2021differential,
      title={Differential Privacy for Text Analytics via Natural Text Sanitization}, 
      author={Xiang Yue and Minxin Du and Tianhao Wang and Yaliang Li and Huan Sun and Sherman S. M. Chow},
      year={2021},
      eprint={2106.01221},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

## Notes

Type your reading notes here...

