
# Multiple Imputation Through XGBoost

[arXiv](https://arxiv.org/abs/2106.01574), [PDF](https://arxiv.org/pdf/2106.01574.pdf)

## Authors

- Yongshi Deng
- Thomas Lumley

## Abstract

Multiple imputation is increasingly used in dealing with missing data. While some conventional multiple imputation approaches are well studied and have shown empirical validity, they entail limitations in processing large datasets with complex data structures. Their imputation performances usually rely on expert knowledge of the inherent relations among variables. In addition, these standard approaches tend to be computationally inefficient for medium and large datasets. In this paper, we propose a scalable multiple imputation framework mixgb, which is based on XGBoost, bootstrapping and predictive mean matching. XGBoost, one of the fastest implementations of gradient boosted trees, is able to automatically retain interactions and non-linear relations in a dataset while achieving high computational efficiency. With the aid of bootstrapping and predictive mean matching, we show that our approach obtains less biased estimates and reflects appropriate imputation variability. The proposed framework is implemented in an R package misle. Supplementary materials for this article are available online.

## Comments



## Source Code

Official Code

- [https://github.com/agnesdeng/mixgb](https://github.com/agnesdeng/mixgb)

Community Code

- [https://paperswithcode.com/paper/multiple-imputation-through-xgboost](https://paperswithcode.com/paper/multiple-imputation-through-xgboost)

## Bibtex

```tex
@misc{deng2021multiple,
      title={Multiple Imputation Through XGBoost}, 
      author={Yongshi Deng and Thomas Lumley},
      year={2021},
      eprint={2106.01574},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}
```

## Notes

Type your reading notes here...

