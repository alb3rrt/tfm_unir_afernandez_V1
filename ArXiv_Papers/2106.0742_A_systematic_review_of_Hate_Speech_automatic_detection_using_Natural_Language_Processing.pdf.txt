arXiv:2106.00742v1 [cs.CL] 22 May 2021

A SYSTEMATIC REVIEW OF HATE SPEECH AUTOMATIC DETECTION USING NATURAL LANGUAGE PROCESSING
Md Saroar Jahan, and Mourad Oussalah University of Oulu, CMVS, BP 4500, 90014 Finland
{mjahan18,mourad.oussalah}@oulu.fi
ABSTRACT
With the multiplication of social media platforms, which offer anonymity, easy access and online community formation and online debate, the issue of hate speech detection and tracking becomes a growing challenge to society, individual, policy-makers and researchers. Despite efforts for leveraging automatic techniques for automatic detection and monitoring, their performances are still far from satisfactory, which constantly calls for future research on the issue. This paper provides a systematic review of literature in this field, with a focus on natural language processing and deep learning technologies, highlighting the terminology, processing pipeline, core methods employed, with a focal point on deep learning architecture. From a methodological perspective, we adopt PRISMA guideline of systematic review of the last 10 years literature from ACM Digital Library and Google Scholar. In the sequel, existing surveys, limitations, and future research directions are extensively discussed.
Keywords Hate speech detection Review · Systematic review · PRISMA hate speech · NLP deep learning review
1 Introduction
In the era of social computing, the interaction between individuals becomes more striking, especially through social media platforms and chat forums. Microblogging applications opened up the chance for people worldwide to express and share their thoughts instantaneously and extensively. Driven, on one hand, by the platform's easy access and anonymity. And, on the other hand, by the user's desire to dominate debate, spread / defend opinions or argumentation, and possibly some business incentives, this offered a fertile environment to disseminate aggressive and harmful content. Despite the discrepancy in hate speech legislation from one country to another, it is usually thought to include communications of animosity or disparagement of an individual or a group on account of a group characteristic such as race, color, national origin, sex, disability, religion, or sexual orientation [100]. Benefiting from the variation in national hate speech legislation, the difficulty to set a limit to the constantly evolving cyberspace, the increased need of individuals and societal actors to express their opinions and counter-attacks from opponents and the delay in manual check by internet operators, the propagation of hate speech online has gained new momentum that continuously challenges both policy-makers and research community. With the development in natural language processing (NLP) technology, much research has been done concerning automatic textual hate speech detection in recent years. A couple of renowned competitions (e.g., SemEval-2019[158] and 2020 [159], GermEval-2018 [150]) have held various events to find a better solution for automated hate speech detection. In this regard, researchers have populated large-scale datasets from multiple sources, which fueled research in the field. Many of these studies have also tackled hate speech in several non-English languages and online communities. This led to investigate and contrast various processing pipelines, including the choice of feature set and Machine Learning (ML) methods (e.g., supervised, unsupervised, and semi-supervised), classification algorithms (e.g., Naives Bayes, Linear Regression, Convolution Neural Network (CNN), LSTM, BERT deep learning architectures, and so on). The limitation of the automatic textual-based approach for efficient detection has been widely acknowledged, which calls for future research in this field. Besides, the variety of technology, application domain, and contextual factors require a constant up-to-date of the advance in this field in order to provide the researcher with a comprehensive and global view in the area of automatic HT detection. Extending existing survey papers in this field, this paper contributes to this goal by providing an updated systematic review of literature of automatic textual hate speech detection with a special focus on machine learning and deep learning

Systematic review of Hate Speech automatic detection
technologies. We frame the problem, its definition and identify methods and resources employed in HT detection. We adopted a systematic approach that critically analyses theoretical aspects and practical resources, such as datasets, methods, existing projects following PRISMA guidelines [90]. In this regards, we have tried to answer the following research questions:
· Q1: What are the specificities among different HS branches and scopes for automatic HS detection from previous literature?
· Q2: What is the state of the deep learning technology in automatic HS detection in practice? · Q3: What is the state of the HS datasets in practice?
The above-researched questions will examine barriers and scopes for the automatic hate speech detection technology. A systematic review-based approach is conducted to answer Q1 and Q2, where we will try to depict and categorize the existing technology and literature. The third research question Q3, will be answered by critically examining the scope and boundaries of the dataset identified by our literature review, highlighting the characteristics and aspects of the available resources.
This review paper is organized as follows: section 2 will include a brief theoretical definition of HS. Section 4 examines the previously identified review papers of HS detection. Section 5 details the systematic literature review document collection methodology. Section 6 presents the results of this literature review, including the state of deep learning technology. Section 7 emphasizes on the available resources (datasets and open-source projects). After that, in section 8, an extensive discussion is carried out. Finally, we have highlighted future research directions and conclusions at the end of this paper.
2 Background
2.1 What is hate speech?
Deciding if a portion of text contains hate speech is not simple, even for human beings. Hate speech is a complex phenomenon, intrinsically associated with relationships between groups, and relies on language nuances. Different organization and authors have tried to define hate speech as follow:
1. Code of Conduct between European Union Commission and companies: "All conduct publicly inciting to violence or hatred directed against a group of persons or a member of such a group defined by reference to race, color, religion, descent or national or ethnic" [151].
2. International minorities associations (ILGA) : 'Hate crime is any form of crime targeting people because of their actual or perceived belonging to a particular group. The crimes can manifest in a variety of forms: physical and psychological intimidation, blackmail, property damage, aggression and violence, rape'1.
3. Nobata et al. [99]- "Language which attacks or demeans a group based on race, ethnic origin, religion, disability, gender, age, disability, or sexual orientation/gender identity."
4. Facebook: "We define hate speech as a direct attack against people on the basis of what we call protected characteristics: race, ethnicity, national origin, disability, religious affiliation, caste, sexual orientation, sex, gender identity, and serious disease. We define attacks as violent or dehumanizing speech, harmful stereotypes, statements of inferiority, expressions of contempt, disgust or dismissal, cursing, and calls for exclusion or segregation. We consider age a protected characteristic when referenced along with another protected characteristic. We also protect refugees, migrants, immigrants, and asylum seekers from the most severe attacks, though we do allow commentary and criticism of immigration policies. Similarly, we provide some protections for characteristics like occupation, when they're referenced along with a protected characteristic2."
5. Twitter: 'You may not promote violence against, threaten, or harass other people on the basis of race, ethnicity, national origin, caste, sexual orientation, gender, gender identity, religious affiliation, age, disability, or serious disease' 3. Examples from Twitter hate-speech are:
· "I'm glad this [violent event] happened. They got what they deserved [referring to persons with the attributes noted above]."
· "[Person with attributes noted above] are dogs" or "[person with attributes noted above] are like animals."
1https://www.ilga-europe.org/what-we-do/our-advocacy-work/hate-crime-hate-speech 2https://www.facebook.com/communitystandards/hate_speech 3https://help.twitter.com/en/rules-and-policies/twitter-rules#hateful-conduct
2

Systematic review of Hate Speech automatic detection

Source
EU Code of conduct ILGA Scientific paper [99] Facebook Twitter YouTube

Table 1: Content Analysis of Hate Speech Definitions

Target Religion Gender Race/ Eth- Radicalization/

Discrimi- nicity/ Color Violence

nation

yes

yes

yes

yes

yes

yes

no

no

no

yes

yes

yes

yes

yes

no

yes

yes

yes

yes

yes

yes

yes

yes

yes

no

yes

yes

yes

yes

yes

Others
intimidation, blackmail, property damage, rape disability, age curse, serious disease, Occupation age , disability, serious disease age

6. YouTube: 'We remove content promoting violence or hatred against individuals or groups based on any of the following attributes: age, caste, disability, ethnicity, gender identity and expression, nationality, race, immigration status, religion, sex/gender, sexual orientation, victims of a major violent event and their kin, and veteran Status'. 4
To better understand the definitions, we consider different terms analysis from the above definitions. Tab. 2 summarizes key components that characterize HS in these definitions. For instance, all the definitions point out that HS has specific targets (person, group, nationality, etc.). Furthermore, most of these definitions refer to religion, gender discrimination, race, color, ethnicity, and violence. While less common criteria for measuring HS include curse, disability, property damage, age, and serious disease.
2.2 Other Related Concepts
From the above definitions and contents analysis, it is clear that some elements are highly related to hate speech ( e.g., racism, violence, gender discrimination, etc.). Moreover, we have found several previous works that have presented significant branches of HS. The analysis of HS's different branches helps to reach insights from different perspectives. This expects to contribute to spotting and recognizing the interrelationships among these terminologies. Here we will discuss some of the essential categories that are found relevant in most Hate Speech studies:
Cyberbullying: Chen et al. [31], Dinakar et al. [37] defined the electronic form of traditional bullying, also, referred to cyberbullying, as the aggression and harassment targeted to an individual who is unable to defend himself. Dredge et al. opined that bullying is known for its repetitive act to the same individual, unlike hate speech which is more general and not necessarily intended to hurt a specific individual [41].
Racism: This category includes racial offense or tribalism, regionalism, xenophobia (especially for migrant workers) and nativism (hostility against immigrants and refugees), and any prejudice against a particular tribe, region, color, or physical posture of an individual. For instance, offending an individual because he belongs to a specific tribe, region, or country [8]
Sexism, Gender discrimination: O'Brien [101] defined sexism as a prejudice or a discrimination based on a person's sex or gender. Sexism can affect anyone, although, it primarily affects women and girls. It has also been linked to stereotypes and gender roles. Matsumoto [86] stated that in many types of hate, there could be the existence of sexual harassment contents. Moreover, Jha and Mamidi [65] reported that sexism might come in two different forms: Hostile (which is an explicit negative attitude) and Benevolent (which is more subtle).
Radicalization: This concept is usually referred to as a motive towards violent extremism. Radicalization and hate speeches are closely related and sometimes used equivalently. Some authors link radicalization to religious-based hate speech. Wadhwa and Bhatia [142] referred to radical groups as "cyber-extremists."
Abusive language, Offensive language: The term abusive language refers to hurtful language and includes hate speech, derogatory language, and profanity. However, many researchers referred to the abusive language as offensive language [99].
4https://support.google.com/youtube/answer/2801939?hl$=$en
3

Systematic review of Hate Speech automatic detection
Figure 1: Relational diagram between different type of hate speech concepts.
Religious hate speech: This includes any religious discrimination, such as Islamic sects, calling for atheism, AntiChristian, and their respective denominations or anti-Hinduism groups. [13] reported that religious hate speech is considered a motive for crimes in countries with the highest social crimes.
2.3 Relationship of HS Concepts and Example
From the above definitions of general HS and other related concepts, we have drawn a relationship diagram shown in Fig. 1. All other related concepts, cyberbullying, racism, sexism, abusive language, and radicalization, have been derived from the HS concept, which acts as a parent node in this hierarchical construction. In the second level, cyberbullying and abusive/offensive concepts are distinguished. Next, other components like sexism, racism, radicalization are discerned. A critical claim advocated by some social science and psychiatry scholars stipulates that cyberbullying cases must include both Insult/Swear wording and a second person/person's name [108]. If there is no second person/person's name available, it may not be considered cyberbullying other than general HS. This means that all cyberbullying cases can also be cast into the HS category, while some HS may not be classified as cyberbullying. However, the above categorization is not always faithful, as exemplified in Table 2. For example, sentence-7 ("This is bad, but John Doe is lucky") includes both Insult word and Person name; however, it is not an HS, cyberbullying, nor abusive case as the relationship between the two is not established. Similarly, sentence-5, "John Doe is not bad," contains both Person name and Insult word with a clear link between the two entities, but it is not connected to HS, cyberbullying, nor abusive case due to the presence of negating form. Likewise, sentence-4, 'John Doe is not a good person,' does not contain Insult words, but it is considered HS, cyberbullying, and offensive. In sentence-3, 'Asylum seekers are dirty,' has an Insult word and target; it falls into HS but is not categorized as cyberbullying because its target is not a Person / second person. All these examples show the requirements mentioned above for HS, cyberbullying, and other cases are potential conditions for the occurrence of HS but not sufficient due to the complexity of the natural language modifiers expression that could negate or shift the meaning. Besides, recognition of HS may be boosted when multiple sentences were put together as in sentence-8 ("John doe working hard. Ugly"), which is considered as an HS, Cyberbullying and Offensive cases even though the second sentence "Ugly" contains only an Insult word without any second person/Person entity. There could be examples of sentences that may comprise multiple HS concepts at the same time. Sentence-1 shows that it contains all categories, HS, cyberbullying, abusive, gender discrimination, racism, and radicalization. The above few cases explain the complications of detecting HS cases and determining their exact categorization, which involves examining all the paragraph's textual information.
4

Systematic review of Hate Speech automatic detection

Table 2: Sentence classification into different HS categories.

Sentence

General Cyber- Abusive Sexisim/

Racism

HS

bulling Offensive Gender Dic-

srimination

1. John doe is <religion name> yes

yes

yes

yes

yes

from <nationality> dirty is a bi-

sexual and violent

2. John doe is dirty

yes

yes

yes

no

no

3. Asylum seekers are not good yes

no

no

no

no

4. John Doe is not good person yes

yes

yes

no

no

5. John Doe is not bad

no

no

no

no

no

6. Group for blacks only!

no

no

no

no

no

7. This is bad, but John Doe is no

no

no

no

no

lucky

8. John doe working hard. Ugly yes

yes

yes

no

no

Radicalization
yes
no no
no
no no no
no

Insult/ Swear word exist
exist notexist notexist exist exist exist
exist

Figure 2: Generic pipeline of automatic HS detection system.
2.4 Generic Pipeline of Automatic HS Detection
Kowsari et al. [70] stipulated four essential parts for any text classification task, which still are valid for the HS classification as well. Figure 2 highlights the generic pipeline of the HS detection task as a text classification systembased approach. Its main components are described below: (i) Dataset collection and preparation: is the first step is HS detection pipeline. Often, datasets are collected from social media platforms (Facebook, Youtube, Twitter, etc.). Preprocessing is performed according to dataset structure and quality. Typically, this involves filtering and normalization aspect of tuextual inputs, which include tokenization, stopwords removal, misspelling correction, noise removal, stemming, lemmatization, among others. We shall also notice that the dataset maybe provided initially so that no collection is required. As part of data preparation, training and testing parts of the dataset should be distinguished for the subsequent machine learning step. (ii) Feature Engineering: is the next phase of the analysis where appropriate features are extracted from the textual inputs so that unstructured text sequences are converted into structured features. Common techniques for feature extractions are TF-IDF, semantic, lexical, topic modeling, sentiment, BOW, word embedding (FastText, GloVe, Word2Vec). Sometimes, dimensionality reduction is applied to reduce the time and memory complexity. Examples of dimension reduction methods are principal component analysis (PCA), linear discriminant analysis (LDA), non-negative matrix factorization (NMF), random projection, autoencoders, and t-distributed stochastic neighbor embedding (t-SNE) [70].
5

Systematic review of Hate Speech automatic detection

Acronym CNN GRU
BGRU
BERT
DistilBERT
mBERT
LR RF TF-IDF
GBDT BOW PoS Tag

Table 3: Acronyms and their full forms.

Full form

Acronym Full form

Convolutional neural network

LSTM

Long short-term memory

Gated recurrent units. Its a gating mech- BiLSTM Bidirectional Long Short-Term Memory

anism in RNNN

Bidirectional gated recurrent unit net- RNN

Recurrent neural

work

Bidirectional Encoder Representations RoBERTa A Robustly Optimized BERT Pretrain-

from Transformers

ing Approach

A distilled version of BERT: smaller, ALBERT A Lite BERT for Self-supervised Learn-

faster

ing

Multilingual BERT

TWilBert A specialization of BERT architecture

both for the Spanish and the Twitter do-

main

Linear regression

NB

Naive Bayes

Random forest

SVM

Support Vector Machin

Term frequency-inverse document fre- SG

Skip gram

quency

Gradient Boosting Decision Tree

ELMO

Embeddings from Language Models

Bag of word

CBOW

Continiuos bag of word

Part-of-speech tagging

GHSOM The Growing Hierarchical Self-

Organizing Map

(iii) Model Training: is one of the most crucial step of the text classification pipeline where a machine learning /deep learning model is trained on the training dataset. Several classifiers can be tailored based on task requirements: RF, NB, LR, CNN, RNN, BERT, etc. Commonly word embedding can be jointly used in a neural network model as an embedding layer which helps to enhance deep learning performance. The output of the machine-learning / deep-learning model can be either binary decision (e.g., hate versus non-hate speech) or multi-class output where the model discriminates various type of hate speech and non-hate speech.
(iv) Evaluation: is the final part of the text classification pipeline where the performance of the machine learning /deep learning model is estimated. Several evaluation metrics are used for this purpose: accuracy, F1 score, precision, Matthews Correlation Coefficient (MCC), receiver operating characteristics (ROC), area under the ROC curve (AUC).
3 List of Acronyms
In order to ease the readability and maintain the coherence of the various notations employed, we list in table 3 the various acronyms and their complete form cited throughout this paper. This concerns mainly the machine learning, deep learning, and feature sets of techniques reviewed in this paper.

6

Systematic review of Hate Speech automatic detection
Figure 3: PRISMA flowchart for selection of previous related review/survey documents.
4 Related work
From a computer science point of view, the scientific study of hate speech is comparatively a new topic, for which the number of review papers in the field is limited. We found only a few survey/review articles during the process of literature review. These were obtained using a systematic review-based approach where we adopted PRISMA framework [90] and conducted a brief systematic review of previous reviews in HS as will be detailed in the following section. 4.1 Methodology for collecting related review papers 4.1.1 Keywords To collect related review papers, we first selected the best keywords to retrieve relevant information from the search database (Google scholar5 and ACM6). Hate speech is a new concept that became popular recently; therefore, we considered other relevant terms referring to particular hate speech types (e.g., cyberbullying, sexism, racism, and homophobia). The search keywords were: Review/survey hate speech detection, Review/survey Offensive Or abusive language detection, Review/survey sexism detection, Review/survey sexism detection, and review/survey cyberbullying detection. 4.1.2 Search for documents We utilized Google Scholar and ACM digital library in order to search for systematic reviews containing the term "review/survey' with the keywords mentioned above in their titles and abstracts. At the same time, no date and language restrictions were imposed. The reason for not selecting "systematic" as a search keyword is that we wanted to collect all reviews that were not only based on systematic methodology but also on narrative methods. The last search was run on 30 December 2020. The title, abstract, authors' names and affiliations, journal name, and year of publication of the identified records were exported to an MS Excel spreadsheet for further analysis.
5https://scholar.google.com/ 6https://dl.acm.org/
7

Systematic review of Hate Speech automatic detection

Table 4: Review of identified survey papers on automatic hate speech detection

Paper Title

Authors, Year Publisher Review Focus

Citation

Name

A Survey on Hate Speech De- Schmidt and ACL

Features for HS Detection, 444

tection using Natural Language Wiegand [133]

anticipating alarming societal

Processing

2017

Changes, sata annotation, classi-

fication methods, etc.

A Survey on Automatic Detec- Fortuna and ACM

How HS work evolved from 211

tion of Hate Speech in Text

Nunes [46]

past, definition of HS, and clas-

2018

sification method.

Cyberbullies in Twitter A fo- [140]

IEEE

Mainly for the cyberbullying on 0

cused review

Twitter; emphasis was given to

identifying Twitter abusers.

DETECTION OF HATE Al-Hassan and COSIT Different category HS detection, 26

SPEECH IN SOCIAL NET- Al-Dossari [8]

multilingual HS detection, and

WORKS: A SURVEY ON 2019

HS in Arabic language.

MULTILINGUAL CORPUS

Tackling Online Abuse: A Sur- Mishra et al. ACL

Describe the existing datasets 9

vey of Automated Abuse Detec- [87] 2019

and review the computational

tion Methods

approaches of HS detection.

Resources and benchmark cor- Poletto et al. Springer Primarily focused on HS 2

pora for hate speech detection: [114] 2020

datasets.

a systematic review

A Review on Offensive Lan- Pradhan et al. Springer Finding best strategies for HS 0

guage Detection

[117] 2020

detection.

Review Type Narrative
Systematic Narrative Narrative
Narrative Systematic Narrative

4.1.3 Review of related review papers.
The above approach identified seven review papers. The study selection process is summarized in Fig. 3. While the initial literature search resulted 2100 records, 2061 were eliminated because either those were not review/survey documents related to HS and computer science or duplicate from both databases. The full texts of the remaining 39 reviews were carefully screened, and 32 articles were excluded because those did not have enough information to consider as review/survey documents or not related to HS/CSE domains. The remaining seven review papers, which passed the eligibility test, were divided into two main categories: narrative and systematic. Typically, narrative reviews do not reveal the methodology of data collection, in contrast to systematic reviews.
The survey of Schmidt and Wiegand [133] is the most cited one (more than 500 citations) 7. The paper follows a narrative method of analysis without revealing the data collection approach. The authors provided a short, comprehensive, structured, and critical overview of the field of automatic HS detection in NLP, highlighting key terminology and focusing on feature engineering relevant to HS / bullying identification, and finally, reviewing the current dataset and societal challenges.
Fortuna and Nunes [46] is the second most cited review paper and followed a systematic review-based approach. The authors presented a critical overview of how the textual automatic detection of hate speech evolved over the past few years. Their analysis proposed a unified and a clearer definition of the HS concept that can help build a model for the automatic detection of HS from machine learning perspective. Additionally, a comparison of performance of various HS detection algorithms is reported. Especially, they found that due to the lack of standards in the dataset, which could make the result biased. We found this review in term of its approach very relevant to our study. However, since this review was conducted at the end of 2017, an update literature is needed.
The survey in Tsapatsoulis and Anastasopoulou [140] focused on cyberbullying on Twitter where an emphasis was given on identifying Twitter abusers and indicated steps required to develop practical applications for the detection of Cyberbullers.
Al-Hassan and Al-Dossari [8] presented a summary of several discussed papers, organized according to their publication date. Their review covered i) English Anti-social behaviors; ii) English hate speech, and finally, iii) Arabic Anti-social behaviors. The provided tables can serve as a quick reference for all the key works performed on automatic HS detection on social media. The approaches and their respective experimental results were listed concisely. They also provided
7All citation mention in this papers are last searched on 03-March-20201
8

Systematic review of Hate Speech automatic detection
Figure 4: Methodology for document collection.
a summary of multilingual contributions directly related to hate speech, with a special focus to the Arabic language in social media platforms. Mishra et al. [87] examined the existing HS datasets and reviewed the computational approaches to abuse detection, analyzing their strengths and weaknesses, discussing the emerging prominent trends, while highlighting the remaining challenges and outlining possible solutions. Poletto et al. [114] followed a systematic review approach to analyze existing HS resources including their development methodology, topical focus, language coverage, and other factors. The results of their analysis highlighted a heterogeneous, growing landscape marked by several issues and room for improvement. Pradhan et al. [117] reviewed strategies for tackling the problem of identifying offense, aggression, and hate speech in user's textual posts as well as comments, micro-blogs, from Twitter and Wikipedia. Although the coverage of the dataset investigated was quite narrow. Table 4 shows the result of previous reviews study. Only two of the identified reviews were found to follow a systematicreview based approach ([46] and [114]) in this field. Unfortunately, one of the review Fortuna and Nunes was performed in late 2017 does not cover more recent work in the field. On the other hand, the work by Poletto et al. is mainly focused on HS datasets corpora. The rest of the identified review papers were not systematic. Some of them reviewed a small number of documents or targeted a specific part of this field (e.g., Tsapatsoulis and Anastasopoulou focused on Twitter cyberbullying). The lack of coverage in the aforementioned reviews and the need for literature up-to-date in the existing systematic reviews, together with a focus on the machine and learning perspective, were the main motivation for the current review work, which aims to fill in this gap. Our approach is complementary to that of [46] in the sense that it follows a systematic review based approach as well but it presents a more up-to-date literature and bears also some key differences. First, we adopt PRISMA protocol for systematic review-based analysis, with two search databases (Google scholar and ACM digital library). Second, a special care during the scrutinizing phase is devoted to track machine learning and deep learning methods with their associated evaluation performance and dataset employed. Third, we track the timely evolution of records and methods. We also enumerate existing data collections, including multilingual more comprehensively than in previous studies. Fourth, we summarize existing open-source projects and valuable resources in the field, and finally, we highlight the key challenges and open research agenda.
5 Systematic literature review methodology for collecting hate speech documents
The previous section 4 presented a brief systematic review of past review papers related to HS automatic detection. This section details our systematic literature review regarding HS automatic detection. For this purpose, we adopted PRISMA framework as in Moher et al., highlighting the keyword selection, Search sources, and filtering process.
5.1 Keyword selection The first phase conducted was the keywords selection. Since hate speech is a concept that comprises broad hate categories, our search criteria were partitioned into six categories: hate speech, sexism, racism, cyberbullying, abusive, and offensive. This provides us the best chance of retrieving a significant number of relevant work. Besides, as we wanted to pay special attention to machine learning and deep learning-based methods, several related abbreviations
9

Systematic review of Hate Speech automatic detection

Different type HS keywords
1. Hate speech detection
2. Sexism detection 3. Cyberbullying de-
tection 4. Racism detection 5. Abusive language
detection 6. Offensive language
detection

Table 5: Keywords list for the query search.

Deep learning Keywords

Deep learning BERT

model related keywords

1. Deep learning hate speech 2. CNN hate speech 3. LSTM hate speech 4. RNN hate speech 5. Deep learning Cyberbully-
ing 6. CNN Cyberbullying 7. LSTM Cyberbullying 8. Deep Learning Offensive 9. CNN Offensive 10. LSTM Offensive

1. BERT hate speech 2. BERT Cyberbully-
ing 3. BERT Abusive 4. BERT Rasism 5. BERT Sexism 6. BERT Offensive

Language keywords
Chinese (Mandaren, Yue, Wu), Hindi, Spanish, Arabic, Bengali, French, Russian, Portuguese, Urdu, Indonesian, German, Japanese, Marathi, Telugu, Turkish, Tamil, Korean.

and keywords have been accommodated and added to the keyword search (i.e., CNN, LSTM, RNN, BERT, etc.). Furthermore, 20 top-speaking languages 8 added in search keywords to retrieve multilingual works. A selected list of
keywords is shown in Table 5:

8The Ethnologue https://www.ethnologue.com/, one of the trusted platforms regarding language information based on more than a thousand bibliography references.
10

Systematic review of Hate Speech automatic detection
Figure 5: PRISMA flowchart for the selected studies for systematic review. 5.2 Search sources We used two different databases (ACM Digital Library and Google Scholar), aiming to gather the most significant number of records in the areas of computer science and engineering (CSE). This is motivated by the availability of search through an API, allowing the application of simple NLP modules to identify duplication and check string matching as well as record statistical trends. On the other hand, our desire to focus on computer science aspect of HS detection makes ACM library as an ideal candidate for search database, while Google scholar expects to identify all other relevant and high impact results outside ACM community. The input database search consists of an OR-logical combination of keywords of individual categories (hate speech OR sexism OR racism... etc.), see Table 5 for detailed listing of such keywords. Besides, this process has been automated by utilizing the beautiful-soup python web crawler for both databases (ACM and Google Scholar) by monitoring the API output, which consists of the paper's title, publication year, abstract, author's name, publisher information, citation, and link to the full article. We have made our scraping code publicly available for the community 9. Initially, we collected papers from 2000 to 2021, and no language restrictions were imposed since we wanted to gather multilingual work associated with hate speech detection. The last search for article collection was run on 18 March 2021. The title, publication year, abstract, author's names, publication venue, and link of full papers were exported to an MS Excel spreadsheet for further analysis.
9https://github.com/saroarjahan/Google_sholars_ACM_digital_library_crawler 11

Systematic review of Hate Speech automatic detection
Figure 6: Number of publications per year from 2000-2021 related automatic hate speech detection in NLP (blue line represent all 463 documents including deep learning and other ML approach, and yellow line represent 96 documents
related to Deep-learning method).
5.3 Filtering Documents The PRISMA flow chart highlighting the inclusion and exclusion criteria for the document search and inclusion in the database is summarized in Figure 5. Initially, 44,030 documents were collected from 2000 to 2021. Since we have collected data from two different databases, duplicate papers have been removed automatically from the system, leaving 33670 records for further title and abstract scrutinizing. In this respect, most documents that were not related to CSE fields and not associated with different hate speech categories (general hate, cyberbullying, abusive, offensive, sexism, racism, etc.) were excluded after the title and abstract screening. The remaining 1329 papers were considered for full-text review. Two independent reviewers with knowledge in this field have carefully performed this manual scrutinizing task. Those articles that were not related to hate speech or CSE fields (e.g., LAW, Psychology fields) were discarded. Similarly, descriptive and conceptual papers that fail to produce any solid results were also ignored. During this phase, disagreements between the two reviewers were discussed and resolved by consensus. If no agreement could be reached, the views of a third reviewer would have been taken into consideration. Finally, 463 articles were considered for the final systematic review and analysis. Among those 463 papers, 96 papers have been found to follow deep learning methods.
6 Systematic review results
6.1 Number of publications per year As we can see in Figure 6, a total of 463 papers were identified from 2000 to 2021 (including deep learning and all other methods). Before 2010, we have found only 1 document related to hate speech. From 2010 to 2016, only 25 papers associated with HS detection were found, yet there was no work related to deep learning. However, since 2017 the number of published documents raised rapidly with a steady increase of deep learning based HS detection approach. A total of 96 documents were found from 2017 to 2021 using deep-learning HS detection, indicating a trend of almost doubling the number of deep learning approach each year. The relatively small value in 2021 is due to the fact that the collection of new documents stopped in March 18, 2021.
12

Systematic review of Hate Speech automatic detection
Figure 7: Most Used Data Platforms (blue histogram represent all 463 documents including deep learning and other ML approach, and yellow histogram represent 96 documents related to Deep-learning method).
6.2 Publication Venue We have scrutinized the obtained records with respect to publication venues in an attempt to identify any dominating trend. From the total of 463 identified documents in textual HS automatic detection, we have found 72 different venues. The publication venues with more than 4 occurrences in our collection are presented in Figure 7. The most common platforms for publication of hate speech documents were ACLWEB10, ArXiv11, IEEE12, Springer13, and ACM14. The Association for Computational Linguistics (ACL) is the premier international scientific and professional society working on NLP's computational problems. Therefore, a vast number of papers were published in ACL-WEB forums. The second most popular source was Arvix, an open-access repository of electronic preprints. This can partially be explained by the fact that the hate speech detection area has become popular, with many autonomous and exploratory work being conducted. Additionally, this high number of publication venues reveals that HS automatic detection is not limited to a few sources of publication venue and testifies the field's multidisciplinary nature.
10https://www.aclweb.org/portal/ 11https://arxiv.org/ 12https://www.ieee.org/ 13https://www.springer.com/gp 14https://www.acm.org/
13

Systematic review of Hate Speech automatic detection
Figure 8: Statistics of the percentage of previous HS wrok in different language.
6.3 Categorization according to methods employed and detection performance This section first reviews the results (identified documents) in terms of machine learning and feature employed, the platform used for dataset collection, category of hate speech investigated, and bibliometric data of the publication15 as well as performance metrics (Accuracy (Acc), Precision (P), Recall (R)) claimed by the authors. After that, we evaluated the state-of-the-art of deep-learning methods related to HS automatic detection. 6.3.1 Statistical trends of results Tables 6 and 7 present some characteristics of selected highly cited papers, organized according to their publication date. The tables can serve as a quick reference for all the key works performed in textual automatic HS detection. The employed methods and related experimental results in terms of Precision, Recall, or F-measure are listed concisely. Table 6's attributes include data platform, type of hate speech, type of machine learning, features, and performance results. One notices, for instance, the dominance of Twitter and YouTube as the main source of data and supervised machine learning algorithms as the dominant machine learning type. Whereas Table 7 repeats the previous process for non-English and multilingual textual data. Furthermore, we have plotted statistical figures regarding all the 463 documents to understand the overall trend according to language, types of HS, data collection platform, ML approach, features, and algorithm used for HS detection. Figure 8 illustrates the proportion of the various languages of the textual input analyzed by HS automatic detection algorithms in the identified records. As expected, English textual source is by far the most investigated. This is rationally justified by the fact that initial work in the field has started with English textual dataset as in Dinakar et al. [37], but also due to the maturity of the natural language Parsers developed for English language as well as the abundance of benchmarking dataset that enable researchers to carry out useful comparative results. Nevertheless, with the advances in multilingual parsers and deep learning technology, together with increasing pressures from policy-makers to handle hate speech issues at local resources, non-English HS detection toolkits have seen a steady increase. The figure indicates that about 51% of all works in this field are performed on English dataset, with an increase of proportion of other languages as well where Arabic (13% ) [93, 59, 12, 143], Turkish (6%) [143, 104], Greek (4%) [143, 6, 136], Danish (5%) [106, 143], Hindi (4%) [121, 22, 88], German (4% ) [72, 120], Malayalam (3%) [130, 109], Tamil (3%) [130, 20], Chinese (1%) [138, 139, 155], Italian (2%) [116], Urdu (1%) [126, 95, 7], Russian(1%) [17], Bengali (1% ) [62, 127, 69], Korean (1%) [91], French (1%) [16, 102, 50], Indonesian (1%) [14], Portuguese (1%) [14], Spanish (1%) [56] and Polish (1%) [118] seem to dominate the rest of the languages in this field. It is worth noticing that despite Chinese being the 2nd largest speaking language globally, it has been much less investigated in HS detection community. One reason could be the lack of Chinese language in HS competition workshop such as SemEval2020 [159] and Hasoc2020 [81] where multilingual tasks included English, Danish, Greek, Arabic,
15All citations last updated on 03-Mar-2021
14

Systematic review of Hate Speech automatic detection
Figure 9: Statistics of the percentage of HS work in different categories.
Figure 10: Statistics of platforms used for data collection. Tamil, Malayalam, Hindi, German and Turkish, which encouraged many participants all over the world to work in these languages. Figure 9 depicts the percentage of different HS categories in the identified records. We can see that publications related to 'general hate' (36%) are a dominant trend followed by 'abusive language' 23% of total records. Cyberbullying and Radicalization categories share the same percentage of (15%) each. While relatively a small percentage is assigned to religion (5%), racial (3%), and sexism (3%) associated hate speech categories. From Figure 10, one can notice that 47% of dataset employed in HS detection was collected from Twitter social network, followed by Facebook (12%), Youtube (9%) and Wikipedia (5%). This indicates a growing trend in research community
15

Systematic review of Hate Speech automatic detection
Figure 11: Statistics on types of ML approach used for HS detection ( e.g., supervised, semi-supervised or unsupervised).
Figure 12: Statistics of algorithm types used for HS detection. to tackle the occurrence of hate speech in social media forums as social media platforms constitute by far the dominant agora of hate speech because of easy access, fast spread and societal impact. The rest of the dataset sources, with low occurrence rate, were mainly investigated for comparative purpose and benchmarking. For instance, Pawar et al. used Formspring dataset for cyberbullying detection and developed methods that enhance question-answer systems. In Section 7, we discuss in detail the current state of the art of HS dataset. Figure 11 provides a global trend in terms of types of machine learning approaches employed in our identified records. Among the ML approaches, we distinguish supervised, semi-supervised, and unsupervised like approaches. The analysis revealed that most of the works adopted supervised methods (73%). From Tables 6 and 7, we can observe that any of these three methods can achieve high-performance accuracy, and there is no substantial evidence to favor one over another one, whereas only the context of data (e.g., availability and quality of training samples) can play a role in deciding about the suitability of one category over another one. For example, Chen et al. used an unsupervised method and lexical & syntactic features to achieve 98% accuracy. Similarly, several works were based on supervised and semi-supervised methods that have shown close or better performance [21] [2]. Nevertheless, it is worth mentioning the popularity of the supervised like approach over other ML approaches, possibility due to the multiplication of benchmarking dataset and machine learning / deep learning platforms that promote supervised approach. Fig. 12 and 13 depict the percentage of ML algorithms and features employed in the identified records, respectively. The SVM method emerges as the most popular HS detection model covering 29% of total records. The use of deep learning models to HS started to rise from 2017 [21][107] to quickly cover about 22% of total identified records. On
16

Systematic review of Hate Speech automatic detection
Figure 13: Statistics of features employed by the ML/deep learning algorithms. the other hand, LR (20%) and NB (14%) were also among popular ML methods investigated by the researchers. We also noticed that in many deep-learning related methods, non-deep learning models were often employed as baseline to compare the performance of the investigated deep-learning model [40] [9] [63] [21]. Fig. 13 shows that TF-IDF based features cover 29% of the total records. However, word embedding models, which have widely being used in deep learning embedding layers, cover 33% of the entire records. The PoStag (3%), topic modeling (3%), and sentiment (3%) features were the least used features. This suggests that the deep-learning models and embedding features seem comparatively popular and widely used by the community. Next, we explored the popularity of the various deep-learning architectures (e.g., CNN, LSTM, BiLSTM, etc.) for HS automatic detection. The results are outlined in the next section 6.3.2.
17

Systematic review of Hate Speech automatic detection

Table 6: Summary of key contributions for English HS detection and their performance in terms of Precision (P), Recall

(R), F1-Score (F), Citation (C)

Author, Year

Platform

Type

ML

Ap- Features Representation Algorithm

P RF C

proach

Chen et al. [31] YouTube

Abusive

Un-

Lexical and syntactic

Match Rules

0.98 0.94 -

472

2012

Supervised

Xiang et al. [154] Twitter

Abusive

Semi-

Topic modelling

LR

- - 0.84 213

2012

Supervised

Dinakar et al. [37] YouTube

Cyberbullying Supervised Tf-idf, lexicon, PoS tag, bi- SVM

.66 - - 446

2012

gram

Warner

and Yahoo, news- Radicalization Supervised Template-based, PoS tagging SVM

.59 .68 .63 432

Hirschberg [144] group

2012

Wadhwa and Bha- Twitter

Radicalization Un-

Topic identification, N- Topic-entity

- - - 29

tia [142] 2013

Supervised grams

mapping

Kwok and Wang Twitter

Racism

Supervised Unigram

Naïve Bayes

-

-

-

273

[75] 2013

Nahar et al. [96] Myspace, Slash- Cyberbullying Semi-

Linguistic features

Fuzzy SVM

.69 .82 .44 60

2014

dot

Supervised

Burnap

and Twitter

Hate

Supervised BOW, Dependencies, Hate- Bayesian LR .89 .69 .77 80

Williams [28]

ful Terms

2014

Agarwal and Twitter

Radicalization Semi-

Linguistic,Term Frequency KNN, SVM

- - .83 97

Sureka [5] 2015

Supervised

Gitari et al. [53] Blog

Hate, Weakly Semi-

Lexicon, Semantic, theme- Rule based

0.73 0.68 0.70 257

2015

hate, Strongly Supervised based features

hate

Djuric et al. [39] Yahoo

Finance Hate, Supervised Paragraph2vec,

CBOW, LR

- - - 409

Waseem and Twitter

Hate

Supervised Character n-grams

LR

0.72 0.77 0.73 665

Hovy [146] 2016

Di Capua et al. YouTube,Form- Cyberbullying Un-

Semantic and syntactic fea- GHSOM net- .60 .94 .74 26

[36] 2016

Spring, Twitter

Supervised tures

work

and

K-mean

Park and Fung Twitter

Abusive

Supervised Character and Word2vec

Hybrid CNN

0.71 0.75 0.73 202

[107] 2017

Chen et al. [30] Youtube, Mys- Abusive

Supervised Word embeddings

FastText

- 0.76 - 9

2017

pace, SlashDot

Badjatiya et al. Twitter

Sexist, Racist Supervised FastText, GloVe Random LR, SVM CNN, 0.93 0.93 0.93 503

[21] 2017

Embedding,Tf-IDF, BOW LSTM and

GBDT

Wiegand et al. Twitter,

Abusive

Supervised Lexical,linguistics and word SVM

.82 .80 0.81 55

[149] 2018a

Wikipedia,

embedding

UseNet

Pawar et al. [110] Form-spring

Cyberbullying Supervised BOW

M-NB and - - .90 7

2018

Stochastic Gra-

dient Descent

Watanabe et al. Twitter

Hate, Offensive Supervised Sentiment-Based, Semantic, J48graft

0.79 0.78 0.78 95

[147] 2018

Unigram

Malmasi and Twitter

Hate, offensive Supervised N-grams, Skip-grams, hierar- RBF kernel, 0.78 0.80 0.79 133

Zampieri [80]

chical, word clusters

SVM

2018

Pitsilis et al. [113] Twitter

Racism or Sex- Supervised Word-based frequency, vec- RNN and LSTM 0.90 0.87 0.88 62

2018

ism

torization

Fernandez and Twitter

Radicalization Supervised Semantic Context

SVM

.85 .84 .85 12

Alani [45] 2018

Ousidhoum et al. Twitter

Sexual orienta- Supervised BOW

LR, biLSTM - - 94 35

[102] 2019a

tion, Religion,

Disability

Zhang and Luo Twitter

Racism, Sexism Supervised Word embeddings

CNN+GRU

- - 0.94 98

[160] 2019

18

Systematic review of Hate Speech automatic detection

Table 7: Summary of key contributions for non-English language in HS detection.

Author, Year

Platform Language Class

ML

Ap- Features Representation Algorithm

P

RF C

proach

Abozinadah et al. Twitter Arabic Abusive

Supervised Profile and tweet-based fea- Naïve Bayes

0.85 0.85 0.85 40

[4] 2015

tures, bag of words, N-gram,

TF-IDF

Magdy et al. [78] Twitter Arabic Terrorism Supervised Temporal patterns, Hashtags SVM

0.87 0.87 0.87 101

2015

(Pro-ISIS

and Anti-

ISIS)

Kaati et al. [66] Twitter Arabic Terrorism Semi-

Data dependent features and AdaBoost

0.56 0.86 0.86 40

2015

(Support Supervised data independent features.

or Oppose

Jihadism)

Abozinadah [2] Twitter Arabic Abusive

Un-

Lexicon, bag of words SVM

0.96 0.96 0.96 13

2016

Supervised (BOW), N-gram

Abozinadah and Twitter Arabic Abusive

Supervised PageRank (PR) algorithm, SVM

0.96 0.96 0.96 14

Jones Jr [3] 2017

Semantic Orientation (SO)

algorithm, statistical mea-

sures.

Mubarak et al. Twitter, Arabic Abusive, Of- Un-

unigram and bigram, Log Just performed 0.98 0.45 0.60 126

[93] 2017

Arabic

fensive

supervised Odds Ratio (LOR), Seed extrinsic evalua-

News Site

Words lists None.

tion

Haidar et al. [58] Facebook, Arabic Cyber- bul- Supervised Tweet to SentiStrength, Fea- SVM

0.93 0.94 0.92 26

2017

Twitter

lying (Yes,

ture Vector

No)

Abdelfatah et al. Twitter Arabic Violent (Vi- Un-

Sparse Gaussian process la- K-means cluster- 0.56 0.60 0.58 7

[1] 2017

olent, Non- supervised tent variable model, morpho- ing

violent)

logical features Vector Space

Model

Alfina et al. [14] Twitter

Indonesian Hate (Hate , Supervised BOW and n-gram

Random Forest -

-

0.93 57

2017

Non-hate)

Özel et al. [105] Twitter, In- Turkish Hate

Supervised BOW

M-Naïve Bayes -

-

0.79 23

2017

stagram

Alakrot et al. [11] YouTube Arabic Offensive, Supervised N-gram

SVM

0.88 0.80 0.82 25

2018b

In-offensive

Albadi et al. [13] Twitter Arabic Religious Supervised Word embeddings(AraVec) GRU-based

0.76 0.78 0.77 51

Albadi et al. [13]

hate, Not

RNN

hate

Alshehri et al. Twitter Arabic Adult, Reg- Supervised Lexicon, N-grams, bag-of- SVM

0.70 0.93 0.78 9

[15] 2018

ular user

means (BOM)

Jaki

and Twitter

German Radicalization Un-

Skip grams and Character tri- K-means, single- 0.84 0.83 0.84 16

De Smedt [64]

( Muslim, Supervised grams

layer averaged

2019

Terrorist,

Perceptron

Islamo

fascistoid)

Alami et al. [12] Twitter Arabic -

Supervised -

AraBERT

90 -

-

-

2020

Sai and Sharma Twitter Tamil- -

Supervised -

XLM-

TENG -

-

-

[130] 2020

English,

RoBERTa + 90,

Malaylam-

mBERT

MENG

English

77

(Code-

mix

)

Polignano et al. Twitter

Italian -

Supervised -

AlBERTO

90 94 -

-

[116] 2019b

Wang et al. [143] Twitter

English -

Supervised -

XLM-RoBETa 92 -

-

-

2020

Turkish

base and lagre 82

Arabic

90

Danish

81

Greek

83

19

Systematic review of Hate Speech automatic detection

Figure 14: Statistics of previous work based on the percentage of different deep learning algorithms used ( e.g., CNN, LSTM, BERT etc).

Table 8: Algorithms and feature used in the papers related to deep-learning analysis.

Architecture name

Frequencies Architecture nam

Frequencies

Word2Vec + LSTM

6

Word2Vec + CNN

4

RandomEmbedding + LSTM

4

RandomEmbedding + CNN

3

Word2Vec + BiLSTM

2

Word2Vec + CNN + LSTM

4

FAstText + LSTM

4

FastText + CNN

3

FAstText + GRU

4

FastText + GRU

1

FAstText + GRU

4

FastText + GRU

1

AraVec + LSTM

4

AraVec + CNN

3

AraVec +CNN+ LSTM

1

Skip-gram + CNN+LSTM

1

ELMO + CNN

1

BERT + CNN

3

ELMO + BERT

1

SKIP-GRAM + CNN

2

BERT Base

7

BERT Large

8

GloVe+CNN

2

GloVe+GBDT+CNN

1

CNN+CNN+CNN

2

CNN+BiGRU

1

6.3.2 Overview of Deep-learning records
Our systematic review has identified 96 documents related to the application of deep-learning technology/models to the task of automatic hate speech detection. In the sequel, we have analyzed two crucial aspects: the architecture of the deep learning model and the features employed.
Figure 14 summarizes the finding in terms of the percentage of the various deep-learning algorithms employed. Notice that BERT (33%) becomes prevalent though it was only introduced recently in 2019. The next most popular deep-learning models are LSTM and CNN, which covered 20% and 12% of total identified records. Hybrid models (combination of multiple models) depicted in the plot are exemplified by BERT+CNN (2%), LSTM+CNN(9%), LSTM+GURU(1%) and BERT+LSTM(2%).
In Table 8, we tracked different architectures of deep learning employed in the identified records. Surprisingly a total of 24 different deep learning models and feature combinations were found, possibly highlighting the diversity of research's attempts to produce novel architectures building on existing HS detection architectures. Most of the architectures used two steps: (i) word embedding layer employing models such as Word2Vec, FastText, GloVe; (ii) deep learning layer, where one distinguishes, among others, CNN, LSTM, GRU architectures.
20

Systematic review of Hate Speech automatic detection
Figure 15: Statistics of word embedding (e.g., Word2Vec, EELMO, FastText, BERT etc ) in Deep learning related records.
During the course of this analysis, four significant insights are distinguished: I) Comparison between non deep-learning and deep-learning models revealed that deep-learning models outperformed popular classifiers (NB, LR, RF, SVM) in most studies [40] [9] [63] [21]. An early work by Badjatiya et al. [21] has compared HS detection with different ML models (LR , SVM, GBDT) showed that deep learning models using either CNN or LSTM model performed on average 13-20% better that LR, SVM or GBDT models. Another recent work by Al-Hassan and Al-Dossari [9] compared SVM as a baseline model to CNN, CNN+LSTM, GRU, CNN+GRU. The authors found that, in all cases, CNN outperformed the baseline model by at least 7% in terms of accuracy.
II) Comparison between CNN, LSTM, BiLSTM, and GRU models revealed mixed results in terms of which deeplearning architecture performs most. For instance, a comparison between CNN and LSTM architecture showed a better CNN performance results in [63], whereas Badjatiya et al. [21] found that LSTM architecture performs better than CNN. Besides, the difficulty in data full reconstruction, the difficulty to reproduce exact preprocessing stages or use of distinct embedding can render such comparison more challenging. Yin et al. [156] conducted a comparative study between two deep-neural network architectures: "RNN (with GRU and LSTM layers) and CNN". They found that RNN is more suited for the long-ranged context dependencies, while CNN sounds better in extracting local features. They also revealed that GRU performs better in case of long sentences. However, several other papers suggested that the concatenation of two or more deep learning models perform better than a single deep learning model [9] [161] [68] [134] [71]. For example, CNN+LSTM and CNN+GRU both performed better than the single application of LSTM and CNN [9]. Zhou et al. [161] suggested a fusion of three CNN models with different parameters as a viable way to improve the performance of hate speech detection. Kapil and Ekbal [68] compared CNN, LSTM, and LSTM+GRU architectures for HS detection in five commonly used datasets, and concluded that in all cases, LSTM+GRU outperform a single LSTM and CNN model by 2-3%. Similarly, Shruthi and KM [134] proposed a hybrid fusion architecture BiLSTM + Random Embedding + TF-IDF + LR that achieves at least a 12% increase in performance compared to a single architecture. III) Comparison between word embedding revealed a lack of comparative studies in this area as well. However, from Table 8, we can see that Word2vec and FastText were regularly used with different deep learning architectures. Although this popularity does not entail systematically a better performance score. For instance, Saleh Alatawi et al. [131] compared word2Vec, GloVe, and Google NewsVec, and showed that word2Vec performed only 1% better than others. However, when compared to BERT model, BERT-Large showed the best accuracy and F1 score. Another work
21

Systematic review of Hate Speech automatic detection
by Rizos et al. [125] comparing FastText, GloVe and GoogleNewsVec revealed no significance accuracy among these embeddings.
On the other hand, since Word2Vec, FastText, GloVe use a vector representation to represent words in a way that captures semantic or meaning-related relationships as well as syntactic or grammar-based relationships, this also bears inherent limitation in the sense that this cannot capture polysemy relationship. That is, for the same word, even if it has different meanings in different contexts, the corresponding vector representation is unchanged. We shall mention the merits of the recently introduced ELMO word embedding model, which was designed to overcome the aforementioned shortcoming. A recent work by Zhou et al. [161] using ELMO embedding showed a better performance compared to CNN. However, since ELMO is a relatively new, the in-depth comparison with other embedding model is still in its infancy. This leaves the door wide for future experiments
IV) The rise of BERT is a striking trend that can be seen in Figure 15, which testifies of its popularity in hate speech detection community (38% share of deep-learning models) in the past five years. This demonstrates the importance of this model as a key state-of-the-art method in the field. Several works explored BERT performance in HS detection [98] [122] [131] [40] where almost all authors who compared BERT model to other deep learning models concluded on the superiority of BERT architecture. For instance, Ranasinghe et al. [122] compared BERT to FastText, CNN, and LSTM. Similarly, Saleh Alatawi et al. [131] compared BERT to BiLSTM and LSTM where BERT showed a significance performance increase. Also, BERT model achieved top performance in the multilingual tasks in [40] [116] [12] [130] [143].
Some research performed a comparison among different BERT models. For instance, Wang et al. [143] found that BERT-large model outperformed BERT-base model for HS detection. In addition, two different BERT architecture concatenations (e.g., XLMR-B + mBERT) are found to perform better than a single pretrained BERT[130]. Furthermore, BERT architecture can be trained in a such a way that it can perform a specific task. For example, Gonzalez et al. [56] proposed TWiLBERT, a specialization of BERT architecture for the Spanish and Twitter domain. They performed an extensive evaluation of TWilBERT models on 14 different text classification tasks, such as irony detection, sentiment analysis and emotion detection. The results obtained by TWilBERT outperformed the state-of-the-art systems and mBERT. Another work by Caselli et al. [29] introduced HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful. In all cases, HateBERT outperformed the corresponding general BERT model.
Besides, some other language-specific BERTs models developed over time for monolingual outperformed multilingual model mBERT: AraBERT (Arabic) [18], AlBERTo (Italian) [115], FinBERT (Finnish) [19], CamemBERT(French) [83], Flaubert (French [76]), BERT-CRF (Portuguese) [137], BERTje (Dutch) [141], RuBERT (Russian) [74] and BERTtweet (A pre-trained language model for English Tweets) [97]. However, to best of our knowledge, not every model has yet been tested for HS domain except AraBERT [12] [38] and AlBERTo [116] which shown better performance for HS detection.
Table 10 summarizes selected key works from three major recent HS detection competitions SemEval-2019 [158], SemEval-2020 [159], and Hasoc-2020 [81].
In SemEval-2019, Task A (offensive language detection) was the most popular sub-task with 104 participating teams. Among the top-10 teams, seven used BERT with variations in the parameters and in the pre-processing steps. The top-performing team Liu et al. [77] used BERT-base-uncased with default-parameters, but with a max sentence length of 64 and trained for 2 epochs and achieved 82.9% F1 score which was 1.4 points better than Nikolov and Radivchev [98]. Although, the difference between the next five systems, ranked 2-6, is very marginal (less than one percent (81.5%-80.6%)). The top nonBERT model by Mahata et al. [79] was ranked fifth. They used an ensemble of CNN and BLSTM+BGRU, together with Twitter word2vec embeddings and token/hashtag normalization.
In semEval-20, 145 teams submitted official runs on the test data and 70 teams submitted system description papers. The best team Wiedemann et al. [148] achieved an F1 score of 0.9204 using an ensemble of ALBERT models of different sizes. The second team Wang et al. [143] achieved an F1 score of 0.9204, and it used RoBERTa-large that was fine-tuned with the dataset in an unsupervised way. The third team Dadu and Pant [33], achieved an F1 score of 0.9198, using an ensemble that combined XLM-RoBERTa-base and XLM-RoBERTa-large trained on Subtask A data for all languages. The top-10 teams were close to each other and employed BERT, RoBERTa or XLM-RoBERTa models; sometimes CNNs and LSTMs were also been mentioned either for comparison or hybridization purpose.
Over 40 research groups participated in Hasoc-2020 competition. The top ranked submission for Hindi-hate speech detection, used a CNN with FastText embeddings as input [121]. The best performance for German hate speech detection task was achieved using a fine-tuned versions of BERT, DistilBERT and RoBERTa [72]. Similarly, the top
22

Systematic review of Hate Speech automatic detection

Table 9: Summary of some key contributions in HS detection by using Deep learning method and their respective

results, in the metrics: Precision (P), Recall (R), F1-Score (F), Citation (C).

Author, Year

Platform

Type

ML

Ap- Features Representation Algorithm

P RF C

proach

Badjatiya et al. Twitter, 16k

Hate speech Supervised FastText, Random embed- CNN, LSTM, .93 .93 .93 503

[21] 2017

ding, GloVe

GBDT

Yin et al. [156] -

-

Supervised

CNN, GRU and .94 - - 534

2017

LSTM

Rizos et al. [125] Twitter, 24k

Hate speech Supervised FastText, Word2Vec, GloVe CNN, LSTM, - - .69 20

2019

GRU

Kamble and Joshi Twitter, 3.8k

Hate speech

Supervised Word2Vec

LSTM, BiL- .83 .78 .80 14

[67] 2018

STM, CNN

Ranasinghe et al. Twitter,

Hate speech Supervised FastText

LSTM, GRU, - - .78 16

[122] 2019

BERT

Faris et al. [44] Twitter, (Arabic) Hate speech Supervised Word2Vec, Aravec

CNN+LSTM .65 .79 .71 3

2020

Al-Hassan and Al- Twitter, 11k Hate, Racism, Supervised Keras word embeding

LSTM,GURU, .72 .75 .73 0

Dossari [9] 2021, (Arabic)

Sexism

CNN+GRU,

Springer

CNN+LSTM

Duwairi et al. [42] Twitter, 9k,2k Hate,

Supervised SG, CNN, CBOW

CNN, CNN- .74 - - 0

2021, Springer (Arabic)

Hate, Abu-

LSTM, and

sive,Misogyny,

BiLSTM-CNN

Racism, Reli-

gious Discrimi-

nation,

Dowlagar and Twitter,(English, Hate, Offensive Supervised ELMO

BERT,

.83 - 83 2

Mamidi [40] German, Hindi)

Multilingual-

2021, arXiv

BERT

Sigurbergsson Twitter, Reddit, Hate, Offensive, Supervised -

AUX-Fast-

- - .67 53

and Derczynski newspaper com- Not,

Tar-

BiLSTM

[135] 2019

ments (Danish) get,Individual,

Group

Ousidhoum et al. Twitter

Sexual orienta- Supervised BOW

LR, biLSTM - - 80 35

[102] 2019a

tion, Religion,

Disability, Tar-

get Group

Mulki et al. [94] Twitter

Abusive, Hate Supervised -

CNN

and .74 - - 29

2019

BiLSTM-CNN

Table 10: Best architecture from previous competition and their respective results, in the metrics: Precision (P), Recall

(R), F1-Score (F), Citation (C).

Organiser

Author, Year

Platform

Language

Features Rep- Algorithm

F1 (%) C

resentation

SemEval-19 Task 6 Liu et al. [77], 2019 Twitter 14k

English

-

LSTM, BERT

82.9 70

SemEval-19 Task 6 Nikolov and Radi- Twitter 14k

English

-

NB, CNN, LR, SVM, 81.5 35

vchev [98], 2019

BERT-Large

SemEval-19 Task 6 Mahata et al. [79], Twitter 14k

English

Word2vec

CNN,

80.6 70

2019

BLSTM+BGRU

SemEval-20 Task 12 Wiedemann et al. Twitter, 14k

English

-

BERT-base, BERT 92

5

[148], 2020

large, RoBERTa,

XLM-RoBERTa,

ALBERT

SemEval-20 Task 12 Wang et al. [143], Twitter, 14k

English

-

XLM-RoBERTa base, 91.9 1

2020

XLM-RoBERTa

large

SemEval-20 Task 12 Dadu and Pant [33], Twitter, 14k

English

-

XLM-RoBERTa

91.8 1

2020

HASOC2020

Mishraa et al. [89], Twitter

English

GloVe

LSTM

51

0

2020

HASOC2020

Kumar et al. [72], Twitter

German

-

BERT, DistilBERT 52

0

2020

and RoBERTa

HASOC2020

Raja et al. [121], Twitter

Hindi

FasText

BiLSTM, CNN

52

0

2020

23

Systematic review of Hate Speech automatic detection
Figure 16: Number of Datasets from different Language and Social Media.
performance in English-language HS detection was based on a LSTM architecture with GloVe embeddings as input [89].
7 Resources for hate speech detection
In the conducted literature review, several useful resources were identified. In this section, we represent the datasets and open source projects.
7.1 Hate speech available datasets Regarding the datasets, we found 69 datasets in 21 different languages. In this section, we summarize the most used dataset attributes and statistics in Tables 11 and 12. This includes dataset names (some names are based on papers title), publication year, dataset source link 16, dataset sizes, the ratio of offensive contents, the class used for annotation, and datasets' language. We noticed that many authors collected their datasets from social media and then annotated them manually based on task requirements. Several annotations have been carried out with experts [146] [160] [73], native speakers [49], volunteer [144], or through crowd-sourcing from anonymous users [34][153][158]. Below we present the primary findings of this analysis. I) Datasets language and platform: Among 69 datasets of 21 different languages, see Figure 16], English dominates by far others, representing 26 datasets alone. However, Arabic, German, Hind-English, Indonesian and Italian are represented in a total of 6, 3, 4, 4 and 5 open datasets, respectively. The rest of the languages have low presence in this set of open dataset. All datasets were collected from different social media platforms (Twitter, Facebook, Youtube, etc.), with exception to Chung et al. [32]'s dataset where some portion were synthetically produced. Twitter is shown to be the most popular platform for collecting hate speech datasets (45% of total datasets were collected from Twitter). Facebook is the second most popular source. The rest of the SM has only been used few times. An interesting code-mixed dataset by Mathur et al. would be an example for targeting users who are active in SM and use the mixed form of language. This dataset has highlighted the predominance of Hindi­English code­mixed data representing the large spread of mixed forms and Hindi words written in Latin script in a non-formal online communication among Indians SM users. Similar code-mixed dataset work is also done in Tamil-English and Malayalam-English using BERT, which achieved a 90% F1 score [130]. (II) Datasets sources: Most of the dataset source repositories are available on GitHub. Therefore, nearly all datasets were publicly available. However, those dataset collected from Twitter have only Twitter Id instances which should be used to retrieve the full tweet messages. Since many tweets might be deleted over time, one may expect that the reconstruction of the full dataset may not be possible. (III) Annotation classes: Figure 17 illustrates the diversity of annotations in the original datasets (e.g., hate, offensive, race, gender, sexism, misogyny, toxicity, group. target, political, etc.). This diversity of annotations translates the variety of hate speech categories and the academic willingness to explore this rich panorama. However, from Tab. 11 and 12, one notices that most of these annotations were based on binary classification (e.g., hate versus non-hate, racism versus non-racism, etc.) [13] [10][132] [25][124][119][43] [26][128][49]. Ternary class levels as well (e.g., Hate, Abusive,
16All datasets' link last access was on 03-march-2021
24

Systematic review of Hate Speech automatic detection
Figure 17: Number of Classes used for annotation.
Figure 18: Statistics of dataset size. k represent thousand.
Normal) are explored in [94] [93][146][153][102]. Some authors used a larger number of classes and sub-classes (up to six) as in [103][158][82][123][26]. In summary, one can distinguish three strategies of annotation scheme. The first one is a binary scheme: two mutually exclusive events (typically yes/no) to mark the presence or absence of HS (or a category of HS). The second one advocates a non-binary scheme with a fixed number of mutually exclusive classes, accounting either for different shades of a given HS category, such as strong hate, weak hate, no hate [111], overtly aggressive, covertly aggressive, not aggressive [73], or for several classes at the same time, such as racism, sexism, racism and sexism, none [146]. The third strategy features multi-level annotation, with finer-grained schemes accounting, for instance, for the type of hate speech, its severity, and the target group. This is the most complex annotation scheme and typically involves several different traits and a scale of variation. For example, Gomez et al. distinguish between racist, sexist, homophobic, religion-based attack, as well as the community targeted by the attack in the annotation process. Nobata et al. [99] discriminate between clean and abusive language, where abusive is labeled as hate speech, derogatory or profane. Basile et al. [24] adopt a three-layer binary annotation for HS, aggressiveness, and nature of the target (individual or group). (IV) Dataset size and ratio of abusive contents: Figure 18 and 19 show the statistic of dataset size and the ratio of offensive content, respectively. We can see 41% of datasets are relatively of a small size (only (0-5)k posts). 14% have (5-10)k sentences. Therefore, most of the dataset (55%) can be cast into a very small size category, indicating the challenges behind acquiring large-scale labeled data for hate speech detection purpose. On the other hand, we have not found any balance dataset. This can lead to overfitting and harm generalisability, especially for deep learning models [57]. Another critical factor that may affect the training process of the model is the ratio of classes. In this regards, we noticed a high number (37%) of the datasets contain significantly less than 20% of offensive content. However, the rest of the datasets ( 63%) have more than 20% offensive content, which could be considered as decent for training purposes.
25

Systematic review of Hate Speech automatic detection
Figure 19: Statistics of the proportion of abusive content contained in hate speech dataset.
(V) Number of Citations17: We collected the number of citations for each dataset source document in Google Scholar and concluded that most dataset sources were cited more than 50 times (Figure 20). Davidson et al. [34] is the most cited papers that have presented a dataset of 24802 tweets, which are manually annotated by CrowdFlower (CF) workers. Workers were asked to label each tweet as one of three categories: hate speech, offensive but not hate-speech, or neither offensive nor hate speech. Three or more people participated in each tweet annotation process. They have used the majority decision for each tweet to assign a label. This dataset has only 6% hate speech, 76% offensive but non-hate, and the rest of the tweets were neutral. The second most cited dataset created by Waseem and Hovy [146] contains 16,914 tweets where 3,383 are related to sexist, 1,972 to racist, and 11,559 to neither sexist nor racist. The authors manually annotated their dataset, after which it was sent to an outside annotator (a 25 year old woman studying gender studies and a nonactivist feminist) to review their annotation. The above two popular datasets provide some insights into the dataset annotation process and criteria. We also noticed that the citation index does not reflect the quality of the dataset itself, but rather its ease and simplicity, which motivated other researchers to test such dataset in their proposals. There could be many possible factors that may represent the quality of a dataset (e.g., annotation criteria, label definitions, understanding perception, dataset size, the ratio of classes). However, we do not have sufficient experimental evidence to compare these dataset quality indices across various HS domains. To the best of our knowledge, only one study found in our search attempted to estimate the quality metrics and the similarity between datasets. In this respect, Fortuna et al. [47] compared the categories across the annotated dataset with respect to both similarity to other categories and homogeneity. For this purpose, average FastText embedding pretrained on Wikipedia was used to represent each category, while intra-dataset class homogeneity index has been put forward to assess category homogeneity. One of their observations is that Davidson's [34] "hate speech" is very different from Waseem's [146] "hate speech", "racism", "sexism", while being relatively close to Basile's HS dataset [24]. One of the main conclusions of their experiments is that many different definitions are being used for equivalent concepts, which makes most of the publicly available datasets incompatible.
17All citations last updated on 03-Mar-2021 26

Systematic review of Hate Speech automatic detection

Figure 20: Number of citations of reference papers of dataset.

Name Hate Speech and Offensive Language

Hate Speech Dataset

Predictive Features for Hate Speech Detection Hate Speech Detection Fox news comments Hate Speech Twitter annotations Sexism using twitter data

Misogyny Identification at

IberEval 2018

CONAN

Multilingual

Dataset of Hate Speech

Characterizing and Detecting

Hateful Users

Online Hate Speech (Gab)

Online Hate Speech (Reddit)

Multilingual and Multi-

Aspect Hate Speech

HS Detection in Multimodal

Publications

SemEval-2019 Task 6
Multilingual Detection of HS Against Immigrants and Women Peer to Peer Hate
HASOC-2019 (English)
Twitter Abusive Behavior Online Harassment
Personal Attacks
Toxicity
Cyberbullying (World of Warcraft) Cyberbullying (League of Legends) Lexicon for Harassment
Aggression and Friendliness

Table 11: Datasets for Hate Speech Detection for English.

Year Link

Platform Size Ratio Class

2017 GitHub Twitter

24,802 .06 Binary (hate speech, offensive but

not hate speech, or neither offensive

nor hate speech)

2018 GitHub Stormfront 9,916 .11 Hate, Relation, Not

2016 GitHub Twitter 16,914 .32 Sexist, Racist, Not

2017 GitHub Fox News 1528 0.28 Binary (Hate / not)

2016 GitHub Twitter 4,033 0.16 Racism, Sexism

2016 GitHub Twitter 712 1

Sexism

2016 GitHub Twitter

3,977 0.47 Sexism

2019 GitHub 2018 GitHub

Synthetic, 1,288 1

Islamophobia

Facebook

Twitter 4,972 0.11 Hate, Not hate

2019 2019 2019

GitHub GitHub GitHub

2020 GitHub

2019 Link 2019 Link

GAB Reddit Twitter Twitter
Twitter Twitter

33,776 0.43 22,324 0.24 5,647 0.76 149,823 0.25
14,100 0.33 13,000 0.4

Hate, Not hate Hate, Not hate Gender, Sexual orientation, Religion, Disability No attacks to any community, Racist, Sexism, Homophobia, Religion-based attack, Attack to other community Offensive, Not Offensive, Target, Not Target, Individual, Group, Othe Hate, Not Hate, Group, Individual, Aggression, Not Aggression

2019 GitHub Twitter

27,330 0.98 Hate, Not Hate

2019
2018 2017
2017

GitHub
Link Not available GitHub

Twitter, Facebook Twitter Twitter
Wikipedia

7,005 0.36
80,000 0.18 35,000 0.16
115,737 0.12

Hate, Offensive , Neither, Profane, Targeted, Not Targeted Abusive, Hateful, Normal, Spam Harassment, Not Harassment
Personal attack, Not Personal attack

2017 GitHub Wikipedia 100,000 NA very toxic, neutral, very healthy

2016 GitHub 2016 GitHub 2018 GitHub 2017 GitHub

World of 16,975 .01

Warcraft

League of 17,354 0.01

Legends

Twitter

24189 0.01

Wikipedia 160,000 NA

Harassment, Not Harassment
Harassment, Not Harassment
Racism, Sexism, Appearancerelated, Intellectual, Political Very aggressive, Neutral, Very friendly

Ref., Citation Davidson et al. [34], 965
de Gibert et al. [51], 83 Waseem and Hovy [146], 680 Gao and Huang [49], 84 Waseem [145], 243
Jha and Mamidi [65], 59 Jha and Mamidi [65], 59 Chung et al. [32], 31
Ribeiro et al. [124], 100 Qian et al. [119], 82 Qian et al. [119], 82 Ousidhoum et al. [102], 41 Gomez et al. [55], 28
Zampieri et al. [157], 235 Basile et al. [23], 127
ElSherief et al. [43], 66 Mandl et al. [82], 120
Founta et al. [48], 167 Golbeck et al. [54], 83 Wulczyn et al. [153], 347 Wulczyn et al. [153], 347 Bretschneider and Peters [26], 6 Bretschneider and Peters [26], 6 Rezvan et al. [123], 19 Wulczyn et al. [153], 347

27

Systematic review of Hate Speech automatic detection

Table 12: Hate speech datasets and Corpus for Arabic, German, Danish, French, Indonesian, Italian, Bengali, Urdu,

Russian and Hindi.

Name

Year Link Platform Size Ratio Class

Lang.

Ref.

Abusive Language Detection 2017 Link Twitter 1,100 0.59 Obscene, Offensive but not obscene, Arabic

Mubarak et al. [93],

on Arabic Social Media

Clean

128

Abusive Language Detection 2017 Link AlJazeera 32,000 0.81 Obscene, Offensive but not obscene, Arabic

Mubarak et al. [93],

on Arabic Social Media

Clean

128

Religious Hate Speech in the 2018 GitHub Twitter 16,914 0.45 Hate, Not hate

Arabic

Albadi et al. [13], 53

Arabic

Anti-Social Behaviour in On- 2018 Link YouTube 15,050 .39 Offensive, Not Offensive

Arabic

Alakrot et al. [10], 26

line Communication

Multi-Aspect Hate Speech 2019 GitHub Twitter 3,353 0.64 Gender, Sexual orientation, Reli- Arabic

Ousidhoum et al.

Analysis

gion, Disability

[102], 41

Arabic Levantine Hate- 2019 GitHub Twitter 5,846 .38 Hate, Abusive, Normal

Arabic

Mulki et al. [94], 34

Speech Dataset

European Refugee Crisis 2017 GitHub League of 469 NA Anti-refugee hate, Not Hate

German

Ross et al. [129], 219

Legends

Offensive Statements To- 2016 GitHub Facebook 5,836 0.11 slightly offensive, explicitly offen- German

Bretschneider and Pe-

wards Foreigners

sive. targets (Foreigner, Govern-

ters [27], 21

ment, Press, Community, Other, Un-

known)

GermEval 2018

2016 GitHub Twitter

8,541 0.34 Offense, Other, Abuse, Insult, Pro- German

Wiegand et al. [150],

fanity

152

HASOC-2019 (German)

2019 GitHub Twitter, 4,669 0.24 Hate, Offensive, neither, Hate, Of- German

Mandl et al. [82], 120

Facebook

fensive, or Profane

Offensive Language and 2019 GitHub Twitter, 3,600 .12 Offensive, Not, Within Offensive Danish

Sigurbergsson and

Hate Speech Detection for

Reddit,

(Target, Not), Within Target (Indi-

Derczynski [135], 54

Danish

newspaper

vidual, Group, Other)

comments

CONAN HS French

2019 GitHub Synthetic, 17,119 1

Islamophobic, not Islamophobic French

Chung et al. [32], 31

Facebook

MLMA hate speech

2019 GitHub League of 4,014 0.72 Gender, Sexual orientation, Reli- French

Ousidhoum et al.

Legends

gion, Disability

[102], 41

Offensive Language Identifi- 2020 GitHub Twitter 4779 0.01 Offensive, Not, Target, Not, Individ- Greek

Pitenis et al. [112], 41

cation in Greek

ual, Group, Other

HS in Indonesian Language 2017 GitHub Twitter 713 0.36 Hate, Not Hate

Indonesian Alfina et al. [14], 62

HS and Abusive Language in 2019 GitHub Twitter 13,169 0.42 No hate speech, No hate speech Indonesian Ibrohim and Budi

Indonesian Twitter

but abusive, Hate speech but no

[61], 34

abuse, Hate speech and abuse, Re-

ligion/creed, Race/ethnicity, Physi-

cal/disability, Gender/sexual orienta-

tion, Other invective/slander, within

hate, strength (Weak, Moderate and

Strongt)

Preliminaries Study for Abu- 2016 GitHub Twitter 2,016 0.54 Not abusive, Abusive but not offen- Indonesian Ibrohim and Budi

sive Language

sive, Offensive

[60], 37

An Italian Twitter Corpus 2018 GitHub Twitter 1,827 0.13 Immigrants, Not

Italian

Sanguinetti et al.

[132], 77

Hindi-English Code-mixed 2018 GitHub Facebook 21,000 0.27 None, Covert Aggression, Overt Hindi, En- Kumar et al. [73], 75

Data

Aggression, Physical threat, Sex- glish

ual threat, Identity threat, Non-

threatening aggression, Attack, De-

fend, Abet

Hindi-English Code-mixed 2018 GitHub Facebook 18,000 0.06 None, Covert Aggression, Overt Hindi, En- Kumar et al. [73], 75

Data

Aggression, Physical threat, Sex- glish

ual threat, Identity threat, Non-

threatening aggression, Attack, De-

fend, Abet

Offensive Tweets in Hinglish 2018 GitHub Twitter 3,189 0.65 Not Offensive, Abusive, Hate

Hindi, En- Mathur et al. [85], 34

Language

glish

A Dataset of Hindi-English 2018 GitHub Twitter 4,575 0.36 Hate, Not

Hindi, En- Bohra et al. [25], 56

Code-Mixed

glish

HASOC-2019 (Hindi)

2016 GitHub Twitter, 5,983 0.51 Hate, Offensive or Neither, Profane, Hindi, En- Mandl et al. [82], 120

Facebook

Targeted or Untargeted

glish

Bengali HaS Dataset

2020 GitHub Facebook, -

-

Personal, Political, Religious, Bengali

Karim et al. [69], 4

YouTube,

Geopoitical and Gender abusive

Wikipedia,

hate

news-

articles

Russian Dataset

2020 GitHub -

-

-

-

Russian and Andrusyak et al. [17],

Ukrainian 4

Roman Urdu

2020 GitHub -

-

-

-

Urdu

Rizwan et al. [126], 3

28

Systematic review of Hate Speech automatic detection
Figure 21: Word cloud representation of GitHub open source projects.
Figure 22: GitHub open source projects programming language. 7.2 Open source projects We checked if there are any open-source projects available for hate-speech automatic detection or can be used as examples or sources for annotated data. For this, we carried out a search on GitHub repository with the search query "hate speech" in the available search engine. We found 1039 repositories, and only 53 were regularly forked and updated. Since this is a large number of repositories, it was challenging to include all of them in this paper and comment on them individually. Therefore, we have restricted to the 15 top-ranked one. Furthermore, we have exported the project repository names and descriptions into a CSV file for word cloud representation, which may help us understand the content of these open source projects in terms of the provided description. Table 13 shows some highly cited HS detection papers source code. For example, Davidson et al. used Twitter dataset with TF-IDF, n-gram feature and LR-SVC model architecture. Furthermore, we have found the source code of Badjatiya et al. which used FastText and CNN, and LSTM models, achieving 78% F1 score and 85% accuracy. Furthermore, a new Korean dataset found in highly 'forked' GitHub repository claimed to be the first human-annotated Korean corpus for toxic speech detection and sizeable unlabeled corpus (Tab. 13, Index 2). Another interesting repository named "Hate_sonar" used the BERT approach and the dataset in Davidson et al.. It created an easily installable python library, which anyone can use for their test project without having any coding skill.
29

Systematic review of Hate Speech automatic detection Furthermore, some highly 'started' and 'forked' works appeared mainly relevant to sentiment analysis; namely TextBlob, VaderSentiment and Transformer. Here, the Transformer provides thousands of pre-trained models (mainly BERT) to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, text generation, and sentiment analysis [152]. Figure 21 shows the word cloud representation of the identified GitHub project descriptions. The illustration indicates the high proportion of words such as hate speech, hateSpeech, speech hate, hateful meme, cyberbullying offensive language, and toxic comment in the repositories related to HS detection. Furthermore, Twitter, tweet, Twitter hate, Reddit, and other social media were also present in this illustration, although with less intensity compared to hate detection related wording. Similarly, deep-learning methods such as BERT, LSTM, CNN, where the increased popularity of BERT is more emphasized. Surprisingly, this is in a full agreement with the literature review as well, where BERT was found to be a dominant trend in deep-learning methods. Among the fifteen top forked repositories, four projects were linked to BERT based model. The connection between hate speech and sentiment analysis is also stressed in Fig. 21, as well as the growing interest in non-English HS detection through wordings like multilingual, Indonesian, Hindi, indicating repositories for multilingual HS detection tasks. Regarding the programming languages employed, we noticed that most of the projects (88%) were developed in Python language, while others used JavaScript (4%), Java (2%), HTML and CSS (4%), and three projects with GO (Fig. 22).
30

Systematic review of Hate Speech automatic detection

Table 13: Fifteen most popular GitHub open source projects.

Repository Name Github Link Focus

Publication Features

Ref., Year

Represen-

tation

1. Hate speech and of- Link, Source Twitter 25k dataset used for HS detection.

Davidson et al. TF-IDF,

fensive language

code given

[35], 2017b n-gram,

bi-gram

2. Korean Hate- Link, Dataset The first human-annotated Korean corpus for Moon et al. -

Speech Dataset

source code toxic speech detection and the large unlabeled [92], 2020b

given but corpus. The data is comments from the Korean

project source entertainment news aggregation platform.

code not

available.

3. Twitter hatespeech Link, source Implementation of paper - "Deep Learning for Badjatiya et al. Fasttext,

code avail- Hate Speech Detection"

[21], 2017

BOW

able.

4. Hate sonar

Link, Install HateSonar allows you to detect hate speech and Davidson et al. -

$ pip install offensive language in text, without the need for [34], 2017a

hatesonar

training. There's no need to train the model.

You have only to fed text into HateSonar. It

detects hate speech with the confidence score.

5. Hate speech Link, Source These files contain text extracted from Storm- de Gibert et al. -

dataset

code available front, a white supremacist forum. A random [52], 2018b

set of forums posts have been sampled and n

manually labelled as containing hate speech or

not.

6. Dataset for Learn- Link, Only HS intervention along with two fully-labeled

-

ing to Intervene

dataset avail- datasets collected from Gab and Reddit. Dis-

able

tinct from existing hate speech datasets, their

datasets retain their conversational context

and introduce human-written intervention re-

sponses.

7. HateXplain

Link, dataset Multilingual multi-aspect hate speech analysis Mathew et al. -

and soruce dataset

[84], 2020

code avail-

able, Install:

pip install

-r require-

ments.txt

8. MLMA hate Link, dataset Multilingual multi-aspect hate speech analysis Ousidhoum -

speech

and soruce dataset

et al. [103],

code available

2019b

9. Korean Hate Link, dataset This hate speech detection model trained on 2020

-

Speech

and soruce kocohub/korean-hate-speech

code available

10. likers-blocker

Link, Browser Block hate promoter twitter suer

2021

-

addon

11. Twitter Hate Link, dataset project analyzed a dataset CSV file from Kag- 2020

BOW,

Speech Detection

and soruce gle containing 31,935 tweets.

TF-IDF

code available

12. Korean hate Link, dataset Recurrent Neural Network based Hate Speech 2020

speech language mod- and soruce Language Model for Korean Hate Speech De-

eling

code available tection

13. TextBlob

Link, soruce TextBlob is a Python library provides a simple 2021

code available, API for diving into common natural language

install: pip processing (NLP) tasks such as part-of-speech

install -U tagging, noun phrase extraction, sentiment anal-

textblob

ysis, classification, translation, and more

14. vaderSentiment Link, soruce VADER is a lexicon and rule-based sentiment 2021

code available, analysis tool that is specifically attuned to sen-

install: pip in- timents expressed in social media.

stall vaderSen-

timent

15. Transformers

Link, soruce Transformers provides thousands of pre-trained Wolf et al.

code avail- models to perform tasks on texts such as clas- [152], 2020

able, install: sification, information extraction, question an-

pip install swering, summarization, translation, text gen-

transformers eration, sentiment analysis

Algorithm Star Fork

LR, SVC 545 217

-

195 12

CNN, LSTM
BERT

182 75 119 23

68 38

40 7

BERT

39 8

LR

35 3

BERT

34 4

28 0 LR, NB, RF 26 16

RNN

26 16

7.6k 1k

2.9k 767

BERT, AL- 29k 8.7k BERT

31

Systematic review of Hate Speech automatic detection
8 Research challenges and opportunities
The above literature review for deep learning and non-deep learning and resource analysis summarized the main research in the field of HS automatic detection from textual inputs. At the same time, we have also identified several challenges and research gaps (Table 14) from previous research.
8.1 Open Source Platforms or Algorithms:
There are indeed many open-source projects available related to HS. However, only few project source codes are available from well-known publications. From the 1039 projects in GitHub, we have only found 53 projects regularly maintained and forked, which may question the usability and source code quality of the rest of the projects. More sharing of code with a clear documentation, algorithms, processes for feature extraction, and open-source datasets can help the discipline evolves more quickly.
8.2 Language and System Barriers
Language evolves quickly, particularly among young populations that frequently communicate in social networks, demanding continuity of research for HS datasets. For instance, online platforms are removing hate contents manually and automatically 18 19. However, those who spread HS content will always try to develop a new way to evade and by pass any system imposed restriction. For example, some users do post HS content as images containing the hate text, which circumvent some basis automatic HS detection. Although image to text conversion might solve some particular problem, still several challenges arise due to limitation of such conversation as well as existing automatic HS detection. Besides, changing the language structure could be another challenge, for example, through usage of unknown abbreviations and mixing different languages, e.g., i) Writing part of a sentence in one language and the other part in another language; (ii) Writing sentence phonetics in another language (e. g., writing Hindi sentences using English).
8.3 Dataset:
. There are no commonly accepted datasets recognized as ideal for automatic HS detection task. Authors annotate dataset differently based on their understanding and tasks requirement. For instance, Figure 17 highlights 47 different annotation labels from 69 datasets, which stress on the diversity of the existing datasets. Besides, 55% of the available datasets' sizes are small and contain a tiny portion of hate content. Many datasets were annotated through crowd-sourcing, which may also question the knowledge of the annotator.
Clear label definitions. There is a prerequisite to have a clear label definition, separating HS from other types of offensive languages [34] [48]. Indeed, dataset can cover a broader spectrum targeting multiple fine-grained HS categories (e.g., sexism, racism, personal attacks, trolling, cyberbullying). This can be performed through either multi-labelling approach, although one notices the presence of ambiguous cases as in Waseem's racism and sexism labels, or in a hierarchical manner as in Basile et al.'s and Kumar et al.'s work on subtypes of HS and aggression, respectively.
Annotation quality. The offensive nature of hate speech and abusive language makes the grammatical structure and cross-sentence boundaries loose, leading to challenging annotation criteria [99]. Therefore, hate speech datasets should be constantly updated according to newly available knowledge. For instance, Poletto et al. found that only about two-thirds of the existing datasets report inter-annotator agreement, guidelines, definitions, and examples. To ensure a high inter-annotator agreement, extensive instructions and the use of expert annotators are required. Furthermore, 98% of the datasets were collected from social networks and labeled manually. Only limited work was directed towards (artificially) dataset creation and enrichment of existing datasets.
8.4 Comparative Studies
From Fig. 12, we identified 24 different hybridization schemes in deep-learning models. However, extensive and comprehensive comparative studies where different approaches are genuinely contrasted and compared were very missing. This leave the door widely open to future comprehensive comparative HS studies in terms of data preprocessing, feature engineering, model training and evaluation.
In addition, little to none work has been found focusing on the labelling issue taking into account the model organization of the individual/group targeted by the HS post, building from advances in social psychology theory and human
18https://about.fb.com/news/2021/02/update-on-our-progress-on-ai-and-hate-speech-detection/ 19https://blog.twitter.com/en_us/topics/company/2019/hatefulconductupdate.html
32

Systematic review of Hate Speech automatic detection computer interaction research. This creates a gap in the practicality of the automatic detection HS developed models as well as on the comparison analysis. This also raises many questions about how the underlined HS detection technique would impact real users' experience and the accuracy of the model compared to human moderation. To answer this question, more interdisciplinary studies and collaboration with organizations are needed. Besides, comparison between various training approaches, debiasing approaches, overfitting models, and what characteristics of the datasets interact with the effectiveness would be worth investigating. For example, when performing transfer learning, the trade-off between domain-specificity, linguistic patterns, and underlying sentiment of hate speech can be considered before model design, feature extraction and preprocessing. 8.5 Multilingual Research As previously pointed out, 50% of HS studies, datasets, and open source projects were provided in English language. Although, we noticed arise in some other non-English resources as well, as in Arabic where AraVec word embedding showed some popularity, there is a scarcity in the development of other non-English NLP resources. Although, we have identified 21 different language HS related works, which creates an opportunity to develop enhanced NLP tools for these languages.
33

Systematic review of Hate Speech automatic detection

Research question Q1: What are the specificities among different HS branches and scopes for automatic HS detection from previous literature?

Table 14: Review of Gaps and future research agenda.

Gap in literature

Future Research Agenda

G1: Discrepancy and frag- - How to develop a common framework for researchers which

mentation of knowledge will be helpful for domain adaptation?

among different domain

- How we can clarify all the concepts and definitions that will be

helpful to obtain high quality and comparable resources?

- How effectively take into account the specificities related to

language and culture, and work towards preventing HS?

Q2: What is the state of deep learning in automatic HS detection in practice?

G2: Multilingual resources.
G3: Comparative study among different deep learning algorithms and related resources.

- Development of NLP resources for other languages (e.g., multilingual sentiment feature, dataset, word embedding, etc.) would leverage HS detection for other languages. - Which existing deep learning models, features, and what characteristics of the datasets are more efficient in tackling HS detection? - What approaches could be used to make the model less biased against specific terms or language styles, from the perspectives of training data or objective. More systematic comparisons between debiasing approaches would be favorable.

Q3: What is the state of the HS datasets in practice?

G4: Model application and impact
G5: Dataset annotation

- Use of deep-learning architecture to create NLP resources which are currently developed with non-deep learning methods that will leverage HS detection. - Can automatic deep-learning models practically aid human moderators in content moderation? In that case, how can human moderators or organizations make use of the outputs feature analysis most effectively? Would that introduce more bias or reduce bias in the content moderation process? What would the impact be on the users of the platform? To answer these questions, interdisciplinary study and collaboration with organizations are needed. - How to avoid the risk of creating data that are biased or too much related to a specific resource? - Development of data-driven taxonomy that highlights how different types of HS datasets concepts are linked and how they differ from one another? - How to deal with the discrepancy of data and error analysis of human annotation issued for previous literature? - How to develop a standard form of annotation guideline? - What type of and how much training or instruction is required to match the annotations of crowdworkers and experts?

- Develop new methods or algorithms for artificial HS

G6: Dataset augmenta- dataset creation and expand the semantic meaning of existing

tion tools and techniques

datasets that will help to create a large-scale balanced dataset.

34

Systematic review of Hate Speech automatic detection
9 Conclusion
In this survey, we presented a critical overview of how the automatic detection of hate speech in the text has evolved over the past few years. Our analysis also included other hate speech domains, e.g., cyberbullying, abusive language, discrimination, sexism, extremism and radicalization. We initially reviewed existing surveys in the field. We found few recent systematic literature reviews related to HS detection, which are shown to be insufficient to summarize the current state of research in the field. Next, we carried out a systematic literature review from Google scholar and ACM digital library databases for all documents related to hate speech published between 2000 and 2021. A total of 463 articles are found to match PRISMA inclusion and exclusion criteria. The findings indicate that initially SVM algorithm and various types of TF-IDF features were the most widely used. However, after the advancement in deep-learning technology, a rapid change in the hate speech analysis methods was observed. The research community preferred to use different kinds of word embedding with CNN and RNN architectures. From 2017 to 2021, several comparative studies have shown the merits of deep-learning models including CNN, RNN using word2Vec, GloVe, FastText, among other embedding as compared to traditional machine learning models such as SVM, LR, NB, and RF models. Nevertheless, comparison among deep learning models is still in its infancy. For instance, mixed results were obtained when comparing CNN to RNN models. Though some authors opined RNNs are more suited for the long-ranged context, while CNN seem useful in extracting features and GRU is found to be more suited for long sentences. Besides, multiple papers suggested that the concatenation of two or more deep learning models performed better than using a single deep learning model. For example, CNN+LSTM and CNN+GRU both performed better than the single application of LSTM and CNN.
Similarly, the comparison of different word-embedding models, e.g, FastText, Word2Vec, GloVe, showed a close performance; however, ELMO performed slightly better than others. Though the work related to ELMO is meager, which leaves the door open for further comparative studies. After introducing contextual relations-based model BERT in 2018, several works claimed BERT's outperforming ELMO, CNN and RNN models. After comparing the best HS detection architecture from Semeval-2019, Semeval-2020 and the HASOC-2020 competitions, BERT-based model was also ranked top among other deep-learning models.
In the final part, we analyzed 69 hate speech datasets. The existing works presented several obstacles for dataset preparation. In general, researchers tend to start by collecting and annotating new comments from SM or using previous datasets. Often, retrieving an old dataset from Twitter is not always fully possible due to tweets' potential removal. This slows down the research's progress because less data is available, making it more challenging to compare different studies' results. Several limitations are found when scrutinizing statistics of past dataset. Significantly, most of the dataset sizes were small, lack the ratio of hate content, and lack label definitions and inter-annotator agreements. Besides, only a fraction of two datasets were synthetically made, which leaves room for artificially dataset creation, augmentation, and enrichment. Finally, we identified the main challenges and opportunities in this field. This includes the scarcity of good open-source code that is regularly maintained and used by the society, the lack of comparative studies that evaluate the existing approaches, and the absence of resources in non-English experiments. With our work, we summarized the current state of the automatic HS detection field. Undoubtedly, this is an area of profound societal impact and with many research challenges.
Acknowledgments
This work is supported by the European Young-sters Resilience through Serious Games, under the Internal Security Fund-Police action:823701-ISFP-2017-AG-RAD grant, which is gratefully acknowledged.
References
[1] Abdelfatah, K.E., Terejanu, G., Alhelbawy, A.A., 2017. Unsupervised detection of violent content in arabic social media. Comput. Sci. Inf. Technol.(CS IT) , 1­7.
[2] Abozinadah, E.A., 2016. Improved micro-blog classification for detecting abusive arabic twitter accounts. International Journal of Data Mining & Knowledge Management Process (IJDKP) Vol 6.
[3] Abozinadah, E.A., Jones Jr, J.H., 2017. A statistical learning approach to detect abusive twitter accounts, in: Proceedings of the International Conference on Compute and Data Analysis, pp. 6­13.
[4] Abozinadah, E.A., Mbaziira, A.V., Jones, J., 2015. Detection of abusive accounts with arabic tweets. Int. J. Knowl. Eng.-IACSIT 1, 113­119.
[5] Agarwal, S., Sureka, A., 2015. Using knn and svm based one-class classifier for detecting online radicalization on twitter, in: International Conference on Distributed Computing and Internet Technology, Springer. pp. 431­442.
35

Systematic review of Hate Speech automatic detection
[6] Ahn, H., Sun, J., Park, C.Y., Seo, J., 2020. Nlpdove at semeval-2020 task 12: Improving offensive language detection with cross-lingual transfer. arXiv preprint arXiv:2008.01354 .
[7] Akhter, M.P., Jiangbin, Z., Naqvi, I.R., Abdelmajeed, M., Sadiq, M.T., 2020. Automatic detection of offensive language for urdu and roman urdu. IEEE Access 8, 91213­91226.
[8] Al-Hassan, A., Al-Dossari, H., 2019. Detection of hate speech in social networks: a survey on multilingual corpus, in: 6th International Conference on Computer Science and Information Technology.
[9] Al-Hassan, A., Al-Dossari, H., 2021. Detection of hate speech in arabic tweets using deep learning. Multimedia Systems , 1­12.
[10] Alakrot, A., Murray, L., Nikolov, N.S., 2018a. Dataset construction for the detection of anti-social behaviour in online communication in arabic. Procedia Computer Science 142, 174­181.
[11] Alakrot, A., Murray, L., Nikolov, N.S., 2018b. Towards accurate detection of offensive language in online communication in arabic. Procedia computer science 142, 315­320.
[12] Alami, H., El Alaoui, S.O., Benlahbib, A., En-nahnahi, N., 2020. Lisac fsdm-usmba team at semeval-2020 task 12: Overcoming arabert's pretrain-finetune discrepancy for arabic offensive language identification, in: Proceedings of the Fourteenth Workshop on Semantic Evaluation, pp. 2080­2085.
[13] Albadi, N., Kurdi, M., Mishra, S., 2018. Are they our brothers? analysis and detection of religious hate speech in the arabic twittersphere, in: Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ACM. pp. 69­76.
[14] Alfina, I., Mulia, R., Fanany, M.I., Ekanata, Y., 2017. Hate speech detection in the indonesian language: A dataset and preliminary study, in: 2017 International Conference on Advanced Computer Science and Information Systems (ICACSIS), IEEE. pp. 233­238.
[15] Alshehri, A., El Moatez Billah Nagoudi, H.A., Abdul-Mageed, M., 2018. Think before your click: Data and models for adult content in arabic twitter, in: TA-COS 2018: 2nd Workshop on Text Analytics for Cybersecurity and Online Safety, p. 15.
[16] Aluru, S.S., Mathew, B., Saha, P., Mukherjee, A., 2020. Deep learning models for multilingual hate speech detection. arXiv preprint arXiv:2004.06465 .
[17] Andrusyak, B., Rimel, M., Kern, R., 2018. Detection of abusive speech for mixed sociolects of russian and ukrainian languages., in: RASLAN, pp. 77­84.
[18] Antoun, W., Baly, F., Hajj, H., 2020. Arabert: Transformer-based model for arabic language understanding. arXiv preprint arXiv:2003.00104 .
[19] Araci, D., 2019. Finbert: Financial sentiment analysis with pre-trained language models. arXiv preprint arXiv:1908.10063 .
[20] Arora, G., 2020. Gauravarora@ hasoc-dravidian-codemix-fire2020: Pre-training ulmfit on synthetically generated code-mixed data for hate speech detection. arXiv preprint arXiv:2010.02094 .
[21] Badjatiya, P., Gupta, S., Gupta, M., Varma, V., 2017. Deep learning for hate speech detection in tweets, in: Proceedings of the 26th international conference on World Wide Web companion, pp. 759­760.
[22] Bashar, M.A., Nayak, R., 2020. Qutnocturnal@ hasoc'19: Cnn for hate speech and offensive content identification in hindi language. arXiv preprint arXiv:2008.12448 .
[23] Basile, P., Caputo, A., Semeraro, G., 2014. An enhanced lesk word sense disambiguation algorithm through a distributional semantic model, in: Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pp. 1591­1600.
[24] Basile, V., Bosco, C., Fersini, E., Debora, N., Patti, V., Pardo, F.M.R., Rosso, P., Sanguinetti, M., et al., 2019. Semeval-2019 task 5: Multilingual detection of hate speech against immigrants and women in twitter, in: 13th International Workshop on Semantic Evaluation, Association for Computational Linguistics. pp. 54­63.
36

Systematic review of Hate Speech automatic detection
[25] Bohra, A., Vijay, D., Singh, V., Akhtar, S.S., Shrivastava, M., 2018. A dataset of hindi-english code-mixed social media text for hate speech detection, in: Proceedings of the second workshop on computational modeling of people's opinions, personality, and emotions in social media, pp. 36­41.
[26] Bretschneider, U., Peters, R., 2016. Detecting cyberbullying in online communities .
[27] Bretschneider, U., Peters, R., 2017. Detecting offensive statements towards foreigners in social media, in: Proceedings of the 50th Hawaii International Conference on System Sciences.
[28] Burnap, P., Williams, M.L., 2014. Hate speech, machine classification and statistical modelling of information flows on twitter: Interpretation and communication for policy decision making .
[29] Caselli, T., Basile, V., Mitrovic´, J., Granitzer, M., 2020. Hatebert: Retraining bert for abusive language detection in english. arXiv preprint arXiv:2010.12472 .
[30] Chen, H., McKeever, S., Delany, S.J., 2017. Abusive text detection using neural networks., in: AICS, pp. 258­260.
[31] Chen, Y., Zhou, Y., Zhu, S., Xu, H., 2012. Detecting offensive language in social media to protect adolescent online safety, in: 2012 International Conference on Privacy, Security, Risk and Trust and 2012 International Confernece on Social Computing, IEEE. pp. 71­80.
[32] Chung, Y.L., Kuzmenko, E., Tekiroglu, S.S., Guerini, M., 2019. Conan­counter narratives through nichesourcing: a multilingual dataset of responses to fight online hate speech. arXiv preprint arXiv:1910.03270 .
[33] Dadu, T., Pant, K., 2020. Team rouges at semeval-2020 task 12: Cross-lingual inductive transfer to detect offensive language, in: Proceedings of the Fourteenth Workshop on Semantic Evaluation, pp. 2183­2189.
[34] Davidson, T., Warmsley, D., Macy, M., Weber, I., 2017a. Automated hate speech detection and the problem of offensive language, in: Proceedings of the International AAAI Conference on Web and Social Media.
[35] Davidson, T., Warmsley, D., Macy, M., Weber, I., 2017b. Automated hate speech detection and the problem of offensive language, in: Proceedings of the 11th International AAAI Conference on Web and Social Media, pp. 512­515.
[36] Di Capua, M., Di Nardo, E., Petrosino, A., 2016. Unsupervised cyber bullying detection in social networks, in: 2016 23rd International conference on pattern recognition (ICPR), IEEE. pp. 432­437.
[37] Dinakar, K., Jones, B., Havasi, C., Lieberman, H., Picard, R., 2012. Common sense reasoning for detection, prevention, and mitigation of cyberbullying. ACM Transactions on Interactive Intelligent Systems (TiiS) 2, 1­30.
[38] Djandji, M., Baly, F., Hajj, H., et al., 2020. Multi-task learning using arabert for offensive language detection, in: Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection, pp. 97­101.
[39] Djuric, N., Zhou, J., Morris, R., Grbovic, M., Radosavljevic, V., Bhamidipati, N., 2015. Hate speech detection with comment embeddings, in: Proceedings of the 24th international conference on world wide web, pp. 29­30.
[40] Dowlagar, S., Mamidi, R., 2021. Hasocone@ fire-hasoc2020: Using bert and multilingual bert models for hate speech detection. arXiv preprint arXiv:2101.09007 .
[41] Dredge, R., Gleeson, J., De la Piedad Garcia, X., 2014. Cyberbullying in social networking sites: An adolescent victim's perspective. Computers in human behavior 36, 13­20.
[42] Duwairi, R., Hayajneh, A., Quwaider, M., 2021. A deep learning framework for automatic detection of hate speech embedded in arabic tweets. Arabian Journal for Science and Engineering 46, 4001­4014.
[43] ElSherief, M., Nilizadeh, S., Nguyen, D., Vigna, G., Belding, E., 2018. Peer to peer hate: Hate speech instigators and their targets, in: Proceedings of the International AAAI Conference on Web and Social Media.
[44] Faris, H., Aljarah, I., Habib, M., Castillo, P.A., 2020. Hate speech detection using word embedding and deep learning in the arabic language context., in: ICPRAM, pp. 453­460.
[45] Fernandez, M., Alani, H., 2018. Contextual semantics for radicalisation detection on twitter .
37

Systematic review of Hate Speech automatic detection
[46] Fortuna, P., Nunes, S., 2018. A survey on automatic detection of hate speech in text. ACM Computing Surveys (CSUR) 51, 1­30.
[47] Fortuna, P., Soler, J., Wanner, L., 2020. Toxic, hateful, offensive or abusive? what are we really classifying? an empirical analysis of hate speech datasets, in: Proceedings of the 12th Language Resources and Evaluation Conference, pp. 6786­6794.
[48] Founta, A., Djouvas, C., Chatzakou, D., Leontiadis, I., Blackburn, J., Stringhini, G., Vakali, A., Sirivianos, M., Kourtellis, N., 2018. Large scale crowdsourcing and characterization of twitter abusive behavior, in: Proceedings of the International AAAI Conference on Web and Social Media.
[49] Gao, L., Huang, R., 2017. Detecting online hate speech using context aware models. arXiv preprint arXiv:1710.07395 .
[50] Ghanghor, N., Ponnusamy, R., Kumaresan, P.K., Priyadharshini, R., Thavareesan, S., Chakravarthi, B.R., 2021. Iiitk@ lt-edi-eacl2021: Hope speech detection for equality, diversity, and inclusion in tamil, malayalam and english, in: Proceedings of the First Workshop on Language Technology for Equality, Diversity and Inclusion, pp. 197­203.
[51] de Gibert, O., Perez, N., García-Pablos, A., Cuadros, M., 2018a. Hate speech dataset from a white supremacy forum. arXiv preprint arXiv:1809.04444 .
[52] de Gibert, O., Perez, N., García-Pablos, A., Cuadros, M., 2018b. Hate Speech Dataset from a White Supremacy Forum, in: Proceedings of the 2nd Workshop on Abusive Language Online (ALW2), Association for Computational Linguistics, Brussels, Belgium. pp. 11­20. URL: https://www.aclweb.org/anthology/W18-5102, doi:10.18653/v1/W18-5102.
[53] Gitari, N.D., Zuping, Z., Damien, H., Long, J., 2015. A lexicon-based approach for hate speech detection. International Journal of Multimedia and Ubiquitous Engineering 10, 215­230.
[54] Golbeck, J., Ashktorab, Z., Banjo, R.O., Berlinger, A., Bhagwan, S., Buntain, C., Cheakalos, P., Geller, A.A., Gnanasekaran, R.K., Gunasekaran, R.R., et al., 2017. A large labeled corpus for online harassment research, in: Proceedings of the 2017 ACM on web science conference, pp. 229­233.
[55] Gomez, R., Gibert, J., Gomez, L., Karatzas, D., 2020. Exploring hate speech detection in multimodal publications, in: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 1470­1478.
[56] Gonzalez, J.A., Hurtado, L.F., Pla, F., 2021. Twilbert: Pre-trained deep bidirectional transformers for spanish twitter. Neurocomputing 426, 58­69.
[57] Goodfellow, I., Bengio, Y., Courville, A., Bengio, Y., 2016. Deep learning. volume 1. MIT press Cambridge.
[58] Haidar, B., Chamoun, M., Serhrouchni, A., 2017. A multilingual system for cyberbullying detection: Arabic content detection using machine learning. Advances in Science, Technology and Engineering Systems Journal 2, 275­284.
[59] Hassan, S., Samih, Y., Mubarak, H., Abdelali, A., 2020. Alt at semeval-2020 task 12: Arabic and english offensive language identification in social media, in: Proceedings of the Fourteenth Workshop on Semantic Evaluation, pp. 1891­1897.
[60] Ibrohim, M.O., Budi, I., 2018. A dataset and preliminaries study for abusive language detection in indonesian social media. Procedia Computer Science 135, 222­229.
[61] Ibrohim, M.O., Budi, I., 2019. Multi-label hate speech and abusive language detection in indonesian twitter, in: Proceedings of the Third Workshop on Abusive Language Online, pp. 46­57.
[62] Ishmam, A.M., Sharmin, S., 2019. Hateful speech detection in public facebook pages for the bengali language, in: 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), IEEE. pp. 555­560.
[63] Jahan, M.S., 2020. Team oulu at semeval-2020 task 12: Multilingual identification of offensive language, type and target of twitter post using translated datasets, in: Proceedings of the Fourteenth Workshop on Semantic Evaluation, pp. 1628­1637.
38

Systematic review of Hate Speech automatic detection
[64] Jaki, S., De Smedt, T., 2019. Right-wing german hate speech on twitter: Analysis and automatic detection. arXiv preprint arXiv:1910.07518 .
[65] Jha, A., Mamidi, R., 2017. When does a compliment become sexist? analysis and classification of ambivalent sexism using twitter data, in: Proceedings of the second workshop on NLP and computational social science, pp. 7­16.
[66] Kaati, L., Omer, E., Prucha, N., Shrestha, A., 2015. Detecting multipliers of jihadism on twitter, in: 2015 IEEE international conference on data mining workshop (ICDMW), IEEE. pp. 954­960.
[67] Kamble, S., Joshi, A., 2018. Hate speech detection from code-mixed hindi-english tweets using deep learning models. arXiv preprint arXiv:1811.05145 .
[68] Kapil, P., Ekbal, A., 2020. A deep neural network based multi-task learning approach to hate speech detection. Knowledge-Based Systems 210, 106458.
[69] Karim, M.R., Chakravarthi, B.R., McCrae, J.P., Cochez, M., 2020. Classification benchmarks for under-resourced bengali language based on multichannel convolutional-lstm network, in: 2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA), IEEE. pp. 390­399.
[70] Kowsari, K., Jafari Meimandi, K., Heidarysafa, M., Mendu, S., Barnes, L., Brown, D., 2019. Text classification algorithms: A survey. Information 10, 150.
[71] Kumar, A., Abirami, S., Trueman, T.E., Cambria, E., 2021. Comment toxicity detection via a multichannel convolutional bidirectional gated recurrent unit. Neurocomputing 441, 272­278.
[72] Kumar, B.L.R., Lahiri, B., Ojha, A.K., Bansal, A., 2020. Comma@ fire 2020: Exploring multilingual joint training across different classification tasks, in: Working Notes of FIRE 2020-Forum for Information Retrieval Evaluation, Hyderabad, India.
[73] Kumar, R., Reganti, A.N., Bhatia, A., Maheshwari, T., 2018. Aggression-annotated corpus of hindi-english code-mixed data. arXiv preprint arXiv:1803.09402 .
[74] Kuratov, Y., Arkhipov, M., 2019. Adaptation of deep bidirectional multilingual transformers for russian language. arXiv preprint arXiv:1905.07213 .
[75] Kwok, I., Wang, Y., 2013. Locate the hate: Detecting tweets against blacks, in: Proceedings of the AAAI Conference on Artificial Intelligence.
[76] Le, H., Vial, L., Frej, J., Segonne, V., Coavoux, M., Lecouteux, B., Allauzen, A., Crabbé, B., Besacier, L., Schwab, D., 2019. Flaubert: Unsupervised language model pre-training for french. arXiv preprint arXiv:1912.05372 .
[77] Liu, P., Li, W., Zou, L., 2019. Nuli at semeval-2019 task 6: Transfer learning for offensive language detection using bidirectional transformers, in: Proceedings of the 13th international workshop on semantic evaluation, pp. 87­91.
[78] Magdy, W., Darwish, K., Weber, I., 2015. # failedrevolutions: Using twitter to study the antecedents of isis support. arXiv preprint arXiv:1503.02401 .
[79] Mahata, D., Zhang, H., Uppal, K., Kumar, Y., Shah, R., Shahid, S., Mehnaz, L., Anand, S., 2019. Midas at semeval-2019 task 6: Identifying offensive posts and targeted offense from twitter, in: Proceedings of the 13th International Workshop on Semantic Evaluation, pp. 683­690.
[80] Malmasi, S., Zampieri, M., 2018. Challenges in discriminating profanity from hate speech. Journal of Experimental & Theoretical Artificial Intelligence 30, 187­202.
[81] Mandl, T., Modha, S., Kumar M, A., Chakravarthi, B.R., 2020. Overview of the hasoc track at fire 2020: Hate speech and offensive language identification in tamil, malayalam, hindi, english and german, in: Forum for Information Retrieval Evaluation, pp. 29­32.
[82] Mandl, T., Modha, S., Majumder, P., Patel, D., Dave, M., Mandlia, C., Patel, A., 2019. Overview of the hasoc track at fire 2019: Hate speech and offensive content identification in indo-european languages, in: Proceedings of the 11th forum for information retrieval evaluation, pp. 14­17.
39

Systematic review of Hate Speech automatic detection
[83] Martin, L., Muller, B., Suárez, P.J.O., Dupont, Y., Romary, L., de la Clergerie, É.V., Seddah, D., Sagot, B., 2019. Camembert: a tasty french language model. arXiv preprint arXiv:1911.03894 .
[84] Mathew, B., Saha, P., Yimam, S.M., Biemann, C., Goyal, P., Mukherjee, A., 2020. Hatexplain: A benchmark dataset for explainable hate speech detection. arXiv preprint arXiv:2012.10289 .
[85] Mathur, P., Sawhney, R., Ayyar, M., Shah, R., 2018. Did you offend me? classification of offensive tweets in hinglish language, in: Proceedings of the 2nd Workshop on Abusive Language Online (ALW2), pp. 138­148.
[86] Matsumoto, D., 2001. The handbook of culture and psychology. Oxford University Press.
[87] Mishra, P., Yannakoudakis, H., Shutova, E., 2019. Tackling online abuse: A survey of automated abuse detection methods. arXiv preprint arXiv:1908.06024 .
[88] Mishra, S., Mishra, S., 2019. 3idiots at hasoc 2019: Fine-tuning transformer neural networks for hate speech identification in indo-european languages., in: FIRE (Working Notes), pp. 208­213.
[89] Mishraa, A.K., Saumyab, S., Kumara, A., 2020. Iiit_dwd@ hasoc 2020: Identifying offensive content in indo-european languages .
[90] Moher, D., Liberati, A., Tetzlaff, J., Altman, D.G., Group, P., et al., 2009. Preferred reporting items for systematic reviews and meta-analyses: the prisma statement. PLoS medicine 6, e1000097.
[91] Moon, J., Cho, W.I., Lee, J., 2020a. Beep! korean corpus of online news comments for toxic speech detection. arXiv preprint arXiv:2005.12503 .
[92] Moon, J., Cho, W.I., Lee, J., 2020b. BEEP! Korean corpus of online news comments for toxic speech detection, in: Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media, Association for Computational Linguistics, Online. pp. 25­31. URL: https://www.aclweb.org/anthology/ 2020.socialnlp-1.4.
[93] Mubarak, H., Darwish, K., Magdy, W., 2017. Abusive language detection on arabic social media, in: Proceedings of the first workshop on abusive language online, pp. 52­56.
[94] Mulki, H., Haddad, H., Ali, C.B., Alshabani, H., 2019. L-hsab: A levantine twitter dataset for hate speech and abusive language, in: Proceedings of the third workshop on abusive language online, pp. 111­118.
[95] Mustafa, R.U., Nawaz, M.S., Farzund, J., Lali, M., Shahzad, B., Viger, P., 2017. Early detection of controversial urdu speeches from social media. Data Sci. Pattern Recognit. 1, 26­42.
[96] Nahar, V., Al-Maskari, S., Li, X., Pang, C., 2014. Semi-supervised learning for cyberbullying detection in social networks, in: Australasian Database Conference, Springer. pp. 160­171.
[97] Nguyen, D.Q., Vu, T., Nguyen, A.T., 2020. Bertweet: A pre-trained language model for english tweets. arXiv preprint arXiv:2005.10200 .
[98] Nikolov, A., Radivchev, V., 2019. Nikolov-radivchev at semeval-2019 task 6: Offensive tweet classification with bert and ensembles, in: Proceedings of the 13th International Workshop on Semantic Evaluation, pp. 691­695.
[99] Nobata, C., Tetreault, J., Thomas, A., Mehdad, Y., Chang, Y., 2016. Abusive language detection in online user content, in: Proceedings of the 25th international conference on world wide web, pp. 145­153.
[100] Nockleby, J.T., 2000. Hate speech. Encyclopedia of the American constitution 3, 1277­1279.
[101] O'Brien, J., 2009. Encyclopedia of gender and society. volume 1. Sage.
[102] Ousidhoum, N., Lin, Z., Zhang, H., Song, Y., Yeung, D.Y., 2019a. Multilingual and multi-aspect hate speech analysis. arXiv preprint arXiv:1908.11049 .
[103] Ousidhoum, N., Lin, Z., Zhang, H., Song, Y., Yeung, D.Y., 2019b. Multilingual and multi-aspect hate speech analysis, in: Proceedings of EMNLP, Association for Computational Linguistics.
[104] Ozdemir, A., Yeniterzi, R., 2020. Su-nlp at semeval-2020 task 12: Offensive language identification in turkish tweets, in: Proceedings of the Fourteenth Workshop on Semantic Evaluation, pp. 2171­2176.
40

Systematic review of Hate Speech automatic detection
[105] Özel, S.A., Saraç, E., Akdemir, S., Aksu, H., 2017. Detection of cyberbullying on social media messages in turkish, in: 2017 International Conference on Computer Science and Engineering (UBMK), IEEE. pp. 366­370.
[106] Pàmies, M., Öhman, E., Kajava, K., Tiedemann, J., 2020. Lt@ helsinki at semeval-2020 task 12: Multilingual or language-specific bert? arXiv preprint arXiv:2008.00805 .
[107] Park, J.H., Fung, P., 2017. One-step and two-step classification for abusive language detection on twitter. arXiv preprint arXiv:1706.01206 .
[108] Patchin, J.W., Hinduja, S., 2006. Bullies move beyond the schoolyard: A preliminary look at cyberbullying. Youth violence and juvenile justice 4, 148­169.
[109] Pathak, V., Joshi, M., Joshi, P., Mundada, M., Joshi, T., 2021. Kbcnmujal@ hasoc-dravidian-codemix-fire2020: Using machine learning for detection of hate speech and offensive code-mixed social media text. arXiv preprint arXiv:2102.09866 .
[110] Pawar, R., Agrawal, Y., Joshi, A., Gorrepati, R., Raje, R.R., 2018. Cyberbullying detection system with multiple server configurations, in: 2018 IEEE International Conference on Electro/Information Technology (EIT), IEEE. pp. 0090­0095.
[111] de Pelle, R.P., Moreira, V.P., 2017. Offensive comments in the brazilian web: a dataset and baseline results, in: Anais do VI Brazilian Workshop on Social Network Analysis and Mining, SBC.
[112] Pitenis, Z., Zampieri, M., Ranasinghe, T., 2020. Offensive language identification in greek. arXiv preprint arXiv:2003.07459 .
[113] Pitsilis, G.K., Ramampiaro, H., Langseth, H., 2018. Effective hate-speech detection in twitter data using recurrent neural networks. Applied Intelligence 48, 4730­4742.
[114] Poletto, F., Basile, V., Sanguinetti, M., Bosco, C., Patti, V., 2020. Resources and benchmark corpora for hate speech detection: a systematic review. Language Resources and Evaluation , 1­47.
[115] Polignano, M., Basile, P., De Gemmis, M., Semeraro, G., Basile, V., 2019a. Alberto: Italian bert language understanding model for nlp challenging tasks based on tweets, in: 6th Italian Conference on Computational Linguistics, CLiC-it 2019, CEUR. pp. 1­6.
[116] Polignano, M., Basile, V., Basile, P., de Gemmis, M., Semeraro, G., 2019b. Alberto: Modeling italian social media language with bert. IJCoL. Italian Journal of Computational Linguistics 5, 11­31.
[117] Pradhan, R., Chaturvedi, A., Tripathi, A., Sharma, D.K., 2020. A review on offensive language detection, in: Advances in Data and Information Sciences. Springer, pp. 433­439.
[118] Ptaszynski, M., Pieciukiewicz, A., Dybala, P., 2019. Results of the poleval 2019 shared task 6: First dataset and open shared task for automatic cyberbullying detection in polish twitter .
[119] Qian, J., Bethke, A., Liu, Y., Belding, E., Wang, W.Y., 2019. A benchmark dataset for learning to intervene in online hate speech. arXiv preprint arXiv:1909.04251 .
[120] Quea, Q., Sunb, R., Xiec, S., 2020. Simon@ hasoc 2020: Detecting hate speech and offensive content in german language with bert and ensembles. FIRE (Working Notes), CEUR .
[121] Raja, R., Srivastavab, S., Saumyac, S., 2021. Nsit & iiitdwd@ hasoc 2020: Deep learning model for hate-speech identification in indo-european languages .
[122] Ranasinghe, T., Zampieri, M., Hettiarachchi, H., 2019. Brums at hasoc 2019: Deep learning models for multilingual hate speech and offensive language identification., in: FIRE (Working Notes), pp. 199­207.
[123] Rezvan, M., Shekarpour, S., Balasuriya, L., Thirunarayan, K., Shalin, V.L., Sheth, A., 2018. A quality type-aware annotated corpus and lexicon for harassment research, in: Proceedings of the 10th ACM Conference on Web Science, pp. 33­36.
[124] Ribeiro, M., Calais, P., Santos, Y., Almeida, V., Meira Jr, W., 2018. Characterizing and detecting hateful users on twitter, in: Proceedings of the International AAAI Conference on Web and Social Media.
41

Systematic review of Hate Speech automatic detection
[125] Rizos, G., Hemker, K., Schuller, B., 2019. Augment to prevent: short-text data augmentation in deep learning for hate-speech classification, in: Proceedings of the 28th ACM International Conference on Information and Knowledge Management, pp. 991­1000.
[126] Rizwan, H., Shakeel, M.H., Karim, A., 2020. Hate-speech and offensive language detection in roman urdu, in: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 2512­2522.
[127] Romim, N., Ahmed, M., Talukder, H., Islam, M.S., 2020. Hate speech detection in the bengali language: A dataset and its baseline evaluation. arXiv preprint arXiv:2012.09686 .
[128] Rosa, H., Matos, D., Ribeiro, R., Coheur, L., Carvalho, J.P., 2018. A "deeper" look at detecting cyberbullying in social networks, in: 2018 International Joint Conference on Neural Networks (IJCNN), IEEE. pp. 1­8.
[129] Ross, B., Rist, M., Carbonell, G., Cabrera, B., Kurowsky, N., Wojatzki, M., 2017. Measuring the reliability of hate speech annotations: The case of the european refugee crisis. arXiv preprint arXiv:1701.08118 .
[130] Sai, S., Sharma, Y., 2020. Siva@ hasoc-dravidian-codemix-fire-2020: Multilingual offensive speech detection in code-mixed and romanized text. FIRE (Working Notes) .
[131] Saleh Alatawi, H., Maatog Alhothali, A., Mustafa Moria, K., 2020. Detecting white supremacist hate speech using domain specific word embedding with deep learning and bert. arXiv e-prints , arXiv­2010.
[132] Sanguinetti, M., Poletto, F., Bosco, C., Patti, V., Stranisci, M., 2018. An italian twitter corpus of hate speech against immigrants, in: Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018).
[133] Schmidt, A., Wiegand, M., 2017. A survey on hate speech detection using natural language processing, in: Proceedings of the Fifth International workshop on natural language processing for social media, pp. 1­10.
[134] Shruthi, P., KM, A.K., 2020. Hate speech detection using deep learning and hybrid features. Inteligencia Artificial 23, 97­111.
[135] Sigurbergsson, G.I., Derczynski, L., 2019. Offensive language and hate speech detection for danish. arXiv preprint arXiv:1908.04531 .
[136] Socha, K., 2020. Ks@ lth at semeval-2020 task 12: Fine-tuning multi-and monolingual transformer models for offensive language detection, in: Proceedings of the Fourteenth Workshop on Semantic Evaluation, pp. 2045­2053.
[137] Souza, F., Nogueira, R., Lotufo, R., 2019. Portuguese named entity recognition using bert-crf. arXiv preprint arXiv:1909.10649 .
[138] Su, H.P., Huang, Z.J., Chang, H.T., Lin, C.J., 2017. Rephrasing profanity in chinese text, in: Proceedings of the First Workshop on Abusive Language Online, pp. 18­24.
[139] Tang, X., Shen, X., Wang, Y., Yang, Y., 2020. Categorizing offensive language in social networks: A chinese corpus, systems and an explanation tool, in: China National Conference on Chinese Computational Linguistics, Springer. pp. 300­315.
[140] Tsapatsoulis, N., Anastasopoulou, V., 2019. Cyberbullies in twitter: A focused review, in: 2019 14th International Workshop on Semantic and Social Media Adaptation and Personalization (SMAP), IEEE. pp. 1­6.
[141] de Vries, W., van Cranenburgh, A., Bisazza, A., Caselli, T., van Noord, G., Nissim, M., 2019. Bertje: A dutch bert model. arXiv preprint arXiv:1912.09582 .
[142] Wadhwa, P., Bhatia, M., 2013. Tracking on-line radicalization using investigative data mining, in: 2013 National Conference on Communications (NCC), IEEE. pp. 1­5.
[143] Wang, S., Liu, J., Ouyang, X., Sun, Y., 2020. Galileo at semeval-2020 task 12: Multi-lingual learning for offensive language identification using pre-trained language models. arXiv preprint arXiv:2010.03542 .
[144] Warner, W., Hirschberg, J., 2012. Detecting hate speech on the world wide web, in: Proceedings of the second workshop on language in social media, Association for Computational Linguistics. pp. 19­26.
42

Systematic review of Hate Speech automatic detection
[145] Waseem, Z., 2016. Are you a racist or am i seeing things? annotator influence on hate speech detection on twitter, in: Proceedings of the first workshop on NLP and computational social science, pp. 138­142.
[146] Waseem, Z., Hovy, D., 2016. Hateful symbols or hateful people? predictive features for hate speech detection on twitter, in: Proceedings of the NAACL student research workshop, pp. 88­93.
[147] Watanabe, H., Bouazizi, M., Ohtsuki, T., 2018. Hate speech on twitter: A pragmatic approach to collect hateful and offensive expressions and perform hate speech detection. IEEE access 6, 13825­13835.
[148] Wiedemann, G., Yimam, S.M., Biemann, C., 2020. Uhh-lt & lt2 at semeval-2020 task 12: Fine-tuning of pre-trained transformer networks for offensive language detection. arXiv preprint arXiv:2004.11493 .
[149] Wiegand, M., Ruppenhofer, J., Schmidt, A., Greenberg, C., 2018a. Inducing a lexicon of abusive words­a feature-based approach .
[150] Wiegand, M., Siegel, M., Ruppenhofer, J., 2018b. Overview of the germeval 2018 shared task on the identification of offensive language .
[151] Wigand, C., Voin, M., 2017. Speech by commissioner jourová--10 years of the eu fundamental rights agency: A call to action in defence of fundamental rights, democracy and the rule of law.
[152] Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M., Davison, J., Shleifer, S., von Platen, P., Ma, C., Jernite, Y., Plu, J., Xu, C., Scao, T.L., Gugger, S., Drame, M., Lhoest, Q., Rush, A.M., 2020. Transformers: State-of-the-art natural language processing, in: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics, Online. pp. 38­45. URL: https://www.aclweb.org/anthology/ 2020.emnlp-demos.6.
[153] Wulczyn, E., Thain, N., Dixon, L., 2017. Ex machina: Personal attacks seen at scale, in: Proceedings of the 26th international conference on world wide web, pp. 1391­1399.
[154] Xiang, G., Fan, B., Wang, L., Hong, J., Rose, C., 2012. Detecting offensive tweets via topical feature discovery over a large scale twitter corpus, in: Proceedings of the 21st ACM international conference on Information and knowledge management, pp. 1980­1984.
[155] Yang, H., Lin, C.J., 2020. Tocp: A dataset for chinese profanity processing, in: Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying, pp. 6­12.
[156] Yin, W., Kann, K., Yu, M., Schütze, H., 2017. Comparative study of cnn and rnn for natural language processing. arXiv preprint arXiv:1702.01923 .
[157] Zampieri, M., Malmasi, S., Nakov, P., Rosenthal, S., Farra, N., Kumar, R., 2019a. Predicting the type and target of offensive posts in social media. arXiv preprint arXiv:1902.09666 .
[158] Zampieri, M., Malmasi, S., Nakov, P., Rosenthal, S., Farra, N., Kumar, R., 2019b. Semeval-2019 task 6: Identifying and categorizing offensive language in social media (offenseval). arXiv preprint arXiv:1903.08983 .
[159] Zampieri, M., Nakov, P., Rosenthal, S., Atanasova, P., Karadzhov, G., Mubarak, H., Derczynski, L., Pitenis, Z., Çöltekin, Ç., 2020. Semeval-2020 task 12: Multilingual offensive language identification in social media (offenseval 2020). arXiv preprint arXiv:2006.07235 .
[160] Zhang, Z., Luo, L., 2019. Hate speech detection: A solved problem? the challenging case of long tail on twitter. Semantic Web 10, 925­945.
[161] Zhou, Y., Yang, Y., Liu, H., Liu, X., Savage, N., 2020. Deep learning based fusion approach for hate speech detection. IEEE Access 8, 128923­128929.
43

