arXiv:2106.00237v1 [cs.CL] 1 Jun 2021

Improving Automatic Hate Speech Detection with Multiword Expression Features
Nicolas Zampieri, Irina Illina, and Dominique Fohr
University of Lorraine, CNRS, INRIA, Loria/ F-54000 Nancy, France {firstname.lastname}@loria.fr
Abstract. The task of automatically detecting hate speech in social media is gaining more and more attention. Given the enormous volume of content posted daily, human monitoring of hate speech is unfeasible. In this work, we propose new word-level features for automatic hate speech detection (HSD): multiword expressions (MWEs). MWEs are lexical units greater than a word that have idiomatic and compositional meanings. We propose to integrate MWE features in a deep neural network-based HSD framework. Our baseline HSD system relies on Universal Sentence Encoder (USE). To incorporate MWE features, we create a three-branch deep neural network: one branch for USE, one for MWE categories, and one for MWE embeddings. We conduct experiments on two hate speech tweet corpora with different MWE categories and with two types of MWE embeddings, word2vec and BERT. Our experiments demonstrate that the proposed HSD system with MWE features significantly outperforms the baseline system in terms of macro-F1.
Keywords: Social media · Hate speech detection · Deep learning.
1 Introduction
Hate speech detection (HSD) is a difficult task both for humans and machines because hateful content is more than just keyword detection. Hatred may be implied, the sentence may be grammatically incorrect and the abbreviations and slangs may be numerous [19]. Recently, the use of machine learning methods for HSD has gained attention, as evidenced by these systems: [20,14]. [16] performed a comparative study between machine learning models and concluded that the deep learning models are more accurate. Current HSD systems are based on natural language processing (NLP) advances and rely on deep neural networks (DNN) [18,15].
Finding the features that best represent the underlying hate speech phenomenon is challenging. Early works on automatic HSD used different word representations, such as a bag of words, surface forms, and character n-grams with machine learning classifiers [30]. The combination of features, such as n-grams, linguistic and syntactic turns out to be interesting as shown by [19]. [5] proposed lexical syntactic features, incorporating style features, structure features, and context-specific features to better predict hate speech in social media. [4] investigated user features to detect bullying and aggressive behavior in tweets.

2

Zampieri et al.

The integration of word embeddings, sentence embeddings, or emojis features in DNN systems allow learning semantics, contexts, and long-term dependencies. For instance, fastText word embeddings are used in a DNN-based HSD system [1]. Universal Sentence Encoder [3] or InferSent [6] allows taking into account the semantic information of the entire sentence. [14] showed that sentence embeddings outperform word embeddings. [8] proposed hybrid emoji-based Masked Language Model to model the common information across different languages. Convolutional Neural Network-gram based system is proposed in [22] and demonstrated good robustness in coarse-grained and fine-grained detection tasks.
In this paper, we focus our research on the automatic HSD in tweets using DNN. Our baseline system relies on Universal Sentence Embeddings (USE). We propose to enrich the baseline system using word-level features, called multiword expressions (MWEs) [23]. MWEs are a class of linguistic forms spanning conventional word boundaries that are both idiosyncratic and pervasive across different languages[7]. We believe that MWE modelling could help to reduce the ambiguity of tweets and lead to better detection of HS [27]. To the best of our knowledge, MWE features have never been used in the framework of DNN-based automatic HSD. Our contribution is as follows. First, we extract different MWE categories and study their distribution in our tweet corpora. Secondly, we design a three-branch deep neural network to integrate MWE features. To do so, the baseline system based on USE embedding is modified by adding a second branch to model different MWE categories and a third branch to take into account the semantic meaning of MWE through word embedding. Thus, the designed system combines word-level and sentence-level features. Finally, we experimentally demonstrate the ability of the proposed MWE-based HSD system to better detect hate speech: a statistically significant improvement is obtained compared to the baseline system. We experimented on two tweet corpora to show that our approach is domain-independent.

2 Proposed methodology
In this section, we describe the proposed HSD system based on MWE features. This system is composed of a three-branch DNN network and combines global feature computed at the sentence level (USE embeddings) and word-level features: MWE categories and word embeddings representing the words belonging to MWEs.

2.1 Universal Sentence Encoder
Universal sentence encoder provides sentence level embeddings. The USE model is trained on a variety of data sources and demonstrated strong transfer performance on a number of NLP tasks [3]. In particular, pre-trained USE showed very good performance on different sentiment detection and semantic textual similarity tasks. The HSD system based on USE obtained the best results at the SemEval2019 campaign (shared task 5) [14]. This power of USE motivated us to use it to design our system.

Improving Automatic Hate Speech Detection with Multiword Expression Features

3

2.2 MWE features
A multiword expression is a group of words that are treated as a unit [23]. For example, the two MWEs stand for and get out have a meaning as a group, but have another meaning if the words are taken separately. MWEs include idioms, light verb constructions, verb-particle constructions, and many compounds. We think that adding information about MWE categories and semantic information from MWEs might help for the HSD task.
Automatic MWE identification and text tagging in terms of MWEs are difficult tasks. Different state-of-the-art deep learning methods have been studied for MWE identification, such as Convolutional Neural Network (CNN), bidirectional Long-Short Term Memory (LSTM) and transformers [11,29,28]. Over the past few years, the interest in MWEs increased as evidenced by different shared tasks: DiMSUM [25], PARSEME [24,21].
In our work, we focus on social media data. These textual data are very particular, may be grammatically incorrect and may contain abbreviations or spelling mistakes. For this type of data, there are no state-of-the-art approaches for MWE identification. A specific MWE identification system is required to parse MWEs in social media corpora. As the adaptation of an MWE identification system for a tweet corpus is a complex task and as it is not the goal of our paper, we decided to adopt a lexicon-based approach to annotate our corpora in terms of MWEs. We extract MWEs from the STREUSLE web corpus (English online reviews corpus), annotated in MWEs [26]. From this corpus, we create an MWE lexicon composed of 1855 MWEs which are classified into 20 lexical categories of MWEs. Table 1 presents these categories with examples. Each tweet of our tweet corpora is lemmatized and parsed with the MWE lexicon. Our parser tags MWEs and takes into account the possible discontinuity of MWEs: we allow that one word, not belonging to the MWE, can be present between the words of the MWE. If, in a sentence, a word belongs to two MWEs, we tag this word with the longest MWE. We do not take into account spelling or grammatical mistakes. We add a special category for words not belonging to any MWE.

2.3 HSD system proposal
In this section, we describe our hate speech detection system using USE embeddings and MWE features. As USE is a feature at the sentence level and MWE features are at the word level, the architecture of our system is composed of a neural network with three branches: two branches are dedicated to the MWE features, the last one deals with USE features. Figure 1 shows the architecture of our system.
In the first branch, we associate to each word of the tweet the number of the MWE category (one-hot encoding). This branch is composed of 3 consecutive blocks of CNN (Conv1D) and MaxPooling layers. Previous experiments with different DNN structures and the fast learning of CNN allow us to focus on this architecture. The second branch takes into account the semantic context of words composing MWE. If a given tweet has one or several MWEs, we associate a word embedding to each word composing these MWEs. We believe that the semantic meaning of MWEs is important to better understand and model them. This branch uses one LSTM layer. We propose to use two

4

Zampieri et al.

types of word embeddings: static where a given word has a single embedding in any context, or dynamic, where a given word can have different embeddings according to his long-term context. We experiment with word2vec and BERT embeddings [17,9]. BERT uses tokens instead of words. Therefore, we use the embedding of each token composing the words of the MWEs. We think that using two branches to model MWEs allows us to take into account complementary information and provides an efficient way of combining different features for a more robust HSD system.
The last branch, USE embedding, supplies relevant semantic information at the sentence level. The three branches are concatenated and went through two dense layers to obtain the system output. The output layer has as many neurons as the number of classes to predict.

3 Experimental setup
3.1 Corpora
The different time frames of collection, the various sampling strategies, and the targets of abuse induce a significant shift in the data distribution and can give a performance variation on different datasets. We use two tweets corpora to show that our approach is domain-independent: the English corpus of SemEval2019 task 5 subTask A (called HatEval in the following) [2] and Founta corpora [10]. We study the influence of MWE features on the HatEval corpus, and we use the Founta corpus to confirm our results. Note that these corpora contain different numbers of classes and different percentages of hateful speech.
We evaluate our models using the official evaluation script of SemEval shared task 5 1 in terms of macro-F1 measure. It is the average of the F1 scores of all classes.
HatEval corpus. In the HatEval corpus, the annotation of a tweet is a binary value indicating if HS is occurring against women or immigrants. The corpus contains 13k tweets. We use standard corpus partition in training, development, and test set with 9k, 1k, and 3k tweets respectively. Each set contains around 42% of hateful tweets. The vocabulary size of the corpus is 66k words.
We apply the following pre-processing for each tweet: we remove mentions (words beginning by @), hashtags (words beginning by #), and URLs. We keep the case unchanged. We use this pre-processing because the systems using this pre-processing obtained the best results at the SemEval2019 shared task 5 subtask A.
For train and development sets, we keep only tweets that contain at least two words. Thus, we obtain 8967 tweets for the training set and 998 tweets for the development set. We split the training part into two subsets, the first one (8003 tweets) to train the models, and the second one (965 tweets) for model validation. In the test set, we keep all tweets after pre-processing, even empty tweets. We tag empty tweets as non-hateful.
Founta corpus contains 100k tweets annotated with normal, abusive, hateful, and spam labels. Our experiments focus on HSD, so we decided to remove spams and we keep around 86k tweets. The vocabulary size of the corpus is 132k words. We apply the
1 https://github.com/msang/hateval/tree/master/ SemEval2019-Task5/evaluation

Improving Automatic Hate Speech Detection with Multiword Expression Features

5

Table 1: MWE categories with examples from STREUSLE corpus [26] and the number of occurrences of MWEs. The train set of HatEvam. The column Hateful (Non-hateful) represents MWE occurences that appear only in hateful (non-hateful) tweets. The column Both represents MWE occurrences that appear in hateful and non-hateful tweets.

MWE5

VMWE5

MWE categories

Examples Hateful Non-hateful Both

Adjective

dead on

9

8

255

Adverb

once again 1

5

194

Discourse

thank you 12

15

401

Nominal

tax payer 25

36

189

Adposition phrase (idiomatic) on the phone 9

36

134

Inherently adpositional verb stand for 11

21

447

Full light verb construction have option 9

10

36

Verbal idioms

Give a crap 14

24

384

Full verb-particle construction take off

11

20

387

Semi verb-particle construction walk out

6

18

153

Auxiliary

be suppose to 4

0

475

Coordinating conjunction

and yet

1

0

8

Determiner

a lot

1

2

242

Infinitive marker

to eat

0

0

12

Adposition

apart from 3

13

573

Non-possessive pronoun

my self

0

3

11

Subordinating conjunction

even if

0

0

28

Cause light verb construction give liberty 1

0

0

Symbol

A+

0

0

0

Interjection

lo and behold 0

0

0

same pre-processing as for the HatEval corpus. We divide the Founta corpus into 3 sets: train, development, and test with 60%, 20%, and 20% respectively. As for the HatEval corpus, we use a small part of training as the validation part. Each set contains about 62%, 31%, and 6% of normal, abusive, and hateful tweets.
3.2 System parameters
Our baseline system utilizes only USE features and corresponds to figure 1 without MWE branches. The system proposed in this article uses USE and the MWE features as presented in figure 1 2.
For the USE embedding, we use the pre-trained model provided by google3 (space dimension is 512) without fine-tuning.
We tag the MWE of each tweet using the lexicon, presented in the section 2.2. If an MWE is found, we put the corresponding MWE category for all words of the MWE. To perform fine-grained analysis, we decided to select MWE categories that have more than 50 occurrences (arbitrary value) and appear less than 97% in hate and non-hate
2 https://github.com/zamp13/MWE-HSD 3 https://tfhub.dev/google/universal-sentence-encoder-large/3

6

Zampieri et al.

Fig. 1: Proposed hate speech detection system using USE and MWE features.
tweets at the same time. We obtain 10 MWE categories: called MWE5 and VMWE5 which are respectively the first and second part of Table 1. VMWE5 is composed of Verbal MWE categories and MWE5 with the rest of the categories. The training part of the HatEval corpus contains 1551 occurrences of VMWE5 and 1329 occurrences of MWE5.
During our experiments, we experiment with all MWE categories presented in Table 1 (containing 19 categories: 18 categories, and a special category for words not belonging to any MWE) and with the combination of VMWE5 and MWE5 (10 MWE categories and a special category).
Concerning the MWE one-hot branch of the proposed system, we set the number of filters to 32, 16, and 8 for the 3 Conv1D layers. The kernel size of each CNN is set to 3.
For the MWE word embedding branch, we set the LSTM layer to 192 neurons. For BERT embedding, we use pre-trained uncased BERT model from [9] (embedding dimension is 768). The BERT embeddings are extracted from the last layer of this model. BERT model is token-based, so we model each token of the words belonging to a MWE. For word2vec embedding, we use the pre-trained embedding of [13]. This model is trained on a large tweet corpus (embedding dimension is 400). In our systems, each dense layer contains 256 neurons.
For each system configuration, we train 9 models with different random initialization. We select the model that obtains the best result on the development set to make predictions on the test set.
4 MWE statistics
We first analyze the distribution of the MWEs in our corpora. Figure 2 presents the percentage of occurrences of MWEs per tweet in HateEval. We observe that about 25% of the HatEval training tweets contain at least one MWE and enable us to influence the HSD performance.
As a further investigation, we analyze MWEs appearing per MWE category and for hate/non-hate classes. In the training set of the HatEval corpus our parser, described in section 2.2, annotated 4257 MWEs. Table 1 shows MWEs that appear only in hateful or non-hateful tweets or both in HatEval training part. We observe that some MWE

Improving Automatic Hate Speech Detection with Multiword Expression Features

7

Fig. 2: Histogram of the occurrences of MWEs per tweet in the training set of HatEval.
categories, as symbol and interjection, do not appear in HatEval training set. We decided to not use these two categories in our experiments. Most of the categories appear in hateful and non-hateful tweets. For the majority of MWE categories, there are MWEs that occur only in hateful speech and MWEs that occur only in non-hateful tweets.
Figure 3 presents the statistics of each MWE category for hate and non-hate classes. As in HatEval the classes are almost balanced (42% of hateful tweets, 58 % of nonhateful tweets), there is no bias due to imbalanced classes. Concerning the MWE categories, there is no categories used only in the hateful speech or only in the non-hateful speech excepted for the cause light verb construction category, but this category is underrepresented). We can note that there is a difference between the use of MWEs in the hateful and the non-hateful tweets: MWEs are used more often in non-hateful speech. For some MWE categories this difference is more important, as for adposition or full verb-particle construction. In contrast, the determiner category occurs more in hateful tweets. These observations reinforce our idea that MWE features can be useful for hate speech detection.

Fig. 3: Number of occurrences of each MWE category in the training set of HatEval. Blue (orange) bars represent occurrences in hateful (non-hateful) tweets.

8

Zampieri et al.

Table 2: The first part All test sets represents F1 and macro-F1 scores (%) on HatEval

and Founta test sets. The second part Tweets containing at least one MWE represents

F1 and macro-F1 scores (%) on tweets containing at least one MWE in HatEval and

Founta test sets.

Features

HatEval

Founta

F1

Macro-F1

F1

Macro-F1

Hateful Non-hate

Norm Abus Hate

All test sets

USE

64.9 66.4 65.7 94.2 87.8 34.6 72.2

USE, MWEall, word2vec

64.5 68.2

USE, VMWE5, MWE5, word2vec 66.1 67.0

66.3 93.8 86.9 36.5 72.4 66.5 93.9 87.1 37.2 72.7

USE, MWEall, BERT USE, VMWE5, MWE5, BERT

64.2 69.4 64.8 68.2

66.8 94.0 87.1 37.5 72.9 66.5 93.8 86.9 38.2 73.0

Tweets containing at least one MWE

USE USE, MWEall, word2vec USE, MWEall, BERT

67.8 62.3 71.7 61.4 73.9 61.3

65.0 91.1 94.1 41.6 75.6 66.6 91.4 86.9 44.6 76.5 67.6 90.9 94 43.3 76.1

5 Experimental results
The goal of our experiments is to study the impact of MWEs on automatic hate speech detection for two different corpora: HatEval with two classes (hate and non-hate) and Founta with three classes (hate, abusive and normal). We carried out experiments with the different groups of MWE categories: MWEall, including all MWE categories, and the combination of VMWE5 and MWE5. We evaluated also different embeddings for the word embedding branch of the proposed system: word2vec and BERT. As described previously, we select the best-performing configuration on the development data to be applied to the test data.
Table 2 displays the macro-F1 on HatEval and Founta test sets. Our baseline system without MWE features, called USE in Table 2, achieves a 65.7% macro-F1 score on HatEval test set. Using MWE features with word2vec or BERT embeddings, the system proposed in this paper performs better than the baseline. For instance, on HatEval, MWEall with BERT embedding configuration achieves the best result with 66.8% of macro-F1. Regarding Founta corpus, we observe a similar result improvement: the baseline system achieves 72.2% and systems with MWE features obtain scores ranging from 72.4% to 73.0% of macro-F1. It is important to note that according to a matched pair test in terms of accuracy with 5% risk [12], the systems using MWE features and word2vec or BERT embeddings significantly outperform the baseline system on the two corpora. Finally, the proposed system with MWEall and BERT embedding for HatEval outperforms the state-of-the-art system FERMI submitted at HatEval competition (SemEval task 5): 66.8% for our system versus 65% for FERMI of macro-F1 [14].
To analyze further MWE features, we experiment with different groups of MWE categories: VMWE5, MWE5, and MWEall. Preliminary experiments with the twobranch system with USE and word embeddings branches only gave a marginal improvement compared to the baseline system. Using the three-branch neural network

Improving Automatic Hate Speech Detection with Multiword Expression Features

9

Table 3: Confusion matrix (%) for HatEval test set using baseline system (USE) and

proposed system (USE with MWEall and BERT embeddings).

USE

USE, MWEall, BERT

Predicted labels

Predicted labels

Non-hateful Hateful Non-hateful Hateful

True

Labels

Non-hateful Hateful

58.4 24.4

41.6 75.6

62.0 27.5

37.9 72.4

Table 4: Confusion matrix (%) for Founta test set using baseline system (USE) and

proposed system (USE with MWEall and BERT embedding).

USE

USE, MWEall, BERT

Predicted labels

Predicted labels

Non-hate Abusive Hateful Non-hate Abusive Hateful

True labels

Non-hateful Abusive Hateful

95.4 7.5 35.4

4.1 0.4 90.1 2.3 39.8 24.7

95.2 8.7 34.8

4.2 0.4 88.5 2.6 37.6 27.5

with only VMWE5 or MWE5 instead of MWEall seems to be interesting only for word2vec embedding. With BERT embedding it is better to use MWEall categories. Finally, the use of all MWEs could be helpful rather than the use of a subgroup of MWE categories. Comparing word2vec and BERT embeddings, dynamic word embedding performs slightly better than the static one, however, the difference is not significant.
Table 3 compares the confusion matrices of two systems: the baseline system and the proposed one with MWEall and BERT embeddings. On the HatEval test corpus, the proposed system classifies better non-hateful tweets than the baseline system (62.0% versus 58.4%). On the other hand, the proposed system classifies a little less well hate speech (72.4% versus 75.6 %). On Founta test set (see Table 4), the conclusions are different, the proposed system classifies better hateful tweets than baseline system (27.5% versus 24.7%), and a little less well normal and abusive speech: 95.2% versus 95.4% for normal speech and 88.5% versus 90.1% for abusive speech. This difference in detection results between HatEval and Founta is confirmed by the F1 score per class in the first part of table 2. We think that the balance between the classes plays an important role here: in the case of HatEval corpus, the classes are balanced, in the case of Founta, the classes are unbalanced.
To perform a deeper analysis, we focus our observations on only the tweets from the test sets containing at least one MWE: 758 tweets from the HatEval test set and 3508 tweets from the Founta test set. Indeed, according to section 4, there is about 25% of tweets containing MWEs. The second part of table 2 shows that the results are consistent with those observed previously in this section, and the obtained improvement is more important.

10

Zampieri et al.

6 Conclusion

In this work, we explored a new way to design a HSD system for short texts, like tweets. We proposed to add new features to our DNN-based detection system: mutliword expression features. We integrated MWE features in a USE-based neural network thanks to a neural network of three branches. This network allows to take into account sentence-level features (USE embedding) and word-level features (MWE categories and the embeddings of the words belonging to the MWEs). The results were validated on two tweet corpora: HatEval and Founta. The models we proposed yielded significant improvements in macro-F1 over the baseline system (USE system). Furthermore, on HatEval corpus, the proposed system with MWEall categories and BERT embedding significantly outperformed the state-of-the-art system FERMI ranked first at the SemEval2019 shared task 5. These results showed that MWE features allow to enrich our baseline system. The proposed approach can be adapted to other NLP tasks, like sentiment analysis or automatic translation.

References
1. Badjatiya, P., Gupta, S., Gupta, M., Varma, V.: Deep learning for hate speech detection in tweets. Proceedings of the 26th International Conference on World Wide Web Companion (2017)
2. Basile, V., Bosco, C., Fersini, E., Nozza, D., Patti, V., Rangel Pardo, F.M., Rosso, P., Sanguinetti, M.: SemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women in twitter. In: Proceedings of the 13th International Workshop on Semantic Evaluation. pp. 54­63. ACL, Minneapolis, Minnesota, USA (Jun 2019). https://doi.org/10.18653/v1/S19-2007, https://www.aclweb.org/ anthology/S19-2007
3. Cer, D., Yang, Y., Kong, S.y., Hua, N., Limtiaco, N., St. John, R., Constant, N., GuajardoCespedes, M., Yuan, S., Tar, C., Strope, B., Kurzweil, R.: Universal sentence encoder for English. In: Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. pp. 169­174. ACL, Brussels, Belgium (Nov 2018). https://doi.org/10.18653/v1/D18-2029, https://www.aclweb.org/ anthology/D18-2029
4. Chatzakou, D., Kourtellis, N., Blackburn, J., Cristofaro, E.D., Stringhini, G., Vakali, A.: Mean birds:detecting aggression and bullying on twitter. In: Proceedings of the 2017 ACM on Web Science Conference. p. 13­22 (2017)
5. Chen, Y., Zhu, S., Zhou, Y., Xu, H.: Detecting offensive language in social media to protect adolescent online safety. In: Proceedings of the 2012 ASE/IEEE International Conference on Social Computing. pp. 71­­80. Washington, USA (2012)
6. Conneau, A., Kiela, D., Schwenk, H., Barrault, L., Bordes, A.: Supervised learning of universal sentence representations from natural language inference data. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. pp. 670­680. ACL, Copenhagen, Denmark (Sep 2017). https://doi.org/10.18653/v1/D17-1070, https: //www.aclweb.org/anthology/D17-1070
7. Constant, M., Eryigit, G., Monti, J., Plas, L.v.d., Ramisch, C., Rosner, M., Todirascu, A.: Multiword expression processing: A Survey. Computational Linguistics 43(4), 837­892 (Dec 2017), https://www.aclweb.org/anthology/J17-4005

Improving Automatic Hate Speech Detection with Multiword Expression Features

11

8. Corazza, M., Menini, S., Cabrio, E., Tonelli, S., Villata, S.: Hybrid emoji-based masked language models for zero-shot abusive language detection. In: Findings of the Association for Computational Linguistics: EMNLP 2020. pp. 943­949. ACL, Online (Nov 2020), https: //www.aclweb.org/anthology/2020.findings-emnlp.84
9. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre-training of deep bidirectional transformers for language understanding. In: Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). pp. 4171­4186. ACL, Minneapolis, Minnesota (Jun 2019). https://doi.org/10.18653/v1/N19-1423, https://www.aclweb. org/anthology/N19-1423
10. Founta, A., Djouvas, C., Chatzakou, D., Leontiadis, I., Blackburn, J., Stringhini, G., Vakali, A., Sirivianos, M., Kourtellis, N.: Large scale crowdsourcing and characterization of twitter abusive behavior. CoRR abs/1802.00393 (2018), http://arxiv.org/abs/1802. 00393
11. Gharbieh, W., Bhavsar, V., Cook, P.: Deep learning models for multiword expression identification. In: Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017). pp. 54­64. ACL, Vancouver, Canada (Aug 2017). https://doi.org/10.18653/v1/S17-1006, https://www.aclweb. org/anthology/S17-1006
12. Gillick, L., Cox, S.J.: Some statistical issues in the comparison of speech recognition algorithms. In: International Conference on Acoustics, Speech, and Signal Processing,. pp. 532­535 vol.1. Glasgow, UK (1989)
13. Godin, F.: Improving and Interpreting Neural Networks for Word-Level Prediction Tasks in Natural Language Processing. Ph.D. thesis, Ghent University, Belgium (2019)
14. Indurthi, V., Syed, B., Shrivastava, M., Chakravartula, N., Gupta, M., Varma, V.: FERMI at SemEval-2019 task 5: Using sentence embeddings to identify hate speech against immigrants and women in twitter. In: Proceedings of the 13th International Workshop on Semantic Evaluation. pp. 70­74. ACL, Minneapolis, Minnesota, USA (Jun 2019). https://doi.org/10.18653/v1/S19-2009, https://www.aclweb.org/ anthology/S19-2009
15. Isaksen, V., Gamba¨ck, B.: Using transfer-based language models to detect hateful and offensive language online. In: Proceedings of the Fourth Workshop on Online Abuse and Harms. pp. 16­27. ACL, Online (Nov 2020), https://www.aclweb.org/anthology/ 2020.alw-1.3
16. Lee, Y., Yoon, S., Jung, K.: Comparative studies of detecting abusive language on twitter. In: Proceedings of the 2nd Workshop on Abusive Language Online (ALW2). p. 101­106 (2018)
17. Mikolov, T., Chen, K., Corrado, G., Dean, J.: Efficient estimation of word representations in vector space. In: ICLR Workshop Papers (2013), http://arxiv.org/abs/1301. 3781
18. Mozafari, M., Farahbakhsh, R., Crespi, N.: A bert-based transfer learning approach for hate speech detection in online social media. CoRR abs/1910.12574 (2019), http://arxiv. org/abs/1910.12574
19. Nobata, C., Tetreault, J., Thomas, A., Mehdad, Y., Chang, Y.: Abusive language detection in online user content. In: Proceedings of the 25th International Conference on World Wide Web. p. 145­153. Montre´al, Canada (2016)
20. Pamungkas, E.W., Cignarella, A.T., Basile, V., Patti, V.: Automatic identification of misogyny in english and italian tweets at evalita 2018 with a multilingual hate lexicon. In: EVALITA@CLiC-it (2018)
21. Ramisch, C., Cordeiro, S.R., Savary, A., Vincze, V., Barbu Mititelu, V., Bhatia, A., Buljan, M., Candito, M., Gantar, P., Giouli, V., Gu¨ngo¨r, T., Hawwari, A., In~urrieta, U., Ko-

12

Zampieri et al.

valevskaite, J., Krek, S., Lichte, T., Liebeskind, C., Monti, J., Parra Escart´in, C., QasemiZadeh, B., Ramisch, R., Schneider, N., Stoyanova, I., Vaidya, A., Walsh, A.: Edition 1.1 of the PARSEME shared task on automatic identification of verbal multiword expressions. In: Proceedings of the Joint Workshop on Linguistic Annotation, Multiword Expressions and Constructions (LAW-MWE-CxG-2018). pp. 222­240. ACL, Santa Fe, New Mexico, USA (Aug 2018), https://www.aclweb.org/anthology/W18-4925 22. Rizwan, H., Shakeel, M.H., Karim, A.: Hate-speech and offensive language detection in roman urdu. In: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing EMNLP. pp. 2512­2522 (2020) 23. Sag, I., Baldwin, T., Bond, F., Copestake, A., Flickinger, D.: Multiword expressions: A pain in the neck for nlp. In: Proceedings of CICLING-2002. pp. 1­15. Mexico City, Mexico (02 2002) 24. Savary, A., Ramisch, C., Cordeiro, S., Sangati, F., Vincze, V., QasemiZadeh, B., Candito, M., Cap, F., Giouli, V., Stoyanova, I., Doucet, A.: The PARSEME shared task on automatic identification of verbal multiword expressions. In: Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017). pp. 31­47. ACL, Valencia, Spain (Apr 2017). https://doi.org/10.18653/v1/W17-1704, https://www.aclweb. org/anthology/W17-1704 25. Schneider, N., Hovy, D., Johannsen, A., Carpuat, M.: SemEval-2016 task 10: Detecting minimal semantic units and their meanings (DiMSUM). In: Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016). pp. 546­559. ACL, San Diego, California (Jun 2016). https://doi.org/10.18653/v1/S16-1084, https://www.aclweb.org/ anthology/S16-1084 26. Schneider, N., Smith, N.A.: A corpus and model integrating multiword expressions and supersenses. In: Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 1537­1547. ACL, Denver, Colorado (May­Jun 2015). https://doi.org/10.3115/v1/N15-1177, https: //www.aclweb.org/anthology/N15-1177 27. Stankovic´, R., Mitrovic´, J., Jokic´, D., Krstev, C.: Multi-word expressions for abusive speech detection in Serbian. In: Proceedings of the Joint Workshop on Multiword Expressions and Electronic Lexicons. pp. 74­84. ACL, online (Dec 2020), https://www.aclweb.org/ anthology/2020.mwe-1.10 28. Taslimipoor, S., Bahaadini, S., Kochmar, E.: MTLB-STRUCT @parseme 2020: Capturing unseen multiword expressions using multi-task learning and pre-trained masked language models. In: Proceedings of the Joint Workshop on Multiword Expressions and Electronic Lexicons. pp. 142­148. ACL, online (Dec 2020), https://www.aclweb.org/ anthology/2020.mwe-1.19 29. Taslimipoor, S., Rohanian, O.: SHOMA at parseme shared task on automatic identification of vmwes: Neural multiword expression tagging with high generalisation. CoRR abs/1809.03056 (2018), http://arxiv.org/abs/1809.03056 30. Waseem, Z., Hovy, D.: Hateful symbols or hateful people? predictive features for hate speech detection on twitter. In: Proceedings of the NAACL Student Research Workshop. pp. 88­ 93. ACL, San Diego, California (Jun 2016). https://doi.org/10.18653/v1/N16-2013, https: //www.aclweb.org/anthology/N16-2013

