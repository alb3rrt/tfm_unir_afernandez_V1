
# GMAIR: Unsupervised Object Detection Based on Spatial Attention and Gaussian Mixture

[arXiv](https://arxiv.org/abs/2106.01722), [PDF](https://arxiv.org/pdf/2106.01722.pdf)

## Authors

- Weijin Zhu
- Yao Shen
- Linfeng Yu
- Lizeth Patricia Aguirre Sanchez

## Abstract

Recent studies on unsupervised object detection based on spatial attention have achieved promising results. Models, such as AIR and SPAIR, output "what" and "where" latent variables that represent the attributes and locations of objects in a scene, respectively. Most of the previous studies concentrate on the "where" localization performance; however, we claim that acquiring "what" object attributes is also essential for representation learning. This paper presents a framework, GMAIR, for unsupervised object detection. It incorporates spatial attention and a Gaussian mixture in a unified deep generative model. GMAIR can locate objects in a scene and simultaneously cluster them without supervision. Furthermore, we analyze the "what" latent variables and clustering process. Finally, we evaluate our model on MultiMNIST and Fruit2D datasets and show that GMAIR achieves competitive results on localization and clustering compared to state-of-the-art methods.

## Comments

15 pages, 5 figures

## Source Code

Official Code

- [https://github.com/EmoFuncs/GMAIR-pytorch](https://github.com/EmoFuncs/GMAIR-pytorch)

Community Code

- [https://paperswithcode.com/paper/gmair-unsupervised-object-detection-based-on](https://paperswithcode.com/paper/gmair-unsupervised-object-detection-based-on)

## Bibtex

```tex
@misc{zhu2021gmair,
      title={GMAIR: Unsupervised Object Detection Based on Spatial Attention and Gaussian Mixture}, 
      author={Weijin Zhu and Yao Shen and Linfeng Yu and Lizeth Patricia Aguirre Sanchez},
      year={2021},
      eprint={2106.01722},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

## Notes

Type your reading notes here...

