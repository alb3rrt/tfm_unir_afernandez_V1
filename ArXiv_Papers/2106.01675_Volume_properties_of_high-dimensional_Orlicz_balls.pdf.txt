Volume properties of high-dimensional Orlicz balls
F. Barthe and P. Wolff

arXiv:2106.01675v1 [math.FA] 3 Jun 2021

Abstract
We prove asymptotic estimates for the volume of families of Orlicz balls in high dimensions. As an application, we describe a large family of Orlicz balls which verify a famous conjecture of Kannan, Lov´asz and Simonovits about spectral gaps. We also study the asymptotic independence of coordinates on uniform random vectors on Orlicz balls, as well as integrability properties of their linear functionals.
Lebesgue spaces play a central role in functional analysis, and enjoy remarkable structural properties. A natural extension of this family is given by the class of Orlicz spaces, which also enjoy a wealth of remarkable properties, see e.g. [20]. Similarly, for p  1, the unit balls of Rn equipped with the p-norm, often denoted by Bpn = {x  Rn; i |xi|p  1}, are well studied convex bodies, and usually the first family of test cases for new conjectures. Their simple analytic description allows for many explicit calculations, for instance of their volume. A simple probabilistic representation of uniform random vectors on Bpn, given in terms of i.i.d. random variables of law exp(-|t|p) dt/Kp is available, see [4]. It allows to investigate various fine properties of the volume distribution on Bpn. The study of general Orlicz balls is more difficult, due to the lack of explicit formulas, in particular for the volume of the set itself.
In this note, we show that probabilistic methods allow to derive precise asymptotic estimates of the volume of Orlicz balls when the dimension tends to infinity, and rough estimates which are valid in every dimension. This allows us to complement a result of Kolesnikov and Milman [12] on the spectral gap of uniform measures on Orlicz balls, by giving an explicit description of the range of parameters where their result applies, see Section 5. In Section 6, we show, among other results, the asymptotic independence of a fixed set of coordinates of uniform random vectors on some families of Orlicz balls of increasing dimensions. This is a natural extension of a classical observation (going back to Maxwell) about uniform vectors on Euclidean spheres and balls. The last section deals with properties of linear functionals of random vectors on Orlicz balls.
After this research work was completed, we learned by J. Prochno of his independent work [10] with Z. Kabluchko about similar volume asymptotics for Orlicz balls. Their paper uses sophisticated methods from the theory of large deviations, which have the potential to give more precise results for a given sequence of balls in increasing dimensions. Our approach is more elementary and focuses on uniform convergence over some wide range of parameters, as required by our applications to the spectral gap conjecture.

1 Notation and statement

For a given Young function  : R  R+ and  > 0, denote

n
Bn = x  Rn : (xi)  1
i=1

the corresponding n-dimensional Orlicz ball. Our aim is to estimate the asymptotic volume

of Bn/En = {x  Rn :

n i=1

(xi)



En}

for

relevant

sequences

En

of

linear

order

in

the

dimension.

1

Let  > 0. Consider the following probability measure on R,

µ(dt)

=

e-(t)

dt Z

,

with Z being a normalization constant. Let X be a random variable with the distribution

µ. Set

m = m = E(X), 2 = 2 = Var (X) .

Our aim is to prove

Theorem 1.1. Consider a Young function  and  > 0. Let n  1 be an integer and

  R. Set

 E := mn +  n,

then

Vol Bn/E

=

(Zem )n

1  2n

e-2 /2 e n (1

+

O(n-1/2))

= ZneE e-2/2(1 + O(n-1/2)),  2n

where the term O(n-1/2) depends on ,  and, non-decreasingly in ||.

Corollary 1.2. Consider a Young function  and  > 0. Let (an)n1 be a bounded sequence, and En := mn + an n, Then when the dimension n tends to ,

Vol Bn/En

 ZneEn e-a2n/(2)2 .  2n

Let

us

mention

that

the

above

results

can

be

applied

to

Bn /En

when

En

=

 mn + an n

where m > 0 is fixed and (an)n is a bounded sequence. Indeed the next lemma ensures

the existence of a  > 0 such that m = m.

Lemma 1.3. Let  as above. Then the map defined (0, +) to (0, +) by

  R() :=

(t)e-(t)dt e-(t) dt

is onto.

Proof. By hypothesis, exp(-) <  for all  > 0. This fact allows us to apply the dominated convergence theorem, and to show that the ratio R() is a continuous function of  > 0. Let us show that lim0+ R() =  and lim R() = 0. The claim will then follow by continuity.
Consider an arbitrary K > 0. Since   0,

e- e-



K

K e- e-

=

K

1-

<K e- e-

K

1

-

Vol({x;

(x) < e-

K })

.

By monotone convergence, lim0+ e- = . Hence, lim inf0+ R()  K. Since this holds for every K > 0, we conclude that lim0+ R() = .
Let  > 0. As above, since   0,

e- e-



+

> e- e-

.

2

Next, using x  ex and for  > 2,

e- 

e-(-1) =

e-e-(-2)  e-(-2) e-,

>

>

>

and

e- 

e-  e-/2Vol({x; (x)  /2}).

/2

Since (0) = 0 and  is continuous, the latter quantity is positive. Combining the above three estimates, we get

e- e-





+

e-(

 2

-2)

Vol({x;

e- (x) 

/2}) .

Letting    yields lim sup R()  , for all  > 0.

2 Probabilistic formulation

We start with a formula relating the volume with an expectation expressed in terms of
independent random variables. Let  > 0. Let (Xi)iN be i.i.d. r.v.'s with the distribution µ(dt) = e-(t) dt/Z. Recall that m = E(Xi) and 2 = Var (Xi) . We denote by Sn the normalized central limit sums:

Sn

=

1  n

n
((Xi) - m).
i=1

With this notation, we get the following representation for any  > 0

Vol Bn/E

=

1{

n i=1

(xi)E}dx

=

1{

n i=1

(xi

)E

}

Zne

= ZnE e

n i=1

(Xi

)

1{

n i=1

(Xi

)E}



= (Zem )nE

e 1 

nSn

{Sn 

E -m n  n

}

.

n

n i=1

(xi)

µ(dxi)

i=1

(2.1)

By the Central Limit Theorem, Sn converges in distribution to a standard Gaussian random variable when n tends to infinity. Such Gaussian approximation results allow to estimate the asymptotic behaviour of the above expectations. Nevertheless, a direct application of the CLT or the Berry-Esseen bounds does not seem to be sufficient for our purposes. A more refined analysis is required, built on classical results and techniques on the distribution of sums of independent random variables which go back to Cram´er [7] (see also [2]).
Theorem 1.1 is a direct consequence of the following one, applied to Yi = ((Xi) - m)/. For a random variable V , let PV and V denote the distribution and the characteristic function.

Theorem 2.1. Let (Yi)i1 be a sequence of i.i.d. real random variables, normalized so

that EYi = 0 and Var(Yi) = 1. Suppose ,  > 0 are such that so-called Cram´er's condition

is satisfied for Yi:

|Yi (t)|  1 -  for |t| > . 
For n  1, let Sn = (Y1 + · · · + Yn)/ n. Then for  > 0 and   R,

(2.2)

E


e n Sn 1Sn

= 1 en-2/2 1 + O(n-1/2) .  2n

3

Remark 2.2. The term O(n-1/2) involves an implicit dependence in ,  and the law of Y1. For n  162 + (2|| + 1)2-2, our argument provides a term O(n-1/2) which depends only on (, , 1/, 3 := E|Yi|3, ||). Moreover the dependence is continuous in the parameters, and non-decreasing in all the parameters but . This allows for uniform bounds when the parameters are in compact subsets of their domain.
Remark 2.3. Note that non-trivial  and  exist by the Riemann-Lebesgue lemma as soon has the law of Yi is absolutely continuous.

3 Probabilistic preliminaries

We start with some useful lemmas. The first one is a key estimate for quantitative central limit theorems, quoted from Petrov's book [17].

Lemma 3.1 ([17], Lemma V.2.1, p. 109). Let X1, . . . , Xn be independent random variables,

EXj = 0, E|Xj|3 <  (j = 1, . . . , n). Denote Bn =

n j=1

EXj2,

Ln

=

Bn-3/2

n j=1

E|Xj

|3

and Sn = Bn-1/2

n j=1

Xj .

Then

|Sn (t) - e-t2/2|  16Ln|t|3e-t2/3

for

|t|



1 4Ln

.

Lemma 3.2 ([17], Lemma I.2.1, p. 10). For any characteristic function ,

1 - |(2t)|2  4(1 - |(t)|2)

holds for all t  R.

Lemma 3.3. Let (Sn) be as in Theorem 2.1. Let T be independent of (Sn) and assume

that its characteristic function T is Lebesgue integrable. Then for all n  1, the density

of

Sn

+

T n

is bounded by a number C

= C(1/, , 3,

T

1), which is non-decreasing in

each of its parameters.

Proof of Lemma 3.3. Since Sn+T/n = SnT (·/n) is Lebesgue integrable, the inversion

formula

ensures

that

the

density

of

Sn

+

1 n

T

at

x

equals

gSn+

1 n

T

(x)

=

1 2


e-itxSn (t)T t/n dt
-

=

1 2


e-itx e-t2 /2 T
-

t/n

dt

+

1 2


e-itx(Sn (t) - e-t2/2)T t/n dt
-



1 2

+

1 2


|Sn (t) - e-t2/2| |T t/n | dt.
-

To bound the last integral, we apply Lemma 3.1 with Bn = n and Ln = 3n-1/2. We get

gSn+T /n(x)



1 2

+

1 2



|t|

n 43

163 n

|t|3

e-t2

/3

dt

+

1 2

|t|>

 n
43

(|Sn

(t)|

+

e-t2 /2 )|T

t/n

| dt



1 2

+

723 n

+

1 2

|t|>

n 43

|Sn (t)| |T

t/n

|

dt

+

1 2

|t|>

n 43

e-t2/2 dt.

I

For integral (I) from the last line we use (2.2) which implies

|Sn (t)| =

Y1

 t/ n

n

 (1 - )n

 for |t|   n.

4

However,



might

be

larger

than

1 43

,

i.e.

43



1.

If

this

is

so,

we

use

Lemma

3.2

on

characteristic functions: since (2.2) implies

1 - |Yi (t)|2   for |t|  ,

Lemma 3.2 implies that for any non-negative integer k,

1 - |Yi (t)|2  4-k for |t|  2-k.

Taking k = log2(43))

implies 2-k 

1 43

and 4-k



1 (83 )2

and hence

|Yi (t)|2



1

-

 (83)2

for

|t|



1 43

.

In any case, we obtain that |Sn (t)| 

1

-

 max(1, (83)2)

n/2



for

|t|



n 43

.

(3.1)

Using the above we estimate the integral (I) as follows. Using a simple estimate

(1 - x)m

= em log(1-x)

 e-mx

=

1 emx



1 mx

valid for any m > 0 and x  (0, 1) (it can be improved if needed), we get

I

1

-

 max(1, (83)2)

n/2



n |T (u)| du

0

 n 2 max(1, (83)2) n

T

12

T

1

1

+

(83)2 

.

Finally

we

obtain

that

the

density

of

Sn +

1 n

T

is

bounded

by

C1 + C23 + C3

T

1+(3 )2 1

for some constant C1, C2, C3 > 0.

Denote by  the density of the standard normal distribution on R and let  be its cumulative distribution function. Our last two preliminary statements are easy consequences of the equality et(t) = e2/2(t - ) satisfied by the Gaussian density

Lemma 3.4. Let Z be a standard normal random variable. For any Borel set A  R,

EeZ 1ZA = e2/2P(Z  A - ).

(3.2)

Lemma

3.5.

For

any

s

>

0

and



 R,

and



such

s -

 s

> 1,

it

holds

 e-x  1

e-

(x-)2 2s2

dx

=

1

e-

2 2s2

0

2s

2s

1+O

1

+

|| s

s

-

 s

.

In particular if s and  stay bounded in the sense that s  [1/S, S], ||  A holds for some

A, S > 0, then for  > 2AS-2 + S-1, the last factor simplifies to 1 + OA,S

1 

.

Proof. Using a standard Gaussian random variable Z, we rewrite the left-hand side as

T :=

 e-x  1

e-

(x-)2 2s2

0

2s

dx

=

Ee-(sZ

+)

1Z

>-

 s

=

e-e2s2/2P

Z

>

s

-

 s

=

e-

2 2s2

e(s-

 s

)2

/2

1 -  s - 

s

5

where the second equality follows from (3.2). Next we use the classical bound, for t > 0,

1



 2

et2/2

1 - (t)



1

,

t

t2 + 2

which

implies

that

for

t

>

1,

 2

tet2

/2

1 - (t)

=

1

+

O(1/t2).

When

s

-

 s

>

1

we

obtain that



2

2s e 2s2 T

=

s

s

-

 s

1+O

1

(s

-

 s

)2

=



1

+

s

s
-

 s

·

1+O

1

(s

-

 s

)2

=1+O

1

+

|| s

s

-

 s

.

The case when  and s are bounded readily follows.

4 Proof of Theorem 2.1

Our aim is to show that for any   R, I = J × (1 + O(n-1/2)) where


I = Ee nSn 1{Sn}

and

J = 1


e n

e-2

/2

.

 2n

The first step is to introduce the modified quantity I2 = Een(Sn+n-1Z)1{Sn+n-1Z},

and to check that it is enough for our purpose to establish I2 = J × (1 + O(n-1/2)). In order to do so we estimate the difference between I and I2.
By the triangle inequality:

|I2

- I|




Ee nSn

|en-1/2

Z

- 1|1{Sn}

+


Ee n(Sn

+n-1Z

)

1{Sn +n-1 Z }

-

1{Sn}

= I3 + I4 + I5,

where

I3

=


Ee nSn

|en-1/2

Z

-

1|1{Sn }

I4

=


Ee n(Sn

+n-1

Z

)1{<Sn

-n-1

Z

}

I5

=


Ee n(Sn

+n-1

Z

)1{-n-1

Z

<Sn}

.

By independence I3 = I · E|en-1/2Z - 1|. Next, we use that for t  [0, 1],

E|etZ - 1|  E e2tZ - 2etZ + 1 = e2t2 - 2et2/2 + 1  3t.

Thus, under the hypothesis n  162 we obtain that I3  3n I  3I/4. For the term I4, we introduce T = U + U  where U and U  are independent random
variables uniformly distributed in (-1, 1) and note that T (u) = (sin(u)/u)2 is Lebesgue integrable. Since |T |  2 a.s.,





I4  e n

P( < Sn   + n-1x)(x) dx

0





 e n P( - 2/n < Sn + T /n   + (x + 2)/n)(x) dx.

0

6

By Lemma 3.3, Sn + T /n has a density which is bounded by a constant, say C > 0. Then

I4  en

 0

C

x

+ n

4

(x)

dx

=

C n

en(-1/2

+ 2)

= C

·

  2

e2

/2

J

·

(-1/2

+ 2)

=

J

· O(n-1/2).

n

The term I5 is estimated in a similar way:

I5  en  en

 e n


exn-1/2P( - x/n < Sn  )(x) dx

0


exn-1/2P( - (x + 2)/n < Sn + T /n   + 2/n)(x) dx

0

 0

exC x

+ n

4 (x) dx

=

J

·

O(n-1/2).

This concludes the first step of the proof, which guarantees that for n  162

|I2

-

I|



3 n

I

+

O

1 n

J.

(4.1)

Our next task is to prove that I2 = J × (1 + O(n-1/2)). We use the Fourier transform approach. It relies on the Parseval formula, which ensures that whenever random variables
V and W have square integrable densities gV and gW , their characteristic functions are also square integrable and the following relation holds:

 -

gV

(x)gW (x) dx

=

1 2


V (t)W (t) dt.
-

(4.2)

Given

n,

set

W

=

 - (Sn

+

1 n

Z

).

Then

I2

= =

Eeennn(Sn0+n-1Zn)e1-{Sn+nxn-d1PZW(x} )=.





e nEe- nW

1W 0

 Let V a random variable having exponential distribution with parameter  n. We have

proved that

I2 := ne-nI2 = gV (x) dPW (x).

Observe

that

our

goal

is

to

establish

that

I2

=

1 e-2/2(1 + O(n-1/2)).
2

Since PW is given by the convolution of a probability measure and of the bounded

density of Z/n, it is absolutely continuous with bounded (and thus square-integrable)

density. Hence, we may apply the Parseval formula (4.2) to V and W . Since W (t) = eitSn (t)e-t2/(2n2), we obtain

where

I2

=

1 2

 -

1

1

-

it n

e-itSn

(t)e-t2 /(2n2 )

dt

=

M+ 2

E

,

M= E=

 -

e-it 1 - itn

e-t2 /2 e-t2 /(2n2 )

dt

 -

e-it 1 - itn

(Sn (t)

-

e-t2 /2 )e-t2 /(2n2 )

dt.

7

Applying Parseval's formula as before, but replacing Sn with and independent standard

Gaussian variable G yields M/(2) = n-2) distribution. Therefore

gV dPW where W =  - (G + Z/n) has N (, 1 +

M 2

=

 ne-n
-

e-

(x-)2 2(1+n-2

)

dx.

2(1 + n-2)

Lemma

3.5

with



:=

 n

and

s2

:=

1

+

n-2

yields,

provided

 n



2||

+

1,

M 2

=

1

e-

2 2(1+n-2 )

(1

+

O(n-1/2))

2(1 + n-2)

= 1

e-

2 2

(1

+

O(n-1/2

)).

2

It remains to bound the error term:

|E| = 

 -

e-it

1

-

it n

(Sn (t)

-

e-t2 /2 )e-t2 /(2n2 )

dt


Sn (t) - e-t2/2 e-t2/(2n2) dt
-





163n-1/2|t|3e-t2/3 dt

|t| n/(43)

+



Sn (t) e-t2/(2n2) dt +

|t|> n/(43)

 C3n-1/2 + I + II,



e-t2/2 dt

|t|> n/(43)

where the second inequality follows from Lemma 3.1. The estimate of the term II is

immediate:

II  2e-n/(1632).

In order to estimate I, we use (3.1) and a variant of its previous application using the bound (1 - x)m  1/emx  2/(mx)2 for x  (0, 1):

I

1

-

 max(1, (83)2)

n/2

 n 2

=

O3

,

1 

,

(n-1/2

).

Hence E = O(n-1/2) = e-2/2O(e2/2n-1/2) = e-2/2O||(n-1/2). This ends the proof of the second step, asserting I2 = J × (1 + O(n-1/2)). Combining the latter with (4.1) yields
the claim of the theorem.

5 Application to spectral gaps
Our volume asymptotics for Orlicz balls allow to complement a result of Kolesnikov and Milman [12] about a famous conjecture by Kannan, Lov´asz and Simonovits, which predicts the approximate value of the Poincar´e constants of convex bodies (a.k.a. inverse spectral gap of the Neumann Laplacian). More precisely if µ is a probability measure on some Euclidean space, one denotes by CP (µ) (resp. CPLin(µ)) the smallest constant C such that for all locally Lipschitz (resp. linear) functions f , it holds
Varµ(f )  C |f |2dµ.

8

Obviously CPLin(µ)  CP (µ), and the KLS conjecture predicts the existence of a universal constant c such that for any dimension n and any convex body K  Rn,

CP (K )  c CPLin(K ),

where K stands for the uniform probability measure on K. The conjecture turned out to be central in the understanding in high-dimension volume distributions of convex sets. We refer to e.g. [1, 5, 12, 13] for more background and references, and to [6] for a recent breakthrough. Kolesnikov and Milman have verified the conjecture for some Orlicz balls. We state next a simplified version of their full result on generalized Orlicz balls. Part of the simplification is unessential, as it amounts to reduce by dilation and translations to a convenient setting. A more significant simplification, compared to their work, is that we consider balls where all coordinates play the same role.

Theorem 5.1 ([12]). Let V : R  R+ be a convex function with V (0) = 0 and such that dµ(x) = e-V (x)dx is a probability measure. We also assume that the function x  xV (x), defined almost everywhere, belongs to the space L2(µ). For each dimension n  1, let

Leveln(V ) :=

E  0; e-E Voln BVn/E



1 e

nne-n n!

.

Then there exists a constant c, which depends only on V (through xV (X) L2(µ)) such that for all E  Leveln(V ),

CP (BVn/E )  c CPLin(BVn/E ).

Moreover,

Leveln(V

)

is

an

interval

of

length

at

most

e

n!en nn

=

 e 2n(1 + o(1))

as

n



,

and

1 + n V (x)e-V (x)dx  Leveln(V ).
R

We canprove more about the set Leveln(V ) and in particular we show that its length is of order n:

Proposition 5.2. Let V : R  R+ be a convex function with V (0) = 0 and such that

dµ(x) = e-V (x)dx is a probability measure. Let m1 be the average of µ and 1 its variance.

For every   (0, 1) there exists an integer n0 = n0(V, ) depending on V such that for all

n  n0,





m1n - 1(1 - ) 2n ; m1n + 1(1 - ) 2n  Leveln(V ).

Proof. µ = µ1

We apply and Z1 =

Theorem e-V =

1.1, with  = V and  = 1. With the 1. We choose E of the following form:

notation E = m1n

of +

the theorem 1 n with

||  (1 - ) 2. The theorem ensures that

Vol BVn/E

= eE e-2/2 1 2n

1 + O 1n

,

where

the

O(n-1/2)

is

uniform

in





[-(1

-

 ) 2, (1

-

 ) 2].

A

sharp

inequality

due

to

Nguyen and Wang ensures that 1 = Vare-V (V )  1 (see [16, 21], [15] and for a short proof [9]). Therefore

e-E Vol BVn/E

  1 e-(1-)2 2n

1 + O 1n

,

whereas

1 nne-n = e-1 (1 + o(1)).

e n!

2n

Hence for n large enough and for all  in the above interval e-EVol BVn/E



1 e

nne-n n!

.

9

Corollary 5.3. Let V : R  R+ be a convex function with V (0) = 0 and such that dµ(x) = e-V (x)dx is a probability measure, of expectation m1 and variance 1. We also assume that the function x  xV (x) belongs to the space L2(µ). Let  (0, 1). Then there exists c = c(V, ) such that for all n  1 and all E  m1n - 1(1 - ) 2n ; m1n + 1(1 - ) 2n ,
CP (BVn/E )  c CPLin(BVn/E ).
Proof. Combining the later proposition and theorem yields the result for n  n0(V, ). In order to deal with smaller dimensions, we simply apply known dimension dependent bounds: e.g. Kannan, Lov´asz and Simonovits [11] proved that CP (K)  nCPLin(K ) for all convex bodies K in Rn, with  a universal constant.

6 Asymptotic independence of coordinates

A classical observation, going back to Maxwell, but also attributed to Borel and to

Poincar´e, states that for a fixed k, dom vector on the Euclidean sphere

the law of the of Rn, centered

first k at the

ocoriogridninaantdesoforfaadiuusnifonrm, ternadns-

to the law of k independent standard Gaussian random variables as n tends to infinity.

Quantitative versions of this asymptotic independence property where given by Diaconis

and Freedman [8], as well as a similar result for the unit sphere of the for the 1-norm,

involving exponential variables in the limit. Extensions to random vectors distributed ac-

cording to the cone measure on the surface of the unit ball Bpn were given by Rachev and Ru¨schendorf [19], while Mogul'skii [14] dealt with the case of the normalized surface

measure. Explicit calculations, or the probabilistic representation put forward in [4], easily

yield asymptotic independence results for the first k coordinates of a uniform vector on

the set Bpn itself, when k is fixed and n tend to infinity. In this section we study marginals of a random vector (n) uniformly distributed on

Bn/En, where En and n tend to . Let us start with the simple case when En = mn for some m > 0, which can be
written as m = m for some  > 0. Let k  1 be a fixed integer, then the density at (x1, . . . , xk)  Rk of the first k coordinates (1(n), . . . , k(n)) is equal to

Voln-k Bn/En  {y  Rn; yi = xi, i  k} Vol Bn/En

=

Vol

Bn-k
/(En -

k i=1

(xi

))

Vol Bn/En

We apply Corollary 1.2 twice: once for the denominator, and once for the numerator after

writing

mn

-

ik

(xi)

=

m(n

-

k)

+

mk

- 
n

ik

(xi)

 n

-k

-

k.

We obtain that the above ratio is equivalent to

Zn-ke(En- ik (xi))  2(n - k)

·

  2n ZneEn



e-

k i=1

(xi

)

Zk

·

Thus we have proved the convergence in distribution of (1(n), . . . , k(n)) to µ k as n tends to infinity. In other words the first k coordinates of (n) are asymptotically i.i.d. of law µ.

This is true for more general balls and for a number of coordinates going also to infinity:



Theorem vector (n)

6.1. Let En be uniformly

= mn + distributed

n n, where (n)n1 on Bn/En. For any kn =

ois(bonu)n, ded.

Let

the

random

lim
n

dT

V

(1(n), . . . , k(nn)), µ kn

= 0.

10

Proof. Below, we tribution µ. Set

simply write i for i(n). tn := n1/4kn1/2 so that tn

Recall that 

(Xi)

= o( n) and kn

are i.i.d. = o(tn).

r.v.'s with the disThe total variation

distance between the law of (1(n), . . . , k(nn)) and µ kn is

Rkn

1 Vol(Bn/En )

Rn-kn

1{(x,y)Bn/En }

dy

-

1 Zkn

e-((x1)+···+(xkn ))

dx



Bkn/tn

Vol Bn-kn
/(En -

kn i=1

(xi ))

Vol(Bn/En )

-

1 Zkn

e-((x1)+···+(xkn ))

dx

+ P (1, . . . , kn )  Bkn/tn + P (X1, . . . , Xkn )  Bkn/tn

=

tn 0

Vol Bn-/(kEnn-t) Vol(Bn /En )

-

e-t Zkn

d dt

Vol(Bkn/t

)

dt

kn

kn

+P

(i) > tn + P

(Xi) > tn .

i=1

i=1

By Markov's inequality,

(6.1)

kn

E

P

(Xi) > tn 

i=1

kn i=1

(Xi)

tn

=

knm tn

=

o(1)

Similarly, and since by definition

n i=1

(i)



En

and

the

i's

are

exchangeable

kn

E

P

(i) > tn 

i=1

kn i=1

(i)

tn



knEn ntn

=

knm tn

=

o(1).





In order to estimate (6.1), we use Theorem 1.1. Since kn = o( n) and tn = o( n), we

know that En - t = m(n - kn) + n n - kn, where

n := n

n

n - kn

+

mkn - t  n - kn

is a bounded sequence such that n - n = o(1), both properties holding uniformly in t  [0, tn]. Therefore, Theorem 1.1 applied to Bn-/(kEnn-t) gives

Vol Bn-/(kEnn-t)

= Zn-kn e(En-t) e-n2 /2(1 + o(1))  2(n - kn)

uniformly in t  [0, tn]. On the other hand, Theorem 1.1 applied to Bn/En yields

Vol Bn/En

= ZneEn e-2n/2(1 + o(1)).  2n

Combining the above two asymptotic expansions, we obtain

Vol Bn-/(kEnn-t) Vol(Bn /En )

=

e-t Zkn

(1

+

o(1))

uniformly in t  [0, tn]. Therefore the term (6.1) equals

o(1)

tn 0

e-t Zkn

d dt

Vol(Bkn/t

)

dt

=

o(1)

·

P

kn
(Xi)  tn
i=1

= o(1).

11

The next result gives the asymptotic distribution of a sort of distance to the boundary for high-dimensional Orlicz balls.
 Theorem 6.2. Let En = mn+n n, where (n)n1 is bounded. Let the random vector (n) be uniformly distributed on Bn/En. Then the following convergence in distribution occurs as n goes to infinity:

n
 · En -  i(n)
i=1

- Exp(1).

Proof. Let Sn := En -

n i=1



i(n)

 0. For t  0,

n

P(Sn  t) = P

 i(n)  En - t

i=1

As before, Theorem 1.1 applied to Bn/En yields

=

Vol Bn/(En-t) Vol Bn/En

·

Vol Bn/En

 ZneEn e-2n/2,  2n

whereas applied to Bn/En-t it gives

Vol Bn/En-t

 Zne(En-t) e-

n- tn

2
/2.

 2n

Taking the quotient gives limn P(Sn  t) = e-t.

7 Integrability of linear functionals

Linear functionals of uniform random vectors on convex bodies are well studied quantities. Their density function, known as the parallel section function, measures the volume of hyperplane sections in a given direction. We refer e.g. to the book [5], and in particular to its sections 2.4 and 8.2 about the 1 and 2 properties, which describe uniform integrability features (exponential integrability for 1, Gaussian type integrability for 2). They can be expressed by upper bounds on the Laplace transform.
In this section, we deal with even Young functions , so that the corresponding sets Bn are origin-symmetric, and actually unconditional. The forthcoming study is valid for any dimension, without taking limits, so we consider the dimension n fixed, and write  = (1, . . . , n) for a uniform random vector on Bn . We show that the arguments of [3] for np unit balls extend to Orlicz balls.
Lemma 7.1. Let a  Rn, and  be uniform on Bn , then
n
Ee a,  Eeai1 .
i=1

Proof.

Let

1, . . . , n

be

i.i.d.

random

variables

with

P(i

=

1)

=

P(i

=

-1)

=

1 2

,

and

independent of . Then by symmetry of , (11, . . . , nn) has the same distribution as

. Hence,

n
Ee a, = E eaiii = E
i=1

n

E

eaiii 

i=1

n
= E cosh(aii).
i=1

12

Next by the subindependence property of coordinates, due Pilipczuk and Wojtaszczyk [18], and using the symmetry again as well as exchangeability:

n

n

n

Ee a,  E cosh(aii) = Eeaii = Eeai1 .

i=1

i=1

i=1

The above lemma shows that the Laplace transform of any linear functional a,  can be upper estimated using the Laplace transform of the first coordinate 1. Therefore it is natural to study the law of 1. For t  R consider the section of Bn :
S(t) := {y  Rn-1; (t, y)  Bn }.
and f (t) := Voln-1(S(t)). Then P1(dt) = f (t)dt/Voln(Bn ). By the Brunn principle, f is a log-concave function. It is also even by symmetry of the ball, therefore it is non-increasing on R+. We observe that a slightly stronger property holds:
Lemma 7.2. Let  be an even Young function and f (t) = Voln {y  Rn-1; (t, y)  Bn } . Then the function log f  -1 is concave and non-increasing on R+. Here -1 is the reciprocal function of the restriction of  to R+.
Proof. Let t, u  0. Let a  S(t) and b  S(u). Then by definition

n-1

n-1

(t) + (ai)  1 and (u) + (bi)  1.

i=1

i=1

Averaging these two inequalities and using the convexity of , we get for any   (0, 1):

n-1
(1 - )(t) + (u) +  ((1 - )ai + bi)  1.
i=1
This can be rewritten as
(1 - )a + b  S -1 ((1 - )(t) + (u)) .

(7.1)

Hence we have shown that (1 - )S(t) + S(u)  S -1 ((1 - )(t) + (u)) ,

and by the Brunn-Minkowski inequality, in multiplicative form f (t)1-f (u)  f -1 ((1 - )(t) + (u)) .

Note that if in (7.1) we had used convexity in the form ((1-)t+u)  (1-)(t)+(u), then we would have derived the Brunn principle from the Brunn-Minkowski inequality.

The next result shows that  is more convex than the square function, the corresponding Orlicz balls enjoy the 2 property. This applies in particular to Bpn for p  2, a case which was treated in [3].
 Theorem 7.3. Let  be an even Young function, such that t > 0  ( t) is convex. Let  be a uniform random vector on Bn . Then for all a  Rn,

Ee a, 

Ee

|a| n

1

n



e

1 2

E

a, 2 .

13

Proof. Let LX (t) = EetX denote the Laplace transform of a real valued random variable. Then with the notation of Lemma 7.2,

L1(t) =

etu

f

(u)

du Vol(Bn

)

.

Lemma 7.2 ensures that there exists a concave function c such that for all u  0, log f (u) = c((u)). Note that c is also non-increasing on R+ since the section function f is. Hence





u  0  log f ( u) = c(( u))



is concave. Theorem 12 of [3] ensures that t  0  R eu tf (u) du is log-concave. In other

words,



t  0  log L1( t)

is concave. From Lemma 7.1, using symmetry and the above concavity property

n

n

Ee a,  L1 (ai) = L1

i=1

i=1

a2i  L1

1 n

a2i

i

n
= L1

|a|

n
.

n

To conclude we need the bound L1(t)  et2E(12)/2 (it follows from the fact that t  0  log L1( t) is concave, hence upper bounded by its tangent application at 0, which is easily seen to be tE(12)/2). We obtain

Ee a,



e

1 2

|a|2

E(12

)

,

and we conclude using the symmetries of  since

E a,  2 = a2i E(i2) + aiajE(ij ) = |a|2E(12).

i

i=j

Acknowledgements: We are grateful to Emanuel Milman and Reda Chhaibi for useful discussions on related topics. We also thank Joscha Prochno for communicating his recent work to us.
References
[1] David Alonso-Guti´errez and Jesu´s Bastero. Approaching the Kannan-Lov´aszSimonovits and variance conjectures, volume 2131 of Lecture Notes in Mathematics. Springer, Cham, 2015.
[2] R. R. Bahadur and R. Ranga Rao. On deviations of the sample mean. Ann. Math. Statist., 31:1015­1027, 1960.
[3] F. Barthe and A. Koldobsky. Extremal slabs in the cube and the Laplace transform. Adv. Math., 174:89­114, 2003.
[4] Franck Barthe, Olivier Gu´edon, Shahar Mendelson, and Assaf Naor. A probabilistic approach to the geometry of the lpn-ball. Ann. Probab., 33(2):480­513, 2005.
[5] Silouanos Brazitikos, Apostolos Giannopoulos, Petros Valettas, and Beatrice-Helen Vritsiou. Geometry of isotropic convex bodies, volume 196 of Mathematical Surveys and Monographs. American Mathematical Society, Providence, RI, 2014.
14

[6] Yuansi Chen. An Almost Constant Lower Bound of the Isoperimetric Coefficient in the KLS Conjecture. Geom. Funct. Anal., 31(1):34­61, 2021.
[7] H. Cram´er. Sur un nouveau th´eor`eme-limite de la th´eorie des probabilit´es. Actualit´es scientifiques et Industrielles, 736, 1938.
[8] Persi Diaconis and David Freedman. A dozen de Finetti-style results in search of a theory. Ann. Inst. H. Poincar´e Probab. Statist., 23(2, suppl.):397­423, 1987.
[9] Matthieu Fradelizi, Mokshay Madiman, and Liyao Wang. Optimal concentration of information content for log-concave densities. In High dimensional probability VII, volume 71 of Progr. Probab., pages 45­60. Springer, [Cham], 2016.
[10] Zakhar Kabluchko and Joscha Prochno. The maximum entropy principle and volumetric properties of Orlicz balls. J. Math. Anal. Appl., 495(1):124687, 19, 2021.
[11] R. Kannan, L. Lov´asz, and M. Simonovits. Isoperimetric problems for convex bodies and a localization lemma. Discrete Comput. Geom., 13(3-4):541­559, 1995.
[12] Alexander V. Kolesnikov and Emanuel Milman. The KLS isoperimetric conjecture for generalized Orlicz balls. Ann. Probab., 46(6):3578­3615, 2018.
[13] Yin Tat Lee and Santosh S. Vempala. The Kannan-Lov´asz-Simonovits conjecture. In Current developments in mathematics 2017, pages 1­36. Int. Press, Somerville, MA, 2019.
[14] A. A. Mogul'skii. de Finetti-type results for lp. Sibirsk. Mat. Zh., 32(4):88­95, 228, 1991.
[15] Van Hoang Nguyen. Dimensional variance inequalities of Brascamp-Lieb type and a local approach to dimensional Pr´ekopa's theorem. J. Funct. Anal., 266(2):931­955, 2014.
[16] V.H. Nguyen. In´egalit´es fonctionnelles et convexit´e. PhD thesis, Universit´e Pierre et Marie Curie (Paris VI), 2013.
[17] V. V. Petrov. Sums of independent random variables. Springer-Verlag, New YorkHeidelberg, 1975. Translated from the Russian by A. A. Brown, Ergebnisse der Mathematik und ihrer Grenzgebiete, Band 82.
[18] Marcin Pilipczuk and Jakub Onufry Wojtaszczyk. The negative association property for the absolute values of random variables equidistributed on a generalized Orlicz ball. Positivity, 12(3):421­474, 2008.
[19] S. T. Rachev and L. Ru¨schendorf. Approximate independence of distributions on spheres and their stability properties. Ann. Probab., 19(3):1311­1337, 1991.
[20] M. M. Rao and Z. D. Ren. Theory of Orlicz spaces, volume 146 of Monographs and Textbooks in Pure and Applied Mathematics. Marcel Dekker, Inc., New York, 1991.
[21] L. Wang. Heat capacity bound, energy fluctuations and convexity. PhD thesis, Yale University, 2014.

Institut de Math´ematiques de Toulouse, UMR 5219 Universit´e de Toulouse & CNRS UPS, F-31062 Toulouse Cedex 09, France.

barthe@math.univ-toulouse.fr pwolff@mimuw.edu.pl

15

