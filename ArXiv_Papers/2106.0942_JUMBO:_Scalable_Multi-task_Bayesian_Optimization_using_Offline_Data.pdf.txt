JUMBO: Scalable Multi-task Bayesian Optimization using Offline Data

arXiv:2106.00942v1 [cs.LG] 2 Jun 2021

Kourosh Hakhamaneshi Pieter Abbeel Vladimir Stojanovic Aditya Grover

UC Berkeley

UC Berkeley

UC Berkeley

FAIR

Abstract
The goal of Multi-task Bayesian Optimization (MBO) is to minimize the number of queries required to accurately optimize a target black-box function, given access to offline evaluations of other auxiliary functions. When offline datasets are large, the scalability of prior approaches comes at the expense of expressivity and inference quality. We propose JUMBO, an MBO algorithm that sidesteps these limitations by querying additional data based on a combination of acquisition signals derived from training two Gaussian Processes (GP): a cold-GP operating directly in the input domain and a warm-GP that operates in the feature space of a deep neural network pretrained using the offline data. Such a decomposition can dynamically control the reliability of information derived from the online and offline data and the use of pretrained neural networks permits scalability to large offline datasets. Theoretically, we derive regret bounds for JUMBO and show that it achieves noregret under conditions analogous to GP-UCB [1]. Empirically, we demonstrate significant performance improvements over existing approaches on two real-world optimization problems: hyper-parameter optimization and automated circuit design.
1 Introduction
Many domains in science and engineering involve the optimization of an unknown black-box function. Such functions can be expensive to evaluate, due to costs such as time and money. Bayesian optimization (BO) is a popular framework for such problems as it seeks to minimize the number of function evaluations required for optimizing a target black-box function [2, 3]. In real-world scenarios however, we often have access to offline evaluations of one or more auxiliary black-box functions related to the target function. For example, one might be interested in finding the optimal hyperparameters of a machine learning model for a given problem and may have access to an offline dataset from previous runs of training the same model on a different dataset for various configurations. Multi-task Bayesian optimization (MBO) is an optimization paradigm that extends BO to exploit such additional sources of information from related black-box functions for efficient optimization [4].
Early works in MBO employ multi-task Gaussian Processes (GP) with inter-task kernels to capture the correlations between the auxiliary and target function [4­6]. Multi-task GPs however fail to scale to large offline datasets. More recent works have proposed combining neural networks (NN) with probabilistic models to improve scalability. For example, MT-BOHAMIANN [7] uses Bayesian NNs (BNN) [8] as surrogate models for MBO. The performance however, depends on the quality of the inference procedure. In contrast, MT-ABLR [9] uses a deterministic NN followed by a Bayesian Linear Regression (BLR) layer at the output to achieve scalability while permitting exact inference. However, the use of a linear kernel can limit the expressiveness of the posterior.
We propose JUMBO, an MBO algorithm that sidesteps the limitations in expressivity and tractability of prior approaches. In JUMBO, we first train a NN on the auxiliary data to learn a feature space, akin to MT-ABLR but without the BLR restriction on the output layer. Thereafter, we train two GPs simultaneously for online data acquisition via BO: a warm-GP on the feature space learned by
Preprint. Under review.

the NN and a cold-GP on the raw input space. The acquisition function in JUMBO combines the individual acquisition functions of both the GPs. It uses the warm-GP to reduce the search space by filtering out poor points. The remaining candidates are scored by the acquisition function for the cold-GP to account for imperfections in learning the feature space of the warm-GP. The use of GPs in the entire framework ensures tractability in posterior inference and updates.
Theoretically, we show that JUMBO is a no-regret algorithm under conditions analogous to those used for analyzing GP-UCB [1]. In practice, we observe significant improvements over the closest baseline on two real-world applications: transferring prior knowledge in hyper-parameter optimization and automated circuit design.
2 Background
We are interested in maximizing a target black-box function f :   R defined over a discrete or compact set   Rd. We assume only query access to f . For every query point x, we receive a noisy observation y = f (x) + . Here, we assume is standard Gaussian noise, i.e.,  N (0, n2 ) where n is the noise standard deviation. Our strategy for optimizing f will be to learn a probabilistic model for regressing the inputs x to y using the available data and using that model to guide the acquisition of additional data for updating the model. In particular, we will be interested in using Gaussian Process regression models within a Bayesian Optimization framework, as described below.
2.1 Gaussian Process (GP) Regression
A Gaussian Process (GP) is defined as a set of random variables such that any finite subset of them follows a multivariate normal distribution. A GP can be used to define a prior distribution over the unknown function f , which can be converted to a posterior distribution once we observe additional data. Formally, a GP prior is defined by a mean function µ0 :   R and a valid kernel function  :  ×   R. A kernel function  is valid if it is symmetric and the Gram matrix K is positive semi-definite. Intuitively, the entries of the kernel matrix Ki,j = (xi, xj) measure the similarity between any two points xi and xj. Given points X = {x1, x2, . . . , xn}, the distribution of the function evaluations f = [f (x1), f (x2), . . . f (xn)] in a GP prior follows a normal distribution, such that f |X  N (µ0(X), K(X, X)) where µ0(X) = [µ0(x1), µ0(x2), . . . µ0(xn)] and K(X, X) is a covariance matrix. For simplicity, we will henceforth assume µ0 to be a zero mean function.
Given a training dataset D, let XD and yD denote the inputs and their noisy observations. Since the observation model is also assumed to be Gaussian, the posterior over f at a test set of points X will follow a multivariate normal distribution with the following mean and covariance:
µ(f |D, X) = K(X, XD)T K~D-1yD, (f |D, X) = K(X, X) - K(X, XD)T K~D-1K(X, XD),
where K~D = K(XD, XD) + n2 I.
Due to the inverse operation during posterior computation, standard GPs can be computationally prohibitive for modeling large datasets. We direct the reader to [10] for an overview on GPs.
2.2 Bayesian Optimization (BO)
Bayesian Optimization (BO) is a class of sequential algorithms for sample-efficient optimization of expensive black-box functions [2, 3]. A BO algorithm typically runs for a fixed number of rounds. At every round t, the algorithm selects a query point xt and observes a noisy function value yt. To select xt, the algorithm first infers the posterior distribution over functions p(f |{(xi, yi)}ti=-11) via a probabilistic model (e.g., Gaussian Processes). Thereafter, xt is chosen to optimize an uncertaintyaware acquisition function that balances exploration and exploitation. For example, a popular acquisition function is the Upper Confidence Bound (UCB) which prefers points that have high expected value (exploitation) and high uncertainty (exploration). With the new point (xt, yt), the posterior distribution can be updated and the whole process is repeated in the next round. At round t, we define the instantaneous regret as rt = f (x) - f (xt) where x is the global optima and xt maximizes the acquisition function. Similarly, we can define the cumulative regret at round T
2

as the sum of instantaneous regrets RT =

T t=1

rt.

A

desired

property

of

any

BO

algorithms

is

to

be

no-regret where the cumulative regret is sub-linear in T as T  , i.e., limT  RT/T = 0.

2.3 Multi-task Bayesian Optimization (MBO)

Our focus setting in this work is a variant of BO, called Multi-Task Bayesian Optimization (MBO).
Here, we assume K > 0 auxiliary real-valued black-box functions {f1, . . . , fK}, each having the same domain  as the target function f [4, 7]. For each function fk, we have an offline dataset D(k) consisting of pairs of input points x and the corresponding function evaluations fk(x). If these auxiliary functions are related to the target function, then we can transfer knowledge from the offline data Daux = D(1)  · · ·  D(K) to improve the sample-efficiency for optimizing f . In
certain applications, we might also have access to offline data from f itself. However, in practice, f is typically expensive to query and its offline dataset Df will be very small.

We discuss some prominent works in MBO that are most closely related to our proposed approach below. See Section 5 for further discussion about other relevant work.

Multi-task BO [4] is an early approach that employs a custom kernel within a multi-task GP [5] to model the relationship between the auxiliary and target functions. Similar to standard GPs, multi-task GPs fail to scale for large offline datasets.

On the other hand, parametric models such as neural networks (NN), can effectively scale to larger datasets but do not defacto quantify uncertainty. Hybrid methods such as DNGO [11] achieve scalability for (single task) BO through the use of a feed forward deep NN followed by Bayesian Linear Regression (BLR) [12]. The NN is trained on the existing data via a simple regression loss (e.g, mean squared error). Once trained, the NN parameters are frozen and the output layer is replaced by BLR for the BO routine. For BLR, the computational complexity of posterior updates scales linearly with the size of the dataset. This step can be understood as applying a GP to the output features of the NN with a linear kernel (i.e. (xi, xj) = h(xi)T h(xj) where h is the NN function with parameters ). For BLR, the computational complexity of posterior inference is linear w.r.t. the number of data points and thus DNGO can scale to large offline datasets.

MT-ABLR [9] extends DNGO to multi task settings by training a single NN to learn a shared

representation h(x) followed by task-specific BLR layers (i.e. predicting f1(x), ..., fK (x), and f (x)

based on inputs). The learning objective corresponds to the maximization of sum of the marginal

log-likelihoods for each task:

K +1 t=1

p(yt

|wt,

h

(Xt),

t

).

The

main

task is

included

in

the last

index, wt is the Bayesian Linear layer weights for task t with prior p(wt) = N (0, w2 t I), t and wt

are the hyper-prior parameters, and (Xt, yt) is the observed data from task t. Learning h(x) by

directly maximizing the marginal likelihood improves the performance of DNGO while maintaining

the computational scalability of its posterior inference in case of large offline data. However, both

DNGO and ABLR have implicit assumptions on the existence of a feature space under which the

target function can be expressed as a linear combination. This can be a restrictive assumption and

furthermore, there is no guarantee that given finite data such feature space can be learned.

MT-BOHAMIANN [7] addresses the limited expressivity of prior approaches by employing Bayesian NNs to specify the posterior over f and feed the NN with input x and additional learned task-specific embeddings (t) for task t. While allowing for a principled treatment of uncertainties, fully Bayesian NNs are computationally expensive to train and their performance depends on the approximation quality of stochastic gradient HMC methods used for posterior inference.

3 Scalable MBO via JUMBO
In the previous section, we observed that prior MBO algorithms make trade-offs in either posterior expressivity or inference quality in order to scale to large offline datasets. Our goal is to show that these trade-offs can be significantly mitigated and consequently, the design of our proposed MBO framework, which we refer to as JUMBO, will be guided by the following desiderata: (1) Scalability to large offline datasets (e.g., via NNs) (2) Exact and computationally tractable posterior updates (e.g., via GPs) (3) Flexible and expressive posteriors (e.g., via non-linear kernels).
3.1 Regression Model

3

The regression model in JUMBO is composed of two GPs: a warm-GP and a cold-GP denoted by GPwarm(0, w) and GPcold(0, c), respectively. As shown in Figure 1, both GPs are trained to model the target function f but operate in different input spaces, as we describe next.

GPwarm (with hyperparameters w) operates on a feature

representation of the input space h(x) derived from the offline dataset Daux. To learn this feature space, we train a multi-headed feed-forward NN to minimize the mean squared error for each auxiliary task, akin to DNGO [11]. Thereafter, in contrast to both DNGO and ABLR, we do not train separate output BLR modules. Rather, we will directly train GPwarm on the output of the NN using the

Figure 1: JUMBO. During the pretraining phase, we learn a NN mapping h (orange) for the warm-GP. The next query based on t (purple) will be the point that has a high score based on the acquisition function of both warm and cold GP (blue).

data acquired from the target function f . Note that for training GPwarm, we can use any non-linear kernel, which results in an expressive posterior that

allows for exact and tractable inference using closed-form expressions.

Additionally, we can encounter scenarios where some of the auxiliary functions are insufficient in reducing the uncertainty in inferring the target function. In such scenarios, relying solely on GPwarm can significantly hurt performance. Therefore, we additionally initialize GPcold (with hyperparameters c) directly on the input space .
If we also have access to offline data from f (i.e. Df ), the hyperparameters of the warm and cold GPs can also be pre-trained jointly along with the neural network parameters. The overall pre-training objective is then given by:

L(, w, c) = LMSE(|Daux) + LGP (w|Df ) + LGP (c|Df )

(1)

where LGP (·|Df ) denotes the negative marginal log-likelihood for the corresponding GP on Df .

3.2 Acquisition Procedure
Post the offline pre-training of the JUMBO's regression model, we can use it for online data acquisition in a standard BO loop. The key design choice here is the acquisition function, which we describe next. At round t, let twarm(x) and tcold(x) be the single task acquisition function (e.g. UCB) of the warm and cold GPs, after observing t - 1 data points, respectively. Next, we define the acquisition function for JUMBO as a convex combination of the individual acquisition functions by employing an interpolation coefficient t(x)  [0, 1]. Formally,

t(x) = t(x)tcold(x) + (1 - t(x))twarm(x).

(2)

Our guiding intuition for the acquisition function in JUMBO is that we are most interested in querying points which are scored highly by the acquisition functions of both GPs.
To this end, note that Eq. 2 essentially captures that points with t(x)  0 will follow twarm(x) and points with t(x)  1 follow tcold(x). We can also choose t(x) to depend on twarm(x). By choosing t(x) to be close to 1 for points x with twarm(x)  maxx twarm(x), we can ensure to acquire points that have high acquisition scores as per both tcold(x) and twarm(x). Next, we will discuss some theoretical results that shed more light on the design of t(x).

3.3 Theoretical Analysis
Here, we will formally derive the regret bound for JUMBO and provide insights on the conditions under which JUMBO outperforms GP-UCB [1]. For this analysis, we will use Upper Confidence Bound (UCB) as our acquisition function for the warm and cold GPs. To do so, we utilize the notion of Maximum Information Gain (MIG). Definition 1 (Maximum Information Gain [1]). Let f  GP(0, ),  : Rd × Rd  R. Consider any   Rd and let ~ = {x1, ..., xn}   be a finite subset. Let y~  Rn be n noisy observations such that (y~ )i = (f~ )i + i, i  N (0, n2 ). Let I denote the Shannon mutual information.

4

The MIG n() of set  after n evaluations is the maximum mutual information between the function values and observations among all choices of n points in . Formally,

n() = max I(y~ ; f~ )
~ ,|~ |=n

This quantity depends on kernel parameters and the set , and also serves as an important tool for characterizing the difficulty of a GP-bandit. For a given kernel, it can be shown that n()  () where () = || for discrete and Vol() for the continuous case [1]. For example for Radial Basis kernel n([0, 1]d)  O(log(n)d+1). For brevity, we focus on settings where  is discrete. Further
results and analysis are deferred to Appendix A.

For GP-UCB [1], it has been shown that for any   (0, 1), if f  GP(0, ) (i.e., the GP assigns non-zero probability to the target function f ), then the cumulative regret RT after T rounds will be bounded with probability at least 1 - :

P r{RT  CT T T (), T  1}  1 - 

(3)

with C

=

8 log(1+n-2 )

and T

= 2 log

||2T 2 6

.

Recall that h :   Z is a mapping from input space  to the feature space Z. We will further make the following modeling assumptions to ensure that the target black-box function f is a sample

from both the cold and warm GPs.

Assumption 1. f  GPcold(0, c).

Assumption 2. Let  denote the NN parameters obtained via pretraining (Eq. 1).Then, there exists a function g  GPwarm(0, w) such that f = g  h .
Theorem 1. Let g   and ¯g =  \ g be some arbitrary partitioning of the input domain .
Define the interpolation coefficient as an indicator t(x) = 1(x  g). Then under Assumptions 1
and 2, JUMBO is no-regret.

Specifically, let s be the number of rounds such that the JUMBO queries for points xt  ¯g. Then,
for any   (0, 1), running JUMBO for T iterations results in a sequence of candidates (xt)tt==T1 for which the following holds with probability at least 1 - :

RT < CT T {T -s(g) + s(Z¯g)}, T  1

(4)

where C

=

8
log(1+n-2

)

,

t

=

2 log

|| 2 t2 3

, and Z¯g = {h (x)|x  ¯g} is the set of output

features for ¯g.

Based on the regret bound in Eq. 4, we can conclude that if the partitioning g is chosen such that (Z¯g) (¯g) and (g) (), then JUMBO has a tighter bound than GP-UCB. The first

condition implies that the second term in Eq. 4 is negligible and intuitively means that GPwarm will only need a few samples to infer the posterior of f defined on ¯g, making BO more sample efficient. The second condition implies that the T -s(g) T () which in

turn makes the regret bound of JUMBO tighter than GP-UCB. Note

that g cannot be made arbitrarily small, since ¯g (and therefore Figure 2: The effect of the pre-

Z¯g) will get larger which conflicts with the first condition. Figure 2 provides an illustrative example. If the learned feature space h (x) compresses set ¯g to a smaller set Z¯g, then GPwarm can infer the posterior of g(h (x)) with only a few samples in ¯g

trained NN h (x) on . In the desirable case, ¯g gets significantly compressed to Z¯g.

(because MIG is lower). Such h (x) will likely emerge when tasks share high-level features with one another. In the appendix, we have included an empirical analysis to show that GPwarmis indeed

operating on a compressed space Z. Consequently, if g is reflective of promising regions consisting of near-optimal points i.e. g = {x   | f (x) - f (x)  lf } for some lf > 0, BO will be able to quickly discard points from subset ¯g and acquire most of its points from g.

5

(a) Target (red) and auxiliary (blue) (b) Correlation between target and aux-

task

iliary tasks

(c) Posterior of GPwarm, GPcold, their UCB and JUMBO's acquisition function
Figure 3: Dynamics of JUMBO after observing 6 data points (a) The two functions have different optimums (b) The tasks are related (c) Iteration 4 of the BO with our proposed model, from top to bottom: (1) GP modeling input to objective using (x, h (x), y) samples (2) GP modeling input to objective using (x, y) samples (3) UCB acquisition function for GPwarm(4) UCB acquisition function for GPcold(5) JUMBO's acquisition function that compromises between the optimum of the two.
3.4 Choice of interpolation coefficient t(x)
The above discussion suggests that the partitioning g should ideally consist of near-optimal points. In practice, we do not know f and hence, we rely on our surrogate model to define (gt) = {x   | twarm - twarm(x)  l}. Here, twarm is the optimal value of twarm(x) and the acquisition threshold l > 0 is a hyper-parameter used for defining near-optimal points w.r.t. twarm(x). At one extreme, l   corresponds to the case where t(x) = tcold(x) (i.e. the GP-UCB routine) and the other extreme l  0 corresponds to case with t(x) = twarm(x). Figure 3 illustrates a synthetic 1D example on how JUMBO obtains the next query point. Figure 3a shows the main objective f (x) (red) and the auxiliary task f1(x) (blue). They share a periodic structure but have different optimums. Figure 3b shows the correlation between the two. Applying GP-UCB [1] will require a considerable amount of samples to learn the periodic structure and the optimal solution. However in JUMBO, as shown in Figure 3c, the warm-GP, trained on (h (x), y) samples, can learn the periodic structure using only 6 samples, while the posterior of the cold-GP has not yet learned this structure. It can also be noted from Figure 3c that JUMBO's acquisition function is tcold(x) when the value of twarm(x) is close to twarm. Therefore, the next query point (marked with a star) has a high score based on both acquisition functions. We summarize JUMBO in Algorithm 1.
4 Experiments
We are interested in investigating the following questions: (1) How does JUMBO perform on benchmark real-world black-box optimization problems relative to baselines? (2) How does the choice of threshold l impact the performance of JUMBO? (3) Is it necessary to have a non-linear mapping on the features learned from the offline dataset or a BLR layer is sufficient?
6

Algorithm 1: JUMBO

Input: Offline auxiliary dataset Daux , Offline target dataset D0f (optional; default: empty set), Threshold l Output: Sequence of solution candidates {xt}Tt=1 maximizing target function f

1 Initialize NN h(x), GPcold, GPwarm.

2 Pretrain NN params jointly with GPcold and GPwarm hyper-params using Daux and D0f as per Eq. 1.;

3 Initialize D0cold = {}, D0warm = {}. 4 for round t = 1 to T do

5 6

1 Set
Set

wt arm = t(x) =

a(rgmwt aramxx-wt awtrmarm(x(x) ).

l ).

7

Set t(x) = t(x)ctold(x) + (1 - t(x))wt arm(x)

8

Pick xt = argmaxx t(x).

9

Obtain noisy observation yt for xt.

10

Update Dtcold  Dtco-ld1  {(xt, yt)} and GPcold.

11

Update Dtwarm  Dtw-arm1  {(h (xi), yi)} and GPwarm.

12 end

Figure 4: The regret of MBO algorithms on Protein, Parkinsons, Naval, and Slice datasets. Standard errors are measured across 10 random seeds.
Our codebase is based on BoTorch [13], a Python library for Bayesian optimization that extends PyTorch [14]. It is provided in the Supplementary Materials with additional details in Appendix.
4.1 Application: Hyperparameter optimization
Datasets. We consider the task of optimizing hyperparameters for fully-connected NN architectures on 4 regression benchmarks from HPOBench [15]: Protein Structure [16], Parkinsons Telemonitoring [17], Naval Propulsion [18], and Slice Localization [19]. HPOBench provides a look-up-tablebased API for querying the validation error of all possible hyper-parameter configurations for a given regression task. These configurations are specified via 9 hyperparameters, that include continuous, categorical, and integer valued variables. The objective we wish to minimize is the validation error of a regression task after 100 epochs of training. For this purpose, we consider an offline dataset that consists of validation errors for some randomly chosen configurations after 3 epochs on a given dataset. The target task is to optimize this error after 100 epochs. In [15], the authors show that this problem is non-trivial as there is small correlation between epochs 3 and 100 for top-1% configurations across all datasets of interest. Evaluation protocol. We validate the performance of JUMBO against the following baselines with a UCB acquisition function [1]:
7

(a)

(b)

(c)

Figure 5: (a) Circuit Design results (b) The optimal acquisition threshold l (=0.05) is far from the GP-UCB and Offline DKL extremes. (c) The Non-linear mapping is a crucial piece of JUMBO's algorithm.

· GP-UCB [1] (i.e. cold-GP only) trains a GP from scratch disregarding Daux completely. Equivalently, it can be interpreted as JUMBO with t(x) = 1 x, t  1 in Eq. 2 and (x) = UCB(x).
· MT-BOHAMIANN [7] trains a BNN on all tasks jointly via SGHMC (Section 2.3).
· MT-ABLR [9] trains a shared NN followed by task-specific BLR layers (Section 2.3).
· GCP [20] uses Gaussian Copula Processes to jointly model the offline and online data.
· Offline DKL (i.e. warm-GP only) is our proposed extension to Deep Kernel Learning, where we train a single GP online in the latent space of a NN pretrained on Daux (See Section 5 for details). Equivalently, it can be interpreted as JUMBO with t(x) = 0 x, t  1 in Eq. 2.
Results. We run JUMBO (with l = 0.1) on all baselines for 50 rounds and 5 random seeds each and measure the simple regret per iteration. The regret curves are shown in Figure 4. We find that JUMBO achieves lower regret than the previous state-of-the-art algorithms for MBO in almost all cases. We believe the slightly worse performance on the slice dataset relative to other baselines is due to the extremely low top-1% correlation between epoch 3 and epoch 100 on this dataset as compared to others (See Figure 10 in [15]), which could result in a suboptimal search space partitioning obtained via the warm-GP. For all other datasets, we find JUMBO to be the best performing method. Notably, on the Protein dataset, JUMBO is always able to find the global optimum, unlike the other approaches.
4.2 Application: Automated Circuit Design
Next, we consider a real-world use case in optimizing circuit design configurations for a suitable performance metric, e.g., power, noise, etc. In practice, designers are interested in performing layout simulations for measuring the performance metric on any design configuration. These simulations are however expensive to run; designers instead often turn to schematic simulations which return inexpensive proxy metrics correlated with the target metric.
In our circuit environment, the circuit configurations are represented by an 8 dimensional vector, with elements taking continuous values between 0 and 1. The offline dataset consists of 1000 pairs of circuit configurations and a scalar goodness score based on the schematic simulations. We consider the same baselines as before: GP-UCB [1], MT-BOHAMIANN [7], MT-ABLR [9], Offline DKL, and GCP [20]. We also consider two other baselines: MF-GP-UCB [21], which extends the GP-UCB baseline to a multi-fidelity setting as schematic score values can be interpreted as a low-fidelity approximation of layout scores, and BOX-GP-UCB [22] which confines the search space to a hypercube over the promising region based on the offline data. We ran each algorithm with l = 0.1 for 100 iterations and measured simple regret against iteration. As reflected in the regret curves in Figure 5a, JUMBO outperforms other algorithms.
4.3 Effect of acquisition threshold l
The threshold l is a key design hyperparameter for defining the acquisition function for JUMBO. In Figure 5b, we illustrate the effect of different choices for l on the performance of the algorithm for the circuit design setup. JUMBO with l =  reduces to GP-UCB (i.e. cold-GP only) and with l = 0, it reduces to offline DKL (i.e. warm-GP only). As we can see, the lowest regret is achieved
8

for l = 0.05. We also note that there is a wide range of l that JUMBO performs well relative to other baselines, suggesting a good degree of robustness and less tuning in practice.
4.4 Ablation: BLR with JUMBO's acquisition function
A key difference between JUMBO and ABLR [9] is replacing the BLR layer with a GP. To test whether there is any merit in having a GP, we ran an experiment on Protein dataset and replaced the GP with a BLR in JUMBO's procedure. Figure 5c shows that JUMBO with GPwarmsignificantly outperforms JUMBO with a BLR layer.
5 Related Work
Transfer Learning in Bayesian Optimization: Utilizing prior information for applying transfer learning to improve Bayesian optimization has been explored in several prior papers. Early work of [4] focuses on the design of multi-task kernels for modeling task correlations [6]. These models tend to suffer from lack of scalability; [23, 24] show that this challenge can be partially mitigated by training an ensemble of task-specific GPs that scale linearly with the number of tasks but still suffer from cubic complexity in the number of observations for each task. To address scalability and robust treatment of uncertainty, several prior works have been suggested [7, 9, 20]. [20] employs a Gaussian Copula to learn a joint prior on hyper-parameters based on offline tasks, and then utilizes a GP on the online task for adapt to the target function. [7] uses a BNN as surrogates for MBO; however, since training BNNs is computationally intensive [9] proposes to use a deterministic NN followed by a BLR layer at the output to achieve scalability.
Some other prior work exploit certain assumptions between the source and target data. For example [25, 26] assume an ordering of the tasks and use this information to train GPs to model residuals between the target and auxiliary tasks. [27, 28] assume existence of a similarity measure between prior and target data which may not be easy to define for problems other than hyper-parameter optimization. A simpler idea is to use prior data to confine the search space to promising regions [22]. However, this highly relies on whether the confined region includes the optimal solution to the target task. Another line of work studies utilizing prior optimization runs to meta-learn acquisition functions [29]. This idea can be utilized in addition to our method and is not a competing direction.
Multi-fidelity Black-box Optimization (MFBO): In multi-fidelity scenarios we can query for noisy approximations to the target function relatively cheaply. For example, in hyperparameter optimization, we can query for cheap proxies to the performance of a configuration on a smaller subset of the training data [30], early stopping [31], or by predicting learning curves [32, 33]. We direct the reader to Section 1.4 in [34] for a comprehensive survey on MBFO. Such methods, similar to MF-GPUCB [21] (section 4.2), are typically constrained to scenarios where such low fidelities are explicitly available and make strong continuity assumptions between the low fidelities and the target function.
Deep Kernel Learning (DKL): Commonly used GP kernels (e.g. RBF, Matern) can only capture simple correlations between points a priori. DKL [35, 36] addresses this issue by learning a latent representation via NN that can be fed to a standard kernel at the output. [11] employs linear kernels at the output of a pre-trained NN while [35] extends it to use non-linear kernels. The warm-GP in JUMBO can be understood as a DKL surrogate model trained using offline data from auxiliary tasks.
6 Conclusion
We proposed JUMBO, a no-regret algorithm that employs a careful hybrid of neural networks and Gaussian Processes and a novel acquisition procedure for scalable and sample-efficient Multi-task Bayesian Optimization. We derived JUMBO's theoretical regret bound and empirically showed it outperforms other competing approaches on set of real-world black-box optimization problems.
References
[1] Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. In Proceedings of the 27th International Conference on Machine Learning. Omnipress, 2010.
9

[2] Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Freitas. Taking the human out of the loop: A review of bayesian optimization. Proceedings of the IEEE, 104(1):148­175, 2015.
[3] Peter I Frazier. A tutorial on bayesian optimization. arXiv preprint arXiv:1807.02811, 2018.
[4] Kevin Swersky, Jasper Snoek, and Ryan P Adams. Multi-task bayesian optimization. Advances in Neural Information Processing Systems, 26:2004­2012, 2013.
[5] Chris Williams, Edwin V Bonilla, and Kian M Chai. Multi-task gaussian process prediction. Advances in neural information processing systems, pages 153­160, 2007.
[6] Matthias Poloczek, Jialei Wang, and Peter I Frazier. Warm starting bayesian optimization. In 2016 Winter Simulation Conference (WSC), pages 770­781. IEEE, 2016.
[7] Jost Tobias Springenberg, Aaron Klein, Stefan Falkner, and Frank Hutter. Bayesian optimization with robust bayesian neural networks. In Proceedings of the 30th International Conference on Neural Information Processing Systems, pages 4141­4149, 2016.
[8] Radford M Neal. Bayesian learning for neural networks, volume 118. Springer Science & Business Media, 2012.
[9] Valerio Perrone, Rodolphe Jenatton, Matthias Seeger, and Cédric Archambeau. Scalable hyperparameter transfer learning. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pages 6846­6856, 2018.
[10] Carl Edward Rasmussen. Gaussian processes in machine learning. In Summer school on machine learning, pages 63­71. Springer, 2003.
[11] Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram, Mostofa Patwary, Mr Prabhat, and Ryan Adams. Scalable bayesian optimization using deep neural networks. In International conference on machine learning, pages 2171­2180. PMLR, 2015.
[12] Christopher M Bishop. Pattern recognition and machine learning. springer, 2006.
[13] Maximilian Balandat, Brian Karrer, Daniel Jiang, Samuel Daulton, Ben Letham, Andrew G Wilson, and Eytan Bakshy. Botorch: A framework for efficient monte-carlo bayesian optimization. Advances in Neural Information Processing Systems, 33, 2020.
[14] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. arXiv preprint arXiv:1912.01703, 2019.
[15] Aaron Klein and Frank Hutter. Tabular benchmarks for joint architecture and hyperparameter optimization. arXiv preprint arXiv:1905.04970, 2019.
[16] PS Rana. Physicochemical properties of protein tertiary structure data set. UCI Machine Learning Repository, 2013.
[17] Athanasios Tsanas, Max A Little, Patrick E McSharry, and Lorraine O Ramig. Enhanced classical dysphonia measures and sparse regression for telemonitoring of parkinson's disease progression. In 2010 IEEE International Conference on Acoustics, Speech and Signal Processing, pages 594­597. IEEE, 2010.
[18] Andrea Coraddu, Luca Oneto, Aessandro Ghio, Stefano Savio, Davide Anguita, and Massimo Figari. Machine learning approaches for improving condition-based maintenance of naval propulsion plants. Proceedings of the Institution of Mechanical Engineers, Part M: Journal of Engineering for the Maritime Environment, 230(1):136­153, 2016.
[19] Franz Graf, Hans-Peter Kriegel, Matthias Schubert, Sebastian Pölsterl, and Alexander Cavallaro. 2d image registration in ct images using radial image descriptors. In International Conference on Medical Image Computing and Computer-Assisted Intervention, pages 607­614. Springer, 2011.
10

[20] David Salinas, Huibin Shen, and Valerio Perrone. A quantile-based approach for hyperparameter transfer learning. In International Conference on Machine Learning, pages 8438­8448. PMLR, 2020.
[21] Kirthevasan Kandasamy, Gautam Dasarathy, Junier Oliva, Jeff Schneider, and Barnabas Poczos. Multi-fidelity gaussian process bandit optimisation. Journal of Artificial Intelligence Research, 66:151­196, 2019.
[22] Valerio Perrone, Huibin Shen, Matthias Seeger, Cedric Archambeau, and Rodolphe Jenatton. Learning search spaces for bayesian optimization: Another view of hyperparameter transfer learning. arXiv preprint arXiv:1909.12552, 2019.
[23] Martin Wistuba, Nicolas Schilling, and Lars Schmidt-Thieme. Scalable gaussian process-based transfer surrogates for hyperparameter optimization. Machine Learning, 107(1):43­78, 2018.
[24] Matthias Feurer, Benjamin Letham, and Eytan Bakshy. Scalable meta-learning for bayesian optimization. arXiv preprint arXiv:1802.02219, 2018.
[25] Alistair Shilton, Sunil Gupta, Santu Rana, and Svetha Venkatesh. Regret bounds for transfer learning in bayesian optimisation. In Artificial Intelligence and Statistics, pages 307­315. PMLR, 2017.
[26] Daniel Golovin, Benjamin Solnik, Subhodeep Moitra, Greg Kochanski, John Karro, and D Sculley. Google vizier: A service for black-box optimization. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining, pages 1487­1495, 2017.
[27] Matthias Feurer, Jost Springenberg, and Frank Hutter. Initializing bayesian hyperparameter optimization via meta-learning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 29, 2015.
[28] Martin Wistuba, Nicolas Schilling, and Lars Schmidt-Thieme. Learning hyperparameter optimization initializations. In 2015 IEEE international conference on data science and advanced analytics (DSAA), pages 1­10. IEEE, 2015.
[29] Michael Volpp, Lukas P Fröhlich, Kirsten Fischer, Andreas Doerr, Stefan Falkner, Frank Hutter, and Christian Daniel. Meta-learning acquisition functions for transfer learning in bayesian optimization. arXiv preprint arXiv:1904.02642, 2019.
[30] Johann Petrak. Fast subsampling performance estimates for classification algorithm selection. In Proceedings of the ECML-00 Workshop on Meta-Learning: Building Automatic Advice Strategies for Model Selection and Method Combination, pages 3­14, 2000.
[31] Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and Ameet Talwalkar. Hyperband: A novel bandit-based approach to hyperparameter optimization. The Journal of Machine Learning Research, 18(1):6765­6816, 2017.
[32] Tobias Domhan, Jost Tobias Springenberg, and Frank Hutter. Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves. In Twenty-fourth international joint conference on artificial intelligence, 2015.
[33] Aaron Klein, Stefan Falkner, Simon Bartels, Philipp Hennig, and Frank Hutter. Fast bayesian optimization of machine learning hyperparameters on large datasets. In Artificial Intelligence and Statistics, pages 528­536. PMLR, 2017.
[34] Frank Hutter, Lars Kotthoff, and Joaquin Vanschoren. Automated machine learning: methods, systems, challenges. Springer Nature, 2019.
[35] Wenbing Huang, Deli Zhao, Fuchun Sun, Huaping Liu, and Edward Chang. Scalable gaussian process regression using deep neural networks. In Twenty-fourth international joint conference on artificial intelligence. Citeseer, 2015.
[36] Roberto Calandra, Jan Peters, Carl Edward Rasmussen, and Marc Peter Deisenroth. Manifold gaussian processes for regression. In 2016 International Joint Conference on Neural Networks (IJCNN), pages 3338­3345. IEEE, 2016.
11

[37] Nikolaus Hansen. The cma evolution strategy: A tutorial. arXiv preprint arXiv:1604.00772, 2016.
[38] Eduardo C Garrido-Merchán and Daniel Hernández-Lobato. Dealing with categorical and integer-valued variables in bayesian optimization with gaussian processes. Neurocomputing, 380:20­35, 2020.
12

A Proofs of Theoretical Results
We will present proofs for Theorem 1 and an additional result in Theorem 5 that extends the no-regret guarantees of JUMBO to continuous domains. Our theoretical derivations will build on prior results from [1] and [21].

A.1 Theorem 1

Let µct (x) and tc(x) denote the posterior mean and standard deviation of GPcold at the end of round t after observing Dtc-old1 = {(xi, yi)ti=-11}. Similarly, we will use µwt (x) and tw(x) to denote the posterior mean and standard deviation of GPwarm at the end of round t after observing Dtw-ar1m = {(h(xi), yi)ti=-11}.

Lemma 2. Pick   (0, 1) and set t = 2 log

||t 

where t1t-1 = 0.5, t > 0 (e.g. t =

 2 t2 3

).

Define

µt(x)

=

t(x)µct (x)+(1-t(x))µwt (x)

and

t(x)

=

t (x)tc (x) + (1 - t (x))tw (x).

Then,

P {|f (x) - µt(x)|  t1/2t(x), x  , t  1}  1 - .

Proof. Fix t  1 and x  . Based on Assumption 1, conditioned on Dtc-old1, f (x)  N (µct (x), tc(x)). Similarly, Assumption 2 implies that conditioned on Dtw-ar1m, f (x) 

N (µwt (x), tw(x)). Let A be the event that |f (x) - µct (x)|  t1/2tc(x) and B the event that

|f (x) - µwt (x)|  t1/2tw(x). From proof of Lemma 5.1 in [1] we know that given a normal distri-

bution z



N (0, 1),

P {z

>

c}



0.5e-

c2 2

.

Using

z

=

f (x)-µct (x) tc (x)

and

c

=

t1/2, P {A¯}



e-t/2.

Similarly, P {B¯}  e-t/2. Using union bound, we have:

P {A¯  B¯}  P {A¯} + P {B¯}  2e-t/2. By union bound, we have:
P {A¯  B¯}  || 2e-t/2   x  , t  1.
t1
The event in this Lemma is just A  B and the proof is concluded.

Next, we state two lemmas from prior work. Lemma 3. If |f (x) - µt(x)|  t1/2t(x), then rt is bounded by 2t1/2t(xt).

Proof. See Lemma 5.2 in [1]. It employs the results of Lemma 2 to prove the statement.

Lemma 4. Let t2(x) denote the posterior variance of a GP after t - 1 observations, and let

A  . Assume that we have queried f at n points (xt)nt=1 of which s points are in A. Then

t:xtA t2(x)



2 log(1+-2

)

s

(A).

Proof. See Lemma 8 in [21].

Proof for Theorem 1

Proof. From Lemma 3, we have:

rt2  4tt2(xt)

(5)

13

Summing over instantaneous regrets for T rounds, we get:

T

T

rt2  4tt2(xt)

(6)

t=1

t=1

T
 4T t2(xt)
t=1


(7) 

 4T 

tc2 (xt) +

tw2 (xt)

(8)

t:xt g

t:xt ¯g



8T 1 + n-2

T -s(g) + s(Z¯g)

(9)

Eq 7 follows from the monotonicity of t = 2 log(t/). Eq. 8 follows from the definition of t in Lemma 2 and the last inequality in Eq. 9 follows from Lemma 4.

Finally, from Cauchy-Schwartz inequality, we know that RT2  T

T t=1

rt2.

Combining

with

Eq.

9,

we obtain the result in Theorem 1.

A.2 Extension to Continuous Domains
We will now derive regret bounds for the general case where   [0, r]d is a d-dimensional compact and convex set with r > 0. This will critically require an additional Lipschitz continuity assumption on f . Theorem 5. Suppose that kernels c and w are such that the derivatives of GPcoldand GPwarmsample paths are bounded with high probably. Precisely, for some constants a, b > 0,

P

f sup

>L

 ae-(L/b)2 , j = 1, 2, . . . , d.

(10)

x xj

Pick   (0, 1), and set t = 2 log(42t2/3) + 4d log(dtbr log(4da/)). Then, running JUMBO
for T iterations results in a sequence of candidates (xt)tt==T1 for which the following holds with probability at least 1 - :

RT <

CT T {T -s(g)

+

s (Z¯g )}

+

2 , T
6



1

where C = 1/(1+n2 ).

To start the proof, we first show that we have confidence on all the points visited by the algorithm. Lemma 6. Pick   (0, 1) and set t = 2 log(t/), where t1 t-1 = 0.5, t > 0. Define µt(x) = t(x)µct (x) + (1 - t(x))µwt (x) and t(x) = t(x)tc(x) + (1 - t(x))tw(x). Then,
|f (xt) - µt(xt)|  t1/2t(xt), t  1

holds with probability of at least 1 - .

Proof. Fix t  1 and x  . Similar to Lemma 3, P {A¯  B¯}  2e-t/2. Since e-t/2 = /t, using the union bound for t  1 concludes the statement.

For the purpose of analysis, we define a discretization set t  , so that the results derived earlier

can be re-applied to bound the regret in continuous case. To enable this approach we will use

conditions on L-Lipschitz continuity to obtain a valid confidence interval on the optimal solution

x. Similar to [1], let us dimension in ) such that

choose for all x

discrtehteizcaltoiosenstptooinf tstiozexitnd

(i.e. t t, [x]t,

uniformly spaced has a distance less

points per than some

threshold. Formally, ||x - [x]t||1  rd/t.

14

Lemma 7. Pick   (0, 1) and set t = 2 log(4t/) + 4d log(dtbr log(4da/)), where t1 t-1 = 0.5, t > 0. Then, for all t  1, the regret is bounded as follows:

rt



2t1/2t(xt)

+

1 t2

(11)

with probabilty of at least 1 - .

Proof. In light of Lemma 6,the proof follows directly from Lemma 5.8 in [1].

Proof of Theorem 5

Proof. From Eq. 9 in the proof of Theorem 1, we have shown that:

T
4tt2(xt)  CT (T -s(g) + s(Z¯g))
t=1

T  1.

Therefore, using Cauchy-Schwarz:

T
2t1/2t(xt) 
t=1

CT (T -s(g) + s(Z¯g))

T  1.

Since

T t=1

1 t2



2 6

,

Theorem

5

follows

Lemma

7.

B Implementation Details

B.1 Pre-training Details
Figure 6 illustrates the skeleton of the architecture that was used for all experiments. The input configuration is fed to a multi-layer perceptron of nl layers with nu hidden units. Then, optionally, a dropout layer is applied to the output and the result is fed to another non-linear layer with nz outputs. The latent features are then mapped to the output with a linear layer. All activations are tanh.

Figure 6: NN Architecture during pre-training: The first blocks is nl layers of nu hidden units with tanh activations. Following that is a dropout layer and then a single layer perceptron to get nz features. Thereafter, the latent features are mapped linearly to the output.
For HPO experiments, we have used nu = 32, nz = 4, nl = 3, learning rate = 5 × 10-5, andbatch size = 128. For circuit experiments we used nu = 200, nz = 32, nl = 3, learning rate = 3 × 10-4, batch size = 64, and dropout rate of 0.5. These hyper-parameters were chosen based on random search by observing the prediction accuracy of the pre-training model on the auxiliary validation dataset which was 20% of the overall dataset.
15

B.2 Details of training the Gaussian Process hyper-parameters

For

both

warm

and

cold

GP,

we

consider

a

Matern

kernel

(i.e.

(x, x

)

=

21- ()





( 2r2)K ( 2r2)

with



=

2.5 where r2

=

||x-x 

||2

).

The length scale 

and

observation noise n

are optimized

in every iteration of BO by taking 100 gradient steps on the likelihood of observations via Adam

optimizer with a learning rate of 0.1.

B.3 Acquisition Function Details

For all experiments, we used Upper Confidence Bound with the exploration-exploitation hyper-

parameter at

round t

set

as

10

exp

-t T

where T

is

the

budget of

total

number of

iterations.

This

way we favor exploration more initially and gradually drift to more exploitation as we approach the

end of the budget. For optimization of acquisition function, we use the derivative free algorithm

CMA-ES [37].

B.4 Dealing with Categorical Variables in HPO
We handle categorical and integer-valued variables in BO similar to [38]. In particular, we used c(T (x), T (x )) as the kernel where T :   T is a deterministic transformation that maps the continuous optimization variable x to a representation space T that adheres to a meaningful distance measurement. For example, for categorical parameters, it converts a continuous input to a one-hot encoding corresponding to a choice for that parameter, and for integer-valued variables, it converts the continuous variable to the closest integer value. Similarly, for the pre-training phase, we also train using h(T (x)).

C Experimental Evidence
All the experiments were done on a quad-core desktop.

C.1 Space compression through the pretrained NN
In this experiment we studied the latent space of a NN fed with uniformly sampled inputs for circuit design and see that 75% of data variance is preserved in only 4 dimensions (with nz = 32), suggesting that the warm-GP is operating in a compressed space.

Figure 7: Explained Variance of latent dimensions
C.2 Tabular Experimental Results In this section we present the quantitative comparison between JUMBO and the best outstanding prior work for each experimental case. In this table we have also included BOHB as another relevant multi-fidelity baseline.
16

Table 1: Comparison of simple regret for HPO. Lower is better. On average JUMBO's simple regret at convergence is 45% better than the state-of-the-art MBO baseline in each experiment.

Protein (×10-3) Parkinsons (×10-3) Naval (×10-5) Slice (×10-4)

GP-UCB MT-BOHAMIANN
MT-ABLR OfflineDKL
BOHB GCP
JUMBO (ours)

1.98 6.71 13.52 1.40 6.38 7.50
0

4.93

1.4

0.77

2.13

2

0.84

4.91

2.3

1.42

2.67

4.9

10.67

3.16

2.1

0.23

3.15

3.3

0.46

0.23

0.7

0.73

BOHB combines the successive halving approach introduced in HyperBand [31] with a probabilistic model that captures the density of good configurations in the input space. Unlike other methods BOHB employs a fixed budget and utilizes the information beyond epoch 3. It runs multiple hyperparameter configurations in parallel and terminates a subset of them after every few epochs based on their current validation error until the budget is exhausted.

17

