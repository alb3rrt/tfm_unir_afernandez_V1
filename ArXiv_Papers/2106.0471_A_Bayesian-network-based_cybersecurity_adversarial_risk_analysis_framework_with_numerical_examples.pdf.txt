A Bayesian-network-based cybersecurity adversarial risk analysis framework with numerical examples
Jiali Wang jiali.wang@qmul.ac.uk, Martin Neil m.neil@qmul.ac.uk
School of Electronic Engineering & Computer Science, Queen Mary University of London.
Corresponding author: Jiali Wang Postal Address: School of Electronic Engineering & Computer Science, Queen Mary University of London, Mile End Road, London E1 4NS.
Abstract
Cybersecurity risk analysis plays an essential role in supporting organizations make effective decision about how to manage and control cybersecurity risk. Cybersecurity risk is a function of the interplay between the defender (the organisation) and the attacker: decisions and actions made by the defender `second guess' the decisions and actions taken by the attacker and vice versa. Insight into this `game' between these two agents provides a means for the defender to identify and make optimal decisions. To date, the adversarial risk analysis framework has provided a decision-analytical approach to solve such game problems in the presence of uncertainty and uses Monte Carlo simulation to calculate and identify optimal decisions. We propose an alternative framework to construct and solve a serial of sequential Defend-Attack models, that incorporates the adversarial risk analysis approach, but uses a new class of influence diagrams algorithm, called hybrid Bayesian network inference, to identify optimal decision strategies. Compared to Monte Carlo simulation the proposed hybrid Bayesian network inference is more versatile because it provides an automated way to compute hybrid Defend-Attack models and extends their use to involve mixtures of continuous and discrete variables, of any kind. More importantly, the hybrid Bayesian network approach is novel in that it supports dynamic decision making whereby new real-time observations can update the Defend-Attack model in practice. We also extend the Defend-Attack model to support cases involving extra variables and longer decision sequence. Examples are presented, illustrating how the proposed framework can be adjusted for more complicated scenarios, including dynamic decision making.
Key words:
Decision Analysis, Adversarial Risk Analysis, Influence Diagrams, Hybrid Bayesian Network, Probabilistic Inference

Contents
1. Introduction .................................................................................................................................. 1 2. Influence Diagrams, Hybrid Bayesian Networks and Decision Trees ............................................ 3 3. The sequential Defend-Attack model ............................................................................................ 5
3.1 Adversarial risk analysis of the Defend-Attack model ................................................................. 5 3.2 Depicting the Defend-Attack game problem using hybrid Bayesian networks ........................... 7 3.3 Risk assessment and decision support for the defender............................................................. 7 4. The sequential Defend-Attack-Defend model ............................................................................. 10 4.1 Adversarial risk analysis of the Defend-Attack-Defend model .................................................. 10 4.2 Depicting a D-A-D game problem using an HBN ....................................................................... 12 4.3 Risk assessment and decision support for the defender........................................................... 13 5. Extensions of the sequential Defend-Attack game model........................................................... 17 5.1 Rules to build and calculate the sequential Defend-Attack game models ................................ 17 5.2 Example 1: The Defend-Attack game with extra variables........................................................ 18 5.3 Example 2: The Defend-Attack game with a longer decision sequence.................................... 23 6. Supporting the defender's dynamic decision making.................................................................. 27 6.1 The algorithm for dynamic decision analysis ............................................................................ 28 6.2 Example 3: the actual attacks are observable ........................................................................... 30 6.3 Example 4: only the consequences of attacks are observable .................................................. 32 7. Conclusion ................................................................................................................................... 36 Acknowledgements.............................................................................................................................. 36 Appendix A: Notations summary ......................................................................................................... 37 Reference ............................................................................................................................................. 38

1. Introduction
Cybersecurity risk analysis plays an essential role in supporting organizations make effective decisions about how to manage and control cybersecurity risk. Cybersecurity risk is a function of the interplay between the defender (the organisation) and the attacker: decisions and actions made by the defender `second guess' the decisions and actions taken by the attacker and vice versa. Insight into this `game' between these two agents provides a means for the defender to identify and make optimal decisions.
Game-theoretical approaches have been the typical choice to model interplay between two or more strategic adversaries and have been widely applied to cybersecurity issues (Do et al., 2017; Manshaei et al., 2013; Roy et al., 2010; Wang et al., 2016). However, conventional game theory faces a challenge when it aims to find solutions for all the participants of the game, in that the solution must be a Nash equilibrium. As the problem and associated game models get more realistic and complex, this requirement makes it increasingly difficult to compute a solution (Joshi et al., 2020) (Gindis, 2009). Moreover, most versions of non-cooperative game theory assume adversaries know their own payoffs, preferences, beliefs and possible actions but also assume that knowledge about these is shared between adversaries (Harsanyi, 1967). This shared knowledge assumption is unrealistic in contexts such as counter-terrorism or cybersecurity, where players will not generally have sufficient knowledge about their opponents or where opponents are motivated to keep secrets (González-Ortega et al., 2019).
Adversarial Risk Analysis (ARA) (Rios Insua et al., 2009) was proposed to address the above mentioned shortcomings of classic game theory. ARA solves the problem by modelling the ability of a player (typically, the defender) to anticipate the opponent's decisions and actions. General security risk analysis problems, as explored in (Brown et al., 2006) (Zhuang & Bier, 2007) (Hausken & Bier, 2011), are modelled as a number of basic templates (i.e. simultaneous Defend-Attack (D-A) model, sequential D-A model, etc) with a known ARA solution in (Banks et al., 2015). The templates differ in the way and order in which the attack and defence actions take place within the global sequence of decisions and events, as well as in the information revealed. These templates can then be represented by Influence Diagrams (ID) (Fenton & Neil, 2019).
How to best model and efficiently calculate optimal decisions using ARA has received a lot of attention in recent years. Opponents in simultaneous decision making games are modelled following ARA in (Rios Insua et al., 2016). Insider threat in sequential D-A games were modelled using the ARA approach in (Joshi et al., 2020). A calculation procedure for conducting ARA for a bi-agent game is introduced in (González-Ortega et al., 2019). In the work (González-Ortega et al., 2019), a model consists of sequential D-A pattern and simultaneous D-A pattern is considered. For more practical cases, (Insua et al., 2019) provides an ARA framework for cybersecurity risk analyse using insurance as part of the
1

security portfolio for decision making and the work done by (Gil & Parra-Arnau, 2019) applied ARA in Counterterrorist Online Surveillance.
It is argued in (Joshi et al., 2020), that in most realistic cybersecurity cases, the defender would deploy their defence first to deter and prevent attacks and, therefore, it makes sense to model the cybersecurity problem as a sequential D-A game, rather than as a simultaneous one. However, solving the sequential D-A model, and its more challenging extensions i.e., the sequential D-A model with extra variables or with a longer decision sequence, has not been systemically investigated in previous research. In this paper, we focus on solving the bi-agent sequential D-A game model and its extensions. We provide a Hybrid Bayesian Network (HBN) based ARA approach as a comprehensive solution and use examples to illustrate how the proposed framework can be applied to practical problems. Our proposed solution can be easily applied to solve other typical sequential game templates summarized in (Banks et al., 2015). For example, the D-A-D model can be regarded as an instance of the sequential D-A model with longer decision sequences. Moreover, solving sequential A-D models (Banks et al., 2015) and the extensions (i.e., sequential A-D-A models) can be regarded as a reflective solution to the "dual problem" of solving the D-A problem, since only the order of making decision changes while the underlying calculating mechanism remains the same compared with solving the D-A model.
Most ARA solutions use Monte Carlo (MC) simulation to carry out the calculation, for example in (Insua et al., 2019) (Rios Insua et al., 2016) (Joshi et al., 2020) (González-Ortega et al., 2019). MC simulation is straightforward to implement. However, this approach can become computationally challenging when dealing with decision dependent uncertainties, especially in D-A models where we encounter longer decision sequences. Moreover, it cannot cope with new evidence that could be used to update the game model, dynamically, in real time, which we contend is a realistic requirement for practical use. In our work, we provide algorithms to implement the ARA approach based on the HBN inference (Yet et al., 2018). The proposed method offers a fully automated way to compute sequential D-A models and can support dynamic decision analysis which has not been solved by previous ARA solutions that adopt MC simulation.
The contributions of our work are threefold: 1) we propose an alternative framework, based on HBN inference and decision trees, to solve the typical sequential Defend-Attack (D-A) games from the ARA perspective; 2) we illustrate how to use this framework to solve more practical D-A problems involving extra variables and longer decision sequence (also known as multi-period game/ k-level thinking); 3) we present numerical examples to show how our framework can support decision making in different application contexts involving extra variables, longer decision sequences and dynamic decision making (in section 4 and 5). The advantages of the proposed framework compared with other previous works are: 1) it offers a fully automated way to compute hybrid D-A models which involve mixtures of continuous and discrete variables; 2) it can provide more flexible decision making about risk in addition to expected utility optimization; 3) it supports dynamic decision making in multi-period D-A games.
2

The rest of the paper is structured as follows. In section 2, we introduce technologies adopted in our work, including hybrid Bayesian networks, influence diagrams and decision trees. In Section 3 we show how we can implement the ARA approach incorporating HBNs using a typical game model: the sequential D-A model. In section 4, we summarize the rules needed to be followed to extend D-A models for more complicated scenarios, i.e., D-A problems with extra variables and with longer decision sequences and apply these rules to two examples. In section 5, we discuss dynamic decision analysis, provide the algorithm and illustrative examples. Conclusions are presented in section 6.

2. Influence Diagrams, Hybrid Bayesian Networks and Decision Trees

In ARA, a decision problem can be structured and represented by an Influence Diagram (ID), which is a generalization of a Bayesian network. In this section, we provide a general introduction of ID, Hybrid Bayesian Networks (HBNs) and how to conduct decision analysis through HBN using Decision Trees (DTs).
BNs are widely used for probabilistic reasoning and have very wide applicability, including enabling statistical reasoning, causal reasoning and diagnostic inference (Fenton & Neil, 2011). A BN is a directed acyclic graph representing a factorization of a joint probability distribution, consisting of nodes representing variables and arcs representing causal or probabilistic relationships (the qualitative part) with probabilistic weights (the quantitative part) sometimes modelled using statistical and deterministic functions. In a BN, each node ! has an associated probability table, $(!| (!)*, called the Conditional Probability Table (CPT) of ! given its parent variables, (!). For a node ! without parents, the CPT is the marginal probability distribution of !, (!). The conditional-independent relationship among variables, represented by the absence of arcs, allows simplification of a BN's joint probability distribution which can be represented by the product of CPTs. Furthermore, the marginal distribution of the child variable can be obtained by marginalizing over its parent variables in the joint distribution (Fenton & Neil, 2019). For example, considering a simple BN consisting of three nodes, in which nodes A and B are parents of node C, and CPTs are (), () and (|, ), we can get the joint distribution of this BN from (, , ) = () ()(|, ) and calculate the marginal distribution of the child node C following () = ",$ (, , ).
Generally, the joint distribution of a BN can be calculated following formula (1):

(%, ... . , &) = &!'% $(!| (!)*

(1)

This factorisation significantly reduces the complexity of inference tasks in BNs.

Computational algorithms for solving BNs, where all variables are discrete, include Junction Tree (JT) (Lin et al., 2014). Solutions for continuous cases include Hybrid BNs Junction Tree algorithm which

3

can be combined with Dynamic Discretization (DD) (Fenton & Neil, 2019), to calculate BN containing mixtures of continuous and discrete variables of any distributional form. HBNs have been implemented and packaged into the BN modelling software application AgenaRisk (Agena Ltd. 2002-2021). In this paper we have used AgenaRisk, a commercial BN package, to build BNs and perform calculations for ARA. AgenaRisk contains off-the-shelf functions for performing inference on HBNs and influence diagrams. An Influence Diagram (ID) is a special type of BN models that represents the interaction between decisions, chance variables, and utilities along with an algorithm to compute the expected utilities and identify those decisions that optimise the utility (Fenton & Neil, 2019) (Yet et al., 2018). In an ID, nodes represent each variable, with the convention that rectangles represent decisions, ovals represent chance variables, and diamonds represent utilities. Each decision node represents a decision, chance nodes represent random variables, which can be observable or non-observable, and utility nodes represent the pay-off for the decision maker. There is always an "ultimate" utility node (with at least one parent) that we seek to optimize. An ID with chance, decision, and utility nodes that can involve mixtures of discrete and continuous variables are called Hybrid IDs (HIDs) which is a kind of Hybrid BNs (HBNs). An ID of the sequential D-A model is shown in Figure 1. This ID represents a sequential D-A game where the defender would make her defence deployment decision (represented by node ) first. This can then be observed by the attacker (i.e., he) and he would use this information to optimise his attack decision, i.e., whether to attack or use how much resource for attacking (represented by node ). Whether the attack is successful is represented by the chance node, , which is conditional on  and . Finally,  and  determine  utility while  and  determine  utility. The decision that maximizes  utility would be the optimal strategy for the defender. The rule for the attacker is similar.
Figure 1 Influence diagram for the sequential Defend-Attack game
Generally, in an ID, incoming arcs to chance or utility nodes represent causal, deterministic, or associational relations between the node and its parents. Incoming arcs to decision nodes (shown by a dashed line) are "informational" arcs, representing the possibility that the temporal ordering, when the state of any parent node might be known before a decision is made. Informational (dashed line) arcs
4

also specify the sequential order of decisions and observations. An ID cannot be computed without a strict sequential order. After constructing an ID for a decision analysis problem, we can construct a Decision Tree (DT) (Fenton & Neil, 2019) to represent all the potential decisions and their corresponding utility values. The decision which corresponds to the maximum (in general) utility would be determined to be the optima in the decision tree. We construct DTs for an ID using a hybrid ID (Yet et al., 2018) in AgenaRisk. Adversarial Risk Analysis (ARA) provides a decision analytic approach offering prescriptive supporting one of the intervening agents (i.e., the defender) based on an expected utility model treating the adversary's decisions as uncertainties. As we have mentioned, since it is rational to model the cybersecurity problem as a sequential D-A game, rather than as a simultaneous one (Joshi et al., 2020), we focus on solving the sequential D-A model and its extensions in this paper. Fundamentally, ARA solves the D-A game by analysing the attacker's problem, anticipating his best choice and taking into account the defender's own options for the most optimal defence strategy. In section 3, we formally illustrate how to use the HBN to solve the typical D-A game from the ARA perspective.
3. The sequential Defend-Attack model
3.1 Adversarial risk analysis of the Defend-Attack model
The adversarial risk analysis of the sequential Defend-Attack (D-A) game model provides a template and procedure to identify the optimal strategy for the defender. In this section, we analyse the D-A game represented by Figure 1 from the ARA perspective and illustrate how to construct an HBN for the calculation and supporting decision making for the defender. We assume that in the ID represented by Figure 1, the defender has a discrete set of possible defence levels, which are represented by the decision node  (Defences). After observing the potential defence levels that can be implemented, the attacker creates a discrete set of possible attack levels  = {%, (, ... , )} represented by node  (Attacks). A dashed arc pointing from node  to  represents the fact that the attacker's decision depends on the potential defence. From the ARA perspective, the D-A game can be divided into the attacker's problem and the defender's problem. To determine the defender's best choice, the defender would analyse the attacker's problem first, which is represented by Figure 2, to anticipate choices the attacker might optimally make. Then, based on this analysis, the defender would determine the optimal strategy for herself in the first place. This calculation procedure is an implementation of backwards induction (Aliprantis & Chakrabarti, 2012) (Banks et al., 2015). Backwards induction analyses decisions from the end to the beginning of the decision sequence to calculate optimal strategies for decision nodes. Assuming rationality, the attacker should choose the
5

strategy that can maximize his utility, given all the potential defence choices, and that the defender will take this into account.
Figure 2 The attacker's problem in the D-A game

 expected utility corresponding to each possible combination of (, )   ×  is:

"(, ) = "( = 0|, )"(, ,  = 0) + "( = 1|, )"(, ,  = 1)

(2)

Therefore, the defender can predict that the optimal attack that would be adopted is:

() = +""(, ),   

(3)

Consequently, the defender can calculate her optimal initial strategy to adopt in the game by analysing the defender's problem which is shown in Figure 3.
Figure 3 The defender's problem in the D-A game

The expected utility of  corresponding to each possible combination of (, )   ×  is:

-(, ) = -( = 0|, )-(, ,  = 0) + -( = 1|, )-(, ,  = 1)

(4)

Under the assumption that the opponent in this game is rational, her best choice is:

 = .--$, ()*

(5)

This calculation follows backwards induction as is represented that, the decision sequence in reality is from  to , while the analysing/calculating sequence is backwards, from  to .
Note that, in contrast with classic game theory, the solution  for the sequential game need not correspond to a Nash equilibrium, since in ARA, players are not assumed to have full and common

6

knowledge and the solution  is derived from the predicted (", ") rather than the actual one (Banks et al., 2015).
3.2 Depicting the Defend-Attack game problem using hybrid Bayesian networks
Here we use an example to show how to implement the sequential D-A game using a Hybrid Bayesian Network (HBN), that models a concrete sequential Defend-Attack game, as shown in Figure 4 (a). We simplify the opponents' decisions as Boolean variables representing to defend or not, for the defender, and to attack or not, for the attacker. We assume that the defender's decision is about whether to defend an information asset. Meanwhile, after observing whether the defender defends, the attacker would consider whether to attack. We show the setting of nodes' CPTs in Figure 4 (b). We assign uniform distributions to the decision nodes: node  (defence decision) and node  (attack decision) representing the opponents' open-mindedness choices. The CPT of the Success node (node ) models how the attack and defence interact to determine the probability of a successful attack. The node  can be true or false. If an attack is not made, the probability of  to be true is zero. We assume that if an attack is made, the probability of success is 0.8 if the asset is undefended, while it decreases to 0.2 if defended. The utility node,  Utility, models the defender's payoff given the asset is defended (utility: -100) and the cost to the defender of a successful attack is (utility: -200). The defender can predict the attacker's utility based on the assumption that the attacker's attack cost (utility: -100) and the payoff from a successful attack (utility: +200).
Figure 4 The BN model of a sequential D-A game
3.3 Risk assessment and decision support for the defender
In subsection 3.1, backwards induction is introduced to determine the optimal strategy for the defender in the D-A model in general. In this subsection, we illustrate how to implement the backwards induction
7

for calculating the optimal decision for the defender in the HBN shown in Figure 4. To achieve this, there are three steps involved. Firstly, the defender would initially analyse the attacker's problem, as shown in Figure 2, to predict what attacks he might make against possible defences. At this point, we regard the defender decision choices as a variable that might be potentially observed by the attacker and used to inform his decision making. Since the decision node for the defender becomes a chance node in this subproblem, we use an oval node to represent it. Here, the attacker's judgment is that there is a fifty-fifty chance of the defender defending or not. We calculate the attacker's utility of attacking, or not, under the two scenarios and identify those choices that maximize his utility, given he observes the defender's action. This calculation follows formula (2). In the Influence Diagram Analysis Function in AgenaRisk, this calculation can be done automatically by selecting node  to be the decision node, node  and  to be the chance node and node  Utility to be the utility node (Agena Ltd. 2002-2021). In this example, we aim to maximize the expected utility and the calculation results are graphically represented by the Decision Tree (DT) shown in Figure 5.
Figure 5 The DT of the attacker's problem
Figure 5 shows the best decision for the attacker in bold arcs, occur when the defender does not defend herself, and the best choice for the attack is to attack, which provides him the maximum utility (60), while if the defender defends, the attacker's best choice would be to not attack, with the maximum utility (0). The second step is to update the CPT of the attacker's decision, , in the model. The CPT for node  is not 0.5 vs 0.5 anymore. The updated CPT for  is ( = | = ) = 1, ( = | = ) = 0, ( = | = ) = 0 and ( =  | = ) = 1 according to the results represented by Figure 5. We illustrate the updated D-A model in Figure 6.
8

Figure 6 The updated D-A model
Then, in the last step, we determine the defender's optimal decision by analysing the defender's problem (shown in Figure 3) using the updated D-A model. In this step, the decision of the attacker is regarded as a variable dependent on the defender's decision. Hence, node  becomes a chance node in the defender's problem. We calculate the defender's utility of defending or not following formula (4). We choose node  as the decision node, node  and  to be the chance nodes and node  Utility as the utility node. The calculation results are graphically represented by the DT shown in Figure 7.
Figure 7 The DT of the defender's problem
Here the optimal choice for the defender is shown by the bold arc, where to maximize her utility (-100) she should defend, otherwise she would suffer from a worse expected payoff (-160) if she does not. Therefore, the optimal decision for the defender is  =  and sequentially, the attacker is anticipated that might not conduct the attack ( = ).
9

4. The sequential Defend-Attack-Defend model
4.1 Adversarial risk analysis of the Defend-Attack-Defend model
The sequential Defend-Attack-Defend (D-A-D) game model is an extension of the sequential DefendAttack game. It assumes that the Defender (she) moves first (at time t = 1), making her initial defence deployment %. The Attacker (he) observes this choice and responds ( at time t = 2. Finally, the Defender chooses an action / to mitigate the damage from the attack at time t = 3. Chance nodes ( and / indicate the random payoffs that the defender and attacker receive on the second and third days of the game. It is assumed that the defender's utility consists of the cost of / and the outcomes from ( and / (Banks et al., 2015). Figure 8 shows the Influence Diagram (ID) of the D-A-D game problem. Previous work on this game has been done by (Lysyanskaya & Triandopoulos, 2006) (Rios & Insua, 2012) (Shan & Zhuang, 2013).
Figure 8 Influence diagram for the sequential Defend-Attack-Defend game

To determine the best choice for the defender, backward induction is implemented, which follows the similar idea with the procedure in the D-A model. The backward induction in the D-A-D model has five steps:
1) searching the optimal strategy of the subgame /, meaning determining choices in / that can maximize the defender's expected utility, corresponding to each possible pair of % and (; the expected utility function of the defender is determined by formula (6):

-(/!, %, () = -(/ = 0|/!, %, () × -(/!, %, (, / = 0) +

(6)

-(/ = 1|/!, %, () × -(/!, %, (, / = 1)

The optimal / is determined by formula (7):

/ = .!-!-(%, (, /)

(7)

2) using results generated from step 1 to update the CPT of / from the model.

10

3) analyse the attacker's problem assuming he can observe the defender's action % and can predict her decision /. The expected utility function of the attacker is determined by formula (8)

"((!, %, /) = "(/ = 0|(!, %, /) × "((!, %, /, / = 0) +

(8)

"(/ = 1|(!, %, /) × "((!, %, /, / = 1)

The optimal ( is determined by formula (9):

( = +""#"(%, (, / )

(9)

4) using results from step 3 to update the CPT for ( from the model. 5) searching the best choice for % that can maximize the defender's expected utility. That is
defined by formula (10):

-(%!, /, () = -(( = 0|%!, /, () × -(%!, /, ( , ( = 0) +

(10)

-(( = 1|%!, /, ( ) × -(%!, /, ( , ( = 1)

The optimal % is determined by formula (11):

% = .$-$-(%, ( , / )

(11)

Finally, the calculated results % = % and / = /(%, () are optimal decisions for the defender while the attacker is predicted to adopt ( = ((%) as his optimal action.
Figure 9 The defender's problem in the D-A-D game

11

Figure 10 The attacker's problem in the D-A-D game
4.2 Depicting a D-A-D game problem using an HBN
In this subsection, we use an example to show how to implement a sequential D-A-D game using an HBN, evaluate involved cyber risks and support the defender to make the optimal defence decision. We build an HBN to model a practical sequential D-A-D game as shown in Figure 11 (a). The defender and the attacker take actions alternatively towards an information system. In this model we use uniformly distributed variables with integer intervals to represent defence levels that the defender would decide to deploy and the attack levels that the attacker would decide to adopt. We assume that the defender's decision at time t = 1 is to equip a defence from level 0 to 3, to protect a target information asset. Level 0 means no defence is deployed. After observing the defender's deployment, the attacker would consider which attack level to adopt at time t = 2. Finally, the defender chooses a defence level to mitigate the damage from the attack at time t = 3. The CPT of Success nodes (node S2 and S3) models how the attack and defence interact to determine the probability of a success attack at time t = 2 and time t = 3. They can be determined using comparative expressions in AgenaRisk. We assume only when the attack level is larger than the defence level, the attack would success. We set the CPT for both S2 and S3 following this idea. The utility node, D_s Utility, models the defender's payoff given the defence is deployed (utility: -50 multiplies the adopted defence level) and the cost of being attacked successfully (utility: -100 for one successful attack). The utility node (A_s Utility) models the attacker's payoff of conducting an attack (utility: -50 multiplies the adopted attack level) and the gain of a successful attack (utility: 100 for one successful attack). We represent CPT settings of involved nodes in Figure 11 (b).
12

Figure 11 The BN modelling a sequential D-A-D game
4.3 Risk assessment and decision support for the defender
To determine the best choice for the defender, we conduct backward induction following procedure introduced in the subsection 4.1. Firstly, the defender would consider the defender's problem shown in Figure 9, that corresponding to each possible combination of % and ( what would be the best defence strategy at time t = 3. The defender's expected utilities with respect to /, given % and (, can be calculated following formula (6). In the Influence Diagram Analysis Function in AgenaRisk, this calculation can be done automatically by selecting node / to be the decision node, nodes % and ( to be the chance nodes and the node D_s Utility to be the utility node. The calculation results are graphically represented by a Decision Tree (DT) shown in Figure 12.
13

Figure 12 The DT with % being the decision node in the defender's problem
14

For each pair of % and (, the defence levels at time =3 that can provide the maximum utility are the optimal defence strategies. We record the results and use them to update the CPT of the node / as shown in Table 1.
Table 1 The updated CPT for %
The next step is to analyse the attacker's problem, which is shown in Figure 10, in the updated D-A-D model. At this step, choices of the defender are regarded as chance nodes, since / has been determined based on % and (, and % is regarded as a random variable in the attacker's problem. We calculate attacker's utilities with respect to ( following formula (8). We select node ( to be the decision node, nodes % and / to be the chance nodes and the node A_s Utility to be the utility node in AgenaRisk and conduct influence diagram analysis. The DT representing calculation results is shown in Figure 13.
Figure 13 The DT with & being the decision node of the attacker's problem
15

The defender can expect that the optimal choices for the attacker corresponding to each % are attack levels which lead to maximum attacker's utilities. We record these results to update the CPT for (. The updated CPT for ( is shown in Table 2.
Table 2 The updated CPT for &
Finally, we analyze the defender's problem with % being the decision node in the updated D-A-D model. The optimal choice for the defender at time t = 1 is shown by the bold path in the Figure 14 that to deploy defence level 3 and the corresponding maximum utility is 0. We have generated the optimal decisions for the defender, which are % = 3 and / = 0. Meanwhile, the attacker is predicted to adopt ( = 0 based on the defender's knowledge and the assumption that the attacker is intelligent and would adopt the attack that can maximize his own utility.
Figure 14 The DT with ' being the decision node in the defender's problem
16

5. Extensions of the sequential Defend-Attack game model
In section 3, we described how to implement influence diagrams of the D-A game model using Hybrid Bayesian Networks (HBNs) and consequently how to conduct the calculation. To illustrate the calculation mechanism, we build models with core variables only, comprising decision nodes, the chance nodes representing if the attacks are successful, or not, and the utility nodes for the two agents. However, in practice, interaction between defenders and attackers may involves more factors (Banks et al., 2015). In this section, we summarize the rules required when building and calculating more complicated sequential D-A game models.
5.1 Rules to build and calculate the sequential Defend-Attack game models
Extending the sequential D-A game models with extra variables or longer sequences is feasible, so long as we follow these rules:
1) Decisions from  and  need to be made alternately. This is described as level-k thinking in (Banks et al., 2015). For example, a D-A-D model can be considered as the defender, the attacker, then the defender decides. In this way, (local) optimal decision for each decision phase (obtained using backwards induction) can lead to the global optimal decision set for the whole adversarial problem.
2) Each decision node is influenced by all the previous decision nodes in the sequence representing when making decision on the certain phase, the agent has the knowledge of all the previous decisions. This can be reflected by creating arcs from all its previous decision nodes 1, ... ,  - 1, for each decision node , pointing to the current node .
3) Set the chance nodes (i.e., success nodes) and utility nodes following dependent relations below: 3.1) ! = !(!0%, !)   = {2, ... , }; 3.2) - = -((, ... , &, %, ... , &0%); 3.3) " = "((, ... , &, (, ... , &);
4) Decision nodes should be discrete variables to guarantee that each decision is made from finite options.
5) Decision nodes are set to follow uniform distributions to represent open mindedness when making decision.
After constructing the sequential D-A model (with extra variables or a longer sequence), we use probabilistic inference in HBNs and constructing Decision Trees (DTs) implementing the backwards induction in the sequential game model to calculate optimal strategies for the defender. In each decision phase in the sequence, we concentrate on the current decision node and regard all its previous decision nodes as chance nodes. The CPT of the current decision node is defined using probabilities conditioned on the adoption of potential strategies given all the combinations of decisions made before the current
17

phase. The initial setting of this CPT is as a uniform distribution representing the agent's open mindedness. We can calculate the agent's utility for each decision option, conditional on each combination of previous decision, and determine the decision that provides the maximum utility value for the agent. We use this information to update the CPT of the current decision node, following the idea that, given previous decisions, the agent will only adopt decisions that lead to maximum utilities, and hence the probability of the agent adopting any decision other than this must be set to zero. Next, we move to the decision node following the current node and repeat the same operation. When we find the optimal strategy for the first decision node in the sequence, we stop and obtain the optimal strategy set for the defender and the predicted action set anticipated for the attacker with an accompanying maximum utility. We formally summarize this calculation process in Algorithm 1 below:

Algorithm 1: The HBN based ARA approach in solving sequential D-A models

Initialization: " = "(%, ... , &0%, ... , (, ... , &, ) - = -(%, ... , &0%, ... , (, ... , &, ) (Assume n is even. When n is odds, the calculation follows the same process) for ( = ,  > 0,  - -) do
if (  ) do calculate: ! = +("("(%, ... , !1%, ... , & 0%, (, ... , !, ... , & , )
update the model: " = "(%, ... , !1%, ... , & 0%, (, ... , !, ... , & , ) - = -(%, ... , !1%, ... , & 0%, (, ... , !, ... , & , ) else if (  ) do

calculate: ! = .(-(-(%, ... , !, ... , & 0%, (, ... , !1%, ... , & , )

end for

update the model:
" = "(%, ... , !, ... , & 0%, (, ... , !1%, ... , & , ) - = -(%, ... , !, ... , & 0%, (, ... , !1%, ... , & , )

output:

updated model: " = "(%, ... , & 0%, ( , ... , & , ) - = -(%, ... , & 0%, ( , ... , & , )
Optimal strategies for the defender:

{%, ... , & 0%}

5.2 Example 1: The Defend-Attack game with extra variables
We now apply the proposed framework to a real cybersecurity problem, a simplified version of the case in (Insua et al., 2019) (Ekin et al., 2019). The problem is depicted in the ID shown in Figure 15, where
18

the model represents a defender facing a competitor, the attacker, that may attempt a DDoS attack to undermine the availability of the defender's website, compromising her customer services and leading to a decrease in share price.
Figure 15 Influence diagram of the case study D-A problem
The decision node Defend decision () represents cloud-based DDoS (Distributed Denial of Service) protection (with states 0, 2, 5, 10 and 100 gigabits per second ()) that the defender can deploy. The level of defence can be observed by the attacker, and therefore influences the attacker's decision, represented by the node Attack Decision. The node Attack Level (), which represents the scale of the attack, is assumed to follow a Gamma distribution, with the parameters  and  follow uniform distributions derived from historical data. The defence deployment  and the  determine the probability of Attack Success () together. The variable Attack Times () is influenced by both Attack decision and  and is assumed to follow a Binomial distribution. The Average Attack Hours () is assumed to follow a Gamma distribution, of which the parameters _1 and _1 also follow uniform distributions derived from historical data (Insua et al., 2019). The Duration of DDoS is derived from  multiplied by . Impact of Share Market is derived from the organization's Share Value (i.e., £1500000), Loss Rate under Attack and Duration of DDoS. In addition, the Defender's Utility (  ) is influenced by the Defend decision and the Impact of Share Market. Different defence deployment incurs different costs (i.e., 2 gbps: £2400; 5 gbps: £3600; 10 gbps: 4800; 100 gbps: £12000) (Insua et al., 2019). The defender's utility is equal to the deployment cost plus its loss in the share market.
19

The attacker needs to decide how many days to conduct the attack over a one-month period. This decision is represented by the node Attack decision with state values from 0 to 30. The longer the attack period is, the more likely the attack will be detected, represented by the node Detection of Attack, and is assumed to follow a Binomial distribution (Insua et al., 2019). If the attack is detected, the attacker would face legal costs, reputational costs, etc, which is represented by Loss of being Detected. If the attack is not detected, the Detection Loss will be zero. We assume the amount that the defender losses in the share market is the gain of the attacker. Based on that, Attacker's Utility is set to equal to Impact of Share Market minus Expected Loss of Being Detected minus the cost of Attack Decision.

We summarize the variables and how we assign expressions for them in AgenaRisk in Table 3.
Table 3 Variables and their expressions in Example 1

Variable
Defend decision Attack decision Alpha Beta Attack Level Attack Success Attack Times Detection of Attack If Detected Loss of Being Detected Expected Loss of Being Detected Alpha_1 Beta_1 Average Attack Hours Duration of DDoS Share Values Loss Rate under attack Impact of Share Market
Defender's Utility
Attacker's Utility

Notation
D A a b AL AS AT DoA ID LBD ELBD a1 b1 AAH DoD SV LR ISM
DU
AU

Expression
 (),  = {0, 2, 5, 10, 100}  (0, 30)  (4.8, 5.6)  (0.8,1.2)  (, )  ( ( - , 0.0)/( + 1.0 - 4),1.0)  (  : ;   : )  (  : ;   : 0.002)  ( > 0.0, "", "")  (: 2430000, : 400000) {  = :  (0.0),   = :  ()}  (3.6,4.8)  (0.8,1.2)  (1, 1)  ×  1500000  (0.00521, 0.00833)  (,  ×  × ) Partitional expression given status of : { = 0: - ,  = 2: -  - 2400,  = 5: -  - 3600,  = 10: -  - 4800,  = 100: -  - 12000}  -  - 792.0 × 

The influence diagram of this practical D-A problem with distributions of each involved variable is

shown in Figure 16.

20

Figure 16 Influence diagram of the practical D-A problem with distributions
We conduct calculation using Algorithm 1 with the results as shown in Figure 17. This shows the optimal strategy for the defender is  = 5 based on her analysis of the attacker's problem, of which the optimal attack is predicted to be  = 30. In this case, the maximum utility of the defender is -3605.
Figure 17 Results of the D-A model with extra variables
The decision tree in the process is shown in Figure 18. 21

Figure 18 The DT of the Competitor Attack Decision
22

5.3 Example 2: The Defend-Attack game with a longer decision sequence
We now apply the proposed framework to represent and solve a practical cybersecurity problem with more rounds of interaction between the defender and the attacker. We first construct the Influence Diagram (ID) for the game using an HBN, and then illustrate how to apply Algorithm 1 to calculate the optimal strategy for the defender. The organization provides online services for clients during the working days (Monday to Friday). Its system faces threats from a potential attacker who contemplates a DDoS attack aiming to disrupt the online service provided by the defender. To guarantee the normal operation of the online service, the defender deploys cloud-based protections against attacks. To simplify the problem, we assume the defender can adopt 0, 12, and 24 hours of protection a day, where zero hours means no protection is adopted; 12 hours means protection spreading in the whole day and the total volume is 12 hours; 24 hours is full protection. We also assume that the protection will be deployed when the defender make decision (%) on Monday and will remain valid until the next day (Tuesday). For the attacker, after observing defender's deployment, he would make an attack decision on Tuesday ((). We assume the attacker has three similar decision choices: conduct a 0, 12 or 24-hour long attack. Similarly, the attack deployment would be valid on the current day through to the next day. When the defender observes the attacker's action on Tuesday, she would make her defence decision (/) on Wednesday. This process continues until the weekend. We illustrate this adversarial problem in Figure 19.
Figure 19 The influence diagram of the Defend-Attack game with longer sequence
We represent decision nodes for the two agents as %, (, /, m  n. For %, the node has three states (0, 12, 24) with uniform distribution. ( is conditional on %, and therefore has nine states.
23

Following the same rule, the decision node n has 3n = 243 states. We use ! ( = 2, ... ,5) to represent whether the attack is successful. In this case, we set ! to be Boolean variables that have states "true" and "false". When the attack time exceeds the defence time, some percentage of the online

service will be interrupted.   !'(,...,n represents on day , how many service orders are

affected by a successful attack. We calculate the percentage of unprotected hours in any day to measure

those service orders interrupted by cyber-attack and assume, on average, the defender will have 1000

total online service orders and 10% of those orders may be affected by the cyber-attack. For example,

on Tuesday, ( = 12,

and % = 0, then the number of interrupted orders would be

%(0p × 1000 ×
(m

10% = 50. We use a TNormal distribution to represent the number of orders interrupted by the attack

with uncertainty, where we set: 1) mean = "(0-()$ × 1000 × 10% = "(0-()$; 2) variance = 400; 3)

(m

p.(m

lower bound = 0; 4) upper bound = 200. Nodes -! represent the defender's utility on day , which is

the cost of deploying protection (£500/hour) and the loss caused by interrupted online service

(£300/order). For the attacker, we assume his utility is the gain from the organization's loss on orders

minus the cost of conducting attacks (£500/hour), which on day  is represented by the node "!. Since utility is additive, we obtain the defender's utility over the whole week, -, from n!'( _!. We do the same with the attacker's utility.

We calculate the optimal strategy using Algorithm 1 and the optimal strategy of the subgame in each decision phase can be identified using a Decision Tree representing all the possible decision path and the resulting utility. We determine the optimal decisions and use these to update the model and repeat the process until we identify the optimal strategy at the first decision node in the sequence. The results are shown in Figure 20, where the optimal strategy calculated for the defender is {% = 12, / = 12, n = 0}, while for the attacker the anticipated strategy is {( = 0, m = 0}. In this case, the maximum utility of the defender is -18 (a loss of £18,000).

Figure 20 Results of the D-A model with longer sequence

Decision trees constructed in the process are shown in Figure 21-24.

24

Figure 21 The DT of D5
25

Figure 22 The DT of A4
26

Figure 23 The DT of D3
Figure 24 The DT of A2
6. Supporting the defender's dynamic decision making
In a game with a longer decision sequence, k-level thinking (i.e., he anticipates, she anticipates, what he would anticipates) is involved. As is shown in example 2, the defender anticipates what the attacker would do based on her belief of the attacker's utility (assuming that implementing an attack and a defence costs the same per hour and the loss of the defender caused by attack is the gain of the attacker) and the attack success probability. Based on the analysis of the attacker's problem, the defender determines her optimal decision at the first place. However, the original decision-making problem can become a dynamic decision-making problem over time, meaning that the defender can always use the fresh-observed data to update the model and make real-time-updated decision accordingly. More precisely, in example 2, the calculated strategies for the defender are optimal standing on Monday without observing any other information. When it comes to Wednesday, the defender can make decision based on what she can observe, i.e., the attack that actually taken or its consequences on Tuesday, and what she can anticipates, i.e., the attack that likely to be conducted in the future (on Thursday). Hence,
27

Dynamic Decision Analysis (DDA), which involves updating the D-A game model using observable information through the decision sequence, is required. In this section, we provide the DDA algorithm to deal with dynamic decision making. Moreover, we represent two examples to illustrate how the proposed DDA algorithm can be applied to analyse practical problems modelled by HBN.
6.1 The algorithm for dynamic decision analysis
The core idea of supporting dynamic decision making here is to update the sequential D-A model with real-time data and conduct decision analysis on the model updated using this data. We consider this dynamic decision-making issue based on example 2. In the example, we have obtained the optimal strategy set for the defender standing on Monday. This strategy set includes the optimal strategies suggested for the defender on Monday (%), Wednesday (/) and Friday (n) based on her prediction of attacks on Tuesday and Thursday (( and m respectively). Hence, initially, the defender would take the optimum decision % on Monday. On Wednesday, the defender can then observe effects of the adopted action or its consequence from the previous day, Tuesday in this case. If the actual attack is observable, we use ( to represent the observed attack (which does necessarily need to equal to the predicted attack ( ). Then we would use the calculated % and the observed ( (rather than the calculated ( ) to update the sequential D-A model; otherwise, if only the attack consequence is observable (i.e., whether the attack succeeded on Tuesday), we use this new observation for ( to update the model. In the latter case, if the attack on Tuesday is not observable, we remove the arc pointing from node ( to /. In addition, to represent the fact that / is influenced by (, we add an arc pointing from ( to /. Then we conduct dynamic decision analysis based on the updated model. We formally summarize the process of supporting dynamic decision-making using Algorithm 2.
28

Algorithm 2: The HBN based ARA approach in solving dynamic decision making
Initialization: " = "(%, ... , &0%, ... , (, ... , &, ) - = -(%, ... , &0%, ... , (, ... , &, ) (Assume n is even. When n is odds, the calculation follows the same process) for ( = 1,    - 1,  =  + 2) do
In the latest model conduct Algorithm 1 and get outputs: The updated model: " = "(%, ... , & 0%, ( , ... , & , ) - = -(%, ... , & 0%, ( , ... , & , ) Optimal strategy set of the game: {%, ... , q, ... , & 0%, ( , ... , q1%, ... , & }
identify optima for q, which is q; if (the actual adopted attack is observable) then do
record the actual attack adopted in day  + 1, which is q1% = q1%; update the model using q = q and q1% = q1%; else if (only the consequence of attack is observable) then do record the consequence of attack in day  + 1, which is q1% = q1%; update the model using q = q and q1% = q1%; remove arcs: q1%--->q1(,..., &0% add the arc: q1%--->q1( end if recover decision nodes in day  + 2,  + 3, ... ,  to be uniform. updated model: " = "(%, ... , q, ... , &0%, ... , (, ... , q1%, ... , &, ) - = -(%, ... , q, ... , &0%, ... , (, ... , q1%, ... , &, ) end for output: Updated model: " = "(%, ... , & 0%, (, ... , &, (, ... , &, ) - = -(%, ... , & 0%, (, ... , &, (, ... , &, ) Optimal strategies for the defender: {%, ... , & 0%}
29

6.2 Example 3: the actual attacks are observable
In this subsection, we show how we can apply algorithm 2 to support dynamic decision-making based on example 2 with the actual attacks are observable. According to the results calculated in Example 2, {% = 12, ( = 0, / = 12, m = 0, n = 0}, the defender would deploy % = % = 12 on Monday as her optimal move. However, when it comes to Wednesday and the defender is going to deploy the defence, we assume she realizes that the attacker attacks i.e., 24 hours on Tuesday rather than 0 hour represented by ( = 0. The strategy for this is to use % = % = 12 and ( = ( = 24 updating the model. We enter observations of % and ( into the model shown in Figure 9. The updated HBN representing the defender's problem and the attacker's problem on Wednesday is shown in Figure 25, while the ID showing distributions of variables are illustrated in Figure 26.
Figure 25 The updated HBNs for the DDM on Wednesday.
Figure 26 The updated HBNs for the DDM on Wednesday-with distribution of variables.
Then to calculate the optimal strategy for the defender standing on Wednesday, we apply Algorithm 2 to the updated HBNs. The optimal strategy for the defender on Wednesday is represented by the DT in Figure 27. Hence, we get / = 24.
30

Figure 27 The DT of D3 given information observed before Wednesday
Decision trees constructed in the process are shown in Figure 28 and 29.
Figure 28 The DT of D5 given information observed on Wednesday
Figure 29 The DT of A4 given information observed on Wednesday
Finally, when it comes to Friday, given observed attack on Thursday, we can calculate the defender's optimal choice following the similar way. Assuming that the attacker eventually adopted m = m = 12 on Thursday, we update the model by entering the observations / = / = 24 and m = m = 12. Then we construct a DT of n to determine the best choice for the defender when she makes the defence decision on Friday. We show this DT in Figure 30, which represents that n = n = 12 is the optimal choice when the defender stands on Friday.
Figure 30 The DT of D5 given information observed on Friday
31

Hence, we support the defender with optimal decisions in the dynamic process that deploy % = 12 at the first place, deploy / = 24 when observing the attack on Tuesday is ( = 24 and deploy n = 12 when observing the attack on Thursday is m =12. We illustrate observations, predictions and the optimal strategy set of this dynamic decision-making process in Figure 31.
Figure 31 Results summary of dynamic decision making in Example 3
6.3 Example 4: only the consequences of attacks are observable
In this subsection, we illustrate how we apply algorithm 2 to support dynamic decision-making based on example 2 with only the consequences of attacks are observable. Let's start from considering how to determine the optimal decision for the defender when it comes to Wednesday. At this time point, the defender has conducted % = % = 12 on Monday and can observe if the attack succeeded on Tuesday (represented by the node (). We remove the arc pointing from node ( to /, since under the assumption of this example, the past attack is no more observable. In addition, to represent / is influenced by (, we add an arc pointing from ( to /. Then we update the model using the real-time data which includes % = % = 12 and the observed states of ( (i.e., assuming ( = False). The updated model is shown in Figure 32 and 33. Algorithm 2 can be then applied to the updated HBNs, where % and ( are chance nodes while / , m and n are decision nodes. The corresponding optimal strategy set can be then calculated.
32

Figure 32 The updated HBNs for the DDM problem on Wednesday.
Figure 33 The updated HBNs for the DDM problem on Wednesday-with distribution of variables.
By constructing the DT for the defender on Wednesday, which is represented in Figure 34, we know that the optimal decision for the defender standing on the current time point (Wednesday) is / = 12. The optimal strategy set for all the decision nodes at this stage is {/ = 12, m = 0, n = 0}. DTs constructed in the process are shown in Figure 35 and 36.
Figure 34 The DT of D3 given information observed on Wednesday
33

Figure 35 The DT of D5 given information observed on Wednesday
Figure 36 The DT of A4 given information observed on Wednesday
The newly calculated strategy / is the optimal one for the defender at the current time point (Wednesday) given observed information have been considered to update her mind while she still uses her best knowledge to predict what attack would be adopted on Thursday. The defender would then adopt this optimal strategy on Wednesday. When it comes to Friday, she needs to update her mind again with the newly observed information and furthermore determines the best move on Friday. We can assume she observes that the attack on Thursday succeeded. Since the attack on Thursday is unobservable in reality, we remove the arc pointing from node m to n. Meanwhile, to represent n is influenced by m, we add an arc pointing from m to n. In this stage, the decision node is only n and there are no attack decisions needed to be predicted for determining the optimal n. The updated HBN is shown in Figure 37 and 38.
34

Figure 37 The updated HBN for the defender's problem on Friday.
Figure 38 The updated HBN for the defender's problem on Friday-with distribution of variables.
Based on the updated model, we construct the corresponding DT which is shown in Figure 39. It can be represented that the optimal strategy for the defender standing on Friday is n = 24.
Figure 39 The DT of D5 given information observed on Friday
Hence, we support the defender with optimal decisions in the dynamic process that deploy % = 12 at the first place, deploy / = 12 when observing the attack on Tuesday fails and deploy n = 12 when observing the attack on Thursday successes. We illustrate observations, predictions and the optimal strategy set of this dynamic decision-making process in Figure 40.
35

Figure 40 Results summary of dynamic decision making in Example 4
7. Conclusion
We propose an HBN based ARA approach for supporting decision making in sequential defend-attack game problems. This kind of problem is typically extracted to the sequential D-A model. We illustrate how to use the proposed method to calculate the optimal strategy in this template. Furthermore, to model more complicated cases that may be likely in practice, we consider two extended sequential D-A templates involving extra variables and longer decision sequence respectively. We construct the algorithm based on HBNs and the ARA approach to calculate optimal decisions for the supported agent (the defender) and provide examples to illustrate how the proposed method can be applied. Since the applied HBN inference provides an automated way to compute hybrid D-A models and extends their use to involve mixtures of continuous and discrete variables, the proposed HBN based ARA approach is more versatile compared with the Monte Carlo (MC) based ARA approach. More importantly, the proposed approach is novel in that it supports dynamic decision making whereby new real-time observations can be employed to update the D-A model timely and optimal decisions can be determined based on both generic information from the past and rigorous anticipation about the future. This dynamic decision analysis mechanism can make more effective use of information and can better simulate the actual decision-making process. Examples are provided, illustrating how the proposed framework can be adjusted for decision analysis in more complicated but more practical scenarios and serving as template for further expansion according to practical application requirement.
Acknowledgements
Jiali Wang is supported by a China Scholarship Council (CSC)/Queen Mary Joint PhD scholarship. Agena Ltd provided the AgenaRisk software gratis.
36

Appendix A: Notations summary

Notation

Definition and Explanation

ARA

Adversarial Risk Analysis

D-A model Defend-Attack model

HBN

Hybrid Bayesian Network

MC simulation Monte Carlo simulation

IDs

Influence Diagrams

HIDs

Hybrid Influence Diagrams

DTs

Decision Trees

CPT

Conditional Probability Table

 = {%, ... , )} A set of defences that the defender can choose from.

 = {%, ... &} A set of attacks that the attacker can choose from.

-(, , )

The utility of the defender given D, A and whether the attack successes (S).

-(, ) ("(, ) is defined in the similar way)
-(| , ) ()


The expected utility that the defender obtains when the decisions are (, )   × ;
-(, ) = -( = 0|, ) × -(, ,  = 0) + -( = 1|, ) × -(, ,  = 1)
The probability of successful attack given the decisions are (, ).
= +""(, ),   ; The optimal strategy in A that can maximize "(, ).
= .--(, ()); The optimal strategy in D that can maximize -(, ) given  = ().

37

Reference
Agena Ltd. 2002-2021. In. AgenaRiskV10 software package, www.AgenaRisk.com. Aliprantis, C. D., & Chakrabarti, S. K. (2012). Games and decision making. OUP Catalogue. Banks, D. L., Aliaga, J. M. R., & Insua, D. R. (2015). Adversarial risk analysis. Chapman and
Hall/CRC. Brown, G., Carlyle, M., Salmerón, J., & Wood, K. (2006). Defending critical infrastructure.
Interfaces, 36(6), 530-544. Do, C. T., Tran, N. H., Hong, C., Kamhoua, C. A., Kwiat, K. A., Blasch, E., Ren, S., Pissinou,
N., & Iyengar, S. S. (2017). Game theory for cyber security and privacy. ACM Computing Surveys (CSUR), 50(2), 30. Ekin, T., Naveiro, R., Torres-Barrán, A., & Ríos-Insua, D. (2019). Augmented Probability Simulation Methods for Non-cooperative Games. arXiv preprint arXiv:1910.04574. Fenton, N., & Neil, M. (2011). The use of Bayes and causal modelling in decision making, uncertainty and risk. CEPIS Upgrade, 12(5), 10-21. Fenton, N., & Neil, M. (2019). Risk assessment and decision analysis with Bayesian networks Second Edition. Crc Press. Gil, C., & Parra-Arnau, J. (2019). An Adversarial-Risk-Analysis Approach to Counterterrorist Online Surveillance. Sensors, 19(3), 480. Gindis, H. (2009). The Bounds of Reason: Game theory and the Unification of the Behavioural Sciences. In: Princeton Univ. Press. González-Ortega, J., Insua, D. R., & Cano, J. (2019). Adversarial risk analysis for bi-agent influence diagrams: An algorithmic approach. European Journal of Operational Research, 273(3), 1085-1096. Harsanyi, J. C. (1967). Games with incomplete information played by "Bayesian" players, I­ III Part I. The basic model. Management science, 14(3), 159-182. Hausken, K., & Bier, V. M. (2011). Defending against multiple different attackers. European Journal of Operational Research, 211(2), 370-384. Insua, D. R., Vieira, A. C., Rubio, J. A., Pieters, W., Labunets, K., & Rasines, D. G. (2019). An adversarial risk analysis framework for cybersecurity. arXiv preprint arXiv:1903.07727. Joshi, C., Rios, J., & Insua, D. R. (2020). Insider threat modeling: An adversarial risk analysis approach. IEEE Transactions on Information Forensics and Security.
38

Lin, P., Neil, M., & Fenton, N. (2014). Risk aggregation in the presence of discrete causally connected random variables. Annals of Actuarial Science, 8(2), 298-319.
Lysyanskaya, A., & Triandopoulos, N. (2006). Rationality and adversarial behavior in multiparty computation. Annual International Cryptology Conference,
Manshaei, M. H., Zhu, Q., Alpcan, T., Bacar, T., & Hubaux, J.-P. (2013). Game theory meets network security and privacy. ACM Computing Surveys (CSUR), 45(3), 25.
Rios Insua, D., Banks, D., & Rios, J. (2016). Modeling opponents in adversarial risk analysis. Risk Analysis, 36(4), 742-755.
Rios Insua, D., Rios, J., & Banks, D. (2009). Adversarial risk analysis. Journal of the American Statistical Association, 104(486), 841-854.
Rios, J., & Insua, D. R. (2012). Adversarial risk analysis for counterterrorism modeling. Risk Analysis: An International Journal, 32(5), 894-915.
Roy, S., Ellis, C., Shiva, S., Dasgupta, D., Shandilya, V., & Wu, Q. (2010). A survey of game theory as applied to network security. 2010 43rd Hawaii International Conference on System Sciences,
Shan, X., & Zhuang, J. (2013). Cost of equity in homeland security resource allocation in the face of a strategic attacker. Risk Analysis, 33(6), 1083-1099.
Wang, Y., Wang, Y., Liu, J., Huang, Z., & Xie, P. (2016). A survey of game theoretic methods for cyber security. 2016 IEEE First International Conference on Data Science in Cyberspace (DSC),
Yet, B., Neil, M., Fenton, N., Constantinou, A., & Dementiev, E. (2018). An improved method for solving hybrid influence diagrams. International Journal of Approximate Reasoning, 95, 93-112.
Zhuang, J., & Bier, V. M. (2007). Balancing terrorism and natural disasters--Defensive strategy with endogenous attacker effort. Operations Research, 55(5), 976-991.
39

