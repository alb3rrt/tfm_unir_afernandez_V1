arXiv:2106.00875v1 [cs.CC] 2 Jun 2021

The Hardest Explicit Construction
Oliver Korten  May 2021

Abstract

We investigate the complexity of explicit construction problems, where the goal is to produce

a particular object of size n possessing some pseudorandom property in time polynomial in n.

We give overwhelming evidence that APEPP, defined originally by Kleinberg et al. [17], is

the natural complexity class associated with explicit constructions for objects whose existence

follows from the probabilistic method, by proving that a host of well-studied explicit construction

problems lie in this class. We then observe that a result of Jer´abek [13] on provability in Bounded

Arithmetic, when reinterpreted as a reduction between search problems, shows that constructing

a truth table of high circuit complexity is complete for APEPP under PNP reductions. This

demonstrates that constructing a hard truth table is a universal explicit construction problem in

a concrete sense. This result in fact gives a precise algorithmic characterization of proving 2(n)

circuit lower bounds for ENP: the complete problem for APEPP has a PNP algorithm if and

only if such a lower bound holds. Together with our proof that pseudorandom generators can

be constructed in APEPP, this also yields a self-contained and significantly simplified proof of

the celebrated result of Impagliazzo and Wigderson [12] that worst-case-hard truth tables can

be used to derandomize algorithms (although the conclusion is weaker as our derandomization

requires an NP oracle). As another corollary of this completeness result, we show that ENP

contains a language of circuit complexity 2(n) if and only if it contains a language of circuit

complexity

2n 3n

.

Finally,

for several of

the problems shown to lie in

APEPP, we demonstrate

direct polynomial time reductions to the explicit construction of hard truth tables.

Department of Computer Science, Columbia University. Email: oliver.korten@columbia.edu
1

1 Introduction
Explicit construction -- the task of replacing a nonconstructive argument for the existence of a certain type of object with a deterministic algorithm that outputs one -- is an important genre of computational problems, whose history is intertwined with the most fundamental questions in complexity and derandomization. The primary method of existence argument for these problems is to show that a random object has a desired property with high probability. This technique, initiated by Erd¨os [9] and since dubbed the "probabilistic method", has proven immensely useful across disparate subfields of combinatorics and computer science. Indeed, the probabilistic method is currently our sole source of certainty that there exist hard Boolean functions, pseudorandom number generators, rigid matrices, and optimal randomness extractors, among a variety of other combinatorial objects.
Explicit construction problems can be phrased, in complexity terms, as sparse search problems: given the input 1n, output some object of size n satisfying a certain property. In the interesting case, such problems are also total : we have a reason to believe that for all n, at least one object with this property exists. In contrast to the fundamental importance of explicit constructions, there has been surprisingly little work attempting to systematically study their complexity. This gap was pointed out previously by Santhanam [25], who studied the complexity of explicit construction problems from the following perspective: we have some property  which is promised to hold for almost all strings of length n. Based on the complexity of testing the property , what can be said about the complexity of producing an n-bit string with property ? However, Santhanam notes that this definition does not seem to directly yield complete problems.
This issue is familiar in the study of the class TFNP: when we have only a promise that a search problem is total, it is seemingly impossible to reduce it to a problem of similar complexity which has a syntactic guarantee of totality. This led to the study, initiated by Papadimitriou [23], of characterizing total search problems based on the combinatorial lemma which guarantees the existence of a solution. In recent work of Kleinberg et al. [17], this method was used to analyse several total search problems in the polynomial hierarchy beyond NP. One class they define is APEPP, which consists of the P2 total search problems whose totality follows from the "Abundant Empty Pigeonhole Principle," which tells us that a function f : {0, 1}n  {0, 1}n+1 cannot be surjective. In this paper, we show that APEPP is the natural syntactic class into which we can place a vast range of explicit construction problems where a solution is guaranteed by the probabilistic method.
Given that APEPP is a syntactic class, it is natural to ask whether some explicit construction problem is complete for it. As it turns out, the answer is positive: constructing a truth table of length 2n with circuit complexity 2 n is in fact complete for APEPP under PNP reductions. Perhaps surprisingly, this important fact had been known for many years in the universe of Bounded Arithmetic, essentially proved in Emil Jer´abek's PhD thesis in 2004. Here Jer´abek shows that the theorem asserting the empty pigeonhole principle is equivalent, in a particular theory of Bounded Arithmetic, to the theorem asserting the existence of hard boolean functions. Although his result is phrased in terms of logical expressibility, when translated to language of search problems his techniques give a PNP reduction from any problem in APEPP to the problem of constructing a hard truth table. In Section 4 we give a self-contained proof of this, and generalize the reduction to hold for arbitrary classes of circuits equipped with oracle gates. Combined with our results placing a wide range of explicit construction problems in APEPP, this shows that in a concrete sense, constructing a hard truth table is a universal explicit construction problem. We give further credence to this claim by showing in addition that several well known explicit construction problems in APEPP, including the explicit construction of rigid matrices, can be directly reduced to the
2

problem of constructing a hard truth table via polynomial time reductions (as opposed to PNP reductions).

1.1 Our Contributions

We investigate the complexity class APEPP introduced in [17], defined by the following complete problem Empty: given a circuit C : {0, 1}n  {0, 1}m with m > n, find an m-bit string outside the range of C. In Section 3 we give overwhelming evidence that APEPP is the natural class associated with explicit constructions from the probabilistic method, by placing a wide range of well studied problems in this class. In particular, we show that the explicit construction problems associated with the following objects lie in APEPP:

·

Truth

tables

of

length

2n

with

circuit

complexity

2n 3n

(Theorem

1)

· Pseudorandom generators (Theorem 3)

· Strongly explicit two-source randomness extractors with 1 bit output for min-entropy log n + O(log(1/ )), and thus strongly explicit O(log n)-Ramsey graphs in both the bipartite and non-bipartite case (Theorem 4)

· Matrices with high rigidity over any finite field (Theorem 5)

· Strings of time-bounded Kolmogorov complexity n - log n relative to any fixed polynomial time bound and any fixed turing maching (Theorem 6)

· Communication problems outside of PSPACECC (Theorem 12)

· Hard data structure problems in the-bit probe model (Theorem 13)

Since the work of Impagliazzo and Wigderson [12] implies that constructing pseudorandom
generators reduces to constructing hard truth tables, APEPP constructions of PRGs follow im-
mediately from APEPP constructions of hard truth tables. However, we provide a self-contained
and simple proof that PRG construction can be reduced to Empty, without requiring the more involved techniques of Nisan, Wigderson and Impagliazzo [21][12]. Together with the result in the following section that constructing hard truth tables is complete for APEPP under PNP reduc-
tions, this gives an alternative and significantly simplified proof that worst-case-hard truth tables
can be used to derandomize algorithms (although it proves a weaker result, that this derandomiza-
tion can be accomplished with an NP oracle). In Section 4 we show that constructing a truth table of length 2n with circuit complexity 2 n is
complete for APEPP under PNP reductions (for any fixed 0 < < 1). As discussed earlier, the
core argument behind this result was proven by Jer´abek in [13], where he shows that the theorem
asserting the existence of hard boolean functions is equivalent to the theorem asserting the empty
pigeonhole principle in a certain fragment of Bounded Arithmetic. We show that, when viewed
through the lens of explicit construction problems, this technique yields a reduction from Empty to the explicit construction of hard truth tables. We also generalize this reduction to arbitrary
oracle circuits, which allows us to prove the following more general statement: constructing a truth table which requires large Pi -oracle circuits is complete for APEPPPi under Pi+2 reductions (the complete problem for APEPPPi is the variant of Empty where the input circuit can have Pi -oracle gates). By recasting and generalizing Jer´abek's theorem in the context of explicit construction problems, we are able to derive several novel results. First and foremost, we conclude that there is a PNP construction of hard truth tables if and only if there is a PNP algorithm for every

3

problem in APEPP, and so in particular such a construction of hard truth tables would automat-

ically imply PNP constructions for each of the well-studied problems discussed in Section 3. This

tells us that constructing hard truth tables is, in a definite sense, a universal explicit construction

problem. Since the existence of a PNP construction of hard truth tables is equivalent to the exis-

tence of a language in ENP with circuit complexity 2(n), this completeness result actually gives

an exact algorithmic characterization of proving 2(n) circuit lower bounds for ENP: such a lower

bound holds if and only if there is a PNP algorithm for Empty. Another corollary we derive is the

following: ENP contains a language of circuit complexity 2(n) if and only if it contains a language

of

circuit

complexity

2n 3n

(i.e.

within

a

constant

factor

of

the

worst

case

circuit

complexity).

Finally, in Section 5 we consider P (as opposed to PNP) reductions from particular explicit

construction problems to the problem of constructing hard truth tables. We show that in the

case of rigidity, bit probe lower bounds, and certain communication complexity lower bounds,

such reductions exist. These reductions take the following form: we show that the failure of

an n-bit string x to satisfy certain pseudorandom properties implies a smaller than worst case

circuit computing x. This then implies that any n-bit string of sufficiently high circuit complexity

will necessarily possess a variety of pseudorandom properties, including high rigidity, high space-

bounded communication complexity, and high bit-probe complexity. We also make note of an

interesting dichotomy, which tells us that any explicit construction problem of a broad type either

has a nontrivial algorithm, or a reduction from hard truth table construction.

Another concrete takeaway from this work is that we demonstrate, for several well-studied

problems, the weakest known assumptions necessary to obtain explicit constructions of a certain

type (polynomial time constructions in some cases and PNP constructions in others). Perhaps the

most interesting application of this is rigidity, as the complexity of rigid matrix construction has

been studied extensively in both the P and PNP regimes. The results in Section 3 and Section 4

show

that

a

matrix

over

any

finite

field

which

is

(

n2 log n

)-far

from

any

rank-0.49n

matrix

(in

hamming

distance) can be be constructed in PNP assuming ENP requires circuits of size 2(n). The weakest

hardness assumption previously known to yield a PNP construction with even remotely similar

parameters requires ENP to have 2(n) hardness for nondeterministic circuits [18]. On the other

hand, the results in Section 5 yield a polynomial time construction of matrices over F2 which are

(

n2 logk+1

n

)-far

from

any

rank-

n logk

n

matrix,

assuming

that

E

requires

circuits

of

size

(

2n nk

).

We

are

not aware of any conditional results which, assuming some circuit size lower bound for a uniform

class, yield a polynomial time construction of matrices with significantly better rigidity parameters

then currently achievable.

1.2 Related Work
A large body of work on the hardness/randomness connection, starting with that of Nisan and Wigderson [21], has exhibited the usefulness of explicit constructions of hard truth tables. The results of Impagliazzo and Wigderson [12] give, in particular, a reduction from explicit constructions of hard truth tables to explicit constructions of pseudorandom generators that fool polynomial size circuits. As noted by Santhanam [25], this immediately implies that for any "dense" property  recognizable in P (dense meaning the fraction of n-bit strings holding this property is at least 1/poly(n)), an efficient construction of a hard truth table immediately implies an efficient construction of an n-bit string with property . But many properties of interest such as Rigidity (or any of the other properties studied in this work) are only known to be recognizable in the larger class NP. Under the stronger assumption that we can construct truth tables hard for certain classes of nondeterministic circuits, constructions for all dense NP properties are known to follow as well [18], so in particular PNP constructions for every problem in APEPP would follow. However,

4

constructing truth tables that are hard for nondeterministic circuits appears strictly harder than

constructing truth tables hard for standard circuits, and in particular does not seem to be contained

in APEPP, so although this yields an explicit construction problem which is hard for APEPP,

it does not appear to be complete. In contrast, we show here that constructing a truth table which

is hard for standard circuits is both contained in and hard for APEPP, thus showing that a PNP

construction of a hard truth table is possible if and only if such a construction is possible for every

problem in APEPP.

For several of the problems we study, a long line of work has gone into improving state-of-the-art

explicit constructions. We give a brief overview here of some recent work on rigid matrices and

extractors. Rigidity was first introduced by Valiant [31], who showed that any matrix which is

n1+ -far from a rank-n matrix for some ,  > 0 cannot be computed by linear size, logarithmic

depth arithmetic circuits. Since then it has been a notorious open problem to provide examples of

an explicit matrix family with rigidity parameters anywhere close to this. A recent breakthrough

was achieved in [1], and improved by [4], which gives PNP constructions of matrices that are

(n2)-far from any rank-2log n/(log log n) matrix, for infinitely many values of n. However, such a

construction is still not sufficient to carry out Valiant's arithmetic circuit lower bound program.

A conditional result of [7] implies that PNP constructions of certain rigid matrices are possible

assuming explicit constructions exist for certain hard data structure problems in the group model.

In terms of polynomial time constructions, the best known construction yields a matrix which is

N2 

log

N 

-far

from

any

-rigid

matrix,

for

any

parameter



[28][10].

The case of Ramsey graphs and extractors is slightly more complicated. There are two common

definitions of the explicit construction problems corresponding to these objects. The first is often

referred to as the "weakly-explicit" version, where we must output the adjacency matrix (in the

case of Ramsey graphs) or truth table (in the case of extractors) in time polynomial in the size

of the truth table/matrix. The second version, referred to as the "strongly-explicit" version, is

to output a succinct circuit which computes the adjacency relation or extractor function. Clearly

the strongly-explicit case is harder, but in both cases, there is a significant gap between what is

achievable by explicit methods and what can be proven possible by the probabilistic method. We

will focus on the strongly explicit case in this work, and in the case of extractors we will focus on

two-source extractors with one bit of output, which remains the most challenging current frontier

[5]. The state of the art constructions for both two-source extractors and Ramsey graphs are due

to Li [19]. He demonstrates a two-source extractor for min-entropy O(log n log log n), and hence

an n-vertex graph which is (log n)O(log log log n)-Ramsey. Our results show that strongly explicit

extractors for min-entropy log n + O(log(1/ )), and thus n-vertex O(log n)-Ramsey graphs, can be

constructed in APEPP. In both cases these parameters are known to be the best possible. For a

comprehensive survey of recent progress on extractors see [5].

Another line of work in the area of explicit constructions investigates the possibility of pseudo-

deterministic constructions of certain objects. Here, the construction algorithm is allowed to use

randomness, but must output the same object on most computation paths. Originally introduced

in [11], this paradigm was recently applied in [22] to the construction of prime numbers, where a

subexponential time pseudodeterministic construction which works for infinitely many input lengths

is given.

2 Definitions
Following [17], we define the set of total functions in P2 , denoted TFP2 , as follows: Definition 1. A relation R(x, y) is in TFP2 if there exists a polynomial p(n) such that the
5

following conditions hold:

1. For every x, there exists a y such that |y|  p(|x|) and R(x, y) holds

2. There is a polynomial time turing machine M such that R(x, y)  z  {0, 1}p(|x|)M (x, y, z) accepts

The search problem associated with such a relation is: "given x, find some y such that R(x, y) holds." For the majority of this paper, we will be concerned primarily with sparse TFP2 search problems, where the only relevant part of the input is its length. We can thus define the following "sparse" subclass of TFP2 :
Definition 2. A relation R(x, y) is in STFP2 if R  TFP2 and for any x1, x2 such that |x1| = |x2|, we have that for all y, R(x1, y)  R(x2, y).

Since the length of x fully determines the set of solutions, the relevant search problem here is: "given 1n, find some y such that R(1n, y) holds." All explicit construction problems considered in Section 3 will be in STFP2 (with the exception of Complexity which we briefly mention as it was studied previously in [17]).
We now define the search problem Empty, which will be the primary subject of this work:

Definition 3. Empty is the following search problem: given a boolean circuit C with n input wires and m output wires where m > n, find an m-bit string outside the range of C.

This problem is total due to the basic lemma, referred to in [17] as the "Empty Pigeonhole Principle" and in the field of Bounded Arithmetic as the "Dual Pigeonhole Principle [13]," which tells us that a map from a smaller set onto a larger one cannot be surjective. Since verifying a solution y consists of determining that for all x, C(x) = y, we have:

Observation 1. Empty  TFP2

Since for any instance of Empty the number of output bits m is at least n + 1, a random m-bit

string

will

be

a

solution

with

probability

at

least

1 2

.

Since

verifying

a

solution

can

be

accomplished

with one call to an NP oracle, this implies the following inclusion:

Observation 2. Empty  FZPPNP

As mentioned in the introduction, this fact tells us that sufficiently strong pseudorandom generators capable of fooling nondeterministic circuits such as those in [18] would suffice to derandomize the above inclusion and yield a PNP algorithm for Empty. In Section 4, we will show that this derandomization can be accomplished under a significantly weaker assumption, using a reduction of a very different form then the hardness-based pseudorandom generators of [21], [12], and [18].
We can now define the class APEPP, which is simply the class of search problems polynomialtime reducible to Empty. This class was originally defined in [17], and is an abbreviation for "Abundant Polynomial Empty Pigeonhole Principle." The term "Abundant" was used to distinguish this from the larger class PEPP also studied in [17]. The complete problem for PEPP is to find a string outside the range of a map C : {0, 1}n \ {0n}  {0, 1}n, which appears significantly more difficult (it is at least as hard as NP [17]). The distinction between APEPP and PEPP also appears in the Bounded Arithmetic literature, where the principle corresponding to APEPP is referred to as the "Dual weak Pigeonhole Principle," while the principle corresponding to PEPP is referred to simply as the "Dual Pigeonhole Principle." We will be concerned only with the abundant/weak principle in this work.

6

Infinitely-often vs. almost-everywhere circuit lower bounds: As a final point of clarification, whenever we make the statement "L requires circuits of size s(n)" for some language L and size bound s, we mean that circuits of size s(n) are required to compute L on length n inputs for all but finitely many n. This is in contrast to the statement "L / SIZE(s(n))," which means the circuit size lower bound holds for infinitely many input lengths. All circuit lower bounds referred to in this work will be of the first kind.

3 Explicit Constructions in APEPP
In this section, we show that a variety of well-studied explicit construction problems can be reduced in polynomial time to Empty. Each proof follows roughly the following format: there is some property of interest , and our goal is to construct an n-bit string which holds this property. For each such  we consider, whenever an n-bit string x fails to have this property, it indicates that x is somehow more "structured" than a random n-bit string. We then utilize this structure to exhibit a map C : {0, 1}k  {0, 1}n with k < n, such that any string not having property  is in the range of C. This then implies that any n-bit string outside the range of C must hold property . Thus any solution to the instance of Empty defined by C will be a solution to our explicit construction problem. For many of the proofs, we will only show that the reduction is valid for n sufficiently large; clearly this is sufficient, since explicit constructions can be done by brute force for fixed input lengths.

A useful coding lemma: In the proofs to come, it will be helpful to utilize succinct and efficiently computable encodings of low-weight strings (the "weight" of binary string is the number of 1 bits it contains). We start with the following fact:

Lemma 1. For sufficiently small

>

0,

we

have

H

(

1 2

-

)  1-

2, where H

denotes the binary

entropy function.

The proof of this lemma can be found in the appendix. Using this we can obtain the following:

Lemma 2. For sufficiently small , there exists an efficiently computable map  : {0, 1}n- 2n+log n 

{0, 1}n such that any n-bit string with weight at most

n 2

-

n is in the range of .

Proof. We employ the coding scheme of [26], which efficiently encodes weight k n-bit strings using

H(k/n)n bits.

In this case, we have k/n =

n 2

-

n

n

=

1 2

-

, so applying the above lemma we get that

H (k/n)n

=

H

(

1 2

-

)n  n(1 -

2) = n -

2n.

Thus we have an efficient encoding that encodes

all n-bit strings with weight exactly

n 2

-

n using n -

2n bits.

To encode a string with weight at

most

n 2

-

n,

we

can

simply

use

the

weight

k-encoding

for

each

k



n 2

-

n, which requires at most

n 2

-

n bits for each k since H

is

increasing

on

the

interval

[0,

1 2

].

We can then use an additional

log(

n 2

-

n)



log n

bits to say which value

of k

we used

the encoder

for,

so that the suitable decoder

can then be applied.

3.1 Hard Truth Tables
Definition 4. Given a string x of length N , we say that x has a circuit of size s if there is a boolean circuit C of fan-in 2 over the basis , , ¬ with log N inputs and s gates, such that C(i) = xi for all 1  i  |x|. If N is not a power of 2, we put no restriction on the value of C(i) for i > |x|.

7

Definition 5. Hard Truth Table is the following search problem: given 1N , output a string x

of

length

N

such

that

x

does

not

have

circuits

of

size

3

N log

N

.

In the typical case where N = 2n for some n, this is equivalent to finding a truth table for an

n-input

boolean

function

requiring

circuits

of

size

2n 3n

,

which

is

within

a

constant

factor

of

the

worst

case circuit complexity for any n-input boolean function.

Theorem 1. Hard Truth Table reduces to Empty

Proof. This proof follows Shannon's classical argument for the existence of functions of high circuit

complexity [27]. We construct an instance of Empty in the form of a circuit  which maps an

encoding

of

a

circuit

to

its

corresponding

truth

table.

In

particular,



will

have

2N 3 log N

+

2 3

N

+

log

N

input bits and N output bits.  interprets its input as a circuit on log N bits, tests its value on

every possible input to generate a 2 log N bit truth table, and then truncates this truth table to be

of length exactly N .

We now

show

that any

N -bit

string x

with

a

circuit

of

size

N 3 log N

is in

the

range

of

.

Given

a

circuit

of size

s

N 3 log N

on

log N

inputs

computing

x,

we

can

encode

it

using

2N 3 log N

+

2 3

N

+ log

N

bits as follows. For each of the s gates, we can use 2 bits to encode whether it is an , , or ¬

gate, and an additional 2 log s bits to specify its inputs. We can then use an additional log s bits

to specify which gate is the terminal output gate. Overall this requires 2s + 2s log s + log s bits. It

is clear that from such an encoding, our circuit  can efficiently decode the circuit and test it on

all

possible

input

values.

For

s



3

N log

N

,

we

have:

2N 2

2s + 2s log s + log s 

+ N + log N

3 log N 3

which is strictly less then N for N sufficiently large. So any string outside the range of  is a solution to Hard Truth Table.

A related problem was studied in [17], referred to there as "Complexity." Rather then an explicit construction problem with sparse input, in this problem you are given as input one truth table x of length N , and asked to produce another truth table y such that y requires large circuits, even with access to x-oracle gates. More formally:

Definition 6. The problem Complexity is defined as follows: given an N -bit string x, find

another

N -bit

string

y

such

that

y

requires

x-oracle

circuits

of

size

N log2

N

.

It should be noted that the "x oracle" is not the typical definition of an oracle gate that can solve arbitrarily sized instances of a fixed language, but rather an oracle for a fixed boolean function on log N variables. In [17] the following is shown:

Theorem 2. Complexity reduces to Empty.

3.2 Pseudorandom Generators
Definition 7. We will say a set R  {0, 1}n is a pseudorandom generator if, for all n-bit circuits of size n:
|P rxR[C(x) = 1] - P ry{0,1}n[C(y) = 1]|  1/n
Standard applications of the probabilistic method show that such pseudorandom generators exist of size polynomial in n. Thus we can define the following total search problem:

8

Definition 8. PRG is the following search problem: given 1n, find a pseudorandom generator R  {0, 1}n.

A polynomial time algorithm for PRG would suffice to derandomize BPP [21]. We now show how to formalize the argument for the totality of PRG using the empty pigeonhole principle. In particular, we show that a PRG of size n6 can be constructed in APEPP.
As noted in the introduction, the results of Impagliazzo Wigderson [12] imply that PRG reduces directly to Hard Truth Table, so a reduction of PRG to Empty follows from Theorem 1. However, we provide here a much simpler direct proof that PRG reduces to Empty, relying only on Yao's next bit predictor lemma, and neither the nearly disjoint subsets construction of [21] nor the rather involved worst-case to average-case reductions of [12]. Together with our completeness result in Section 4, this gives an alternative, self-contained proof that worst-case-hard truth tables can be used to construct pseudorandom generators (although it yields a weaker result, as our derandomization will require an NP oracle).

Theorem 3. PRG reduces to EMPTY

Proof. We start by constructing the following circuit .  interprets its input as representing a

set R- of n6 strings of length n - 1, a circuit D of size cn (for a fixed universal constant c to be

defined later) with n - 1 input bits and one output bit, a log n-bit index i  [n], and a string S

encoding

an

n6-bit

string

with

weight

at

most

n6 2

- n4.

Given

these,



feeds

each

n - 1-bit

string

x  R- through D, then inserts the output as an extra bit at the ith position of x to obtain an

n-bit string x. Let R = {x | x  R-}. In the final step,  decodes the n6-bit string represented

by S, and flips ith bit of the jth element of R if and only if the jth position of S has a 1, to obtain

R.  then outputs R.

It is clear that  can be implemented as a polynomial sized circuit in n, and further that  can

be constructed in polynomial time given 1n. We now show there are fewer inputs then outputs.

Note that the input size is equal to the number of bits needed to specify R-, D, i, S, which is

n7 - n6 + O~(n) + log n + bits(S), where bits(S) is the number of bits needed to specify S. Since S

an

n6-bit

string

with

weight

at

most

n6 2

- n4

=

n6(

1 2

-

1 n2

),

we

can

apply

Lemma

2

with

=

1 n2

to

give

an

encoding

for

S

using

n6(1 -

1 n4

)

+

log(n6

)

=

n6 - n2 + 6 log n

bits.

Thus

the

overall

number

of bits of input is at most n7 - n6 + O~(n) + log n + n6 - n2 + 6 log n = n7 + O~(n) + 7 log n - n2 which

is strictly less then the n7 bits of output (for sufficiently large n). So this is indeed a polynomial

time reduction to a valid instance of Empty. It remains to show that any string outside the range

of  is a pseudorandom generator.

Let R  {0, 1}n be a set of size n6 which is not a pseudorandom generator. So there exists a

circuit C of size n such that:

|P rxR[C(x) = 1] - P ry{0,1}n[C(y) = 1]| > 1/n

By Yao's next bit predictor lemma [32] [30], this implies the existence of an index i  [n] and a circuit D : {0, 1}n-1  {0, 1} of size cn for some fixed universal constant c, such that

11 P rxR[D(x1, . . . , xi-1, xi+1, . . . , xn) = xi] > 2 + n2

where x = x1, . . . , xn. Since R has size n6, this implies that D correctly guesses the ith bit of x  R

from

the

other

n

-

1

bits

for

at

least

n6(

1 2

+

1 n2

)

=

n6 2

+ n4

of the elements of R.

So if we let S

be the n6-bit string with a 1 at the indices where D guesses the wrong value of xi, we see that the

weight

of

S

is

at

most

n6 2

- n4

as

required.

Taking

R-

=

{r-i

|

r



R},

where

r-i

is

the

n-1

bit

9

string obtained by deleting the ith element of r, we have that from R-, D, i, S we can efficiently deduce R.
So overall, have established that for any R which is not a pseudorandom generator, there exists some R-, D, i, S such that our circuit  outputs R on input R-, D, i, S. Thus, any string outside the range of  is a pseudorandom generator.

3.3 Strongly Explicit Randomness Extractors and Ramsey Graphs

A (k, ) two-source extractor with one bit of output is a function f : {0, 1}n × {0, 1}n  {0, 1} such that for any pair of distributions X, Y on {0, 1}n of min-entropy at least k, the value of f (xy) for a random x, y in the product distribution of X, Y is -close to an unbiased coin flip. By a well-known simplification of [6], to show that a function f is a (k, ) extractor, it suffices to show that it satisfies the above condition for every pair of "flat" k-sources X, Y , which are uniform distributions over subsets of {0, 1}n of size 2k. We will thus use the following definition of two-source extractors to define our explicit construction problem:

Definition 9. We say that a function f : {0, 1}n × {0, 1}n  {0, 1} is a (k, ) extractor if the

following holds: for any two sets X, Y



{0, 1}n

of

size

2k ,

|P rxX,yY

[f (xy)

=

1]

-

1 2

|



.

Definition 10. (k, )-Extractor is the following search problem: given 1n, output a circuit C with 2n inputs such that the function fC : {0, 1}n×{0, 1}n  {0, 1} defined by C is a (k, ) extractor.

The above problem definition does not expressly constrain the size of C, though for a construction to be "explicit" in any useful sense (efficiently computable as a function of n), C would have to have size polynomial in n. The following reduction placing extractor construction in APEPP will immediately imply that we can construct a (log n + O(1), ) extractor of circuit size approximately n3 in APEPP for any fixed .

Theorem 4. For any

satisfying

1 2n2 /5

<

<

1 2

,

(log n + 2 log(1/

) + 3,

)-Extractor

reduces to

Empty.

Proof. Let d =

4
2

.

We will set up an instance of Empty with at most 2d2n3 + 2dn2 -

2d2n2 +

2 log(2dn) + 1 inputs and exactly 2d2n3 outputs which has the following property: Let A be any

2d2n3-bit string outside the range of this circuit, viewed as an ordered list of d2n2 elements of F22n denoted 1, . . . d2n2, and consider the function f : {0, 1}2n  {0, 1}2n defined by

d2 n2
f (x) = ixi-1
i=1

Then the function g : {0, 1}2n  {0, 1} defined by

g(x) = f (x) mod 2

is a (log dn, ) extractor. Since log dn = log n + log d  log n + log(4/ 2 + 1)  log n + 2 log(1/ ) + 3,

this would give the required result.

Let 1, . . . d2n2 be any sequence of coefficients in F22n such that the above function g corre-

sponding to the i is not a (log dn, ) extractor. So there exists two sets of n-bit strings X, Y ,

each

of

size

2log dn

=

dn,

and

some

b



{0, 1}

such

that

P rxX,yY [f (xy)

=

b]

>

1 2

+

.

Let

R = {xy | x  X, y  Y }  {0, 1}2n. We have |R| = |X||Y | = d2n2. Let r1, . . . rd2n2 denote the

lexicographical enumeration of R. By assumption, we have that g(ri) = b

mod

2

for

at

least

a

1 2

+

10

fraction of indices i. So then, if we let i be the 2n - 1-bit prefix of g(ri), we can deduce the value

of

g(ri)

from

i

and

b

for

at

least

d2n2(

1 2

+

) values of i.

Thus,

there

is

some

d2n2

(

1 2

-

)-weight

d2n2-bit string S, such that from b, S, and the i's, we can deduce g(ri) for all i. Now, once we are

able to deduce g(x) for each of the d2n2 distinct values of x in R, since g is a degree d2n2 -1 polyno-

mial, we can uniquely and efficiently determine the coefficients i of g using Gaussian elimination on the corresponding d2n2 × d2n2 Vandermonde matrix.

So we have shown that for any set of i's which does not define a (log dn, ) extractor, there

exists X, Y, b, S, and i's, from which we can efficiently deduce the i's. It is clear that we can

encode X, Y using 2dn2 bits, b using 1 bit, and the i's using d2n2(2n - 1) = 2d2n3 - d2n2 bits.

Since

S

is

a

d2n2(

1 2

-

)-weight d2n2-bit string, by Lemma 2, we can encode S using at most

d2n2(1 - 2) + log(d2n2) = d2n2 - 2d2n2 + log(d2n2) bits. So in total the number of input bits is

at most:

2dn2 + 1 + d2n2 - 2d2n2 + log(d2n2) + 2d2n3 - d2n2 = 2d2n3 + (2d - 2d2)n2 + 2 log(dn) + 1

Since we chose

4
2

+

1



d



4
2

,

we

have

that(2d

-

2d2) < -1 for



1 2

,

so

the

number

of

output

bits is at most 2d2n3 - n2 + 2 log(dn) + 1. Since we assumed



, 1
2n2 /5

we

have

n2

>

2 log(dn) + 1,

so this is strictly less then the number of output bits 2d2n3.

So this implies that the circuit  mapping X, Y, b, S and the i's to a corresponding set of i's

is a valid instance of Empty, and that any solution to this instance is a set of coefficients defining a

(log n+2 log(1/ )+3, ) extractor. From the coefficients i we can easily construct an efficient circuit

computing the function g, thus solving the problem (log n + 2 log(1/ ) + 3, )-Extractor.

For the typical parameter regime where is an arbitrarily small constant, this gives a two source extractor for min-entropy log n + O(1).

Corollary 1. Explicit construction of strongly explicit Ramsey graphs (n-vertex graphs containing no clique or independent set of c log n for some constant c), in both the bipartite and non-bipartite case, reduce to Empty.

Proof. As noted in [3], any two-source extractor in the above sense (with fixed to any constant less then one half) is automatically a bipartite Ramsey graph, and from a strongly explicit bipartite Ramsey graph we can construct a strongly explicit non-bipartite Ramsey graph efficiently.

3.4 Rigid Matrices

Definition 11. We say that n × n matrix M over Fq is (r, s) rigid if for any matrix S  Fnq ×n with at most s non-zero entries, M + S has rank greater than r.

Definition 12. ( , , q)-Rigid is the following problem: given 1n, output an n × n matrix M over

Fq

which

is

(

n,

n2 log n

)

rigid.

Theorem 5. For any ,  such that

+

<

1 2

,

and

any

prime

power

q,

(

, , q)-Rigid

reduces

to

Empty.

Proof.

Let

M

be

any

n×n

matrix

over

Fq

which

is

not

(

n,

n2 log n

)

rigid.

So

there

exists

a

matrix

X of rank

n

and

a

matrix

S

with

at

most

n2 log n

non-zero

entries,

such

that

M

=

X

- S.

X can

equivalently be expressed as the product of an n × n matrix L and an n × n matrix R, and thus

from the description of L, R, S, we can efficiently compute M .

Since L, R have dimensions n × n and n × n respectively, each can be described using n2 log q

bits.

Since

S

has at

most

n2 log n

non-zero entries,

S

can be described

with at

most 2n2 log q

bits

11

as

follows:

we

store

a

list

of

the

indices

corresponding

to

each

of

the

n2 log n

non-zero

matrix

entries

(2 log n bits per entry), along with the contents of that entry (log q bits per entry). So overall the

number of bits needed to specify L, R, S is at most 2 n2 log q + 2n2 log q = 2( + )n2 log q. Note

that the number of bits needed to describe an arbitrary n × n matrix over Fq is n2 log q. So if we

construct a circuit mapping an encoding of L, R, S to the n × n matrix LR - S, provided

+

<

1 2

this will be a valid instance of Empty with fewer input bits then output bits, and any string outside

the

range

of

this

circuit

will

encode

an

(

n,

n2 log n

)

rigid

matrix

over

Fq .

3.5 Strings of High Time-Bounded Kolmogorov Complexity
Definition 13. Let U be any fixed turing machine, and let t : N  N be a time bound. For a string x, KUt (x) denotes the length of the smallest string y such that U outputs x on input y in t(|x|) steps.
Definition 14. For a turing machine U and time bound t, we define the following explicit construction problem KUt -Random: given 1n, output an n bit string x such that KUt (x)  n - log n
Theorem 6. For any fixed turing machine U and fixed polynomial time bound t, KUt -Random reduces to Empty
Proof. We construct a circuit  with n - 1 input bits and n output bits as follows. We interpret the first n - log n - 1 input bits as a string x, and the last log n bits as a string i. We interpret i in binary to be a "length" parameter, and truncate x to length k = min(i, n - log n - 1). Now, we run the Cook-Levin reduction to produce a circuit  with k inputs and n outputs which simulates U on a length k inputs for t(n) steps and outputs the result.  can be produced from k, n, U in poly(n) time for a fixed t, U , and thus can be produced and simulated by a polynomial sized circuit  (whose description can in turn be computed in polynomial time given n, U ).
For any n-bit string x with KUt (x) < n - log n , there is some k-bit string y, with k  n - log n - 1, such that U produces x in t(n) steps, and so if we pad y to y of length exactly n - log n - 1,  will output x on input y k. So any string outside the range of this circuit will be a solution to KUt -Random.

3.6 Other Problems
In Section 5, we introduce two more explicit construction problems and show that each of these, in addition to a variant of the rigidity problem, can be reduced directly to Hard Truth Table in polynomial time. This also implies that both problems are contained in APEPP. We will postpone a formal definition of each of these new problems until Section 5, but give an informal statement here for completeness:

Explicit communication problems outside PSPACECC: An explicit 2n ×2n communication matrix which cannot by solved by any o(n)-space protocol can be constructed in APEPP.

Explicit data structure problems with high bit-probe complexity: An explicit data structure problem with nearly maximum complexity in the bit-probe model can be constructed in APEPP.

12

4 Constructing Hard Truth Tables is Complete for APEPP
In this section we show that constructing a hard truth table is complete for APEPP under PNP reductions. As mentioned before, the core of this theorem was originally proven by Jer´abek [13]. Jer´abek's result is phrased in the language of proof complexity, stating that the theorem asserting the existence of hard boolean functions is equivalent to the empty pigeonhole principle in a particular theory of Bounded Arithmetic. We demonstrate below that when translated to the language of search problems and explicit constructions, his proof yields a PNP reduction from Empty to the problem of constructing a hard truth table. We in fact prove a more general statement here which holds for arbitrary circuit classes equipped with oracle gates. For a very broad set of circuit classes C, we prove that given a truth table which is hard for C-circuits, we can find an empty pigeonhole of any C-circuit using polynomially many calls to an oracle for inverting C-circuits (by inverting we mean finding the preimage of a given string, or reporting that none exist). In order to make this precise, we first define the type of generalized circuit classes we will consider.
Definition 15. A circuit class C is a (possibly infinite) set of boolean-valued boolean functions. A C-circuit is a circuit composed entirely of gates computing functions in C. For a language L, we will refer to the "circuit class L" to mean the circuit class defined by the set of boolean functions {Ln | n  N}  {, , ¬}, where Ln is the n-bit boolean function deciding L on length n inputs. For a complexity class C with a complete language L, we will refer to "the circuit class C" to mean the circuit class corresponding to L.
We say that a circuit class C is "sufficiently strong" if there exist C-circuits computing the two-input ,  functions and the one-input ¬ function.
Given a class of circuits C, a C-inverter is an oracle which, given a C-circuit C and some string y, determines whether there exists an x such that C(x) = y, and produces such an x if it exists. A C-reduction is a polynomial time reduction that uses a C-inverter.
Note that in the special case where C = {, , ¬}, a C-reduction is equivalent to a PNP reduction.
Definition 16. For a circuit class C, the class of search problems APEPPC is defined by the following complete problem EMPTYC: given a C-circuit with more output wires than input wires, find a boolean string whose length is equal to the number of output wires but which is not in the range of this circuit. For any strictly increasing function f : N  N, we define the problem EM P T YCf(n), which is the special case of EMPTYC where the circuit is required to have f (n) output wires, where n is the number of input wires.
We start with the following technical lemma, which allows us to restrict our attention to circuits with exactly twice as many outputs as inputs.
Lemma 3. For any circuit class C, EM P T YC2n is complete for APEPPC under C-reductions.
Proof. It is straightforward to see that EM P T YCn+1 is complete for APEPPC: given a C-circuit C with n inputs and more than n outputs, we can simply delete all the output bits except for the first n + 1 to obtain an instant of EM P T YCn+1. Any n + 1-bit string outside the range of this smaller circuit can than be padded arbitrarily to the output size of the original circuit, and this padded string must also be outside the range of C.
We now reduce EM P T YCn+1 to EM P T YC2n. Let C be some C-circuit with n inputs and n + 1 outputs. For a non-negative integer i, let Ci be a circuit with (n + i)n inputs and (n + i + 1)n outputs, defined as follows: viewing the input as n + i blocks of length n, we apply C to each block,
13

concatenate the results, and then ignore the last i bits. This output has length (n + i)(n + 1) - i = n2 + ni + n + i - i = n(n + i + 1) as required. Now, we construct the circuit C with n2 inputs and 2n2 outputs, by feeding the input wires into C0, then the output of C0 into C1, and so on up to Cn-1, whose output is then the output of C (in other words this circuit computes the function Cn-1  . . .  C0). Since this circuit has twice as many outputs as inputs it is an instance of EM P T YC2n, and it is clearly of size polynomial in |C|, since each Ci has at most 2n copies of C and there are n Ci's. We now claim that given a string y outside the range of C, we can find a string outside the range of C using an C inverter. We start by determining if y is outside of the range of Cn-1. If it is, then some contiguous n + 1-bit block of y must be outside the range of C, since y is obtained by computing C on 2n blocks of n bits and concatenating the results. We can look at each block one at a time and determine which is outside the range of C using our C-inverter. Otherwise, y has a preimage under Cn-1, and we repeat this search on that preimage, examining Cn-2 next, and so on until we get to C0. Since y is outside the range of C, at some point this process must terminate before we invert y all the way back to the input layer, and so at some point we must locate a string outside the range of C. Definition 17. Let -HardC denote the following search problem: given 1N , output a string x of length N such that x cannot be computed by C-circuits of size N .
In the case where C = {, , ¬}, we drop the subscript and refer to this problem simply as Hard. For N = 2n, a solution to -Hard on input 1N is a truth table of a function on n variables requiring 2 n-sized circuits, the same object used to build the Impagliazzo-Wigderson generator. Theorem 7. Let C be any sufficiently strong circuit class and > 0 be a constant such that -HardC is total for sufficiently large input lengths. Then EmptyC reduces to -HardC under C-reductions. Proof. By Lemma 3 we know that EmptyC reduces to EMPTY2Cn under C-reductions. Now, let C be an instance of EMPTY2Cn, and let k = 2 log |C| 1 . Consider the following map C : {0, 1}n  {0, 1}2kn, defined informally as follows: given a string x  {0, 1}n, apply C once to get 2 n-bit strings, then apply C to both of those n-bit strings to get four, and continue k times until we have 2k n-bit strings, or equivalently a 2kn-bit string. This process is illustrated in Figure 1 below:
14

Figure 1: Extending a map C : {0, 1}n  {0, 1}2n to a map C : {0, 1}n  {0, 1}2kn . Dotted boxes indicate the number of bits along a wire.
To define this function more formally, first we define the following maps L, R : {0, 1}2n  {0, 1}n, where L takes a 2n-bit string and ouputs the first n bits, and R takes a 2n-bit string and outputs the last n bits. Given a nonempty sequence 1, . . . t  {L, R}, let C : {0, 1}n  {0, 1}n be the function t  C  . . .  1  C. Now, given a binary string, we can associate it with such a sequence by associating 0 with L and 1 with R, and so we will abuse notation and write Cx for a binary string x as shorthand for C where  is the sequence of L, R associated with the binary string x. We are now ready to formally define our function C. As C is a map {0, 1}n  {0, 1}2kn, we can think of the output as being clumped into 2k blocks, each containing n bits. Given this terminology, C behaves as follows: on input x, the ith block of the output of C will be C i (x), where i denotes the standard representation of i as a k-bit binary string.
From here, the proof proceeds in two steps. First, we show that, by setting m = n2k = poly(|C|), any solution to -HardC on input 1m will be a string that is not in the range of C. Second, we will show that given a string outside in the range of C, we can find a string outside the range of C using only a polynomial number of calls to a C-inverter.
To carry out the first of these steps, we will show that any string in the range of C, when interpreted as a truth table of length m = n2k on log n + k variables, can be computed by a
2
circuit of size O(|C|k). Since, by construction of k, we have that m  |C| , a solution to -Hard on input 1m will be a truth table of length m not computable by a circuit of size m  |C|2, and thus a circuit of size O(|C|k) = O(|C| log |C|) would be a contradiction for all input lengths greater than some absolute constant. We construct such a circuit for any string in the range of C as follows: let y be a 2kn-bit string such that for some x  {0, 1}n, C(x) = y. The circuit computing y will have x written as advice/constants, and will feed x through k copies of the circuit C in series. We will split the log n + k input variables into a block of k variables we call i, and a block of log n variables we call j. We then use i to determine whether to apply L or R to the output of one of the copies of C before feeding it into the next, to get some resulting string xi, and then we use j to index into the jth position of xi, to get yi,j. A diagram of this circuit is shown in Figure 2:
15

Figure 2: A succinct circuit whose truth table is y, for any y in the range of C. Dotted boxes indicate the number of bits along a wire. Note that although x is shown as an input in this diagram, for any given y we fix a preimage x as constants/advice, and so the only true inputs to this circuit are i, j.

To see that this circuit has size O(|C|k), note that the subcircuits computing either L or R depending on a bit of i can be computed easily with O(n) gates over the basis {, , ¬} (this is essentially a multiplexer), and also that the final subcircuit indexing into an n-bit string can be computed with O(n) {, , ¬} gates as well; since we assumed C is sufficiently strong, both of these subcircuits can therefore be computed with O(n) C-gates. Since |C|  n, and this circuit contains only k copies of C and the aforementioned subcircuits, plus the constants describing the string x of length n, this circuit has O(|C|k) size as claimed.
Thus, we now know that any solution to -HardC on input 1m will not be in the range of C, and by assumption -HardC is total for sufficiently large input lengths so such a solution exists. It remains only to show that we can use a string outside the range of C, together with an C-inverter, to find a string outside the range of C. We proceed exactly as in the proof of Lemma 3. Let y be any string outside the range of C. Refer to Figure 1 which gives a diagram of a circuit computing C; at a layer i  [k] of this circuit, we have 2i blocks of n bits feeding into 2i copies of C, and these copies of C then output 2i+1 blocks of n bits at the next layer. So working back from the output layer k, we can test if any consecutive 2n-bit block of y is outside of the range of C. If none of them are, then we find a preimage for all blocks, interpret this as the output of the previous layer, and continue our search from there. We follow this process all the way back to the input layer or until we find an empty pigeonhole of C. If we never find an empty pigeonhole of C, then this process will terminate at the input layer with a string x such that C(x) = y, which is impossible by assumption, so at some point we must indeed find a string outside the range of C. Checking whether a particular string is an empty pigeonhole, or finding a preimage if it's not, can be accomplished with one call to a C-inverter by definition. We perform this test at most 2k = poly(|C|) times (once for every copy of C in the diagram in Figure 1), so overall this process can be accomplished in polynomial time using a C-inverter.

We now examine the implications of this theorem for particular circuit classes of interest.

Theorem 8. For any 0 <

<

1 2

,

-HardPi is complete for APEPPPi under Pi+2 reductions.

Proof. Containment of -HardPi in APEPPPi follows directly from the proof of Theorem 1 with

minimal adjustments; we must add the assumption

<

1 2

to

account

for

the

unbounded

fan-in

of

16

oracle gates in our counting argument. So it remains only to show that -HardPi is hard for this class as well. Since the above reduction uses a polynomial number of calls to the C-inverter, it suffices to show that we can implement a Pi -circuit inverter using a Pi+2 oracle. Given this, we can complete the entire reduction in PPi+2 = Pi+2.
Let C be a Pi -circuit with m oracle gates, and y be a potential output. To test if y is a valid output, we nondeterministically guess an input x, in addition to an output value for every gate in C, and a set of witness strings z1 . . . zm, one for each of our oracle gates. We then check that each gate output is valid (we will use the guessed witnesses here), and that the value of the terminal gate outputs is y. The verification of the terminal gates and all classical //¬ gates can be done in polynomial time. Verifying that all Pi oracle gates have valid outputs given their inputs corresponds to verifying that a sequence of strings x1, . . . , xm satisfy a sequence of Pi and Pi predicates P1, . . . , Pm, where m is of polynomial length. For each i such that Pi is a Pi predicate, this predicate is of the form zPi(xi, z) where Pi is a Pi-1 predicate, and so we can use the zi we originally guessed and simplify these to Pi-1 predicates. For any i such that Pi is a Pi predicate we ignore zi. In this way, we can transform all Pi into Pi predicates. Verifying that a sequence of of strings satisfies a sequence of Pi predicates can then be checked with a single Pi predicate representing their conjunction. So overall the verification process can be carried by checking a single Pi predicate, and so determining the existence of a solution can be done in Pi+1. From a Pi+1 test to determine the existence of a preimage for y, we can compute a preimage when one exists in Pi+2 by a standard application of binary search.
In the absence of any oracle gates, we have the following:
Theorem 9. For any 0 < < 1, -Hard is complete for APEPP under PNP reductions.

4.1 Implications of Completeness

This result gives an exact algorithmic characterization of the possibility of proving 2(n) Pi -circuit lower bounds for EPi+1 :

Theorem 10. There exists a language in EPi+1 with Pi -circuit complexity 2(n) if and only if there is a Pi+2 algorithm for EmptyPi .

Proof. Say there is a language L in EPi+1 with Pi -circuit complexity 2(n). So there exists an > 0 such that for all but finitely many n, L cannot be computed on length n inputs with Pi -
circuits of size less then 2 n. So then we have a polynomial time algorithm for 2 -HardPi as follows: given 1n, output the truth table of L over log n -bit inputs. Since L  EPi+1, this can

be done in 2 log n 2O(log n) = poly(n) time with a Pi+1 oracle. This truth table will have length

n 2



2

log n

 n. We then pad this truth table with 0's at the end to be of length n. If there was a

circuit of size n /2 for this n-bit truth table on log n bits, then on the first log n bits of input

this computes the truth table for L on

log n

-bit inputs.

Since

n 2

 2 log n , this would imply a

circuit of size 2 log n to compute L on log n -bit inputs, contradicting the hardness assumption.

Thus, there exists a Pi+2 algorithm for 2 -HardPi for some > 0, and so by Theorem 9, there

also exists a Pi+2 algorithm for EmptyPi .

Alternatively, say there is a Pi+2 algorithm for Empty. So in particular there is a Pi+2

algorithm for -HardPi for any fixed

<

1 2

.

Consider the language L decided by the following

EPi+1 machine: given an n-bit input, we use our Pi+2 algorithm for -HardPi on input 12n to

generate a truth table, then look up the n-bit input in this truth table to determine whether

17

to accept or reject. By definition this language must have Pi -circuit complexity 2(n), and this machine will run in time poly(2n) = 2O(n) with a Pi+1 oracle.
In the most interesting case, we conclude that a 2(n) circuit lower bound for ENP holds if and only if there is a PNP algorithm for Empty. Together with the results in Section 3, this gives newfound insight into the difficulty of proving exponential circuit lower bounds for the class ENP: proving such a lower bound requires solving a universal explicit construction problem, and would immediately imply PNP constructions for a vast range of combinatorial objects which we currently have no means of constructing without a P2 oracle. Theorem 10 also allows us to derive the following interesting fact about the circuit complexity of ENP:

Corollary 2 (Worst-Case to Worst-Case Hardness Amplification in ENP). If there is a language

in

ENP

of

circuit

complexity

2(n),

then

there

is

a

language

in

ENP

requiring

circuits

of

size

2n 3n

.

Proof. By Theorem 10, if there is a language in ENP of circuit complexity 2(n), then there is

a PNP algorithm for Empty. By Theorem 1, this implies a PNP algorithm for Hard Truth

Table, and thus a PNP

construction of a truth table

of length N

with

hardness

3

N log

N

.

This

in

turn

implies

the

existence

of

a

language

in

ENP

of

circuit

complexity

2n 3n

.

Thus, we can unconditionally rule out the possibility that the hardest language in ENP has

circuit complexity (2 n) for some 0 < < 1: either all of ENP has circuits of size 2o(n) infinitely

often,

or

some

language

requires

circuits

of

size

2n 3n

almost

everywhere.

We can refine this slightly as follows. We will refer to the search problem "given a truth table

x, find a circuit computing x of minimum size" as FMCSP (the functional variant of MCSP).

Corollary 3. If there is a language in EFMCSP of circuit complexity 2(n), then there is a language

in

EFMCSP

requiring

circuits

of

size

2n 3n

.

Proof. Recall the two reductions in Lemma 3 and Theorem 7. In order to find an empty pigeonhole

of the input circuit C given a solution to -Hard, we only need to use the C-inverter on C itself.

In the case of a reduction from Hard Truth Table to -Hard, the circuit of interest C maps

circuits

of

size

at

most

N 3 log N

to

their

N -bit

truth

tables,

and

so

an

oracle

for

FMSCP

would

suffice

to invert C.

It should be noted that a related result was proven in [16], showing that this type of hardness

amplification is possible in E assuming MCSP P. However, their proof does not translate directly

to an unconditional result in the oracle setting. Due to their use of the Impagliazzo-Wigderson

generator, directly applying their proof in the oracle setting using the relativized generator of [18]

would instead show that if EMCSP requires 2(n)-sized nondeterministic circuits, then EMCSP

requires

2n 3n

-sized

standard

circuits,

which

is

a

weaker

statement

then

what

is

shown

above

(modulo

the search/decision distinction between FMCSP and MCSP).

5 Direct P Reductions to Hard Truth Table
Ideally we could extend the completeness result in Theorem 9 to work with polynomial time reductions, as opposed to PNP reductions. However, the NP oracle seems highly necessary for the proof techniques used above. Despite this obstacle, we show that there is a natural set of problems in APEPP which can be reduced to the problem of finding truth tables of hard functions via P reductions.

18

A simple way to phrase the following results is that any truth table with sufficiently large circuit complexity will necessarily satisfy a variety of other pseudorandom properties for which no explicit constructions are known, including: rigidity over F2, high space-bounded communication complexity, and high bit-probe complexity. To show this, we demonstrate that the failure of a string x to possess any of these properties implies a smaller than worst case circuit for x.
To give the tightest reductions possible, we will introduce one new parameterized version of the hard truth table construction problem:

Definition 18. (k, c)-Quite Hard is the following problem: given 1N , output an N -bit truth table

with

hardness

cN logk N

This problem is total for any fixed c > 0 provided k > 1, or for any c 

1 3

when k = 1.

We

recall also the definition of -Hard, where we must construct a truth table of hardness N .

5.1 Rigidity

We begin with the case of rigidity. We will define the following weaker version of the rigidity construction problem:

Definition 19. k-Rather Rigid is the following search problem: given 1N , construct an N × N

matrix

over

F2

which

is

(

N logk

N

,

N2 logk+1

N

)-rigid.

Theorem 11. For all k > 1 there exists a constant c such that k-Rather Rigid reduces in polynomial time to (k, c)-Quite Hard.

Proof.

To

prove

this,

it

suffices

to

show

that for

any

matrix M

which

is

not

(

N logk

N

,

N2 logk+1

N

)-rigid,

we

can

construct

a

boolean

circuit

with

O(

N2 logk N

)

gates

which

decides

the

value

of

M

(i,

j)

given

the

2n-bit input (i, j). This then implies that for some fixed constant c, any function f which requires

circuits

of

size

greater

than

c

N2 logk N

must

be

(

N logk

N

,

N2 logk+1 N

)-rigid.

Say

M

is

not

(

N logk

N

,

N2 logk+1

N

)-rigid.

So

there

exists

an

N

×

N logk N

matrix

L,

an

N logk N

×N

matrix R,

and

an N × N

matrix S

with

at most

N2 logk+1 N

nonzero entries, such

that LR  S = M .

We will construct a circuit allowing us to efficiently index M which uses these matrices L, R, S

as advice.

The

number

of

bits

needed

to

specify

these

matrices

is

4

N2 logk n

:

L and R are written

explicitly,

and

S

is

written

as

a

list

of

N2 logk+1 N

labels,

each

of

length

2 log N ,

specifying

which

entries

of S are non-zero. It remains to show that the additional circuitry we need to compute M (i, j)

given i, j, L, R, S does not increase things too much.

By definition, we have that:

M (i, j) = rowi(L), colj(R)  Si,j

where the dot product is taken over F2. Now consider the circuit diagram shown in Figure 3:

19

Figure 3: A small circuit for a non-rigid truth table

The subcircuits computing blockk(A) given k, A are defined as follows. Given pq input wires partitioned into p blocks of q wires, and an index k on log p bits, blockk(A) outputs the kth block
of wires of A. The subcircuit computing ij  X? given X, ij is defined as follows. Given pq input

wires partitioned into p blocks of q wires, and a q-bit input ij, output 1 if one of the p blocks

has a value equal to that of ij, and output 0 if none of them do. Finally, the subcircuit (X)

computes the parity of its input string, the subcircuit (X, Y ) computes the bit-wise AND of two

equal length strings, and the terminal gate computes the two-bit parity function.

Given the previous equation relating the (i, j)th index of M to the (i, j)th indices of L, R, S, it

is straightforward to see that this circuit performs the necessary calculation. The two blockk(A) gates on the left-hand side of the circuit allow us to index into the ith row of L and the jth column

of R, after which we apply the bit-wise  and  gates to take the dot product of these which equals

(LR)i,j. On the right-hand side of the circuit, the ij  X gate determines the value of Si,j. Finally,

the last two-bit parity gate computes (LR)i,j  Si,j = Mi,j as required.

It is clear that the (X) and (X, Y ) can be implemented with a number of gates linear in

their

input

size,

which

in

this

case

is

N logk

N

.

To implement blockk(A), say A consists of p blocks of q wires. So for each block i, we can attach

log p constants giving a unique binary label for that block, and then use O(log p) gates to compute

for each block whether k is equal to that block's label, for a total of O(q log p) gates. We then AND

each wire in a block with the result of that comparison, adding another qp AND gates, and then

for the jth wire of the output, OR together the results for the jth wires of every block, adding an

additional O(q) OR gates for each of the p outputs, so O(pq) overall. The total number of gates

required

is

thus

at

most

O(q log p + pq).

In

the

case

of

this

circuit,

p

=

O(N )

and

q

=

O(

N logk

N

),

so

this

is

at

most

O(

N2 logk N

).

To implement ij

 X?,

say A consists again of p blocks

of q

wires,

20

and so k is q bits long. To test if ij is equal to the value of one of the blocks, we simply compare

ij to each of the p blocks using O(q) gates, and then OR the results of all comparisons together,

requiring O(p) OR gates. So the total number of additional gates is at most O(pq). In the case of

this

circuit,

p=

N2 logk+1 N

and

q = 2 log N ,

so

this

is

O(

N2 logk N

)

So

overall,

we

have shown this

circuit

has

size

O(

N2 logk N

).

Thus,

for

some

fixed

constant

c,

any

function

N

×N



{0, 1}

requiring

circuits

of size

cN 2 logk N

must

be

(

N logk

N

,

N2 logk+1 N

)

rigid.

5.2 Space-Bounded Communication Complexity

The class PSPACECC was defined originally in [2] as a generalization of the class PHCC to an unbounded alternation of quantifiers. We will not give this original definition, but rather a simplification due to [29].

Definition 20. Let f : {0, 1}n × {0, 1}n  {0, 1}. We say f has a space-s protocol if there is a deterministic protocol deciding f of the following form. Alice receives x  {0, 1}n, and Bob receives y  {0, 1}n. There is an s-bit shared memory, and Alice and Bob alternate turns writing to this memory. On a player's turn, they can modify the contents of the s-bit shared memory as a function only of its previous contents and their private input x or y, or decide to halt and output some z  {0, 1} (this decision is also a function only of their input and the shared memory's previous state). This protocol is valid if f (xy) = z for all x, y.

By a result of Song [29], we have that if f  PSPACECC then f has a poly(log n) space protocol (Song uses a slightly different model where Alice and Bob have private s-bit tapes, but our model is at least as strong up to a doubling in space since sharing the tape only increases their ability to communicate). Due to a basic counting argument, most functions f require (n) space, and any such function must lie outside of PSPACECC. However, it has been a long standing open problem to give an explicit construction a communication matrix outside of even PHCC [29]. We thus define the following search problem:

Definition 21. -SPACE is the following search problem. Given 1N , where N = 2n, output a communication matrix {0, 1}n × {0, 1}n  {0, 1} such that f requires space-n communication
protocols.

Theorem 12. For any  <

<

1 2

,

-Space

reduces

to

(

1 2

+

)-Hard.

Proof. The proof follows the exact same strategy as above, constructing a smaller-than-worst-case
circuit for any matrix with a n-space protocol. We will omit the detailed construction of our circuit since it very similar to the above proof, but the basic idea as follows. Let f : {0, 1}n × {0, 1}n  {0, 1}, and let N = 2n. We can represent a space s protocol for f as 2s + 4 different N × 2s
binary matrices, with each of the first 2s matrices telling us how one of the two players will modify
a certain cell of the shared memory as a function of its previous state and their input, and the
last four matrices determining whether a certain player will halt or continue and the value they
will output if they halt, again as a function of their input and the shared memory contents. For
s = log N (with < 1), we can then take these matrices as advice to our circuit, for a total of N 1+ log N bits of advice. We can then add circuitry to simulate 2s+1 = 2N steps of this protocol on a given input x, y  {0, 1}n×{0, 1}n, indexing into the advice matrices in order to determine what
to do next using the same indexing constructions we had for the proof of Theorem 11. Any matrix solvable by a space s protocol will be solved by a protocol that halts after 2s+1 steps (otherwise it will loop forever), so simulating for 2s+1 steps suffices. Since each of the indexing operations can be

21

implemented using a number of gates linear in N 1+ log N using the constructions from the proof

of Theorem 11, our overall circuit for f will have size O(2N N 1+ log N ) = O(N 1+2 log N ). Thus,

for any

<

1 2

,

a

truth

table

of

length

N2

requiring

circuits

of

size

N 1+2

will require  log N -space

protocols for any  < .

5.3 Bit Probe Lower Bounds

In [8], Elias and Flower defined a broad model for studying the space/query complexity of data structure problems, known as the "bit-probe model."

Definition 22. Given two sets D, Q, a function f : D × Q  {0, 1} and an integer b, the bit-probe complexity of f for space b, denoted BCb(f ), is the minimum over all encodings G : D  {0, 1}b of the number of bits of G(x) that need to be probed in order to determine f (x, y) for the worst case
x  D, y  Q, given access to y.

In this general definition of a data structure problem, we think of D as the set of all possible pieces of "data" we might wish to encode in our data structure, b as the number of bits we can use to encode a piece of data, Q as the set of queries we wish to answer about an encoded piece of data, and f as telling us the correct answers to all data/query pairs. BCb(f ) then tells us the minimum number of probes required by any space-b data structure in order to answer every query correctly for every possible piece of data.
This model was investigated further by Miltersen [20], who showed, using a simple counting argument, that most problems require an infeasible amount of space/probes in this model, but pointed out that no explicit data structure problem is known to be infeasible in this sense. We thus define the following explicit construction problem:

Definition 23. -Probe is the following search problem: given 1N where N = 2n output a truth table f : {0, 1}n × {0, 1}n  {0, 1} such that BC2n(f ) > n.

Theorem 13.

For any  < 2

<

1,

-Probe

reduces

to

(

1 2

+

)-Hard.

Proof. Say f is a function f : D × Q  {0, 1} such that BCb(f )  k. So in particular there is an encoding G : D  {0, 1}b such for any x  D, y  Q, given access to y we can determine f (x, y) using at most k probes to G(x). Let H : Q  [b]k be the function which, given y, tells us which positions of G(x) to query. Finally, let  : {0, 1}k × Q  {0, 1} be the function which
determines f (x, y) given the results of the probes and the value of y. We will now give a compact
representation for f , and then use it to construct a circuit computing f .
Let R be a |D| × b binary matrix whose rows are indexed by elements of D, where Ri,j gives the value of the jth bit of G(i). Let S be a |Q| × k log b matrix whose rows are indexed by elements of Q, such that the ith row of S is H(i)  [b]k. Finally, let Z be a 2k × |Q| matrix such that
Zi,j = (i, j). Now, given x  D, y  Q, we can use S, R, Z to determine f (x, y) as follows. First find the yth
row of S to get H(y), which is a list of k indices in [b]. Next, find the xth row of R, which is the
b-bit string G(x). Then, probe the indices specified by H(y) to get some k-bit string w, and finally
output Zw,y, which is precisely (w, y) = f (x, y). As in the previous proofs, it can easily be shown that these indexing operations can be accom-
plished with circuits of size linear in S, R, Z. Therefore, f has a circuit of size O(|S| + |R| + |Z|) = O(|Q|k log b + |D|b + 2k|Q|). So for any function D × Q  {0, 1}n requiring circuits of size (|Q|k log b + |D|b + 2k|Q|), we must have BCb(f ) > k.

22

In particular, if we take D = Q = {0, 1}n, and for any fixed < 1 we take b = 2 n, k = n, we

get that for any function f : {0, 1}2n  {0, 1} requiring circuits of size (2(1+ )n), it must be the

case that BC2 n(f ) > n, since |Q|k log b + |D|b + 2k|Q| = 2n 2n2 + 2n2 n + 2 n2n = O(2(1+ )n). So

if we take  < , any truth table of length N 2 with hardness N 1+ , or in other words any solution

to

(

1 2

+

2 )-Hard

on

input

1N2 ,

must

satisfy

BC2n (f )

>

n.

5.4 Some Concluding Thoughts

As noted in Section 3, Theorem 12 and Theorem 13 immediately imply that the problems -Space

and -Probe lie in APEPP, since we

can construct truth tables with hardness

N 3 log N

in

APEPP

by Theorem 1. Although we phrase these results as reductions, they can also be interpreted as

giving conditional polynomial time constructions of various objects, under different circuit lower

bound assumptions for the class E. In particular, Theorems 12 and 13 establish that if E contains

a

language

of

circuit

complexity

2(

1 2

+

)n

for

some

> 0, then polynomial time constructions of

hard problems in the bit-probe and space-bounded communication models follow. Theorem 11

establishes

that

if

E

contains

a

language

of

circuit

complexity

c2n nk

for

some

fixed

universal

constant

c,

then

polynomial

time

constructions

of

(

n logk

n

,

n2 logk+1

n

)-rigid

matrices

over

F2

follow.

It would be interesting as well to find some natural explicit construction problem for which a

reduction exists in the opposite direction, i.e. this problem is at least has hard as Hard Truth Table or perhaps -Hard. Aside from KUn2-Random for which such a reduction is immediate, we do not know of any other examples. However, we observe the following dichotomy: any explicit

construction problem either has a non-trivial algorithm, or is at least as difficult as constructing a

somewhat hard truth table. More precisely:

Lemma 4. Let f : N  N be non-increasing, and let  be any property (language) recognizable in complexity class C. Let -Construction be the search problem: given 1n, output an n-bit string with property . If -Construction is total for sufficiently large n, then for sufficiently large n one of the following holds:
1. There is a TIME(2O~ (f(n))) algorithm using a C-oracle that solves -Construction on length n inputs.

2. There is a polynomial time reduction from the problem of constructing an n-bit truth table
with circuit complexity f (n) to -Construction on length n inputs.
Proof. The proof is a straightforward application of the "easy witness" paradigm [15]. Let n be the set of n-bit strings with property  and let Hfn be the set of n-bit strings with circuit complexity at most f (n). If n Hfn =  then any solution to the explicit construction problem for  is necessarily a string with circuit complexity exceeding f (n), and hence a polynomial time reduction from truth table construction to -Construction trivially follows. On the other hand, if n  Hfn = , we can search over Hfn for a solution to -Construction and will be guaranteed to find a solution. Since |Hfn| = 2O~(f(n)), we can then solve -Construction by iterating over Hfn and using a C-oracle to test if each potential solution indeed holds property , in TIME(2O~ (f(n))).

In particular, we conclude that for any total property  recognizable in NP (so for example any explicit construction problem in APEPP), either -Construction has a 2no(1)-time algorithm using an NP oracle, or -Hard reduces in polynomial time to -Construction for some fixed
> 0 (more precisely, this dichotomy holds separately for each input length, and so at least one of
the two cases holds for infinitely many input lengths)

23

6 Open Problems
The most significant question left open in this work is whether -Hard is complete for APEPP under polynomial time reductions. One way to demonstrate evidence against this possibility would be to show hardness of Empty, perhaps under cryptographic assumptions, since it is widely conjectured that -Hard does have a polynomial time algorithm for some > 0 (this is often cited as the primary reason for believing P = BPP [12]). It should be noted that the complexity of the dual version of Empty, known as WeakPigeon, is equivalent to the worst-case complexity of breaking collision-resistant hash functions (in WeakPigeon we are given a circuit C : {0, 1}n  {0, 1}m with m < n, and asked to find a collision [14]). A hardness result for Empty would be interesting in another respect as well: just as the Natural Proofs barrier [24] shows that a generic method of proving circuit lower bounds via a "Natural Property" would require solving a hard computational problem, hardness of Empty would show that we should not expect to prove exponential lower bounds for E via an efficient algorithm that finds an empty pigeonhole for an arbitrary function; something about the specific function mapping circuits to their truth tables would have to be utilized.
7 Acknowledgements
The author would like to thank Christos Papadimitriou for his guidance and for many inspiring discussions throughout the completion of this work, and Mihalis Yannakakis for his comments on a draft of this manuscript.
References
[1] J. Alman and L. Chen, Efficient construction of rigid matrices using an np oracle, in 2019 IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS), 2019, pp. 1034­1055.
[2] L. Babai, P. Frankl, and J. Simon, Complexity classes in communication complexity theory, in 27th Annual Symposium on Foundations of Computer Science (sfcs 1986), 1986, pp. 337­347.
[3] B. Barak, A. Rao, R. Shaltiel, and A. Wigderson, 2-source dispersers for sub-polynomial entropy and ramsey graphs beating the frankl-wilson construction, in Proceedings of the Thirty-Eighth Annual ACM Symposium on Theory of Computing, STOC '06, New York, NY, USA, 2006, Association for Computing Machinery, p. 671­680.
[4] A. Bhangale, P. Harsha, O. Paradise, and A. Tal, Rigid matrices from rectangular pcps, 2020. [5] E. Chattopadhyay, Guest column: A recipe for constructing two-source extractors, SIGACT News, 51 (2020),
p. 38­57. [6] B. Chor and O. Goldreich, Unbiased bits from sources of weak randomness and probabilistic communication
complexity, in 26th Annual Symposium on Foundations of Computer Science (sfcs 1985), 1985, pp. 429­442. [7] Z. Dvir, A. Golovnev, and O. Weinstein, Static data structure lower bounds imply rigidity, in Proceedings
of the 51st Annual ACM SIGACT Symposium on Theory of Computing, STOC 2019, New York, NY, USA, 2019, Association for Computing Machinery, p. 967­978. [8] P. Elias and R. A. Flower, The complexity of some simple retrieval problems, J. ACM, 22 (1975), p. 367­379. [9] P. Erdo¨s, Some remarks on the theory of graphs, Bulletin of the American Mathematical Society, 53 (1947), pp. 292­294. [10] J. Friedman, A note on matrix rigidity, Combinatorica, 13 (1993), pp. 235­239. [11] E. Gat and S. Goldwasser, Probabilistic search algorithms with unique answers and their cryptographic applications, Electronic Colloquium on Computational Complexity (ECCC), 18 (2011), p. 136. [12] R. Impagliazzo and A. Wigderson, P = BPP if E requires exponential circuits: Derandomizing the XOR lemma, in Proceedings of the Twenty-Ninth Annual ACM Symposium on Theory of Computing, STOC '97, New York, NY, USA, 1997, Association for Computing Machinery, p. 220­229.
24

[13] E. Jera´bek, Dual weak pigeonhole principle, boolean complexity, and derandomization, Annals of Pure and Applied Logic, 129 (2004), pp. 1­37.

[14]

, Integer factoring and modular square roots, Journal of Computer and System Sciences, 82 (2016), pp. 380­

394.

[15] V. Kabanets, Easiness assumptions and hardness tests: Trading time for zero error, Journal of Computer and System Sciences, 63 (2001), pp. 236­252.

[16] V. Kabanets and J.-Y. Cai, Circuit minimization problem, in Proceedings of the Thirty-Second Annual ACM Symposium on Theory of Computing, STOC '00, New York, NY, USA, 2000, Association for Computing Machinery, p. 73­79.

[17] R. Kleinberg, O. Korten, D. Mitropolsky, and C. Papadimitriou, Total Functions in the Polynomial Hierarchy, in 12th Innovations in Theoretical Computer Science Conference (ITCS 2021), J. R. Lee, ed., vol. 185 of Leibniz International Proceedings in Informatics (LIPIcs), Dagstuhl, Germany, 2021, Schloss Dagstuhl­LeibnizZentrum fu¨r Informatik, pp. 44:1­44:18.

[18] A. R. Klivans and D. van Melkebeek, Graph nonisomorphism has subexponential size proofs unless the polynomial-time hierarchy collapses, SIAM Journal on Computing, 31 (2002), pp. 1501­1526.

[19] X. Li, Improved non-malleable extractors, non-malleable codes and independent source extractors, in Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2017, New York, NY, USA, 2017, Association for Computing Machinery, p. 1144­1156.

[20] P. B. Miltersen, The bit probe complexity measure revisited, in STACS 93, P. Enjalbert, A. Finkel, and K. W. Wagner, eds., Berlin, Heidelberg, 1993, Springer Berlin Heidelberg, pp. 662­671.

[21] N. Nisan and A. Wigderson, Hardness vs randomness, Journal of Computer and System Sciences, 49 (1994), pp. 149­167.

[22] I. C. Oliveira and R. Santhanam, Pseudodeterministic constructions in subexponential time, in Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2017, New York, NY, USA, 2017, Association for Computing Machinery, p. 665­677.

[23] C. H. Papadimitriou, On the complexity of the parity argument and other inefficient proofs of existence, Journal of Computer and System Sciences, 48 (1994), pp. 498 ­ 532.

[24] A. A. Razborov and S. Rudich, Natural proofs, Journal of Computer and System Sciences, 55 (1997), pp. 24­ 35.

[25] R. Santhanam, The complexity of explicit constructions, Theory of Computing Systems, 51 (2012), pp. 297­ 312. Copyright - Springer Science+Business Media, LLC 2012; Document feature - ; Equations; Last updated 2020-11-18; CODEN - TCSYFI.

[26] J. Schalkwijk, An algorithm for source coding, IEEE Transactions on Information Theory, 18 (1972), pp. 395­ 399.

[27] C. E. Shannon, The synthesis of two-terminal switching circuits, The Bell System Technical Journal, 28 (1949), pp. 59­98.

[28] M. A. Shokrollahi, D. Spielman, and V. Stemann, A remark on matrix rigidity, Information Processing Letters, 64 (1997), pp. 283­285.

[29] H. Song, Space-bounded Communication Complexity, PhD thesis, Tsinghua University, 2014.

[30] S. P. Vadhan, Pseudorandomness, vol. 7, Now Delft, 2012.

[31] L. G. Valiant, Graph-theoretic arguments in low-level complexity, in Mathematical Foundations of Computer Science 1977, J. Gruska, ed., Berlin, Heidelberg, 1977, Springer Berlin Heidelberg, pp. 162­176.

[32] A. C. Yao, Theory and application of trapdoor functions, in 23rd Annual Symposium on Foundations of Computer Science (sfcs 1982), 1982, pp. 80­91.

8 Appendix

Here we give a proof of Lemma 1, restated below:

Lemma. For sufficiently small

>

0,

we

have

H

(

1 2

-

)  1-

2, where H

denotes the binary

entropy function.

25

Proof. By the definition of H we have:

1

1

1

1

1

H( - ) = ( - ) log

2

2

1 2

-

+ ( + ) log 2

1 2

+

=

(1)

1

2

1

2

( - ) log

+ ( + ) log

=

(2)

2

1-2

2

1+2

1

1

( - )(1 - log(1 - 2 )) + ( + )(1 - log(1 + 2 )) =

(3)

2

2

1 log(1 - 2 )

1 log(1 + 2 )

-

- + log(1 - 2 ) + -

+ - log(1 + 2 ) =

(4)

2

2

2

2

log(1 - 2 ) + log(1 + 2 )

1-

- (log(1 + 2 ) - log(1 - 2 ))

(5)

2

Now, using the fact that:

1  -1k+1xk

log(1 + x) =

ln 2

k

k=1

for x  (-1, 1), we have that, for

<

1 2

:

1  -1k+1(2 )k

log(1 + 2 ) =

ln 2

k

k=1

and

1  -1k+1(-2 )k

1  -12k+1(2 )k

1  -(2 )k

log(1 - 2 ) =

=

=

ln 2

k

ln 2

k

ln 2

k

k=1

k=1

k=1

Thus, combining these we get the following two equalities:

1  -(2 )2k

log(1 + 2 ) + log(1 - 2 ) =

(6)

ln 2

k

k=1

1  2(2 )2k-1

log(1 + 2 ) - log(1 - 2 ) =

(7)

ln 2 2k - 1

k=1

Thus overall for

<

1 2

we

have:

1

1  (2 )2k

 2(2 )2k-1

H( - ) = 1 +

-

(8)

2

2 ln 2

k ln 2 2k - 1

k=1

k=1

So for sufficiently small:

1 H( -

32 42 )1+ -

1-

2

(9)

2

ln 2 ln 2

26

