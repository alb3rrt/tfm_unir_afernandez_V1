GENERALIZED GEOGRAPHICALLY WEIGHTED REGRESSION MODEL WITHIN A MODULARIZED
BAYESIAN FRAMEWORK

arXiv:2106.00996v1 [stat.ME] 2 Jun 2021

Yang Liu MRC Biostatistics Unit University of Cambridge
Cambridge, UK yang.liu@mrc-bsu.cam.ac.uk

Robert J.B. Goudie MRC Biostatistics Unit University of Cambridge
Cambridge, UK robert.goudie@mrc-bsu.cam.ac.uk

June 3, 2021

ABSTRACT

Geographically weighted regression (GWR) models handle geographical dependence through a spatially varying coefficient model and have been widely used in applied science, but its Bayesian extension is unclear because it involves a weighted log-likelihood which does not imply a probability distribution on data. We present a Bayesian GWR model and show that its essence is dealing with partial misspecification of the model. Current modularized Bayesian inference methods accommodate partial misspecification from single component of the model. We extend these methods to handle partial misspecification in more than one component of the model, as required for our Bayesian GWR model. Information from the various spatial locations is manipulated via a geographically weighted kernel and the optimal manipulation is chosen according to a Kullback­Leibler (KL) divergence. We justify the model via an information risk minimization approach and show the consistency of the proposed estimator in terms of a geographically weighted KL divergence.
Keywords Geographically weighted regression · Modularized Bayesian · Cutting feedback · Model misspecification · Power likelihood

1 Introduction
Conventional regression models have been widely used in various studies to infer the association between variables. While basic regression models often assume an independent sampling scheme, dependence must be taken into consideration when dataset or sampling scheme has a complicated structure. Since more commonality is believed to be shared between near areas for various factors (e.g., culture, economy, meteorology and population), one important type of dependence is geographical dependence which is normally considered in geographic information science (GIS), econometrics and public health. One assumption is that this geographical dependence is induced by the data itself and in this case spatial random fields models can
Correspondence: Yang Liu, MRC Biostatistics Unit, University of Cambridge, Robinson Way, CB2 0SR

A PREPRINT - JUNE 3, 2021

be applied to describe the geographical dependence between data sampled from different locations (e.g., Zhu et al., 2005; Lin, 2010; Afroughi et al., 2011; Fuglstad et al., 2015; Utazi et al., 2019; Marques et al., 2020). The other assumption is that this geographical dependence is induced by the true data generating process; this is called spatial non-stationarity. In other words, there are different data generating processes in different locations, meaning the data are generated independently but not identically.

Geographically weighted regression (GWR) models (e.g., Fotheringham et al., 1996; Brunsdon et al., 1996) and its extensions (e.g., Nakaya et al., 2005; Chen et al., 2012; Leong and Yue, 2017; Mu et al., 2018; Liu et al., 2018; Wu et al., 2020; Li and Fotheringham, 2020) have been proposed based on the second assumption. Rather than assuming a constant association between variables with constant coefficients, GWR models assume the underlying association may vary geographically. Suppose we have observations (Xi, Yi) at sampling location i with coordinates (ui, vi), i = 0, ..., n. We assume that the unknown true data generating process of the outcome Yi, given the covariate vector Xi, is pi(Yi|Xi) at a particular location i. GWR models usually assume that pi is a generalized linear model (GLM) E(Yi|Xi) = g-1(Xi(ui, vi)), with link function g, and where the coefficient (u, v) is a smooth function with respect to (u, v). For simplicity, we define i = (ui, vi) for location i.

In addition to the coefficient i, for some generalized geographically weighted regression models, such as negative binomial or beta regression (da Silva and Rodrigues, 2014; da Silva and de Oliveira Lima, 2017), for each location i there is an additional parameter i that determines the variability (scale) of the distribution. The additional parameter i is usually regarded as a nuisance parameter. This variability could be attributed to sampling or measurement errors, which may be different at different locations. We assume that i is similar, but not the same, across spatial locations but the variability is not spatially smooth. For instance, consider a variability induced by a difference in measurement equipment: each location may have arbitrarily bought different measurement equipment and therefore the variabilities of observations at different locations are not constant but not spatially smooth. We denote the likelihood of the GLM as p(Yi|i, i) at location i. For example, in the case of a negative binomial likelihood, with a log link function, the likelihood is:

p(Yi|i, i)

=

(Yi +i -1 ) (i -1 )(Yi +1)

1

i -1

1+i exp(Xii)

. i exp(Xii) Yi
1+i exp(Xii)

(1)

We assume that a single location i = 0 is of primary interest, and our primary aim is to estimate 0 and 0 at this location. When we have insufficient samples at the location of interest i = 0 to accurately estimate these parameters at this location using only data from this location, we would like to use the first law of geography to justify additionally using data that are sampled from neighbouring locations. The first law of geography states that `everything is related to everything else, but near things are more related than distant things' (Tobler, 1970). "Borrowing" samples from neighbouring locations to support the estimation of 0 should decrease the variance of estimates, although bias might be introduced.

For now, assume we have m observations Yi,1:m = (Yi,1, Yi,2, ..., Yi,m) at each location i. The complete set of observations is Y0:n,1:m = (Y0,1:m, Y1,1:m, . . . , Yn,1:m) with corresponding parameters 0:n = (0, ..., n). We assume that Yi,1, ..., Yi,m are independent identical observations of the random variable yi at location i, i = 0, ..., n. In addition, we assume Y0,1:m, . . . , Yn,1:m are independent but not necessarily identically-distributed. Let di be the geographic distance between location of interest 0 and location i. The generalized GWR likelihood is written as a locally weighted likelihood:

n

p(Y0:n,1:m|0:n, 0) = p(Y0,1:m|0, 0) p(Yi,1:m|i, 0)W (di,),

(2)

i=1

where W (di, ) is a geographically weighted kernel, with bandwidth , determined by the distance. Following the first law of geography, geographically weighted kernels gradually decrease to 0 as the distance di increases. One popular choice of weighted kernel is a Gaussian kernel (Brunsdon et al., 1996)

W (di, ) = exp

-

d2i 2

,

(3)

where  is a geographical bandwidth which regulates the kernel size.

2

A PREPRINT - JUNE 3, 2021

Bayesian inference for GWR models is not immediately clear. On the one hand, (2) is not in general a proper probability density if the power terms are not 1. Hence, Bayes' theorem does not apply. In the special case of a Gaussian likelihood, W (di, ) can be viewed as a scale parameter of i and thus we obtain a proper probability, as noted in previous studies (Subedi et al., 2018; Ma et al., 2020). A Bayesian extension for a broader distribution family is unclear. On the other hand, (2) without power terms treats data sampled from neighbouring locations i, i = 0, as if they share the same relationship with covariate Xi as data sampled from the location of interest i = 0. This inevitably leads to the problem of misspecification since i = 0 due to the spatial non-stationarity. The degree of misspecification depends on the total variation of i.
In this article, we extend the generalized GWR model to the Bayesian framework and justify its usage. The formulation is inspired by ideas from partial misspecification of Bayesian models and the modularized Bayesian analysis (Liu et al., 2009). We show that the essence of Bayesian GWR model is dealing with misspecification due to incorporating extra observations from neighbouring locations. The model involves a geographically powered posterior, with the power term being a deterministic functional form of the geographical distance. The contribution from each location to the inference of the parameter of interest is manipulated through a geographical bandwidth in the power term and we discuss the optimal selection of this bandwidth so that the negative impact from misspecification and positive impact from extra observations are well balanced. We show some theoretical properties of the model and outline the algorithm.

2 Robust Bayesian Inference and Modularization

Several attractive properties of Bayesian inference rely on the correct specification of the model. However, it is generally impossible to ensure the correct specification of a complete Bayesian model. Here, we adopt the M-closed view that a model is correctly specified if the true data generating process p(Y ) is exactly equal to a parametric distribution p0 (Y |0), given parameters 0  , which is subsequently referred as the likelihood (Bissiri et al., 2016). Misspecification might exist in all aspects of the model, or in only a few components (or modules in the terminology of Liu et al. (2009)) of the model.
In the case of all aspects of the model being misspecified, modification of the conventional Bayesian model is required to improve the robustness of the model. One approach is to raise the likelihood to a power term and regard its logarithm as a loss function (Friel and Pettitt, 2008; Bissiri et al., 2016; Holmes and Walker, 2017), to obtain a weighted likelihood similar to the generalized GWR in (2):

ppow,(|Y )  p(Y |)().

(4)

This is called the power posterior or fractional posterior, with power . While weighted likelihoods have a long history in frequentist statistics (e.g., Cai et al., 2000; Markatou, 2000; Hu and Zidek, 2002; Biswas et al., 2015), it is only recently that justification of their usage in Bayesian statistics has been studied. One interpretation of the power term is that it adjusts the sample size with a multiplier  (Miller and Dunson, 2019). Another interpretation is that it is equivalent to a data-dependent prior (Martin et al., 2017). Miller and Dunson (2019) further argue that (4) approximates p(|DKL(p(·|), p(·)) < R) under mild conditions, where the Kullback-Leibler (KL) divergence DKL(p(·|), p(·)) = p(y) log(p(y)/p(y|))dy and R is determined by the number of samples and the power . The contraction of the power posterior is shown by Bhattacharya et al. (2019). These papers suggest that, in the case of a M-open view, where the true data generating process does not belong to the parametric distributions termed as likelihood, inference can proceed by looking for parameters whose likelihood approximates the true data generating process. In addition, an appropriate choice of  can accommodate this departure of misspecified p(Y |) from the truth p(Y ) and the model is robust (Miller and Dunson, 2019). Importantly, the power  controls the relative credence given to the observed data and the prior; consequently it is not deemed as a parameter. Therefore, a prior is not assigned for  and it is not updated via Bayes theorem.
In the case of partial misspecification, misspecification of even a single module can cause incorrect estimation of other modules, even if these modules are correctly specified (Plummer, 2015; Liu and Goudie, 2020). Consider the two module model illustrated in Figure 1, with likelihood terms p(Y |, ) and p(Z|),

3





A PREPRINT - JUNE 3, 2021

Y

Z

Figure 1: DAG representation of a two module model. The modules are separated by a dashed line.

and prior terms () and (). The posterior distribution, with parameters of interest  = (, ), is

p(Y |, )() p(Y |)p(Z|)()

p(|Y, Z) = p(|Y, )p(|Y, Z) =

.

p(Y |)

p(Y, Z)

Suppose that the specification of the likelihood for Y is suspected to be incorrect. If we wish to prevent Y affecting estimation of , then we can use the cut distribution (Lunn et al., 2009), defined for this model as

p(Y |, )() p(Z|)()

pcut(|Y, Z) := p(|Y, )p(|Z) = p(Y |)

, p(Z )

Note that under the cut distribution  depends on only the data Z; the data Y makes no contribution to the estimation of . This is called "cutting the feedback" (Lunn et al., 2009). This model has been used for Bayesian propensity scores (e.g., McCandless et al., 2010; Kaplan and Chen, 2012; Zigler and Dominici, 2014) where feedback from the outcome module to the propensity score module should be removed (Rubin, 2008; Zigler et al., 2013). It has also been used in various other fields (e.g., Blangiardo et al., 2011; Arendt et al., 2012; Frank et al., 2019).
The cut distribution and the standard posterior are two extremes: all information from the suspect module is either removed or retained. However, completely cutting or retaining the feedback from the suspect module might either lose usable information or introduce excessive bias. To control the feedback from the potentially misspecified module, a combination of the power posterior and cut model was recently proposed by Carmona and Nicholls (2020). Their Semi-Modular Inference (SMI) model introduces an auxiliary variable ~, which has the same distribution as , to regulate the contributions to the estimation of . Given a prior (, ~), the SMI distribution of the augmented parameter (, ~, ) is

p(, ~, |Y, Z) = ppow,(~, |Y, Z)p(|Y, ),

where

ppow,(~, |Y, Z)  p(Z|)p(Y |, ~)(, ~)

is a power posterior of ~ and , with power . The SMI distribution of the parameters of interest  = (, ) is
p(|Y, Z) = p(, ~, |Y, Z)d~.

The power  controls how much information from the suspect module which involves observation Y is used to estimate .

3 Modularized Bayesian Inference for Multiple Modules
3.1 Standard Bayesian posterior and cut distribution
To establish notation, first consider the simple case when the spatial coefficient function (ui, vi) = (u0, v0) = 0; that is  is constant across the whole geographical space and so we can directly include all data from all locations into the model. Denote the likelihood p(Yi,1:m|i, 0) at location i, with i =

4

A PREPRINT - JUNE 3, 2021

0, 1, ..., n. The DAG of this model is shown in Figure 2. The joint distribution with an independent prior

(0:n, 0) = (0)

n i=0

(i)

is

n
p(Y0:n,1:m, 0:n, 0) = (0:n, 0) p(Yi,1:m|i, 0).
i=0

0

Y0,1:m

Y1,1:m

Y2,1:m

Yn,1:m

......

0

1

2

n

Figure 2: DAG representation when (ui, vi) = 0.

The following lemma gives the form of the standard Bayesian posterior. Lemma 1. The standard Bayesian posterior is:

n

p(0:n, 0|Y0:n,1:m) = p(0, 0|Y0:n,1:m) p(i|Yi,1:m, 0).

(5)

i=1

Proof. See appendix.

Note that, estimation of (0, 0) is influenced by all observations Y0,1:m, . . . , Yn,1:m as is standard in Bayesian inference: the contribution from any location is equal in the sense that no manipulation of feedback is conducted.
In contrast, consider the case when (ui, vi) is not constant. If we nevertheless include data from location (ui, vi), i = 0 to estimate the parameter (0, 0) and regard yi  p(·|i, 0) as module i, i = 0, 1, ..., n, then the likelihood ni=0p(Yi,1:m|i, 0) is clearly misspecified since 0 = (ui, vi). A straightforward way to handle this misspecification is to remove the influence of these modules on the estimation of 0 by using the cut distribution. The cut distribution for this model is:

n

pcut(0:n, 0|Y0:n,1:m) := p(0, 0|Y0,1:m) p(i|Yi,1:m, 0).

(6)

i=1

Here, estimation of 0 depends on only Y0,1:m. Contributions from Y1:n,1:m at other locations are all removed.

3.2 Manipulating the multiple feedback and the Bayesian GWR posterior
Suppose now that (u, v) is not constant but is a smooth function with respect to (u, v) so that closer locations have more similar . Therefore, it is inappropriate to treat the misspecification as equally problematic at every location and may lead to a loss of usable information from the dataset. Instead we propose to manipulate contributions to the estimation of 0 from observations Yi,1:m neighbouring the location of interest i = 0 by varying amounts. We achieve this by allocating a geographically weighted kernel W (di, ) to the likelihood of Yi,1:m where di is the distance between location 0 and location i.

5

W(d)
1

A PREPRINT - JUNE 3, 2021 Geographical weighted kernel

0
0
Y0,1:m

d

W1(d1) W2(d2)

Y1,1:m

Y2,1:m

Multiple flexible cut: Wn(dn)
Yn,1:m

......

0

1

2

n

Figure 3: DAG representation when the feedback is manipulated. Modules Yi,1:m|(0, i) are separated by a dashed line.

Figure 3 shows a DAG of this model. It can be viewed as a case of manipulating the feedback between

multiple modules. Extending Carmona and Nicholls (2020), we introduce an auxiliary variable ~1:n =

(~1, ..., ~n), which has the same likelihood term as 1:n. We set an independent prior (0, ~1:n, 0) =

n i=1

(~i)(0)(0).

Then

we

write

n

p(0:n, ~1:n, 0|Y0:n,1:m) = ppow,(0, ~1:n, 0|Y0:n,1:m) p(i|Yi,1:m, 0),

(7)

i=1

where

n

ppow,(0, ~1:n, 0|Y0:n,1:m)  p(Y0,1:m|0, 0)(0, ~1:n, 0) p(Yi,1:m|~i, 0)W (di,)

(8)

i=1

is called the geographically-powered posterior and is used to adjust contributions from observations Yi,1:m by allocating the corresponding weighted kernel W (di, ) to the likelihood p(Yi,1:m|0, ~i). Note that (8) is an extension of the usual power posterior and it contains (2) (i.e. the GWR locally weighted likelihood).
Given the geographical bandwidth , the SMI distribution for this multiple module case is

p(0:n, 0|Y0:n,1:m) = p(0:n, ~1:n, 0|Y0:n,1:m)d~1:n.

The Bayesian GWR posterior for the parameters of interest 0 and 0 at the location of interest i = 0 is

p(0, 0|Y0:n,1:m) = p(0:n, 0|Y0:n,1:m)d1:n.

(9)

The estimation of parameter of interest (0, 0) via (9) is named as Bayesian GWR model. Bayesian GWR model manipulates the feedback from each of the multiple neighbouring observations through the geographical bandwidth , and reduces to the cut distribution and the standard posterior distribution for

6

A PREPRINT - JUNE 3, 2021

certain values for . When the variation of (u, v) is so large that we are not confident to include neighbouring locations, then   0 and the estimation of 0 and 0 only depends on observations Y0,1:m.

n

pcut(0:n,

0|Y0:n,1:m)

:=

lim
0

p (0:n ,

0|Y0:n,1:m)

=

p(0,

0|Y0,1:m)

p(i|Yi,1:m, 0).

i=1

This is the cut distribution (6). In contrast, when the variation of (u, v) is so small that we can include observations from all locations, then    and estimation of 0 and 0 depends on all observations Y0:n,1:m as in the standard posterior distribution (5):

n

p(0:n,

0|Y0:n,1:m)

=

lim


p (0:n ,

0|Y0:n,1:m)

=

p(0,

0|Y0:n,1:m)

p(i|Yi,1:m, 0).

i=1

In summary, we propose the Bayesian GWR model for multiple suspect modules for the situation that the geographical weighted kernel (3) has a known and deterministic functional form respect to the geographical coordinates. Since the joint `likelihood' involved in (8) is the geographically weighted likelihood widely used in the GWR framework, the essence of the Bayesian GWR model is a particular extension of SMI model.

3.3 Theoretical analysis

Bayes' theorem can not be used to justify the proposed geographically-powered posterior because the power likelihood is not a proper probability distribution. Instead we justify the geographically-powered posterior as a minimizing rule within an information processing framework, thus avoiding the need to appeal to Bayes' theorem. We also study its property subject to a large sample size.
We write the true data generating process for the complete set of observations Y0:n,1:m as

n

nm

p1:m(Y0:n,1:m) = pi,1:m(Yi,1:m) =

pi(Yi,j ),

i=0

i=0 j=1

where pi is the true generating process at location i. Denoting  = (0, ~1:n, 0)   and Wi = W (di, ) and omitting  in ppow, for simplicity, the geographically-powered likelihood ppow(Y0:n,1:m|) for observations Y0:n,1:m is written as (2) where i is replaced with ~i for i = 0. Let  be the probability measure of prior distribution. If ppow(Y0:n,1:m) := ppow(Y0:n,1:m|)d() < , we can re-write the probability measure of geographically-powered posterior (8) on any    in terms of the true data
generating processes as

Ppow(|Y0:n,1:m) =

 exp {-r0,1:m() -  exp {-r0,1:m() -

n i=1

Wi

ri,1:m()}

(d)

n i=1

Wi

ri,1:m()}

(d)

,

(10)

where

r0,1:m() = log

p0,1:m(Y0,1:m) p(Y0,1:m|0, 0)

; ri,1:m() = log

pi,1:m(Yi,1:m) p(Yi,1:m|~i, 0)

i = 0.

This representation makes it clear that (10) is an extension of the Gibbs posterior (Jiang and Tanner, 2008), which is also known as the generalized Bayesian posterior (Grünwald and van Ommen, 2017); pseudo posterior (Walker and Hjort, 2001; Alquier et al., 2016); and quasi-posterior (Chernozhukov and Hong, 2003)), which plays an essential role in the study of the PAC-Bayesian inference (e.g., Dalalyan and Tsybakov, 2008; Lever et al., 2013). The Gibbs posterior generalizes the usual Bayesian posterior by defining a prior for the parameter of a loss function, which need not be the negative log-likelihood as used in standard Bayesian inference.

Our model extends the existing Gibbs posterior literature by allowing multiple learning rates (also interpreted as temperatures in thermodynamics (Geman and Geman, 1984)) which correspond to geographically

7

A PREPRINT - JUNE 3, 2021

weighted kernels. The loss function (or the statistical risk function) at each location is Wiri,1:m(), where W0 = 1. We denote the empirical total loss function L1:m(), given the parameter of the model , as:

1

n

L1:m() = m r0,1:m() + Wiri,1:m() .

i=1

Let F be a probability measure on the parameter space  which results from processing the information

from observations Y0:n,1:m and prior knowledge . We aim to show that the geographically-powered

posterior Ppow is the optimal F in the sense that Ppow minimizes an information bound. We first need

to construct this information bound. Bhattacharya et al. (2019) provides a PAC-Bayesian type bound for

the power posterior. The bound controls a Rényi divergence which characterizes the performance of the

power posterior. We now denote the Rényi divergence between two arbitrary distribution p and q, given an

  (0, 1), as:

1 D(p(·), q(·)) =  - 1 log

p(y)q(y)1-dy .

We have the following theorem that extends the Theorem 3.4 of Bhattacharya et al. (2019) by allowing multiple learning rates.

Theorem 1 (Weighted Rényi divergence Bound). Given a distribution f () with probability measure F (·) over parameter space , for any   (0, 1), the following inequality

n
(1 - Wi)DWi p(·|~i, 0), pi(·) F (d)

i=1

1 
m

n
r0,1:m() + Wiri,1:m()

F (d) + DKL(f (·), (·)) + 1 log

m

m

1 

i=1

holds with P1:m probability at least (1 - ). Proof. See appendix.
Remark 1. Theorem 1 leads to the following "information posterior bound" (Tong Zhang, 2006) (proof is given in the supplementary materials). The bound

E - log

E

exp (-L1:m())

F

Y0:n,1:m P1:m



E L1:m()
F

+

DKL(f (·),(·)) m

+

1 m

log

1 

holds with P1:m probability at least (1 - ).

Given a distribution F which results from an information processing rule, the Remark states that the negative logarithm of the expected exponential of the negative loss is controlled by the empirical loss from the usage of F and an additional penalty on the discrepancy between F and the prior . Tong Zhang (2006) proposed an approach called "Information Risk Minimization" which selects F by minimizing the right hand side of the information posterior bound. Note that, although the bound involves , the inequality holds for any   (0, 1). Hence, the selection of F is not affected by . Similarly, the true data generating process drops out since it does not involve F . To apply this approach, it is equivalent to find a F which minimizes the following criterion function

n
Mm(f ()) = DKL(f (·), (·))- f () log (p(Y0,1:m|0, 0)) d- Wi
i=1

f () log p(Yi,1:m|~i, 0) d.

Note that, the "Information Risk Minimization" used here can be regarded as a modified "Information Conservation Principle" (Zellner, 1988), which states that an optimal information processing rule has equal input information Iin, which consists the information processing (i.e., prior knowledge, observations and

8

A PREPRINT - JUNE 3, 2021

model), and output information Iout. In our setting, for the probability measure F , the input information Iin is:

Iin := =

log(())F (d) + log(())F (d) +

log (ppow(Y0:n,1:m|)) F (d)
n
log (p(Y0,1:m|0, 0)) F (d) + Wi
i=1

log p(Yi,1:m|~i, 0) F (d).

Note that in contrast to the original input information discussed in Zellner (1988), the input information from each geographical location is manipulated by the geographically weighted kernel. The output information Iout is:
Iout := log(f ())F (d) + log(ppow(Y0:n,1:m))F (d).

Now we present the following theorem which justifies the use of the geographically-powered posterior (10) as the form of probability distribution that statistically learns information from the observations and the prior knowledge while minimising the loss.
Theorem 2 (Justification). If ppow(Y0:n,1:m) := p(Y0:n,1:m|)()d < , the geographicallypowered posterior ppow(|Y0:n,1:m) minimizes the criterion function Mm(f ()) with respect to a probability distribution f (). In addition, the geographically-powered posterior results from the optimal information processing rule.
Proof. See appendix.

We now consider the large sample size setting. Let y0:n = {y0, y1, ..., yn} be random variables corre-

sponding to a single observation at each location and y0:n  P =

n i=1

Pi

.

Although

the

GWR

model

is less necessary in the large sample size setting (since effective statistical inference can be conducted

separately at each location), we wish to show that the posterior predictive distribution y^i  P (·|~i, 0),

where (~i, 0)  Ppow, approaches the truth yi  Pi(·) at each location i = 0, 1, ..., n when the degree of

the partial misspecification varies across the geographical space. Denote the expected total loss function

L(), given the parameter of the model , as:

L() = E
y0:n P

log

p0(y0) p(y0|0, 0)

n
+ Wi log
i=1

pi(yi) p(yi|~i, 0)

.

We present the following theorem.

Theorem 3 (Consistency). Given a finite number of observations, the geographically-powered posterior

Ppow minimizes

E (L1:m()) + m-1DKL(ppow(·|Y0:n,1:m), (·)).
Ppow

When the sample size m   at all locations and suppose that the limit of the geographically-powered posterior Pp(ow) := limm Ppow exists, then Pp(ow) puts all its mass at  = (0, ~1:n, 0) which minimizes the expected total loss function (a geographically weighted combination of Kullback-Leibler divergences):

 = arg min L()

 =(0 ,~1:n ,0 )

n

= arg min DKL (p0(·), p(·|0, 0)) + WiDKL pi(·), p(·|~i, 0) .

 =(0 ,~1:n ,0 )

i=1

Proof. See appendix.

Although partial misspecification remains and predictions drawn from the model will not follow the true data generating process, Theorem 3 states that the geographically-powered posterior draws predictions that balance minimizing the empirical total loss function and the discrepancy between posterior and prior knowledge. When the sample size increases, the model acts similarly to a standard Bayesian model by

9

A PREPRINT - JUNE 3, 2021

learning more from observations. In the limit of an infinite sample size, the model provides a prediction that is closest to the true data generating process. Note that, although the model draws predictions close to the truth, more priority is assigned to locations close to the location of interest. Hence, we cannot use a single Bayesian GWR model when inference is needed for multiple locations. Instead, separate models should be applied at each location of interest.

4 Inference for Multiple Locations and Bandwidth Selection

4.1 Method

In Section 3, we considered the setting when there is a single location of interest. We now consider inference for multiple sampling locations when each is of interest. This is done by running multiple Bayesian GWR models separately for locations while assuming the same geographical bandwidth for all models. We give the following definition which generalizes the Bayesian GWR model by relaxing the location of interest.

Definition 1. Consider observations Yi,1:m sampled from locations i with coordinate (ui, vi), i = 0, ..., n;

a bandwidth  and a specific geographical coordinate (u, v) that we call the geographical centre. Define

the Bayesian GWR model M = ((u, v), ) with parameter M = (M,0:n, M ) to be the SMI model with

distribution

pM (M |Y0:n,1:m) = pM (M , ~M,0:n|Y0:n,1:m)d~M,0:n,

(11)

where ~M,1:n is the auxiliary variable for model M and

pM (M , ~M,0:n|Y0:n,1:m)  (~M,0:n, M )

n i=0

p(Yi,1:m

|~M,i

,

M

)W

(di

,)

n i=0

p(M,i|Yi,1:m,

M

),

(12)

where di is the geographical distance between location (ui, vi) and the geographical centre (u, v). In the special case when the geographical centre is one of the sampling locations, which we assume without loss of generality to be (u0, v0), then (11) and (12) reduce to (7) and (8).

To measure the predictive performance of a model M for, for example, a new observation Yi from location i with true generating process pi(Yi), we use the Kullback-Leibler (KL) divergence. This is achieved by looking at the expected log pointwise predictive density (Gelman et al., 2014; Jacob et al., 2017),
which is essentially a constant term minus the KL divergence, defined as

elpd(ui,vi)(M ) := pi(Yi) log (pM (Yi|Y0:n,1:m)) dYi, where the predictive distribution pM (Yi|Y0:n,1:m) is defined as
pM (Yi|Y0:n,1:m) := p(Yi|M,i, M )pM (M |Y0:n,1:m)dM

= p(Yi|M,i, M )pM (M,i, M |Y0:n,1:m)dM,idM .

Here, we denote pM (M,i, M |Y0:n,1:m) := pM (M |Y0:n,1:m)dM,-i, where we define M,-i = (M,0, ..., M,i-1, M,i+1, ..., M,n).
The following assumption can be viewed as a rephrasing of the first law of geography (Tobler, 1970), since for an arbitrary location of interest i, observations from closer locations contribute more to the estimation of the shared parameter  when the geographical centre is exactly equal to the location of interest. Assumption 1. For any fixed geographical bandwidth  and specific location with geographical coordinates (uk, vk), elpd(uk,vk)(M ) is maximized when the geographical centre (u, v) = (uk, vk). That is:
((uk, vk), ) = arg max elpd(uk,vk)(M ), .
M

Now, we define the space of Bayesian GWR models M = {M = ((u, v), ) :  > 0}. The following assumption assumes inferences from multiple models are independent.

10

A PREPRINT - JUNE 3, 2021

Assumption 2. Given a dataset Y0:n,1:m and Bayesian GWR models Ms  M, s = 1, ..., S, we have the joint Bayesian GWR posterior
S
p(M1 , ..., MS |Y0:n,1:m) = pMs (Ms |Y0:n,1:m).
s=1

We are now ready to extend inference to multiple locations. Given a set of Bayesian GWR models
M = (M0, ..., Mn), one for each geographic sampling location, all with identical geographical bandwidth , we define the expected log pointwise predictive density for new observations Y0:n = (Y0, ..., Yn) with each single observation Yi from location i as

elpd(M ) =

n
log (p(Y0:n|Y0:n,1:m)) pi(Yi)dY0:n,
i=0

where

p(Y0:n|Y0:n,1:m) = p(Y0:n|M0 , ..., Mn )p(M0 , ..., Mn |Y0:n,1:m)dM0 ...dMn .

We then present the following theorem to select the optimal bandwidth.
Theorem 4 (Bandwidth selection). Given Assumption 1 and 2, for observations Y0:n,1:m sampled from locations i with coordinates (ui, vi), i = 0, ..., n, the optimal combination of n + 1 separate Bayesian GWR models M = (M0, ..., Mn) that maximizes elpd(M ), where each Mi = ((ui , vi), ) is used for prediction in location i, satisfies

1. For all 0  i  n,

(ui , vi) = (ui, vi).

2. Redefine Mi() = ((ui, vi), ), then the optimal bandwidth  maximizes the mean (across all sampling locations) expected log pointwise predictive density.



=

arg max


n

1 +

1

n i=0

elpd(ui,vi)(Mi()).

(13)

Proof. See appendix.

In practice, we do not know the true data generating process pi. Numerous methods (e.g., Gelman et al.,
2014) can be applied to approximate (13). The simplest way to estimate each term elpd(ui,vi)(Mi) is to use the log pointwise predictive density defined as

1m

lppd(ui,vi)(Mi) = m

log

j=0

p(Yi,j |Mi )pMi (Mi |Y0:n,1:m)dMi .

(14)

This can be easily approximated by the Monte Carlo samples drawn from the Bayesian GWR posterior.
However, lppd measures within-sample predictive accuracy so will generally overestimate elpd (Gelman
et al., 2014). We therefore adopt cross-validation to estimate elpd(ui,vi)(Mi). We train the model Mi on all observations from other locations Yj,1:m, j = i and a subset Yi,1:m of the observations from location i, and estimate elpd using the testing set Yi,m +1:m using (14). Note that, cross-validation can be computationally expensive since it requires multiple partitions of the set of observations Yi,1:m.

4.2 Algorithm
We summarize the algorithm for the Bayesian GWR model when there are n locations. For a set of candidate geographical bandwidths {r}Rr=1, we select the optimal geographical bandwidth  using Algorithm 1. Samples at each iteration can be drawn by using any standard sampler (e.g., MetropolisHastings or Gibbs sampler). The algorithm requires an iterative approximation of the elpd at each location.

11

A PREPRINT - JUNE 3, 2021

This can be done in parallel to expedite computation. Once the optimal geographical bandwidth  has been selected, we refit model with this bandwidth to the whole dataset, as described in Algorithm 2. We provide the code for both algorithms in Python Version 3 (https://github.com/MathBilibili/ Bayesian-geographically-weighted-regression).

Algorithm 1 Selection of Geographical Bandwidth 
Require: A candidate set of geographical bandwidths {r}Rr=1, observations Y1:n,1:m and its corresponding coordinates {(ui, vi)}ni=1, likelihood p(Y |, ), prior (), (~) and (), number of iterations S, number Q of k-fold cross validation folds.

1: for r  {1, ..., R} do

2: for q  {1, ..., Q} do

3:

Select the testing set Yi,(m +1:m), a random 100/k% subset of observations at location i, and

training set Y (i) = Y1:n,1:m \ Yi,(m +1:m) for location i, i = 1, . . . , n.

4:

Call Algorithm 2 with Bayesian GWR models Mi(r) = ((ui, vi), r) and location-specific

dataset Y (i), i = 1, . . . , n.

5:

Approximate the elpd(ui,vi)(Mi(r)) on testing set using samples {((is), i(s))}Ss=1, i =

1, . . . , n.

6: end for

7:

Calculate

qth

mean

elpd:

elpdq (r )

=

1 n

8: end for

9: return {{elpdq(r)}Qq=1}Rr=1.

n i=1

elpd(ui,vi)(Mi(r

)).

Algorithm 2 Bayesian GWR Model for multiple locations
Require: a geographical bandwidth , observations Y1:n,1:m and its corresponding coordinates {(ui, vi)}ni=1, likelihood p(Y |, ), prior (), (~) and (), number of iterations S.
1: Set Bayesian GWR models Mi() = ((ui, vi), ) and location-specific dataset Y (i) = Y1:n,1:m, i = 1, . . . , n.
2: for i  {1, ..., n} do 3: Calculate kernels W (di, ) using (3). 4: Draw Samples {i(s), ~-(si), (is)} from ppow,(i, ~-i, i|Y (i)), s = 1, . . . , S, according to (8),
using any standard sampler. 5: end for 6: return Bayesian GWR posterior samples {{((is), i(s))}Ss=1}ni=1.

5 Simulation
To illustrate our methodology and the influence of the geographical bandwidth, we simulated data on a 10 × 10 regular lattice (u, v), with u = 1, ..., 10 and v = 1, ..., 10, with geographically varying coefficients  = (0, 1(u, v), 2(u)) defined as:
0 = 3 1(u, v) = 0.1 + 0.01 u2 + v2
2(u) = 0.05(sin(/2 + (u/20)) + cos(/2 + (u/20)) + 4).
We generated the true (u, v)  N (0.5, 0.012) independently: the resulting (u, v) is relatively constant across spatial locations, and its variability is not spatially smooth. With these coefficients, we simulated 200 independent samples at each location from a negative binomial distribution, with covariates drawn from a uniform distribution.
12

A PREPRINT - JUNE 3, 2021
We then fitted our Bayesian GWR model to each location separately and independently, for a geographical bandwidth , so that Assumption 2 can be satisfied. To estimate the elpd by cross validation, we excluded half of samples at the location of interest from the training set. We drew 7 × 103 iterations for each of 10 independent chains at each location, discarding the first 3 × 103 samples as burn-in.
0.0001 1
Figure 4: ELPD against geographical bandwidth. Each boxplot represents the elpd estimates from 10 chains across whole space. The red line is the average elpd estimates across the 10 chains. The blue dashed line indicates the optimal bandwidth.
To identify the optimal geographical bandwidth , we repeated this process for each of the 12 candidate values  = 0.0001, 0.5, 0.7, 1, 2, 3, 4, 5, 6, 7, 10 and 20. Figure 4 shows the estimated mean expected log pointwise predictive density (mean elpd across space), according to Eq.29, for each candidate value. It can be seen that the mean elpd achieves its highest value when bandwidth is 1, so we will compare results with  = 1,  = 0.0001 (the smallest candidate, equivalent to using samples only from the geographic centre) and  = 20 (the largest candidate, assuming the least geographic variation).
We then ran the model on the complete dataset without excluding any observations. For each location, we ran 10 chains independently for 7 × 103 iterations, discarding the first 3 × 103 samples as burn-in (trace plot in supplementary materials). The true values and estimated means for coefficients (0, 1, 2), when  = 0.0001, 1, and 20, are shown in Figure 5. When  = 0.0001, estimation at each location relies almost exclusively on data from that location, so estimated coefficients varies considerably across spatial locations: the connection between locations is almost completely "cut". Furthermore, some estimates are extreme, due to the small number of samples used by the model because neighbouring samples are not included. In contrast, when  = 20, we can see the estimated coefficients are almost constant across geographic locations, due to the large bandwidth that assumes samples from neighbouring locations are very similar to samples from the location of interest. Finally, the estimates using the optimal bandwidth  = 1 are close to the true values across all geographic locations.
Figure 6 shows boxplots of the squared error between the Bayesian GWR estimated means and the true values of the three coefficients across all geographic locations. The true 0 is constant, therefore a large bandwidth that incorporates more samples will have lower mean squared error. Hence, the models with  = 1 and 20 provide a good estimation of 0, with  = 20 clearly performing better. In contrast, the model with  = 0.0001 fails to estimate the true value of 0 as sample size at each location is not sufficient to support the estimation. For 1 and 2 which do vary geographically, the model with  = 20 as expected performs poorly because the model assumes little geographic variation. The model with  = 0.0001 also
13

A PREPRINT - JUNE 3, 2021

9 7 5 3 1
13579

9 7 5 3 1
13579

9 7 5 3 1
13579

9 7 5 3 1
13579

9 7 5 3 1
13579

9 7 5 3 1
13579

9 7 5 3 1
13579

9 7 5 3 1
13579

9 7 5 3 1
13579

9

9

9

7

7

7

5

5

5

3

3

3

1 13579

1 13579

1 13579

2.4 2.6 2.8 3.0 3.2 3.4

0.12 0.14 0.16 0.18 0.20 0.22 0.24

0.16 0.18 0.20 0.22 0.24

Figure 5: Heatmap of the true values and estimated means for the coefficients 0, 1 and 2 by the Bayesian GWR model, with geographic bandwidth  = 0.0001, 1 and 20.

performs poorly due to the insufficient sample size at each individual location. Overall, the model with the optimal bandwidth  = 1 performs the best in mean squared error.
We further explore this by looking at the estimation of individual location ^(u, v) to the true value (u, v). An ideal model should give estimation which achieves ^ = . However, estimation will inevitably affected by error. Notice that, although we have run a Bayesian GWR model independently at each of the
14

A PREPRINT - JUNE 3, 2021

20

1

Bandwidth

0.0001 0
20

0.1

0.2

0.3

0.4

1

0.0001 0
20

0.001

0.002

0.003

0.004

1

0.0001

0

0.001

0.002

0.003

0.004

0.005

Squred Error
Figure 6: Boxplots of the squared error of the estimated mean coefficients 0, 1 and 2 under the
Bayesian GWR model across geographic locations, with geographic bandwidth  = 0.0001, 1, and 20.

The orange line and green triangle indicate the median and mean squared error.

100 locations, they share the same geographical bandwidth . Therefore, it is reasonable to assume that the degree of error introduced due to the model should be similar for all locations. Here, we assume the following equation:
^(u, v) = F ((u, v)) + (u, v),
where F is a unknown deterministic function and (u, v) i.i.d follows an arbitrary distribution with mean 0 and variance 2. The term (u, v) describes the random error that naturally arises from samples due to the randomness of observations and can be reduced by increasing the sample size. The squared error is (F ((u, v)) + (u, v) - (u, v))2. The function F describes the systematic error that is due to the misspecification (i.e., the use of samples from neighbouring locations). When a coefficient varies geographically, this systematic error can not be removed if we include neighbouring samples. If there is no systematic error (i.e., we do not borrow any sample from neighbouring locations or coefficient does not vary across the space), then F ((u, v)) = (u, v).
Figure 7 shows a scatter plot of the estimated mean coefficients at each of the geographic locations for each bandwidth choice, against their true values. The estimates when  = 0.0001 distribute evenly around the true values because this model emphasizes local characteristics, but with large variance due to the large random error due to the insufficient number of samples used by this model. In contrast, the estimates when  = 20 are relatively horizontal because this model assumes coefficients are relatively constant across the geographical space, leading to a large deviation from the true values due to the systematic error caused by including too much information from neighbouring geographic locations. The model with the optimal bandwidth  = 1 has less systematic error than  = 20, and much smaller random error than  = 0.0001.
Given the clear linear trend for all bandwidth choices, we assume a linear form F ((u, v)) = a+b(u, v) for the systematic error, and summarise the results via the linear regression coefficients (Table 1). We first consider the systematic error. When  = 0.0001 and  = 1, the intercept is close to 0 and the slope is close to 1, indicating the systematic error is very small. In contrast when  = 20, the intercept differs from 0 and the slope is clearly not close to 1. This confirms the systematic error we discussed before. Specifically, the slope goes to 1 when  = 20. This again reveals the fact that larger geographical bandwidth ignores geographical variation. Now we consider the random error. It is clear that, for both 1 and 2, the model
15

A PREPRINT - JUNE 3, 2021

0.275 0.250 0.225 0.200 0.175 0.150 0.125 0.100
0.100

0.125

0.150

0.175

0.200

0.225

Bandwidth 0.0001 1 20

0.250

0.275

Estimation

0.35

0.30

0.25

0.20

0.15

Bandwidth 0.0001
1

20

0.10

0.10

0.15

0.20

0.25

0.30

0.35

True value

Figure 7: Scatter plot of the estimated mean coefficient for 1 and 2 under the Bayesian GWR model against the true value at each of the 100 geographic locations. Results are shown for geographic

bandwidths  = 0.0001 (blue),  = 1 (red) and  = 20 (yellow). The diagonal benchmark line ^ = 

indicates where the estimates should be centred around if there is no systematic error.

with  = 20 gives the smallest random error  and  increases as  decreases. This trend reveals the varying pattern of the dispersion thanks to the changing of the sample size. In summary, the model with  = 1 balances both systematic and random error.
6 Application to Real Data
It has been shown in epidemiological studies that there is a global variation in the seasonal activity of the influenza virus (e.g., Finkelman et al., 2007; Azziz Baumgartner et al., 2012; Lam et al., 2019). In particular, there are normally clear and consistent influenza epidemic peaks during the winter in the high-latitude regions (Cox and Subbarao, 2000), whereas seasonal transmission patterns are unclear in low-latitude (subtropical/tropical) regions (Viboud et al., 2006; Li et al., 2019). This suggests that transmission and viability of the influenza virus is linked with atmospheric conditions: the regular occurrence of influenza epidemic in temperate regions is largely attributed to the exposure of cold and dry environments (e.g., Lowen et al., 2007; Lowen and Steel, 2014; Deyle et al., 2016; Chong et al., 2020). However, this relationship is weaker in subtropical/tropical regions (Tamerius et al., 2013). In this section, we apply the Bayesian GWR model to a human influenza dataset to assess spatial variation in the association between the occurrence of influenza and two major climatic factors (temperature and precipitation).
16

A PREPRINT - JUNE 3, 2021

Table 1: Estimated intercept a^, slope ^b and standard deviation ^ under the linear model of the estimated mean coefficients for each choice of geographic bandwidth. means p-value is larger than 0.05.

Coefficient 1
2

Bandwidth 0.0001 1 20 0.0001 1 20

a^ 0.0024 0.0107 0.1774 0.0066 0.0078 0.1889

^b 0.9855 0.9417 0.0381 0.9682 0.9617 0.0421

^ 0.0172 0.0071 0.0002 0.03258 0.01225 0.00007

We used monthly, country-level human influenza surveillance data between January 2010 and December 2014 from the World Health Organization FluNet (http://www.who.int/influenza/gisrs_ laboratory/flunet/en/). We selected 20 countries of similar size and with relatively comprehensive influenza records. We selected 16 European countries to represent the temperate region (Austria; Belgium; Bosnia and Herzegovina; Croatia; Czech; France; Germany; Hungary; Italy; Luxembourg; Netherlands; Poland; Romania; Slovakia; Slovenia; UK) and 4 South-East Asian countries to represent the tropical region (Cambodia; Laos; Thailand; Vietnam). We used the geographical center coordinates (ui, vi), i = 1, ..., 20 of each country as the geographical coordinates. The dataset contains the number of positive cases Yi,t and total number of tests Ni,t in country i = 1, ..., 20 during month t. The temperature Xi1,t (degrees Celsius) and amount of precipitation Xi2,t (mm/month) during month t in country i were obtained from CRUCY (Harris et al., 2014).

UK

1.2 20 1.0 15 0.8 10 0.6 5 0.4 0 0.2 -5
0 -10 Jul-09

Aug-10 Sep-11 Oct-12 Nov-13

500 450 400 350 300 250 200 150 100 50 0 Dec-14

Period(month)

32 16
8 4 2 1 2010

Influenza positive rate Temperature

Precipitation

Period(month)

0.6 20 0.5 15
10 0.4 5
0.3 0

Thailand

400

32

350

16

300

250

8

200

0.2 -5 -10
0.1 -15 0 -20 Jul-09

Aug-10 Sep-11 Oct-12 Nov-13

150 100
50 0 Dec-14

4
2
1 2010

Influenza positive rate Temperature

Precipitation

2011 2011

2012

2013

Time(year)

2012

2013

Time(year)

2014 2014

Figure 8: Association between influenza, temperature and precipitation in the UK and Thailand. Left panel: Monthly influenza positivity rate, temperature (degrees Celsius) and precipitation (mm/month). Right panel: Wavelet power spectrum (absolute square of the wavelet transform) of the influenza activity. The black line surrounds the significant area (p-value < 0.01), where the power spectrum is significantly large than the power spectrum of random noise.

The countries we included show distinct patterns of influenza activities. Figure 8 shows, for the UK and Thailand, the monthly influenza positivity rate, temperature, precipitation and the corresponding wavelet analysis of the periodicity of influenza activity. In the UK, we can observe that the peak of influenza activity

17

A PREPRINT - JUNE 3, 2021
is consistent with the winter season in the UK and a clear negative correlation can be observed between influenza positivity rate and temperature. The relationship visually appears less strong for precipitation. In contrast, in Thailand influenza has a more variable peak time and the relationship with temperature and precipitation is not clear. We used wavelet analysis (using WaveletComp in R) to further quantify the distinct seasonality of influenza activities between two countries. This decomposes the influenza time series into numerous wavelets, each with a distinct frequency. The degree to which influenza follows a particular periodicity can be assessed by the magnitude of the corresponding wavelet. This reveals clear evidence of periodicity of between 10-15 months in all years in the UK, whereas there is no consistent periodicity in Thailand (Figure 8).

100 1000 2000 3000 4000 5000 6000 7000

10000

20000

Figure 9: ELPD against geographical bandwidth. Each boxplot represents the elpd estimates from 30 chains across 20 countries. The red line is the average elpd estimates across the 30 chains. The blue dashed line indicates the optimal bandwidth.

In our Bayesian GWR model, we assumed that the number of positive cases Yi,t follows a negative binomial distribution, as in (1), except that the total number of tests Ni,t was embedded into the link function and spherical distance was calculated using the haversine formula. The mean and variance of Yi,t are:
E(Yi,t|Xi1,t, Xi2,t) = exp(log(Ni,t) + 0(ui, vi) + 1(ui, vi)Xi1,t + 2(ui, vi)Xi2,t), Var(Yi,t|Xi1,t, Xi2,t) = E(Yi,t|Xi1,t, Xi2,t) + iE2(Yi,t|Xi1,t, Xi2,t).
We considered each of the 20 countries seperately, with each of the following geographical bandwidths  = 100, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 10000 and 20000 (kilometres). These choices of bandwidth cover a broad range of different assumptions regarding the impact of neighbouring countries. For each country, we randomly left-out 50% of the observations to use as a test set. We ran 30 independent MCMC chains, and after discarding the first 3 × 103 samples, we drew 104 samples from the Bayesian GWR posterior. Figure 9 shows the estimated elpd for each bandwidth across the whole space, suggesting that the optimal choice of the bandwidth from the candidate set is 3000. This bandwidth indicates that there is spatial variation of the underlying association across the countries we selected. Note that, the range of

18

A PREPRINT - JUNE 3, 2021

3000 kilometres has roughly spans either Europe or South-East Asia but not both, meaning that spatial non-stationarity was detected between these two regions but the spatial non-stationarity is not significant within the two regions.

a

95% CI Upper Bound

b

95% CI Upper Bound

Median 95% CI Lower Bound

µ

Median 95% CI Lower Bound

-0.162

-0.152 -0.141 -0.131 -0.120 -0.109 -0.099 0 600 1200 2400 Kilometers

-0.0580 -0.0445 -0.0311 -0.0175 -0.0041 0.0093 0.0228

-0.0077 -0.0066 -0.0056 -0.0046 -0.0035 -0.0025 -0.0014 -0.0004 -0.0001 0.0002 0.0005 0.0008 0.0012 0.0015

0 300 600

1200 Kilometers

0 600 1200 2400 Kilometers

0 300 600

1200Kilometers

Figure 10: Median (middle panel), lower (bottom panel) and upper (top panel) 95% credible intervals for  for European (left column) and East Asian (right column) countries. Panel (a) shows estimates for 1 for temperature (a); panel (b) shows estimates for 2 for precipitation. The color and map scales are listed at the bottom.

We applied the model in all 20 countries independently, using the whole dataset and with bandwidth  = 3000. We ran 20 independent MCMC chains for each country, and retained 104 samples after discarding the first 3 × 103 samples as burn-in. The pooled samples drawn from the Bayesian GWR posterior for  for temperature and precipitation were used to estimate the median, upper 95% bound of credible interval (CI) and lower 95% bound of credible interval (CI) for each country. Figure 10 shows the results, after applying kriging interpolation with ArcGIS Version 10.7. These estimates imply that in European countries a negative association exists between influenza and both temperature and precipitation. That is, influenza transmission tends to be more prevalent during the cold and dry season. In contrast, there is no significant association in the south-east Asian countries. These conclusions are consistent with previous findings (e.g., Tamerius et al., 2013).

7 Conclusions
We have introduced and extended the SMI model and the candidate distribution selection technique to the field of geographic information science (GIS). Currently, a Bayesian approach for GWR models is only available for the simple linear regression (e.g. Subedi et al. (2018)). We therefore elucidate the theoretical validity of applying a Bayesian approach to generalized GWR models and reveal the essential link between the Bayesian GWR model and the cutting feedback problem. The motivation of Bayesian GWR model is to decrease the random error at the expense of introducing systematic error. This is realized by incorporating

19

A PREPRINT - JUNE 3, 2021
observations from neighbouring locations. The geographically weighted kernel manipulates the information provided by extra observations. The optimal geographical bandwidth  balances the trade-off between two types of error.
While most GWR models have considered the spatially smooth parameters (coefficients), a more general case when some of the parameters are locally unique but not spatially smooth (i.e. linear regression, negative binomial regression and beta regression which involve the ) is not considered in the GWR literature. Hence, our model can be viewed as an extension of the conventional GWR models that is able to simultaneously deal with (1) spatially smooth and (2) locally unique but not spatially smooth parameters.
The SMI model is only established as a single cut model (i.e. two modules case). In this study, we extend it to a special case of multiple cuts when information from suspect modules are manipulated via a deterministic functional form controlled by a single kernel bandwidth.
Supplementary Materials
The supplementary appendix contains all technical proofs of results stated in the paper.
Acknowledgement
Yang Liu was supported by a Cambridge International Scholarship from the Cambridge Commonwealth, European and International Trust. Robert J.B. Goudie was funded by the UK Medical Research Council [programme code MC_UU_00002/2] and was supported by the NIHR Cambridge Biomedical Research Centre (BRC-1215-20014). The views expressed are those of the authors and not necessarily those of the NIHR or the Department of Health and Social Care.
References
Afroughi, S., Faghihzadeh, S., Khaledi, M. J., Motlagh, M. G., and Hajizadeh, E. (2011). Analysis of clustered spatially correlated binary data using autologistic model and Bayesian method with an application to dental caries of 3­5-year-old children. Journal of Applied Statistics, 38(12):2763­2774.
Alquier, P., Ridgway, J., and Chopin, N. (2016). On the properties of variational approximations of Gibbs posteriors. Journal of Machine Learning Research, 17(236):1­41.
Arendt, P. D., Apley, D. W., and Chen, W. (2012). Quantification of model uncertainty: Calibration, model discrepancy, and identifiability. Journal of Mechanical Design, 134(10). 100908.
Azziz Baumgartner, E., Dao, C. N., Nasreen, S., Bhuiyan, M. U., Mah-E-Muneer, S., Mamun, A. A., Sharker, M. A. Y., Zaman, R. U., Cheng, P.-Y., Klimov, A. I., Widdowson, M.-A., Uyeki, T. M., Luby, S. P., Mounts, A., and Bresee, J. (2012). Seasonality, timing, and climate drivers of influenza activity worldwide. The Journal of Infectious Diseases, 206(6):838­846.
Bhattacharya, A., Pati, D., and Yang, Y. (2019). Bayesian fractional posteriors. The Annals of Statistics, 47(1):39 ­ 66.
Bissiri, P. G., Holmes, C. C., and Walker, S. G. (2016). A general framework for updating belief distributions. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 78(5):1103­1130.
Biswas, A., Roy, T., Majumder, S., and Basu, A. (2015). A new weighted likelihood approach. Stat, 4(1):97­107.
Blangiardo, M., Hansell, A., and Richardson, S. (2011). A bayesian model of time activity data to investigate health effect of air pollution in time series studies. Atmospheric Environment, 45(2):379 ­ 386.
Brunsdon, C., Fotheringham, A. S., and Charlton, M. E. (1996). Geographically weighted regression: A method for exploring spatial nonstationarity. Geographical Analysis, 28(4):281­298.
Cai, Z., Fan, J., and Li, R. (2000). Efficient estimation and inferences for varying-coefficient models. Journal of the American Statistical Association, 95(451):888­902.
20

A PREPRINT - JUNE 3, 2021
Carmona, C. and Nicholls, G. (2020). Semi-modular inference: Enhanced learning in multi-modular models by tempering the influence of components. In Chiappa, S. and Calandra, R., editors, Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics, volume 108 of Proceedings of Machine Learning Research, pages 4226­4235. PMLR.
Chen, V. Y.-J., Deng, W.-S., Yang, T.-C., and Matthews, S. A. (2012). Geographically weighted quantile regression (GWQR): An application to U.S. mortality data. Geographical Analysis, 44(2):134­150.
Chernozhukov, V. and Hong, H. (2003). An mcmc approach to classical estimation. Journal of Econometrics, 115(2):293 ­ 346.
Chong, K. C., Lee, T. C., Bialasiewicz, S., Chen, J., Smith, D. W., Choy, W. S., Krajden, M., Jalal, H., Jennings, L., Alexander, B., et al. (2020). Association between meteorological variations and activities of influenza A and B across different climate zones: A multi-region modelling analysis across the globe. Journal of Infection, 80(1):84­98.
Cox, N. J. and Subbarao, K. (2000). Global epidemiology of influenza: Past and present. Annual Review of Medicine, 51(1):407­421. PMID: 10774473.
da Silva, A. R. and de Oliveira Lima, A. (2017). Geographically weighted beta regression. Spatial Statistics, 21:279 ­ 303.
da Silva, A. R. and Rodrigues, T. C. V. (2014). Geographically weighted negative binomial regression--incorporating overdispersion. Statistics and Computing, 24(5):769­783.
Dalalyan, A. and Tsybakov, A. B. (2008). Aggregation by exponential weighting, sharp pac-bayesian bounds and sparsity. Machine Learning, 72(1-2):39­61.
Deyle, E. R., Maher, M. C., Hernandez, R. D., Basu, S., and Sugihara, G. (2016). Global environmental drivers of influenza. Proceedings of the National Academy of Sciences, 113(46):13081­13086.
Finkelman, B. S., Viboud, C., Koelle, K., Ferrari, M. J., Bharti, N., and Grenfell, B. T. (2007). Global patterns in seasonal activity of influenza A/H3N2, A/H1N1, and B from 1997 to 2005: Viral coexistence and latitudinal gradients. PLOS ONE, 2(12):1­10.
Fotheringham, A. S., Charlton, M., and Brunsdon, C. (1996). The geography of parameter space: an investigation of spatial non-stationarity. International Journal of Geographical Information Systems, 10(5):605­627.
Frank, J. M., Massman, W. J., Ewers, B. E., and Williams, D. G. (2019). Bayesian analyses of 17 winters of water vapor fluxes show bark beetles reduce sublimation. Water Resources Research, 55(2):1598­1623.
Friel, N. and Pettitt, A. N. (2008). Marginal likelihood estimation via power posteriors. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 70(3):589­607.
Fuglstad, G.-A., Lindgren, F., Simpson, D., and Rue, H. (2015). Exploring a new class of non-stationary spatial Gaussian random fields with varying local anisotropy. Statistica Sinica, 25(1):115­133.
Gelman, A., Hwang, J., and Vehtari, A. (2014). Understanding predictive information criteria for Bayesian models. Statistics and Computing, 24(6):997­1016.
Geman, S. and Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-6(6):721­741.
Grünwald, P. and van Ommen, T. (2017). Inconsistency of Bayesian inference for misspecified linear models, and a proposal for repairing it. Bayesian Analysis, 12(4):1069 ­ 1103.
Harris, I., Jones, P., Osborn, T., and Lister, D. (2014). Updated high-resolution grids of monthly climatic observations ­ the cru ts3.10 dataset. International Journal of Climatology, 34(3):623­642.
Holmes, C. C. and Walker, S. G. (2017). Assigning a value to a power likelihood in a general Bayesian model. Biometrika, 104(2):497­503.
Hu, F. and Zidek, J. V. (2002). The weighted likelihood. Canadian Journal of Statistics, 30(3):347­371.
Jacob, P. E., Murray, L. M., Holmes, C. C., and Robert, C. P. (2017). Better together? statistical learning in models made of modules. arXiv preprint arXiv:1708.08719.
21

A PREPRINT - JUNE 3, 2021
Jiang, W. and Tanner, M. A. (2008). Gibbs posterior for variable selection in high-dimensional classification and data mining. The Annals of Statistics, 36(5):2207 ­ 2231.
Kaplan, D. and Chen, J. (2012). A two-step bayesian approach for propensity score analysis: Simulations and case study. Psychometrika, 77(3):581­609.
Lam, T. T., Tang, J. W., Lai, F. Y., Zaraket, H., Dbaibo, G., Bialasiewicz, S., Tozer, S., Heraud, J.-M., Drews, S. J., Hachette, T., et al. (2019). Comparative global epidemiology of influenza, respiratory syncytial and parainfluenza viruses, 2010­2015. Journal of Infection, 79(4):373­382.
Leong, Y.-Y. and Yue, J. C. (2017). A modification to geographically weighted regression. International Journal of Health Geographics, 16(1):11.
Lever, G., Laviolette, F., and Shawe-Taylor, J. (2013). Tighter pac-bayes bounds through distributiondependent priors. Theoretical Computer Science, 473:4 ­ 28. Special Issue on Algorithmic Learning Theory.
Li, Y., Reeves, R. M., Wang, X., Bassat, Q., Brooks, W. A., Cohen, C., Moore, D. P., Nunes, M., Rath, B., Campbell, H., et al. (2019). Global patterns in monthly activity of influenza virus, respiratory syncytial virus, parainfluenza virus, and metapneumovirus: a systematic analysis. The Lancet Global Health, 7(8):e1031­e1045.
Li, Z. and Fotheringham, A. S. (2020). Computational improvements to multi-scale geographically weighted regression. International Journal of Geographical Information Science, 34(7):1378­1397.
Lin, P.-S. (2010). Estimating equations for separable spatial-temporal binary data. Environmental and Ecological Statistics, 17(4):543­557.
Liu, F., Bayarri, M., Berger, J., et al. (2009). Modularization in Bayesian analysis, with emphasis on analysis of computer models. Bayesian Analysis, 4(1):119­150.
Liu, Y. and Goudie, R. J. (2020). Stochastic approximation cut algorithm for inference in modularized Bayesian models. arXiv preprint arXiv:2006.01584.
Liu, Y., Lam, K.-F., Wu, J. T., and Lam, T. T.-Y. (2018). Geographically weighted temporally correlated logistic regression model. Scientific Reports, 8(1):1­14.
Lowen, A. C., Mubareka, S., Steel, J., and Palese, P. (2007). Influenza virus transmission is dependent on relative humidity and temperature. PLOS Pathogens, 3(10):1­7.
Lowen, A. C. and Steel, J. (2014). Roles of humidity and temperature in shaping influenza seasonality. Journal of Virology, 88(14):7692­7695.
Lunn, D., Best, N., Spiegelhalter, D., Graham, G., and Neuenschwander, B. (2009). Combining mcmc with `sequential' pkpd modelling. Journal of Pharmacokinetics and Pharmacodynamics, 36(1):19--38.
Ma, Z., Xue, Y., and Hu, G. (2020). Geographically weighted regression analysis for spatial economics data: A Bayesian recourse. International Regional Science Review, 0(0):0160017620959823.
Markatou, M. (2000). Mixture models, robustness, and the weighted likelihood methodology. Biometrics, 56(2):483­486.
Marques, I., Klein, N., and Kneib, T. (2020). Non-stationary spatial regression for modelling monthly precipitation in germany. Spatial Statistics, 40:100386. Space-Time Modeling of Rare Events and Environmental Risks: METMA Conference.
Martin, R., Mess, R., and Walker, S. G. (2017). Empirical Bayes posterior concentration in sparse highdimensional linear models. Bernoulli, 23(3):1822 ­ 1847.
McCandless, L. C., Douglas, I. J., Evans, S. J., and Smeeth, L. (2010). Cutting feedback in Bayesian regression adjustment for the propensity score. The International Journal of Biostatistics, 6(2).
Miller, J. W. and Dunson, D. B. (2019). Robust Bayesian inference via coarsening. Journal of the American Statistical Association, 114(527):1113­1125. PMID: 31942084.
Mu, J., Wang, G., and Wang, L. (2018). Estimation and inference in spatially varying coefficient models. Environmetrics, 29(1):e2485. e2485 env.2485.
22

A PREPRINT - JUNE 3, 2021
Nakaya, T., Fotheringham, A. S., Brunsdon, C., and Charlton, M. (2005). Geographically weighted poisson regression for disease association mapping. Statistics in Medicine, 24(17):2695­2717.
Plummer, M. (2015). Cuts in Bayesian graphical models. Statistics and Computing, 25(1):37­43. Rubin, D. B. (2008). For objective causal inference, design trumps analysis. The Annals of Applied Statistics,
2(3):808 ­ 840. Subedi, N., Zhang, L., and Zhen, Z. (2018). Bayesian geographically weighted regression and its application
for local modeling of relationships between tree variables. iForest - Biogeosciences and Forestry, (5):542­ 552. Tamerius, J. D., Shaman, J., Alonso, W. J., Bloom-Feshbach, K., Uejio, C. K., Comrie, A., and Viboud, C. (2013). Environmental predictors of seasonal influenza epidemics across temperate and tropical climates. PLOS Pathogens, 9(3):1­12. Tobler, W. R. (1970). A computer movie simulating urban growth in the detroit region. Economic Geography, 46(sup1):234­240. Tong Zhang (2006). Information-theoretic upper and lower bounds for statistical estimation. IEEE Transactions on Information Theory, 52(4):1307­1321. Utazi, C., Thorley, J., Alegana, V., Ferrari, M., Nilsen, K., Takahashi, S., Metcalf, C., Lessler, J., and Tatem, A. (2019). A spatial regression model for the disaggregation of areal unit based data to high-resolution grids with application to vaccination coverage mapping. Statistical Methods in Medical Research, 28(1011):3226­3241. PMID: 30229698. Viboud, C., Alonso, W. J., and Simonsen, L. (2006). Influenza in tropical regions. PLOS Medicine, 3(4):null. Walker, S. and Hjort, N. L. (2001). On Bayesian consistency. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 63(4):811­821. Wu, S., Wang, Z., Du, Z., Huang, B., Zhang, F., and Liu, R. (2020). Geographically and temporally neural network weighted regression for modeling spatiotemporal non-stationary relationships. International Journal of Geographical Information Science, 0(0):1­27. Zellner, A. (1988). Optimal information processing and Bayes's theorem. The American Statistician, 42(4):278­280. Zhu, J., Huang, H.-C., and Wu, J. (2005). Modeling spatial-temporal binary data using Markov random fields. Journal of Agricultural, Biological, and Environmental Statistics, 10(2):212­225. Zigler, C. M. and Dominici, F. (2014). Uncertainty in propensity score estimation: Bayesian methods for variable selection and model-averaged causal effects. Journal of the American Statistical Association, 109(505):95­107. PMID: 24696528. Zigler, C. M., Watts, K., Yeh, R. W., Wang, Y., Coull, B. A., and Dominici, F. (2013). Model feedback in Bayesian propensity score estimation. Biometrics, 69(1):263­273.
Appendices
A Proofs of the Main Text
A.1 Proof of the Lemma 1
Proof. We prove the lemma when n = 2; the proof can be easily extended to case when n > 2 by induction. Given the posterior p(0:n, 0|Y0:n,1:m), we have
p(0, 1, 2, 0|Y0:2,1:m) = p(2|0, 1, 0, Y0:2,1:m)p(0, 1, 0|Y0:2,1:m).
23

A PREPRINT - JUNE 3, 2021

Then by conditional independence of 2 and (Y0:1,1:m, 0:1) given 0, we have p(0, 1, 2, 0|Y0:2,1:m) = p(2|Y2,1:m, 0)p(0, 1, 0|Y0:2,1:m).
For the term p(0, 1, 0|Y0:2,1:m), we have p(0, 1, 0|Y0:2,1:m) = p(1|0, 0, Y0:2,1:m)p(0, 0|Y0:2,1:m) = p(1|0, 2, 0, Y0:2,1:m)p(2|0, 0, Y0:2,1:m)d2 p(0, 0|Y0:2,1:m).
Similarly, by conditional independence of 1 and (Y-1,1:m, -1) given 
p(0, 1, 0|Y0:2,1:m) = p(1|Y1,1:m, 0)p(2|0, 0, Y0:2,1:m)d2 p(0, 0|Y0:2,1:m) = p(1|Y1,1:m, 0)p(0, 0|Y0:2,1:m).
Hence, we have: p(0, 1, 2, 0|Y0:2,1:m) = p(2|Y2,1:m, 0)p(1|Y1,1:m, 0)p(0, 0|Y0:2,1:m).

A.2 Proof of the Theorem 1

Proof. We first notice that the following equality holds:

n

E

exp -r0,1:m() - Wiri,1:m()

Y0:n,1:m P1:m

i=1

=

p(Y0,1:m|0, 0) n p0,1:m(Y0,1:m) i=1

p(Yi,1:m|~i, 0) pi,1:m(Yi,1:m)

Wi
P1:m(dY0:n,1:m)

n
=
i=1

p(Yi,1:m|~i, 0) pi,1:m(Yi,1:m)

Wi
Pi,1:m(dYi,1:m)

For an arbitrary single term, it is straightforward to have that

p(Yi,1:m|~i, 0) pi,1:m(Yi,1:m)

Wi
Pi,1:m(dYi,1:m)

= exp log (p(Yi,1:m|~i, 0))Wi (pi,1:m(Yi,1:m))1-Wi dYi,1:m

= exp -m(1 - Wi)DWi p(·|~i, 0), pi(·) .

Hence, it follows that

n

E

exp -r0,1:m() - Wiri,1:m()

Y0:n,1:m P1:m

i=1

n
= exp - m(1 - Wi)DWi p(·|~i, 0), pi(·) .

i=1

Now move the right hand side term to the left side and multiply , so we obtain

n

E

exp -r0,1:m() - Wiri,1:m()

Y0:n,1:m P1:m

i=1

n
+ m(1 - Wi)DWi

p(·|~i, 0), pi(·)

1 - log( )


i=1

= .

24

A PREPRINT - JUNE 3, 2021

Now we calculate the expectation with respect to prior  and exchange expectations by Fubini's theorem.

n

E

E exp -r0,1:m() - Wiri,1:m()

Y0:n,1:m P1:m  

i=1

n
+ m(1 - Wi)DWi

p(·|~i, 0), pi(·)

1 - log( )


i=1

= .

The Donsker-Varadhan's change of measure states that for any measurable function  :   R, we have

E ()  DKL(f (·), (·)) + log E exp(()) .

F



By applying this Donsker-Varadhan's change of measure on the left side of the above equality, we have

E exp E

Y0:n,1:m P1:m

F

n
+ m(1 - Wi)DWi
i=1

 .

n
-r0,1:m() - Wiri,1:m()
i=1

p(·|~i, 0), pi(·)

1 - log(  ) - DKL(f (·), (·))

By applying the Markov's inequality, with P1:m probability at least (1 - ), we have

n
exp E -r0,1:m() - Wiri,1:m()
F i=1
n
+ m(1 - Wi)DWi p(·|~i, 0), pi(·)
i=1
 1.

1 - log(  ) - DKL(f (·), (·))

Remove the exponential function and multiply 1/m, we have the following inequality holds

n
(1 - Wi)DWi p(·|~i, 0), pi(·) F (d)

i=1

1 
m

n
r0,1:m + Wiri,1:m

F (d) + DKL(f (·), (·)) + 1 log

m

m

1 

i=1

with P1:m probability at least (1 - ).

A.3 Proof of the remark of Theorem 1

Proof. Given the inequality in Theorem 1, the left hand side of the inequality can be modified as





1

n


m

E
F

- 

i=1

log

E
Yi,1:m Pi,1:m

p(Yi,1:m|~i, 0)

Wi  

pi,1:m(Yi,1:m)

 

=E
F

- log

1

m

E

exp (-mL1:m())

Y0:n,1:m P1:m

 E - log

E

exp (-L1:m()) ,

F

Y0:n,1:m P1:m

25

A PREPRINT - JUNE 3, 2021

and the right hand side of the inequality can be rewritten as:

E L1:m()
F

+

DKL(f (·), (·)) m

+

1 m

log

1 

.

Hence, we have derived the "information posterior bound".

A.4 Proof of the Theorem 2
Proof. We rewrite the criterion function as:

Mm(f ()) = DKL(f (·), (·)) - f () log (ppow(Y0:n,1:m|)) d.

Minimizing Mm(f ()) is equivalent to minimizing:

I(f ()) = f () log(f ())d - f () log(())d + log(ppow(Y0:n,1:m))

- f () log (ppow(Y0:n,1:m|)) d

= f () log f ()ppow(Y0:n,1:m) d ppow(Y0:n,1:m|)()

f ()

= f () log

d

ppow(|Y0:n,1:m)

Obviously we have:

ppow(|Y0:n,1:m)d =

ppow(Y0:n,1:m|)() d = 1, ppow(Y0:n,1:m)

so geographically-powered posterior Ppow(|Y0:n,1:m) is a proper probability distribution and therefore we can write I(f ()) as an Kullback-Leibler divergence:

I(f ()) = DKL

f (·), ppow(Y0:n,1:m|·)(·) ppow(Y0:n,1:m)

 0.

It is clear that f () = ppow(|Y0:n,1:m) minimizes the criterion function Mm(f ()) by reducing the difference of input and output information I(f ()) to 0 and thus it results from an optimal information processing rule.

A.5 Proof of the Theorem 3
Proof. Note that, this theorem easily follows the result of Theorem 1. Here we provide a different way to prove it.
According to Theorem 2, f () = ppow(|Y0:n,1:m) minimizes Mm(f ()). Meanwhile, minimizing Mm(f ()) is equivalent to minimizing:
Km(f ()) = m-1 f () log (p1:m(Y0:n,1:m)) d + m-1DKL(f (·), (·))
- m-1 f () log (p(Y0,1:m|0, 0)) d
n
- m-1 Wi f () log p(Yi,1:m|~i, 0) d
i=1
= m-1 f () log p1:m(Y0:n,1:m) d Ppow(Y0:n,1:m|)
+ m-1DKL(f (·), (·))

26

A PREPRINT - JUNE 3, 2021

Denote the jth batch of observations from all locations by Y0:n,j = (Y0,j, Y1,j, ..., Yn,j). By independence:

Km(f ()) = m-1

m
f () log
j=1

p(Y0:n,j )

p(Y0,j |0, 0)

n i=1

p(Yi,j

|~i,

0)Wi

d

+ m-1DKL(f (·), (·))

= m-1

m
f ()
j=1

log

p0(Yi,j ) p(Yi,j |0, 0)

n
+ Wi log
i=1

pi(Yi,j ) p(Yi,j |~i, 0)

d

+ (m) + m-1DKL(f (·), (·)),

= (m) + E L1:m() + m-1DKL(f (·), (·)),
F

where

m
(m) := m-1

n
(1 - Wi) log(pi(Yi,j) .

j=1 i=1

is a constant. Hence we have the geographically-powered posterior Ppow minimizes

E L1:m() + m-1DKL(ppow(·|Y0:n,1:m), (·)).
Ppow

When m  , we have Km(f ()) converges to:

K(f ()) = = +

f () f () f ()

p1:m(Y0:n,1:m) log

p1:m(Y0:n,1:m)

p(y0|0, 0)

n i=1

p(yi

|~i

,

0

)Wi

dY0:n,1:md

p1:m(Y0:n,1:m) log

p0(y0) p(y0|0, 0)

dY0:n,1:md

n
p1:m(Y0:n,1:m) log
i=1

pi(yi) p(yi|~i, 0)Wi

dY0:n,1:md.

We now look at an arbitrary single term and decompose it:

f ()

p1:m(Y0:n,1:m) log

pi(yi) p(yi|~i, 0)Wi

dY0:n,1:md

= f ()(1 - Wi) pi(yi) log(pi(yi))dyid

+

f ()Wi

pi(yi) log

pi(yi) p(yi|~i, 0)

dyid

= (1 - Wi) pi(yi) log(pi(yi))dyi + Wi f ()DKL(pi(·), p(·|~i, 0))d

= (1 - Wi) pi(yi) log(pi(yi))dyi + Wi E DKL(pi(·), p(·|~i, 0)) ,
Pp(o w )

where the expectation is calculated with respect to distribution f (). We denote a constant  as:

n
 = (1 - Wi)
i=1

pi(yi) log(pi(yi))dyi.

We then have

n

K(f ()) =  + E DKL(p0(·), p(·|0, 0)) + WiDKL(pi(·), p(·|~i, 0))

Pp(o w )

i=1

=  + E L().
Pp(o w )

27

A PREPRINT - JUNE 3, 2021

According to Theorem 2 and assuming the probability measure Pp(ow) exists, f () = p(p ow)(|Y0:n,1:)
minimizes K(f ()). Since  is a constant, the geographically-powered posterior p(p ow)(|Y0:n,1:) is required to put all its mass at  = (0, ~1:n, 0) when m  , where  satisfies:

n

 = arg min DKL (p0(·), p(·|0, 0)) + WiDKL pi(·), p(·|~i, 0) .

 =(0 ,~1:n ,0 )

i=1

A.6 Proof of the Theorem 4

Proof. To obtain the best predictive performance for new observations Y0:n from locations (ui, vi), i = 0, ..., n, we need to maximise the expected log pointwise predictive density for Y0:n. Let Mi be the corresponding parameters of model Mi, i = 0, ..., n. By the assumption of the geographically weighted

regression model (i.e., observation Y is independently generated from the true data generating process, we

have

n

n

p(Y0:n|M0 , ..., Mn ) = p(Yi|M0 , ..., Mn ) = p(Yi|Mi ).

i=0

i=0

By the Assumption 2, we have
n
p(M0 , ..., Mn |Y0:n,1:m) = pMi (Mi |Y0:n,1:m).
i=0
Then we have

p(Y0:n|Y0:n,1:m) = p(Y0:n|M0 , ..., Mn )p(M0 , ..., Mn |Y0:n,1:m)dM0 ...dMn

n
=
i=0

p(Yi|Mi )pMi (Mi |Y0:n,1:m)dMi .

Plugging it into the expected log pointwise predictive density for Y0:n, we have

n

elpd(M ) = log (p(Y0:n|Y0:n,1:m)) pi(Yi)dY0:n

i=0


n

=

log

p(Yi|Mi )pMi (Mi |Y0:n,1:m)dMi

i=0

n
=
i=0 n
=
i=0 n

log

p(Yi|Mi )pMi (Mi |Y0:n,1:m)dMi

pi(Yi) log(pMi (Yi|Y0:n,1:m))dYi

= elpd(ui,vi)(Mi).
i=0


n
pj (Yj) dY0:n
j=0
pi(Yi) dYi

Given any geographically weighted regression model Mi = ((ui, vi), ), by Assumption 1, we have that for  > 0, Mi() = ((ui, vi), ) always maximizes the elpd. That is

elpd(ui,vi)(Mi)  elpd(ui,vi)(Mi()), i = 0, ..., n.

Now we have

n
elpd(M )  elpd(ui,vi)(Mi()).
i=0

28

A PREPRINT - JUNE 3, 2021

This has proved (ui , vi) = (ui, vi) for all i. To further maximize elpd(M ), we simply require



=

arg max


n

1 +

1

n i=0

elpd(ui,vi)(Mi()).

29

A PREPRINT - JUNE 3, 2021

B Supplementary Figure

4.4 4.2 4.0 3.8 3.6 3.4 3.2 3.0 2.8
0

Bandwidth=0.0001

3.6 3.4 3.2 3.0

1000 2000

3000 4000 5000

6000

7000

2.8 2.6
0

Bandwidth=1

3.075

3.050

3.025

3.000

2.975

2.950

2.925

1000 2000

3000 4000 5000

6000

2.900

7000

0

Bandwidth=20

1000 2000

3000 4000 5000

6000

7000

0.20 0.18 0.16 0.14 0.12 0.10 0.08 0.06
0
0.25 0.20 0.15 0.10 0.05 0.00
0
0.9 0.8 0.7 0.6 0.5
0

0.20

0.18

0.16

0.14

0.12

1000 2000 1000 2000

3000 4000 3000 4000

5000 5000

6000 6000

7000 7000

0.10 0
0.275 0.250 0.225 0.200 0.175 0.150 0.125 0.100 0.075
0

1.0 0.9 0.8 0.7 0.6 0.5

1000 2000

3000 4000 5000

6000

7000

0

1000 2000

3000 4000 5000

6000

0.190

0.188

0.186

0.184

0.182

0.180

0.178

0.176

7000

0

1000 2000

3000 4000 5000

6000

7000

1000 2000 1000 2000

3000 4000 5000 3000 4000 5000

6000 6000

0.210

0.205

0.200

0.195

0.190

0.185

0.180

7000

0

1.0

0.9

0.8

0.7

0.6

0.5

7000

0

1000 2000

3000 4000 5000

6000

7000

1000 2000

3000 4000 5000

6000

7000

Figure A1: Trace plot of SMI samples for 0, 1, 2 and  when   {0.0001, 1, 20}. Each plot contains results of 10 chains. The upper and lower bounds of trace plots reveal that the empirical Bayesian GWR posterior tends to have lower variance with higher geographical bandwidth.

30

