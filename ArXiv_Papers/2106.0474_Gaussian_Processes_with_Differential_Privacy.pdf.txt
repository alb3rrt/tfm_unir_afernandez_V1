arXiv:2106.00474v1 [cs.LG] 1 Jun 2021

Gaussian Processes with Differential Privacy
Antti Honkela Helsinki Institute for Information Technology HIIT
Department of Computer Science University of Helsinki
antti.honkela@helsinki.fi
Abstract
Gaussian processes (GPs) are non-parametric Bayesian models that are widely used for diverse prediction tasks. Previous work in adding strong privacy protection to GPs via differential privacy (DP) has been limited to protecting only the privacy of the prediction targets (model outputs) but not inputs. We break this limitation by introducing GPs with DP protection for both model inputs and outputs. We achieve this by using sparse GP methodology and publishing a private variational approximation on known inducing points. The approximation covariance is adjusted to approximately account for the added uncertainty from DP noise. The approximation can be used to compute arbitrary predictions using standard sparse GP techniques. We propose a method for hyperparameter learning using a private selection protocol applied to validation set log-likelihood. Our experiments demonstrate that given sufficient amount of data, the method can produce accurate models under strong privacy protection.
1 Introduction
Differential privacy (DP; Dwork et al., 2006) is currently the standard approach for privacy-preserving machine learning. Based on the idea of bounding the impact of a single individual on the outcome, DP has been widely and successfully applied to models that treat each observation independently, ranging from deep learning (e.g. Abadi et al., 2016) to Bayesian regression models (e.g. Bernstein and Sheldon, 2019) to generic Bayesian inference using Markov chain Monte Carlo (e.g. Heikkilä et al., 2019) or variational inference (Jälkö et al., 2017).
Gaussian processes (GPs; Rasmussen and Williams, 2006) are a class of highly popular nonparametric Bayesian models, that do not fit this paradigm. GPs are often used to define a non-linear non-parametric regression model by modelling the (potentially multivariate) output value y = f (x) at each input x using a distribution over functions f . These are assumed to follow the GP f  GP(µ, k) with some mean function µ (often assumed to be zero) and covariance or kernel k. Observations are usually assumed to include noise. By definition, the distribution of f evaluated at any number of points follows a multivariate Gaussian distribution. After fitting a GP to the data, the distribution of f at each point depends directly on all observations. The dependence on inputs x is especially complicated. This has caused the previous work in DP GPs (Smith et al., 2018, 2019) to use DP mechanism for functional data (Hall et al., 2013) to address only the significantly weaker privacy model of label privacy, where only the privacy of the outputs (Y) is considered while the inputs (X) are assumed non-sensitive. We seek a method to protect both X and Y. In order to do that, we formulate the GP learning problem in a way that has less complicated dependence on the input data X.
Our main novel contributions are:
Preprint. Under review.

· A method for learning a variational sparse GP approximation under DP for both inputs and outputs.
· A method for approximately correcting the approximation posterior to account for DP noise.
· A method for learning DP-GP hyperparameters under DP.

2 Background

2.1 Differential privacy (DP)

DP defines a statistical criterion for a randomised algorithm that bounds the accuracy of inferences an adversary can make about the inputs of the algorithm using its outputs, providing a guarantee of privacy to input data subjects. The guarantee applies regardless of additional side information the adversary may have, and degrades gracefully under repeated use of the data.
DP definition is based on the concept of neighbouring data sets D  D . We use the substitute neighbourhood, where D  D if D can be obtained from D by substituting a single entry.
Definition 1. Given  0,   [0, 1], a randomised algorithm M is ( , )-DP if for all neighbouring data sets D  D and for all measurable sets of outputs O  Range(M), we have

Pr[M(D)  O]  e Pr[M(D)  O] + .

(1)

Lower values of and  correspond to stronger privacy.
Our main tool for achieving DP is the analytical Gaussian mechanism (Balle and Wang, 2018), which can release the value of a function f (D) under ( , )-DP by adding Gaussian noise whose variance is tuned to the L2-sensitivity of f , f = supDD f (D) - f (D ) 2.

2.2 Sparse and variational GPs
Gaussian processes (GPs) provide a means for performing exact Bayesian inference over functions f  GP(µ, k(·, ·)) (Rasmussen and Williams, 2006). A GP defines a distribution over functions, which is specified by the mean function µ, often assumed to be zero, and covariance or kernel function k(·, ·). Covariance function is the key parameter that defines the smoothness and other properties of the functions f .
The first GP learning problem is inference of the posterior GP given noisy observations of some underlying function. Assuming the observations follow a Gaussian likelihood, it is possible to perform exact inference over f , but given n observations this will require operations with n × n kernel matrix that require O(n3) time and results in a complicated dependence on input data that is unfavourable to DP. A popular method for reducing the computational complexity is to employ a sparse GP method that seeks to replace the dependence on the full input X with dependence on a smaller number of inducing inputs Z and values of the function at those points u = f (z) (Snelson and Ghahramani, 2005; Candela and Rasmussen, 2005; Titsias, 2009; Bauer et al., 2016).
The variational sparse GP first introduced by Titsias (2009) solves the problem by defining a variational distribution q(u) over the function values at the inducing inputs. Assuming that the inducing inputs and kernel parameters are fixed and a Gaussian observation model with noise variance 2, the optimal q(u) = N (u; m, S) can be written in closed form as (Titsias, 2009, Eq. 10):
m = -2KZZ KZX Y, S = KZZ KZZ ,  = (KZZ + -2KZX KXZ )-1, (2)
where KZZ = (k(zi, zj)) is a matrix of kernel values between inducing inputs and KZX = KTXZ = (k(zi, xj)) is a matrix of kernel values between inducing inputs and input data locations X. The variational approximation can be used to evaluate arbitrary predictions (Hensman et al., 2015, Eq. 21).
The above discussion assumes the kernel and all other hyperparameters of the model are known, which is usually not the case. The resulting second GP learning problem, hyperparameter learning, is addressed in the variational framework by finding hyperparameters that maximise the variational evidence lower bound (ELBO) (Titsias, 2009).

2

3 GP inference under differential privacy

One key insight in making variational GPs DP is that we only need to publish Z and q(u) to allow using the model to make predictions on arbitrary new points. Assuming that Z is chosen independently of the input data or using some other DP mechanism, it will be enough to ensure the privacy of m and S that define q(u).

Following (2), q(u) only depends on the private data X, Y via two terms:

n

n

A = KZX Y = kiyi, B = KZX KXZ = kikTi ,

(3)

i=1

i=1

where ki = KZXi = (k(zj, xi))|jZ=|1 is a vector of kernel values between xi and all inducing points Z.

Both of these terms are sums over data points (xi, yi), suggesting one can implement efficient DP mechanisms for these by evaluating the sensitivity of the terms.

3.1 Sensitivity calculations

Sensitivity calculations will depend on the kernel. Assuming a bounded kernel with |k|  f2, we

have a trivial bound

k 2  |Z|f2 =: Rk.

(4)

Assuming scalar y with |y|  Ry, we can adapt the sensitivity analysis of Kulkarni et al. (2021) for

the mechanism

M(X, Y) =

A B^

+N

0, diag(a2Id, b2Id2 )

(5)

to obtain the sensitivity

=

b2 2a2

Ry4

+

2Ry2 Rk2

+

2

a2 b2

Rk4 .

(6)

Here B^ denotes the vector [k12 · · · kd2





2k1k2 · · · 2kd-1kd] formed from upper diagonal elements

of A with off-diagonal elements scaled up, which can be used to reconstruct a full noisy symmetric

B, d = |Z| and d2 =

d+2 d

.

Full derivation of Eq.

(6)

is in the Supplementary material.

3.2 Kernel-dependent sensitivity

The bound ki 2  |Z|f2 is pessimistic. It is possible to obtain tighter bounds by making assumptions about the kernel and inducing input placement.
Let us assume that we have a stationary kernel that is decreasing as a function of the distance of the two inputs. This class includes most standard stationary kernels. We can write this as k = f2kr(r), with 0  kr(r)  1.
Let us further assume that the minimum distance between two input points is at least dz. In 1D we have for example

ki f4

2 2

=

|Z |
k(zj , xi)2
j=1



|Z |/2 j =0

2kr(j dz)2 + ( |Z|/2

-

|Z|/2 )kr( |Z|/2 dz)2.

(7)

In higher dimensions an accurate analysis becomes considerably more difficult. We can still obtain a simple bound on the kernel values by noting that we can have at most one inducing point at a distance smaller than dz/2. This yields the bound

ki f4

2 2

=

|Z |
k(zj , xi)2
j=1



1 + (|Z|

- 1)kr(dz/2)2.

(8)

3

3.3 Noise-aware DP posterior approximation

Applying the Gaussian mechanism to privatise (3), we will replace A and B with A + Ea and B + Eb, respectively, where Ea and Eb are the noise terms. A naive application of these to the update rules in Eq. (2) would replace  with (KZZ + -2(KZX KXZ + Eb))-1, which can become non-positive definite if the noise Eb is large. This would make the results basically meaningless, as S would not be a valid covariance matrix anymore.

In order to avoid this issue, the update needs to be moderated by adding a diagonal regularisation term to obtain the DP update for q(u) = N (u; m, S):

m = -2KZZ ~ (A + Ea), S = KZZ ~ KZZ + S2, ~ = (KZZ + -2(B + Eb) + I)-1, (9)
where  is a constant selected to make sure KZZ + -2(B + Eb) + I remains positive definite and S2 is added to the covariance to account for the impact of DP noise to m.
In order to set , we use Lemma 6 of Wang (2018), which shows that with probability 1 - , Eb 2  b2d log(2d2/), where the dimensionality d = |Z| is the equal to the number of inducing points Z and b2 is the variance of noise added to B. Using this and taking into account the smaller variance of off-diagonal terms, we can set

 = b-2

|Z| log(2|Z|2/) |Z| + 1 2|Z |

(10)

with suitable  to have a high probability of ~ being positive definite. We use  = 0.01 in the experiments. Unlike the AdaSSP mechanism of Wang (2018) this approach is inspired by, we do not use a DP estimate of the minimum eigenvalue, because the smallest eigenvalues of kernel matrices are typically very close to zero, which means that adding a DP estimate of the eigenvalue would mostly just add noise and drain the privacy budget.

To evaluate S2, we observe that the DP mechanism adds two noise terms Ea and Eb that impact m. As the two noise terms are independent, their impacts can be evaluated separately. As Ea  N (0, a2I) is purely additive, the covariance added by it can be computed easily to obtain

S2,1 = Cov[-2KZZ ~ Ea] = a2-4KZZ ~ 2KZZ .

(11)

As Eb is not additive, we estimate its impact by linearising the expression for m in (Eb)ij to obtain

m



m(Eb

=

Eb )

+

m (Eb)ij

(Eb)ij

(12)

m (Eb)ij

= --4KZZ ~ Eij~ (A + Ea),

(13)

where (Eij)kl = (i = k)(j = l), i.e. it is a matrix of all zeros except a single 1 at position (i, j).
This allows computing the additional covariance component due to Eb as a sum of contributions of the independent elements (Eb)ij added to the upper triangular matrix as

|Z|
S2,2 = -8b2KZZ ~ Eii~ (A + Ea)(A + Ea)T ~ Eii~ KZZ
i=1

|Z|
+

|Z |

-8 b2 2

KZZ ~ Eij ~ (A + Ea)(A + Ea)T ~ Eji~ KZZ

i=1 j=i+1

+ KZZ ~ Eji~ (A + Ea)(A + Ea)T ~ Eij~ KZZ . (14)

The final covariance of DP q(u) is thus

S = KZZ ~ KZZ + S2 = KZZ ~ KZZ + S2,1 + S2,2.

(15)

The additional terms in the covariance only depend on the previously released DP quantities and therefore have no additional impact on the privacy.

4

Algorithm 1 Algorithm for DP-GP inference using known hyperparameters.
function DP-GP-INFERENCE(X, Y, Z, k(·, ·), , c, Ry, , ) Compute Rk using Eq. (4), (7) or (8) Compute sensitivity  for DP-mechanism using Eq. (6) with a/b = c Compute a for ( , )-DP -sensitive analytical Gaussian mechanism (Balle and Wang, 2018) b  a/c Compute q(u) = N (u; m, S) on Z using Eq. (9) return m, S

3.4 Final algorithm and its privacy
Theorem 2. The DP-GP inference in Algorithm 1 is ( , )-DP with respect to the input data set (X, Y).
Proof. The only part of the algorithm using the input data is the computation of q(u) using Eq. (9). This update only accesses the data via Eq. (3). These are made private using the Gaussian mechanism of Eq. (5) whose noise variance is calibrated using the given privacy parameters and the sensitivity computed above.

4 Hyperparameter learning

GPs depend on a number of hyperparameters such as observation noise level and kernel parameters. These are commonly either inferred by applying Markov chain Monte Carlo (MCMC) to obtain a posterior distribution or optimised. In both cases, the process commonly makes use of the marginal likelihood of the parameters, obtained by analytically marginalising the GP and available in closed form for GP regression, or in the case of variational approximation the variational evidence lower bound (ELBO).
While the marginal likelihood and the ELBO can be written in closed form, their expressions have a complex dependence especially on the input data X, making it difficult to evaluate these quantities under DP.
To avoid this issue, we will instead use validation set likelihood as the objective for hyperparameter optimisation. We further assume independence of the validation set points in the likelihood to make the expression easier to evaluate under DP.

4.1 DP evaluation of validation set likelihood

Using standard variational GP techniques (Hensman et al., 2015), given an approximation q(u) = N (u; m, S) over values at inducing points Z and hyperparameters , the predictive distribution at a new set of noise-free validation points V can be computed as

p(yV |V, X, Y, )  p(yV |V, u, )p(u|X, y, ) du  p(yV |V, u, )q(u|) du, (16)

u

u

which can be evaluated analytically to obtain normal N (µ^ , ^ ) with

µ^ = KV Z K-ZZ1 m, ^ = KV V - KV Z K-ZZ1 (KZZ - S)K-ZZ1 KZV .

(17)

Under our assumption of independence, we will only consider the diagonal of ^ . This yields the likelihood of noisy validation set (V, yV ) as

|V |
log p(yV |V, X, Y, )  log N (yV ; µ^ , diag(^ ) + 2I|V |) = log N (yV,i; µ^i, ^ ii + 2), (18)
i=1

which only depends on (X, y) via (m, S) and where each term of the sum only depends on the corresponding element of the validation set.

The usual way to estimate the sum under DP would be to bound each term and add noise to the result using for example Laplace or Gaussian mechanism. This is not easy in our case because the normal

5

log-likelihood cannot easily be bounded tightly over a wide range of parameter values, but at the same time the values of the terms in the sum are often quite similar as they depend strongly on the model hyperparameters .

To avoid these complications, we apply a generic mean estimation method COINPRESS (Biswas et al., 2020) that uses a multi-step approach with iteratively tightening bounds to allow accurate estimation even if the original bounds are very loose. Our estimate of the log-likelihood is simply |V | times the mean estimate returned by COINPRESS.

We use COINPRESS with centre and radius of the interval of possible values defined as RCP =

Ry2 2

,

CCP

=

-

1 2

log(2)

-

log



-

Ry2 2

.

Values

outside

this

interval

are

clipped

to

the

bounds

of

the

interval. The justification of the bounds is in Supplementary material. COINPRESS operates under

the zero-concentrated DP model -zCDP. Given ( , ), we use CoinPress with

2

CP =

+ log(1/) - log(1/) ,

(19)

which guarantees that the result will be ( , )-DP (Bun and Steinke, 2016). We use COINPRESS with 12 iterations with 3/4 of  budget assigned to the last iteration and the rest split evenly between the preceding iterations. Under very small privacy budget, COINPRESS sometimes returns values outside the interval. Such values are ignored in our use in Algorithm 2.

4.2 DP learning of optimal hyperparameters
Using these DP estimates of the validation set log-likelihood, it is in principle possible to apply MCMC or standard optimisation techniques to infer the hyperparameters. This approach is not very practical, as these methods typically require evaluating the log-likelihood for a large number of candidate values, and without additional measures each of these would carry a significant privacy cost.
To avoid this erosion of privacy guarantees, we apply the method for private selection from private candidates proposed by Liu and Talwar (2019), which allows privately selecting the optimal hyperparameters from a large set of possible values with O( ) privacy when each candidate model evaluation is -DP. The corresponding guarantees for ( , )-DP candidate models are weaker, but still offer substantial improvement over naive composition.
In order to apply the private selection algorithm, we need to formulate the composition of GP inference and validation set likelihood evaluation as a single DP mechanism over the union of disjoint training and validation sets. This generalises Lemma 5.1 of Liu and Talwar (2019) to cases where the hyperparameter goodness measure is not a counting query but a general ( , )-DP mechanism.
Following Liu and Talwar (2019), we define Mi(D1), i = 1, . . . , K as the ( , )-DP mechanisms for GP inference using training set D1 using different hyperparameter values. Mechanisms qi(m, D2) are ( , )-DP mechanisms to evaluate the validation set D2 log-likelihood of the model m  Mi(D1). The final mechanism is Q(D1, D2)  (m, qi(m, D2)), where i  Uniform([K]), m  Mi(D1).
Lemma 3. Assume D1  D2 = , the mechanisms Mi(D1), i = 1, . . . , K are ( , )-DP with respect to D1, and the mechanisms qi(m, D2), i = 1, . . . , K are ( , )-DP with respect to D2. Then the joint mechanism Q(D1, D2) defined above is ( , )-DP with respect to D = (D1, D2).

Proof. Let us consider two neighbouring data sets D = (D1, D2) and D = (D1, D2) that differ by a single element. Depending on whether the different element is in the D1 or D2 part, we have two cases.
If the differing element is in the D1 part, we have D2 = D2 and thus qi(m, D2) = qi(m, D2). The output of Q(D1, D2) is post-processing of the DP-mechanism Mi(D1) and thus satisfies ( , )-DP.
If the differing element is in the D2 part, we have D1 = D1 and thus Mi(D1) = Mi(D1). As the distribution of m is thus same under both scenarios, we have for any measurable set S  Range(Q) and for all m and i,
Pr((m, qi(m, D2))  S)  e Pr((m, qi(m, D2))  S) + 
by ( , )-DP of qi(m, D2). Therefore Q(D1, D2) is ( , )-DP with respect to (D1, D2).

6

We can now define Algorithm 2 to find optimal hyperparameters using a bounded step variant of

Algorithm 2 of Liu and Talwar (2019). The algorithm repeatedly draws randomly from Q(D1, D2)

and keeps a record of the highest scoring candidate. It outputs the highest scoring candidate after

every

draw

with

probability



>

0,

or

after

at

most

T

=

1 

log

1 2

draws,

where

2



[0, 1].

Lemma

3

as well as Theorem 3.4 of Liu and Talwar (2019) show that when both GP inference and validation

set log-likelihood evaluation are ( , )-DP, the output of the hyperparameter inference algorithm is

( tot, tot)-DP with





tot = 3 + 3 2, tot = 2T + 2.

(20)

4.3 Final algorithm and its privacy

Algorithm 2 Algorithm for finding optimal DP-GP hyperparameters within a set of candidate kernels

and noise variances  = (1 = (k1, 1), . . . , k = (kk, k)).

function DP-GP-HYPERPARAMETER-LEARNING(X1, Y1, X2, Y2, Z, Ry, , tot, tot, )

t0  FIND-ROOT(t[1- log(t)] - tot, t) 

  2t20/2; 2  2/;  tot/3 - 2

T



1 

log

1 2

;

vopt  -

for t = 1, . . . , T do

i  Uniform(1, . . . , k)

m, S  DP-GP-INFERENCE(X1, Y1, Z, ki(·, ·), i, Ry, , ) vj  log p(Y2,j|X2,j, X, Y, i), j = 1, . . . , |X2| using Eq. (18) v~  |X2|COINPRESS-MEAN(CLIP(vj , CCP, RCP), CCP, RCP, CP) if v~  CCP + RCP and v~ > vopt then
vopt  v~; mopt  (m, S)

if rand(1) <  then

return (mopt, vopt)

return (mopt, vopt)

Theorem 4. Algorithm 2 is ( tot, tot)-DP with respect to the combination of the training and validation sets ((X1, Y1), (X2, Y2)).
The proof, which follows from Lemma 3 and Theorem 3.4 of Liu and Talwar (2019), is included in the Supplementary material.

5 Classification
The above discussion relies on the ability to perform exact inference on the GP which is only possible if the likelihood is also Gaussian. Milios et al. (2018) propose a number of methods to represent classification tasks using a GP with a Gaussian likelihood. Under their model, processes f = [f1, . . . , fC] representing the log-probability of each class can be learned using a normal likelihood with
p(y~i|f ) = N (y~i; fi, ~i2), y~i = log i - i2/2, ~i2 = log(1/1 + 1), i = yi +  , (21)
where yi are one-hot encoded binary targets and 0 <  1 is a regularisation constant.
As the required transformation is data-point-specific, it does not impact DP. The only additional caveat is that the likelihood will be heteroscedastic with different noise levels for different points. A version of DP-GP that supports diagonal heteroscedastic noise is derived in the Supplementary material.

6 Experiments
6.1 Inference of a noisy function We first illustrate the DP-GP inference with a task of inferring function f (x) = sin(2x)/2x from N = 1024 noisy observations on interval [-4, 4]. We place |Z| = 9 inducing points on a regular grid

7

= 0.3
1.0 0.5 0.0 0.5 1.0 1.5
2.5 0.0 2.5

= 1.0
1.0 0.5 0.0 0.5 1.0
2.5 0.0 2.5

= 3.0
1.0 0.5 0.0 0.5 1.0
2.5 0.0 2.5

= 10.0
1.0 0.5 0.0 0.5 1.0
2.5 0.0 2.5

Figure 1: Illustration of DP-GP inference with varying and  = 10-4 on a data set of N = 1024 points sampled from the black function with noise. The blue line is the posterior mean for the GP with shaded region denoting 2 sd confidence region. Green dots denote means of inducing point values under q(u).

p(ptest < )

p(ptest < )

1.00

= 0.50

0.75

0.50

0.25

0.00 1.00

100

101

0.75

0.50

0.25

0.00 1.00

100

101

0.75

0.50

0.25

0.00 100

101

= 0.90

100

101

100

101

100

101

= 0.95

100

101

100

101

100

101

= 0.99
= 0.1

100

101

= 0.3

100

101

reference = 0.5 DP-GP naive

100

101

p(ptest < )

Figure 2: Uncertainty calibration accuracy of the proposed DP-GP algorithm and a naive algorithm omitting the additional posterior covariance contributions due to noise added for DP. The curves show the fraction of test points within  high posterior density region. The error bars indicate two standard errors of the mean after 40 repeats.

between -3 and 3. We assume the noise standard deviation  = 0.1 is known. We use exponentiated quadratic (a.k.a. squared exponential) kernel with length scale l = 1.0. The results in Fig. 1 show how the model becomes more accurate as increases and the privacy becomes less tight, but the posterior confidence intervals for the true function scale with the privacy level.
6.2 Uncertainty calibration
In this experiment we test the calibration accuracy of the predictive uncertainty of the learned GP model. To avoid model mismatch, we draw the target function from a GP with exponentiated quadratic covariance with l = 1.0, and simulate Ntot = 1024 noisy observations from this function on the interval [-4, 4]. The observations are divided to training and test sets of equal size, and a DP-GP is fitted using the training set to |Z| = 15 inducing points regularly spaced on the interval [-3.5, 3.5]. We then evaluate predictions of the model for the test set points, and check the fraction of test set
8

1.0

0.8

0.6

0.4

0.2

0.0

0.1 0.2 0.3

1

2

3

= 1.0 = 3.0 = 10.0 = 30.0

Figure 3: Probability of finding specific observation noise  and length scale values in hyperparameter learning experiment after 100 repeats.
points that are within the central high posterior density region covering fraction  of the posterior. If the posterior uncertainty is properly calibrated, the observed fraction should be close to .
Fig. 2 shows the calibration results for a range of values of interval width  (columns), observation noise standard deviations  (rows) and privacy levels . The value  = 10-4 is used in all cases. The results show a comparison of the proposed full model ("DP-GP") with a naive model that omits the DP uncertainty calibration in the posterior covariance ("naive") relative to the reference level  ("reference").
The results indicate that the additional terms significantly improve the calibration, especially for low observation noise and tight privacy where the calibration of the naive model is the poorest. The proposed model is still overconfident in many cases, possibly due to ignoring the error caused by the additional necessary regularisation from Eq. (10). It is noteworthy that the DP-GP calibration is significantly less sensitive to , which suggests it is able to capture the additional uncertainty caused by DP. The runtime of the experiment using 40 repeats in 48 different scenarios was less than 30 seconds on a modern laptop CPU.
6.3 Hyperparameter learning
Finally we demonstrate the accuracy of hyperparameter learning using a set of N = 2048 points generated similarly as in Sec. 6.1, split evenly to training and validation sets. We use a search among 9 combinations of 3 observation noise levels   {0.1/3, 0.1, 0.3} and 3 kernel length scales
 {1/3, 1.0, 3.0}, where consecutive values differ by a factor of 3. The results shown in Fig. 3 show that = 3.0 is needed for any sensible results and observation noise level estimates improve up to = 30.0. The accuracy and runtime can be traded off with parameter . 100 repeats with 4 values of took approximately 10 minutes on a modern laptop CPU with  = 0.01.
7 Discussion
We have presented the basic algorithms needed for learning GPs under DP protection for both inputs and outputs, significantly improving privacy over previous privacy-preserving GPs. DP-GP publishes a variational approximation on a set of fixed inducing points. This is computed using analytical Gaussian mechanism for releasing a function of input-vs-inducing-point cross kernels and outputs.
The largest pain point for GP inference part is the need to add the diagonal regularising term to ensure the perturbed second moment matrix is positive definite. This appears unavoidable, as developing a DP mechanism that would add purely positive definite noise is not possible, as careful analysis of the invalid Wishart mechanism proposals has indicated.
Because our mechanism operates on the kernel matrix rather than input data, privacy bounds depend on the number of inducing points but not on input dimensionality. In practice, input dimensionality will impact the method as it affects the number of inducing points required for a good approximation. The method also works on non-vectorial data such as graphs or strings.
9

Important questions for future work include optimising the ratio a/b that we assumed to be even, possibly by making use of terms of S2. Co-developing kernels with small KZXi 2 such as limited range kernels and better bounds can help improve utility. Finding more efficient algorithms for hyperparameter learning and testing the method in different practical applications would also be important.
Acknowledgements
The author would like to thank Michalis Titsias and Razane Tajeddine for useful comments and suggestions. This work has been supported by the Academy of Finland (Finnish Center for Artificial Intelligence FCAI and grant 325573) as well as by the Strategic Research Council at the Academy of Finland (grant 336032).
References
M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang. Deep Learning with Differential Privacy. In Proc. CCS 2016, 2016.
B. Balle and Y.-X. Wang. Improving the Gaussian Mechanism for Differential Privacy: Analytical Calibration and Optimal Denoising. In Proceedings of the 35th International Conference on Machine Learning, 2018.
M. Bauer, M. v. d. Wilk, and C. E. Rasmussen. Understanding Probabilistic Sparse Gaussian Process Approximations. In Advances in Neural Information Processing Systems 29 (NIPS 2016), 2016.
G. Bernstein and D. R. Sheldon. Differentially Private Bayesian Linear Regression. In Advances in Neural Information Processing Systems 32 (NeurIPS 2019), 2019.
S. Biswas, Y. Dong, G. Kamath, and J. Ullman. CoinPress: Practical Private Mean and Covariance Estimation. In Advances in Neural Information Processing Systems 33 (NeurIPS 2020), 2020.
M. Bun and T. Steinke. Concentrated Differential Privacy: Simplifications, Extensions, and Lower Bounds. In Theory of Cryptography (TCC 2016), 2016.
J. Q. Candela and C. E. Rasmussen. A Unifying View of Sparse Approximate Gaussian Process Regression. J. Mach. Learn. Res., 6:1939­1959, 2005.
C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating Noise to Sensitivity in Private Data Analysis. In Theory of Cryptography, 2006.
R. Hall, A. Rinaldo, and L. A. Wasserman. Differential privacy for functions and functional data. J. Mach. Learn. Res., 14(1):703­727, 2013.
M. A. Heikkilä, J. Jälkö, O. Dikmen, and A. Honkela. Differentially Private Markov Chain Monte Carlo. In Advances in Neural Information Processing Systems 32 (NeurIPS 2019), 2019.
J. Hensman, A. Matthews, and Z. Ghahramani. Scalable Variational Gaussian Process Classification. In Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics, 2015.
J. Jälkö, A. Honkela, and O. Dikmen. Differentially Private Variational Inference for Non-conjugate Models. In Proceedings of the Thirty-Third Conference on Uncertainty in Artificial Intelligence (UAI 2017), 2017.
T. Kulkarni, J. Jälkö, A. Koskela, S. Kaski, and A. Honkela. Differentially Private Bayesian Inference for Generalized Linear Models. arXiv:2011.00467 [cs, stat], May 2021. arXiv: 2011.00467.
J. Liu and K. Talwar. Private selection from private candidates. In Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing, June 2019.
D. Milios, R. Camoriano, P. Michiardi, L. Rosasco, and M. Filippone. Dirichlet-based Gaussian Processes for Large-scale Calibrated Classification. In Advances in Neural Information Processing Systems 31 (NeurIPS 2018), 2018.
10

C. E. Rasmussen and C. K. I. Williams. Gaussian Processes for Machine Learning. The MIT Press, 2006.
M. T. Smith, M. A. Álvarez, M. Zwiessele, and N. D. Lawrence. Differentially Private Regression with Gaussian Processes. In Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics, April 2018.
M. T. Smith, M. A. Alvarez, and N. D. Lawrence. Differentially Private Regression and Classification with Sparse Gaussian Processes. arXiv:1909.09147 [cs, stat], September 2019. arXiv: 1909.09147.
E. Snelson and Z. Ghahramani. Sparse Gaussian Processes using Pseudo-inputs. In Advances in Neural Information Processing Systems 18 (NIPS 2005), 2005.
M. Titsias. Variational Learning of Inducing Variables in Sparse Gaussian Processes. In Proceedings of the Twelth International Conference on Artificial Intelligence and Statistics (AISTATS 2009), 2009.
Y.-X. Wang. Revisiting differentially private linear regression: optimal and adaptive prediction & estimation in unbounded domain. In Proceedings of the Thirty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI 2018), 2018.

A Sensitivity for the Gaussian mechanism for DP-GP inference

Following Kulkarni et al. (2021), we define functions

ta(x) = x,





(22)

tb(x) = [x21 · · · x2d 2x1x2 · · · 2xd-1xd]T .

(23)

Using this notation, the quantities A and B can be expressed as sums of yita(ki) and tb(ki), respectively.

The following Lemma and its proof are analogous to Lemma 3.3 of Kulkarni et al. (2021):

Lemma 5. Let ta and tb be defined as in Eqs. (22) and (23) and let a, b > 0. Consider the

mechanism

|X |

M(X, Y) =

yita(ki) tb(ki)

+N

0, diag(a2Id, b2Id2 )

,

i=1

where d2 =

d+2 2

,

with

d

=

|Z |.

Assuming

ki 2  Rk and |yi|  Ry, M can be reduced to a

Gaussian mechanism with noise variance a2 and sensitivity

=

b2 2a2

Ry4

+

2Ry2 Rk2

+

2

a2 b2

Rk4 .

(24)

Proof. As M is a sum over terms each depending on a single data entry, we can compute the sensitivity as the maximal change in a single entry of the sum when the input changes from (x, y) to (x , y ). Denoting k = kZx, k = kZx , we can bound the first term

yta(k) - y

ta(k )

2 2

=

yk 2 + y k

2 - 2 yk, y k

 2Rk2Ry2 - 2yy k, k

(25)

and the second term

tb(k) - tb(k )

2 2

=

k 4+

k

4 - 2 k, k

2  2Rk4 - 2 k, k

2.

(26)

Similarly as Kulkarni et al. (2021), we can rescale the two parts to share the same variance a2 by noticing that

|X |

M(X, Y) =

yita(ki) tb(ki)

+N

0, diag(a2Id, b2Id2 )

i=1





(27)

|X |

=

Id 0

0
b
a


i=1

yita(ki)

a b

tb

(ki

)

+N

0, a2Id+d2 )  .

11

We can bound the sensitivity of

|X | i=1

yita(ki)

a b

tb

(ki

)

using Eqs. (25) and (26) as

2  -2ct2 - 2yy t + 2cRk4 + 2Rk2Ry2,

(28)

where

we

have

denoted

c

=

a2 b2

,

t

=

k, k

. Viewed as a second order polynomial over t, RHS has

its

maximum

at

t

=

-

yy 2c

which yields

2



2cRk4

+ 2Rk2 Ry2

+

(yy )2 2c



2cRk4

+ 2Rk2 Ry2

+

Ry4 , 2c

(29)

which can be simplified to yield the claim.

B Approximate bounds for validation set log-likelihood for hyperparameter learning

Hyperparameter learning uses an estimate of mean validation set log-likelihood evaluated using COINPRESS (Biswas et al., 2020). COINPRESS requires bounds for the function but is not extremely sensitive to the bounds because of the multi-step protocol. In this section, we derive approximate bounds for validation set log-likelihoods. Values outside these bounds will be clipped to make them adhere to the bounds.

The validation set density is a normal with mean given by the GP prediction and variance equal to GP predictive variance plus observation noise variance 2. In order to obtain approximate bounds, we consider values obtained with either perfect mean prediction or one that is off by 2Ry, where Ry  |y| is the bound used in the sensitivity calculations, both under variance equal to just the observation noise. The upper bound for the log-likelihood is tight, but the "lower bound" is not
an actual bound as even smaller log-likelihoods are possible if the GP predictions are more than 2 max |y| off. Such values are simply clipped.

These yield clipping bounds for the log-likelihood L

1

Lmax

=

- 2

log(2)

-

log



(30)

Lmin

=

1 -
2

log(2)

-

log



-

4Ry2 22

.

(31)

These correspond to COINPRESS parameters for the centre and radius of the region of interest

R

=

Ry2 2

(32)

C

=

1 -
2

log(2)

-

log



-

Ry2 2

.

(33)

C Proof of Theorem 4 (hyperparameter learning privacy)

Proof. We show that Algorithm 2 is ( tot, tot)-DP with respect to the combination of the training and validation sets ((X1, Y1), (X2, Y2)).

We start by defining 2 to minimise tot. By using the definition of T , we find the optimal value



2

2 =

. 

(34)

Using this value,





2

2

tot =  1 - log 

= t[1 - log t],

(35)



where t =

2 

.

We

solve

this

equation

numerically

to

find

t0

that

matches

the

desired

tot,

allowing

us to solve for  = 2t20/2 that yields the desired tot.

12

Given , we can easily solve for required to match the target tot.
Lemma 3 shows that the combination of DP-GP-INFERENCE and COINPRESS-MEAN is ( , )-DP with respect to the combination of training and validation sets.
We then use the finite stopping variant of Algorithm 2 of Liu and Talwar (2019), which is ( tot, tot)DP by Theorem 3.4 of Liu and Talwar (2019) when applied to ( , )-DP inference-and-evaluation algorithm.

D DP-GP inference under heteroscedastic noise

Let us assume heteroscedastic observation noise with covariance n = diag(12, . . . , |2X|), where i2 is the observation noise variance associated with the ith observation (Xi, yi). The standard variational GP update rules in this setting are
m = KZZ KZX -n 1Y, S = KZZ KZZ ,  = (KZZ + KZX -n 1KXZ )-1. (36)

Corresponding A and B terms needed for DP are now

n
Ah = KZX -n 1Y = i-2kiyi,
i=1

n

Bh = KZX -n 1KXZ =

i-2kikTi .

i=1

(37)

Assuming i are bounded with i2  R, we can adapt the method to use the new versions Ah and Bh at the cost of increasing the sensitivity by a factor R.

These can be used to derive the heterogeneous noise DP-GP updates

mh = KZZ ~ h(Ah + E1), Sh = KZZ ~ hKZZ + S2, ~ h = (KZZ + (Bh + E2) + hI)-1, (38)
with corresponding noise correction terms making up S2,h:

S2,1,h = Cov[KZZ ~ hE1] = a2KZZ ~ 2hKZZ .

(39)

and

|Z |
S2,2,h = b2KZZ ~ hEii~ h(Ah + E1)(Ah + E1)T ~ hEii~ hKZZ
i=1

|Z|
+

|Z |

b2 2

KZZ ~ hEij ~ h(Ah + E1)(Ah + E1)T ~ hEji~ hKZZ

i=1 j=i+1

+ KZZ ~ hEji~ h(Ah + E1)(Ah + E1)T ~ hEij ~ hKZZ . (40)

Finally, the regularisation term  reduces to

h = b

|Z| log(2|Z|2/) |Z| + 1 . 2|Z |

(41)

13

