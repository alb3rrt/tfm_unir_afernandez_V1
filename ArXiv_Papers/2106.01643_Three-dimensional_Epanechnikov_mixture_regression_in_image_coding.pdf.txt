Signal Processing 185 (2021) 108090
Contents lists available at ScienceDirect
Signal Processing
journal homepage: www.elsevier.com/locate/sigpro

Three-dimensional Epanechnikov mixture regression in image codingR
Boning Liu a, Yan Zhao a,, Xiaomeng Jiang b, Shigang Wang a
a College of Communication Engineering, Jilin University, Changchun 130012, P. R. China b College of Mathematics, Jilin University, Changchun 130012, P. R. China

article info
Article history: Received 2 December 2020 Revised 19 February 2021 Accepted 22 March 2021 Available online 26 March 2021
Keywords: Epanechnikov kernel Epanechnikov mixture model Epanechnikov mixture regression Image coding Kernel method

a b s t r a c t
Kernel methods have been studied extensively in recent years. We propose a three-dimensional (3-D) Epanechnikov Mixture Regression (EMR) based on our Epanechnikov Kernel (EK) and realize a complete framework for image coding. In our research, we deduce the covariance-matrix form of 3-D Epanechnikov kernels and their correlated statistics to obtain the Epanechnikov mixture models. To apply our theories to image coding, we propose the 3-D EMR which can better model an image in smaller blocks compared with the conventional Gaussian Mixture Regression (GMR). The regressions are all based on our improved Expectation-Maximization (EM) algorithm with mean square error optimization. Finally, we design an Adaptive Mode Selection (AMS) algorithm to realize the best model pattern combination for coding. Our recovered image has clear outlines and superior coding efficiency compared to JPEG below 0.25bpp. Our work realizes an unprecedented theory application by: (1) enriching the theory of Epanechnikov kernel, (2) improving the EM algorithm using MSE optimization, (3) exploiting the EMR and its application in image coding, and (4) AMS optimal modeling combined with Gaussian and Epanechnikov kernel.
© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license
( http://creativecommons.org/licenses/by-nc-nd/4.0/ )

1. Introduction
Kernel methods have been widely applied in the artificial intelligence field such as computer vision [1] and pattern recognition [2]. The most common function in machine learning is the Gaussian Kernel (GK) [3], and the kernel methods provide tremendous application potential in other kernel functions. For example, correntropy has different properties when compared with secondorder statistics that can be very useful in non-Gaussian signal processing [4]. Graph signals can also be recovered through a kernelbased reconstruction of space-time function [5]. In the context of deep learning, using deep architectures to perform kernel machine optimization has been explored [6]. Recently, studies on using kernel methods have been extended for developing non-parametric kernels. A regression approach was proposed to extend the nonparametric kernel matrix to the corresponding kernel function [7].
In such a trend, research studies in image coding are also expanding to kernel regression frameworks. Among them, the most
R This work is supported by the National Natural Science Foundation of China (No.61631009, No.61771220) and the National Key R&D Program of China (2017YFB1002900, 2017YFB0404800).
 Corresponding author. E-mail addresses: liuboning_jlu@sina.com (B. Liu), zhao_y@jlu.edu.cn (Y. Zhao),
jxmlucy@sina.com (X. Jiang), wangshigang@vip.sina.com (S. Wang).

notable was the Steered Mixture-of-Experts (SMoE), a model-based approach proposed by R. Verhack [8]. In this model, it was assumed that image pixel values are instantiations of a non-linear random process that can be modelled by spatially piecewise stationary Gaussian processes. SMoE can be flexibly applied to the image and light field representation, processing, and coding [9]. Apart from 2-D image coding, SMoE has also been applied to 4-D light field images and 5-D light field video representation [10,11], which fully demonstrates the superiority of model-based coding in higher dimensions. Moreover, several studies were conducted to optimize the performance of SMoE. In [12], a Gradient Descent optimization using the Mean Square Error (MSE) of the regressed imagery was proposed. Based on MSE, the Gradient Descent optimization for the efficiency of different covariance representations has also been discussed in [13]. It has been proven that the SMoE regressed by SSIM loss can compete with JPEG2000 even for high bitrates [14]. After all, SMoE is a revolutionary approach for image compression that drastically departs from traditional pixel-based coding algorithms. However, a disadvantage of SMoE is the limitation toward kernel types. Therefore, we aim to propose a new kernel theory and its application in image compression by modeling.
The Epanechnikov Kernel (EK) is an excellent kernel function owing to its computational convenience and concentration of distribution [15]. This kernel function has achieved promising results in many machine learning applications. In a related work, 1-D

https://doi.org/10.1016/j.sigpro.2021.108090 0165-1684/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)

B. Liu, Y. Zhao, X. Jiang et al.

Signal Processing 185 (2021) 108090

Epanechnikov kernels were used to calculate the expected value of the irradiance estimators in photon mapping density estimation [16]. The EK can estimate function density in anomaly detection methods and can also be substituted for the GK of the Gaussian Mixture Model (GMM) to form an improved generalized fuzzy model [17,18]. The EK density estimation was selected for the moving foreground detection in the improved CAMShift object tracking [19]. However, its application is considerably limited when compared with the Gaussian function because of the imperfection of the theoretical framework. The reason for selecting the EK was its ease of calculation and the discontinuity, which is different from the GK. Owing to discontinuous function, EK is energy concentrated and its modeling results were found to be effective according to our experiments. Our EK-based coding framework is an improvement of the model type for SMoE.
In our previous work, we had developed a rudimentary study on image coding based on EK, which lacked a complete theory and coding scheme design [20]. In this paper, we utilize the theory of mathematical statistics and kernel density estimation to obtain a complete derivation of EK and its related statistics. We also deduce an accurate covariance-matrix expression of three-dimensional (3D) EK and its marginal distribution, conditional distribution and conditional mean, which are necessary for Epanechnikov Mixture Regression (EMR). Furthermore, our EK derivation in the mixtureof-experts provides for other kernels to be applied into regression theory. Under the Bayesian framework, images are modeled by local experts through Epanechnikov Mixture Models (EMMs) with global distribution and then the image can be reconstructed by parameters obtained from EMR, which is a stride from modeling theory to image coding.
The novelties of this paper are: (1) deduction of covariancematrix form of the 3-D EK and its correlated statistics; (2) improving the EM algorithm using MSE optimization; (3) proposing the 3-D EMR and using it in image coding; (4) Adaptive Mode Selection (AMS) combined EMR with GMR.
The remainder of the paper is organized as follows. Section 2 deduces the covariance-matrix form of the threedimensional Epanechnikov kernel and its correlated statistics. Section 3 presents the algorithm and visualization of EMR. Then, the modeling effect of EMR compared with GMR is discussed in Section 4. In Section 5, the proposed AMS algorithm with coding details is presented. Experimental results are detailed in Section 6. Finally, conclusions and future work are stated in Section 7.
2. Correlated theories of 3-D Epanechnikov kernel
2.1. Motivation of the kernel selection
The precondition of SMoE is that image pixels are instantiations of a non-linear and non-stationary random process which can be modeled by GMMs. We explore the possibility of image modeling based on mixture models of other kernels. We select Epanechnikov Kernel (EK) because it is discontinuous, which can make its distribution on a central domain and better simulate the functional influence. Moreover, EK can be easily calculated compared to other triple, quartic, and even cos-form functions. Therefore, under the same assumption as SMoE, we break the limitation of the model type and design Epanechnikov Mixture Models (EMMs) to accomplish the regression.
2.2. Mixture-of-Experts based on Epanechnikov mixture models
In our work, we define variable x, y, and z as abscissa value, ordinate value, and gray value of each pixel in an image, respectively. As for the formula expression in this section, we define
 = (x, y, z)T and  = (x, y)T .

Under the Bayesian framework, we assume that image pixels are modeled as local experts with global distributed 3-D EK, in which the distribution of each EK is global but discontinuous, and thus actually simulates local support. The mixture of Epanechnikov distribution is represented as

K

p() =  j fj, j (),

(1)

j=1

where  j is the prior corresponding to Kj=1 j = 1. fj, j () is the 3-D EK whose parameters are  j and j.  j=(Xj , Yj , Z j )T and ^ j=(Xj , Yj )T are the mean values of the variables for the jth expert. The covariance matrix ofthe variables for the

X j X j

X j Y j

X j Z j

jth expert is j= YjXj

Y j Y j

YjZ j , within which R j=

Z j X j

Z jYj

Z j Z j

X j X j

XjYj . Therefore, parameter set of the jth mixture

Y j X j

Y j Y j

model is j =  j,  j, j .

The regression foundation is the Mixture-of-Experts (ME), in

which every expert mj,

()
j

and

its

gate

function

g^ j,R j, j ()

co-

operate with each other [21,22]. m() indicates the expected gray

value towards each pixel, from which we reconstruct the decoded

image with the parameter sets j =  j,  j, j , j = 1, 2, . . . , K.

K

m~  =

  g^ j,Rj,j

mj, j ,

(2)

j=1

Therefore, to use (2) for regression, we have to determine the

expression

of

3-D

EK

f j ,

(  ) ,
j

gate

function

g^ j,R j, j (),

and

conditional mean mj,

(), which are shown in Section 2.2.1, Sec-
j

tion 2.2.2, and Section 2.2.3, respectively.

2.2.1. 3-D Epanechnikov kernel
In order to use the model for our compression method, we need
to obtain the general function of 3-D EK with respect to the mean
vector  j and covariance matrix j. We determine the expression of 3-D EK according to the principle that a kernel function K(x) must satisfy K(x)dx = 1 and K(x) 0 [23]. For calculation con-
venience, we begin with a basic ellipsoid form in (3) with axial
lengths a, b, and c,

f^(^ ) =

k 1 - ^T
0 ,

2^ ,

^T 2^  1
otherwise.

(3)

where ^ = (x^, y^, z^)T represents the variables in this coordinate sys-

tem. k is the undetermined coefficient for normalization. =

diag (

1 a

,

1 b

,

1 c

) .

The integral of f^(^ ) over its distribution domain is 1, from

which we can obtain

k

1 - ^ T 2^ d ^ = 1, ^ : ^ T 2^  1 .

(4)

 ^

From Appendix A, it can be observed that
1 - ^T 2^ d ^ = (8 )/(15| |). As such, we can cal-

 ^
culate the undetermined coefficient k as k = (15| |)/(8 ) and the
3-D EK expression with a basic ellipsoid form is

f^(^ ) =

15| | 8 

1 - ^T

2^ ,

^T 2^  1

(5)

0 ,

otherwise.

We define the covariance matrix of f^ ^ as ^ , whose calculation
is detailed in Appendix B. From Appendix B, it is known that ^ =

2

B. Liu, Y. Zhao, X. Jiang et al.

Signal Processing 185 (2021) 108090

1 7

(

-1 )2, therefore we can get

f^ ^ =

15| | 8 

1

-

^ T

·

1 7

^

-1

·

 ^

,

1 7

^ T

^

-1^



1

(6)

0 ,

otherwise.

Next, we focus on determining the general form of 3-D EK. Be-
cause the scale change has been included in f^(^ ), we consider
a linear transformation including translation and rotation in (7).
The translation distance is  j=(Xj , Yj , Zj )T and the orthonormal matrix is U , which satisfies U -1 =U T and det(U ) = 1.

^ = U ·  -  j .

(7)

Substituting (7) into (5), we obtain the general form of 3-D EK with respect to the linear transformations as follows:

f^(U  -  j )

=

15| | 8 

1 -

- j TU -1

2U -j

,

0 ,

- j TU -1 2U - j  1
otherwise.

(8)

The general form of covariance matrix is j . Because the general form is acquired by a variable transformation in (7), the co-
variance matrix is

1 7

-1 j

=

U -1

2U .

(9)

From (9), we find | | = 1/( 73| j|) and the general form of three-dimensional Epanechnikov kernel respect to  j and j is

f j,

15
()= 8 |73
j

j |

1-

1 7

- j T

-1 j

- j

,

0 ,

1 7

- j T

-1 j

- j

1 (10)

otherwise.

The Cholesky decomposition of the covariance matrix is also deter-

mined:

j

=

1 U -1 7

-1 2U =

1 

U T

-1

7

T

1 

U T

-1

.

7

(11)

2.2.2. Gate function of 3-D EMM
The gate function g^ j,R j,j () is a normalized mixing weight

 g^ j,R j,j

=

 jF^ j,Rj 

  K
j=1

j F^ j , R j

,

(12)

in which F^ j,R j () is the marginal distribution of fj,R j (). Because the distribution of gray level z at each position  is inde-
pendent of each other, F^ j,Rj () can be obtained through

+ 

 F^ j , R j

=

fj,

()dz.
j

-

(13)

To calculate the integration by variable substitution, we define

that

' = x', y', z' T =  -  j, ' = x', y' T =  - ^ j.

(14)

Then, the integral turns out to be

F0,Rj ( ) =

+ 
f 0 ,
-

( )dz =
j

z 2
z1 8

15
7 3 |

1- 1 T j| 7

-j 1  d z ,
(15)

in which z1 and z2 can be solved from the two endpoints of

1 7



T

-1 j



=

1 .

To simplify the calculation, we represent the inverse of the co-

variance matrix as

X j X j

X j Y j

-1 X j Z j

a b c

-1 j

=

Y j X j

Y j Y j

Y j Z j

= b d e .

Z j X j

Z jYj

Z j Z j

c e  f

(16)

Therefore, we obtain

1 (x , y , z )
7

-1 j

(x

,

y

,

z

)T= 1

(17)

 f z 2 + 2 cx + ey z + (ax 2 + dy 2 + 2bx y - 7) = 0. (18)

Hence, we solve the equation (18) and obtain the solutions as

z 1

=

-(c x

+ e y f


)- t

,

z 2

=

-(c x

+ e y f


)+ t

(19)

in which

t = (cx + ey )2 - (ax 2 + dy 2 + 2bx y - 7) f .

(20)

Finally,

when

1 7



T

-1 j



 1,

the

integral

in

(15)

becomes

 | |   | | F0,Rj

' = 15
8 73

j

z2' z1'

1

-

1 7

' T

-1 j

' dz' = 15
8 73

3

· 4t 2

j

21 

2 f

3

( )| | ( ) = 15 | | 8 73

· 4|

j |

1 2

7|R j |- x' ,y'

R j R-j 1 x' ,y' T

2

21|R j |2

j

3

=5 ·
14 |Rj|

1-

1 7

'

T

R -j 1

'

2
.

(21)

Therefore, the general form of the marginal distribution is

 F^ j,Rj 

 5 = 14 |Rj|

1

-

1 7

 - ^ j

T R -j 1

 - ^ j

0 ,

3

2
,

1 7

 - ^ j

T R -j 1

 - ^ j

1

otherwise.

(22)

2.2.3. Conditional mean

Because the distribution of z is independent at each location ,

we conclude the conditional distribution of z| as ej,

(z|):
j

 | ( ) ej, j z

= fj, j ()
F^ j , R j 

   

3 4

= 

|R j | | j|

( ) ( ) 1-

1 7

- j T

-1 j

- j

3

( ) ( ) 1-

1 7

-^ j

T R -j 1

-^ j

2
,

1 -

1 7

 - j

T

×

-1 j

 - j

1

0 ,

otherwise.

(23)

Combined with (14), the conditional mean of z in the condition of
 is

+ 

+ 

m 0 ,

( )=
j

ze j,

(z|)dz =
j

(z +Zj )e0,

(z | )dz
j

-

-

(24)

We use (19) to obtain the following integral:

m 0 ,

j ( ) = Zj +

z 2
z e0,

z 1

(z
j

| 

) d z

= Zj +

z 2
z

z 1

f 0 , F0,R

j j

( (

) )

d z

   =

Zj +

z 2
z

15
8 73|

j |

1

-

1 7

T -1 j
3

d z

z 1

15
8 73|

j

|

·

4t 2

21 

2 f

= Z j +

21 

2 f

4

t

3 2

·

z 2
z
z 1

1- 1  T
7

-1

d z

= Z j -

c x

+
f

e y

.

(25)

According to (16), the result of the conditional mean can be formulated as

 mj, j

=

Z j

-

(c, e)  f

-

j

= Z j

  + ZjXj , ZjYj R-j 1 - ^ j .

(26)

3

B. Liu, Y. Zhao, X. Jiang et al.

Signal Processing 185 (2021) 108090

3. 3-D Epanechnikov mixture regression 3.1. Representation and optimization
We design the EMR in Algorithm 1 to estimate the parame-

Algorithm 1 Epanechnikov Mixture Regression (EMR).

1: Initialize matrix dataN×3 using Kmeans algorithm into K clus-

ters, whose parameters are 1 = ( j1, j1,  j1 ), j = 1, 2, . . ., K.

2: Substitute 1 into (2) and obtain the initial modeled block Z^1.

Then,

we

can

obtain

MSE(1)

=

1 N

N i =1

(zZ^1

i

-

zZ^0

) 2 .
i

3: for t = 2 : 8

4: Update Qti j, i = 1, 2, . . ., N, j = 1, 2, . . ., K using (27).

5: for j = 1 : K

6:

Update jt =

N i =1

Q

t i

j

 i

N i =1

Qti

j

,

jt =

 Ni=1 Q ti

j

(i- j)T

N i =1

Qti

j

(i

-

j )

,

jt =

N i =1

Q

N

t i

j .

7: end

8: Substituting t = ( jt , jt ,  jt ), j = 1, 2, . . ., K into (2), we

can

obtain

MSE(t )

=

1 N

N i =1

(zZ^t

i

-

zZ^0

) 2 .
i

9: end

10: t0 = find (MSE == min(MSE))
11: Output t0

ters of EMM for optimizing the gray value in each image pixel. We
model the Y, U, and V channels of a color image separately. As for
a certain channel, it is assumed that the total number of channel
pixels is N and the ith pixel is denoted as (xi, yi, zi ), in which xi, yi,
and zi represent the X-coordinate, Y-coordinate, and gray value of the pixel, respectively. We represent each channel this way to pre-
pare for modeling the next step. Therefore, we can represent the
data of each channel as an N×3 matrix as dataN×3 and then we use Kmeans++ Clustering [24] to initialize dataN×3 into K models
whose parameters are 1 = ( j1, j1,  j1 ), j = 1, 2, . . . , K.
We apply the M-step of the Expectation-Maximization (EM) al-
gorithm [25] of GMM in Step 6 of Algorithm 1 to iterate for the
optimal EMM parameters. The core of E-step is the posterior prob-
ability

Qtij = P( j|i) =

j
K j=1

fj
j

, j (i ) fj, j (i

)

.

(27)

Unalike the original EM algorithm, we do not use the log-
likelihood for regression. In this study, we measure the Mean Square Error (MSE) between the recovery Z^t in (2) and the original image block Z^0 for each iteration of parameters and select the parameter set with the minimum MSE. zZ^0 i in Algorithm 1 indicates the gray value of the ith pixel in block Z^0, and zZ^t i indicates the gray value of the ith pixel of the tth iteration block Z^t .
The two EM optimization algorithms are shown in Fig. 1, and it
shows that the MSE based algorithm has better performance and
consumes less time compared to the log-like-based optimization.
This is because our MSE based algorithm directly selects the re-
constructed image according to the error to the original one and
there is also no time loss for calculating the log-like probability.

3.2. Theoretical visualization of regression
We select a 32×32 block of Lena modeled by nine kernels using EMR and GMR for visualizing the kernel comparison examples in Fig. 2. To ensure that the experiments are fair, we implement the mixture regression of GMM identical to Algorithm 1 only by

substituting (27) with

Qtij = p( j|i ) =

j

·

 1
(2 )3|

exp
j |

-

1 2

(i

-  j )T

-1 j

(i

-



j

)

 K
j=1

j

·

 1
(2 )3|

exp
j |

-

1 2

(i

-  j )T

-1 j

(i

-

j )

.

(28)

Fig. 2(d) outlines the continuous probability distribution in (1), in

which the nine ellipsoids represent the nine models with Epanech-

nikov distribution. Compared to GMM in Fig. 2(g), EMM has a

tighter correlated distribution.

The concentrated-distribution ellipsoids of EMM can enhance

the correlation of regression. According to (2), the two essential

statistics for the image reconstruction are: the conditional mean

m j,

()
j

and

gate

function

g^ j,R j, j ()

of

each

Epanechnikov

ex-

pert, which can be respectively visualized through (26) and (12).

Conditional means mj,

(),
j

j = 1, 2, . . . , 9 of EMR are shown as

nine linear mean planes in Fig. 2(e), whose slope is steeper than

that of the GMR in Fig. 2(h). The reason is that the EK function is

locally simulated, whereas GK has a flat long tail of distribution.

Therefore, the covariance matrix of EK may be more extreme and

then the gray value has a shaper change according to (26). The top

view of g^ j,R j,j (), j = 1, 2, . . . , 9 is shown in Fig. 2(f), in which
the distinct borders of each gate function of EMR can be seen,

whereas the gate function of GMR shown in Fig. 2(i) is smooth.

This reflects that the discontinuity of EK-based function simulates

the local support of gate function, which makes the reconstructed

image of EMR clearer than that of GMR.

4. EMR Modeling representation

In this section, we analyze the modeling effects of the two kernels by conducting experiments. The EMR is in Algorithm 1 and the optimization framework of GMR has been the same with EMR as mentioned in Section 3.2. In this part of the experiments, we model an image block using EMR and GMR under the blocksizes of 16×16, 32×32, and 64×64 using different quantities of models. In addition, we estimate the bit consumption of a single kernel towards different blocksizes, which is shown in Table 1. The statistics, which are the same for EMR and GMR, are obtained from hundreds of image pieces with accurate quantization and the reconstructed block is nearly the same as the modeling result. The modeling results in Fig. 3 include bit-SSIM curves and comparison examples.
Examples for modeling results using eight 256 × 256 image blocks are shown in Fig. 3. The ranges of SSIM are slightly different for each image result because some images contain much high frequency contents, whereas others are flat, and the different numbers of models is another reason. From Fig. 3, we can see that EMR shows better performance over GMR at 16×16 blocks based modeling, and EMR16 is always the best of all. If the number of experimental models is increased, the improvements of image quality will be saturated, which is shown in Fig. 3 (d). These results confirm the theoretical conclusion described in Section 3.2: the discontinuity of EMR simulates the local effect of modeling; therefore, the smaller blocks have better performance, whereas the modeling of larger blocks cannot be well correlated.
As for the running speed of both kernels, we present the sum of modeling and reconstruction times of Butterfly as an example. If the number of models for each 16×16 block is 11, the total time consumed by the entire image is 9.87 s and 10.89 s for EMR and GMR, respectively. For 32×32 based modeling, if the number of models is 38 for each block, the total run time is 21.05 s and 20.44 s for EMR and GMR, respectively. The modeling of the entire image based on a 64×64 block requires 170.00 s and 181.17 s by EMR and GMR, respectively, when we use 144 models in each

4

B. Liu, Y. Zhao, X. Jiang et al.

Signal Processing 185 (2021) 108090

Fig. 1. Average SSIM and time consuming comparing among three EM optimization algorithms for a certain block of size 16 × 16, 32 × 32, and 64 × 64. Our MSE-based EM algorithm is the optimal one.

Fig. 2. Experimental results modeled by EMR and GMR together with the regressing visualization.

Table 1 Bits Consumption Towards Three Blocksizes of EMM/GMM.

Blocksize Xj Yj Zj

X j X j

X j Y j

X j Z j

Y j Y j

Yj Zj  j bits/kernel

16 × 16

4

4

8

6

7

10

6

10

7 62

32 × 32

5

5

8

8

9

11

8

11

7 72

64 × 64

6

6

8

10

10

12

10

12

7 81

5

B. Liu, Y. Zhao, X. Jiang et al.

Signal Processing 185 (2021) 108090

Fig. 3. Modeling results. The numbers of models used for bit-SSIM curves are marked at each sub-caption.

block. Therefore, the speed is similar for both kernels and the smaller block pattern is more efficient.
5. Coding framework
As shown in our schematic diagram in Fig. 4, a color image is encoded in Y, U, and V channels separately, within which the U and

V channels are downsampled once in both directions into UD and
VD. , the same for Y and U/V channel, is the Lagrange parameter
in (29) which we use to control the adaptive modeling. To real-
ize a smooth transition from adjacent blocks, we implement the
Adaptive Mode Selection (AMS) algorithm with overlapping blocks
referenced in [9], and we set that the width as OLY for the Y channel, and OLUV for the U/V channel. As for a certain channel at

6

B. Liu, Y. Zhao, X. Jiang et al.

Signal Processing 185 (2021) 108090

Fig. 3. Continued

a certain , different sizes of blocks have the same overlapping
width.
In the decoder, the reconstructed UDr and VDr are de-blocked and upsampled into Ur and Vr just by replicating the adjacent pixel in a row or column.

5.1. Adaptive mode selection
We use the EMR and GMR mentioned in Section 4 to design the AMS algorithm and to determine an optimal mode of coding, whose goal is to achieve the optimal coding mode satisfying the balance between image distortion and bitrates. As for the coding

7

B. Liu, Y. Zhao, X. Jiang et al.

Signal Processing 185 (2021) 108090

Fig. 4. A schematic diagram of our coding framework.

Fig. 5. R-D curves of EMR and GMR based coding respectively towards 16 × 16, 32 × 32 and 64 × 64 blocks. The black dotted line is the probable critical point of R.

mode in our framework, each 64 × 64 block can be divided into 32 × 32 and 16 × 16 units encoded by either GMR or EMR with an adequate number of models.
Using J in (29), our AMS algorithm selects the mode corresponding to the minimum J. The specific task is to minimize the distortion D subject to a selected bit rate R for an image block of a particular size. The constrained problem turns out to be an un-
constrained one and we aimed at determining a reasonable  to
minimize the value of J expressed in (29) by using the Lagrange multiplier method.

J = D + R,

(29)

in which  = -D/R is the negative slope of the R-D curve, which
represents the Lagrange multiplier. D is the squared error, and R is the total number of bits.
The bits consuming of accurate modeling for each kernel is 62, 72, and 81 towards 16×16, 32×32, and 64×64 blocks, respectively, as shown in Table 1. We can then use thousands of image pieces to estimate relatively accurate R-D curves as shown in Fig. 5, from which we estimate the critical bitrate. The critical bitrate is a bitrate value that can satisfy the balance we want to achieve between image distortion and bit consumption, which is marked as a black dotted line in Fig. 5. As for 16 × 16, 32 × 32, and 64 × 64 blocks, we first set the approximate critical bitrate to be 248, 720, and 1296 bits, respectively, equivalent to the maximum number of models iterations to be 248/62 = 4, 720/72 = 10, and 1296/81 = 16. Therefore, we set the upper limit of number of
models to (n64, n32, n16) of Y channels as 16, 10, and 4. Moreover, the upper limit (n64, n32, n16) of U and V channels is set as 8, 4,
and 4. The pseudo-code of AMS is given in Algorithm 2, in which
J represents the J-values of the modeled block regressed by Epanechnikov or Gaussian kernel with different numbers of models, that is, JE3 in Step 2 denotes J-value of 64 × 64 block modeled by Epanechnikov kernel using three models. Notably, the D in (29) is calculated without the added overlapping parts. Our algorithm iterates over all the cases through nested loops and the final result is produced by filtering the optimal result of each loop according to the minimum value of J. The mode includes block size, kernel type, and the number of experts drawn through command f ind from matrix J. From the conclusion detailed in Section 4, we just model the 16×16 and 64×64 blocks using EMR and GMR, re-

Algorithm 2 Adaptive Mode Selection: AMS (n64,n32,n16).

1: Input: 64 × 64 image block A, a target 

2: J= JE1 JE2 JE3 · · ·JEn64 and J64= minJ, mode64= find(J==J64 )
3: for Ai, i = 1 : 4 (Divide A into 4 32 × 32 blocks (A1 to A4))

4:

J =

JE1 JE2 JE3 · · ·JEn32 JG1 JG2 JG3 · · ·JGn32

and J32i= minJ, mode32i= find(J== J32i )

5: for Ai j, j = 1 : 4 (Divide Ai into 4 16 × 16 pieces (Ai1 to Ai4))

6:

J= JE1 JE2 JE3 · · ·JEn16 and J16i j= minJ, mode16i j= find(J==J16i j )

7: end

8:

Compare

4 j=1

J 16 i

j

with

J32i ,

which

are

respectively

cor-

responding to

mode16i1 mode16i2 mode16i3 mode16i4

and mode32i . The smaller

value is set as J32i and the corresponding modes are recoded as

mode32i . 9: end

10: Like Step 8, we pick up the mode between

mode321 mode322 mode323 mode324

and mode64 by choosing the smaller one between

4 i =1

J32i

and

J64 .

11: Output: Parameters of the optimal mode of modeling combi-

nation.

spectively. However, we make a selection between EMR and GMR at the 32×32 based condition because of the comparable effect. Examples of mode selection are shown in Fig. 6, and the model distribution under different conditions can be observed.
5.2. Coding of modeling parameters
A certain image has a header that contains marks of the min-
imum value and span of all the parameters except  j, the angle of eigen-decomposition in (30).  j does not require a header mark
because its range is certainly [-90, 90]. Therefore, for a certain Y, U, or V channel, a header has 3×3×7×2×8 = 1008 bits (3 channels, 3 blocksizes, 7 parameters with 2 marks and 8 bits each).
As for the encoding within each block, there is a Flag which determines the blocksize (B), number of models (NM), and the kernel type (EG). There is another portion of Parameters encoded as nP according to different blocksizes. The bits for flag and parameters of

8

B. Liu, Y. Zhao, X. Jiang et al.

Signal Processing 185 (2021) 108090

Fig. 6. Optimal mode selection examples of our AMS towards Y-channel ( = 100). The green numbers represent the number of models of EMR and the red ones represent
GMR. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)

Table 2 Bits Allocation of Parameters of a Certain Kernel for Different Blocksizes: B is encoded as 11 (16 × 16), 10 (32 × 32) and 0 (64 × 64). nNM of different blocksizes depends on the upper limit of the number of models (n16, n32, and n64). EG is encoded as 1 for EK as well as 0 for GK.

Condition

Kernel Bits Allocation

NM B

Flag nF (bits)

Parameters nP (bits)

n B

nNM

nEG

nXj

nY j

nZj

n j

n e 1 j

n e 2 j

n X j Z j

n YjZj

Y

16×16 2

2

- 3

3

5

4

4

4

4

4

>1

32×32 2

4

1 4

4

5

4

5

5

4

4

64×64 1

4

- 5

5

5

4

6

6

4

4

16×16 2

2

- -

-

5

-

-

-

4

4

=1

32×32 2

4

- -

-

5

-

-

-

4

4

64×64 1

4

- -

-

5

-

-

-

4

4

U/V

16×16 2

2

- 2

2

4

3

3

3

-

-

>1

32×32 2

2

1 3

3

4

3

4

4

-

-

64×64 1

3

- 4

4

4

3

5

5

-

-

16×16 2

2

- -

-

4

-

-

-

-

-

=1

32×32 2

2

- -

-

4

-

-

-

-

-

64×64 1

3

- -

-

4

-

-

-

-

-

a certain kernel, which are called as kernel bits, are presented in Table 2.
RY , RU , and RV in Fig. 4 are all combined with the header bits and the kernel bits of each channel. For each channel, all of the quantized data of each parameter for a certain blocksize is encoded using the Adaptive Arithmetic Coding (AAC) [26].
Table 2 shows the details of bits allocation of a certain kernel towards different blocksizes. In Table 2, if a B code 0 or 10 appears, there will be NM models encoded as nP in Table 2. If a B code 11 appears, there will be four 16 × 16 blocks encoded as
(nNM + nEG ) + nP × NM, only the first of which requires the B mark.
For quantization of U and V channels, XjZ j and YjZ j are set to be zero. Coding details of the parameters are discussed in the following sections.

5.2.1. Eigenvalue decomposition of position matrix

As for the 2 × 2 covariance matrix R j, two eigenvectors V2×2 =

V 11 V21

V12 V22

and two eigenvalues e1 j , e2 j are obtained through

eigen-decomposition. According to [8], the covariance matrix can

be implemented by encoding e1 j , e2 j , and  j which is the angle of
principal eigenvector towards the positive X-axis.

Angle  j corresponds to the smaller eigenvalue between e1j and
e2 j denoted as ea j , so it is drawn from

j

=

arctan V2a V 1 a

,

(30)

from which angle  j is known to be ranging from -90 to 90 based on our sufficient experiments. Moreover, the prior  j does

not need to be encoded and is estimated by

j =

1 NM

+

e1 j e2 j

NM i =1

e 1 i

e 2 i

/ 2 .

(31)

5.2.2. Special case of a single-kernel block If a block is optimally represented by one model, it can be re-
covered equally well by using either Epanechnikov or Gaussian regressions. The reason lies in the particularity of the EM algorithm under the case of one model in Algorithm 1. After the initialization
of mean value matrix 1 and covariance matrix 1 of the original
image data, we can then obtain the result of posterior probability Qti j (E-step) utilizing Equation (27) and (28). When the number of kernels j = 1, then Qti1 = 1 and M-step turns out to be

1 =

N i =1
N

 i

,

1 =

N i =1

(  i

-

1 )T
N

(  i

-

1

)

,

1 = 1. (32)

In this case, the iteration results are only related to the samples
i, i = 1, . . . , N. Therefore, we do not use any bit to tell the model
type under such a case, and without loss of generality, we model
the 16 × 16 blocks by EK while 32 × 32 and 64 × 64 by GK.
As for a certain block size, the 2-D position samples i, i = 1, . . . , N are determined, thus the position mean value ^ j and po-
sition covariance matrix R j are determined. Only the gray value zi,
i = 1, . . . , N are different. Therefore, only X1Z1 , Y1Z1 and Z1 are
encoded as shown in Table 2.

5.3. Parameter decoding
At the decoder, parameters are approximately recovered from the encoded bitstream. With e1j as an example, k is the encoded

9

B. Liu, Y. Zhao, X. Jiang et al.

Signal Processing 185 (2021) 108090

Fig. 7. An example of overlapping reconstruction of four 64×64 blocks of Y channel. The blue blocks represent the core contents and the pink borders represent the overlapping width. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)

Fig. 8. Examples of our method, JPEG2000, and JPEG, together with the bpp-SSIM map. The bpp and SSIM of the chosen images are marked below.

bit representation of the original eigenvector e1j , which can be reconstructed as follows:

e1j [k]

=

M e 1

+

(k

-

1)

·

E e 1 2ne1 j -

, k 1

=

1, 2, · · ·

, 2ne1 j

,

(33)

in which Me1 and Ee1 represent the minimum and span of e1 j . With all the decoded parameters, modeled image Ip can be restored through (2).
After the images are reconstructed, the border merging is necessary. The implement of AMS has included the overlapping pixels; therefore, the reconstruction can realize a smoother transition from block to block. According to Fig. 7, the reconstruction is based on merging the overlapping border in proportion.
After the blocks are reconstructed, we implement a Deblocking algorithm to further weaken the block artifact. The deblocking is done for all the block borders by copying the boundary pixels and

overlapping in proportion. For Y, the duplicate pixel width is 2 for
16×16 block. As for 32×32 block, it is 3 when  > 800, 2 when   800. As for 64×64 block, the width is 5, 3, and 2 for  > 800, 100 <   800, and   100. In addition to U and V, the width is 2
for 16×16 block and for 32×32 and 64×64 block, is respectively 3
and 6 when  > 200, 2 and 4 when   200. A Block-matching and 3D filtering (BM3D) algorithm [27] is finally added, with  = 15 for Y and  = 20 for U and V.
6. Experimental results
We compare the reconstructed results of some of the test images in case of specific bits with JPEG and JPEG2000 in Fig. 8 and Fig. 9. The test images of our experiments are derived from the DIV2K dataset [28]. In our algorithm, different bit consumption is
realized by adjusting , which is chosen from 50000, 10000, 3200,

10

B. Liu, Y. Zhao, X. Jiang et al.

Signal Processing 185 (2021) 108090

Fig. 9. Comparison bpp-SSIM maps of other images among ours, JPEG and JPEG2000. I23 and I38 are 1024×768, I44 is 768×1024, and I45 is 1024×576. Others are of 1024×704.

800, 400, 100, and 20 from low to high bit rates in our exper-
iments. If  < 100, we obtain the encoding results by increasing
the bits of each parameter based on Table 2. As for the setting
of overlapping border, if >3200, OLY = 6, OLUV = 8; if 400<3200, OLY = 4, OLUV = 5; if 100<  400, OLY = 2, OLUV = 3; if 100, OLY =1,
OLUV =2. The JPEG is implemented with QF=2, 5, 8, 10, 12, and 15. As for JPEG2000, the input bpps are setted at 0.005bpp, 0.02bpp, 0.05bpp, 0.1bpp, 0.15bpp, 0.2bpp, and 0.25bpp. All of the experiments using different algorithms are implemented using Matlab 2017b.
From the four test images in Fig. 8, we show the specific image results. The bpp-SSIM curves of other images are shown in Fig. 9.
The bpp-SSIM maps show that our method considerably outperforms JPEG and can also approach JPEG2000 at lower bitrates. At low bitrates, our method can achieve a competitive visual effect over JPEG below 0.25bpp with only 10% - 20% of bits consumed. Additionally, the SSIM is generally up to 0.85, which demonstrates superior compression performance for low reconstruction qualities, compared to JPEG. As the number of consumed bits increases, the effect of our method flattens out. From the images, it can be seen that our reconstructed images are smooth and color adaptive, which is suitable for human vision.
However, our framework is not pixel-based, which may bring a great property in low bitrates and has less block effect compared with JPEG, but the reconstruction is also lacking details in contrast to the JPEG2000. At high bitrates, the high-frequency information may become necessary, therefore our modeling-based method is less competitive compared with transform-based algorithms when the bpp becomes larger.
Regarding the consumption of time, our framework is implemented using an Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz. The computational runtime for a single image is about one hour. A total of 16.7% of the time is spent on the U and V channels. The most time-consuming step is the K-means++ initialization.
7. Conclusion and future work
In conclusion, our EK and its correlated theory perform well in image coding especially in smaller blocks because the EK has a strong discontinuity, which enhances local support. This is also probably the reason that as the number of models increases, the close interaction between the models makes the EK more dominant than the GK. Our framework is an entirely modeling-based

algorithm combined with EMR in smaller blocks, GMR in larger ones and a kernel selection is made for the middle-size blocks. Therefore, the proposed AMS algorithm can successfully leverage the two kernels. In essence, the framework enriches the practical significance of Epanechnikov kernel in image coding, which is an extension of Gaussian-only kernels in modeling-based compression.
The 3-D EK we deduced jumps out of the common usage of GK and provides more possibilities for applications of different models. The derivation process in this paper can be used as a reference for other kernel functions to be applied to regression modeling in the future. Our model-based image coding algorithm does not perform well at high bit rates, which can be optimized in the future. The optimization theories of EMR also need to be explored in order to anticipate with those new-developed SMoE algorithms. However, the goal of this paper is only to show the potential of using the EK in the application of image coding. We are looking forward to more applications for other fields based on Epanechnikov-correlated theories.

Declaration of Competing Interest
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

Appendix A. Triple integral details of
1 - ^T ^ d ^ , ^ : ^T ^  1
 ^

In order to compute a triple integral, we need to convert the
variable of standard coordinates (x^, y^, z^) to that of spherical coordinates (r,  , ), 0  r  1, 0    2 , 0    

x^ = ar sin  cos  y^ = br sin  sin  z^ = cr cos 

(A.1)

and

x^ x^ x^

J

=

 (x^, y^, z^)  (r,  , )

=

r  y^ r  z^

  y^   z^



 y^ 

= abcr2 sin .

 z^

r  

(A.2)

11

B. Liu, Y. Zhao, X. Jiang et al.

Thus, the integral turns out to be

1 - ^T ^ d ^

^ :^T ^1

x^2 y^2 z^2

=

1 - a2 + b2 + c2 dx^dy^dz^

x^2 a 2

+

y^2 b 2

+

z^2 c 2

1

= abc

2 
d 
0


d 
0

1 0

1 - r2

r2 sin dr =

8 abc
15

=

8  15 |

| .

(A.3)

Appendix B. Calculation of ^

X^ , Y^ , and Z^ are the random value of x^, y^, and z^, therefore the

covariance matrix of unit-sphere EK is





Cov X^ , X^ Cov X^ , Y^ Cov X^ , Z^

^ = Cov Y^ , X^ Cov Y^ , Y^ Cov Y^ , Z^ .

(B.1)

Cov Z^, X^ Cov Z^, Y^ Cov Z^, Z^

We take the calculation of Cov(X^ , X^ ) as an example: Cov X^ , X^ = E X^ 2 - E2 X^ .

(B.2)

Because the distribution of f^(^ ) is even symmetric about the
origin of the coordinate system. Firstly, we can get the result of
E(X^ ) easily:

E(X^ ) =

x^· f^(^ )dx^dy^dz^

15

=

x^ · 8

x^2 a 2

+

y^2 b 2

+

z^2 c 2

1

1 -

x^2 y^2 z^2 a2 + b2 + c2

dx^dy^dz^ = 0

(B.3)

Next, we can figure out E(X^ 2) according to (A.1) and (A.2).

E X^ 2

=

x^2

·

15
8 

1 -

x^2 y^2 z^2 a2 + b2 + c2

dx^dy^dz^

x^2 a 2

+

y^2 b 2

+

z^2 c 2

1

=

15
8 

2 
0

d 


0

d 

1 0

a 2

( r

sin



cos



) 2

1 - r2

r2 sin dr =

a 2 7

(B.4)

Thus, Cov(X^ , X^ ) = a2/7. Similarly, we can know Cov(Y^ , Y^ ) = b2/7,

Cov(Z^, Z^) = c2/7,

Cov(X^ , Y^ ) = Cov(Y^ , X^ ) = 0,

Cov(X^ , Z^) =

Cov(Z^, X^ ) = 0, Cov(Y^ , Z^) = Cov(Z^, Y^ ) = 0. Therefore,

^ = 1 diag a2, b2, c2 = 1 -1 2.

7

7

(B.5)

Supplementary material

Supplementary material associated with this article can be found, in the online version, at 10.1016/j.sigpro.2021.108090

CRediT authorship contribution statement

Boning Liu: Conceptualization, Methodology, Software, Validation, Formal analysis, Visualization, Writing - original draft, Investigation. Yan Zhao: Resources, Writing - review & editing, Project administration, Funding acquisition. Xiaomeng Jiang: Validation, Formal analysis, Investigation. Shigang Wang: Resources, Funding acquisition.
References
[1] C.H. Lampert, Kernel methods in computer vision, Foundations and Trends in Computer Graphics and Vision (2009).

Signal Processing 185 (2021) 108090
[2] J.K. Pillai, M. Puertas, R. Chellappa, Cross-sensor iris recognition through kernel learning, IEEE Trans. Pattern Anal. Mach. Intell. 36 (2014) 73­85, doi:10.1109/ TPAMI.2013.98.
[3] C.E. Rasmussen, C.K.I. Williams, Gaussian processes for machine learning, MIT Press, 2005.
[4] W. Liu, P.P. Pokharel, J.C. Principe, Correntropy: properties and applications in non-gaussian signal processing, IEEE Trans. Signal Process. 55 (11) (2007) 5286­5298.
[5] D. Romero, V.N. Ioannidis, G.B. Giannakis, Kernel-based reconstruction of space-time functions on dynamic graphs, IEEE J. Sel. Top. Signal Process. PP (99) (2016). 1­1
[6] H. Song, J.J. Thiagarajan, P. Sattigeri, A. Spanias, Optimizing kernel machines using deep learning, IEEE Trans. Neural Netw. Learn. Syst. (2018) 1­13.
[7] B. Pan, W.S. Chen, B. Chen, C. Xu, J. Lai, Out-of-sample extensions for non­ parametric kernel methods, IEEE Trans. Neural Netw. Learn. Syst. 28 (2) (2016) 334­345 .
[8] R. Verhack, T. Sikora, L. Lange, G.V. Wallendael, P. Lambert, A universal image coding approach using sparse steered mixture-of-experts regression, in: IEEE International Conference on Image Processing, 2016.
[9] R. Verhack, Steered mixture-of-experts for image and light field representation, processing, and coding, 2020, URL: 10.14279/depositonce-10270.
[10] R. Verhack, T. Sikora, L. Lange, R. Jongebloed, P. Lambert, Steered mixture-of­ experts for light field coding, depth estimation, and processing, in: 2017 IEEE International Conference on Multimedia and Expo (ICME), 2017.
[11] R. Verhack, S. Thomas, G.V. Wallendael, P. Lambert, Steered mixture-of-experts for light field images and video: representation and coding, IEEE Trans. Multimedia PP (99) (2019). 1­1
[12] E. Bochinski, R. Jongebloed, M. Tok, T. Sikora, Regularized gradient descent training of steered mixture of experts for sparse image representation, in: 2018 25th IEEE International Conference on Image Processing (ICIP), 2018, pp. 3873­ 3877, doi:10.1109/ICIP.2018.8451823.
[13] M. Tok, R. Jongebloed, L. Lange, E. Bochinski, T. Sikora, An mse approach for training and coding steered mixtures of experts, in: 2018 Picture Coding Symposium (PCS), 2018, pp. 273­277, doi:10.1109/PCS.2018.8456250.
[14] R. Jongebloed, E. Bochinski, L. Lange, T. Sikora, Quantized and regularized optimization for coding images using steered mixtures-of-experts, in: 2019 Data Compression Conference (DCC), 2019, pp. 359­368, doi:10.1109/DCC.2019. 00044.
[15] D.P.P. Mesquita, J.P.P. Gomes, A.H. Souza Junior, Epanechnikov kernel for incomplete data, Electron Lett 53 (21) (2017) 1408­1410, doi:10.1049/el.2017.0507.
[16] R.J. Garcia Hernandez, C. Urena, J. Poch, M. Sbert, Overestimation and underestimation biases in photon mapping with non-constant kernels, IEEE Trans. Vis. Comput. Graph. 20 (10) (2014) 1441­1450.
[17] W. Hu, J. Gao, B. Li, O. Wu, J. Du, S. Maybank, Anomaly detection using local kernel density estimation and context-based regression, IEEE Trans. Knowl. Data Eng. 32 (2) (2020) 218­233, doi:10.1109/TKDE.2018.2882404.
[18] Z. Qinli, C. Yu, An improved generalized fuzzy model based on epanechnikov quadratic kernel and its application to nonlinear system identification, Automatic Control and Computer ences 53 (1) (2019) 12­21.
[19] Dawei, Li, Lihong, Xu, Yang, Wu, Improved camshift object tracking based on epanechnikov kernel density estimation and kalman filter, in: 29th Chinese Control And Decision Conference (CCDC), 2017, pp. 3120­3126.
[20] B. Liu, Y. Zhao, X. Jiang, S. Wang, An image coding approach based on mixtureof-experts regression using epanechnikov kernel, in: ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019, pp. 1807­1811, doi:10.1109/ICASSP.2019.8682374.
[21] H.D. Nguyen, L.R. Lloyd-Jones, G.J. Mclachlan, A universal approximation theorem for mixture-of-experts models (2016).
[22] S.E. Yuksel, J.N. Wilson, P.D. Gader, Twenty years of mixture of experts, IEEE Trans. Neural Netw. Learn. Syst. 23 (8) (2012) 1177­1193, doi:10.1109/TNNLS. 2012.2200299.
[23] T. Gasser, H.G. Müller, Kernel estimation of regression functions, Springer Berlin Heidelberg, 1979.
[24] Y. Kubo, M. Nii, T. Muto, H. Tanaka, H. Inui, N. Yagi, K. Nobuhara, S. Kobashi, Artificial humeral head modeling using kmeans++ clustering and pca, in: 2020 IEEE 2nd Global Conference on Life Sciences and Technologies (LifeTech), 2020, pp. 5­7, doi:10.1109/LifeTech48969.2020.1570619195.
[25] T.K. Moon, The expectation-maximization algorithm, Signal Processing Magazine IEEE 13 (6) (1996) 47­60, doi:10.1007/978-0-387-22775-7_22.
[26] D. Marpe, H. Schwarz, T. Wiegand, Context-based adaptive binary arithmetic coding in the h.264/avc video compression standard, IEEE Trans. Circuits Syst. Video Technol. 13 (7) (2003) 620­636, doi:10.1109/TCSVT.2003.815173.
[27] K. Dabov, A. Foi, V. Katkovnik, K. Egiazarian, Image denoising by sparse 3d transform-domain collaborative filtering, IEEE Trans. Image Process. 16 (8) (2007) 2080­2095, doi:10.1109/TIP.2007.901238.
[28] E. Agustsson, R. Timofte, Ntire 2017 challenge on single image super-resolution: Dataset and study, in: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2017.

12

