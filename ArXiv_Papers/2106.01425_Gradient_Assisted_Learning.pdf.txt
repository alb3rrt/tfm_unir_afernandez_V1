Gradient Assisted Learning

arXiv:2106.01425v1 [cs.LG] 2 Jun 2021

Enmao Diao Department of Electrical and Computer Engineering
Duke University enmao.diao@duke.edu

Jie Ding School of Statistics University of Minnesota-Twin Cities dingj@umn.edu

Vahid Tarokh Department of Electrical and Computer Engineering
Duke University vahid.tarokh@duke.edu

Abstract
In distributed settings, collaborations between different entities, such as financial institutions, medical centers, and retail markets, are crucial to providing improved service and performance. However, the underlying entities may have little interest in sharing their private data, proprietary models, and objective functions. These privacy requirements have created new challenges for collaboration. In this work, we propose Gradient Assisted Learning (GAL), a new method for various entities to assist each other in supervised learning tasks without sharing data, models, and objective functions. In this framework, all participants collaboratively optimize the aggregate of local loss functions, and each participant autonomously builds its own model by iteratively fitting the gradients of the objective function. Experimental studies demonstrate that Gradient Assisted Learning can achieve performance close to centralized learning when all data, models, and objective functions are fully disclosed.
1 Introduction
One of the main challenges in harnessing the power of big data is the fusion of knowledge from numerous decentralized organizations that may have proprietary data, models, and objective functions. Due to various ethical and regulatory constraints, it may not be feasible for decentralized organizations to centralize their data and fully collaborate to learn a shared model. Thus, a large-scale autonomous decentralized learning method that can avoid data, models, and objective functions transparency may be of critical interest.
Cooperative learning may have various scientific and business applications [1]. As illustrated in Figure 1, a medical institute may be helped by multiple clinical laboratories and pharmaceutical entities to improve clinical treatment and facilitate scientific research [2, 3]. Financial organizations may collaborate with universities and insurance companies to predict loan default rates [4]. As the above organizations hold heterogeneous features from a potentially similar cohort of people, they can form a community of shared interest to provide better Machine-Learning-as-a-Service (MLaaS) [5] without transmitting their private data, proprietary models, and objective functions.
The main idea of Gradient Assisted Learning (GAL) is outlined below. In the training stage, the organization to be assisted, denoted by Alice, will calculate a set of `residuals' and broadcast these to other organizations. These residuals approximate the fastest direction of reducing the training loss in hindsight. Subsequently, other organizations will fit the residuals using their local data, models, and objective functions and send the fitted values back to Alice. Alice will then assign weights to each organization to best approximate the fastest direction of learning. Next, Alice will line search
Preprint. Under review.

Private Data
Proprietary Model
Figure 1: Decentralized organizations form a community of shared interest to provide better MachineLearning-as-a-Service.
for the optimal gradient assisted learning rate along the calculated direction of learning. The above procedure is repeated until Alice accomplishes a sufficient level of learning. In the inference stage, other organizations will send their locally predicted values to Alice, who will then assemble them to generate the final prediction. We show that the number of assistance rounds needed to approach the centralized performance is often small (e.g., less than ten). That is practically appealing, as GAL is primarily developed for large organizations with rich computation resources. A limited number of interactions with others will reduce the communications and networking costs. Our main contributions are summarized below.
· We propose a Gradient Assisted Learning (GAL) algorithm that is suitable for large-scale autonomous decentralized learning and can effectively exploit task-relevant information preserved by decentralized organizations. Our method enables simultaneous collaboration between multiple organizations without centralized sharing of a model, objective function, or data. Additionally, GAL does not need frequent synchronization of organizations. Moreover, GAL has low communication and networking costs. It typically requires less than ten rounds of assistance.
· Interestingly, for the special case of vertically distributed data, GAL generalizes the classical Gradient Boosting algorithms.
· Our proposed framework can significantly outperform learning baselines and achieve nearoracle performance on various benchmark datasets while producing lower communications overhead compared with the state-of-the-art techniques.
2 Related work
Multimodal Data Fusion Vertically distributed data can be viewed as multimodal data with modalities provided in a distributed manner to different learners/organizations. Standard multimodal data fusion methods include the early, intermediate, and late data fusions [6,7]. These methods concatenate different modes of data at the input, intermediate representation, and final prediction levels. However, these data fusion methods may compromise data privacy in decentralized settings since the underlying organizations may be required to have the task labels to train their local models synchronously. In contrast, our method presented below only requires that organizations asynchronously fit their pseudo-residuals.
Gradient Boosting We are inspired by Gradient Boosting [8,9], where weak learners are sequentially trained from the same dataset and aggregated into a strong learner. In our learning context, each organization uses side-information from heterogeneous data sources to improve a particular learner's performance. Our method can be regarded as a generalization of Gradient Boosting to address decentralized learning with vertically distributed data.
2

Federated Learning Federated learning [10­13] is a popular distributed learning framework developed for edge devices. Its main idea is to learn a joint model by averaging locally learned model parameters. It avoids the need for the transmission of local training data. Conceptually, the goal of Federated Learning is to exploit the resources of edge devices with communication efficiency. Vertical Federated Learning methods split sub-networks for local clients to jointly optimize a global model [14­19]. These methods can be viewed as federated learning with an intermediate data fusion method, and the central server will have access to the true labels. In order to converge, these methods typically require frequent synchronization of backward gradients and a significant number of communication rounds [19]. In contrast, our proposed method trains multiple local models with pseudo-residuals, each contributing to a small portion of the overarching loss. Consequently, our method can achieve near-oracle performance with significantly fewer communication rounds and does not require a global transparent model.
Assisted Learning Assisted Learning (AL) [20] is a decentralized collaborative learning framework for organizations to improve their learning quality. In that context, neither the organization being assisted nor the assisting organizations share their private local models and data. Prior work on AL is limited to mean squared loss regression with only two organizations using a sequential exchange of information. Inspired by Gradient Boosting, our proposed Gradient Assisted Learning (GAL) is a general method for multiple organizations to assist each other in supervised learning scenarios. Our technical novelties include 1) generalization from squared loss to any differentiable loss for supervised learning, 2) allowing for private loss functions at each organization, 3) generalization from a sequential protocol between two organizations to parallel aggregation across multiple organizations, and 4) introduction of the assisted learning rate for fast convergence.
The outline of this paper is given next. In Section 3, we introduce and formulate GAL. In Section 4, we provide extensive experimental studies of GAL under various settings. We provide conclusions and final remarks in Section 5.

3 Gradient Assisted Learning

3.1 Notation

Suppose that there are N data observations independently drawn from a joint distribution pxy =

pxpy|x, where y  Y and x  Rd respectively represent the task label and feature variables, and

d is the number of features. For regression tasks, we have Y = R. For K-class classification

tasks, Y = {e1, . . . , eK }, where ek is the canonical vector representing the class k, k = 1, . . . , K.

Let E and EN denote the expectation and empirical expectation, respectively. Thus, EN g(y, x) =

N -1

N i=1

g(yi,

xi)

for

any

measurable

function

g,

where

(yi,

xi)

are

i.i.d.

observations

from

pxy .

Suppose that there are M organizations. Each organization m only holds Xm, a sub-vector of

X (illustrated in Figure 2). In general, we assume that the variables in X1, . . . , XM are disjoint in the

presentation of our algorithm, although our method also allows for the sharing of some variables. For

example, one organization may observe demographic features for a mobile user cohort, and another

organization holds health-related features of that cohort. Without loss of generality, we suppose that

Alice is the organization to be assisted. Alice has local data x1 and task label y1. Other organizations are collaborators of Alice.

features

samples

Figure 2: An illustration of the organizations' vertically distributed data.
3.2 Problem formulation For m = 1, . . . , M , let {xi,m}Ni=1 denote the available data to the organization m. Thus, N objects are simultaneously observed by M organizations, each observing a subset of features from the x  Rd. Alice also has private task labels {yi,1}Ni=1 for training purposes. Let Fm and Lm respectively denote supervised function class (such as generalized linear functions or neural networks) and the private objective function of organization m. We will assume that Lm is differentiable. Without loss of generality, we assume that Alice denotes organization 1, who will be
3

assisted. Without assistance from other organizations, Alice would learn a model that minimizes the
following empirical risk, FAlone = argminF1F1 EN L1(y, F1(x1)), Note that the above formulation only involves Alice's local data x1 and local model (as represented by F1 and L1). Without privacy concerns, Alice would be able to operate on other organizations' data x2, . . . , xM as well. Recall that x represents the ensemble of all the available data variables. In general, the most ideal case for
Alice is to minimize the following empirical risk, FJoint = argminF F EN L1(y, F (x)), where F is a supervised function class defined on the space of x.

In reality, Alice has no access to the complete data and model resources of other organizations. In this light, she shall be happy to outsource the learning task to other organizations to cooperatively build a model in hindsight, without the need to share any organization's local data or models. In the prediction stage, Alice can collect the pieces of information needed to form a final prediction, to hopefully achieve a performance that significantly improves over her single-organization performance. To this end, we will develop a solution for Alice to achieve such a goal.

We will include detailed derivations and discussions of our solution in Subsection 3.3. For readability,
we will summarize notations that we will frequently use in this exposition below. Our method will require Alice to occasionally send a continuous-valued vector r1 = [ri,1]Ni=1  RN×k to each organization m (elaborated later). Upon the input of these residual vectors, the organization m will
locally learn a supervised function fm that maps from its feature space to the residual space. With a slight abuse of notation, we also refer to fm as the learned model. To this end, organization m will perform the empirical risk minimization

1N

fm = argmin EN
f Fm

m(r1,

f

(xm))

=

argmin
f Fm

N

i=1

m (ri,1, f (xi,m))

(1)

to obtain a locally trained model fm. Here, Fm and m respectively denote the supervised function class and loss function of the organization m. We note that m are private local loss functions for fitting the pseudo-residual r1 and may not necessarily be the same as L1 for fitting true labels. For example, L1 may be the cross-entropy loss for classification of label y, while 1:M could be the squared loss for regression of the response r1. The above local training (optimization) is often performed using the stochastic gradient descent (SGD) algorithm. In our assisted learning context,
L1, Fm, and m are proprietary local resources that cannot be shared across organizations.

3.3 The GAL algorithm
We first introduce the derivation of the GAL algorithm from a functional gradient descent perspective. Then, we cast the algorithm into pseudocode and discuss each step. Consider the unrealistic case that Alice has all the data x needed for a centralized supervised function F : x  F (x). Recall that the goal of Alice is to minimize the population loss Epx,y L1(y, F (x)) over a data distribution px,y. If px,y is known, starting with an initial guess F 0(x), Alice would have performed a gradient descent step in the form of

F1



F0

-



·

 F

Epx,y L1(y,

F (x))

|F =F 0 =

F0

-



·

Epx,y

 F

L1(y,

F (x))

|F =F 0 ,

(2)

where the equality holds under the standard regularity conditions of exchanging integration and

differentiation. Note that the second term in (2) is a function on Rd. However, because Alice only

has access to her own data x1, the expectation Epx,y cannot be realistically evaluated. Therefore,

we need to approximate it with functions in a pre-specified function set. In other words, we will

find

f

from

FM

that

`best'

approximates

Epx,y

 F

L1(y, F (x)).

We

will

show

that

this

is

actionable

without requiring the organizations to share proprietary data, models, and objective functions.

Recall that Fm is the function set locally used by the organization m, and xm is correspondingly observed portion of x. The function class that we propose to approximate the second term in (2) is

M

FM = f : x  wmfm(xm), fm  Fm, x  Rd, w  PM ,

(3)

m=1

where PM = {w  RM :

M m=1

wm

=

1,

wm



0}

denotes

the

probability

simplex.

The

gradient

assistance weights wm's are interpreted as the contributions of each organization at a particular greedy

update step. The gradient assistance weights are constrained to sum to one to ensure the function

space is compact, and the solutions exist.

4

User ID

Residual1

Residual2

Residual3

B0

B1

B2

B3

B0

B1

B2

B3

H1

H2

H3

M1

M2

M3

User ID

H1

H2

H3

M1

M2

M3

I1

I2

I3

(a) Learning Stage

M1

M2

M3

(b) Prediction Stage

Figure 3: Learning and Prediction Stage for Gradient Assisted Learning.

End User Service Provider Collaborator
Private Data
Proprietary Model

Algorithm 1 GAL: Gradient Assisted Learning (from the perspective of the service receiver, Alice)

Input: M decentralized organizations, each holding data {xi,m}Ni=1 (local) corresponding to N objects, the task label {yi,1}Ni=1 initially held by the service receiver (Alice local) , model class Fm (local), gradient assistance weights w (Alice local), assistance rate  (Alice local), overarching loss function L1 (Alice local), residual loss function m (local), number of assistance rounds T .
Learning Stage:
Intialization: Let t = 0, and initialize F 0(x) = EN (y1)
for assistance round t from 1 to T do Compute pseudo-residual

r1t = -

L1(y1,F t-1(x))
F t-1(x)

Broadcast pseudo-residual r1t to other organizations for organization m from 1 to M in parallel do
fmt = argminfmFm EN m (r1t , fm(xm))
end
Gather predictions fmt (xm), m = 1, . . . M , from all the organizations Optimize the gradient assistance weights

w^t = argminwPM EN 1 r1t ,

M m=1

wmfmt

(xm)

Line search for the gradient assisted learning rate

^t = argminR EN L1 F t(x) = F t-1(x) + ^t end

y1, F t-1(x) + 

M m=1

w^mt fmt (xm)

M m=1

w^mt

fmt

(xm

)

Prediction Stage:

For each data observation x, of which xm is held by organization m:

Gather predictions fmt (xm), t = 1, . . . , T from each organization m, m = 1, . . . , M

Predict with F T (x) = F 0(x1) +

T t=1

^t

M m=1

w^mt fmt

(xm

)

We propose the following solution so that each organization can operate on its own local data, model, and objective function. Alice initializes with a startup model, denoted by F 0(x) = F 0(x1, y1), based only on her local data and labels. Alice broadcasts r1 (named `pseudo residuals') to each organization m, m = 2, · · · , M , who will then fit a local model fm using r1. Each organization will then send the fitted values from fm to Alice, who will train suitable gradient assistance weights wm. Subsequently, Alice finds the  in (2) that minimizes her current empirical risk. The above procedure is iterated for a finite number of rounds until Alice obtains a satisfactory performance (e.g., on validation data). The validation will be based on the same technique as the prediction stage to be described below. This training stage is described under the `learning stage' of Algorithm 1. Note that the pseudocode is from the perspective of Alice, the service receiver. For each organization m, it will only need to perform the empirical risk minimization using the label r1t sent by Alice at each round t.
5

In the Prediction/Inference stage (given above in Algorithm 1), other organizations send prediction results generated from their local models to Alice, who will calculate a prediction result F T (x) that is implicitly operated on x, where T is the number of iteration steps.
We note that the idea of approximating functional derivatives with regularized functions was historically used to develop the seminal work of gradient boosting [8, 9]. Interestingly, when there is only one organization, the above method reduces to the standard gradient boosting algorithm [8, 9].
Example. We provide a realistic example in Figure 3 to demonstrate each step of our algorithm presented in Algorithm 1. Alice, the service receiver (bank) squared in red dashed line, is the organization to be assisted. Before learning, it broadcasts user identification (ID) to locate and align vertically distributed data held by other organizations. At the beginning of the Learning Stage, the bank deterministically initializes the values of F 0(x) to be the average values of y1, namely F 0(x) = EN (y10). For the regression task, F 0(x) is a single scalar. For classification task, F 0(x) is a point in the K-dimensional simplex PK.
During the first assistance round in the Learning Stage, the bank computes pseudo-residual r11 and broadcasts it to other organizations (e.g., hospital, mall, and insurance company). Then, all the organizations, including the bank, will fit a new local model with 1) their local data, 2) the pseudo-residual r11, and 3) their local loss function m (e.g., 2-loss). We note that organizations have complete autonomy on model fitting. In particular, they can choose their own learning algorithms and models by considering their resources (e.g., computation power). Next, the bank will aggregate all the predictions from each organization's local models by optimizing a weight vector w1:M referred to as gradient assistance weights. As previously discussed in Equation (3), we approximate the oracle gradient (operated on centralized data, in hindsight) with a weighted average of those predictions from organizations. We then numerically search for the gradient assisted learning rate . This process can be iterated multiple times until the learning rate is low or the validation loss is satisfactory.
During the Prediction Stage, organizations will predict with trained models at every assistance round and transmit their predictions to the bank. Similar to the Learning Stage, the synchronization of each organization is unnecessary. The bank computes the final prediction with gradient assistance weights, learning rates, and received predictions.
Organizations in our learning framework form a shared community of interest. Each serviceproviding organization can provide end-to-end assistance for an organization without sharing anyone's proprietary data, models, and objective functions. In practice, the participating organizations may receive financial rewards from the one being assisted. Moreover, every organization in this framework can provide its own task and seek help from others. As a result, all organizations become mutually beneficial to each other.
4 Experimental Studies
Datasets We experiment with several different types of data introduced below. 1) UCI datasets downloadable from the scikit-learn package [21], including Diabetes [22], Boston Housing [23], Blob [21], Iris [24], Wine [25], Breast Cancer [26], and QSAR [27] datasets, where we randomly partition the features into 2, 4, or 8 subsets, each for an organization. 2) MNIST [28] and CIFAR10 [29] image datasets, where we split each image into image patches as depicted in Figure 6. We do not adopt data augmentation such as horizontal flipping. 3) MIMIC3 [30] dataset, where the task aims to predict the length-of-stay with in-hospital data. We split the time series features of MIMIC3 for 4 organizations. 4) ModelNet40 [31] dataset, which contains 2D camera views of 3D object data for 12 organizations (following [32]). For all the datasets, we train on 80% of the available data and test on the remaining for UCI datasets. The summary statistics of each dataset are elaborated in Table 5 of the supplementary document. We conduct four random experiments for all datasets with different seeds, and the standard deviation are shown in the brackets.
Model settings We use linear models for the UCI datasets, convolution neural networks (CNN) for the MNIST, CIFAR10, and ModelNet40 datasets, and long short-term memory (LSTM) for the MIMIC3 dataset. Although we have used the same model architecture for every organization in the experiments, our algorithm does not require the organizations to have the same local learning algorithms and models. Details of the architectures are given in the supplementary document.
Learning For regression tasks on datasets such as the Diabetes, Boston Housing, and MIMIC3, we train with l1 for the residual loss m and the overarching loss L1, and evaluate using the mean
6

absolute deviation (MAD). For classification tasks on the remaining datasets, we train with 2-loss for the residual loss m and cross-entropy loss for the overarching loss L1, and evaluate using accuracy. We use the SGD optimizer for linear and CNN with a learning rate of 10-1 and the Adam optimizer for LSTM with a learning rate of 10-4. The number of local epochs E is 100 for UCI datasets and 10 for the rest. The number of assistance rounds T is 10 in our experiments.
To optimize gradient assistance weights, we use the Adam optimizer with a learning rate of 10-1 and enforce the parameters to sum to 1 by using the softmax function. We perform a line search for the gradient assisted learning rate with the Limited-Memory BFGS optimizer using a learning rate of 1. In the experiments, we found that using the quasi-newton method greatly improves the convergence rates due to better estimation of gradient assisted learning rates compared with SGD and Adam. Details of learning hyper-parameters are included in Table 7 in the supplementary document.
4.1 Baselines
Our experiments are performed with four baselines, including `Interm', `Late', `Joint', and `Alone'. `Interm' and `Late' refer to intermediate and late data fusions [6, 7], respectively. `Interm' works for CNN and LSTM by averaging the hidden representation of each local model. `Late' also works for linear models as it averages the output of each local model. `Joint' is the oracle case where all the data are held by Alice and trained with the Gradient Boosting reduced from GAL. `Alone' is the single-agent scenario, where only Alice's data are used for learning and prediction.
The experimental results are shown in Tables 1 and 2. We also visualize the performance of CIFAR10 and MIMIC3 at each assistance round in Figure 4(a,d). Our method significantly outperforms the bottom line `Alone' in all the settings. This is expected since the first organization holds partial data and does not receive any assistance under `Alone'. Interestingly, the performance of MNIST for M = 8 drops significantly under `Alone' because the organization only holds the left upper image patch, which is usually completely dark (shown in Figure 6 of the supplement). The results demonstrate that with GAL, an organization with little informative data can leverage other organizations' private data and models, and even achieve near-oracle performance (the `Joint' case). Moreover, we found that the number of assistance rounds needed to approach the centralized performance is small (e.g., often within ten). We point out that although `Interm', `Late', and `Joint' marginally outperform our method, they require training of centralized data. Our GAL algorithm replaces the true label used in `Interm', `Late', and `Joint' oracle case with pseudo-residual to preserve the privacy (in terms of data, model, and objective). The results from both regression and classification datasets lead to similar conclusions. More results for different numbers of organizations can be found in the supplementary document.

Table 1: Results on the UCI datasets (M = 8). The Diabetes and Boston Housing (regression) are evaluated with MAD, and the rest (classification) are evaluated with Accuracy (in percentage).

Dataset
Late Joint
Alone GAL

Diabetes
136.2(0.1) 43.4(0.3)
59.7(9.2) 42.7(0.6)

Boston Housing
8.0(0.0) 3.0(0.0)
5.8(0.9) 3.2(0.2)

Blob
100.0(0.0) 100.0(0.0)
41.3(10.8) 100.0(0.0)

Wine
100.0(0.0) 100.0(0.0)
63.9(15.6) 96.5(3.0)

Breast Cancer
96.9(0.4) 98.9(0.4)
92.5(3.4) 98.5(0.7)

QSAR
76.9(0.8) 84(0.2)
68.8(3.4) 82.5(0.8)

Table 2: Results on the MNIST (M = 8), CIFAR10 (M = 8), MIMIC3, and ModelNet40 datasets. The MIMIC3 (regression) is evaluated with MAD, and the rest (classification) are evaluated with Accuracy. Note that the `Joint' of ModelNet40 does not perform well because of the known fact that a joint model cannot take into account multiple orientations [32].

Dataset
Interm Late Joint
Alone GAL

MNIST
98.8(0.1) 98.0(0.1) 99.4(0.0)
24.2(0.1) 96.3(0.6)

CIFAR10
78.2(0.2) 74.4(0.3) 80.1(0.2)
46.3(0.3) 74.3(0.2)

MIMIC3
92.4(0.3) 94.3(0.1) 96.2(2.2)
103.2(0.8) 96.4(1.8)

ModelNet40
85.8(0.2) 86.6(0.2) 46.3(1.4)
76.4(1.1) 83.0(0.2)

7

(a)

(b)

(c)

(d)

(e)

(f)

Figure 4: Results of CIFAR10 (a-c) (M = 8) and MIMIC3 (d-e) (M = 4) datasets. GAL significantly

outperforms `Alone' and performs close to the centralized case `Joint.' The gradient assisted learning

rate diminishes to zero as the overarching loss converges. Constant gradient assisted learning rate

( = 1) converges much slower. The gradient assistance weights of the central image patches

(m = {2, 3, 6, 7}) are larger than the boundary ones at the first few rounds.

4.2 State-of-the-art results on the MIMIC3 and ModelNet40 datasets
We perform experiments with the MIMIC3 and ModelNet40 data to compare our method with the related works, including Assisted Learning (AL) [20] and vertical asynchronous Federated Learning (VAFL) [19]. The results are shown in Table 3. We also provide benchmark results where all the data are held by Alice [32, 33]. We provide some discussions below.
MIMIC3 Our method significantly outperforms AL and performs close to the oracle case. We note that our backbone model (LSTM) is the same as the one used in the benchmark [33], but AL used different model configurations [20]. Compared with AL, our method introduces the gradient assisted learning rate to improve the convergence, as discussed in Section 4.3. Moreover, GAL can optimize multiple organizations in parallel with the help of gradient assistance weights, while AL is restricted to sequential training of data from each organization. Thus, compared with AL, GAL can significantly improve the performance and reduce the communication cost.
ModelNet40 Our method performs better than VAFL with much fewer communication rounds. Vertical federated learning method such as VAFL [19] and SplitFed [18] can be viewed as federated learning with intermediate data fusion. They typically require frequent communications of hidden representations and gradients to optimize a global model in hindsight. In particular, VAFL allocates separate convolution layers for each organization and transmits hidden representations to the server. We note that the VAFL server will have access to the true label and objective function, while GAL allows Alice to preserve such privacy. The VAFL server will compute and transmit the gradients of hidden representations to each organization for further local backward propagation. On the contrary, GAL trains one local model at each communication round for every organization, and each model solves a small part of the overarching loss function (namely, the pseudo-residual multiplied by the gradient assisted learning rate). Therefore, compared with VAFL, GAL can significantly reduce the communication cost of training vertically distributed data.
4.3 Gradient assisted learning rate
We show the gradient assisted learning rate of CIFAR10 and MIMIC3 datasets at each assistance round in Figure 4(b,e). More results are included in the supplementary document. Recall that we adopt a quasi-newton method to line search for the gradient assistance rate. Standard first-order optimization methods usually fail to produce accurate line search results and require more assistance rounds to converge. We perform an ablation study of using a constant gradient assisted learning rate ( = 1). As shown in Figure 4(a,d), the constant gradient assisted learning rate leads to a convergence much slower than line search method. Fast convergence is desirable since the computation and

8

Table 3: Comparison between GAL and the state-of-the-art methods. In the table, M represents the number of organizations, T is the number of communication rounds (better to be smaller). The performance metrics are MAD for MIMIC3 and Accuracy for ModelNet40.

Dataset

Method

M T Performance

MIMIC3

Benchmark [33] 1 N/A

AL [20] GAL

3 30 4 10

94.7
110.8 96.4

MVCNN [32] 1 N/A

88.1

ModelNet40 VAFL [19]

4 5000

81.0

GAL

12 10

83.0

communication cost increases with the number of assistance rounds. To determine the maximum number of assistance rounds T for the service receiver, we can run the GAL procedure until the gradient assisted learning rate becomes small. When the gradient assistance rate is small as shown in Figure 4(e), the overarching loss converges to zero. In this light, an organization may stop receiving assisted learning when the gradient assisted learning rate is below a threshold.
4.4 Gradient assistance weights
We show the gradient assistance weights of CIFAR10 and MIMIC3 datasets at each assistance round in Figure 4(c,f). More results can be found in the supplementary document. The results of MIMIC3 show that the contributing organization with the largest assistance weight may change from one round to another. For image datasets MNIST and CIFAR10, it is interesting that the image patches with dominant contributions are m = (2, 3, 6, 7) (colored in red). These image patches correspond to the center of the original image, which matches our intuition appealingly.
We also perform an ablation study of the gradient assistance weights by adding noises (Gaussian with zero mean and 2 variance,   {1, 5}) to the transmitted pseudo-residuals to a (randomly chosen) half of the clients during learning and prediction. The purpose of adding noises is to mimic realistic scenarios where some assisting organizations are uninformative, add a moderate amount of noise to enhance data privacy [34], or inject adversarial pseudo-residuals. We summarize the results of this ablation study in Table 4 and Figure 5. The results show that the GAL equipped with gradient assistance weights is more robust than the GAL with direct average. We note that as the number of participating organizations becomes large, the gradient assistance weights can also be used for organization (meta-feature) selection.

Table 4: Ablation study of gradient assistance weights by adding noises to the transmitted pseudoresiduals to half of the organizations. The evaluation metrics are the same as Tables 1 and 2.

Dataset =1 =5

Weight
 
 

Diabetes
49.0(1.6) 46.4(2.3)
61.0(2.4) 49.7(3.1)

Boston Housing
4.3(0.2) 4.0(0.2)
5.8(0.2) 4.7(0.5)

Blob
46.3(6.5) 78.8(8.2)
12.5(2.5) 62.5(9.0)

Wine
81.2(5.3) 88.9(2.0)
54.2(6.9) 84.7(1.4)

Breast Cancer
90.8(2.5) 96.7(1.0)
78.5(2.0) 96.9(1.3)

QSAR
73.2(1.0) 78.9(1.2)
61.8(0.5) 77.1(0.8)

MNIST
75.1(0.4) 92.7(0.1)
33.8(0.3) 92.1(0.2)

CIFAR10
45.4(0.3) 61.0(0.4)
23.3(0.6) 57.3(0.3)

MIMIC3
99.3(0.8) 94.9(1.2)
110.5(0.6) 96.4(0.8)

ModelNet40
55.8(1.0) 78.3(0.9)
24.5(0.4) 77.5(0.4)

(a)

(b)

(c)

(d)

Figure 5: Ablation study results on CIFAR10 (a-b) (M = 8) and MIMIC3 (c-d) (M = 4) datasets.
Plots (a,c) show that the GAL equipped with gradient assistance weight significantly outperforms the GAL with direct average under noise injections (N (0, 2) ,  = {1, 5}) to the transmitted
pseudo-residual to half of the organizations during learning and prediction. Plots (b,d) show the gradient assistance weight of noisy (in orange,  = 1) and noise-free organizations (in red).

9

5 Conclusion
In this paper, we proposed Gradient Assisted Learning, a decentralized learning method for multiple organizations to collaborate while preserving privacy. The proposed solution can significantly outperform the learning baselines, state-of-the art methods, and achieve near-oracle performance (as if data were centralized) on various datasets. Our approach enables organizations to form a shared community of interest without compromising their private data and models while achieving near-oracle full collaboration performance. Moreover, this is achieved without any constraints on the models selected by the collaborating organizations.
Acknowledgments and Disclosure of Funding
This work was supported by the Office of Naval Research (ONR) under grant number N00014-18-12244.
References
[1] R. Roman, J. Zhou, and J. Lopez, "On the features and challenges of security and privacy in distributed internet of things," Comput. Netw., vol. 57, no. 10, pp. 2266­2279, 2013.
[2] J. T. Farrar, A. B. Troxel, K. Haynes, I. Gilron, R. D. Kerns, N. P. Katz, B. A. Rappaport, M. C. Rowbotham, A. M. Tierney, D. C. Turk et al., "Effect of variability in the 7-day baseline pain diary on the assay sensitivity of neuropathic pain randomized clinical trials: an acttion study," Pain®, vol. 155, no. 8, pp. 1622­1631, 2014.
[3] B. Lo, "Sharing clinical trial data: maximizing benefits, minimizing risk," JAMA, vol. 313, no. 8, pp. 793­794, 2015.
[4] L. Zhu, D. Qiu, D. Ergu, C. Ying, and K. Liu, "A study on predicting loan default based on the random forest algorithm," Procedia Computer Science, vol. 162, pp. 503­513, 2019.
[5] M. Ribeiro, K. Grolinger, and M. A. Capretz, "Mlaas: Machine learning as a service," in Proc. ICMLA. IEEE, 2015, pp. 896­902.
[6] B. Khaleghi, A. Khamis, F. O. Karray, and S. N. Razavi, "Multisensor data fusion: A review of the state-of-the-art," Information fusion, vol. 14, no. 1, pp. 28­44, 2013.
[7] D. Lahat, T. Adali, and C. Jutten, "Multimodal data fusion: an overview of methods, challenges, and prospects," Proceedings of the IEEE, vol. 103, no. 9, pp. 1449­1477, 2015.
[8] L. Mason, J. Baxter, P. Bartlett, and M. Frean, "Boosting algorithms as gradient descent in function space," 1999.
[9] J. H. Friedman, "Greedy function approximation: a gradient boosting machine," Ann. Stat., pp. 1189­1232, 2001.
[10] R. Shokri and V. Shmatikov, "Privacy-preserving deep learning," in Proc. CCS, 2015, pp. 1310­1321.
[11] J. Konecny, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh, and D. Bacon, "Federated learning: Strategies for improving communication efficiency," arXiv preprint arXiv:1610.05492, 2016.
[12] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, "Communication-efficient learning of deep networks from decentralized data," in Proc. AISTATS, 2017, pp. 1273­1282.
[13] E. Diao, J. Ding, and V. Tarokh, "HeteroFL: Computation and communication efficient federated learning for heterogeneous clients," in International Conference on Learning Representations, 2021.
[14] P. Vepakomma, O. Gupta, T. Swedish, and R. Raskar, "Split learning for health: Distributed deep learning without sharing raw patient data," arXiv preprint arXiv:1812.00564, 2018.
[15] Q. Yang, Y. Liu, T. Chen, and Y. Tong, "Federated machine learning: Concept and applications," in Proc. TIST, vol. 10, no. 2, p. 12, 2019.
[16] Y. Liu, Y. Kang, X. Zhang, L. Li, Y. Cheng, T. Chen, M. Hong, and Q. Yang, "A communication efficient vertical federated learning framework," arXiv preprint arXiv:1912.11187, 2019.
10

[17] J. Hamer, M. Mohri, and A. T. Suresh, "Fedboost: A communication-efficient algorithm for federated learning," in Proc. ICML, 2020, pp. 3973­3983.
[18] C. Thapa, M. A. P. Chamikara, and S. Camtepe, "Splitfed: When federated learning meets split learning," arXiv preprint arXiv:2004.12088, 2020.
[19] T. Chen, X. Jin, Y. Sun, and W. Yin, "Vafl: a method of vertical asynchronous federated learning," arXiv preprint arXiv:2007.06081, 2020.
[20] X. Xian, X. Wang, J. Ding, and R. Ghanadan, "Assisted learning: A framework for multiorganization learning," Advances in Neural Information Processing Systems, vol. 33, 2020.
[21] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, "Scikit-learn: Machine learning in Python," Journal of Machine Learning Research, vol. 12, pp. 2825­2830, 2011.
[22] B. Efron, T. Hastie, I. Johnstone, R. Tibshirani et al., "Least angle regression," Ann. Stat., vol. 32, no. 2, pp. 407­499, 2004.
[23] D. Harrison Jr and D. L. Rubinfeld, "Hedonic housing prices and the demand for clean air," J. Environ. Econ. Manag., vol. 5, no. 1, pp. 81­102, 1978.
[24] R. A. Fisher, "The use of multiple measurements in taxonomic problems," Annals of eugenics, vol. 7, no. 2, pp. 179­188, 1936.
[25] S. Aeberhard, D. Coomans, and O. De Vel, "Comparative analysis of statistical pattern recognition methods in high dimensional settings," Pattern Recognition, vol. 27, no. 8, pp. 1065­1077, 1994.
[26] W. N. Street, W. H. Wolberg, and O. L. Mangasarian, "Nuclear feature extraction for breast tumor diagnosis," in Biomedical image processing and biomedical visualization, vol. 1905. International Society for Optics and Photonics, 1993, pp. 861­870.
[27] K. Mansouri, T. Ringsted, D. Ballabio, R. Todeschini, and V. Consonni, "Quantitative structure­ activity relationship models for ready biodegradability of chemicals," J. Chem. Inf. Model., vol. 53, no. 4, pp. 867­878, 2013.
[28] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, "Gradient-based learning applied to document recognition," Proceedings of the IEEE, vol. 86, no. 11, pp. 2278­2324, 1998.
[29] A. Krizhevsky, G. Hinton et al., "Learning multiple layers of features from tiny images," 2009. [30] A. E. Johnson, T. J. Pollard, L. Shen, H. L. Li-wei, M. Feng, M. Ghassemi, B. Moody,
P. Szolovits, L. A. Celi, and R. G. Mark, "Mimic-iii, a freely accessible critical care database," Sci. Data, vol. 3, p. 160035, 2016. [31] Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and J. Xiao, "3d shapenets: A deep representation for volumetric shapes," in Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 1912­1920. [32] H. Su, S. Maji, E. Kalogerakis, and E. Learned-Miller, "Multi-view convolutional neural networks for 3d shape recognition," in Proceedings of the IEEE international conference on computer vision, 2015, pp. 945­953. [33] H. Harutyunyan, H. Khachatrian, D. C. Kale, G. Ver Steeg, and A. Galstyan, "Multitask learning and benchmarking with clinical time series data," Sci. Data, vol. 6, no. 1, pp. 1­18, 2019. [34] J. Dong, A. Roth, and W. J. Su, "Gaussian differential privacy," arXiv preprint arXiv:1905.02383, 2019.
11

Supplementary material

We provide additional experimental results in this supplementary material.
Summary of experimental results In Table 5, we illustrate the statistics of datasets used in our experiments. In Figure 6, we show how MNIST and CIFAR10 images are split into 2, 4, and 8 image patches. The left upper image patch (labeled [1]) of MNIST image is less informative which demonstrates that an organization with little informative data can leverage other organizations' private data and models. The central image patches (labeled [2, 3, 6, 7]) of MNIST and CIFAR10 images are more informative than others, which leads to larger corresponding gradient assistance weights. Table 6 summarizes the deep neural network architecture used for the MNIST, CIFAR10, and ModelNet40 datasets. Table 7 shows the hyperparameters used in our experiments. In Tables 8 and 9, we demonstrate the results of our experiments for M = 2. In Tables 10 and 11, we demonstrate the results of our experiments for M = 4. In Tables 12 and 13, we include ablation studies of the noise injection to half of the organizations for M = 2 and M = 4, respectively.
From Figures 7 to 17, we show the results of Diabetes, Boston Housing, Blob, Iris, Breast Cancer, Wine, QSAR, MNIST, CIFAR10, MIMIC3, and ModelNet40 datasets, respectively. All the results indicate that the proposed GAL algorithm allows all the participants to collaboratively and efficiently optimize the objective by the iterative fitting of pseudo-residuals.

Table 5: Detailed statistics used in each data experiment. The variables d and K respectively denote the number of features (or the shape of the image) and the length of the prediction vector (or equivalently, the number of classes in the classification task).

Dataset

Ntrain Ntest

d

KM

Diabetes

353 89

10

1 {2, 4, 8}

BostonHousing 404 102

13

1 {2, 4, 8}

Blob

80

20

10

10 {2, 4, 8}

Iris

120 30

4

3 {2, 4}

Wine

142 36

13

3 {2, 4, 8}

BreastCancer 455 114

30

2 {2, 4, 8}

QSAR

844 211

41

2 {2, 4, 8}

MNIST

60000 10000 (1,28,28) 10 {2, 4, 8}

CIFAR10 50000 10000 (3,32,32) 10 {2, 4, 8}

ModelNet40 3163 800 (12,3,32,32,32) 40 {12}

MIMIC3

16000 8000

76

1 {4}

1

2

1

2

M = 2

1

2

M = 4

3

4

M = 2

1

2

M = 4

3

4

Service Receiver
Collaborator

M = 8

1

2

3

4

5

6

7

8

Service Receiver
Collaborator

M = 8

1

2

3

4

5

6

7

8

(a)

(b)

Figure 6: An illustration of (a) MNIST and (b) CIFAR10 data split into 2, 4, and 8 image patches. The left upper image patch (labeled [1]) of MNIST images is less informative in general. In contrast, the central image patches (labeled [2, 3, 6, 7]) of MNIST and CIFAR10 images are more informative.

12

Table 6: The model architecture of Convolutional Neural Networks (CNN) used in our experiments of the MNIST, CIFAR10, and ModelNet40 datasets. The nc, H, W represent the shape of images, namely the number of image channels, height, and width, respectively. K is the number of classes in the classification task. The BatchNorm and ReLU layers follow Conv(output channel size, kernel size, stride, padding) layers. The MaxPool(output channel size, kernel size) layer reduces the height and width by half.
Image x  Rnc×H×W Conv(64, 3, 1, 1) MaxPool(64, 2) Conv(128, 3, 1, 1) MaxPool(128, 2) Conv(256, 3, 1, 1) MaxPool(256, 2) Conv(512, 3, 1, 1) MaxPool(512, 2)
Global Average Pooling Linear(512, K)

Table 7: Hyperparameters used in our experiments for training local models, gradient assisted learning rates, and gradient assistance weights.

Model

Architecture

Local

Epoch Batch size Optimizer Learning rate Weight decay

Gradient assited learning rates

Epoch Batch size Optimizer Learning rate

Gradient assistance weights

Epoch Batch size Optimizer Learning rate Weight decay

Assistance rounds

UCI MNIST CIFAR10 ModelNet40

Linear

CNN

100 1024

10

512

512

SGD

1.0E-01

5.0E-04

10 Full L-BFGS
1

100 1024 Adam 1.0E-01 5.0E-04

10

MIMIC3 LSTM
64 Adam 1.0E-04

Table 8: Results of UCI datasets (M = 2). Diabetes and Boston Housing (regression) are evaluated with MAD and the rest (classification) are evaluated with Accuracy.

Dataset
Late Joint
Alone GAL

Diabetes
120.2(0.1) 43.4(0.3)
46.8(3.5) 43.2(0.8)

Boston Housing
3.6(0.1) 3.0(0.0)
4.1(0.7) 2.9(0.1)

Blob
100.0(0.0) 100.0(0.0)
100.0(0.0) 100.0(0.0)

Wine
100.0(0.0) 99.2(1.4)
92.5(6.0) 99.2(1.4)

Breast Cancer
100.0(0.0) 100.0(0.0)
93.1(6.4) 96.5(2.3)

QSAR
99.3(0.4) 98.9(0.4)
98.9(0.6) 99.1(0.4)

13

Table 9: Results of MNIST (M = 2) and CIFAR10 (M = 2) datasets.

Dataset
Interm Late Joint
Alone GAL

MNIST
99.4(0.0) 99.0(0.0) 99.4(0.0)
96.7(0.2) 98.5(0.2)

CIFAR10
81.1(0.3) 81.0(0.2) 80.1(0.2)
72.7(0.2) 78.7(0.4)

Table 10: Results of UCI datasets (M = 4). Diabetes and Boston Housing (regression) are evaluated with MAD and the rest (classification) are evaluated with Accuracy.

Dataset
Late Joint
Alone GAL

Diabetes
129.5(0.1) 43.4(0.3)
56.6(8.2) 43.3(1.1)

BostonHousing
4.7(0.0) 3.0(0.0)
4.8(0.6) 3.0(0.1)

Blob
100.0(0.0) 100.0(0.0)
80.0(6.1) 100.0(0.0)

Wine
100.0(0.0) 99.2(1.4)
79.2(13.0) 100.0(0.0)

BreastCancer
100.0(0.0) 100.0(0.0)
84.7(1.4) 97.9(2.3)

QSAR
98.5(0.7) 98.9(0.4)
97.1(1.0) 99.1(0.6)

Table 11: Results of MNIST (M = 4) and CIFAR10 (M = 4) datasets.

Dataset
Interm Late Joint
Alone GAL

MNIST
99.1(0.0) 98.4(0.1) 99.4(0.0)
81.2(0.1) 96.6(0.2)

CIFAR10
79.8(0.1) 77.5(0.2) 80.1(0.2)
60.0(0.4) 77.3(0.2)

Table 12: Ablation study (M = 2) of gradient assistance weights by adding noises to the transmitted pseudo-residuals to half of the organizations. The evaluation metrics are the same as Tables 1 and 2.

Dataset =1 =5

Weight
 
 

Diabetes
50.1(1.9) 47.8(2.4)
58.8(1.3) 46.5(3.1)

Boston Housing
4.4(0.2) 3.5(0.5)
6.1(0.2) 4.1(0.8)

Blob
62.5(2.5) 97.5(4.3)
25.0(9.4) 83.8(7.4)

Iris
80.8(6.4) 95(3.7)
52.5(10.9) 90(4.1)

Wine
86.8(2.3) 96.5(3.0)
63.9(3.4) 93.1(4.2)

Breast Cancer
89.9(3.1) 98.7(1.0)
73.2(1.0) 97.6(1.1)

QSAR
73.2(1.3) 80.2(0.5)
63.3(0.5) 78.3(1)

MNIST
79.7(0.3) 96.8(0.1)
34.8(0.5) 96.3(0.1)

CIFAR10
48.8(0.3) 71.4(0.1)
22.0(0.2) 65.9(0.3)

Table 13: Ablation study (M = 4) of gradient assistance weights by adding noises to the transmitted pseudo-residuals to half of the organizations. The evaluation metrics are the same as Tables 1 and 2.

Dataset =1 =5

Weight
 
 

Diabetes
46.7(1.0) 45(2.8)
59.4(1.1) 49.6(3.7)

Boston Housing
4.1(0.1) 3.7(0.5)
5.7(0.4) 4.1(0.7)

Blob
46.3(6.5) 90.0(5.0)
13.8(4.1) 66.3(9.6)

Iris
80.0(5.3) 95.8(4.3)
54.2(7.6) 93.3(2.4)

Wine
85.4(3.0) 94.4(3.4)
61.1(7.1) 93.7(3.6)

Breast Cancer
91.2(1.4) 97.8(1.0)
75.9(2.9) 97.8(0.4)

QSAR
72.6(2.2) 79.1(1.1)
64.1(1.8) 76.7(1.6)

MNIST
78.7(0.1) 94.1(0.1)
38.4(0.3) 93.0(0.2)

CIFAR10
47.6(0.3) 65.4(0.3)
22.6(0.5) 59.9(0.6)

(a)

(b)

(c)

Figure 7: Results of Diabetes (M = 8) dataset.

14

(a)

(b)

(c)

Figure 8: Results of Boston Housing (M = 8) dataset.

(a)

(b)

(c)

Figure 9: Results of Blob (M = 8) dataset.

(a)

(b)

(c)

Figure 10: Results of Iris (M = 4) dataset.

(a)

(b)

(c)

Figure 11: Results of Breast Cancer (M = 8) dataset.

(a)

(b)

(c)

Figure 12: Results of Wine (M = 8) dataset.

15

(a)

(b)

(c)

Figure 13: Results of QSAR (M = 8) dataset.

(a)

(b)

(c)

Figure 14: Results of MNIST (M = 8) dataset.

(a)

(b)

(c)

Figure 15: Results of CIFAR10 (M = 8) dataset.

(a)

(b)

(c)

Figure 16: Results of MIMIC3 (M = 4) dataset.

(a)

(b)

(c)

Figure 17: Results of ModelNet40 (M = 12) dataset.

16

