
# Gaussian Processes with Differential Privacy

[arXiv](https://arxiv.org/abs/2106.0474), [PDF](https://arxiv.org/pdf/2106.0474.pdf)

## Authors

- Antti Honkela

## Abstract

Gaussian processes (GPs) are non-parametric Bayesian models that are widely used for diverse prediction tasks. Previous work in adding strong privacy protection to GPs via differential privacy (DP) has been limited to protecting only the privacy of the prediction targets (model outputs) but not inputs. We break this limitation by introducing GPs with DP protection for both model inputs and outputs. We achieve this by using sparse GP methodology and publishing a private variational approximation on known inducing points. The approximation covariance is adjusted to approximately account for the added uncertainty from DP noise. The approximation can be used to compute arbitrary predictions using standard sparse GP techniques. We propose a method for hyperparameter learning using a private selection protocol applied to validation set log-likelihood. Our experiments demonstrate that given sufficient amount of data, the method can produce accurate models under strong privacy protection.

## Comments



## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{honkela2021gaussian,
      title={Gaussian Processes with Differential Privacy}, 
      author={Antti Honkela},
      year={2021},
      eprint={2106.00474},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```

## Notes

Type your reading notes here...

