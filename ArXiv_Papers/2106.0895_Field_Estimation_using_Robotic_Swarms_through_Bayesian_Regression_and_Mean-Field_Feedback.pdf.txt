Field Estimation using Robotic Swarms through Bayesian Regression and Mean-Field Feedback
Tongjia Zheng and Hai Lin

arXiv:2106.00895v1 [eess.SY] 2 Jun 2021

Abstract-- Recent years have seen an increased interest in using mean-field density based modelling and control strategy for deploying robotic swarms. In this paper, we study how to dynamically deploy the robots subject to their physical constraints to efficiently measure and reconstruct certain unknown spatial field (e.g. the air pollution index over a city). Specifically, the evolution of the robots' density is modelled by mean-field partial differential equations (PDEs) which are uniquely determined by the robots' individual dynamics. Bayesian regression models are used to obtain predictions and return a variance function that represents the confidence of the prediction. We formulate a PDE constrained optimization problem based on this variance function to dynamically generate a reference density signal which guides the robots to uncertain areas to collect new data, and design mean-field feedback-based control laws such that the robots' density converges to this reference signal. We also show that the proposed feedback law is robust to density estimation errors in the sense of input-to-state stability. Simulations are included to verify the effectiveness of the algorithms.
I. INTRODUCTION
In this paper, we study the deployment and control problem of robotic swarms to quickly and efficiently measure and reconstruct an underlying spatial field. Our work is motivated by environment monitoring problems, in which one needs to dynamically deploy mobile sensors to collect data and reconstruct certain quantity (e.g. the air pollution index).
Employing a large group of mobile sensors provides superior robustness and efficiency, but also poses significant challenges from a control theory perspective. Many methods have been proposed in the literature for controlling robotic swarms, such as graph theory based approaches [1], game theory (especially mean-field game theory) based design [2], distributed optimal control based motion planning [3]. Our work is inspired by the mean-field based modelling and control strategy for robotic swarms [4]. Earlier efforts need to partition the spatial domain and use an abstracted Markov chain model [5], which suffers from the state explosion issues. More recent work that follows the "mean-field" philosophy but provides more powerful modelling capabilities is by using partial differential equations (PDEs) [6], [7], [8], [9]. In this approach, individual robots are modelled by stochastic differential equations and their spatial distribution satisfies an associated PDE, such as the Fokker-Planck equation. Existing mean-field PDE approaches usually assume that a target distribution is given and the goal is to design
*This work was supported by the National Science Foundation under Grant No. IIS-1724070, CNS-1830335, IIS-2007949.
Tongia Zheng and Hai Lin are with the Department of Electrical Engineering, University of Notre Dame, Notre Dame, IN 46556, USA (e-mail: tzheng1@nd.edu, hlin1@nd.edu.).

proper mean-field feedback laws to guide the swarm towards the target distribution. However, in a field estimation task, the target distribution is not known as it is related to the underneath function/quantity to be measured.
To estimate an unknown field, the robots need to move to uncertain areas to collect more data. This goal is related to the resampling problem in regression, which is usually fulfilled using Bayesian regression (BR) [10]. For example, resampling can take place at locations with large predictive variance. However, such resampling techniques are not directly suitable for field estimation tasks because of the inherent dynamics and physcial constraints of the robots ­ we cannot instantly change the sampling positions. Instead we have to design control laws to physically drive them to the new positions. Meanwhile, we need to do it in an energyefficient and robust manner.
This motivates us to integrate BR models into the PDEbased control design to achieve automatic deployment based on the real-time prediction quality. Specifically, BR models are used to construct a prediction for the unknown function, as well as a variance function that represents its predictive confidence. We formulate a PDE-constrained optimization problem based on this variance function to generate a reference model which encodes the desired evolution of the robots' density in order to improve the prediction quality. Then, we design mean-field feedback laws for the robots such that their density evolves according to the reference model, and analyze its robustness in terms of density estimation errors using the notion of input-to-state stability.
The problem of field estimation and deployment has also been studied in recent works [11], [7], [8], [12]. In [8], [12], the authors also consider a field estimation problem followed by an optimal control formulation for swarm deployment. However, the numerical solutions are usually open-loop and have robustness issues due to environmental uncertainty. In [11], [7], the authors formulate an optimal mass transport problem followed by mean-field feedback strategies. Our work differs in that we not only design closed-loop control laws but also study their robustness property. In summary, our contribution includes two aspects. First, we present a candidate framework for integrating machine learning techniques into the mean-field PDE approach for automatically deploying the robots based on real-time performance. Second, we propose mean-field feedback laws for density tracking problems and prove their robustness to density estimation errors. In this way, we can formally guarantee that the real-time deployment requirement generated by the machine learning algorithms will be fulfilled.

The rest of the paper is organized as follow. Section II introduces some preliminaries. Section III gives the problem formulation. Section IV is our main results in which we use BR models to generate reference models and design mean-field feedback laws for the PDE system to converge to the reference model. Section V presents an agent-based simulation to verify the effectiveness.

II. PRELIMINARIES

A. Notation

Let Rn be the n-dimensional Euclidean space. We denote

by  an open, bounded, and connected subset of Rn, with

boundary . Let µ be the Lebesgue measure. For 1  p <

, denote by Lp() the space of functions f such that

 |f (x)|pdµ < , endowed with the norm f Lp() =  |f (x)|pdµ 1/p. The gradient and Laplacian of a scalar function f (x) are denoted by f and f , respectively. The

divergence of a vector field F is denoted by  · F. For 1 

p <  and k  N, denote by W k,p() the Sobolev space of

functions f  Lp() having weak derivatives Df in Lp()

for all multi-indices  of length ||  k, endowed with the

norm f = W k,p()

||k

 |f (x)|p dµ

1/p
.

B. Input-to-state stability

Input-to-state stability (ISS) is a stability notion for studying nonlinear systems with external inputs [13]. To define the ISS concept we need to introduce the following classes of comparison functions [14]:

K := { : R+  R+| is continuous and strictly increasing, (0) = 0, and (r) > 0 for r > 0}
K := {  K| is unbounded} L := { : R+  R+| is continuous and strictly decreasing with lim (t) = 0}
t
KL := { : R+ × R+  R+| is continuous, (·, t)  K, (r, ·)  L, t  0, r > 0}.

Definition 1: [14] Consider a control system  =
(X, U, ) consisting of normed linear spaces (X, · X ) and (U, · U ), called the state space and the input space, endowed with the norms · X and · U respectively, and a transition map  : R+ × X × U  X. The system is called ISS if there exist functions   KL and   K, such that

(t, 0, u) X  ( 0 X , t) + ( u U ),
holds 0  X, t  0 and u  U . It is called locally input-to-state stable (LISS), if there also exists constants x, u > 0 such that the above inequality holds 0 :
0 X  x, t  0 and u  U : u U  u. The following lemma provides a tool for verifying the (L)ISS property by constructing Lyapunov functionals. Lemma 1: [14] If there exists a continuous functional V : X  R+, functions a1, a2, a  K,   K, and constants x, u > 0, such that:
a1( x X )  V (x)  a2( x X ), x  X,

and 0 : 0 X  x, u  U : u U  u, V (x) satisfies V (x)  -a( x X ),  x X  ( u U ),
then the system is LISS. If x =  and u = , then the system is ISS. The corresponding functional V is called an (L)ISS Lyapunov functional.

III. PROBLEM FORMULATION
This work studies the problem of dynamically deploying a
robotic swarm to measure and construct an unknown function f (x) on a domain   Rm. Denote by {Xi(t)}ni=1  Rm the robots' positions, where n is the population. Each robot obtains a noisy measurement yi of f (Xi) such that yi = f (Xi) + , where  follows an i.i.d. Gaussian distribution. We assume a sampling period t so that measurements are taken at discrete time k with t = kt. At each step k, we obtain a data set Dk = {(Xi(k), yi(k)) |i = 1, . . . , n}. We denote Dk = kj=1Dj to represent all the data collected by time kt. The robots' motion is assumed to satisfy

dXi = v(Xi, t)dt + 2(Xi, t)dBt, i = 1, . . . , n, (1)

where Xi   is the position of the i-th robot, v  Rm is the velocity field that acts on the robot, Bt  Rm is an m-dimensional Wiener process which represents stochastic motions, and 2  R is the standard deviation.
The density of the robots, denoted by p(x, t), is known to
be governed by the following Fokker-Planck equation:

tp = - · (vp) + (p) in  × (0, ),

p = p0 on  × {0},

(2)

n · ((p) - vp) = 0 on  × (0, ),

where n is the unit inner normal to the boundary , and p0 is the initial density. The last equation is a reflecting boundary condition to confine the swarm within .
Problem 1: Our goal to design the velocity field v to guide the robots' movements in order to efficiently reconstruct the unknown f (x) with the increasingly rich data collection Dk.
This problem is essentially a resampling problem ­ we
want to take new measurements to construct a better prediction f¯. It however poses additional challenges because we need to consider the robots' physical constraints and
design suitable motion commands to make the resampling more efficient.

IV. MAIN RESULTS
A. Generation of reference models
This section studies the problem of generating reference models for the swarm, i.e. where to resample. Intuitively, we expect the robots to move to the areas where the prediction f¯ is less confident. BR models turn out to fulfill this purpose because besides predicting the function value f¯(x), they also return the variance Var[f¯(x)] to represent its confidence. Our objective is to minimize the variance by resampling f .
Specifically, given Dk, we use BR models (in particular Gaussian process regression models [15]) to obtain a prediction f¯k(x) and its associated variance Vk(x) := Var[f¯k(x)]

for all x  . We want the robots to move to areas with larger

Vk(x). We define Wk(x) = max{Vk(x)-, 0} and construct

a target density pf (x, kt) =



Wk (x) Wk (x)dx

,

where



is

a

small

tolerance to ensure that the algorithm terminates. We would

like to formulate an optimization problem for (2) to reach

pf . An optimization formulation enables us to impose many

practical requirements, such as penalizing the high density

area to avoid concentration (which helps reducing robot-

robot collision) or penalizing the velocity to save energy.

Note that pf is time-varying because Dk grows with time. However, since the robots move continuously, Vk(x) does not

change significantly within a short interval, for which there

is no need to perform regression and update the reference

model at every step. We choose to update the reference

model periodically with a period T (T  t), and within

each period, pf is held fixed. Let tc be the current time and tf := tc + T . We formulate an optimization problem:

tc +T

J =  p(tf ), tf dx +

L(p, v, t)dxdt



tc



s.t. tp = - · [v(x, t)p(x, t)] in 

(3)

p(x, tc) = p0

vp · n = 0 on 

where the constraint is chosen to be a transport equation. (Certainly we can subject to the (2), but it will unnecessarily complicate the optimality conditions to be derived and its numerical solution.) Problem (3) is a PDE-constrained optimization problem. We follow the procedure in [16] to obtain the necessary conditions for optimal solutions:

State equation:

p t

=

-

·

(vp),

s.t. p(x, 0) = p0(x)

vp · n = 0 on 

Co-state equation:

 t

=

L p

-  · v,

(4)

s.t.

(x, tf )

=

 p

|tf

 = 0 on 

Optimization condition:

L v

=

p,

where we corrected a mistake on the boundary condition in [16]. (Note that there is lack of math rigor when applying the calculus of variations for finite dimensional systems to a PDE. We will formally study its well-posedness issue in our future work.) A solution of (4) represents a locally optimal trajectory of pr and vr, so we obtain a reference model:

tpr = - · (vrpr) in  × (0, ),

pr = p0 on  × {0},

(5)

vrpr · n = 0 on  × (0, ),

which describes the desired density evolution for the robots. The reference control law vr obtained in this way is openloop. The remaining task is to design feedback laws v for (2) such that its solution p converges to the solution of (5).

B. Density tracking control
In this section, we study how to design v for the robots such that their density p evolves according to the reference model. Our deign is inspired by the recent work [6], where a mean-field feedback, namely designing v as a function of p, was proposed. Given desired trajectories of pr and vr from (5), we define the tracking error as  = p - pr and design v such that  satisfies the diffusion equation:

t(x, t) =  · [(x, t)(x, t)],

(6)

where  is the diffusion coefficient. Under mild conditions on , its solution converges to a constant function, which will be 0 because for any t,  dx =  pdx -  prdx = 1 - 1 = 0. We propose the mean-field feedback law:

v

=

-

(x,

t)(p

-

pr) - p

(p)

-

vrpr

,

(7)

where  is a design parameter that can be used to locally adjust the velocity magnitude. We require supx,t0 (x, t) <  and infx,t0 (x, t) > 0. The convergence property of (7) is given below.
Theorem 1 (Exponential stability): Consider the PDE
system (2) with control law (7). If the solution satisfies p > 0, then  L2()  0 exponentially.
Proof: Substituting (7) into (2), we obtain

t =  · ()  = 0
n ·  = 0

in  × (0, ), on  × {0}, on  × (0, ),

which is a diffusion equation. Its stability is well-known in
the PDE literature. A proof can be found in [17]. To be well-defined, the control law (7) requires that p > 0.
This requirement can be satisfied if we replace p with an estimate p^. In this case, the control law is given by

v = - (x, t)(p^ - pr) - (p^) - vrpr , p^

(8)

where p^ is obtained using kernel density estimation [18], i.e.

p^(x, t)

=

1 nhm

n

K

1 h

(x

-

Xi(t))

,

(9)

i=1

where

K (x)

=

1 (2)m/2

exp

-

1 2

xx

is the Gaussian kernel.

Remark 1: We should point out that the proposed frame-

work is essentially centralized because we require a commu-

nication center that communicates with the robots to perform

regression, solve the optimization problem and estimate the

density. The deployment algorithm is given in Algorithm 1.

C. Robustness of the control law
Since we replace the original control law (7) with (8), we should discuss its robustness issue with respect to density estimation errors. A similar problem has been studied in our previous work [17]. The control law (8) is more complicated than the one in [17]. Nevertheless, the techniques used there apply to this work. Before presenting the robustness results, we shall discuss the solution property of (2). We denote

Algorithm 1: Deployment algorithm
Each robot i sends its position Xi and measurement (Xi, yi) to the center;
The center estimates p^ using {Xi}ni=1 and performs regression on D0 to obtain V0;
while supx Vk >  do The center generates a reference model and sends {(pr(x, t), vr(x, t)}Tt=0 to all robots; for t = tc : t : tc + T do Each robot computes its own velocity (8) and
sends its new position and measurement to
the center;
The center estimates and sends p^ to all robots;
end The center performs regression on Dk to obtain Vk ; end

by fi the i-th component of a vector field f and denote iu := u/xi for a function u(x, t). The following lemma is proved in [17].
Lemma 2 (Well-posedness [17]): Assume

vi, , i  L( × (0, T )), i and p0  L(). (10)

Then there exists a unique weak solution p for (2) with p 
H1( × (0, T )) and  p(·, t)dx = 1 for t  (0, T ]. If we further assume

ivi, i2  L( × (0, T )), i,

(11)

then p0  (or >)0 implies p  (or >)0 for t  [0, T ]. Due to our choice of K(x) in (9), p^  C()×C((0, T )).
Since  is bounded and n is finite, we have infx,t p^(x, t) > 0 and supx,t ikp^(x, t) <  for any k  N. Therefore, if we additionally have p0 > 0, , pr,  W 2,() × L((0, T )), , vr,i  W 1,() × L((0, T )), then the system (2) under (8) satisfies the regularity conditions (10) and (11). These requirements are mild and can be easily satisfied in practice.
Now we discuss the robustness issue, which can arise in two situations. First, any estimation algorithm contains estimation error due to finite samples. Second, for (8) to satisfy the regularity conditions, sometimes we have to correct p^. For example, we may want to add a small constant to p^ and renormalize it when p^ is close to 0, which introduces artificial estimation errors. We define  := p^/p - 1. Then  = 0 if and only if p^ = p, for which we treat  as the estimation error. Although seemingly unusual, this error model is more suitable for density estimates using KDE. An equivalent way to define  is that p^ = p + p, where the additive noise is weighted by p. It is known that under mild conditions, the estimation error of KDE is asymptotically Gaussian with a covariance proportional to the true density [18]. In other words, the estimation error is more uncertain when the true density is larger. Hence, weighting the noise by p makes  a more uniform error model. The robustness result is given below.

Theorem 2 (ISS): Consider the PDE system (2) with con-

trol law (8). Assume the regularity conditions (10) and (11)

are satisfied and p0 > 0. Then the tracking error  is ISS in

L2 with respect to disturbances

 1+

and
L2

 1+

.
L2

Proof: The proof is a modification of the proof of

Theorem 3 in [17]. First, Lemma 2 implies that p(·, t) is

absolutely continuous. Substituting (8) into (2) and using

p^ = p(1 + ), we obtain

tp =  ·

p

(p^

-

pr

)

- (p^) p^

-

vrpr

+ (p)

=·

(p

-

pr)

+

(

-

)p + pr 1+

-

vrpr

.

Consider

a

Lyapunov

function

V

(t)

=

1 2

(p - pr)2dx. By

the Divergence theorem and the boundary condition, we have

V = (p - pr)(tp - tpr)dx


= - (p - pr) · (p - pr) + vrpr



+

(

-

)p + pr 1+

-

vrpr

dx

=



-||2

-



·

(

-

)p

+ (pr 1+

+

vrpr) dx

Let min := infx,t (x, t) > 0. Since p > 0, there exists a constant  > 0 such that

V

 - min



2 L2

+



-

L



L2

+ pr + vrpr L  L2

 1 +  L2

 1 +  L2

Fix a constant   (0, 1) to split the first term and apply the

Poincare´ inequality [19] for the first two terms. We obtain

V



-

min(1 - C2

)



2 L2

-

min C



L2



L2

+   -  L  L2

 1 +  L2

+ pr + vrpr L  L2

 1+

,
L2

where C > 0 is the constant from the Poincare´ inequality.

Hence, we will have

V



-

min(1 - C2

)



2 L2

if

C pr + vrpr L

 L2 

min

 1+ L2

C  -  L +


1+ L2 .

min

where the right-hand side is a class K function of

 1+ L2

and

 1+

property.

. According to Lemma 1, we obtain the ISS
L2

4

3.5 4

3.5

3

f(x) Prediction error

3

2.5

2.5 2
2

1.5

1.5

1 20
15 10 5 x2

00

20 15 10 5
x1

1

0.5

0

0

5

10

15

20

25

30

Time

Fig. 1: The unknown function (left); prediction error (right).

This theorem means that with the mean-field feedback
control law (8), the density tracking error  L2() remains bounded in the presence of estimation error  and converges asymptotically if  = 0.

V. SIMULATION STUDIES

In this section, we simulate a group of 100 robots to

take measurements and reconstruct a sinc function f (x) =

2+

sin(2 x x

)

over



=

[0, 20]2

(see

Fig.

1).

The

robots'

initial positions are drawn from a uniform distribution over

[0, 7]2. We follow Algorithm 1 to conduct the simulation,

which contains two loops. In the inner loop, the robots take

measurements with a sampling period t = 0.875s and

noise   N (0, 0.04). In the outer loop, we update the

reference model with a period T = 7s, i.e. after receiving

every 8 new data sets. To generate the reference model,

we follow the procedure in Section IV-A to obtain the target

density pf and formulate the optimization problem, in which

we set

(p(tf ), tf ) = wf [D(p(tf ) pf ) + D(pf p(tf ))]

d
L(p, v, t) = wp[D(p pf ) + D(pf p)] + wv vi2

i=1

where

wf ,

wp

and

wv

are

weights,

and

D(p, q)

=

p log

p q

.

The optimality conditions (4) are solved using the general-

ized reduced gradient method given in [16]. It discretizes the

time axis into N intervals and parameterizes every element vl  Rm, l = 1, . . . , N using the Fourier sine series:

IJ

vl(x) =

sin(ix1/b) sin(ix1/c)aijl(t)

i=1 j=1

which forces vl(x) to be zero on the boundary of a rectangular work space [0, b] × [0, c] and hence satisfies the boundary condition of (5). The coefficients aijl  Rm are to be determined. Here N = 12, m = 2 and I = J = 8. With initialized aijl, approximations of p and  are obtained by numerically solving the state and co-state equations in (4). Holding these two approximations fixed, the coefficients aijl are updated by a gradient-based algorithm that minimizes the
augmented cost. This process is iterated until it converges to
a local minimum that satisfies the optimization condition in (4). The obtained coefficients aijk are used to compute vr and generate pr according to (5).
The agents' trajectories are simulated using (1). Their
velocity commands are computed using (8), where we use (9) to estimate p^. The predictive variance drops below the prespecified  = 0.1 threshold after 4T . Simulation results are

given in Fig. 2, where the four columns represent four time steps t = 0, T, 3T and 4T . The prediction error f - f¯ L2 is given in Fig. 1. It is seen that the robots keep moving to areas with larger predictive variance to take more measurements and eventually recover f (x). This verifies that the proposed algorithm is able to robustly guide the robots based on realtime performance.
VI. CONCLUSION AND DISCUSSION
This work presented a candidate framework for integrating machine learning techniques into the mean-field PDE-based approach for robotic swarms to achieve automatic deployment in real-time. We used BR models as an example to illustrate how to generate reference models based on the real-time prediction quality by formulating an optimization problem, and then designed density tracking laws such that the robots' density evolves according to the reference models. The presented algorithms were applicable for field estimation tasks, while the idea of using machine learning for generating reference models and using density tracking laws for controlling the robots applies to a much wider range of applications of robotic swarms. The proposed framework was essentially centralized. Nevertheless, the control strategy was scalable to swarm sizes because each robot only needs to compute its own torque input to follow the velocity field. Our future work will focus on decentralizing the meanfield feedback control algorithm by integrating the distributed density estimation algorithms that we recently proposed [20], [21].
REFERENCES
[1] R. Olfati-Saber, J. A. Fax, and R. M. Murray, "Consensus and cooperation in networked multi-agent systems," Proceedings of the IEEE, vol. 95, no. 1, pp. 215­233, 2007.
[2] J.-M. Lasry and P.-L. Lions, "Mean field games," Japanese journal of mathematics, vol. 2, no. 1, pp. 229­260, 2007.
[3] G. Foderaro, P. Zhu, H. Wei, T. A. Wettergren, and S. Ferrari, "Distributed optimal control of sensor networks for dynamic target tracking," IEEE Transactions on Control of Network Systems, vol. 5, no. 1, pp. 142­153, 2016.
[4] K. Elamvazhuthi and S. Berman, "Mean-field models in swarm robotics: a survey," Bioinspiration & Biomimetics, vol. 15, no. 1, p. 015001, 2019.
[5] B. Ac¸ikmes¸e and D. S. Bayard, "A markov chain approach to probabilistic swarm guidance," in 2012 American Control Conference (ACC). IEEE, 2012, pp. 6300­6307.
[6] U. Eren and B. Ac¸ikmes¸e, "Velocity field generation for density control of swarms using heat equation and smoothing kernels," IFACPapersOnLine, vol. 50, no. 1, pp. 9405­9411, 2017.
[7] V. Krishnan and S. Mart´inez, "Distributed control for spatial selforganization of multi-agent swarms," SIAM Journal on Control and Optimization, vol. 56, no. 5, pp. 3642­3667, 2018.
[8] K. Elamvazhuthi, H. Kuiper, and S. Berman, "Pde-based optimization for stochastic mapping and coverage strategies using robotic ensembles," Automatica, vol. 95, pp. 356­367, 2018.
[9] T. Zheng, Z. Liu, and H. Lin, "Complex pattern generation for swarm robotic systems using spatial-temporal logic and density feedback control," in 2020 American Control Conference (ACC). IEEE, 2020, pp. 5301­5306.
[10] A. Gelman, J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari, and D. B. Rubin, Bayesian data analysis. CRC press, 2013.
[11] M. H. de Badyn, U. Eren, B. Ac¸ikmes¸e, and M. Mesbahi, "Optimal mass transport and kernel density estimation for state-dependent networked dynamic systems," in 2018 IEEE Conference on Decision and Control (CDC). IEEE, 2018, pp. 1225­1230.

x2

time = 0 20

time = 7 20

time = 21 20

time = 28 20

15

15

15

15

x2

x2

x2

10

10

10

10

5

5

5

5

0

0

0

0

0

5

10

15

20

0

5

10

15

20

0

5

10

15

20

0

5

10

15

20

x

x

x

x

1

1

1

1

4

4

4

4

Prediction

Prediction

Prediction

3

3

3

3

2

2

2

2

1 20
10

1

20

20

10

10

1

20

20

10

10

1

20

20

10

10

20 10

x2

00

x1

x2

00

x1

x2

00

x1

x2

00

x1

1

1

1

1

Prediction

Standard deviation

Standard deviation

Standard deviation

Standard deviation

0.5

0.5

0.5

0.5

0 20
10

0

20

20

10

10

0

20

20

10

10

0

20

20

10

10

20 10

x2

00

x1

20

x2

00

x1

20

x2

00

x1

20

x2

00

x1

20

15

15

15

15

x2

x2

x2

x2

10

10

10

10

5

5

5

5

0

0

0

0

0

5

10

15

20

0

5

10

15

20

0

5

10

15

20

0

5

10

15

20

Fig.

2:

x1
Movements of

the

robots

(1st

row),

x1
prediction

f¯(x)

using

GP

x1
regression

(2nd

row),

predictive

x1
standard

deviation

V(x) of GP regression (3rd row) and generated velocity fields v (4th row).

[12] J. Morelli, P. Zhu, B. Doerr, R. Linares, and S. Ferrari, "Integrated mapping and path planning for very large-scale robotic (vlsr) systems," in 2019 International Conference on Robotics and Automation (ICRA). IEEE, 2019, pp. 3356­3362.
[13] E. D. Sontag and Y. Wang, "On characterizations of the input-to-state stability property," Systems & Control Letters, vol. 24, no. 5, pp. 351­ 359, 1995.
[14] S. Dashkovskiy and A. Mironchenko, "Input-to-state stability of infinite-dimensional control systems," Mathematics of Control, Signals, and Systems, vol. 25, no. 1, pp. 1­35, 2013.
[15] C. E. Rasmussen, "Gaussian processes in machine learning," in Summer School on Machine Learning. Springer, 2003, pp. 63­71.
[16] K. Rudd, G. Foderaro, and S. Ferrari, "A generalized reduced gradient method for the optimal control of multiscale dynamical systems," in 52nd IEEE Conference on Decision and Control. IEEE, 2013, pp. 3857­3863.
[17] T. Zheng, Q. Han, and H. Lin, "Transporting robotic swarms via meanfield feedback control," arXiv preprint arXiv:2006.11462, 2020.
[18] B. P. Rao, "Nonparametric functional estimation," Bull. Amer. Math. Soc, vol. 14, pp. 310­312, 1986.
[19] G. M. Lieberman, Second order parabolic differential equations. World scientific, 1996.
[20] T. Zheng, Q. Han, and H. Lin, "Pde-based dynamic density estimation for large-scale agent systems," IEEE Control Systems Letters, 2020.
[21] T. Zheng and H. Lin, "Distributed density filtering for large-scale systems using mean-filed models," 2021 American Control Conference (ACC), to appear, 2021.

