An occupation kernel approach to optimal control

arXiv:2106.00663v1 [math.OC] 1 Jun 2021

Rushikesh Kamalapurkar and Joel A. Rosenfeld
In this effort, a novel operator theoretic framework is developed for data-driven solution of optimal control problems. The developed methods focus on the use of trajectories (i.e., time-series) as the fundamental unit of data for the resolution of optimal control problems in dynamical systems. Trajectory information in the dynamical systems is embedded in a reproducing kernel Hilbert space (RKHS) through what are called occupation kernels. The occupation kernels are tied to the dynamics of the system through the densely defined Liouville operator. The pairing of Liouville operators and occupation kernels allows for lifting of nonlinear finite-dimensional optimal control problems into the space of infinite-dimensional linear programs over RKHSs.

I. Introduction
N solutions of optimal control problems are obtained by using Pontryagin's maximum principle [1] to convert the optimal control problem into a two-point boundary value problem [2, 3] or a nonlinear programming problem [4­9]. While there is a rich history of literature on the topic of numerical optimal control, the computational efficiency of numerical optimal control is limited by that of nonlinear programming, where solutions of large problems can be computationally prohibitive and the solutions, when available, are typically only locally optimal.
Based on the seminal work of Lasserre [10] on moments and positive polynomials, occupation measure approaches that convert a nonlinear optimal control problem into an infinite dimensional linear program that can be efficiently solved using sum of squares based convex programming methods were developed in results such as [11­14].
While computationally efficient, techniques that utilize occupation measures are typically only applicable to systems where the functions that describe the dynamics, the cost functions, and the constraint sets are polynomials. The techniques developed in this paper also convert finite dimensional nonlinear optimal control problems into infinite dimensional linear programs, but utilize a reproducing kernel Hilbert space framework. An advantage of framing the infinite dimensional linear program within the reproducing kernel Hilbert space framework is that the developed tools are applicable to optimal control problems with a broader range of cost functions and constraining sets. Principally, the advantage is realized by exchanging the moment problem for occupation measures with the more flexible approximation abilities of reproducing kernel Hilbert spaces.

II. Reproducing Kernel Hilbert Spaces
Definition 1. A real-valued reproducing kernel Hilbert space (RKHS), , over a set  R is a Hilbert space of functions :  R such that for every  , the evaluation functional := ( ) is bounded.

By the Reisz representation theorem, for each  there is a corresponding function  such that

,

= ( ), where , denotes the inner product. For each RKHS, there is a uniquely identified kernel

function, ( , ) := , , such that for any finite collection of points, { } =1, the corresponding Gram matrix, ( ( , )) , =1, is positive semi-definite.
The importance of RKHSs lies in their ability to perform as function approximators. In particular, just as the

collection of polynomials is dense inside of the space of continuous functions over compact subsets of R , universal

RKHSs are those spaces that are also dense in the space of continuous functions over compact subsets of R . Moreover,

the following lemma demonstrates that it is sufficient to consider linear combinations of the kernel functions themselves

for function approximation when the kernel is in a universal RKHS.

Lemma 2. Consider the subset := { (·, ) :  } of a RKHS over a set with kernel . Then span is dense in with respect to the Hilbert space norm. Moreover, if is continuous, then span is dense in with respect to the uniform norm over restrictions to compact subsets of .

Proof. See [15, Theorem 4.21].
Assistant Professor, School of Mechanical Engineering, Oklahoma State University, Stillwater, OK 74078. Assistant Professor, Department of Mathematics and Statistics, University of South Florida, Tampa, Fl 33620.

1

III. Problem formulation

Let ( ) be a real-valued RKHS of continuous functions over the set . Let and be compact subsets of R ,

a compact subset of R ,  := [0, ] × , and =  × . Throughout the rest of this manuscript the RKHSs ( ),

( ) and () denote the RKHSs obtained through the functions in ( ) where the inputs have been projected to

, , and , respectively. Let : [0, ] × R × R  R be a locally Lipschitz function and consider the dynamical

system

= ( , , ),

(0) = 0  R .

(1)

A state of the dynamical system corresponding to the initial condition 0 and controller : [0, ]  R will be written as ( ; 0, ).
For a fixed , the optimal control problem is formulated as the need to minimize the cost



( (·), (·)) = ( , ( ), ( ))d + ( ( )),

(2)

0

for functions   ( ) and  ( ), over the set of differentiable functions : [0, ]  R and continuous functions [0, ]  R subject to the constraints (1). For ease of exposition, the formulation considered here is more restrictive than strictly necessary. The methods developed in the following can be extended to include measurable control signals and absolutely continuous state trajectories.
In the following, occupation kernels and Liouville operators, first introduced in [16] are utilized to lift the nonlinear optimal control problem into the space of infinite-dimensional linear programs.

IV. Occupation kernels and the cost functional

Whenever ( , ( ), ( )) 

for all  [0, ], the functional




0

( , ( ), ( ))d , that maps from ( ) to R,

is linear and bounded. Indeed, given the kernel function corresponding to ( ), it can be seen that





( , ( ), ( ))d 

, (·, ( , ( ), ( ))) ( )d

0

0



( ) sup (( , ( ), ( )), ( , ( ), ( ))) 

( ) sup ( , ).

[0, ]



As such, by the Reisz representation theorem, there exists a function  (·), (·) 

(

)

such

that


0

( , ( ), ( ))d =

,  (·), (·) ( ). The function  (·), (·) is the occupation kernel corresponding to the signals (·) and (·). Note

that at this juncture, the signals (·) and (·) are independent, i.e., (·) is not necessarily a trajectory of the dynamical

system (1) in response to (·).

The occupation kernel itself may be expressed as 

( ·) ,

(·) (

)

 =0

( , ( , ( ), ( )))d . Moreover,





( ·) ,

( ·)

2 (

)=

(( , ( ), ( )), ( , ( ), ( ))) d ,

(3)

00

and when ( , ) = ( - 2) is a radial basis function, such as the Wendland RBF or the Gaussian RBF, (3) may be bounded as  0, 2 ( )  2(0)
Using the occupation kernels and the reproducing property , (·, ) = ( ) of the kernel function
 corresponding to the RKHS ( ), the cost functional in (2) can be expressed as

( (·), (·)) = ,  (·), (·) ( ) + , (·, ( )) ( ).

(4)

Note that the cost functional is linear with respect to the kernels  (·), (·) and . If the dynamical system that constrains (·) to be a solution in response to (·) can also be expressed as a linear constraint on the space of kernels,
the optimal control problem can be posed as a linear program in the infinite dimensional kernel space.

2

V. System dynamics and the total derivative operator
In the following, a formulation of the dynamics in terms of total derivative operators is developed to construct the aforementioned linear constraint.

Definition 3. Define the total derivative operator with symbol denoted by : D ( )  ( ) as ( , ) + ( , , ) ·  ( , ) where the domain D ( ) is defined cannonically as

( , ) :=

D ( ) = {  () :  ( )}.

(5)

The total derivative operator is seldom a compact operator. As such, to analyze the relationship between the total derivative operator and the occupation kernels, the theory of densely defined operators is leveraged.

Definition 4 (Densely Defined Operator). Given a set D ( )  , a linear operator : D ( )  is said to be densely defined when D ( ) is dense in .

Differentiation is a canonical example of a densely defined operator. The following example, while not posed over a RKHS, demonstrates this property of differentiation over the Hilbert space 2 [0, 1].

Example 5. Let = and suppose that the Hilbert space in question is 2 [0, 1]. Since the derivative of any

polynomial is again a is a dense domain for

polynomial . It is also

and polynomials are dense in 2 [0, 1], D ( clear that D ( ) cannot be extended to all of

)

:= { 2 [0,

: 1] as

is a polynomial ( ) = is in

over [0, 1]} 2 [0, 1] and

(

)

=

1 2

is not.

The relationship between the total derivative operator and the occupation kernels is expressed through the adjoint of the total derivative operator, and for the development to be cogent, the adjoint needs to be densely defined. Since adjoints of closed operators over a Hilbert space are densely defined [17, Chapter 5], closedness of the total derivative operator is analyzed in the following.

Definition 6. Let be an operator over . is said to be closed, if whenever { }=1  ,  and   according to the Hilbert space norm, then  D ( ) and = .

The following theorem establishes a connection between the total derivative operator and signals (·) and (·) whenever (·) is a solution of (1) under (·). For brevity of notation, let  0, denote the occupation kernel  (·, 0, (·)), (·) .

Theorem 7. The operator introduced in Definition 3 is closed. Moreover, for an admissible trajectory  ( , ( ), ( )), with initial condition 0, and that resides within a compact set for all  [0, ], the function  0, is in the domain of the adjoint of .

Proof. Suppose that { }=0  D ( )  () such that   () and

  ( ). Since the

differentiability of the functions in is inherited from the kernel function (see [15, Corollary 4.36]), the function

is well defined for each  () (but is not necessarily a function in ()). However, for any fixed and the

mapping  ( , ) is a continuous linear functional over (). By [15, Corollary 4.36],

(, )-

(, ) =

( ( , ) - ( , ))  - ()

+ ((( , )), (( , ))).

Hence,

( , )  ( , ) for each  and = 1, . . . , . Hence,

(, )+ (, , )· (, ) 

( , ) + ( , , ) ·  ( , ) as ( , , ) is constant with respect to . Thus,  = and  D ( ), and is
closed with the domain given in Definition 3. To demonstrate that  0, is in the domain of  , note that

 ( , ( )) + ( , ( ), ( )) ( , ( ))
0
= ,  (·, ( , ( ))) -  (·, (0, (0))) () 

 =
0
()

( , ( )) = | ( , ( )) - (0, (0))|  (·, ( , ( ))) -  (·, (0, (0))) () .

Finally, given bounds on and ( ) 2, a bound on  (·, ( , ( ))) -  (·, (0, (0))) () may be established.

Thus, the functional over D ( ) given as 

,  0, is bounded when  ( , ( ), ( )) is a trajectory of the

system. It follows that the function  0, is in the domain of the adjoint of the operator . That is,

,  0, ( ) = ,   0, () = ( , ( )) - (0, (0))

(6)

for all  D ( ).

3

Through consideration of (6) for an admissible trajectory satisfying the hypothesis of Theorem 7,  D ( ) and setting ( )  ( , )  ( ), it can be observed that

,  (·, (0, 0)) () = (0, (0)) = - ,   0, + ( , ( )) = - ,  0, ( ) + , (·, ( )) ( ) = (- , ), ( 0, , (·, ( ))) ( )× ( ).

Letting L : D ( )  ( ) × ( ) denote the linear mapping L = - , , it follows that

, L ( 0, , (·, ( ))) () = ,  (·, (0, 0)) () for all  (). Hence, the system dynamics are en-

coded by the linear constraint

L ( 0, , (·, ( ))) =  (·, (0, 0)).

(7)

VI. A reformulation of the optimal control problem
Using (4) and (7), the optimal control problem is expressed as an infinite dimensional linear program

:
 0,

min
, (·,

(

))

(

0,

,

subject to: L ( 0, ,

(·, ( ))), (, ) ( )× ( ) (·, ( ))) =  (·, (0, 0)).

To solve , finite-dimensional representation of the decision variables  0, and (·, ( )) is required. The representation is cogent under the following assumptions.

Assumption 8. is densely defined on () together with a countable basis for D ( ), given as { }=1  D ( ). Furthermore, for all  , the kernel functions satisfy (·, )  D ( ).

Under Assumption 8, the optimal control problem can be expressed as the need to find the optimal real valued weights { } =1 and { } =1 that provide approximations for  0, and (·, ( )) as

 0, (·) 

(·, )

(8)

=1

(·, ( )) 
=1
where { } =1  is a collection of center in , and { } =1  of can then be evaluated as

(·, ),

(9)

is a collection of centers in . The objective function

( 0, , (·, ( ))), (, ) ( )× ( ) 
=1

(·, ),
=1

(·, ) , (, )
( )× ( )

=
=1

(·, ),  ( ) +
=1

(·, ),

( )=

( ) +

=1

=1

( ). (10)

Similarly, the constraint in is satisfied provided L , ( 0, , (·, ( ))) ( )× ( ) = (0, 0) for all  D ( ), which in turn, is satisfied provided L , ( 0, , (·, ( ))) ( )× ( ) = (0, 0) for all = 1, · · · , . Selecting a finite set of basis functions { 1, . . . , }, the constraint of can thus be approximated using linear
constraints of the form

( , )-

( ) = (0, 0), = 1, · · · , .

(11)

=1

=1

The optimal control problem thus admits the finite-rank representation

subject to:
=1

: min

( ) +

()

{ } =1 , { } =1 =1

=1

( , )-
=1

( ) = (0, 0),

= 1, · · · , .

4

To ensure that the optimization problem is bounded, (3) may be employed as  0, 2  2(0), when is the Gaussian or Wendland RBF, and (·, ( )) 2  sup  ( , ). Alternatively, (0) may be replaced by an appropriate supremum bound. Depending on the selection of the kernel, a theoretically achievable approximation of  0, and (·, ( )) can be justified based on the density (or fill distance) of the centers within their respective parent sets.
VII. Conclusion
In this abstract, the concepts of occupation kernels and total derivative operators are utilized to lift a nonlinear optimal control problem into a linear infinite-dimensional optimal control problem over functions in a RKHS. A finite-rank representation of the infinite-dimensional problem is obtained using kernel functions of the RKHSs and a countable basis for the domain of the total derivative operator. The authors plan to include an expanded introduction that places this work in the context of other lifting techniques such as occupation measures, provide a procedure to extract the optimal value function from a solution of , and add a few example problems that demonstrate the utility of the developed methods.
VIII. Acknowledgements
This research was supported by the Air Force Office of Scientific Research (AFOSR) under contract numbers FA9550-20-1-0127 and FA9550-21-1-0134, and the National Science Foundation (NSF) under award 2027976. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsoring agencies.
References
[1] Pontryagin, L. S., Boltyanskii, V. G., Gamkrelidze, R. V., and Mishchenko, E. F., The mathematical theory of optimal processes, Interscience, New York, 1962.
[2] von Stryk, O., and Bulirsch, R., "Direct and indirect methods for trajectory optimization," Ann. Oper. Res., Vol. 37, No. 1, 1992, pp. 357­373.
[3] Betts, J. T., "Survey of numerical methods for trajectory optimization," J. Guid. Control Dynam., Vol. 21, No. 2, 1998, pp. 193­207.
[4] Hargraves, C. R., and Paris, S. W., "Direct trajectory optimization using nonlinear programming and collocation," J. Guid. Control Dynam., Vol. 10, No. 4, 1987, pp. 338­342.
[5] Huntington, G. T., "Advancement and analysis of a Gauss pseudospectral transcription for optimal control," Ph.D. thesis, Department of Aeronautics and Astronautics, MIT, May 2007.
[6] Fahroo, F., and Ross, I. M., "Pseudospectral methods for infinite-horizon nonlinear optimal control problems," J. Guid. Control Dynam., Vol. 31, No. 4, 2008, pp. 927­936.
[7] Rao, A. V., Benson, D. A., Darby, C. L., Patterson, M. A., Francolin, C., and Huntington, G. T., "Algorithm 902: GPOPS, a MATLAB software for solving multiple-phase optimal control problems using the Gauss pseudospectral method," ACM Trans. Math. Softw., Vol. 37, No. 2, 2010, pp. 1­39.
[8] Darby, C. L., Hager, W. W., and Rao, A. V., "An hp-adaptive pseudospectral method for solving optimal control problems," Optim. Control Appl. Methods, Vol. 32, No. 4, 2011, pp. 476­502. https://doi.org/10.1002/oca.957.
[9] Garg, D., Hager, W. W., and Rao, A. V., "Pseudospectral methods for solving infinite-horizon optimal control problems," Automatica, Vol. 47, No. 4, 2011, pp. 829­837.
[10] Lasserre, J. B., Moments, Positive Polynomials and Their Applications, Imperial College Press, 2010.
[11] Lasserre, J. B., Henrion, D., Prieur, C., and Trélat, E., "Nonlinear optimal control via occupation measures and LMIrelaxations," SIAM J. Control Optim., Vol. 47, No. 4, 2008, pp. 1643­1666.
[12] Majumdar, A., Vasudevan, R., Tobenkin, M. M., and Tedrake, R., "Convex optimization of nonlinear feedback controllers via occupation measures," Int. J. Robot. Res., Vol. 33, No. 9, 2014, pp. 1209­1230.
5

[13] Claeys, M., Daafouz, J., and Henrion, D., "Modal occupation measures and LMI relaxations for nonlinear switched systems control," Automatica, Vol. 64, 2016, pp. 143­154.
[14] Zhao, P., Mohan, S., and Vasudevan, R., "Control synthesis for nonlinear optimal control via convex relaxations," Proc. Am. Control Conf., 2017, pp. 2654­2661.
[15] Steinwart, I., and Christmann, A., Support vector machines, Information Science and Statistics, Springer, New York, 2008. [16] Rosenfeld, J., Russo, B., Kamalapurkar, R., and Johnson, T., "The Occupation Kernel Method for Nonlinear System Identifi-
cation," arXiv:1909.11792, 2020. Submitted to SIAM Journal on Control and Optimization. [17] Pedersen, G. K., Analysis now, Vol. 118, Springer Science & Business Media, 2012.
6

