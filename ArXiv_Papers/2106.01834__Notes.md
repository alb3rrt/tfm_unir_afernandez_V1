
# Continual Learning in Deep Networks: an Analysis of the Last Layer

[arXiv](https://arxiv.org/abs/2106.01834), [PDF](https://arxiv.org/pdf/2106.01834.pdf)

## Authors

- Timothée Lesort
- Thomas George
- Irina Rish

## Abstract

We study how different output layer types of a deep neural network learn and forget in continual learning settings. We describe the three factors affecting catastrophic forgetting in the output layer: (1) weights modifications, (2) interferences, and (3) projection drift. Our goal is to provide more insights into how different types of output layers can address (1) and (2). We also propose potential solutions and evaluate them on several benchmarks. We show that the best-performing output layer type depends on the data distribution drifts or the amount of data available. In particular, in some cases where a standard linear layer would fail, it is sufficient to change the parametrization and get significantly better performance while still training with SGD. Our results and analysis shed light on the dynamics of the output layer in continual learning scenarios and help select the best-suited output layer for a given scenario.

## Comments



## Source Code

Official Code



Community Code

- [https://paperswithcode.com/paper/continual-learning-in-deep-networks-an](https://paperswithcode.com/paper/continual-learning-in-deep-networks-an)

## Bibtex

```tex
@misc{lesort2021continual,
      title={Continual Learning in Deep Networks: an Analysis of the Last Layer}, 
      author={Timothée Lesort and Thomas George and Irina Rish},
      year={2021},
      eprint={2106.01834},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```

## Notes

Type your reading notes here...

