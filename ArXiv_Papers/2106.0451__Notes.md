
# Highlight Timestamp Detection Model for Comedy Videos via Multimodal Sentiment Analysis

[arXiv](https://arxiv.org/abs/2106.0451), [PDF](https://arxiv.org/pdf/2106.0451.pdf)

## Authors

- Fan Huang

## Abstract

Nowadays, the videos on the Internet are prevailing. The precise and in-depth understanding of the videos is a difficult but valuable problem for both platforms and researchers. The existing video understand models do well in object recognition tasks but currently still cannot understand the abstract and contextual features like highlight humor frames in comedy videos. The current industrial works are also mainly focused on the basic category classification task based on the appearances of objects. The feature detection methods for the abstract category remains blank. A data structure that includes the information of video frames, audio spectrum and texts provide a new direction to explore. The multimodal models are proposed to make this in-depth video understanding mission possible. In this paper, we analyze the difficulties in abstract understanding of videos and propose a multimodal structure to obtain state-of-the-art performance in this field. Then we select several benchmarks for multimodal video understanding and apply the most suitable model to find the best performance. At last, we evaluate the overall spotlights and drawbacks of the models and methods in this paper and point out the possible directions for further improvements.

## Comments



## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{huang2021highlight,
      title={Highlight Timestamp Detection Model for Comedy Videos via Multimodal Sentiment Analysis}, 
      author={Fan Huang},
      year={2021},
      eprint={2106.00451},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

## Notes

Type your reading notes here...

