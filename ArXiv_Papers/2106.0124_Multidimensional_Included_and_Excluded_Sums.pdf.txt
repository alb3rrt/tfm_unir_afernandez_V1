Multidimensional Included and Excluded Sums

Helen Xu

Sean Fraser

Charles E. Leiserson

arXiv:2106.00124v1 [cs.DS] 31 May 2021

Abstract This paper presents algorithms for the included-sums

(x1, x2)

and excluded-sums problems used by scientific computing applications such as the fast multipole method.

n1

k1

X

These problems are defined in terms of a -dimensional

k2

array of  elements and a binary associative operator 

on the elements. The included-sum problem requires

that the elements within overlapping boxes cornered at

n2

each element within the array be reduced using . The

(a)

(b)

excluded-sum problem reduces the elements outside each Figure 1: An illustration of included and excluded sums box. The weak versions of these problems assume that in 2 dimensions on an 1 × 2 matrix using a (1, 2)-box.
the operator  has an inverse , whereas the strong (a) For a coordinate (1, 2) of the matrix, the included-sums

versions do not require this assumption. In addition to problem requires all the points in the 1 × 2 box cornered

studying existing algorithms to solve these problems, we at (1, 2), shown as a grey rectangle, to be reduced using a

introduce three new algorithms. The bidirectional box-sum (BDBS) algorithm
solves the strong included-sums problem in ( ) time, asymptotically beating the classical summedarea table (SAT) algorithm, which runs in (2 )

binary associative operator . The included-sums problem requires that this reduction be performed at every coordinate of the matrix, not just at a single coordinate as is shown in the figure. (b) A similar illustration for excluded sums, which reduces the points outside the box.

and which only solves the weak version of the problem. image to answer queries for the sum of elements in arbi-

Empirically, the BDBS algorithm outperforms the SAT trary rectangular subregions of a matrix in constant time.

algorithm in higher dimensions by up to 17.1×.

The integral image has applications in real-time image

The box-complement algorithm can solve the processing and filtering [18]. The fast multipole method

strong excluded-sums problem in ( ) time, asymp- (FMM) is a widely used numerical approximation for the

totically beating the state-of-the-art corners algorithm calculation of long-ranged forces in various  -particle

by Demaine et al., which runs in (2 ) time. In 3 simulations [2, 16]. The essence of the FMM is a reduc-

dimensions the box-complement algorithm empirically tion of a neighboring subregion's elements, excluding

outperforms the corners algorithm by about 1.4× given elements too close, using a multipole expansion to allow

similar amounts of space.

for fewer pairwise calculations [9, 12]. Specifically, the

The weak excluded-sums problem can be solved in multipole-to-local expansion in the FMM adds relevant

( ) time by the bidirectional box-sum comple- expansions outside some close neighborhood but inside

ment (BDBSC) algorithm, which is a trivial extension some larger bounding region for each element [2, 28].

of the BDBS algorithm. Given an operator inverse , High-dimensional applications include the FMM for par-

BDBSC can beat box-complement by up to a factor of 4. ticle simulations in 3D space [8,17] and direct summation

problems in higher dimensions [25].

1 Introduction

These problems give rise to the excluded-sums

Many scientific computing applications require reducing many (potentially overlapping) regions of a tensor, or multidimensional array, to a single value for each region quickly and accurately. For example, the integral-image problem (or summed-area table) [7, 11] preprocesses an

problem [13], which underlies applications that require reducing regions of a tensor to a single value using a binary associative operator. For example, the excludedsums problem corresponds to the translation of the local expansion coefficients within each box in the FMM [16]. The problems are called "sums" for ease of presentation,

Computer Science and Artificial Intelligence Laboratory. but the general problem statements (and therefore Massachusetts Institute of Technology. Email: {hjxu, sfraser, algorithms to solve the problems) apply to any context

cel}@mit.edu.

involving a monoid (, , ), where  a set of values, 

1

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

is a binary associative operator defined on , and    is the identity for .
Although the excluded-sums problem is particularly challenging and meaningful for multidimensional tensors, let us start by considering the problem in only 2 dimensions. And, to understand the excluded-sums









1 3 6 2 5 16 19 10 10 7 75 72 81 81 84

 

3

9

1

1

2 18 16 10 8

4 73 75 81 83 87

 

5

1

5

3

2 13 11 10 14 1178 80 81 77 80

 

4

3

2

0

9 15 8 10 24 1776 83 81 67 74

6 2 1 7 8 8 3 8 15 8 83 78 83 76 83

problem, it helps to understand the included-sums

(a)

(b)

(c)

problem as well. Figure 1 illustrates included and excluded sums in 2 dimensions, and Figure 2 provides examples using ordinary addition as the  operator. We have an 1 × 2 matrix  of elements over a monoid

Figure 2: Examples of the included- and excluded-sums problems on an input matrix in 2 dimensions with box size (3, 3) using the max operator. (a) The input matrix. The square shows the box cornered at (3, 3). (b) The solution for the included-sums problem with the + operator. The

(, , ). We also are given a "box size" k = (1, 2) highlighted square contains the included sum for the box

such that 1  1 and 2  2. The included sum at in (a). The included-sums problem requires computing the

a coordinate (1, 2), as shown in Figure 1(a), involves included sum for every element in the input matrix. (c) A

reducing -- accumulating using  -- all the elements similar example for excluded sums. The highlighted square

of  inside the k-box cornered at (1, 2), that is,

contains the excluded sum for the box in (a).

1+1-1 2+2-1
  [1, 2] ,

problem, and any algorithm for the strong excludedsums problem trivially solves the weak excluded-sums

1=1 2=2

problem. This paper presents efficient algorithms for

where if a coordinate goes out of range, we assume both the weak and strong excluded-sums problems.

that its value is the identity . The included-sums

problem computes the included sum for all coordinates Summed-area Table for Weak Excluded Sums

of , which can be straightforwardly accomplished with The summed-area table (SAT) algorithm uses the

four nested loops in (1212) time. Similarly, the classical summed-area table method [7,11,29] to solve the

excluded sum at a coordinate, as shown in Figure 1(b), weak included-sums problem on a -dimensional tensor

reduces all the elements of  outside the k-box cornered  having  elements in (2 ) time. This algorithm

at (1, 2). The excluded-sums problem computes precomputes prefix sums along each dimension of  and

the excluded sum for all coordinates of , which can be uses inclusion-exclusion to "add" and "subtract" prefixes

straightforwardly accomplished in (12(1 - 1)(2 - to find the included sum for arbitrary boxes. The SAT

2)) time. We shall see much better algorithms for both algorithm cannot be used to solve the strong included-

problems.

sums problem, however, because it requires an operator

inverse. The summed-area table algorithm can easily

Excluded Sums and Operator Inverse One way be extended to an algorithm for weak excluded-sums by

to solve the excluded-sums problem is to solve the totaling the entire tensor and subtracting the solution

included-sums problem and then use the inverse  of to weak included sums. We will call this algorithm the

the  operator to "subtract" out the results from the SAT complement (SATC) algorithm.

reduction of the entire tensor. This approach fails

for operators without inverse, however, such as the Corners Algorithm for Strong Excluded Sums

maximum operator max. As another example, the The naive algorithm for strong excluded sums that just

FMM involves solving the excluded-sums problem over sums up the area of interest for each element runs in

a domain of functions which cannot be "subtracted," ( 2) time in the worst case, because it wastes work by

because the functions exhibit singularities [13]. Even recomputing reductions for overlapping regions. To avoid

for simpler domains, using the inverse (if it exists) may recomputing sums, Demaine et al. [13] introduced an

have unintended consequences. For example, subtracting algorithm that solve the strong excluded-sums problem

finite-precision floating-point values can suffer from in arbitrary dimensions, which we will call the corners

catastrophic cancellation [13, 30] and high round-off algorithm.

error [19]. Some contexts may permit the use of an

At a high level, the corners algorithm partitions the

inverse, but others may not.

excluded region for each box into 2 disjoint regions

Consequently, we refine the included- and excluded- that each share a distinct vertex of the box, while

sums problems into weak and strong versions. The collectively filling the entire tensor, excluding the box.

weak version requires an operator inverse, while the The algorithm heavily depends on prefix and suffix sums

strong version does not. Any algorithm for the included- to compute the reduction of elements in each of the

sums problem trivially solves the weak excluded-sums disjoint regions.

2

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

algorithm takes (2 ) time. With ( ) space, the corners algorithm takes (2 ) time.

Contributions This paper presents algorithms for in-

cluded and strong excluded sums in arbitrary dimensions

that improve the runtime from exponential to linear in

the number of dimensions. For strong included sums,

we introduce the bidirectional box-sum (BDBS) al-

gorithm that uses prefix and suffix sums to compute

the included sum efficiently. The BDBS algorithm can

be easily extended into an algorithm for weak excluded

sums, which we will call the bidirectional box-sum

complement (BDBSC) algorithm. For strong excluded

sums, the main insight in this paper is the formulation of

the excluded sums in terms of the "box complement" on

which the box-complement algorithm is based. Table 1

Figure 3: Space and time per element of the corners and box- summarizes all algorithms considered in this paper.

complement algorithms in 3 dimensions. We use Corners(c)

Figure 3 illustrates the performance and space usage

and Corners Spine to denote variants of the corners algorithm
with extra space. We set the number of elements  = 681472 = 883 and the box lengths 1 = 2 = 3 = 4 (for  = 64).

of the box-complement algorithm and variants of the 3D corners algorithm. Since the paper that introduced the corners algorithm stopped short of a general construction in higher dimensions, the 3D case is the highest

dimensionality for which we have implementations of

the box-complement and corners algorithm. The 3D

case is of interest because applications such as the FMM

often present in three dimensions [8, 17]. We find that

the box-complement algorithm outperforms the corners

algorithm by about 1.4× when given similar amounts of

space, though the corners algorithm with twice the space

as box-complement is 2× faster. The box-complement

algorithm uses a fixed (constant) factor of extra space,

while the corners algorithm can use a variable amount

of space. We found that the performance of the corners

algorithm depends heavily on its space usage. We use

Corners(c) to denote the implementation of the corners

algorithm that uses a factor of  in space to store leaves

in the computation tree and gather the results into the

output. Furthermore, we also explored a variant of the

Figure 4: Time per element of algorithms for excluded sums in corners algorithm in Appendix A, called Corners Spine, arbitrary dimensions. The number of elements  of the tensor which uses extra space to store the spine of the compuin each dimension was in the range [2097152, 134217728] tation tree and asymptotically reduce the runtime.

(selected to be a exact power of the number of dimensions).

Figure 4 demonstrates how algorithms for weak

For each number of dimensions , we set the box volume excluded sums scale with dimension. We omit the corners

 = 8.

algorithm because the original paper stopped short of

Since the original article that proposed the corners algorithm does not include a formal analysis of its runtime or space usage in arbitrary dimensions, we present one in Appendix A. Given a -dimensional tensor of  elements, the corners algorithm takes (2 ) time to compute the excluded sum in the best case because there are 2 corners and each one requires ( ) time to add its contribution to each excluded box. As we'll see, the bound is tight: given ( ) space, the corners

a construction of how to find the corners in higher dimensions. We also omit an evaluation of includedsums algorithms because the relative performance of all algorithms would be the same. The naive and summed-area table perform well in lower dimensions but exhibit crossover points (at 3 and 6 dimensions, respectively) because their runtimes grow exponentially with dimension. In contrast, the BDBS and boxcomplement algorithms scale linearly in the number

3

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

Algorithm
Naive included sum Naive included sum complement Naive excluded sums Summed-area table (SAT) Summed-area table
complement (SATC) Corners(c) Corners Spine(c) Bidirectional box sum (BDBS) Bidirectional box sum
complement (BDBSC) Box-complement

Source [This work] [This work] [This work]
[11, 29]
[11, 29]
[13] [13] [This work]
[This work]
[This work]

Time ( ) ( ) ( 2) (2 )
(2 )
(( + 1/)2 ) ((2+1 + 2( - ) + 2) )
( )
( )
( )

Space ( ) ( ) ( ) ( )
( )
( ) ( ) ( )
( )
( )

Included or Excluded? Included Excluded Excluded Included
Excluded
Excluded Excluded Included
Excluded
Excluded

Strong or Weak? Strong Weak Strong Weak
Weak
Strong Strong Strong
Weak
Strong

Table 1: A summary of all algorithms for excluded sums in this paper. All algorithms take as input a -dimensional tensor of  elements. We include the runtime, space usage, whether an algorithm solves the included- or excluded-sums problem, and whether it solves the strong or weak version of the problem. We use  to denote the volume of the box (in the runtime of the naive algorithm). The corners algorithm takes a parameter  of extra space that it uses to improve its runtime.

of dimensions and outperform the summed-area table describes and analyzes the resulting box-complement

method by at least 1.3× after 6 dimensions. The BDBS algorithm. Section 6 presents an empirical evaluation

algorithm demonstrates the advantage of solving the of algorithms for excluded sums. Finally, we provide

weak problem, if you can, because it is always faster than concluding remarks in Section 7.

the box-complement algorithm, which doesn't exploit

an operator inverse. Both algorithms introduced in this 2 Preliminaries

paper outperform existing methods in higher dimensions, This section reviews tensor preliminaries used to describe

however.

algorithms in later sections. It also formalizes the

To be specific, our contributions are as follows:

included- and excluded-sums problems in terms of tensor

· the bidirectional box-sum (BDBS) algorithm for strong included sums;

notation. Finally, it describes the prefix- and suffix-sums primitive underlying the main algorithms in this paper.

· the bidirectional box-sum complement (BDBSC) Tensor Preliminaries We first introduce the coordi-

algorithm for weak excluded sums;

nate and tensor notation we use to explain our algo-

rithms and why they work. At a high level, tensors

· the box-complement algorithm for strong excluded are -dimensional arrays of elements over some monoid

sums;

(, , ). In this paper, tensors are represented by cap-

· theorems showing that, for a -dimensional tensor of size  , these algorithms all run in ( ) time and ( ) space;

ital script letters (e.g., ) and vectors are represented by lowercase boldface letters (e.g., a).
We shall use the following terminology. A dimensional coordinate domain  is is the cross

· implementations of these algorithms in C++; and product  = 1×2×. . .×, where  = {1, 2, . . . , } for   1. The size of  is 12 · · · . Given a
· empirical evaluations showing that the box- coordinate domain  and a monoid (, , ) as defined

complement algorithm outperforms the corners al- in Section 1, a tensor  can be viewed for our purposes

gorithm in 3D given similar space and that both as a mapping  :   . That is, a tensor maps a

the BDBSC algorithm and box-complement algo- coordinate x   to an element [x]  . The size of

rithm outperform the SATC algorithm in higher a tensor is the size of its coordinate domain. We omit the

dimensions.

coordinate domain  and monoid (, , ) when they

are clear from context.

Outline The rest of the paper is organized as follows.

We use Python-like colon notation  : , where

Section 2 provides necessary preliminaries and notation   , to denote the half-open interval [, ) of

to understand the algorithms and proofs. Section 3 coordinates along a particular dimension. If  : 

presents an efficient algorithm to solve the included- would extend outside of [1, ], where  is the maximum

sums problem, which will be used as a key subroutine in coordinate, it denotes only the coordinates actually in the

the box-complement algorithm. Section 4 formulates the interval, that is, the interval max{1, } : min{ + 1, }.

excluded sum as the "box-complement," and Section 5

4

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

If the lower bound is missing, as in : , we interpret where

the interval as 1 : , and similarly, if the upper bound is missing, as in  : , it denotes the interval [, ]. If both (2.1)
bounds are missing, as in : , we interpret the interval as

{  =

1   -1

if  = 1, if  > 1 .

the whole coordinate range [1, ].

Let Prefix denote the algorithm that directly

We can use colon notation when indexing a tensor implements the recursion in Equation 2.1. Given

 to define subtensors, or boxes. For example, an array a and indices start  end , the function

[3 : 5, 4 : 6] denotes the elements of  at coordinates Prefix(a, start, end ) computes the prefix sum in the

(3, 4), (3, 5), (4, 4), (4, 5). For full generality, a box  range [start, end ] of a in (end - start) time. Similarly,

cornered at coordinates x = (1, 2, . . . , ) and x = the suffix-sums operation is the reverse of the prefix (1, 2, . . . , ), where  <  for all  = 1, 2, . . . , , is sum and computes the sum right-to-left rather than leftthe box (1 : 1, 2 : 2, . . . ,  : ). Given a box size to-right. Let Suffix(a, start, end ) be the corresponding k = (1, . . . , ), a k-box cornered at coordinate x is algorithm for suffix sums. the box cornered at x and x = (1 + 1, 2 + 2, . . . ,  +
). A (tensor) row is a box with a single value in 3 Included Sums

each coordinate position in the colon notation, except This section presents the bidirectional box-sum algo-

for one position, which includes that entire dimension. rithm (BDBS) algorithm to compute the included

For example, if x = (1, 2, . . . , ) is a coordinate of a sum along an arbitrary dimension, which is used as a

tensor , then [1, 2, . . . , -1, : , +1, +2, . . . , ] main subroutine in the box-complement algorithm for

denotes a row along dimension .

excluded sums. As a warm-up, we will first describe how

The colon notation can be combined with the to solve the included-sums problem in one dimension and

reduction operator  to indicate the reduction of all extend the technique to higher dimensions. We include

elements in a subtensor:

the one-dimensional case for clarity, but the main focus

 [1 : 1, 2 : 2, . . . ,  : ]

 



=

···

[1, 2, . . . , ] .

of this paper is the multidimensional case. We will sketch the subroutines for higher dimensions
in this section. The full version of the paper includes all

1[1,1) 2[2,2)

 [ , )

the pseudocode and omitted proofs for BDBS in 1D. We

sketch the key subroutines in higher dimensions and omit Problem Definitions We can now formalize the them from this paper because they straightforwardly included- and excluded-sums problems from Section 1. extend the computation from 1 dimension.

Definition 1. (Included and Excluded Sums) An algorithm for the included-sums problem takes as input a -dimensional tensor  :    with size  and a box size k = (1, 2, . . . , ). It produces a new tensor  :    such that every output element [x] holds the reduction under  of elements within the k-box of  cornered at x. An algorithm for the excluded-sums problem is defined similarly, except that the reduction is of elements outside the k-box cornered at x.
In other words, an included-sums algorithm computes, for all x = (1, 2, . . . , )   , the value [x] =  [1 : 1+1, 2 : 2+2, . . . ,  : +]. It's messier to write the output of an excluded-sums problem using colon notation, but fortunately, our proofs do not rely on it.
As we have noted in Section 1, there are weak and strong versions of both problems which allow and do not allow an operator inverse, respectively.
Prefix and Suffix Sums The prefix-sums operation [4] takes an array a = (1, 2, . . . , ) of  elements and returns the "running sum" b = (1, 2, . . . , ) ,

Included Sums in 1D Before investigating the included sums in higher dimensions, let us first turn our attention to the 1D case for ease of understanding. Figure 13 presents an algorithm BDBS-1D which takes as input a list  of length  and a (scalar) box size1  and outputs a list  of corresponding included sums. At a high level, the BDBS-1D algorithm generates two intermediate lists  and , each of length  , and performs / prefix and suffix sums of length  on each intermediate list. By construction, for  = 1, 2, . . . ,  , we have [] = [/ :  + 1], and [] = [ : ( + 1)/].
Finally, BDBS-1D uses  and  to compute the included sum of size  for each coordinate in one pass. Figure 5 illustrates the ranged prefix and suffix sums in BDBS-1D, and Figure 6 presents a concrete example of the computation.
1For simplicity in the algorithm descriptions and pseudocode, we assume that  mod  = 0 for all dimensions  = 1, 2, . . . , . In implementations, the input can either be padded with the identity to make this assumption hold, or it can add in extra code to deal with unaligned boxes.

5

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

k

k

Suffix

Prefix

[1, 2, . . . , ] =

 [1 : 1 + 2, . . . ,  :  + , +2, . . . , ].







 
-

Figure 5: An illustration of the computation in the bidirectional box-sum algorithm. The arrows represent prefix and suffix sums in runs of size , and the shaded region represents the prefix and suffix components of the region of size  outlined by the dotted lines.
Position 1 2 3 4 5 6 7 8
A 25316390
Ap 2 7 10 11 6 9 18 18
As 11 9 4 1 18 12 9 0
A 11 15 13 19 18 12 9 0
Figure 6: An example of computing the 1D included sum using the bidirectional box-sum algorithm, where  = 8 and  = 4. The input array is , the -wise prefix and suffix sums are stored in  and , respectively, and the output is in .

Overall, BDBS computes the full included sum of a tensor with  elements in ( ) time and ( ) space by performing the included sum along each dimension in turn.
Although we cannot directly use BDBS to solve the strong excluded-sums problem, the next sections demonstrate how to use the BDBS technique as a key subroutine in the box-complement algorithm for strong excluded sums.
4 Excluded Sums and the Box Complement
The main insight in this section is the formulation of the excluded sum as the recursive "box complement". We show how to partition the excluded region into 2 nonoverlapping parts in  dimensions. This decomposition of the excluded region underlies the box-complement for strong excluded sums in the next section.
First, let's see how the formulation of the "box complement" relates to the excluded sum. At a high level, given a box , a coordinate x is in the "-complement" of  if and only if x is "out of range" in some dimension   , and "in the range" for all dimensions greater than .

Definition 2. (Box Complement) Given a -

BDBS-1D solves the included-sums problem on dimensional coordinate domain  and a dimension

an array of size  in ( ) time and ( ) space.   {1, 2, . . . , }, the i-complement of a box  cornered

First, it uses two temporary arrays to compute the at coordinates x = (1, . . . , ) and x = (1, . . . , ) is prefix and suffix as illustrated in Figure 5 in ( ) the set

time. It then makes one more pass through the data () = {(1, . . . , )   : there exists   [1, ]

to compute the included sum, requiring ( ) time. Figure 13 in Appendix B contains the full pseudocode for BDBS-1D.

such that  / [, ), and for all   [ + 1, ],   [, )}.

Generalizing to Arbitrary Dimensions The main focus of this work is multidimensional included and excluded sums. Computing the included sum along an arbitrary dimension is almost exactly the same as computing it along 1 dimension in terms of the underlying ranged prefix and suffix sums. We sketch an algorithm BDBS that generalizes BDBS-1D to arbitrary dimensions.
Let  be a -dimensional tensor with  elements

Given a box , the reduction of all elements at coordinates in () is exactly the excluded sum with respect to . The box complement recursively partitions an excluded region into disjoint sets of coordinates.
Theorem 4.1. (Recursive Box-complement) Let  be a box cornered at coordinates x = (1, . . . , ) and x = (1, . . . , ) in some coordinate domain  . The -complement of  can be expressed recursively in terms of the ( - 1)-complement of  as follows:

and let k be a box size. The BDBS algorithm computes the included sum along dimensions  = 1, 2, . . . ,  in turn. After performing the included-sum computation along dimensions 1, 2, . . . , , every coordinate in the output  contains the included sum in each dimension up to :

() = ( : , . . . , : , : , +1 : +1, . . . ,  :  ) 

 





-

( : , . . . , : ,  : , +1 : +1, . . . ,  :  )  -1(),

 





-1

-

6

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

where 0() = .

We use the box-complement formulation in the next

section to efficiently compute the excluded sums on a Proof. For simplicity of notation, let RHS() be the tensor by reducing in disjoint regions of the tensor. right-hand side of the equation in the statement of The-

orem 4.1. Let y = (1, . . . , ) be a coordinate. In order to show the equality, we will show that y  () if and only if y  RHS(). Forward Direction: y  ()  y  RHS(). We proceed by case analysis when y  (). Let    be the highest dimension at which y is "out of range," or where  <  or   .

5 Box-Complement Algorithm
This section describes and analyzes the box-complement algorithm for strong excluded sums, which efficiently implements the dimension reduction in Section 4. The box-complement algorithm relies heavily on prefix, suffix, and included sums as described in Sections 2 and 3.
Given a -dimensional tensor  of size  and a

Case 1:  = .

box size k, the box-complement algorithm solves the

Definition 2 and  =  imply that either  < excluded-sums problem with respect to k for coordinates

 or   , and      for all in  in ( ) time and ( ) space. Appendix C

 > . By definition,  <  implies y  contains all omitted pseudocode and proofs for the serial

( : , . . . , : , : , +1 : +1, . . . ,  : ). Similarly,   box-complement algorithm.

 implies y  ( : , . . . , : ,  : +1 : +1, . . . ,  : ).

These are exactly the first two terms in RHS().

Algorithm Sketch At a high level, the box-

Case 2:  < . Definition 2 and  <  imply that y  -1().

complement algorithm proceeds by dimension reduction. That is, the algorithm takes  dimension-reduction steps, where each step adds two of the components from Corol-

Backwards Direction: y  RHS()  y  (). lary 4.1 to each element in the output tensor. In the

We again proceed by case analysis.

th dimension-reduction step, the box-complement algo-

Case 1: y  ( : , . . . , : , : , +1 : +1, . . . ,  : ) or y  ( : , . . . , : ,  : , +1 : +1, . . . ,  : ). Definition 2 implies y  () because there exists
some    (in this case,  = ) such that  <  and    <  for all  > .

rithm computes the -complement of  (Definition 2) for all coordinates in the tensor by performing a prefix and suffix sum along the th dimension and then performing the BDBS technique along the remaining  -  dimensions. After the th dimension-reduction step, the box-complement algorithm operates on a tensor of  - 

Case 2: y  -1().

dimensions because  dimensions have been reduced so

Definition 2 implies that there exists  in the range far via prefix sums. Figure 7 presents an example of

1     - 1 such that  <  or    and that for all   , we have    < . Therefore, y  -1() implies y  () since there exists some    (in this case,  < ) where  <  or    and    <  for all  > 1.
Therefore, () can be recursively expressed as RHS().

the dimension reduction in 2 dimensions, and Figure 8 illustrates the recursive box-complement in 3 dimensions.
Prefix and Suffix Sums In the th dimension reduction step, the box-complement algorithm uses prefix and suffix sums along the th dimension to reduce the elements "out of range" along the th dimension in the -complement. That is, given a tensor  of

In general, unrolling the recursion in Theorem 4.1 yields 2 disjoint partitions that exactly comprise the excluded sum with respect to a box.

size  = 1 · 2 · · ·  and a number  <  of dimensions reduced so far, we define a subroutine PrefixAlong-Dim(, ) that fixes the first  dimensions at 1, . . . ,  (respectively), and then computes the prefix

Corollary 4.1. (Excluded-sum Components)

sum along dimension +1 for all remaining rows in dimen-

The excluded sum can be represented as the union of 2 sions  + 2, . . . , . The pseudocode for Prefix-Along-

disjoint sets of coordinates as follows:





()

=



( : , . . . , 

:,

: , +1

: +1, . . . , 

: )

=1

 
-1




-



Dim(, ) can be found in Figure 14 in Appendix C,

and

the

proof

that

it

incurs

(=+1

) 

time

can

be

found in Appendix C.

The subroutine Prefix-Along-Dim computes the

reduction of elements "out of range" along dimension .

 ( : , . . . , : ,  +  : , +1 : +1, . . . ,  : ) .

 





-1

-

That is, after Prefix-Along-Dim(, ), for each coordinate +1 = 1, 2, . . . , +1 along dimension  + 1, every

7

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

ffffff f X

(ii) BDBS along each column

(i) Prefix along each row
(a)

f ffffff f X ffffff

(ii) BDBS along each column

(i) Suffix along each row (b)

ffffff

ffffffffffffff

X

ffffff

Prefix

(c)

ffffff

ffffffffffffff

X

ffffffffffffffffff

ffffff

(d)

Suffix

Figure 7: Steps for computing the excluded sum in 2 dimensions with included sums on prefix and suffix sums. The steps are labeled in the order they are computed. The 1-complement (a) prefix and (b) suffix steps perform a prefix and suffix along dimension 1 and an included sum along dimension 2. The numbers in (a),(b) represent the order of subroutines in those steps. The 2-complement (c) prefix and (d) suffix steps perform a prefix and suffix sum on the reduced array, denoted by the blue rectangle, from step (a). The red box denotes the excluded region, and solid lines with arrows denote prefix or suffix sums along a row or column. The long dashed line represents the included sum along each column.

each row along a specified dimension after dimension

reduction. Let  be a -dimensional tensor, k be a

3

3

3 box size,  be the number of reduced dimensions so far,

2

1

Full Prefix / Suffix Dimensions:

1

Included Sum Dimensions:

2, 3

(a)

2 1 1, 2
3 (b)

2 1 1, 2, 3
None (c)

and  be the dimension to compute the included sum along such that  > . BDBS-Along-Dim(, k, , ) computes the included sum along the th dimension for all rows ( 1, . . . , , : , . . . , : ). That is, for each coordinate x = ( 1, . . . , , +1, . . . ,  ), the output tensor  contains the included sum along dimension :

Figure 8: An example of the recursive box-complement in 3 dimensions with dimensions labeled 1, 2, 3. The subfigures (a), (b), and (c) illustrate the 1-, 2-, and 3-complement, respectively. The blue region represents the coordinates inside the box, and the regions outlined by dotted lines represent the partitions defined by Corollary 4.1. For each partition, the face against the edge of the tensor is highlighted in green.
coordinate in the (dimension-reduced) output  contains the prefix up to that coordinate in dimension  + 1:

[1, . . . , , +1, +2, . . . , ] =

 


 
--1

 [1, . . . , , : +1 + 1, +2, . . . , ].

 


 
--1

Since the similar subroutine Suffix-Along-Dim has almost exactly the same analysis and structure, we omit its discussion.

[x] =  [1, . . . , , +1, . . . , ,

 


 
-

+1 : +1 + +1, +2, . . . , ].
 
--1

BDBS-Along-Dim(,

k,

,

)

takes

(=+1

) 

time

because

it

iterates

over

(
=+1



) /

+1

rows

and runs in (+1) time per row. It takes ( ) space

using the same technique as BDBS-1D.

Adding in the Contribution Each dimensionreduction step must add its respective contribution to each element in the output. Given an input tensor  and output tensor , both of size  , the function Add-Contribution takes ( ) time to add in the contribution with a pass through the tensors. The full pseudocode can be found in Figure 15 in Appendix C.

Included Sums In the th dimension reduction step, the box-complement algorithm uses the BDBS technique along the th dimension to reduce the elements "in range" along the th dimension in the -complement. That is, given a tensor  of size  = 1 · 2 · · ·  and a number  <  of dimensions reduced so far, we define a subroutine BDBS-Along-Dim.
BDBS-Along-Dim computes the included sum for

Putting It All Together Finally, we will see how to use the previously defined subroutines to describe and analyze the box-complement algorithm for excluded sums. Figure 9 presents pseudocode for the boxcomplement algorithm. Each dimension-reduction step has a corresponding prefix and suffix step to add in the two components in the recursive box-complement. Given an input tensor  of size  , the box-complement algo-

8

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

rithm takes ( ) space because all of its subroutines Therefore, the total time of Box-Complement is

use at most a constant number of temporaries of size  , ( ).

as seen in Figure 9.

Given a tensor  as input, the box-complement

algorithm solves the excluded-sums problem by computing the recursive box-complement components from Corollary 4.1. By construction, for dimension   [1, ], the prefix-sum part of the th dimension-reduction step outputs a tensor  such that for all coordinates x = (1, . . . , ), we have
 [1, . . . , ] = [ : , . . . , : , : +1,
 


Box-Complement(, k)
1 // Input: Tensor  with -dimensions, box size k // Output: Tensor  with size and dimensions // matching  containing the excluded sum.
2 init  with the same size as  3   ;    4 // Current dimension-reduction step 5 for i  1 to d

+2 : +2 + +2, . . . ,  :  + ].

6 // Saved from previous dimension-reduction step.





7

--1

8

Similarly, the suffix-sum step constructs a tensor  9

   reduced up to dimension  - 1    // Save input to suffix step // PREFIX STEP

such that for all x,



[1, . . . , ] = [ : , . . . , : , +1 + +1 : ,

10

// Reduced up to  dimensions. Prefix-Along-Dim along

 


11

dimension i on .

+2 : +2 + +2, . . . ,  :  + ].

12





13

--1

14

We can now analyze the performance of the box- 15

complement algorithm.

16

   // Save for next round // Do included sum on dimensions [ + 1, ]. for j  i + 1 to d
//  reduced up to  dimensions BDBS-Along-Dim on

Theorem 5.1. (Time of Box-complement) Given a -dimensional tensor  of size  = 1 · 2 · . . . · , Box-Complement solves the excluded-sums problem in ( ) time.

17 18 19 20

21

dimension  in  // Add into result Add-Contribution from  into 
// SUFFIX STEP

Proof. We analyze the prefix step (since the suffix step

// Do suffix sum along dimension 

is symmetric, it has the same running time). Let 22

Suffix-Along-Dim along

  {1, . . . , } denote a dimension.

23

The th dimension reduction step in 24

dimension  in  // Do included sum on dimensions [ + 1, ]

Box-Complement involves 1 prefix step and ( - ) 25

for j  i + 1 to d

included sum calls, which each have (= ) time. Furthermore, adding in the contribution at each

26 27

//  reduced up to  dimensions BDBS-Along-Dim on

dimension-reduction step takes ( ) time. The total 28

dimension  in 

time over  steps is therefore

( (


))


29

// Add into result

30

Add-Contribution from  into 

  ( -  + 1)   +  . Adding in the 31 return 

=1

=

contribution is clearly ( ) in total. Next, we bound the runtime of the prefix and in-
cluded sums. In each dimension-reduction step, reducing the number of dimensions of interest exponentially

Figure 9: Pseudocode for the box-complement algorithm. For ease of presentation, we omit the exact parameters to the subroutines and describe their function in the algorithm. The pseudocode with parameters can be found in Figure 16.

decreases the size of the considered tensor. That is, di-

mension reduction exponentially reduces the size of the

input:


=



 /2-1.

The

total

time

required

to

compute the box-complement components is therefore









 



( -  + 1)   ( -  + 1) 2-1

=1

=

=1

 2( + 2- - 1) = ( ).

6 Experimental Evaluation
This section presents an empirical evaluation of strong and weak excluded-sums algorithms. In 3 dimensions, we compare strong excluded-sums algorithms: specifically, we evaluate the box-complement algorithm and variants of the corners algorithm and find that the boxcomplement outperforms the corners algorithm given

9

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

similar space. Furthermore, we compare weak excludedsums algorithms in higher dimensions. Lastly, to simulate a more expensive operator than numeric addition when reducing, we compare the box-complement algorithm and variants of the corners algorithm using an artificial slowdown.

Experimental Setup We implemented all algorithms

in C++. We used the Tapir/LLVM [27] branch of the

LLVM [23, 24] compiler (version 9) with the -O3 and

-march=native and -flto flags.

All experiments were run on a 8-core 2-way hyper-

threaded Intel Xeon CPU E5-2666 v3 @ 2.90GHz with

30GB of memory from AWS [1]. For each test, we took

the median of 3 trials.

To gather empirical data about space usage, we

interposed malloc and free. The theoretical space usage Figure 10: The scalability of excluded-sum algorithms as

of the different algorithms can be found in Table 1.

a function of the cost of operator  on a 3D domain of

 = 4096 elements. The horizontal axis is the time in

Strong Excluded Sums in 3D Figure 3 summarizes nanoseconds to execute . The vertical axis represents the

the results of our evaluation of the box-complement and time per element of the given algorithm divided by the time

corners algorithm in 3 dimensions with a box length of for . We inflated the time of  using increasingly large 1 = 2 = 3 = 4 (for a total box volume of  = 64) arguments to the standard recursive implementation of a and number of elements  = 681472. We tested with Fibonacci computation.

varying  but found that the time and space per element were flat (full results in Appendix D). We found that the box-complement algorithm outperforms the corners algorithm by about 1.4× when given similar amounts of space, though the corners algorithm with 2× the space as the box-complement algorithm was 2× faster.
We explored two different methods of using extra space in the corners algorithm based on the computation tree of prefixes and suffixes: (1) storing the spine of the computation tree to asymptotically reduce the running time, and (2) storing the leaves of the computation tree to reduce passes through the output. Although storing the leaves does not asymptotically affect the behavior of the corners algorithm, we found that reducing the number of passes through the output has significant effects on

take different amounts of time. Figure 10 summarizes our findings. We ran the
algorithms on a 3D domain of  = 4096 elements. (Although this domain may seem small, Appendix D shows that the results are relatively insensitive to domain size.) For inexpensive  operators, the box-complement algorithm is the second fastest, but as the cost of  increases, the box-complement algorithm dominates. The reason for this outcome is that box-complement performs approximately 12  operations per element in 3D, whereas the most efficient corners algorithm performs about 22  operations. As  becomes more costly, the time spent executing  dominates the other bookkeeping overhead.

empirical performance. Storing the spine did not improve performance, because the runtime is dominated by the number of passes through the output.

Weak Excluded Sums in Higher Dimensions Figure 4 presents the results of our evaluation of weak excluded-sum algorithms in higher dimensions. For all

Excluded Sums With Different Operators Most of our experiments used numeric addition for the  operator. Because some applications, such as FMM, involve much more costly  operators, we studied how the excluded-sum algorithms scale with the cost of . To do so, we added a tunable slowdown to the invocation of  in the algorithms. Specifically, they call an unoptimized implementation of the standard recursive Fibonacci computation. By varying the argument to the Fibonacci function, we can simulate  operators that

dimensions  = 1, 2, . . . , , we set the box length  = 8 and chose a number of elements  to be a perfect power of dimension . Table 1 presents the asymptotic runtime of the different excluded-sum algorithms.
The weak naive algorithm for excluded sums with nested loops outperforms all of the other algorithms up to 2 dimensions because its runtime is dependent on the box volume, which is low in smaller dimensions. Since its runtime grows exponentially with the box length, however, we limited it to 5 dimensions.
The summed-area table algorithm outperforms the

10

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

BDBS and box-complement algorithms up to 6 dimensions, but its runtime scales exponentially in the number of dimensions.
Finally, the BDBS and box-complement algorithms scale linearly in the number of dimensions and outperform both naive and summed-area table methods in higher dimensions. Specifically, the box-complement algorithm outperforms the summed-area table algorithm by between 1.3× and 4× after 6 dimensions. The BDBS algorithm demonstrates an advantage to having an inverse: it outperforms the box-complement algorithm by 1.1× to 4×. Therefore, the BDBS algorithm dominates the box-complement algorithm for weak excluded sums.
7 Conclusion
In this paper, we introduced the box-complement algorithm for the excluded-sums problem, which improves the running time of the state-of-the-art corners algorithm from (2 ) to ( ) time. The space usage of the box-complement algorithm is independent of the number of dimensions, while the corners algorithm may use space dependent on the number of dimensions to achieve its running-time lower bound.
The three new algorithms from this paper parallelize straightforwardly. In the work/span model [10], all three algorithms are work-efficient, achieving ( ) work. The BDBS and BDBSC algorithms achieve ( log  ) span, and the box-complement algorithm achieves (2 log  ) span.
Acknowledgments
The idea behind the box-complement algorithm was originally conceived jointly with Erik Demaine many years ago, and we thank him for helpful discussions. Research was sponsored by the United States Air Force Research Laboratory and the United States Air Force Artificial Intelligence Accelerator and was accomplished under Cooperative Agreement Number FA8750-19-21000. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the United States Air Force or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein.

11

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

References
[1] Amazon. Amazon Web Services. https://aws.amazon. com/, 2021.
[2] Rick Beatson and Leslie Greengard. A short course on fast multipole methods. Wavelets, Multilevel Methods and Elliptic PDEs, pages 1­37, 1997.
[3] Pierre Blanchard, Nicholas J. Higham, and Theo Mary. A class of fast and accurate summation algorithms. SIAM Journal on Scientific Computing, 42(3):A1541­ A1557, 2020.
[4] Guy E. Blelloch. Prefix sums and their applications. Technical Report CMU-CS-90-190, School of Computer Science, Carnegie Mellon University, November 1990.
[5] Guy E. Blelloch, Daniel Anderson, and Laxman Dhulipala. ParlayLib: a toolkit for parallel algorithms on shared-memory multicore machines. page 507­509, 2020.
[6] Robert D. Blumofe, Christopher F. Joerg, Bradley C. Kuszmaul, Charles E. Leiserson, Keith H. Randall, and Yuli Zhou. Cilk: An efficient multithreaded runtime system. Journal of Parallel and Distributed Computing, 37(1):55­69, 1996.
[7] Derek Bradley and Gerhard Roth. Adaptive thresholding using the integral image. Journal of Graphics Tools, 12(2):13­21, 2007.
[8] Hongwei Cheng, William Y. Crutchfield, Zydrunas Gimbutas, Leslie F. Greengard, J. Frank Ethridge, Jingfang Huang, Vladimir Rokhlin, Norman Yarvin, and Junsheng Zhao. A wideband fast multipole method for the Helmholtz equation in three dimensions. Journal of Computational Physics, 216(1):300­325, 2006.
[9] Ronald Coifman, Vladimir Rokhlin, and Stephen Wandzura. The fast multipole method for the wave equation: A pedestrian prescription. IEEE Antennas and Propagation Magazine, 35(3):7­12, 1993.
[10] Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. Introduction to Algorithms. MIT Press, 3rd edition, 2009.
[11] Franklin C. Crow. Summed-area tables for texture mapping. pages 207­212, 1984.
[12] Eric Darve. The fast multipole method: numerical implementation. Journal of Computational Physics, 160(1):195­240, 2000.
[13] E. D. Demaine, M. L. Demaine, A. Edelman, C. E. Leiserson, and P. Persson. Building blocks and excluded sums. SIAM News, 38(4):1­5, 2005.
[14] S. Fraser, H. Xu, and C. E. Leiserson. Work-efficient parallel algorithms for accurate floating-point prefix sums. In 2020 IEEE High Performance Extreme Computing Conference (HPEC), pages 1­7, 2020.
[15] Sean Fraser. Computing included and excluded sums using parallel prefix. Master's thesis, Massachusetts Institute of Technology, 2020.
[16] L. Greengard and V. Rokhlin. A fast algorithm for particle simulations. J. Comput. Phys., 135(2):280­292, August 1997.

[17] Nail A. Gumerov and Ramani Duraiswami. Fast multipole methods for the Helmholtz equation in three dimensions. Elsevier, 2005.
[18] Justin Hensley, Thorsten Scheuermann, Greg Coombe, Montek Singh, and Anselmo Lastra. Fast summed-area table generation and its applications. In Computer Graphics Forum, volume 24, pages 547­555. Wiley Online Library, 2005.
[19] Nicholas J. Higham. The accuracy of floating point summation. SIAM J. Scientific Computing, 14:783­799, 1993.
[20] Nicholas J. Higham. Accuracy and Stability of Numerical Algorithms. Society for Industrial and Applied Mathematics, Philadelphia, PA, USA, 2nd edition, 2002.
[21] Intel Corporation. Intel Cilk Plus Language Specification, 2010. Document Number: 324396001US. Available from http://software.intel.com/ sites/products/cilk-plus/cilk_plus_language_ specification.pdf.
[22] Peter M. Kogge and Harold S. Stone. A parallel algorithm for the efficient solution of a general class of recurrence equations. IEEE Transactions on Computers, 100(8):786­793, 1973.
[23] Chris Lattner. LLVM: An infrastructure for multi-stage optimization. Master's thesis, Computer Science Dept., University of Illinois at Urbana-Champaign, Urbana, IL, December 2002.
[24] Chris Lattner and Vikram Adve. LLVM: A compilation framework for lifelong program analysis & transformation. In International Symposium on Code Generation and Optimization (CGO), page 75, Palo Alto, California, March 2004.
[25] William B March and George Biros. Far-field compression for fast kernel summation methods in high dimensions. Applied and Computational Harmonic Analysis, 43(1):39­75, 2017.
[26] Tao B. Schardl, William S. Moses, and Charles E. Leiserson. Tapir: Embedding fork-join parallelism into LLVM's intermediate representation. In ACM SIGPLAN Notices, volume 52, pages 249­265. ACM, 2017.
[27] Tao B Schardl, William S Moses, and Charles E Leiserson. Tapir: Embedding recursive fork-join parallelism into llvm's intermediate representation. ACM Transactions on Parallel Computing (TOPC), 6(4):1­33, 2019.
[28] Xiaobai Sun and Nikos P Pitsianis. A matrix version of the fast multipole method. Siam Review, 43(2):289­300, 2001.
[29] Ernesto Tapia. A note on the computation of highdimensional integral images. Pattern Recognition Letters, 32(2):197­201, 2011.
[30] Gernot Ziegler. Summed area computation using ripmap of partial sums, 2012. GPU Technology Conference (talk).

12

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

A Analysis of Corners Algorithm

This section presents an analysis of the time and space

usage of the corners algorithm [13] for the excluded-

P (0)

S (1)

sums problem. The original article that proposed the

corners algorithm did not include an analysis of its performance. As we will see, the runtime of the corners

PP PS SP SS

height = d

algorithm is a function of the space it is allowed. Algorithm Description. Given a -dimensional

...(00) (01) (10) (1...1)

tensor  of size  and a box , the corners algorithm

partitions the excluded region () into 2 disjoint regions corresponding to the corners of the box. Each excluded sum is the sum of the reductions of each of the

PP...P (00...0)

SS...S (11...1)

corresponding 2 regions. The corners algorithm com-

putes the reduction of each partition with a combination Figure 12: The dependency tree of computations in the

of prefix and suffix sums over the entire tensor and saves corners algorithm. P and S represent full-tensor prefix and

work by reusing prefixes and suffixes in overlapping re- suffix sums, respectively. Each leaf is a string of length  that

gions. Figure 11 illustrates an example of the corners denotes a series of prefix and suffix sums along the entire

algorithm.

tensor.

(1,1)

without reusing computation between paths takes ( ) space, but ( ) time per leaf, for total time (2 ).

We will see how to use extra space to reuse computation

PP

between paths and reduce the total time.

PS

n1

k1

(x1, x2)

Theorem A.1. (Time / Space Tradeoff) Given a multiplicative space allowance  such that 1    , the corners algorithm solves the excluded-sums problem in ((2+1 +2(-)+2) ) time if it is allowed ( ) space.

SP

k2

SS

n2

Figure 11: An example of the corners algorithm in 2 dimensions on an 1 ×2 matrix using a (1, 2)-box cornered at (1, 2). The grey regions represent excluded regions computed via prefix and suffix sums, and the black boxes correspond to the corner of each region with the relevant contribution. The labels  ,  , ,  represent the combination of prefixes and suffixes corresponding to each vertex.
We can represent each length- combination of prefixes and suffixes as a length- binary string where a 0 or 1 in the -th position corresponds to a prefix or suffix (resp.) at depth . As illustrated in Figure 12, the corners algorithm defines a computation tree where each node represents a combination of prefixes and suffixes, and each edge from depth  - 1 to  represents a full prefix or suffix along dimension . The total height of this computation tree is , so there are 2 leaves.
Analysis. The most naive implementation of the corners algorithm that computes every root-to-leaf path

Proof. The corners algorithm must traverse the entire computation tree in order to compute all of the leaves. If it follows a depth-first traversal of the tree, one possible use of the extra ( ) allowed space is to keep the intermediate combination of prefix and suffices at the first  internal nodes along the current root-to-leaf path in the traversal. We will analyze this scheme in terms of 1) the amount of time that each leaf requires independently, and 2) the total shared work between leaves. The total time of the algorithm is the sum of these two components. Independent work: For each leaf, if the first  prefixes and suffixes have been computed along its root-to-leaf path, there are an additional ( - ) prefix and suffix computations required to compute that leaf. Therefore, each leaf takes (( - ) ) additional time outside of the shared computation, for a total of (2( - ) ) time. Shared work: The remaining time of the algorithm is the amount of time it takes to compute the higher levels of the tree up to depth  given a  factor in space. Given a node  at depth  with position  such that 1   < , the amount of time it takes to compute the intermediate sums along the root-to-leaf path to  depends on the difference in the bit representation between  and  - 1. Specifically, if  and  - 1 differ in  bits, it takes 

13

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

additional time to store the intermediate sums for node  at depth . In general, the number of nodes that differ in   {1, 2, . . . , } positions at depth  is 2-. Therefore, the total time of computing the intermediate sums is


  2-  2+1 = (2 ).
=1

Putting it together: Each leaf also requires ( )

time to add in the contribution. Therefore, the total





time is  2 + 2( - ) + 2 .





 

 

 

shared independent contribution

The time of the corners algorithm is lower bounded by (2 ) and minimized when  = (). Given ( )
space, the corners algorithm solves the excluded-sums problem in (2 ) time. Given ( ) space, the
corners algorithm solves the excluded-sums problem in (2 ) time.

14

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

B Included Sums Appendix

BDBS-1D(, , )

1 // Input: List  of size  and

// included-sum length . // Output: List  of size  where each // entry [] = [ :  + ] for  = 1, 2, . . .  . 2 allocate A with  slots
3   ;    4 for i  1 to N /k

5

// -wise prefix sum along 

6

Prefix(, ( - 1) + 1, )

7

// -wise suffix sum along 

8

Suffix(, ( - 1) + 1, )

9 for i  1 to N // Combine into result

10

if i mod  = 0

11

[i ]  [i ]

12

else

13

[i ]  [i ]  [i + k - 1]

14 return 

time of BDBS-1D is ( ). Furthermore, BDBS-1D uses two temporary arrays of size  each for the prefix and suffix, for total space ( ).

Figure 13: Pseudocode for the 1D included sum.

Lemma B.1. (Correctness in 1D) BDBS-1D solves the included sums problem in 1 dimension.

Proof. Consider a list  with  elements and box length . We will show that for each  = 1, 2, . . . ,  , the output [] contains the desired sum. For  mod  = 1, this holds by construction. For all other , the previously defined prefix and suffix sum give the desired result. Recall that [] = [ +  - 1] + [], [] = [ : ( + 1)/ · ], and [ +  - 1] = [( +  - 1)/ ·  :  + ]. Also note that for all  mod  = 1, ( +  - 1)/ = ( + 1)/.
Therefore,

[] = [ +  - 1] + []

[   + 1  ] [  +  - 1 

]

= :

· +

· : +





= [ :  + ]

which is exactly the desired sum.

Lemma B.2. (Time and Space in 1D) Given an input array  of size  and box length , BDBS-1D takes ( ) time and ( ) space.

Proof. The total time of the prefix and suffix sums is ( ), and the loop that aggregates the result into 
has  iterations of (1) time each. Therefore, the total

15

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

C Excluded Sums Appendix

Prefix-Along-Dim(, i )
1 // Input: Tensor  ( dimensions, side lengths // (1, . . . , ), dimension  to do the prefix sum // along. // Output: Modify  to do the prefix sum along // dimension  + 1, fixing dimensions up to .

2 // Iterate through coordinates by varying

// coordinates in dimensions  + 2, . . . , 

// while fixing the first  dimensions.

// Blanks mean they are not iterated over

// in the outer loop

3 for

4 {x = (1, . . . , )  (1, . . . , , _, :, . . . , : )}

 

 



--1

5

// Prefix sum along row

// (can be replaced with a parallel prefix)

6

for   2 to ni+1

7

[1, . . . , , , +2, . . . , ] =

 

 



--1

8

[1, . . . , ,  - 1, +2, . . . , ]

 


 
--1

Figure 14: Prefix sum along all rows along a dimension with initial dimensions fixed.
The suffix sum along a dimension is almost exactly the same, so we omit it.

Add-Contribution(, , i , offset)

1 // Input: Input tensor , output tensor ,

// fixing dimensions up to .

// Output: For all coords in , add the // relevant contribution from .

2 for {(1, . . . , )  (:, . . . , :)}

3

if +1 + offset  +1

4

[1, . . . , ] =

5

[1, . . . , , +1 + offset , +2, . . . , ]

 



-

Lemma C.1. (Time of Prefix Sum) Prefix-

Along-Dim(, )

takes

(=+1

) 

time.

Proof. The outer loop over dimensions  + 2, . . . ,  has

( max 1,


=+2

) 

iterations,

each

with

(+1)

work

for the inner prefix sum. Therefore, the total time is

(=+1



) .

Figure 15: Adding in the contribution.

Lemma C.2. (Adding Contribution) Add-Contribution takes ( ) time.

16

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

1 // Input: Tensor  of  dimensions and side lengths

// (1, . . . , ) output tensor , side lengths of the // excluded box k = (1, . . . , ),    for all //  = 1, 2, . . . , .

// Output: Tensor  with size and dimensions

// matching  containing the excluded sum.

2   ,   ,    // Prefix and suffix temp 3 for i  1 to d // Current dimension-reduction step

4

// PREFIX STEP

// At this point,  should hold prefixes up to // dimension  - 1.

5

  

6

// Save the input to the suffix step

7

  

8

// Do prefix sum along dimension 

9

Prefix-Along-Dim(, i - 1)

10

// Save prefix up to dimension  in 

11

  

12

// Do included sum on dimensions [ + 1, ]

13

for j  i + 1 to d

14

BDBS-Along-Dim(, i - 1, j , k)

15

// Add into result

16

Add-Contribution(, , i , -1)

17

// SUFFIX STEP

// Start with the prefix up until dimension

//  - 1

18

  

19

// Do suffix sum along dimension 

20

Suffix-Along-Dim(, i - 1)

21

// Do included sum on dimensions [ + 1, ]

22

for j  i + 1 to d

23

BDBS-Along-Dim(, i - 1, j , k)

24

// Add into result

25

Add-Contribution(, , i - 1, )

Figure 16: Pseudocode for the box-complement algorithm with parameters filled in. For the th dimension-reduction step, the copy of temporaries only needs to copy the last  -  + 1 dimensions due to the dimension reduction.

17

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

D Additional experimental data The data in this appendix was generated with the experimental setup described in Section 6.
Figure 18: Space per element of algorithms for strong excluded sums in 3D. Figure 17: Time per element of algorithms for strong excluded sums in 3D.

Figure 19: Space and time per element of the corners and box-complement algorithms in 3 dimensions, with an artificial slowdown added to each numeric addition (or ) that dominates the runtime.

18

Copyright © 2021 by SIAM

Unauthorized reproduction of this article is prohibited

