
# Full-Resolution Encoder-Decoder Networks with Multi-Scale Feature Fusion for Human Pose Estimation

[arXiv](https://arxiv.org/abs/2106.0566), [PDF](https://arxiv.org/pdf/2106.0566.pdf)

## Authors

- Jie Ou
- Mingjian Chen
- Hong Wu

## Abstract

To achieve more accurate 2D human pose estimation, we extend the successful encoder-decoder network, simple baseline network (SBN), in three ways. To reduce the quantization errors caused by the large output stride size, two more decoder modules are appended to the end of the simple baseline network to get full output resolution. Then, the global context blocks (GCBs) are added to the encoder and decoder modules to enhance them with global context features. Furthermore, we propose a novel spatial-attention-based multi-scale feature collection and distribution module (SA-MFCD) to fuse and distribute multi-scale features to boost the pose estimation. Experimental results on the MS COCO dataset indicate that our network can remarkably improve the accuracy of human pose estimation over SBN, our network using ResNet34 as the backbone network can even achieve the same accuracy as SBN with ResNet152, and our networks can achieve superior results with big backbone networks.

## Comments



## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{ou2021fullresolution,
      title={Full-Resolution Encoder-Decoder Networks with Multi-Scale Feature Fusion for Human Pose Estimation}, 
      author={Jie Ou and Mingjian Chen and Hong Wu},
      year={2021},
      eprint={2106.00566},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

## Notes

Type your reading notes here...

