arXiv:2106.00508v1 [cs.CR] 1 Jun 2021

Differentially Private Densest Subgraph
Alireza Farhadi MohammadTaghi Hajiaghayi Elaine Shi
Abstract
Given a graph, the densest subgraph problem asks for a set of vertices such that the average degree among these vertices is maximized. Densest subgraph has numerous applications in learning, e.g., community detection in social networks, link spam detection, correlation mining, bioinformatics, and so on. Although there are efficient algorithms that output either exact or approximate solutions to the densest subgraph problem, existing algorithms may violate the privacy of the individuals in the network, e.g., leaking the existence/non-existence of edges.
In this paper, we study the densest subgraph problem in the framework of the differential privacy, and we derive the first upper and lower bounds for this problem. We show that there exists a linear-time -differentially private algorithm that finds a 2-approximation of the densest subgraph with an extra poly-logarithmic additive error. Our algorithm not only reports the approximate density of the densest subgraph, but also reports the vertices that form the dense subgraph.
Our upper bound almost matches the famous 2-approximation by Charikar both in performance and in approximation ratio, but we additionally achieve differential privacy. In comparison with Charikar's algorithm, our algorithm has an extra poly-logarithmic additive error. We partly justify the additive error with a new lower bound, showing that for any differentially private algorithm that provides a constant-factor approximation, a sub-logarithmic additive error is inherent.
We also practically study our differentially private algorithm on real-world graphs, and we show that in practice the algorithm finds a solution which is very close to the optimal.
1 Introduction
The densest subgraph problem (DSP) [16] is a fundamental tool to many graph mining applications. Given an undirected graph G = (V, E), the density of an induced subgraph S  V is defined as dG(S) = |E(S)|/|S|, where E(S) is the set of all edges in the subgraph induced by the vertices S  V . In the densest subgraph problem, the goal is to find a subset of vertices S  V with the highest density dG(S). The densest subgraph problem (DSP) is used as a crucial tool for community detection in social network graphs. This problem also has notable applications in learning including link spam detection [14], correlation mining [29], story identification [1] and bioinformatics [30] ­ we refer the reader to the tutorial by Gionis and Tsourakakis [15] for more applications of DSP. Due to its importance, the DSP problem has been studied extensively in the literature [16, 7, 24, 31, 32, 4]: it is long known that efficient, polynomial-time algorithms exist for finding the exact solution of DSP [16, 7, 24].
In many applications of DSP, however, the underlying graph is privacy sensitive (e.g., social network graphs). Therefore, one might be concerned that the result output by the DSP algorithm might breach the privacy privacy of the individuals in the network, e.g., disclose the (non)-existence of friendship between pairs of individuals. In this paper, we explore how to perform community
University of Maryland. Email: {farhadi,hajiagha}@cs.umd.edu. Carnegie Mellon University. Email: runting@cs.cmu.edu.
1

detection on sensitive graphs, while protecting individuals' privacy. To this end, we ask the following question,
Can we construct a differentially private algorithm that computes a good approximation of the densest subgraph of a given graph G?
We first help the reader recall the notion of differential privacy [8] in a graph context. Let G and G be two graphs that are identical expect the existence/non-existence of a single edge. Informally, the differential privacy requires that the outputs of the (randomized) algorithm on G and G are close in distribution. In this way, the output of the algorithm does not reveal meaningful information about the existence of an edge in the graph. Henceforth, we say that two undirected graphs G and G are neighboring if they differ in only one edge. More formally, differential privacy (DP) is defined as follows [8].
Definition 1.1 (( , )-Differential Privacy (DP)). Let > 0 and   [0, 1]. We say that a randomized algorithm Alg achieves ( , )-differential privacy or ( , )-DP for short, if for any two neighboring graphs G and G , for any subset U of the output space,
Pr[Alg(G)  U ]  e · Pr[Alg(G )  U ] + 
Whenever  = 0, we also say that the algorithm satisfies -DP.
For the densest subgraph problem, we assume that the output contains 1) a dense subset of vertices S  V ; and 2) an estimate of the density of S. Had we required the algorithm to output only an estimate of maxSV dG(S), i.e., an estimated density of the densest subgraph, then it would have been easy to devise a DP algorithm: observe that the quantity maxSV dG(S) has small global sensitivity, that is, if we flip the existence of a single edge in G, the quantity maxSV dG(S) changes by at most 1. As a result, we can just use the standard Laplacian mechanism [8] to output a DP estimate with good accuracy. However, we stress that most interesting applications would also want to know the dense community S -- simply knowing an estimate of its density would not be too useful.
The requirement to also report a dense vertex set S  V makes it much more challenging to devise a DP algorithm. In our case, none of the off-the-shelf DP mechanisms would directly work to the best of our knowledge. First, observe that the output is high-dimensional, and has high global sensitivity as we explain in Appendix A. Therefore, the standard Laplacian mechanism [8, 34, 11] (also called output perturbation) completely fails. Another na¨ive approach is randomized response [35, 34, 11] (also called input perturbation), i.e., adding some noise to obfuscate the existence of each edge. Unfortunately, as we argue in Appendix A, the randomized response approach gives poor utility. Finally, the exponential mechanism [25, 34, 11] also fails -- not only is it not polynomial-time, the standard analysis gives an error bound as large as O(n) which makes the result meaningless.
1.1 Our Results and Contributions
We present new upper- and lower-bounds for the differentially private, densest subgraph problem. First, we give a DP approximation algorithm for the densest subgraph problem. The runtime and accuracy of our algorithm are roughly competitive to the state-of-the-art non-private approximation algorithm by Charikar [7]. Specifically, let n denote the number of vertices. Our algorithm is linear-time, and achieves -DP and (2, O( 1 log2.5 n))-approximation -- here we have two approximation parameters: the first parameter 2 is the multiplicative approximation ratio, and the second parameter O( 1 log2.5 n) is an additive error. In comparison, Charikar's famous (non-private)
2

linear-time algorithm achieves (2, 0)-approximation where the additive error is 0. We justify the extra additive error with a new lower bound, showing that to achieve any constant-multiplicative approximation, some sub-logarithmic additive error is unavoidable. Our upper- and lower-bound results are stated in the following theorems:

Theorem 1.2 (DP approximation of densest subgraph). Given a graph G, and parameters > 0
and   [0, 1], there exists a linear-time -DP algorithm that succeeds with the probability of 1 -  and outputs S  V and an estimate d such that

OP

T /2

-

1 O(

·

log2.5

n

·

log

1 

)



dG(S)



OP

T,

and

|d

-

dG(S)|



1 O(

·

log2.5

n

·

log

1 )


where OP T is the true density of the densest subgraph.

Theorem 1.3 (Lower bound on additive error for DP densest subgraph). Let  > 1, > 0 be

arbitrary constants, exp(-n0.49) <  < 0.000001 · min(1,

, exp(- )), and 0   

 log

1 4

.

Then,

there

exists

a

sufficiently

small



=



1 

1

log

1 

such that there does not exist an ( , )-DP

mechanism that achieves (, )-approximation with 1 -  probability.

Note that our upper bound achieves -DP, and our lower bound works even for ( , )-DP. This makes both our upper- and lower-bounds stronger. The proof of Theorem 1.3 is available in Appendix D. Finally, we conclude the paper in Section 5 by demonstrating the performance of our algorithm on real-world datasets. We show that in practice, our algorithm achieves a very accurate solution, even if the privacy parameter is very small.

1.2 Technical Highlight
To see the intuition behind our final algorithm, it helps to break it down into several intermediate steps, to see how the various techniques are eventually woven together.

Background on Charikar's famous algorithm. Our algorithm is inspired by a work of Charikar [7]. Charikar [7] shows that a simple greedy algorithm can achieve a multiplicative approximation ratio of 2 for DSP. The greedy algorithm is as follows. Let G = (V, E) be an undirected graph. Initially, let S := V , i.e., S is initalized to the set of all vertices. At each iteration, the algorithm finds a vertex vmin  S with the minimum degree in the graph induced by the vertices of S, and removes vmin from S. Consider an algorithm that repeats the aforementioned procedure until the set S becomes empty. From all of the sets S encountered during the execution of the algorithm, the algorithm returns the one with the highest density. Charikar proved that this simple greedy algorithm achieves an approximation ratio of 2.

Warmup idea: a quadratic-time DP algorithm. Our first idea is as follows. In Charikar's algorithm, in each iteration, all residual vertices v  S examine their degree within the subgraph induced by S -- henceforth we call the the degree of v in the subgraph induced by S the residual degree of v. Charikar's algorithm picks the v with the minimum residual degree and removes it from S. Our idea is to replace the residual degree with a noisy, DP counterpart. Unfortunately, na¨ively adding independent noise to the true residual degree in each of the n iterations would result in an n-fold loss in error given a fixed privacy budget (and the loss can be reduced to n if we allowed ( , )-DP rather than -DP and used the advanced composition theorem [12, 34, 11]).
Our idea is to rely on the elegant DP prefix sum mechanism by Dwork et al. [9] and Chan, Shi, and Song [5, 6]. Specifically, we can think of the problem as follows.

3

· Initially, every vertex computes its noisy total degree using the standard Laplacian mechanism. Although there are n vertices, we only need to add noise of constant average magnitude by using parallel composition.
· Next, every vertex u still remaining in S maintains a noisy counter to keep track of roughly how many of its direct neighbors have departed (i.e., have been removed from S). If we subtract this value from the vertice's noisy total degree, we get an estimate of its residual degree in the subgraph induced by S.
Therefore, the problem boils down to how to have every residual vertex v maintain a noisy counter of how many of its neighbors have departed. Imagine that every time a neighbor of u departs, a value of 1 is accumulated to v's counter; and every time a non-neighbor of u departs, 0 is accumulated to v's counter. Using the elegant DP prefix sum mechanism by Dwork et al. [9] and Chan et al. [5, 6], we can report v's noisy counter value at any time step, incurring only O( 1 · poly log n) error with all but negligible probability. The noisy counter values and the vertices' noisy degrees are then used to determine which vertex is to depart next. Further, although it seems like there are n counters, using parallel composition, we need not incur extra loss in the privacy budget due to the n counters.
By extending Charikar's proof (which we omit in this short roadmap), we can prove that this warmup algorithm achieves the desired (2, 1 · poly log n)-approximation. In particular, the error of the prefix sum mechanism directly contributes to the additive error term. Unfortunately, the warmup algorithm incurs (n2) runtime, since we need to update O(n) noisy counters in each of the n iterations.
Making it quasilinear time. Our final goal is to get an O(m + n)-time algorithm where m denotes the number of edges and n denotes the number of vertices. However, as an important stepping stone, let us first consider how to make it quasilinear time in m + n. The key observation is that when the graph is sparse, updates to the vertices' noisy counters (realized by the prefix sum mechanisms) are also sparse. Most of the n2 updates come with an input 0, and only m of them come with an input of 1. Our idea is therefore to avoid triggering updates when the input is 0.
While the intuition seems simple, realizing this idea differentially privately is actually tricky since we need to avoid consuming too much privacy budget. At a very high level, each vertex v  S keeps track of a noisy outstanding counter Cnt(v) of the number of its neighbors that departed recently, but have not been accumulated into the prefix sum mechanism yet. When a vertex u gets removed from S, it informs its neighboring vertices to update their noisy outstanding counters. At this moment, each vertex v also checks if its noisy outstanding counter Cnt(v) has exceeded some predetermined polylogarithmic noisy threshold -- if so, it accumulates the current outstanding counter into its prefix sum mechanism, and resets Cnt(v) to 0.
The key technical challenge here is that we would be invoking with high probability the total of O(m) updates to the vertices' noisy outstanding counters, but we cannot afford an O(m)-fold loss in the privacy budget (or equivalently, an O(m)-fold loss in error when the privacy budget is fixed). To resolve this problem, our idea is in spirit reminiscent of the sparse-vector technique [10, 28, 20].We show that we can reduce the privacy analysis of our algorithm to the standard sparse-vector technique. See the subsequent "proof techniques" paragraph regarding the technical challenges in the analysis and proof.
Final touches: making it linear time. The above algorithm can be implemented in O(m + n) log n time if we use a Fibonacci heap to store the residual vertices based on their residual degree (i.e., degree in the graph induced by S). To make the algorithm linear time, we discretize vertices residual degree into polylogarithmically sized regions, and place each vertice in a corresponding bucket based on its residual degree.
4

Using an idea inspired by Charikar [7], one can show that if a vertex is removed from the k-th bucket in the current iteration, then, in the next iteration, we only need to sequentially look at the (k - 1)-th, k-th, and (k + 1)-th, ... buckets. Moreover, within each bucket, all vertices are treated as having roughly the same degree, and we do not further differentiate them in picking the next vertex to remove from S. Using appropriate data structures to store the buckets and the vertices within the buckets, we can eventually obtain a DP-algorithm that completes in O(m + n) runtime. Here, the discretization due to bucketing introduces some additive polylogarithmic error, but asymptotically we still preserve the (2, O( 1 log2.5 n))-approximation as before. We defer the detailed algorithm and analysis to Section 4.
Proof techniques. Proving our algorithm DP turns out to be rather non-trivial. Specifically, our algorithm is not a simple sequential composition of the various underlying building blocks (e.g., prefix sum mechanism, and outstanding counter threshold queries). Therefore, we cannot simply analyze each building block separately and then use standard composition theorems to get the desired DP guarantees. The problem is that the building blocks are interleaved in an adaptive way: the outcome of one step of the prefix sum mechanism corresponding to some vertex will affect the input to the next step of some outstanding counter query, which will then affect the input to the next step of prefix sum mechanism. Despite the complex and adaptive nature of our algorithm, we show that the privacy analysis of our algorithm can be reduced the privacy bounds of sparsevector-technique. The actual proof is involved and we defer the detailed exposition to Section B.1, Appendix B.2, and Appendix C. All the missing proofs are available in the appendices with the same Theorem number.
1.3 Additional Related Work
Differentially private algorithms for graphs. Early works on differentially private graph algorithms focused on computing simple statistics from graphs. The elegant work by Nissim et al. [26] was the first to apply the DP notion to graph computations. Specifically, they showed how to release the cost of minimum spanning tree and the number of triangles in a graph. The work by Karwa et al. [22] extended triangle counting to counting other subgraph structures differentially privately. The work by Hay et al. [21] considered how to release degree distribution while preserving DP. Other works consider how to release the answers to all queries belonging ot some class on a given graph. For example, Gupta, Roth, and Ullman [19] consider how to compute a private synthetic data structure for answering all cut queries with O(n1.5) error where n denotes the number of vertices. Gupta, Hardt, Roth, and Ullman show how to release the cut function on arbitrary graphs [17].
Closely related work. Our DSP problem can be viewed as a combinatorial optimization problem. To the best of our knowledge, there exist few works that consider how to solve combinatorial optimization problems differentially privatey in graphs. The first such work was the elegant work by Gupta et al. [18]. They showed polynomial-time DP algorithms for approximating the min-cut and vertex cover problem. For min-cut, their solution can report the vertices on both sides of the cut. However, for vertex cover, their algorithm cannot report the exact set of vertices in the vertex cover -- instead, it outputs a permutation of vertices, and if one knows the set of edges, one can recover a good vertex cover from this permutation.
Other notions of privacy. In this paper, we consider the notion of edge differential privacy in graphs, which was a standard notion adopted in various prior works [18, 17, 19, 26, 22, 21]. Some
5

works study stronger notions. For example, Kasiviswanathan et al. [23] and Blocki et al. [3] investigate the notion of node differential privacy, where neighboring graphs are defined as two graphs that differ in one node rather than one edge. Gehrke et al. [13] explore a different strengthening of differential privacy for social network graphs. An interesting future work direction is to understand whether we can design accurate DSP algorithms that satisfy these strengthened notions of privacy.

2 Preliminaries

2.1 Densest Subgraph

We define the densest subgraph problem [16, 7]. Let G = (V, E) be an undirected graph and S  V . We define E(S) to be the edges induced by S, i.e., E(S) := {(i, j)  E : i, j  S}.

Definition

2.1.

Let

S

 V.

We

define

the

density

d(S)

of

the

subset

S

to

be

d(S) :=

|E(S)| |S|

.

We

define the density d(G) of the undirected graph G(V, E) to be d(G) := maxSV d(S).

Observe that 2d(S) is simply the average degree of the subgraph induced by S. We next define the notion of approximation we use to measure the algorithm's utility.

Definition 2.2 (Approximation algorithm for densest subgraph). Given an undirected graph G = (V, E), we want to design a randomized algorithm Alg that outputs 1) a subset of vertices S  V which is an estimate of the densest subgraph; and 2) a noisy density d, which is an estimate of d(G).
Let   1,  > 0, and   (0, 1]. Such an algorithm Alg is said to achieve (, )-approximation
with 1 -  probability, iff with 1 -  probability, the following hold:

(i). d(S)  d(G)/ - , i.e., the algorithm outputs a dense set S whose (true) density is close to d(G); and

(ii). |d - d(S)|  , i.e., the estimated density d is close to the true density of the reported subgraph S.

As mentioned in Section 1, we consider edge differential privacy in this paper. We say that two undirected graphs G and G are neighboring if the adjacency matrix of G and G differ in only one entry (i.e., G and G are the same except for the existence/non-existence of a single edge). The notion of ( , )-differential privacy and -differential privacy were formally defined in Section 1.

2.2 Mathematical Tools

We define the symmetric geometric distribution [2, 33] which can be viewed as a discrete version of the standard Laplacian distrubtion [8].

Definition 2.3 (Symmetric geometric distribution). Let  > 1. The symmetric geometric distri-

bution

Geom()

takes

integer

values

such

that

the

probability

mass

function

at

k

is

-1 +1

· -|k|.

We shall assume that sampling from the symmetric geometric distribution takes constant time.

How to sample such noises was discussed in detail in earlier works on differential privacy [2].

The global sensitivity of a function f (I), denoted f , is defined as follows:

f := max |f (I) - f (I )|1
I,I neighboring

The following fact about the geometric mechanism (which is equivalent to a discrete version of the Laplacian mechanism) was shown in previous works [8, 9, 5, 6, 2].

Fact 1 (Geometric mechanism). The geometric mechanism f (I) := f (I) + Geom(exp( /f )) sat-

isfies -DP. Moreover, for   (0, 1), for any input I, the error |f (I) - f (I)| is upper bounded by

O( f

· log

1 

)

with

probability

1 - .

6

2.3 Building Block: Differentially Private Prefix Sum Mechanism
Dwork et al. [9] as well as Chan, Shi, and Song [5, 6] suggest a DP prefix sum mechanism. Initially, the mechanism is initialized with N , which is an upper bound on the total number of values that will arrive, and at the time of initialization, the mechanism's output is defined to be 0. Next, a sequence of at most N integer values arrive one by one, and the value that arrives at time t  [N ] is denoted xt. In every time step t, the mechanism outputs an estimate PSumt of the prefix sum
t t xt . The term errt := |PSumt - t t xt | measures the error of the estimate at time t. We say that two integer sequences x := (x1, . . . , xN ) and x := (x1, . . . , xN ) are neighboring, if the vector x - x has exactly one coordinate that is either 1 or -1, and all other coordinates are 0. A prefix sum mechanism for length-N sequences is said to satisfy -adaptive-DP, iff for any admissible (even unbounded) adversary A, for any set ,
Pr[ExptA0  ]  e · Pr[ExptA1  ]
where for b  {0, 1}, ExptAb is defined as follows:
ExptAb :
· Initialize a prefix sum mechanism denoted PSum.
· For t := 1, 2, . . . , N :
­ A outputs the next values x(t0) and x(t1); ­ Input x(tb) to PSum, and send PSum's new output to A.
· Output A's view which includes the sequence of all outputs produced by PSum.

Admissible A. A is said to be admissible, iff with probability 1, the two sequences it produces {x(t0)}t[N] and {x(t1)}t[N] are neighboring.

The earlier works [9, 5, 6] prove the following theorem about such a DP prefix-sum mechanism:

Theorem 2.4 (DP prefix-sum mechanism [9, 5, 6]). There is an -adaptive-DP prefix-sum mechanism satisfying the above syntax, and moreover,

(i).

for

any

fixed

t  [N ]

and



 (0, 1),

with

probability

1 - ,

errt

< O(1

· log1.5 N

·

log

1 

).

(ii). making n updates to the prefix-sum mechanism takes total time O(n), that is, the average time per update is O(1).

Note that although the earlier works [9, 5, 6] stated only the non-adaptive version of the above theorem where the sequence is not chosen adaptively, it is not hard to see that their proofs actually work for adaptive sequences too.

3 A Quasilinear-Time Scheme
3.1 Detailed Construction
We first describe an algorithm that runs in time quasilinear in m+n where m denotes the number of edges and n denotes the number of vertices. The intuition behind our algorithm has been explained in Section 1.2. Later in Section 4, we describe how to improve the algorithm's runtime to O(m + n).

7

Algorithm 1: Differentially Private Densest Subgraph - Quasilinear-Time Variant.

Remark: Below is the meta-algorithm. Immediately after the meta-algorithm description,

we describe additional data structure tricks to run it in quasilinear time.

Data : Let G := (V, E) be the input graph. Let 0 = 1 = 2 = = /4. Let

T

:=

C

log n log

1 

for

a

suitably

large

constant

C.

1: Every vertex v  V computes its noisy degree D(v) = deg(v) + Geom(e 0/2) where deg(v)

denotes v's true degree.

2: Every vertex v  V initializes an 1-DP prefix-sum algorithm. Henceforth we use PSum(v) denote the DP-prefix-sum instance for the vertex v; moreover, the notation PSum(v) also

denotes the current outcome of the algorithm PSum(v).

3: Every vertex v  V initializes a counter, denoted Cnt(v) := 0. Additionally, initialize a fresh

noise E(u) := Geom(e 2).

4: Let S := V and dmax := 0. Repeat the following until S is empty:

(a) Find the vertex v  S whose D(v) - PSum(v) is the smallest. (b) If dmax < D(v) - PSum(v), then update dmax := D(v) - PSum(v) and let S := S. (c) Remove v from S.

(d) For each u  S such that (u, v)  E: let Cnt(u) := Cnt(u) + 1.

(e) For each u  S:

· Let N := Geom(e 2) be a fresh noise.
· If Cnt(u) + E(u) + N > T: input Cnt(u) to PSum(u), reset Cnt(u) := 0 and initialize a fresh noise E(u) := Geom(e 2).

5: return S and d := min

E(S)+Geom(exp( |S|

)) , |S|

.

Running it in quasilinear time. In the above algorithm, if we run Line (4e) na¨ively as is, it will require (n2) time. However, with an additional data structructure trick, we can run the above algorithm in time O(m + n log n). Recall that every time a vertex u's outstanding counter Cnt(u) is reset to 0, we also sample a fresh E(u), and subsequently until Cnt(u) is reset to 0 again, in every time step, we will check if Cnt(u) + E(u) + N > T where N is freshly sampled in the respective time step -- and if so, PSum(u) must be updated. Equivalently, we can change the sampling as follows: any time Cnt(u) gets updated (i.e., either reset to 0 or incremented), we sample a random variable  (u), which means the following: if Cnt(u) does not get updated, when is the next time step in which the event Cnt(u) + E(u) + N > T happens. Note that if  (u) > n, we can simply treat  (u) = . We may assume that  (u) can be sampled in constant time, since it follows a geometric distribution (see earlier works [2] on how to do this). Therefore, we can maintain a table L[1..n] where L[t ] stores a linked list of vertices that want their PSum updated in time step t . If a vertice u's  (u) value changes from t1 to t2 before time step t1, then we remove u from L[t1] and add u to L[t2] -- this can be accomplished in constant time if in the table  (u) that stores the next PSum update time for u, we also store a pointer to u's position in the table L. Instead of executing Line 4(e) in a brute-force way, we can simply read L[t] in each time step t to look for the vertices that want their PSum updated in time step t.
Moreover, we will also use a Fibonnaci heap to maintain the residual noisy degree (i.e., D(v) - PSum(v)) of every vertex. Due to the way T is chosen, for a proper constant C, one can show
8

Figure 1: The approximation ratio of differentially private DSP algorithm for different choices of .

through a standard Chernoff bound that with the probability of 1 - , there cannot be more than 3m PSum updates in which the true increment input to the PSum instance is 0. This means that there cannot be more than O(m) PSum updates in total except with  probability. Summarizing the above, the above algorithm can be executed in time O(m + n log n) with 1 -  probability.

3.2 Differential Privacy and Utility Guarantees

We now formally state the algorithm's differential privacy guarantees as well as utility.

Theorem 3.1 (Differential privacy of the output). The algorithm in Section 3.1 satisfies ( 0 + 1 + 2 + )-DP.

Our algorithm's utility is stated in the following theorem:

Theorem 3.2 (Utility of our algorithm). Our algorithm in Section 3.1 achieves (2, O( 1 · log2.5 n ·

log

1 

))-approximation

with

probability

1

-

.

4 A Linear-Time Algorithm

As mentioned, the algorithm in Section 3.1 takes O(m + n log n) time. We suggest an improved

version that runs in linear time, inspired by a trick suggested by Charikar [7].

Observe that minvSt+1 |E(v, St+1)| - minvSt |E(v, St)|  1. Our algorithm is maintaining a

noisy estimate D(v)-PSum(v) of |E(v, St)| for all residual vertices v. As we discussed, all estimates

have

at

most

O( 1

log2.5 n log

1 

)

error

with

1

-



probability.

Henceforth let C be a sufficiently

large constant, and let err :=

C

log2.5

n log

1 

.

We can discretize the value of D(v) - PSum(v)

into B := n/err + 1 buckets. The i-th bucket will contain values from the range [(i - 1) · err -

9

err/2, (i - 1) · err + err/2]. We can now maintain a data structure such that each vertex is placed in the right bucket depending on the current estimate D(v) - PSum(v). Inside each bucket, we maintain a linked list of vertices. We also maintain an array such that each vertex stores the bucket it currently belongs to, as well as its pointer in the corresponding linked list.
With this idea, we can modify the algorithm in Section 3.1 into a variant that runs in linear time.

Algorithm 2: Differentially Private Densest Subgraph - Linear-Time Variant.

Data

: Let G := (V, E) be the input graph. Let 0 = 1 = 2 = = /4. Let

T :=

C

log n log

1 

for

a

suitably

large

constant

C.

Initialization: Run the initialization steps of Algorithm 1 in Section 3.1, and moreover,

place all vertices in the right bucket. Recall that each vertex stores a

pointer to where it resides in the linked list of its bucket. Initially, let

idx = 1. We may assume that the (imaginary) 0-th bucket is always empty.

1: Let S := V and dmax := 0. Repeat the following until S is empty:

(a) Let idx be the bucket from which a vertex is removed in the previous time step. Check whether each bucket idx - 1, idx , · · · is non-empty, and let idx be the smallest non-empty bucket among these. Let v be an arbitrary vertex from this bucket idx . Remove v from the bucket.
(b) If dmax < D(v) - PSum(v), then update dmax := D(v) - PSum(v) and let S := S.
(c) Remove v from S.

(d) For each u  S such that (u, v)  E: let Cnt(u) := Cnt(u) + 1.

(e) For each u  S, if Cnt(u) + E(u) + N > T where N := Geom(e 2) denotes a fresh noise: // This line is executed efficiently using the same data structure as mentioned in Section 3.1.

· Input Cnt(u) to PSum(u); · Based on the updated value D(u) - PSum(u), relocate u to a new bucket if necessary; · Reset Cnt(u) := 0, and resample a fresh E(u) := Geom(e 2).

2: return S and d := min

E(S)+Geom(exp( |S|

)) , |S|

.

Theorem 4.1 (Linear-time variant). The above algorithm satisfies -DP and moreover, it achieves

(2, O( 1

·

log2.5 n

·

log

1 

))-approximation

with

probability

1

-

.

The algorithm completes in time

O(n + m) with 1 - exp(-(m)) probability where n = |V | and m = |E|.

5 Empirical Results
In this section, we analyze our differentially private algorithm experimentally on real-world datasets and compare it to the optimal solution of DSP.
The first set of datasets on which we run our experiments are social network graphs. We first use socfb-American75 and socfb-Amherst41 datasets available in [27] which are sampled graphs of friendship relations between users in Facebook. Our DSP algorithm intuitively finds a large

10

community in this network. Figure 1 shows the approximation ratio of our algorithm for different choices of . We also set the parameter  equal to 2-30  10-9. Thus, our -DP algorithm succeeds with the probability of at least (1 - 10-9) which is very close to 1. Figure 1 shows our algorithm achieves the accuracy of 75% even when is a very small number such as 0.2. Also, our algorithm is more than 90% accurate when is at least 0.5. This shows that in practice our algorithm finds a very good solution for DSP, despite the fact that our theoretical analysis only achieves (2, 1 · poly log n)-approximation1.
We also run our algorithm on the network of citations. We use cit-HepPh dataset available in [27]. This dataset is the citation graph between High Energy Physics papers. The solution of this graph can be used to detect communities in the aforementioned area in Physics. As it is shown in Figure 1 our algorithm achieves the accuracy of 80% when is at least 0.5.
References
[1] Albert Angel, Nikos Sarkas, Nick Koudas, and Divesh Srivastava. Dense subgraph maintenance under streaming edge weight updates for real-time story identification. Proc. VLDB Endow., 5(6):574­585, February 2012.
[2] Victor Balcer and Salil P. Vadhan. Differential privacy on finite computers. In Anna R. Karlin, editor, 9th Innovations in Theoretical Computer Science Conference (ITCS), volume 94, pages 43:1­43:21. Schloss Dagstuhl - Leibniz-Zentrum fu¨r Informatik, 2018.
[3] Jeremiah Blocki, Avrim Blum, Anupam Datta, and Or Sheffet. Differentially private data analysis of social networks via restricted sensitivity. In ITCS, 2013.
[4] Digvijay Boob, Yu Gao, Richard Peng, Saurabh Sawlani, Charalampos E. Tsourakakis, Di Wang, and Junxing Wang. Flowless: Extracting densest subgraphs without flow computations. In WWW '20: The Web Conference 2020, Taipei, Taiwan, April 20-24, 2020.
[5] T.-H. Hubert Chan, Elaine Shi, and Dawn Song. Private and continual release of statistics. In ICALP, 2010.
[6] T.-H. Hubert Chan, Elaine Shi, and Dawn Song. Private and continual release of statistics. TISSEC, 14(3):26, 2011.
[7] Moses Charikar. Greedy approximation algorithms for finding dense components in a graph. In Proceedings of the Third International Workshop on Approximation Algorithms for Combinatorial Optimization (APPROX), 2000.
[8] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In Theory of Cryptography Conference (TCC), 2006.
[9] Cynthia Dwork, Moni Naor, Toniann Pitassi, and Guy N. Rothblum. Differential privacy under continual observation. In ACM Symposium on Theory of Computing (STOC), 2010.
[10] Cynthia Dwork, Moni Naor, Omer Reingold, Guy N. Rothblum, and Salil Vadhan. On the complexity of differentially private data release: Efficient algorithms and hardness results. In STOC, 2009.
1Note that for our experiments we have chosen graphs such that they have a large solution for the DSP. This is due to the fact that when the solution of DSP is very small, an O( 1 · poly log n) additive error can result in a worse accuracy. That said, in Appendix D we show that some sub-logarithmic additive error is unavoidable for any differentially private algorithm.
11

[11] Cynthia Dwork and Aaron Roth. The algorithmic foundations of differential privacy. Found. Trends Theor. Comput. Sci., 9(3­4):211­407, 2014.
[12] Cynthia Dwork, Guy N. Rothblum, and Salil Vadhan. Boosting and differential privacy. In FOCS, 2010.
[13] Johannes Gehrke, Edward Lui, and Rafael Pass. Towards privacy for social networks: A zero-knowledge based definition of privacy. In Proceedings of the 8th Conference on Theory of Cryptography, 2011.
[14] David Gibson, Ravi Kumar, and Andrew Tomkins. Discovering large dense subgraphs in massive graphs. In VLDB, 2005.
[15] Aristides Gionis and Charalampos E. Tsourakakis. Dense subgraph discovery (dsd). Tutorial at KDD 2015, http://people.seas.harvard.edu/~babis/dsd.pdf.
[16] A. V. Goldberg. Finding a maximum density subgraph. Technical report, USA, 1984.
[17] Anupam Gupta, Moritz Hardt, Aaron Roth, and Jonathan Ullman. Privately releasing conjunctions and the statistical query barrier. In STOC, 2011.
[18] Anupam Gupta, Katrina Ligett, Frank McSherry, Aaron Roth, and Kunal Talwar. Differentially private combinatorial optimization. In SODA, 2010.
[19] Anupam Gupta, Aaron Roth, and Jonathan Ullman. Iterative constructions and private data release. In TCC, 2012.
[20] Moritz Hardt and Guy N. Rothblum. A multiplicative weights mechanism for privacypreserving data analysis. In IEEE Symposium on Foundations of Computer Science (FOCS), pages 61­70, 2010.
[21] Michael Hay, Chao Li, Gerome Miklau, and David Jensen. Accurate estimation of the degree distribution of private networks. In Proceedings of the 2009 Ninth IEEE International Conference on Data Mining, ICDM '09, 2009.
[22] Vishesh Karwa, Sofya Raskhodnikova, Adam Smith, and Grigory Yaroslavtsev. Private analysis of graph structure. ACM Trans. Database Syst., 2014.
[23] Shiva Prasad Kasiviswanathan, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Analyzing graphs with node differential privacy. In TCC'13, 2013.
[24] Samir Khuller and Barna Saha. On finding dense subgraphs. In ICALP, 2009.
[25] Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In FOCS, 2007.
[26] Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Smooth sensitivity and sampling in private data analysis. In Proceedings of the thirty-ninth annual ACM symposium on Theory of computing, STOC '07, pages 75­84, New York, NY, USA, 2007. ACM.
[27] Ryan A. Rossi and Nesreen K. Ahmed. The network data repository with interactive graph analytics and visualization. In AAAI, 2015. URL: http://networkrepository.com.
[28] Aaron Roth and Tim Roughgarden. Interactive privacy via the median mechanism. In STOC, 2010.
12

[29] Polina Rozenshtein, Giulia Preti, Aristides Gionis, and Yannis Velegrakis. Mining dense subgraphs with similar edges. https://arxiv.org/abs/2007.03950, 2020.
[30] Barna Saha, Allison Hoch, Samir Khuller, Louiqa Raschid, and Xiao-Ning Zhang. Dense subgraphs with restrictions and applications to gene annotation graphs. In Research in Computational Molecular Biology, 2010.
[31] Atish Das Sarma, Ashwin Lall, Danupon Nanongkai, and Amitabh Trehan. Dense subgraphs on dynamic networks. In DISC, 2012.
[32] Saurabh Sawlani and Junxing Wang. Near-optimal fully dynamic densest subgraph. In STOC, 2020.
[33] Elaine Shi, T-H. Hubert Chan, Eleanor Rieffel, Richard Chow, and Dawn Song. Privacypreserving aggregation of time-series data. In Network and Distributed System Security Symposium (NDSS), 2011.
[34] Salil Vahdan. The complexity of differential privacy. In Tutorials on the Foundations of Cryptography, https://salil.seas.harvard.edu/publications/complexity-differential-privacy, 2017.
[35] Stanley L. Warner. Randomized response: A survey technique for eliminating evasive answer bias. Journal of the American Statistical Association, 1965.
13

A Failed Na¨ive Approaches
A standard technique for attaining differential privacy is to add noise to the answer calibrated to the global sensitivity of the function being computed [8]. We argue that this approach fails to give meaningful utility since the densest subgraph problem has high global sensitivity.

Reporting the densest subgraph has high global sensitivity. The densest subgraph problem has high global sensitivity if we require that the algorithm outputs the set of vertices that form a dense subgraph. For example, one can easily construct a family of graphs G with n vertices, and satisfying the following properties:
· G contains two disjoint sets of vertices S and S of densities d and d respectively. There are no edges between S and S .
· The densest subgraph of S is S itself; and the densest subgraph of S is S itself. Furthermore, d < d < d + 1/|S |.
This means that the densest subgraph of G is S ; however, if we remove one edge from S , the densest subgraph of the resulting graph would become S. Therefore, the ordinary approach of perturbing the output with noise roughly proportional to global sensitivity [8] does not apply.

Randomized response gives poor utility. A na¨ive approach for solving the DP densest subgraph problem is to rely on randomized response [35, 11, 34] where we use G = (V, E) to denote the original graph given as input:

(i). First, generate a rerandomized graph G as follows: for each (i, j)  V 2 and i < j, flip the

existence

of

the

edge

(i, j)

with

probability

p

:=

1 1+e

.

(ii). Then, run an exact densest subgraph algorithm on the rerandomized graph G. Output the densest subgraph S  V found.

(iii). Output d := (|E(S)| + Geom(e ))/|S| as an estimate of d(G).

It is not hard to show that the above algorithm satisfies 2 -DP, However, the algorithm fails to

give a good approximation. To understand why, consider the following example -- henceforth we

will use dG(·) and dG(·) to denote the density of a subset of vertices in the original graph G and the

rerandomized graph G, respectively. Suppose that = 1 and thus p= (1). Consider some graph G = (V, E), in which the true densest subgraph S is a clique of size n, and therefore d(G) = n.

Moreover, suppose that all vertices not in S do not have any edges in G. One can show that for

any fixed subset U

V

of size at least

n log2

,
n

with

1

-

o(1)

probability,

dG(U )



[p

·

|U |/2,

2p

·

|U |].

Thus with almost all

1- the

o(1) probability, the na¨ive algorithm will report a large subgraph U   V vertices. However, when U   V , the true density dG(U )  1 which is a

containing n factor

smaller than the true answer d(G). In other words, the reported set U  is not a good approximation

of the densest subgraph of G.

B Deferred Proofs for our Quasilinear-Time Scheme
B.1 Deferred Proofs of Differential Privacy
Below, we prove Theorem 3.1. Fix two arbitrary neighboring graphs G and G that differ in only one edge. In the proof below,
we use the notation Pr[·] to denote the probability when G is used as the input, and we the notation

14

Pr[·] to denote the probability when G is used as input. In our algorithm, every time a vertex is
removed from the residual set S, we call it a time step denoted t. Let Ut be the set of vertices whose PSum instance is updated during time step t. For a vertex u  Ut, let t(u) be the new output of PSum(u) after the update. Henceforth, we use the notation preut to denote the time steps up to t (inclusive) in which PSum(u) is updated, the increment passed as input to PSum(u)
during each of these updates, and the new outcome of PSum(u) after each update. We use Iu to denote the time steps in which u is updated.
For an execution of the algorithm, we define the trace as {D(v)}vV , {Ut, {t(u)}uUt}t, where t is different time steps of the algorithm. Note that given the trace, one can uniquely determine the
sequence of the vertices removed in the densest subgraph algorithm. Throughout the proof we fix an arbitrary trace tr = {D(v)}vV , {Ut, {t(u)}uUt}t , and we show that e- · Pr[tr]  Pr[tr] 
e · Pr[tr], hence the algorithm is -DP.
First, consider when G is the input. Let pre0 := {D(v)}vV and for t > 0, let pret := (pret-1, Ut, {t(u)}uUt). We have the following:

Pr[{D(v)}vV , {Ut, {t(u)}uUt }t]

= Pr[pre0] ·

Pr[Ut|pret-1]·

t>0

· Pr PSum(u) outputs t(u) on new input CntGt (u) (pret-1, Ut)
uUt

= Pr[pre0] ·

Pr[Ut|pret-1]

t>0

· Pr PSum(u) outputs t(u) on new input CntGt (u) preut-1

uUt

= Pr[pre0] · Pr[Ut|pret-1] · Pr PSum(u) outputs {t(u)}tIu on updates {CntGt (u)}tIu

t>0

uV

Similarly, we have that

Pr[{D(v)}vV , {Ut, {t(u)}uUt }t]

=Pr[pre0] · Pr[Ut|pret-1] · Pr PSum(u) outputs {t(u)}tIu on updates {CntGt (u)}tIu

t>0

uV

Claim B.1. e- 0 · Pr[pre0]  Pr[pre0]  e 0 · Pr[pre0]
Proof. Observe that G and G differ in at most one edge, and the (non)-existence of every edge affects the degree of at most two vertices. The claim therefore follows from Fact 1.

Claim B.2.

e- 2 · Pr[Ut|pret-1]  Pr[Ut|pret-1]  e 2 · Pr[Ut|pret-1]

t>0

t>0

t>0

Proof. Recall that two graphs G and G differ in only one edge. Let e = {i, j} be this edge, then we can assume w.l.o.g. that e  G and e / G. Now consider the trace {D(v)}vV , {Ut, {t(u)}uUt}t. As we discussed earlier given the trace, we can uniquely determine the sequence of the vertices
15

removed in Step 4 of the algorithm. Let t be the first time step that the algorithm removes one of
the vertices i or j. By symmetry, we can assume that this vertex is i, i.e., i  Ut . Assuming that the algorithm has the same set of noisy degrees {D(v)}vV at the beginning for
both graphs G and G, the algorithm does not see any difference between G and G~ until it reaches
time t . This is because for every vertex v that the algorithm removes before time t , this vertex
has the same set of neighbors in both G and G. Therefore,

Pr[Ut|pret-1] =

Pr[Ut|pret-1] .

(1)

0<t<t

0<t<t

Note that the equality above follows from the fact that given pre0, the algorithm has the same set of noisy degrees {D(v)}vV for both G and G.
Consider the time step t where the algorithm removes i from S. When we run the algorithm on G, vertex j is a neighbor of i. Thus, the algorithm increases the Cnt(j) in this time step. However,
this is not the case in G, and the Cnt(j) remains the same when we run the algorithm on G. We consider two cases for the rest of the proof.

· Case 1: The first case is when j / Ut for any t  t . This means that the algorithm never updates the PSum(j) after the step t . Let t be the time step where the algorithm removes j from S in Step 4 of the algorithm. It is easy to see that given the trace of the algorithm, we can uniquely determine t . We then have,

Pr[Ut|pret-1] =

Pr[u  Ut|pret-1] · Pr[u / Ut|pret-1]

t tt

t tt uUt

u/Ut

=

Pr[u  Ut|pret-1] ·

Pr[u / Ut|pret-1] . (2)

uV t[t ,t ]Iu

t[t ,t ]-Iu

Similarly, for the graph G, we have

Pr[Ut|pret-1] =

Pr[u  Ut|pret-1] ·

Pr[u / Ut|pret-1] . (3)

t tt

uV t[t ,t ]Iu

t[t ,t ]-Iu

In order to complete the proof of this case, we first claim that for every vertex u = j, we have

Pr[u  Ut|pret-1] ·

Pr[u / Ut|pret-1]

t[t ,t ]Iu

t[t ,t ]-Iu

=

Pr[u  Ut|pret-1] ·

Pr[u / Ut|pret-1] .

(4)

t[t ,t ]Iu

t[t ,t ]-Iu

The claim clearly holds for every vertex u = i, j, since u has exactly the same set of neighbors in both G and G. Therefore, given pret-1 we have CntGt (u) = CntGt (u), thus the claim holds. Also, considering the vertex i, the algorithm removes i from S at the time step t , and it never
updates the prefix sum for i after that. Therefore Pr[i  Ut|pret-1] = Pr[i  Ut|pret-1] = 0
for any t  t . Similarly, we have Pr[i / Ut|pret-1] = Pr[i / Ut|pret-1] = 1 for any t  t which implies our claim for the vertex i. We now give the following bound for vertex j.

Claim B.3. For Case 1, let p = t[t ,t ]Ij Pr[j  Ut|pret-1] · t[t ,t ]-Ij Pr[j / Ut|pret-1]
and p = t[t ,t ]Ij Pr[j  Ut|pret-1] · t[t ,t ]-Ij Pr[j / Ut|pret-1], we then have e- 2 p  p  e 2p.

16

Proof. Recall that we are assuming that j / Ut for any t  t . Therefore, [t , t ]  Ij = , and we have

Pr[j  Ut|pret-1] ·

Pr[j / Ut|pret-1] = Pr[j / t tt Ut|pret -1] .

t[t ,t ]Ij

t[t ,t ]-Ij

Similarly, we have

Pr[j  Ut|pret-1] ·

Pr[j / Ut|pret-1] = Pr[j / t tt Ut|pret -1] .

t[t ,t ]Ij

t[t ,t ]-Ij

Recall that we fix the trace tr. Now considering the vertex j, the expression Pr[j / t tt Ut|pret -1] (or Pr[j / t tt Ut|pret -1]) can be equivalently thought as the following. For every time step t  t  t , compute the noisy counter Cnt(j) + N and compare it with the noisy threshold T - E(j), where N is a fresh random noise, and E(j) was chosen the last time Cnt(j) was reset to 0. We want to know what is the probability that for all of t  t  t , Cnt(j) + N never exceeds the threshold T - E(j). This random process is identical to the sparse vector algorithm (see page 57, Algorithm 1 of [11]), applied to the following database and sequence of queries, for the privacy budget 2. Specifically, the database here is a sequence of boolean values that represent whether j is connected to the vertex being removed in steps t to t respectively. The sequence of queries is whether the prefix sum of the database in each time step exceeds T. Note that for G and G respectively, the two databases defined above differ only in one position, i.e., the bit in time step t when i is removed. Moreover, all the prefix sums have sensitity 1. The proof of the sparse vector technique immediately gives us the following (see Theorem 3.23 of [11]):
e- 2 · Pr[j / t tt Ut|pret -1]  Pr[j / t tt Ut|pret -1]
 e 2 · Pr[j / t tt Ut|pret -1] .

Considering any time step t > t , the algorithm has removed both vertices i and j, and it does not see any difference between G and G. Thus,

Pr[Ut|pret-1] = Pr[Ut|pret-1] .

t <t

t <t

The equality above along with equalities (1), (4) and also Claim B.3 implies Claim B.2 for this case.

· Case 2: The second case is when j  Ut for some t  t . Let t  t be the smallest index such that j  Ut . Note that if in the trace tr vertex j gets removed in Step 4 of the algorithm not later than the time step t , we then clearly have Pr[tr] = Pr[tr] = 0, and Claim B.2 clearly holds. Otherwise, we can assume that vertex j gets removed some time after the time step t . It is easy to verify that equations (2) and (3) still hold in Case 2. Also, Equation (4) holds for every vertex u = j. We now give the following bound for vertex j.

Claim B.4. For Case 2, let p = t[t ,t ]Ij Pr[j  Ut|pret-1] · t[t ,t ]-Ij Pr[j / Ut|pret-1]
and p = t[t ,t ]Ij Pr[j  Ut|pret-1] · t[t ,t ]-Ij Pr[j / Ut|pret-1], we then have e- 2 p  p  e 2p.

17

Proof. Recall that we are assuming that j  Ut and j / Ut for any t  t < t . Therefore, [t , t ]  Ij = {t }, and we have

Pr[j  Ut|pret-1] ·

Pr[j / Ut|pret-1]

t[t ,t ]Ij

t[t ,t ]-Ij

= Pr[j  Ut |pret -1] · Pr[j / t t<t Ut|pret -1] (henceforth denoted p) .

Similarly, we have

Pr[j  Ut|pret-1] ·

Pr[j / Ut|pret-1]

t[t ,t ]Ij

t[t ,t ]-Ij

= Pr[j  Ut |pret -1] · Pr[j / t t<t Ut|pret -1] (henceforth denoted p) .

The expressions p or p are equivalent to the following. For every time step t  t  t , the algorithm computes the noisy counter Cnt(j) + N and compares it to the noisy threshold T - E(j). We want to know what is the probability that for all of t  t < t , Cnt(j) + N does not exceed threshold T - E(j), but finally in time t , Cnt(j) + N indeed exceeds threshold T - E(j). Similar to what we discussed in Claim B.3, we can directly apply the analysis of the sparse vector technique here, and obtain that e- 2 · p  p  e 2 · p.

Considering any time step t > t , the algorithm has removed vertex i and the induced subgraph between the vertices in S is exactly the same for both graphs G and G. The algorithm also resets the counters CntG(j) and CntG(j) at the time step t . Furthermore, the
PSum values are exactly the same for G and G conditioning on pret . Thus, the algorithm does not see any difference between G and G after the time step t and we have

Pr[Ut|pret-1] = Pr[Ut|pret-1] .

t <t

t <t

The equality above along with equalities (1), (4) and also Claim B.4 implies Claim B.2 for this case.

This completes the proof for both Case 1 and Case 2 and proves Claim B.2.

Claim B.5. Let p := uV Pr PSum(u) outputs {t(u)}tIu on updates {CntGt (u)}tIu and let p := uV Pr PSum(u) outputs {t(u)}tIu on updates {CntGt (u)}tIu . It must be that e- 1p  p  e 1p.
Proof. Since G and G are neighboring, there is at most one (u, t) pair where t  Iu such that CntGt (u) and CntGt (u) differ by 1. For all other (u, t) pair where t  Iu, CntGt (u) and CntGt (u) must be the same. The claim therefore follows from the 1-DP of the prefix sum mechanism.

Proof of Theorem 3.1. Let S be the subgraph output by the algorithm. Observe that S is uniquely determined by trace {D(v)}vV , {Ut, {t(u)}uUt}t. Therefore, given Claims B.1, B.2, and B.5, we conclude that for any S, e-( 0+ 1+ 2) · Pr[S]  Pr[S]  e 0+ 1+ 2 · Pr[S]. Besides S, the algorithm also needs to output d. Since G and G differ in at most one edge, and due to the distribution of the noise in computing d, it follows that for any d and S,
e- Pr[d|S]  Pr[d|S]  e Pr[d|S]
Therefore, for any S and d, we have that e-( 0+ 1+ 2+ ) · Pr[S, d]  Pr[S, d]  e 0+ 1+ 2+ · Pr[S, d].

18

B.2 Deferred Proofs of Utility
In this section, we prove Theorem 3.2. To prove Theorem 3.2, we will need to use the following lemma proven by Charikar [7].
Lemma B.6 (Upper bound on d(G) [7]). Let G := (V, E) be an undirected graph, and suppose that we arbitrarily assign an orientation to each edge. Let dmax be the maximum number of edges oriented towards any vertex. Then, it must be that d(G)  dmax.
Proof. of Theorem 3.2
Claim B.7. With 1-0.1 probability, the following holds throughout the algorithm: at the beginning of every time step, let S be the residual set, and let v  S; then,
D(v) - PSum(v) - |E(v, S)|  O 1 · log2.5 n · log 1 + T. 

Proof. Recall that 0 = 1 = 2 = = /4. For a fixed v  V , by the property of the Geom(e 0/2)

noise

distribution

in

D(v),

with

probability

1-

0.1 2n

,

|deg(v) - D(v)|

<

C

·

log

n

·

log

1 

for

some

appropriate constant C. Taking the union bound over all v  V , with probability 1 - 0.1/2, it

holds

that

for

all

v



V

,

|deg(v)

-

D(v)|

<

C

·

log n

·

log

1 

.

By Theorem

2.4, for

any v  V

and any fixed time step,

with probability

1

-

0.1 2n2

,

the

error

of

PSum(v)

for

the

fixed

time

step

is

upper

bounded

by

O( 1

· log2.5 n · log

1 

).

Taking

a

union

bound

over

all

time

steps,

it

must

be

that

for

any

fixed

v,

with

probability

1

-

0.1 2n

,

the

error

of

PSum(v)

is

upper

bounded

O( 1

· log2.5 n · log

1 

)

in

all

time

steps.

Taking

a

union

bound

over

all

vertices,

it

must

be

that

with

probability

1

-

0.1 2

,

the

above

holds

for

all

vertices.

Recall that we do not update PSum(v) in every time step, only when Cnt(v) + E(v) + N

has exceeded the threshold T. Further, E(v, V \S) is equal to the true sum of all incre-

ments input to PSum(v) so far, plus Cnt(v). For any fixed E(v), with 1 - 0.1/n3 probability,

|E (v)|



O( 1

log

n

log

1 

).

The

same

holds

for

each

fixed

N.

Therefore,

with

1 - 0.1

probability,

it must be that any noise E(v) or N generated throughout the algorithm has magnitude at most

O(

1

log

n

log

1 

).

This means with 1 - 0.1

probability, throughout the algorithm and for any v,

the outstanding counter value Cnt(v) that has not been accumulated by PSum(v) cannot exceed

T

+

O(

1

log

n

log

1 

).

Therefore, with probability 1 - 0.1, it must be that at the beginning of every time step, and

for every v  S where S is the current residual set -- henceforth, we use TruePSum(v) to mean the

true prefix sum of all inputs that have been sent to PSum(v):

D(v) - PSum(v) - |E(v, S)|

= D(v) - PSum(v) - (deg(v) - |E(v, V \S|)

 D(v) - deg(v) + |E(v, V \S|) - PSum(v)

= D(v) - deg(v) + Cnt(v) + TruePSum(v) - PSum(v)

 D(v) - deg(v) + Cnt(v) + TruePSum(v) - PSum(v)

O

1

1

· log n · log

+T+O

1

1

· log n · log

+O

1 · log2.5 n · log 1







O 1 · log2.5 n · log 1 + T 

19

Claim B.8. Consider some execution of our algorithm, and let and let err := maxt,vSt D(v) -
PSumt(v)-|E(v, St)| where St denotes the residual set at the beginning of time step t, and PSumt(v) denotes the output of PSum(v) at the beginning of time step t. Then, d(S)  (d(G) - 4 · err)/2.

Proof. Fix an arbitrary time step t, it holds that minvSt |E(v, St)|  2|E(St)|/|St|. Let vt  St be the actual vertex that is removed in time step t, i.e., vt := arg minv(D(v) - PSumt(v)). It
therefore holds that |E(vt, St)| - minvSt |E(v, St)|  2 · err. Now, suppose that as a vertex vt gets removed from the residual graph St, all edges E(vt, St)
are oriented towards vt. Observe that the dmax := maxt(D(vt) - PSumt(vt)) value at the end of
the algorithm is a good estimate of maxt(E(vt, St)). Specifically, dmax  maxt(E(vt, St)) - 2 · err. Henceforth let t := arg maxt(D(vt) - PSumt(vt)), and therefore, our algorithm's output S := St.
By Lemma B.6, it holds that d(G)  maxt(E(vt, St))  dmax + 2 · err = D(vt) - PSumt(vt) + 2 · err  minvSt |E(v, St)| + 2 · err + 2 · err = 2 · err  2|E(St)|/|St| + 4 · err = 2|E(S)|/|S| + 4 · err. In other words, d(S)  (d(G) - 4 · err)/2.

Finally, observe that by the definition of d and due to Fact 1, with probability 1 - 0.1,

|d - d(S)|



O( 1 log

1 

).

Theorem

3.2

now

follows

from

this

fact,

as

well

as

Claims

B.7

and

B.8,

and the choice of T.

C Deferred Proofs for the Linear-Time Algorithm

In this section, we prove Theorem 4.1. The DP proof is the same as Theorem 3.1. For the utility

analysis, we may assume that whenever PSum(u) is updated from  to  for any vertex u, it holds

that  -  < err/2 where err is the discretization parameter used in the bucketing -- using the

same type of arguments as the proof of Claim B.7, one can show that this indeed holds except with

0.1 probability. This means that no vertex v's noisy residual degree D(v)-PSum(v) should shrink

by more than err/2+1 in two adjacent time steps, i.e., whenever a vertex v moves buckets, it cannot

move left by more than 1 bucket. Therefore, effectively, the only difference between this linear-time

variant and the earlier algorithm in Section 3.1 is the following: in this new variant, we do not

necessarily pick arg minv(v, St) in every time step t. We could pick a vertex vt in time step t such

that |vt - arg minv(v, St)|  err. This introduces an additive err term in the proof of Theorem 3.2.

Due to the choice of err, and redoing Theorem 3.2 with the extra additive err term, we conclude

that

the

above

algorithm

achieves

(2,

O( 1

·

log2.5

n

·

log

1 

))-approximation

with

probability

1

-

.

We now bound the algorithm's runtime. First, not counting the runtime associated with PSum

updates, the rest of the algorithm is easily seen to take only O(n + m) time -- specifically, the total

work spent in Line 1 is at most O(n) due to the same reason as Charika's non-DP, linear-time

algorithm. Due to the runtime of PSum stated in Theorem 2.4, to prove the statement about

the runtime, it suffices to show that the number of PSum updates is upper bounded by 4m with

probability exp(-(m)). Consider running the algorithm till it makes exactly 4m PSum updates

-- if the algorithm ends before making 4m PSum updates, we can simply pad it to exactly 4m

number of PSum updates by appending filler PSum updates at the end of the algorithm which does

not affect the outcome. In this way, there is exactly one noise E associated with each of the 4m

PSum updates. Due to the choice of T, the probability that each E is greater than T is at most

/n. Due to the Chernoff bound, the probability that there exist 3m or more noises E that are

greater than T is exp(-(m)). This means that for m of these PSum updates, the true increment

input to the PSum instance must be at least 1, and thus one edge must be consumed for each of

these m PSum updates. In other words, except with exp(-(m)) probability, the algorithm must

have ended after having made 4m or fewer PSum updates.

20

D Lower Bound

Theorem 1.3. Let  > 1, > 0 be arbitrary constants, exp(-n0.49) <  < 0.000001 ·

min(1,

, exp(-

)), and

0

 log

1 4

.

Then, there

exists a sufficiently

small  = 

1 

1

log

1 

such that there does not exist an ( , )-DP mechanism that achieves (, )-approximation with 1 - 

probability.

Proof.

Suppose there exists an ( , )-DP mechanism denoted M that achieves (, )-

approximation

with

1-

probability,

for

the

parameters

stated

above.

Let



=

1 100

1

log

1 4

.

We

will reach a contradition below. Thus, no ( , )-DP mechanism can achieve a (, )-approximation.

Consider a graph over n vertices V := [n]. Suppose that a subset A  V of size 4 + 1 of the

vertices form a clique, and there are no other edges in G. Therefore, the densest subgraph of G is

A,

and

its

density

is

|A|-1 2

which

is

2.

Note

that

for

our

choices

of

parameters,

we

always

have

  1.

If we run the mechanism M over this graph G, we know that with probability 1 - , the true

density of set of vertices output is at least . This means that with probability 1 - , at most (4)(4 + 1)/(2)  162 vertices are output, since the graph G has (4)(4 + 1)/2 total

number of edges. In other words, the expected number of vertices output is upper bounded by

(1 - ) · 162 +  · n .

(5)

We claim that there must exist a set B of size 4 + 1 that is disjoint from A such that with

probability at least 1/2, no vertex in B is output. Suppose that this is not the case, then, the

expected number of vertices contained in the output is at least s :=

n-(4+1) 4+1

·

1 2

.

For suitable

choice of parameters as stated in the theorem statement, s would be greater than Equation (5) for

sufficiently large n, which leads to a contradiction.

Now, consider another graph G in which the set B of vertices form a clique and there are no

other edges in G . G can be obtained by making 2 · (4 + 1)(4)/2  3222 edge modifications

starting from G.

We now use the group privacy theorem to derive a lower bound on the probability that mech-

anism M does not output any of the vertices in B if we run it on G .

Theorem D.1 (Group Privacy). Let M be a ( , )-DP mechanism, and G, G be two datasets. Then, for any subset U of the output space,
Pr[Alg(G)  U ]  ek · Pr[Alg(G )  U ] +  · k · ek ,

where k is the hamming distance between G and G .

By ( , )-DP and the group privacy theorem, it holds that if we run the mechanism M on the graph G , the probability that none of B is selected is at least

1 - 3222 exp(3222 ) · exp(- · 3222) = 1 exp(-32 · 22) - 3222

2

2

> 2 -  =  ,

where

the

inequality

above

is

because





1 100

1

log

1 4

,

and





 log

1 4

.

Thus,

with

larger

than



probability, the true density of the set of vertices output is 0. Therefore, it is impossible that the

mechanism M gives (, )-approximation with 1 -  probability (over any graph).

21

