Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 2021-4-28. doi:10.1186/s42400-021-00094-6

RESEARCH
Social Engineering in Cybersecurity: A Domain Ontology and Knowledge Graph Application Examples
Zuoguang Wang1,2*, Hongsong Zhu1,2*, Peipei Liu1,2 and Limin Sun1,2

Abstract
Social engineering has posed a serious threat to cyberspace security. To protect against social engineering attacks, a fundamental work is to know what constitutes social engineering. This paper first develops a domain ontology of social engineering in cybersecurity and conducts ontology evaluation by its knowledge graph application. The domain ontology defines 11 concepts of core entities that significantly constitute or aect social engineering domain, together with 22 kinds of relations describing how these entities related to each other. It provides a formal and explicit knowledge schema to understand, analyze, reuse and share domain knowledge of social engineering. Furthermore, this paper builds a knowledge graph based on 15 social engineering attack incidents and scenarios. 7 knowledge graph application examples (in 6 analysis patterns) demonstrate that the ontology together with knowledge graph is useful to 1) understand and analyze social engineering attack scenario and incident, 2) find the top ranked social engineering threat elements (e.g. the most exploited human vulnerabilities and most used attack mediums), 3) find potential social engineering threats to victims, 4) find potential targets for social engineering attackers, 5) find potential attack paths from specific attacker to specific target, and 6) analyze the same origin attacks.
Keywords: Social engineering attack; Cyber security; Ontology; Knowledge graph; Attack scenarios; Threat analysis; Attack path; Attack model; Taxonomy; Composition and structure

1 Introduction
In the context of cybersecurity, social engineering describes a type of attack in which the attacker exploit human vulnerabilities (by means such as influence, persuasion, deception, manipulation and inducing) to breach the security goals (such as confidentiality, integrity, availability, controllability and auditability) of cyberspace elements (such as infrastructure, data, resource, user and operation). Succinctly, social engineering is a type of attack wherein the attacker exploit human vulnerability through social interaction to breach cyberspace security [1]. Many distinctive features make social engineering to be a quite popular attack in hacker community and a serious, universal and persistent threat to cyber security. 1) Compared to classical attacks such as password cracking by
*Correspondence: wangzuoguang16@mails.ucas.ac.cn; zhuhongsong@iie.ac.cn 1School of Cyber Security, University of Chinese Academy of Sciences, Beijing, CN 2Beijing Key Laboratory of IoT Information Security Technology, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, CN Full list of author information is available at the end of the article

brute-force and software vulnerabilities exploit, social engineering exploits human vulnerabilities to bypass or break through security barriers, without having to combat with firewall or antivirus software by deep coding. 2) For some attack scenarios, social engineering can be as simple as making a phone call and impersonating an insider to elicit the classified information. 3) Especially in past decades when defense mainly focus on the digital domain yet overlooks human factors in security. As the development of security technology, classical attacks become harder and more and more attackers turn to social engineering. 4) Human vulnerabilities seem inevitable, after all, there is not a cyber system doesn't rely on humans or involve human factors on earth and these human factors are vulnerable obviously or can be largely turned into security vulnerabilities by skilled attackers. Moreover, social engineering threat is increasingly serious along with its evolution in new technical and cyber environment. Social engineering gets not only large amounts of sensitive information about people, network and devices but also more attack channels with the wide applications of So-

This article has been accepted for publication in a future issue of Cybersecurity (ISSN: 2523-3246), but has not been fully edited. Content may change prior to final publication. Citation information, DOI: 10.1186/s42400-021-00094-6 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/.

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 2 of 20

cial Networking Sites (SNSs), Internet of Things (IoT), Industrial Internet, mobile communication and wearable devices. And large part of above information is open source, which simplifies the information gathering for social engineering. Social engineering becomes more e cient and automated by technology such as machine learning and artificial intelligence. As a result, a large group of targets can be reached and specific victims can be carefully selected to craft more creditable attack. The spread of social engineering tools decrease the threat threshold. Loose o ce policy (bring your own device, remote o ce, etc.) leads to the weakening of area-isolation of dierent security levels and creates more attack opportunities. Targeted, large-scale, robotic, automated and advanced social engineering attack is becoming possible [1].
To protect against social engineering, the fundamental work is to know what social engineering is, what entities significantly constitute or aect social engineering and how these entities relate to each other. Study [1] proposed a definition of social engineering in cybersecurity based on systematically conceptual evolution analysis. Yet only the definition is not enough to get insight into all the issue above, and further, to server as a tool for analyzing social engineering attack scenarios or incidents and providing a formal, explicit, reusable knowledge schema of social engineering domain.
Ontology is a term comes from philosophy to describe the existence of beings in the world and adopted in informatics, semantic web, knowledge engineering and Artificial Intelligence (AI) fields, in which an ontology is a formal, explicit description of knowledge as a set of concepts within a domain and the relationships among them (i.e. what entities exist in a domain and how they related). It defines a common vocabulary for researchers who need to share information and includes definitions of basic concepts in the domain and their relations [2]. In an ontology, semantic information and components such as concept, object, relation, attribute, constraints and axiom are encoded or formally specified, by which an ontology is machinereadable and has capacity for reasoning. In this way, ontology not only introduce a formal, explicit, shareable and reusable knowledge representation but also can add new knowledge about the domain.
Thus, we propose a domain ontology of social engineering to understand, analyze, reuse and share domain knowledge of social engineering.
Organization: Section 2 describes the the background material and methodology to develop domain ontology. Section 3 presents the material and ontology implementation. Section 4 is the result: domain ontology of social engineering in cybersecurity. Section 5 is the evaluation and application of the ontology and

knowledge graph. Section 6 is the discussion. Section 7 concludes the paper.
2 Methodology to develop domain ontology
There is no single correct way or methodology for developing ontologies [2]. Since ontology design is a creative process and many factors will aect the design choices, such as the potential applications of the ontology, the designer's understanding and view of the domain, dierent domain features, anticipations of the ontology to be more intuitive, general, detailed, extensible and / or maintainable.
In this paper, we design the methodology to develop domain ontology of social engineering based on the method reported in work [2] with some modification. Prot´eg´e 5.5.0 [3] is used to edit and implement the ontology. It should be noted that "entity" in real word are described as "concept" in ontology and "class" in Prot´eg´e; "relation" is described as "object property" in Prot´eg´e. The methodology is described as Figure 1.

Determine the domain, purpose
and scope

Consider reusing existing ontologies

Enumerate important terms in the ontology

Result: ontology

Define core concepts, concept taxonomy and description
revise
Validate

Define relations, relation description and characteristic
Define other descriptions e.g. rules, annotations, axioms

Figure 1 Overview of methodology to develop domain ontology of social engineering

(1) Determine the domain, purpose and scope. As described before, the domain of the ontology is social engineering in cybersecurity. The purpose of the ontology, i) for design is to present what entities significantly constitute or aect social engineering and how these entities relate to each other, ii) and for application is to server as a tool for understanding social engineering, analyzing social engineering attack scenarios or incidents and providing a formal, explicit, reusable knowledge schema of social engineering domain. Thus, social engineering itself as a type of attack, measures regarding social engineering defense will not be included here although they are important. Defense will be the theme in our future work.

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 3 of 20

(2) Consider reusing existing ontologies. We did a systematic literature survey on social engineering and accumulated a literature database which contains 450+ studies from 1984.9 (time of the earliest literature available where the term "social engineering" was found in cybersecurity [1]) to 2020.5.[1] Few work focus on the social engineering ontology, yet a lot of terms can be obtained from literature survey. (3) Enumerate important terms in the ontology. "Initially, it is important to get a comprehensive list of terms without worrying about overlap between concepts they represent, relations among the terms ..." [2]. These terms are useful to intuitively and quickly get a sketchy understanding on a domain, and helpful to develop a core concepts set after due consideration. A total of 350 relevant terms are enumerated from the literature database mentioned in (2). Table 1 shows these terms in a compact layout by length order. [2] The next two steps are the most important steps in the ontology design process [2]. (4) Define core concepts, concept taxonomy and description. In work [2], this step is to create the class hierarchy for a single concept "Wine". However, the "class, sub-class" hierarchy is a structure typically used to classification, in which only the relation "is a" or "is type of" is described. This is not the purpose of this paper. Thus, dierently, we define a set of concepts for entities which significantly constitute or aect social engineering domain and discuss their taxonomy. Then, we define more expressive relations among concepts in next step. For each core concept, a definition is provided and relevant synonym terms are mentioned, to facilitate the reuse and sharing of domain knowledge. For example, attacker (a.k.a. social engineer) is the party to conduct social engineering attack; it can be an individual or an organization, and internal or external. In Prot´eg´e, these concepts are edited in the "Classes" tab. Two Classes "Attacker" and "Social Engineer" are created and because they represent the same class (concept), a description (class axiom) "Equivalent To" is set between them in the "Description" tab. As Figure 2 shows. (5) Define relations, relation description and characteristic. This step we create the relations among concepts based on their definitions. Some relations directly expressed in the definition while some may be implicit and need a explicit description. For example, attack
[1]The literature database was submitted as supplementary material for review. [2]Term lists organized by alphabetical order and semantic groups were submitted as supplementary material for review.

Figure 2 Edit concepts and their description
motivation is the factors that motivate (incent, drive, cause or prompt) the attacker to conduct a social engineering attack; thus, a concise relation "motivate" from "attack motivation" to "attacker" can be created. And to be more compatible, two sub-relation "incent" and "drive" or another equivalent relation can be added. In Prot´eg´e, these relations are edited in the "Object properties" tab. For above example, "motivate" as an Object property is created; "Attack Motivation" is its Domain and "Attacker" is its Range. Because it represents that a class points to another different class, the relation characteristic "Irreflexive" is set. As Figure 3 shows.
Figure 3 Edit relations, relation description and characteristic
(6) Define other descriptions. Besides above, other descriptions can be added, such as annotations, axioms, rules. Examples are as follows. For class "Attacker", its definition can be added as a comment in Annotations tab with "rdfs:comment", to facilitate conceptual understanding and later debug. Axioms are statements that are asserted to be true. For

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 4 of 20

Table 1 Terms related to social engineering in cybersecurity

APT groups Facebook Instagram person name attack vector company partner reciprocity norm mobile application

posts in social media

fun hacker flattery integrity server name central route confidentiality religion belief network disruption

similarity and liking

war hubris gluttony interests take effect desk sniffing controllability shoulder surfing penetration tester

vulnerability exploit

XSS induce humility prejudice attach files eavesdropping decision making social relations

perform attack

intellectual challenge

bias letter identity principle attack model employee name deindividuation website phishing source credibility

internal phone numbers

card medium kindness secretary attack skill impersonation direct approach adjacent overhear telephone operator

malicious popup window

CSRF motive laziness self-love auditability item dropping dumpster diving attack motivation trust relationship

obtain physical access

envy piston LinkedIn terrorism availability launch attack economic profit behavioral habits authoritative voice

reputation destruction

fear spying openness user name carelessness name-dropping fake mobile app computer operator cultural disruption

social engineering bot

goal target password compliment email footer reverse sting group influence conscientiousness data exfiltration

social exchange theory

hoax victim phishing conformity email format security risk instant message data modification denial of service

software vulnerability

KeeK baiting phreaker contractor equivocation self interest office snooping deceptive website emotion and feeling

thought and expression

lust charity pleasure diffidence extraversion time pressure craft attack drive-by download executive assistant

vulnerability analysis

name clients politics excitement face-to-face trojan attack self-disclosure drive-by-pharming individual attacker

portable storage drives

scam disgust RFID tag flirtation friendliness trojan device social disorder external attacker intuitive judgement

questionnaire surveying

SNSs friends scarcity heuristics inexperience vulnerability social engineer external pressure neurophysiological

Social Networking Sites

anger Google+ smishing job title ingratiation watering hole social software facial expression organizational logo

the quest for knowledge

cloud hobbies software moral duty interruption attack pattern thoughtlessness instant messenger unauthorized access

administrative assistant

dread manager strategy motivation intimidation attack purpose application name internal attacker cognitive dissonance

organizational structure

email manuals surprise persuasion IP addresses build relation attack framework IT infrastructure disgruntled employee

voice mail systems vendor

greed partner sympathy pretending manipulation financial gain attack technique network intrusion facial action coding

commitment and consistency

guilt phisher trailing pretexting masquerading framing effect bystander effect personal interest interesting malwares

human resources department

lingo picture trashing road apple new employee identity thief confidence trick physical presence network interception

reverse social engineering

photo profile weakness attack goal piggybacking image spoiling data destruction physical sabotage rapport relationship

social responsibility norm

prank purpose authority attack path quid pro quo mobile devices data fabrication political purpose system administrator

diffusion of responsibility

Skype QR code bluetooth attack plan receptionist mobile website e-mail addresses social validation Voice over IP (VoIP)

short message service (SMS)

sloth revenge calendars connections social proof movable device effect mechanism sports fanaticism accounting department Elaboration Likelihood Model

trick sadness credulity distraction stereotyping pop-up windows financial return technical support attacker organization computer hardware manufacturer

video tension curiosity elicitation thinking set security guard foot-in-the-door attack consequence competitive advantage computer software manufacturer

weibo Twitter deception gullibility trust theory social network IT professionals creating confusion fixed-action patterns

telephone system administrator

wrath vishing happiness helpfulness agreeableness spear phishing mental shortcuts employee functionsimpression management low level of need for cognition

apathy website help desk indifferent attack medium urgent request micro expression fake business card information gathering increasing the number of friends

attack whaling ignorance information attack method attack approach peripheral route family information instant communication IVR (Interactive Voice Response)

awards attacker impulsion neuroticism attack target attack strategy person-to-person gather information language and thinking interpersonal deception theory (IDT)

Flickr courtesy influence overloading attack threat attacker group phone, telephone habitual behaviors organizational policy integrative model of organizational trust

relation "motivate", we can create an inverse relation "motivated by" and then set the description (object property axiom) "Inverse Of" against "motivate", to facilitate the knowledge retrieval like "attacker is motivated by certain attack motivation". Ontology can also generate new knowledge by reasoning with rules. Assume that "dierent attackers are regarded as from the same attack organization if they motivated by the same motivation and attack the same victim", then the following rule can be defined to implement the reasoning. Rule: motivate(?m, ?a) ^ attack(?a,?v) ^ motivate(?m, ?b) ^ attack(?b,?v) ^ dierentFrom(?a, ?b) ! same attack organization(?a, ?b). As Figure 4 shows.
(7) Validate and revise. After defining the concepts, relations and related descriptions, a domain ontology is created. Yet it is initial and imperfect. Minor mistakes such as misplacement and typing error may be occurred when large amount of items existed. Illogical or contradictory descriptions may be defined. Some class, relations or descriptions may be absent or superfluous. Thus, an iterative process is necessary for ontology development, validation and revision. By virtue of the ontology is formal and explicit encoded, any faults that cause logical inconsistency can be found. The built-in reasoner HermiT is used for

this reasoning validation. Further, we create instances as the actual data to conduct a deductive validation, as Figure 4 shows. This is an intuitive method to test whether the ontology (e.g. the rules) is eective, and it also provides a way helpful to adjust descriptions and revise the ontology to achieve the purpose previously.
Figure 4 Define and apply rules to knowledge reasoning
(8) Result: Ontology. Finally, a domain ontology of social engineering is developed after iterative revision and validation.

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 5 of 20

3 Material and ontology implementation
The background material regarding literature and terms have been mentioned in Section 2 and we will not repeat them here. This section presents the key material and procedures for the ontology implementation, i.e. defining the concepts, relations and other descriptions related.

3.1 Define core concepts in the domain ontology
This subsection details 11 core concepts corresponding to entities that significantly constitute or aect social engineering domain. For each concept, the concept definition, synonym term, taxonomy and some other properties are described. Figure 5 shows these entities (concepts). The circular arrow represents an approximate attack cycle for typical attack scenarios: 1) the attacker motivated by certain factors 2) to gather specific information, formulate attack strategy, craft attack method 3) and then through certain medium the attack method is performed and the attack target is interacted with 4) to exploit their vulnerabilities which take eect and lead to attack consequences; 5) the consequence feed back to the attack goal predetermined to satisfy the attack motivation.

Attack Motivation

Attacker

Social Engineering Information

Attack Goal
Attack Consequence

Social Engineering in Cybersecurity

Attack Strategy Attack Method

Effect Mechanism

Attack Medium (Social Interaction)

Human Vulnerability

Attack Target / Victim

Figure 5 Core entities (concepts) in social engineering domain

3.1.1 Attacker
For social engineering, the attacker (a.k.a. social engineer) is the party to conduct a social engineering attack; it is typically motivated by certain factors discussed in Section 3.1.2. Social engineering attackers appear in various forms in reality, such as hackers, phreakers, phishers, disgruntled employees, identity thieves, penetration testers, script kiddies, malicious users. Dierent criteria can also be used for the attacker's taxonomy. The attacker identified as an individual person is familiar to the public, yet it does not have to be an individual. The attacker can also be a group or an organization. The attacker can be a real person, or a virtual human role (e.g. a bot), and it can be from internal or external. Figure 6.

Attacker

taxonomy 1 taxonomy 2 taxonomy 3

individual group organization internal external real person virtual human role

Figure 6 Taxonomy of attacker (social engineer)

3.1.2 Attack Motivation Attack motivation is the factors that motivate (incent, drive, cause or prompt) the attacker to conduct a social engineering attack. It can be intrinsic or extrinsic. Considering that this simple taxonomy does not seem to be significantly helpful to the social engineering analysis, a common list of attack motivations in social engineering may be more intuitive. It includes but is not limited to: 1) financial gain [4], 2) competitive advantage [5], 3) revenge [4], 4) external pressure, 5) personal interest, 6) intellectual challenge, 7) increasing followers or friends in SNSs, 8) image spoiling (denigration, reputation destruction, stigmatization), 9) prank, 10) fun or pleasure, 11) politics, 12) war, 13) religious belief, 14) fanaticism, 15) social disorder, 16) cultural disruption [6], 17) terrorism, 18) espionage, 19) security test.
3.1.3 Attack Goal and Object The attack goal (a.k.a. attack purpose) is something that the attacker wants to achieve by specific attack methods so that the attack motivation can be satisfied. For social engineering, it is some kinds of breaching against cyberspace security. In general, to breach cyberspace security is to breach the security goals (confidentiality, integrity, availability, controllability, auditability, etc.) of the four basic elements of cyberspace (i.e. attack object) [1]. These four basic elements are Carrier (the infrastructure, hardware and software facilities of cyberspace), Resources (the objects, data content that flows through the cyberspace), Subjects (the main body roles and users, including human users, organizations, equipment, software, websites, etc.), and Operations (all kinds of activities of processing Resources, including creation, storage, change, use, transmission, display, etc.) [7, 8]. For complex attack scenarios, there may be sub-goals (precondition) exist, which themselves may not breach the cybersecurity.
Social engineering attack goal includes but is not limited to: 1) network intrusion, interception or disruption, 2) gain unauthorized access to information or systems, 3) denial of service, 4) data exfiltration, modification, fabrication or destruction, 5) infrastructure

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 6 of 20

sabotage, 6) obtain physical access to restricted areas. Thus, it can be simply classified as above categories or use other taxonomies as Figure 7 shows.

Attack Goal and Object

network intrusion, interception or disruption

intuitive taxonomy

gain unauthorized access to information or systems denial of service
data exfiltration, modification, fabrication or destruction infrastructure sabotage

obtain physical access to restricted areas

to breach security goals
taxonomy 2

... confidentiality integrity availability controllability auditability

... carrier

to breach cyberspace elements (object) taxonomy 3

resources subjects operations

...

Figure 7 Taxonomy of social engineering attack goal

3.1.4 Social Engineering Information In many attack scenarios, the success of social engineering relies heavily on the information gathered, such as personal information of the targets (victims), organization information, network information, social relation information. In a broad sense, every bit of information posted publicly or leaked in cyberspace or in reality might provide attackers the resource, such as to learn the environment, to discover targets, to find vulnerable human factors and cyber vulnerabilities, to formulate attack strategy, and to craft attack methods. This is also a feature of social engineering compared with classical computer attack. Thus, this paper use "social engineering information" to represent any information that helps the attacker to conduct a social engineering attack.
Social engineering information includes but is not limited to: 1) person name, 2) identity 3) photograph, 4) habits and characteristics, 5) hobbies or interests, 6) job title, 7) job responsibility, 8) schedule, 9) routines, 10) new employee, 11) organizational structure, 12) organizational policy, 13) organizational logo, 14) company partner, 15) lingo, 16) manuals, 17) interpersonal relations, 18) family information, 19) profile in SNSs, 20) posts in social media, 21) connections in SNSs, 22) SNSs group information, 23) (internal)

phone numbers, 24) email information (address, format, footer, etc.), 25) username, 26) password, 27) network information, 28) computer name, 29) IP addresses, 30) server name, 31) application information, 32) version information, 33) hardware information, 34) IT infrastructure information, 35) building structure, 36) location information.
Figure 8 presents a taxonomy based on what space the information describes, in which the last level may be more intuitive. Other taxonomies can be also workable, such as publicly accessible information, restricted information; personal information, social relations information and other various environments (cyber, cultural, physical) information.

Social Engineering Information

individual identification

psychological characters personality trait behavior and habits

individual information

describe social space

... interpersonal relations organization information job information communication information

social information

... account information

network information

computer information

describe cyber space

application, service software information hardware information infrastructure information

environment information

describe physical space

... building structure location information
...

Figure 8 Taxonomy of social engineering information

3.1.5 Attack Strategy Attack strategy is a plan, pattern, or guidance of actions formulated by the attacker for certain attack goal. It is necessary especially for complex social engineering attacks. Usually, social engineering attackers formulate the attack strategy based on their comprehensive understanding on the attack situation, such as resources, environments, targets, vulnerabilities and mediums. There are two common social engineering strategies in literature: forward (usual) strategy and reverse strategy. In forward attack strategy, the attacker directly contacts the targets and delivers attack payloads to them, waiting the targets to trigger the attack and be compromised. However, in reverse social engineering, the targets are prompted to contact the attacker actively for a request or help, and the attacker usually pretends to be a party of legitimate, authoritative, expert or trustworthy in advance. As a result,

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 7 of 20

a higher degree of trust is established and the targets are more likely to be attacked. E.g. The attacker first makes a network failure and then pretends to be a technical support sta; when the targets seek for a help, the attacker convinces them with certain excuses into revealing the password or installing a malicious software.
From the duration perspective, attack strategy can be persistent strategy or short-term strategy. Some other categories are also helpful to label the attack strategies, as Figure 9 shows.

Attack Strategy

common taxonomy
duration taxonomy
other strategy categories or labels

forward strategy
usual strategy
reverse strategy persistent strategy short-term strategy targeted strategy multiple targets strategy progressive strategy

Figure 9 Taxonomy of social engineering attack strategy

smishing+DoS spear phishing+
CSRF phishing+XSS
phishing+ drive-by download social engineering
based APT ...
name-dropping authoritative voice
using awards quid pro quo
intimidation equivocation creating confusion
flirtation confidence trick
trust building rapport building compliments, flattery create urgent context using fake name card
...

combined method
Attack Method used in auxilliary tricks

human based method

influence deception persuasion manipulation inducing
...

also common
skills used in other methods

pretending impersonation masquerading

shoulder surfing

piggybacking

trailing

computer based method

(phone) pretexting vishing (email) phishing website phishing smishing spear phishing whaling WiFi phishing trojan attack baiting watering hole

...

3.1.6 Attack Method When the attack strategy existed, attack method is generally according to or guided by it. Attack method is the way, manner or means of carrying an attack out; the attacker crafts and performs it to achieve specific attack goal. Synonyms such as attack vector, attack technique and attack approach are used to convey the same meaning. A common taxonomy in literature is to divide social engineering attacks into human-based and computer-based (or technology-based) [9­13]. Figure 10 (right) presents 20 attack method instances, in which some methods such as influence, deception, persuasion, manipulation and induction also describe skills frequently used in other methods. In many attack scenarios, multiple social engineering methods can be jointly used; classical attack methods that exploit non-human-vulnerabilities might also be combined to perform social engineering attacks. Besides, there are many auxiliary tricks or cunning actions may be utilized in dierent methods to assist the attack (e.g. to obtain trust, influence or deceive the targets). Figure 10 shows the overview of these categories and the corresponding instances. It is a non-exhaustive list and it seems impossible to enumerate all the social engineering attack methods, since new attack methods are emerging as the development of cyber technology, the evolution of environment and attackers' creation.
3.1.7 Attack Target, Victim Attack target is the party to suer a social engineering attack and bring about an attack consequence.

Figure 10 Taxonomy of social engineering attack method

The attacker applies attack method to the targets, and they become victims once their vulnerabilities were exploited. For attackers, anyone helpful to achieve the attack goal is a potential attack target. And the attacker might select multiple targets in some attack scenarios. The potential attack targets include but is not limited to: 1) new employees, 2) secretaries, 3) help desk, 4) technical support, 5) system administrators, 6) telephone operators, 7) security guards, 8) receptionists, 9) contractors, 10) clients, 11) partners, 12) managers, 13) executive assistants, 14) manufacturers, 15) vendors [14]. Similar to the attacker, attack target can be an individual, a group or an organization; a real person or a virtual human role; from internal or external. As Figure 11 shows.

Attack Target (Victim)

taxonomy 1 taxonomy 2 taxonomy 3 taxonomy 4

individual group organization internal external real person virtual human role common target special selected target

Figure 11 Taxonomy of social engineering attack target

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 8 of 20

3.1.8 Social Interaction and Attack Medium Social engineering is a type of attack involves social interaction which is defined as the communication between or joint activity involving two or more human roles [1]. It covers the interpersonal interaction in the real world and user interaction in cyberspace. Attack medium is not only the entity so that the social interaction can implement (through which the target is contacted), but also the substance or channel through which attack methods are carried out. In some social engineering attacks, several dierent mediums might be used. E.g. The attacker deceives the target through phone to receive an important document, and then carry out phishing attack in the email.
The taxonomies of social interaction can be various according to dierent criteria. It can be direct (e.g. face to face in the real world) or indirect (e.g. email), realtime (e.g. phone talking) or non-real-time (e.g. email), active or passive (e.g. reverse social engineering). As Figure 12 shows.
The attack mediums include but is not limited to: 1) the real world, 2) attach files, 3) letter, 4) manual, 5) card, 6) picture, 7) video, 8) RFID tag, 9) QR code, 10) phone, 11) email, 12) website, 13) software, 14) Bluetooth, 15) pop-up window, 16) instant messenger, 17) cloud service, 18) Voice over IP (VoIP), 19) portable storage drives, 20) short message service (SMS), 21) mobile communication devices, 22) SNSs.

Social Interaction

taxonomy 1 taxonomy 2 taxonomy 3

direct indirect real-time non-real-time active passive

Figure 12 Taxonomy of social interaction in social engineering

3.1.9 Human Vulnerability Human vulnerability is the human factor exploited by the attacker to conduct a social engineering attack through various kinds of attack methods. This is a distinctive attribute of social engineering compared to classical computer attacks. For social engineering, other types of vulnerability (e.g. software vulnerabilities) can be exploited together with human vulnerability, yet they are non-necessary [1]. A wide range of human factors can be exploited in social engineering, and a skilled social engineer (attacker) can transform common or inconspicuous human factors into security vulnerabilities exploitable in specific attack scenarios.
In general, human vulnerabilities in social engineering fall into four aspects: 1) cognition and knowledge,

2) behavior and habit, 3) emotion and feeling, and 4) psychological vulnerabilities. And the psychological vulnerabilities can be further divided into three levels: 1) human nature, 2) personality trait and 3) individual character from the evolution perspective of human wholeness to individuation [15]. Following is a non-exhaustive list of human vulnerabilities, which contains 43 instances of these six categories.
· Cognition and Knowledge (8 instances): ignorance, inexperience, thinking set and stereotyping, prejudice / bias, conformity, intuitive judgement, low level of need for cognition, heuristics and mental shortcuts.
· Behavior and Habit (4 instances): laziness / sloth, carelessness and thoughtlessness, fixed-action patterns, behavioral habits / habitual behaviors.
· Emotions and Feelings (11 instances): fear / dread, curiosity, anger / wrath, excitement, tension, happiness, sadness, disgust, surprise, guilt, impulsion, fluke mind.
· Human nature (6 instances): self-love, sympathy, helpfulness, greed, gluttony, lust.
· Personality traits (5 dimensions): conscientiousness, extraversion, agreeableness, openness, neuroticism.
· Individual characters (9 instances): credulity / gullibility, friendliness, kindness and charity, courtesy, humility, di dence, apathy / indierent, hubris, envy.
3.1.10 Eect Mechanism Social engineering eect mechanism describes the structural relation that what, why or how specific attack eect (consequence) corresponds to specific human vulnerability, in specific attack situation [15]. Given the attack scenarios and human vulnerabilities, it explains or predicts the attack consequence. E.g. Impression management theory and reciprocity norm explain why new employees (inexperience, helpfulness, etc.) are more vulnerable to give up their username and password to technical support stas pretended by the attacker, who helps to resolve their network failure first and then request an information disclosure with certain excuses. Social engineering eect mechanisms involve lots of principles and theories in multiple disciplines such as sociology, psychology, social psychology, cognitive science, neuroscience and psycholinguistics. Study [15] summarizes six aspects of social engineering eect mechanisms: 1) persuasion, 2) influence, 3) cognition, attitude and behavior, 4) trust and deception, 5) language, thought and decision, 6) emotion and decision-making. Following is a non-exhaustive list of eect mechanisms, which contains 38 instances of these six aspects.

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 9 of 20

· Persuasion (7 instances): similarity & liking & helping in persuasion, distraction in persuasion and manipulation, source credibility and obey to authority, the central route to persuasion, the peripheral route to persuasion, Elaboration Likelihood Model of persuasion, recipient's need for cognition in persuasion.
· Influence (8 instances): group influence and conformity, normative influence (social validation), informational influence (social proof), social exchange theory, reciprocity norm, social responsibility norm, moral duty, self-disclosure and rapport relation building.
· Cognition, Attitude and Behavior (9 instances): impression management theory, cognitive dissonance, commitment and consistency, foot-in-thedoor eect, diusion of responsibility, bystander eect, deindividuation in group, time pressure and thought overloading, scarcity: perceived value and fear arousing.
· Trust and Deception (5 instances): trust and take risk, factor aecting trust, factor aecting deception, integrative model of organizational trust, interpersonal deception theory (IDT).
· Language, Thought and Decision (4 instances): relation between language and thinking, framing effect and cognitive bias, language invoke confusion: induce and manipulation, indirectness of thought and negative conception expression in language.
· Emotion and Decision-making (5 instances): neurophysiological mechanism of emotion & decision, emotion and feelings influence decision making, facial expression & deception leakage, facial action coding, micro expression identify and deception detecting.

Attack Consequence

network intrusion, interception or disruption

intuitive taxonomy

provide unauthorized access to information or systems denial of service
data exfiltration, modification, fabrication or destruction infrastructure sabotage

give up physical access to restricted areas

... confidentiality

breach / harm security goals
taxonomy 2

integrity availability controllability auditability

... carrier

breach / harm cyberspace elements (object)
taxonomy 3

resources subjects operations

...

Figure 13 Taxonomy of social engineering attack consequence

3.1.11 Attack Consequence Attack consequence is something that follows as a result or eect of a social engineering attack. The attacker feed it back to the attack goal to decide whether a further attack is required. The taxonomy of attack consequence is similar with the taxonomy of attack goal, as Figure 13 shows.
Due to the subclass name in prot´eg´e will be converted to node labels in later knowledge graph, considering the intuitive demonstration and data feature, multiple dierent taxonomies can be used to assist knowledge analysis. Figure 14 (left) shows the implementation of concepts defined above. Table 2 shows the related concepts descriptions set as class axioms in prot´eg´e yet not reflected in the Figure 14. [3]
[3]The implementation file was submitted as supplementary material (SEiCS-Ontology+instances.owl) for review.

Figure 14 Overview of concepts and relations defined in Prot´eg´e

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 10 of 20

Table 2 Other descriptions of concepts (class axioms)

No. Concept 1 Attacker 2 Attack Target 3 Attack Goal
4 Attack Medium

Description Equivalent To Equivalent To Equivalent To Equivalent To (Entity of)

Concept Social Engineer Victim Attack Purpose
Social Interaction

3.2 Define relations in the domain ontology
Based on the definitions presented in Section 3.1, we extract 22 kinds of relations among the core concepts. Table 3 shows these relations and their Domain (start), direction and Range (end). Figure 14 (right) shows the implementation of these relations in Prot´eg´e, and Table 4 shows the related concepts descriptions set as object property (relation) axioms yet not reflected in the Figure 14 and Table 3.

Table 3 Define relations among the core concepts

No. Concept (Domain) Relation (!)

Concept (Range)

1 Attack Motivation motivate

Attacker

2 Attacker

motivated by

Attack Motivation

3 Attacker

gather and use Social Engineering

Information

4 Attacker

craft and perform Attack Method

5 Attacker

formulate

Attack Strategy

6 Attack Method

to achieve

Attack Goal

7 Attack Method

guided by

Attack Strategy

8 Attack Method

apply to

Attack Target

9 Attack Method

performed through Attack Medium

10 Attack Method

to exploit

Human Vulnerability

11 Attack Strategy based on

Social Engineering

Information

12 Attack Target

suer

Attack Method

13 Attack Target

have vul

Human Vulnerability

14 Attack Target

interacted through Attack Medium

15 Attack Target

bring out

Attack Consequence

16 Human Vulnerability take eected by Eect Mechanism

17 Eect Mechanism explain

Attack Consequence

18 Attack Consequence feed back to

Attack Goal

19 Attack Goal

to satisfy

Attack Motivation

20 Sub-goal

subgoal of

Goal

21 Attack Method

with skill

Common Skill

22 Attack Method

with trick

Auxiliary Trick

Table 4 Other descriptions of relations (object property axioms)

No. Relation 1 motivate 2 incent 3 drive 4 incented by 5 driven by 6 incent 7 drive 8 apply to
9 conduct 10 exploited by

Description Inverse Of SubProperty Of SubProperty Of SubProperty Of SubProperty Of Inverse Of Inverse Of Inverse Of

Relation motivated by motivate motivate motivated by motivated by incented by driven by suer

optional verbose relations

Equivalent To

craft and perform

Inverse Of

to exploit

3.3 Define other descriptions in the ontology Besides the axioms descriptions for concepts and relations in Table 2 and Table 4, annotations are optional to facilitate the ontology implementation and many comments (a type of annotation) for instances are added in Section 5.1 to help the instances edition and knowledge analysis.
Here three reasoning rules are defined for simple scenario analysis such as unique attacker, victim and attack consequence. Figure 15. The rule 1 is used to add a new relation: if 1) an attacker crafts and performs certain attack method and 2) the attack method is applied to a target, then a relation "attack" will be created from the attacker to the target (victim). The rules 2 and 3 are used to automatically complete the relations that are not designated explicitly in the instance data but have defined in ontology. This is useful to improve knowledge base and convenient for the instances' creation. The built-in reasoner HermiT can be used to implement the reasoning. For complex attack analysis, these rules might need some adjustments and other reasoning tools can also be used.
Figure 15 Rules defined in the ontology
Above is the key material and ontology implementation after the ontology revise and validation. The supplementary material will lead reviewers / independent researcher to reproduce the result.
4 Result: domain ontology of social engineering in cybersecurity
Figure 16 shows the domain ontology of social engineering in cybersecurity developed in Prot´eg´e 3. The core concepts and their relations is marked inside the red polygon, the outside shows the taxonomies (also as the labels) used, and the right area is the legend for relations (the directed color connection in the figure). To be intuitive and integrative, Figure 17 presents the ontology in a more clear and concise way.
Overall, 11 core concepts and 22 kinds of relations among them are formally and explicitly encoded / defined in Prot´eg´e, together with related description, rules and annotations. For this domain ontology, it can be exported with multiple ontology description language and file formats, such as RDF / XML, OWL /

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 11 of 20

Figure 16 The domain ontology of social engineering in cybersecurity developed in Prot´eg´e

Attack Motivation

to satisfy

Attack Goal

feed back to

Attack Consequence

motivated by

to achieve

bring about

explain

Attacker (Social Engineer)

craft and perform

Attack Method

apply to suffer

Attack Target (Victim)

Effect Mechanism

gather and use formulate

guided by

Social Engineering Information

based on

Attack Strategy

performed through

interacted through have

take effected by

Attack Medium (Social Interaction)

to exploit

Human Vulnerability

Figure 17 The domain ontology of social engineering in cybersecurity

XML, Turtle and JSON-LD, to reuse and share the domain knowledge schema.
5 Evaluation: knowledge graph application examples
The best way to evaluate the quality of the ontology developed may be problem-solving methods or using it in applications which reflect the design goal [2]. Corresponding to the purpose of the ontology development

presented in Section 2, this section evaluates the domain ontology by its knowledge graph application for analyzing social engineering attack scenarios or incidents. First, the ontology serve as a machine processable knowledge schema is used to create the instances, generate the knowledge base and build a knowledge graph. Then, 7 knowledge graph application examples are presented for social engineering attack analysis.

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 12 of 20

Table 5 Material of social engineering attack scenarios / incidents adopted from [1, 15] and used to generate knowledge base

No. Social Engineering Attack Scenarios / Incidents Description

Human Vulnerabilities

Effect Mechanisms

Pretexting. The attacker attempts to elicit classified or sensitive information from victims (e.g. tele-

phone company operators, motivated by using telephone service without payment) by pretexting via

telephone. (1) The attacker makes a prior survey to know better the lingo, organization and victims, Credulity or gullibility, sad- Social responsibility norm and moral

1

and pretexts to be an inner staff (e.g. who is in a trouble) or technical support to elicit information. ness, sympathy, the desire to (2) The attacker requests classified information by pretending to be a cable splicer and pretexting that be helpful, agreeableness,

duty, (similarity liking and helping), emotions and feelings influence deci-

he is wiring two hundred pair terminals for police. Who would want to refuse a little help to a com- kindness and charity, inexpe- sion-making, ELM, IDT, factors af-

pany man coping with that heavy-duty assignment? She feels sorry for him, she's had bad days on the rience.

fecting trust.

job herself, and she'll bend the rules a little to help out a fellow employee with a problem.

Shoulder surfing. The internal attacker (for security test) pretends to be a maintenance worker to Carelessness and

Distraction in persuasion and

2

(get access to the target workplace and) contact with the victims. When the victim is not paying attention, the attacker collects information such as username and password by surfing over the vic-

thoughtlessness, credulity, gullibility, friendliness,

manipulation, IDT, factor affecting deception and trust, peripheral route

tim's shoulder, snooping prominent places such as sticky notes, papers or computers.

ignorance.

to persuasion.

3

Vishing and Pretexting. The attacker (e.g. motivated by financial gain) pretends to be a new employee and convince the targets that he will suffer greatly if the request is not granted. E.g. request the technical support (e.g. Paul) to reset the password of certain account to deal with an urgent task,

Guilt, sympathy, the desire to be helpful, friendliness,

and further ask a VPN to access from outside.

credulity.

Foot-in-the-door, impression management theory, two routes to persuasion, IDT, cognitive dissonance, ELM, emotions and feelings influence decision-making.

4

Vishing and Pretexting. The attacker (e.g. motivated by financial gain, intellectual challenge) calls a staff of the technical support department to say that the CEO authorized his requesting an urgent VPN channel for a project presentation in another city, and further tells he / she that other staffs did

Fear and dread, conformity, neuroticism, the desire to be

this before, such as Paul.

helpful, credulity.

Source credibility and obey to authority, diffusion of responsibility, bystander effect, deindividuation in group.

5

Manipulating conversation. The attackers (e.g. motivated by fun or pleasure) induce the group conversation to a security topic, one of the attackers discloses his password to discuss whether it is strong enough. If most of the other participants (or attackers) also start disclosing password, the targets are likely to be manipulated to disclose password or other sensitive information.

Conformity, agreeableness, extraversion, credulity, courtesy and humility, diffidence.

Group influence and conformity, social validation, IDT, reciprocity norm, selfdisclosure and rapport relation building, social exchange theory, cognitive dissonance.

Piggybacking. An authorized person provides access to an unauthorized person by keeping the secured door open for providing help or other reasons. Most employees do not know every colleague 6 at a (large) organization and will hold a door open for politeness, let alone the attacker is nicely dressed, shoes shined, hair perfect, with polite manner and a smile; victims will less likely to suspect. (e.g. motivated by espionage)

Courtesy, humility, credulity, openness to experience, the desire to be helpful, friendliness, intuitive judgement.

Peripheral route to persuasion, (similarity liking & helping), distraction in persuasion and manipulation, IDT, factors affecting trust, facial expression and deception leakage.

Trailing and Impersonating. The attacker (e.g. for security test, personal interest) pretends to be an Helpfulness, think set and

employee of target organization through suitable disguises such as uniform and printed badge, gain- stereotyping, heuristics think- ELM, peripheral route to persua-

7

ing access to an establishment by following employees who have security card (under the cover of lunch rush at a large corporation). The security guard and employee see in the eye, but he has accus-

ing and mental shortcuts, intu- sion, distraction in persuasion and itive judgement, apathy, indif- manipulation, level of need for

tomed to it. In some organizations, the lazy security guards put the access card on the desk for those ferent, Ignorance, lazy and cognition.

who forget bringing the access card to pick it up for themselves.

sloth.

Baiting. The attacker (e.g. motivated by competitive advantage) leaves a USB stick containing mali- Curiosity, excitement, greed, (similarity liking and helping), ELM,

8 cious codes in a location where it is likely to be found by the victims. The outside of the USB stick is conscientiousness, sympathy two routes to persuasion, IDT, emothe logo of the target organization or attractive icons to lure the victims to pick up and insert into or the desire to be helpful, tions and feelings influence decision-

computer. Once inserted, the malicious code may execute automatically.

inexperience.

making.

Reverse SE. The attacker (e.g. motivated by espionage) sends an email using faked address (technical support department) to a new employee informing he / she that "a network test will be conduct recently, and

Reciprocity norm, impression management theory, commitment and

if there is a network failure, please contact xxx". The attacker makes a network fault and waits for the new Inexperience, intuitive

consistency, framing effect and cogni-

9

employee's request. After helping to resolve the problem, the attacker says sincerely "Would you like to do us a favor, just one minute, that completing a survey used for developing a security awareness training pro-

judgement, agreeableness, ignorance, credulity, con-

tive bias, language invoke confusion induce and manipulation, group influ-

gram for new employees; nearly 80% of the employees have already done this." "Ok, my pleasure." "Are formity, the desire to be help- ence and conformity, diffusion of re-

you aware of our email policies? ... It can be dangerous to open unsolicited attachment ... We need to know ful.

sponsibility, factors affecting trust and

your password to evaluate the security awareness of new employees. It is a secure matter" "Okay, it is ..."

deception, IDT.

10

Phishing. The attacker (e.g. motivated by financial gain) sends phishing emails with faked address to Excitement, happiness, greed, inform targets that there is a very low discount coupons of food (or sport event ticket) in a limited gluttony, surprise, time. The email contains tempting food pictures (or passionate sports posters). This lure the targets to extraversion, impulsion, fear, click on malicious links (with encoded URL address: att.eg.net), divulge privacy information, etc. intuitive judgement.

IDT, peripheral route to persuasion, distraction in persuasion and manipulation, emotions and feelings influence decision-making, scarcity: perceived value and fear arousing.

Spear Phishing. The (fired) attacker (e.g. motivated by revenge, financial gain, prank) finds there is

Deindividuation, emotions and feel-

11

some resentment between employees of the target organization through text, images or videos in SNSs, and sends SNSs message or email embedded with malicious code to selected targets, claiming it was a hoax virus that could be forwarded anonymously to someone they didn't like. This may com-

Disgust, prejudice, anger or wrath, hubris, envy.

ings influence decision-making, neurophysiological mechanism of emotion & decision, micro expression

promise a large group of individuals in the organization.

identifying.

Smishing. The attacker (e.g. motivated by financial gain, competitive advantage) blocks the target CEO's cell phone signal and sends SMS message to his secretary by faking the CEO's phone num12 ber: "I'm in a meeting at another city and couldn't talk on the phone. Encrypt the organization structure table and a contract file to a zip with key *** and send it to xxx@xxx.xxx immediately! Other-

Fear and dread, tension, neuroticism, self-love, credulity.

Source credibility and obey to authority, time pressure and thought overloading, emotions and feelings influence decision-making (fear-arousing

wise, we will lose an important business."

in persuasion), IDT.

Trojan attack, honey trap. The attacker (e.g. motivated by financial gain) puts software in website 13 and implies it is free for downloading and watching porn images or videos. Text marked that "you
won't see the seductive images If you don't act." Once the targets opened the link or installed the software, the attacker's computer or mobile device is compromised.

Lust, greed, excitement, curiosity, impulsion, intuitive judgement.

IDT, emotions and feelings influence decision-making, peripheral route to persuasion, distraction in persuasion and manipulation, indirectness of thinking and negative expression in language.

Water-holing. The attacker (e.g. motivated by financial gain) finds that the targets usually, regu-

14

larly, will or are likely waiting for the targets'

to visit certain websites, and then infects these websites with malicious code trigger. The targets will be compromised e.g. when visit the websites, down-

load software (malware) or click (malicious) links.

Fixed-action patterns, behavioral habits of site-visiting, think set and stereotyping.

IDT, factors affecting trust and deception, social and organizational trust theory.

Whaling attack. A spear phishing attack directed specifically at high-value targets such as senior

15 eajmcoxsobaenetcfimreouernasteipivnlaosercneseas,niiiCnbdnciEwlyoiOotreypubo,orsririsnatCcettehesFrdeOnad.ra.uAelTlnpehhdhingeoethnhaelteeydtasnacctuyuktmaosecturobk(metoeirs.isgzr,uee.osgdmruigsaaotanletlnidyrvizaapcanteoetdrnidsotcoenbonxaynatl-flflaiiiozrnwmgeaadonrt,sceh,ii,enaeelmrw.eggagha.iiiil"scn.fth.)ro.acottthhrtiaeeoefrnttxaatxurnhgxsdeienbwtog'usthhstniahenalreiemnrsaegestlt,emabjvcaoeahibetnestttdiisnitusnlgeocf/,ofhtr--Hccstuaeertruese,lroeiisstntystinpucesiintsiagsvn,,edtchjrumienddekgunieltnmiagtlyess.nhetto, ortr-

ELM, the central route to persuasion, the peripheral route to persuasion, time pressure and thought overloading, factors affecting deception and trust, integrative model of organizational trust.

ware (trojan horse or back door with encoded domain address: att.eg.net)".

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 13 of 20

Figure 18 The overview of the knowledge base generated in Prot´eg´e

5.1 Create instances, knowledge base and knowledge graph
An ontology together with a set of instances organized by the knowledge schema defined by the ontology constitutes a knowledge base, which further serve as the data source of a knowledge graph. For this paper, a dataset of social engineering attack scenarios that contains the necessary instance classes such as attacker, victim / target, human vulnerability, social interaction (medium) and attack goal is in demand. Yet there is not such a public dataset available now. Thus, the attack incidents and typical attack scenarios described in work [1] and [15] are adopted and expanded as material to create instances for each concept defined in the ontology and build the knowledge base. Overall, 15 attack scenarios (Table 5) in 14 social engineering attack types are used to generate a relatively medium-small size knowledge base.
The instances and their interrelations described in every attack scenario are dissected and edited in Prot´eg´e also, since it is convenient to check the data consistency and revise errors according to the ontology. In this process, we add many comments (for instances of attacker, attack method and victim) to assist the instances creation and knowledge analysis. Figure 18 shows the overview of the knowledge base in Prot´eg´e. A total of 224 instances are created in the knowledge base. [4]
[4]The implementation file was submitted as supplementary material (SEiCS-Ontology+instances-inferred.owl) for review.

Due to the limited functionality of Prot´eg´e for data analysis and visualization, we select Neo4j (community3.5.19) [16] as the tool to display the knowledge graph and analyze social engineering attacks. Neo4j is easier and faster to represent, retrieve and navigate connected data. And the Neo4j CQL (cypher query language) commands are declarative pattern-matching, which is in human-readable format and easy to learn.
There are mainly two steps to migrate data from Prot´eg´e to Neo4j. First, export the ontology and instances in Prot´eg´e to RDF/XML or OWL/XML file, with the reasoner enabled to infer and complete the knowledge according to the axioms and rules defined. Then, import the RDF/XML 4 file into Neo4j by the plugin neosemantics (version 3.5.0.4). The detailed scripts and commands used to build the knowledge graph is submitted as supplementary material.
According to the statistic in Neo4j, 1785 triples were imported and parsed, and 344 resource nodes and 939 relations were created in the whole knowledge graph. Figure 19 shows the knowledge graph consist of all instances nodes and their interrelations. The legend for node color is in the left bottom.
In the knowledge graph, the relations craft and perform, apply to, to exploit, have vul, bring about among nodes attacker, attack method, victim, human vulnerability, attack consequence are colored with red, to abstract and denote an attack occurrence (Figure 19), for the convenience of attack analysis.

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 14 of 20

habit_in...

persona...

red color edges: craft_and_perform to_exploit apply_to hav_vul bring_about

interper... prank

gather_and_use

job_resp... job_title...

motivate motivated_by

gather_and_use

posts_in... informa...

IT_infras...

persiste...

organiz... targete...

location...

block_m... to_achieve

taketantk_taeoe_fkn_ee...xefnpfl_teoaeictftkft_eaebnkyc_tetean_f_ektfbetxaefeyfakpcnlekittee_cta_enaxntitetan__kbpnfe_etlakybefrfeyafakafeneifeck_ecntecneebt_tcenfr_t_enfi_ped_x_bfb_eteenbftpryecfylafytghtfearkio__ocer...on_eatbceue_ymtnbxxge__boppheldbelybur_fxaioyttifinphtntelrgaca_oietkau_xnehbgepbnaotlhx_yuvoateip_elftnf_eaaixevkecneputltxltnth_a_oapaiaelktbkktftvfayoeeeaie_ennkncne___te_x_eevnffeb_pfflufyelefefofcicefttett_ecc_tttobeb_a__ydykbe_ebyxetnbypax_latkeopcfiealftknkea__icteten_ofntfb_aeyeckftfe_hfeenabxe_cvyepeteelxf_d_hatfi_pvbawlenoibuyvaclt_iatehca_n_te_ktcbvsx_ooyhtfuk_i_plieollefeeeltaexxdvief_oppelndb_lei_oaeeiontcbitxttkdatsao_e_cpot_lr_eupkbof_xaeeoeeetpfiaxcptxlxxltxtotcepoaylppaire...kpl_l_lo_knaidetitota_exipihnotftottenpnraehlaa_fbreevrokekoiixsorfdeetefnp_uu_lmnetgnbvgae_..._ic_aadhaeutancl_ekf_ttpbffkefahb_eort...knyecuoeao_ttctuan_tett_gf_tbaehffaycbtfecckeyrokccat_tf__te_abxbtatycatynprkladtea_ocfwtnoiphitk_t_eatta_erffekohvafox__eerenctcerpa_ntrtmldtaix__vtof_octba_peuit_lpcyflketaofkeox_nitreatpfdoalc_c_totpotpehrii_exeatterrpcbflofmvhsk_yocoeaoirruetrvfaaxmeffpt_pmle_vrepoaifulltdney_ed_ttt_tdht_opoor_beo_ra_oetfbecsxruooxtkiarp__tol...pnit_tlamsooegfiocoxt_tiy_hptaloiaf_obceihetavohaecihevcudhertae_itav_vfbeotvee_a_vttu_ecalefoxovnke___dpuilt_lehseonopaxsiadttett_vrupioefl_ebbsroe_frtoagaixvycomtocpplukt_alle_osei_rttaftdtootfa_iooottrs_t_fhshaamyraacctevkoihedisuf__egttyvctvorhhueol_rac_feortexaau_tfxpttalcg_pralnohaicacotdnrfki_tadtf__ptpap_eeearnrrfnffdodoo_r_rrppmmmeeerrffdo_ogrra...tamthmtearc_kacnrdga_fautats_tghteaaeatrnc_hkdae_rngp_dae_atrgfuhnasoedtrer_h_umaesrne_da_nusde_usgeather_gaantdh_e...r_andg_autshgeeart_haerng_dgaat_anthudseh_reeu_rsa_enadn_du_suese

formulate gathegra_tahnerd_a_nuds_euse

AAEAAAAAtftttttttfttttattaaaeaaacccccccckkkktkkk______e_MMTMSMrG(atee1ororectag5tdahhite)liveoa(utgadn2(mty1(i0is3(5o()m731)n))2((31) 30)) software

have...

to_achieve interactepde_rtfhorromuegd_hthrough have_vul

have_vul have_vul

ttoa_keexnpt_oleo_feiftxepclot_itbtoy_exploithave_vul to_exploit

interacted_through

apply_to suffer

have_vuhl ave_vul interactberdin_...g_abohuatve_vul

hatvaekta_epkvneeur_nfelo_tfaerfmfktetfafeecaeketcndtekate_i__n_nebketbd_htyfneeyt_reffaoen_fbrkeucea_acetgtfect_acnh_ftbtfbaekk_eefyykece_xetdefapttncf_no_klfett_aebe__hcteieennabtyrfdf__okffy_beeeebuefxyccfapgntetc_lh_c_akbiteb_ny_ttfybaoefykxepeclanti_n_beeyftfxaoepp_clepatx_ilnpbyel_yoxttitoaptakeltkaaxeekpinnneltan__ahe_i...nkefaefffenvet_cac...ettk_f_ebfbehneyyc_axtep_vfblfeayeti_acnvtk_ueblny _eeffxepclta_inby

to_exploihtavteo__vualchieve
bring_about have_vul

to_achieve

to_satisfy to_satisfy

explain explain explain

to_achieve

taken_effect_by explain
bring_abo...

explainexplain explain
explain

etexaxepkpexleaxlpanpilinlan_aieinneftexfaxpetkplacaekltianen_inb_n_eyefefffxeeepccxttltap_a_bklibaeyninyn_eexfpfelcati_nby

ha...

have_vul takenin_teerfafcetcedt__tbhyrough
have_vul
suffberring_about

performedt_ot_...exploit have_vul

have_vul

to_exploit

to_exploit have_vul

to_achieve

to_explotito_achieve

explain

explain taken_effect_by
explain explain

performedi_nthteroraucgthed_through

gatmheort_iavanmtdem_odout_tisbivveaaytteed_bymmoottiivvaatmteeodt_ibvyate formulate

to_exploitto_exploittoh_aevxep_vloulithave_vul

to_exploit

peirnftoerrmatncreteudeu_sdttr_h_otrhaoprnuohpg...u...hrgehjudSNtiackS...esentxre_poxelpafjlivfanatetiaidnalncckukctit_ee_tsirsinannbomagt__...yedef_uteftx1aifif_snperkf3cceteelsat...cbon_rctivtbn_iate_...hssyieb...lichpkfa...myfhtf_eapraaicemavpvepctepna_iu_intio1ebvaodndrlutvwy1_f...lsohl_eo...e_yiv...a_rxfree......mep...ivesbcxuxlebeovtp...b_dsriefivtg_eliicmaointutgnoxhxueignlattrtelgc1oor_hsluahge_dciiua_t4ekaoxotuteorgecbvpew_fe...taxrh_ealbsoarnthoapafe_mpfai_aitfvu_ltrantxctppon_vk_uroaeittvpsyaa...ile...leastkiftyeuynel...tnastnfreod_mafa_erfkidfn_t_kikovvte-ocpteee_e_eu_rirthiexefnnstptnmnc_mfprmltatfa_tfeu..._bef_laetoagotgkkaeeeoceftatryirkriketefacantam_mfdfrtf...keapeml_etfonnfiktekc...ceo_v_keeabnent__irrtbenoakt1oe_ecncynemew_h_iobetyt_ntmtnttse_f0dfeeaem_nryeitp__efef_v_i_ao...efbUxkd_ftfebnea...repfefaaktffehlpfyeaic_eticc...eyekffeteefveSnetbtlncfftfeehicctatcnmctasae_rer_eavsantBytttts_tiaotf_cbiekbkep_coa_he_c_khneoe_etcteeb_betytdby_aetk_vbtffieanfr_it...b_yvsyfnevffn_eeycmanb_yeeaebylaedttheh__nkctcolyhc_geieykfe_te_eratta_fvc_tdtr_faemft_ndtebevvhu_ofb_fakckre_ypbbfeeelr_ltuyetkte...o...e_cayp...to__coyeg...bfhtpunpvvtfzn___yehe_gairuu_tbeehin_riobacrhennlectlxyxaottkiaiyuefeertf_ptnvpegeppefaftaxbvrageameentlxlkptaefttosya...hoi_htc_eoccpbltchurdca_vesinteipttftero_kltaik_tuf_..._ieinoi...xaeeefnbenntrelbetdprrfgxyci...d...fcfinmy_krveo_lpfot_ktaea...ec_arehihepletbibmnxneool_narcetd...aopyboiervt...grwpttuyl_bufdd...oaetvwowvttoee...aeig__thonoeeix_oirxtiivrkthccpnmhtrc_xhsprusireholewrtrn_daptktnlalo_xn_siuiaiaivtenlpmku...ds...iemht_eagiefseilikgn_a...eolxixctiilh...sxtnihpip1vnftkl_7lttrwpafl...lielalime5iasaktl_wl...mixiaefacneiet...c...ekpnxhtnirh...enerpt...l8e__bansatidalseseea..._e_cir_ct...t_fnk...lxiixhfeoxt...buinnaibeeippppnaxl_htaiegcxlr...elnatoplalaceectaipgaacoxa_thu_eckl_iiexxpvekaliaintb_tipteaeh_arnnprapletnfrsbitayixmtaedvixnoikiayalnaoac_npleiaotts...gepeanktrrvtotial_taveiignmatueai_...osiialunl_khdt...nsenoi_ivntihatnetc_isl_cefeuntiuth_klyatxytsftlinatlhe...eavifpeoalaetmagm_ennrfke_mackletotcfrc...or_et_see_eeiko_fuoteaxvhpksionifc_ent...adltfegumeltafpkfa_bftautgtecatieenhel_eytenk_...eivoayelxtevovacfecbxeaaerrdn_nafr_tkteaxtntteckpyfti...ie_e...atrt__tein_n_rctfpta_ibeevoxeelofeeeueebtthntava...mxcypka_lfhc_ndfo_fieapcpsbyafeua_lieltekvfvaepanoe__exeloetyiee_tecvxaldcnntvbe_pciee...xsdofptittctrhseienebh__flfmpiyha_jtt..._rolravab_esffe_x_otaaib_ylbto...i...eovteyavevacop...pntfbiiovkaecyry_tsuceafvtuittdmallxynkeeie_iftek_abeitpllhcpedgyveob_vncvuiehixtlnatantibs_ni_utayilpe_inafgagmgeea_tvaetecic_ryleltkknv_xetaaab...xeaeemytee...einetpelfiedkptdon...pfyo_fniittlbfhasfnioeoe_lo_nmavf_taehnttrbbseei..._nkectbeatuofaaticerdaeaineoecefyrttt_xvkrxtl6_g...afcc_vi_ntferaet_iseppuagee...kn_fanmbaabe_t_bnkeclfetsn_bgclxaaeohnrfckgtttoe_...yxeytuuiitecei_...p_fyachtkonnaev_dpatre_...fibetlhxcgtekolvtreakenesubafate_l_oyfataa_ceoe8epetbixfr__iutbl_rakntketriiemen_n_arpeetrnipnbbt_yshioeetn7v_xcami_kbttefo...x_elaygnopneuatfugneaorrryuepeve_eflu_flentaidtnta__dfed_stbiofcxlecw_o...ethxlaie_odf_ofonlrpeyat_hfcikvnpe_ixpbetm_aaf_whitf_utautleppeo_tccbhbe_ftavl...fougeegvrl...selfxgoaiobctp__uauiyeete...ruarhsetadp_tn_ssyiaieph_o__cnbnee...atkebtsar_tlts...vxb_hveotxhithheivuicyilv_bnhshppywutlaerio...eexevlbtkrlrffsvyiegltrloeiorp_ioordyoieeii..._ate_yxgil...v_ncfrlu_ht...uwaarluikoepaadnaeuwvfmsotmgtn_natrxeiuilainll...nhsim...haottuitdldpuldnmntteaokhdtecbpit_lh_unkrle_irdtaa__mveu_ecrluit_elma_elsiasii2kotun_astninnis...npt-atkfoo_...etctneas_ree_feghstthwi_a...edneirteetilxl...coai_fslirit_bope..._ittcftvoskcmaofoumeahcel-irmythoal...bvsc__...kuitn_fop...iineotsmtefoteoebito_gm9keeogxdhttabuvf_nuitytfohcdalip_f_euoy_aleivg_botreeprtttvuktahl_...v_exa_oxooilrtiahbe...bprusverpenbmcplftae_vi_taeftntaeal...oye_eyonosliee...uibsitvovt_lxueacitpicletdumdyesepaiehittcttatmsdftttllfti__l...abtiyliaosnoeoueefasobnvb_vahimmkerfxn_ipebf_gua_...epydeyisntapgcf...et_rntfapnuyalel...fooopvnv5tmirxheas...htcg_es...utl_fr_re...oio_pleyhaafc_nimlsb...elybot_beef_p__tvavlheaaia...afui_doaeytvrtexrueeeyctaetxktsxkbihuiooivgic_uop_vxnlp_utfsopalteihtsae...theoavbm_eovf_pefaag_laltln_lttyfthtuana___gov...uaatobeeaeiuokl_t_velrataoolnvaeaiag_remyihlviatx_e_cu_tpxten...atstefiveot_rintpbeeepaklnerrnh...hftutivtoe__asechaf_xvlxo_tol...e_a_terooehdfuofpchv_phepotepva_tvekuarce_xfiit..._ivaaholt_uirealpets_uee...ptfvptltrtcteoekrmavauooabfv_ebopxnlltrrahhel...etel_covnpivxectytelog_ler_iypt_ot_rtyt_dutaectaiodp...ttetia6ato_oeeoi_v_bsle_r_tlrtvoanvnko__eitxt_vluntivd_sdn_e_pox2mueyhovkumpseo_iugluibae...xe_tdttpe_as_cetieelosnloxtiyxl_ttexobvrott_therolxent_ip_poea_popauuistuiymarepietx...d_cm_biilnolfllinmstevxoothneoetrlyf_otueedooopraafxobciitvafiidtadg_...ttetlupft1i...iiy_tu...voe_ittvephe...ilttcuvtsgeti_oaveuhcd_taceat_tertami...rrctce...kt_fepaafoosvi_htoeokobriemkueetuubtarntntsrnevdygm_irotvlmyviaenmf_hgf3eenacae_ioe_otl_ufo_cdtet...cer_fefr_vvoftrewl_f...mxusrfita...uak_iesatvifrtophimmedfetalecctpanateetexrthv_clt_k...otec_edppoo__rsta_e...diiutl...b_at_lsta5ninosmomsn_eygbtitkoybiutdvt_h...h..._t...yiryioetal_ft_s4wl_ifpfaottpfgnfeie..._yeievccptvrrdcrg...ehartkfeti_artoat__t_cbeeeebftsrk_s...gttmiykeyfrelta_nihoaei...eattmnnlt...rotlvoonemp_nh_dtiardegg1or_ueshcda......f_t_lahgrh2acfsaospi-i_...tpeetnhtchee...iaemt...vpee...thcnaeeeentlritdve...erffg__dip...ao_tv-estbrcac_eaeto_olr_hsnthyuh...ormt...evt_f_oarstieadtouvnoepgveaac_nprsltedetumhgucehewch_t_a_rgibovkrftekteo...ootouhhg__vderetunlermoeir_agro...r...atpkee9hc3hudlt__ierg_knooot...hwhartef_uertnsstooirgpirtuatnue4_ahhegatattcaui_hrocestcftsh_erfrporspkwiwyaidioeaer...cectriv_miVrkittttgetsofrhhiehfooea1cy__gdsrdrttg...smiouhm_rcrk_auibteeotceihtegglhkrhtlsmr_d_hoireov...aoo_arauantu_lm...th_gadkgemocrnoh_dheofordust_u_eiut_bsviwvbaugeagayagslhi_attttieogeet...nehhaadgt_t_egl_oam_htbraorteg_o_yohifar...cato_menikatvrdgbnha__odctaeetue_rnrabsutie_sodens_iiaue...a_lartnbeugte_dSgsperleao_Mle_...ueantu...lsoc_Siae...zot__vf......bmotrioeed_...aa_c...ph...iemveasnunbipgeuootwalr...lg_ooanrf kna...aimzp...ep-ldic...naettiwo...__pemro...vi...

have_vul

interacted_...

gather_and_use

taken_effect_by explain

taken_effect... taken_ef...
have_vul

ttoa_keexnpl_oeitfttfoae_ktceatex_knpbe_lyoenift_fheeafcvftee_c_bvtyu_bl y

to_acihnietveeracted_through have_vul

have_vul

to_satisfy to_satisfy

gatghaert_haenrd__aunsde _use

gather_and_use

taken_effect_by

to_exploit have_vul

to_exploittaken_effteoc_te_xbpyltoo_ietxploit

motivated_by motivate

to_satisfy to_satisfy

formulate

formulate

to_achieve

suffer apply_to performed_through

craft_and_perform tatot_haeccarxkvapfleto__ciratvanfutdl__apnhcedrra_favpoferter_f_moavtrnuomld__epxepcrlrfoaoifrtt_matno_dt_eoxp_pelarfcoiohtirceramvtatfeta_caknd_performcraft_angaudti_tdaepcde_krbfyorm
formulate gather_angda_tusheer_and_use

motivated_by motivate

formulate

to_pseatrifsofyrmed_through suffearpply_to

gathgeur_idanedd__ubsey

to_achieve

formulate

performed_t...

to_achieve

fcorramftu_laatned_pearftotarmcktfoo_rmacuhlaieteve

have_vul

gather_and_use

craft_and_perform

to_exploit

gather_and_guagsteafhoterhmre_uarl_naatden_...use

gather_and_use

craft_and_perform

subgoal_of

to_achieve

Attack_Consequence(14)

languag...

self-disc...

informa... reciproc...

foot-in-...

convinc...

subgoal_of

trigger_t...

Human_Vulnerability(43)

social_e...

sadness

Social_Engineering_Information(22)

Figure 19 The knowledge graph generated in Neo4j

5.2 7 knowledge graph application examples By virtue of the domain ontology and knowledge graph, there are at least 7 application examples (in 6 patterns) available to analyze social engineering attack scenarios or incidents. [5]
5.2.1 Analyze single social engineering attack scenario or incident
The components of a specific social engineering attack scenario can be dissected into 11 classes of nodes with dierent color. These nodes are interconnected and constitute an intuitive and vivid knowledge graph. By this way, the security researchers can get an insight of an attack quickly from the whole to the part.
[5]All the CQL scripts for these application were submitted as supplementary material for review.

A case in point is the knowledge graph of attack scenario 9 (a reverse social engineering attack) as Figure 20 shows. The left part (of area 2) depicts the contents surrounding the attacker: the attacker9 motivated by espionage to gather and use information about organization structure, new employee and email address; formulate reverse and progressive strategy; craft and perform (red arrow) multiple attack methods to elicit password or other sensitive information, or get access or help to breach cybersecurity. Goal and subgoals in area 1 form an attack tree structure, which enables to describe the multi-step attacks in progressive strategy or other complex attack scenarios. The middle part (area 2) depicts the attack mediums through which the attack methods are performed, and also the

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 15 of 20

self-disc...

commit...

informa...

normati...

taken_effect_by

taken_effect_by taken_effect_by
taken_effect_...

taken_effect_by

manipul...

similarit...

source_...

cognitiv...

taken_effect_bytatkakeenn__eeffffeecctt__byby

motivated_... to_satisfy to_achieve
to_achieve

taken_effect_by

persuasi...

with_skill

to_obtai... to_satisfy

feed_back_to

agreeab...takent_aefkfee...n_effect_bytatk...en_efrfeecct_ibpy roc...

distracti...

email_in...

induce

espiona...

disclose...

with_skill

new_em... organiz...
reverse_... progres...

gatherg_aathnedr__aunsde_use gather_and_use
formulate formulate

performed_t...

attactokw_eaitctrhoh9i_e_svkgcecirlcrelaarfafttt_f__...aai...nndd__pppeerrrffeo......texrmetiv...aekresp_eear_f_...o...rmpede_rtfhorromug...ahpepmalaayptpap_epptipollllyyley__t_ptootohoin...teirnatecrtaectde_d..._t...victim9_...

bring_about

bring_about

interacted_through

craft_and_perform

subgoal_of

feed_back_to

subgoal_of to_achieve performed_thro...

performed_thro...

get_a_re...

to_achieve

phishin...

network

disclose...

subgoal_of

trigger_t...

to_provi...

have_vul

have_vul

have_vul

taken_eff...

taken_ef...

conform... taken_effect_by

takenta_ekfefenc_te_bffyect_by

helpfuln... takeinn_teefgtfaerkcaet_tnbi_...yeffect_by

foot-in-... social_e...

hgarvoe_uvpul_i... have_vul

taken_... inexperi...

tatakekne_ne_ffeefcfte_bcyt_by

impressi...

taken_effect_by

taken_effect_by

takent_aekffeenct__ebyffectt_abtkayeknen__...teafkfeecnt__beyffect_by

have_vulhave_vul

credulit... taken_effect_by

social_re...

taken_effect_by

intuiigtinvoer...ant...akteank_eentft_faaeekkf...fee...nn__eeffffefaeccttc_attbk_oybernys__ef......takeinn_teeffercpt_ebry...

scarcity_...

taken_effect_by

taken_effect_...

takeren_ceifpfeicet_nb...y

deindivi...

peripher...

decepti...

area 2

diffusio...

taken_effect_by taken_effect_by

subgoal_of to_achieve
to_achieve

tatkaekne_enff_eecftf_ebcyt_by

with_skill subgoal_of

area 1

create_a...

convinc...

framing... indirect...

languag... facial_ex...

Figure 20 Analyze single social engineering attack scenario (e.g. scenario 9) by knowledge graph

interaction form with targets (victims). The right part depicts the nodes related to victim: the victim9 brings about certain attack consequences, due to he / she has vulnerabilities such as conformity, inexperience and helpfulness, which (are exploited by attack methods and) are taken eect by mechanisms displayed in the right edge nodes. Some relations (suer, to exploit, explain) are not displayed here to get a clear view, which can be returned by adding CQL expressions, clicking the node (expand / collapse relations) or using the setting "connect result nodes".
5.2.2 Analyze the most exploited human vulnerabilities
As one of the confrontational focuses between social engineering attack and defense, human vulnerability is what attackers want to exploit and what defenders / victims want to eliminate or mitigate. Knowing the frequently exploited human vulnerabilities is of great significance for social engineering defense. The exploited frequency for each human vulnerability in the knowledge base can be counted and ranked by CQL expressions (MATCH, COUNT, ORDER). Figure 21 extracts the top 3 human vulnerabilities most exploited by various kinds of attack methods: credulity, helpfulness and conformity. This suggests that these human vulnerabilities should be watched out in security-

related issues and paid more attention in defense measures such as security awareness training.

pretend...

to_exploit

baiting

to_exploit
8

pretend...

to_exploit

helpfuln...

to_exploit to_exploit

to_exploit

piggyba...

pretexti...

to_exploit

to_exp...

to_exploitto_exploit

to_exploit

vishing_...

vishing_...

to_exploit

to_exploit

pretexti...

to_exploit

credulit...

to_exploit

12

to_exploit

to_exploit

to_exploit

phishin... to_ex...
conform...

smishing

to_exploit to_exploit

manipul...

to_exploit

pretend...

to_exploit to_exploit

shoulde...

to_exploit

spear_p...

whaling

to_exploit

6

inducing

Figure 21 Find the most exploited (top 3) human vulnerabilities

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 16 of 20

5.2.3 Analyze the most used attack mediums and interaction forms
Similar to the analysis pattern in Section 5.2.2, the statistic analysis of attack mediums and interaction forms can be executed to get an understanding of where the social engineering attacks are frequently occurred. Figure 22 presents the top 3 mediums most used to perform social engineering attack in the knowledge base: email, website and telephone. This reflects that many social engineering attacks are performed through network and electronic communication, meanwhile reminds us to beware social engineering threat when using these communication mediums.

pretexti...

phishin...
reverse_... performe...

perfor...

performed_thr...

performed_th...

email

5

pretexti... performed_th...

telepho...

perform...

phishing

perform...

performed_thr...

performed_thr...

4

pretend...

perfor...

spear_p... perfor...

websites performed_through whaling

perfo...

5

water-h...

perfor...

trojan_a...

Figure 22 Find the most used (top 3) attack mediums and social interaction

5.2.4 Find additional (potential) threats for victims (targets)
For specific victim (target), knowledge graph can be used to find additional (potential) threats beyond the given scenario. The following analysis pattern can be extracted from the domain ontology and attack scenario analysis:
1. if (v1)  (hv) in S1 and (a2)  (am2)  (hv)  (v2) in S2
2. then (a2)  (am2)  (hv)  (v1) is feasible
Namely: the attacker a2 can also employ the attack methods am2 to attack victim v1 (i.e. exploited the victim v1's vulnerabilities hv ), if a victim v1 has certain human vulnerabilities hv and exploited in scenario S1 meanwhile the hv are found also exploited in another scenario S2 by attacker a2 through attack method am2.
Figure 23 shows this application where victim7 serves as an example. It depicts that the victim7 has five human vulnerabilities and exploited by attacker7

attacker6

cra...

attacker... whaling

attacker...

craft...

craft...

to_exploit

to_exploit

piggyba...

to_exploit

heuristic...

apathy_...

thinking...

to_exploit

water-h...

have_vul to_exploit

to_exploit have_vul

to_exploit have_vul

a... victim7_... s... trailing_...

atta... to_exploit

to_e... have_vul

craft_and_performhave_vul

attacker7

laziness...

ignoran...

to_exploit

to_exploit

attacker9 craft_an... phishin...

shoulde... craft_and_... attacker2

Figure 23 For specific victim, find additional threats beyond the given scenario

in scenario7; besides, three of these vulnerabilities can be also exploited by another 5 pairs of attacker and attack method. In short, for victim7 there are 5 additional and potential attack threats, and precautions should be taken against them.
To evaluate this and the latter two analysis patterns, we extracted all the undirected and acyclic graphs (among red color edges) from an attacker to a victim in the knowledge graph. This treatment generated a clear labeled dataset, meanwhile avoided the subjectivity in the process of labeling. In total, 345 reachable paths (i.e. attack paths) were labeled.
Among these attack paths, 177 (attacker, attack method) pairs are labeled. For all the 15 victims, this analysis pattern find 156 new (attacker, attack method) threat pairs beyond the 21 pairs described in Table 5. Besides, the above analysis pattern recalls 176 pairs without wrong cases. The recall rate is 99.43% and the F1 score is 99.71%. One pair was omitted due to one attack method's edges to exploit hv were divided and assigned to other attack methods in the same scenario.
5.2.5 Find potential targets for attackers For specific attacker, knowledge graph can be used to find additional or potential targets beyond the given scenario. Similar to the previous analysis pattern, the following logic was extracted:

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 17 of 20

victim5_...

apply_tsouffer

ha...

manipul...

to_exploit

extraver...

surprise

to_ex...

gluttony

to_exploit

have_vul

to_exploit

phishing to...

greed

have_vul

happine...

havthecoaar__avtvetfuta_x_vlcapunklldo_iptverifcortmim10...

to_exploit

have_vulto_exploit have_vul
have_v... impulsi...

to_expl... to_exploit

have_vul

to_exploitto_e...

baiting apply_tosuffer

have_vul

victim8_...

have_vul

excitem...

have_vul

attacker10...

to_exploit

trojan_a...

to_exploit have_vul

ha...

whaling

to_exploit have_vul

intuitive...

have_vutol _evxipclotiitm13...

have_vul

to_exploit have_vul

to_exploit
su... a...

victim15... pretexti... a...

victim6_... suffer appl... piggyba...

s... victim9_...

Figure 24 For specific attacker, find potential targets (victims) beyond the given scenario

1. if (a1)  (am1)  (hv)  (v1) in S1 and (am2)  (hv)  (v2) in S2
2. then (a1)  (am1 or am2)  (hv)  (v1) is feasible
Namely: the victim v2 can be also attacked by the attacker a1 through attack method am1 or am2, if a victim v1 has certain human vulnerabilities hv and exploited by attack method am1 crafted by attacker a1 in scenario S1 meanwhile the victim v2 is found also has the same vulnerabilities hv in scenario S2 exploited by attack method am2.
Figure 24 shows this application where attacker10 serves as an example. It presents that the attacker10 crafts and performs phishing to exploit victim10's vulnerabilities in scenario10; moreover, another 6 targets have the same vulnerabilities that victim10 has and can be also exploited by attacker10 through phishing (or attack methods in other scenarios). In brief, 6 potential targets are found for attacker10. For practice, it is helpful to notify all the potential targets if attacker10 or phishing is a serious security threat. If this is a penetration testing, Figure 24 will oer testers more attack targets and attack methods.
For all the 15 attackers, this analysis pattern find 123 new exploitable targets beyond the 15 victims described in Table 5, and 156 new (attack method, targets) pairs beyond the 21 pairs described in Table 5. This analysis pattern recalls 176 (attack method, targets) pairs without wrong cases. The recall rate is

99.43% and the F1 score is 99.71%. One pair was omitted due to one attack method's edges to exploit hv were divided and assigned to other attack methods in the same scenario.

piggybacki...

whaling

to_exploit

to_exploit

intuitive_ju...

to_exploit

pretexting_...

to_exploit

have_vul

trojan_atta...

to_exploit

have_...

impulsion

to_ex...

to_exp...

to_exploit to_exploit

victim13_c...

greed

have_vul

have_v... to_exploit to_expl...

phishing

craft_and_p...

excitement

attacker10

to_exploit

baiting

to_exploit

Figure 25 For specific attacker and victim, find potential attack paths and methods

5.2.6 Find paths from specific attacker to specific target
For specific attacker and specific victim which are not in the same attack scenario, knowledge graph can be used to check or find feasible attack paths and potential attack methods. This is a combination of the previous two analysis patterns, and the following pattern was extracted:
1. if (a1)  (am1)  (hv) in S1 and (v2)  (hv) in S2
2. then (a1)  (am1)  (hv)  (v2) is feasible
Namely, the attack path from attacker a1 to target v2 is feasible, if attacker a1 can successfully exploit human vulnerability hv by attack method am1, meanwhile the target v2 is found has the vulnerability hv.
Figure 25 shows this application where attacker10 and victim13 serve as the examples. The following 4 attack paths is extracted from the knowledge base: (attacker10)-[craft and perform] ! (phishing)-[to exploit] ! (4 human vulnerabilities) [has]-(victim13). In addition, another 5 attack methods that exploit the victim13's vulnerabilities but not within the attack paths are also presented in Figure 25. These methods are potentially available for attacker10 to reach victim13.
For all the 15 attackers and 15 targets, this analysis pattern find 251 new attack paths beyond the 94 paths

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 18 of 20

300

250

(A, AM) (AM, T/V)

AP

200

Labeled

177

177

345

Recall

176

176

344

150

Recall rate 99.43% 99.43% 99.71%

100

F1 score 99.71% 99.71% 99.85% 50

A: attacker AM: attack method T/V: attack target / victim AP: attack paths

0
existed in scenarios description new find beyond the scenarios description folds

7.43
(A,AM) 21 156 7.43

7.43
(AM,T/V) 21 156 7.43

Figure 26 Experiment results and statistic analysis of Section 5.2.4, 5.2.5 and 5.2.6

8.2
(A, T/V) 15 123 8.2

9

8

7

6

5

4

2.67

3

2

1

0 AP 94 251 2.67

described in Table 5, and 123 new (attacker, targets) pairs beyond the 15 pairs described in Table 5. For all 345 labeled attack paths, this analysis pattern recalls 344 attack paths without wrong cases. The recall rate is 99.71% and the F1 score is 99.85%. One attack path was omitted due to one attack method's edges to exploit hv were divided and assigned to other attack methods in the same scenario.
Figure 26 summarizes the experiment results and statistic analysis of Section 5.2.4, 5.2.5 and 5.2.6.
5.2.7 Analyze the same origin attack In general, the attack method am1 and am2 are similar or related if they have some common features; am1 and am2 might be launched by the same attacker if they have certain crucial common features, e.g they point to the same domain address controlled (by attacker). Further, am1 and am2 is likely to be same-origin and the attacker a1 and a2 is likely in the same attack organization, if above (am1, am2) are launched respectively by two dierent attackers (a1, a2) who are motivated by the same motivation m to attack dierent victims (v1, v2) who have the same a liation. Based on above cognition or assumption, Figure 27 shows the knowledge graph application example to analyze same origin attack.
Besides returning the graph existed in the knowledge base, new relations and nodes can be created. A new relation "same a liation" is created between victim10 and victim15, since they both have the data property "a liation" with the equal value. There is a potential relation "same origin attack" between whaling and phishing nodes, because in the whaling attack Trojan horse or back door with encoded domain address "att.eg.net" is used meanwhile this address is also found in the malicious link of phishing attack. Furthermore, due to attacker15 and attacker10 have the same motivation "financial gain" and victim15 and

victim10 in the same "Company A", given all these, it can be inferred that these two scenarios compose a same-origin and organized attack. Thus, we create new relation "same origin attack" between the two attack method nodes and relation "in the same organization" between the two attacker nodes.

financial_g...

motivated_by

motivated_by

same_attack_organization

attacker10

attacker15

same_attack_organization

craft_a... craft_a...

Node.comment: ... malicious links with encoded URL
address: att.eg.net ...

phishing

same_origin_attack same_origin_attack

whaling

Node.comment: ... trojan horse or back door
with encoded domain address: att.eg.net ...

apply_to apply_to

Node.affiliation: Company A

victim10_c...

same_affiliation same_affiliation

victim15_hi...

Node.affiliation: Company A

Figure 27 Analyze the same origin attack by knowledge graph

6 Discussion
There are some studies related to social engineering ontology. Simmonds et al. [17] proposed a conceptualization / ontology for network security attacks, in which components (access, actor, attack, threat, motive, information, outcome, impact, intangible, system administrator) are included. Although some components (e.g. actor, motive, information) are similar to concepts in this paper, the ontology [17] focuses on network security (and access control), which cannot be used to describe social engineering domain. Oosterloo [18] presented an ontological chart, in which concepts

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 19 of 20

such as attacker, threat, risk, stakeholder and asset are involved. But this chart is served as a model to summarize and organize aspects related to social engineering risk management, and the purpose is not a formal and explicit description of concepts and relations in social engineering domain. Vedeshin [19] discussed three phases (orchestration, exploitation, and compromise) of social engineering attacks, in which some classes (such as target, actor, goal, techniques, medium, execution steps and maintaining access) are discussed. However, this taxonomy is used to classify dierent social engineering attacks. Mouton et al. [20] described an ontological model of social engineering attack consisted of six entities: social engineer, target, medium, goal, compliance principles and techniques. However, the concept definitions of these entities were not presented and the relations among these entities were also not specified. That is, it does not constitute a domain ontology. Besides, the social engineering definition in [20] is proposed form the perspective of persuasion, which describes only a part of social engineering [1]. As another result, the model does not include some important entities (e.g. human vulnerability) and aspects (e.g. deception and trust). Tchakount´e et al. [21] discussed a certain spear phishing scenario / flow and its description logic (DL), yet other social engineering attack types were not involved. Li and Ni [22] discussed the di culty to distinguish social engineering attacks (methods) collected from six studies. They identified some core concepts to characterize social engineering attack by aligning these concepts with existing security concepts, and then provided a description logic for a security ontology and attack classification. In the security ontology, social engineer, social engineering attack, human and human vulnerability were respectively aligned as subclass of attacker, attack, asset and vulnerability; another two concepts attack media and social engineering techniques were also included. However, human is the target yet not the asset that social engineering attacks aim to harm, and according to their text and ontology implementation, social engineering attack and technique seem to refer the same concept. This might be reasons why the concepts' relations in their work were not aligned. Besides, the domain ontology of social engineering is not the focus of study [22], and the above six (or five) concepts are not su cient to analyze relatively complex social engineering attack incidents / scenarios. Alshanfari et al. [23] gathered some terms related to social engineering and attempted to organize them by Prot´eg´e using method described in [2]. However, the terms were extracted only from 30 publications from 2015 to 2018 and only three entity classes (attack type, threat and countermeasures) were presented, in which some terms

are just related to the class yet are not the instances of it (e.g. guilt, websites in attack type; sensitive information, password in threat). Besides, relations among these classes were not described clearly. Thus, this work is mainly oriented to the terms and classification. Nevertheless, we would like to appreciate above works and other researchers who make eorts in this field.
We develop a domain ontology of social engineering in cybersecurity and conducts ontology evaluation by knowledge graph application.
· The domain ontology describes what entities significantly constitute or aect social engineering and how they relate to each other, provides a formal and explicit knowledge schema, and can be used to understand, analyze, reuse and share domain knowledge of social engineering.
· The 7 analysis examples by knowledge graph not only show the ontology evaluation and application, but also present new means to analyze social engineering attack and threat.
· In addition, the way that 1) use Prot´eg´e to develop ontology, create instances and knoledge base 2) and then employ Neo4j to import RDF/OWL data, optimize knoledge base and construct knoledge graph for better data analysis and visualization also provides a reference for related research.
· In the ontology, some taxonomies (subclasses) or relations might be verbose or omitted. But as mentioned before, subclass name will be converted to node labels and inverse relations can facilitate the knowledge retrieval, and therefore, users can add or delete them based on specific application requirements.
· The material of attack scenarios and the data of ontology+instances oer a dataset can be used for future related research. The knowledge graph dataset (224 instances nodes, 344 resource nodes and 939 relations of 15 attack scenarios) seems small. Yet it covers 14 kinds of social engineering types, and the 6 kinds of analysis patterns have demonstrated the various feasibilities of the proposed ontology and knowledge graph in analyzing social engineering attack and threat.
· To the best of our knowledge, this is the first work which completes a domain ontology for social engineering in cybersecurity, and further provides its knowledge graph application for attack analysis.
Due to the complexity of social engineering domain, the ontology seems impossible perfect in the only once establishment. We throw out a brick to attract a jade and look forward superior studies by researchers in this field.

Wang et al. This paper was accepted by Cybersecurity (ISSN: 2523-3246) on 28 April. doi:10.1186/s42400-021-00094-6 Page 20 of 20

7 Conclusion
This paper develops a domain ontology of social engineering in cybersecurity, in which 11 concepts of core entities that significantly constitute or aect the social engineering domain together with 22 kinds of relations among these concepts are defined. It provides a formal and explicit knowledge schema to understand, analyze, reuse and share domain knowledge of social engineering. Based on this domain ontology, this paper builds a knowledge graph using 15 social engineering attack incidents / typical scenarios. The 7 knowledge graph application examples (in 6 kinds of analysis patterns) demonstrate that the ontology together with the knowledge graph can be used to analyze social engineering attack scenarios or incidents, to find (the top ranked) threat elements (e.g. the most exploited human vulnerabilities, attack mediums), to find potential attackers, targets and attack paths, and to analyze the same origin attacks.
Author details 1School of Cyber Security, University of Chinese Academy of Sciences, Beijing, CN. 2Beijing Key Laboratory of IoT Information Security Technology, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, CN.
References 1. Z. Wang, L. Sun, H. Zhu, Defining Social Engineering in Cybersecurity, IEEE Access 8 (2020) 85094­85115. URL: https://doi.org/10.1109/access.2020.2992807. 2. N. F. Noy, D. L. McGuinness, Ontology Development 101: A Guide to Creating Your First Ontology, Technical Report, Knowledge Systems Laboratory, 2001. URL: https://protege.stanford.edu/ publications/ontology_development/ontology101.pdf. 3. M. A. Musen, Prot´eg´e Team, The Prot´eg´e Project: A Look Back and a Look Forward, AI Matters 1 (2015) 4­12. URL: https://pubmed.ncbi.nlm.nih.gov/27239556. 4. D. Research, The Risk of Social Engineering on Information Security: A Survey of IT Professionals, Technical Report, Dimensional Research, www.dimensionalresearch.com, 2011. URL: https://www.stamx.net/files/ The- Risk- of- Social- Engineering- on- Information- Security. pdf. 5. A. Chitrey, D. Singh, V. Singh, A comprehensive study of social engineering based attacks in india to develop a conceptual model, International Journal of Information and Network Security 1 (2012) 45. 6. R. E. Indrajit, Social Engineering Framework: Understanding the Deception Approach to Human Element of Security, International Journal of Computer Science Issues (IJCSI) 14 (2017) 8­16. 7. B. Fang, The definitions of fundamental concepts, in: Cyberspace Sovereignty, Springer, 2018, pp. 1­52. 8. B. Fang, Define cyberspace security, Chinese Journal of Network and Information Security 4 (2018) 1­5. 9. P. Damle, Social engineering: A tip of the iceberg, Information Systems Control Journal 2 (2002) 51­52.
10. K. C. Redmon, Mitigation of Social Engineering Attacks in Corporate America, Greenville: East Carolina University (2005).
11. K. Ivaturi, L. Janczewski, A taxonomy for social engineering attacks, in: International Conference on Information Resources Management, Centre for Information Technology, Organizations, and People, 2011, pp. 1­12. URL: https://aisel.aisnet.org/cgi/viewcontent.cgi? article=1015&context=confirm2011.
12. C. F. Mohd Foozy, R. Ahmad, M. Abdollah, Y. Robiah, Z. Masud, Generic Taxonomy of Social Engineering Attack, in: MUiCET, 2011, pp. 1­7.

13. P. S. Maan, M. Sharma, Social engineering: A partial technical attack, International Journal of Computer Science Issues 9 (2012) 1694­0814. URL: https://pdfs.semanticscholar.org/7e51/ 0456042c26cade06d74ea755c774713c46cf.pdf.
14. K. D. Mitnick, W. L. Simon, The Art of Deception: Controlling the Human Element of Security, John Wiley & Sons, 2011.
15. Z. Wang, H. Zhu, L. Sun, Social Engineering in Cybersecurity: Eect Mechanisms, Human Vulnerabilities and Attack Methods, IEEE Access 9 (2021) 11895­11910. URL: https://doi.org/10.1109/ACCESS.2021.3051633.
16. Neo4j community edition 3.5.19, 15 June 2020. URL: https://neo4j.com/download- center/#community.
17. A. Simmonds, P. Sandilands, L. van Ekert, An Ontology for Network Security Attacks, in: S. Manandhar, J. Austin, U. Desai, Y. Oyanagi, A. K. Talukder (Eds.), Applied Computing, Springer Berlin Heidelberg, Berlin, Heidelberg, 2004, pp. 317­323.
18. B. Oosterloo, Managing social engineering risk: making social engineering transparant, Ph.D. thesis, University of Twente, 2008. URL: http://essay.utwente.nl/59233/1/scriptie_B_Oosterloo.pdf.
19. A. Vedeshin, Contributions of Understanding and Defending Against Social Engineering Attacks, Master's thesis, Department of Computer Science, Tallinn University of Technology, 2016.
20. F. Mouton, L. Leenen, M. M. Malan, H. S. Venter, Towards an Ontological Model Defining the Social Engineering Domain, in: ICT and Society, IFIP Advances in Information and Communication Technology, Springer, Berlin, Heidelberg, 2014, pp. 266­279. URL: https: //link.springer.com/chapter/10.1007/978- 3- 662- 44208- 1_22.
21. F. Tchakount´e, D. Molengar, J. M. Ngossaha, A Description Logic Ontology for Email Phishing, International Journal of Information Security Science 9 (2020) 44­63.
22. T. Li, Y. Ni, Paving Ontological Foundation for Social Engineering Analysis, in: P. Giorgini, B. Weber (Eds.), Advanced Information Systems Engineering, Springer International Publishing, Cham, 2019, pp. 246­260.
23. I. Alshanfari, R. Ismail, N. J. M. Zaizi, F. A. Wahid, Ontology-based formal specifications for social engineering, International Journal of Technology Management and Information System 2 (2020) 35­46.

