The Semi-Supervised iNaturalist Challenge at the FGVC8 Workshop
Jong-Chyi Su Subhransu Maji University of Massachusetts Amherst
{jcsu, smaji}@cs.umass.edu

arXiv:2106.01364v1 [cs.CV] 2 Jun 2021

Abstract
Semi-iNat is a challenging dataset for semi-supervised classification with a long-tailed distribution of classes, finegrained categories, and domain shifts between labeled and unlabeled data. This dataset is behind the second iteration of the semi-supervised recognition challenge to be held at the FGVC8 workshop at CVPR 2021. Different from the previous one, this dataset (i) includes images of species from different kingdoms in the natural taxonomy, (ii) is at a larger scale -- with 810 in-class and 1629 outof-class species for a total of 330k images, and (iii) does not provide in/out-of-class labels, but provides coarse taxonomic labels (kingdom and phylum) for the unlabeled images. This document describes baseline results and the details of the dataset which is available here: https: //github.com/cvl-umass/semi-inat-2021.
1. Introduction
Semi-supervised image classification concerns the problem of learning a classifier in the presence of labeled and unlabeled images. While there has been a considerable number of techniques proposed in recent years, progress has been limited in part due to the lack of realistic benchmarks and evaluation protocols. To this end, we presented a semi-supervised dataset called Semi-Aves [4] as part of the FGVC7 workshop. Semi-Aves contains 1000 bird species where labeled data are from 200 species. Both labeled and unlabeled data have long-tailed distributions. The challenge exposed some limitations of existing methods, such as the lack of robustness of out-of-domain unlabeled data and limited improvements in the transfer learning setting [3]. Motivated by this we present another iteration of this challenge to be held at the FGVC8 workshop at CVPR 2021.
Semi-iNat builds on the previous year's benchmark while incorporating some new challenges. First, the dataset contains species from three kingdoms: Animal, Plants, and Fungi (Fig. 1 and Tab. 1), unlike Semi-Aves which contains only Aves (birds). There are a total of 2439 animal species and 330k images, which is more than two times

Mollusca Chordata Arthropoda Echinodermata

Tracheophyta Bryophyta Basidiomycota Ascomycota

Figure 1. Examples from the Semi-iNat dataset. The Semi-iNat dataset includes images from 8 different phyla.

Kingdom

Phylum

Cin Cout

Mollusca

11 24

Animalia (1294)

Chordata Arthropoda

113 228 301 605

Echinodermata 4

8

Plantae (1028)

Tracheophyta 336 674

Bryophyta

6 12

Fungi Basidiomycota 29 58

(117)

Ascomycota 10 20

Table 1. The number of species in the taxonomy. For each phylum, we select around one-third of the species for the in-class set Cin and the rest for the out-of-class set Cout.

larger than Semi-Aves. In addition, we do not provide the label if the unlabeled images are from the same classes as labeled data (which we did in Semi-Aves), and instead provide the coarse taxonomy for unlabeled data. Coarse taxonomic labels are easily obtained from non-experts and provide a weak supervisory signal that could be exploited by the learning methods. In the following sections, we describe the data collection process and provide baseline performances.

1

Split

Semi-Aves

Details

Classes #Images #img/cls Split

Semi-iNat Details Classes #Images #img/cls

Train

Labeled

200

3,959

5-43 Train Labeled

810

9,721

5-80

Train Unlabeled (in) 200 26,640 16-229 Train Unlabeled 2439 313,248 19-400
Train Unlabeled (out) 800 122,208 23-250

Val

Labeled

200

2,000

10

Val Labeled

810

4,050

5

Test

Public

200

4,000

20

Test Public

810

8,100

10

Test

Private

200

4,000

20

Test Private

810

8,100

10

Table 2. Statistics of the Semi-Aves [4] and Semi-iNat dataset. Both labeled and unlabeled training sets have a long-tailed distribution, while validation and test sets are uniformly distributed. The test set splits are only used for the Kaggle competition at the FGVC8 workshop. We also show the statistics of Semi-Aves [4] on the left for a comparison. Different from Semi-Aves, Semi-iNat has more species and images, and a single set of unlabeled data.

2. The Semi-iNat Dataset
We create the dataset including organisms across different kingdoms in the taxonomy rank. We first remove the species that appear in the previous iNat challenges [5], including iNat-17, iNat-18, iNat-19, iNat-21, and the SemiAves [4] challenges, to avoid any overlap. We then select the most common species from the iNaturalist website [1]. To ensure the diversity of images in each category, we only select one image per contributor (photographer).
Next, we split the species into two sets Cin and Cout, one for in-class and one for out-of-class data. To avoid a large domain mismatch between them, we make the split depending on the taxonomy. For each phylum, we randomly select about one-third of the species for Cin, and the rest for Cout. The number of species in the taxonomy is shown in Tab. 1. For each species in Cin, we first select 5/10/10 images for validation, public test, and private test set. Among the rest of the images, we then sample around 10% of the images as labeled data Lin and the rest as unlabeled data Uin. We also ensure a minimum of 5 labeled images per class. For species in Cout, there are up to 400 images and all of them are included in Uout. The two sets of unlabeled data U = Uin  Uout are then combined and no domain labels are provided. The statistics of the class distribution are shown in Tab. 2 and the histogram is shown in Fig. 2.
In addition to class labels, we also provide the full taxonomy of the species in Cin. For each unlabeled image in Uout, we provide its kingdom and phylum information. This is to model a scenario where coarse labels can be acquired much more easily than fine-grained ones and may be used to improve the performance of SSL algorithms. Last, we restrict the image resolution to be at most 300px on either side, different from Semi-Aves where its at most 500px.

400 350

LUUiionnut

300

Number of Images

250

200

150

100

50

00

500

Ran10k0e0d Species I1n5d00ex

2000

2500

Figure 2. Class distribution of Semi-iNat dataset. Note that the distinction between Uin and Uout are only shown here for visualization. We did not provide the domain labels for unlabeled data.

3. Baselines
We present results using ResNet-50 [2] models trained from scratch or from ImageNet pre-trained model. We also train models using the labels Lin only (baseline), and when including the ground-truth labels of images from Uin (oracle). We train using stochastic gradient descent with cosine learning rate decay and a batch size of 64 following [3]. The learning rate and weight decay are tuned between [1e-2, 3e3] and [1e-3 1e-5]. We train the model for 50k and 150k iterations when ImageNet pre-training is used. For training from scratch, we use 3× more iterations. Tab. 3 shows that ImageNet pre-training provides a 22% improvement over training from scratch. The gap between baseline and oracle shows that there is ample room for improvement.
We further analyze the predictions of the baseline model (trained from ImageNet) by showing the confusion matrix.

2

Method

from scratch Top-1 Top-5

from ImageNet Top-1 Top-5

Baseline Oracle

19.2% 93.3%

36.4% 96.9%

41.0% 94.3%

63.7% 97.5%

Table 3. Performance of ResNet-50 on Semi-iNat. The baseline is trained on labeled data only, while the oracle is trained on all the data and their (hidden) labels in Lin  Uin.

Mollusca (A) 0.58 0.05 0.19 0.00 0.05 0.00 0.12 0.00

Chordata (A) 0.01 0.76 0.11 0.00 0.10 0.00 0.02 0.00

0.8

Arthropoda (A) 0.01 0.02 0.90 0.00 0.06 0.00 0.01 0.00

0.6

Echinodermata (A) 0.05 0.09 0.14 0.60 0.06 0.01 0.05 0.00

Tracheophyta (P) 0.00 0.01 0.04 0.00 0.93 0.01 0.01 0.00

0.4

Bryophyta (P) 0.00 0.03 0.02 0.00 0.26 0.65 0.04 0.01

Basidiomycota (F) 0.02 0.02 0.05 0.00 0.06 0.00 0.85 0.01

0.2

Ascomycota (F) 0.00 0.03 0.12 0.01 0.12 0.00 0.02 0.71

MolluscaC(hAo)rdaAtrath(ArEo)cphoidnaod(eAr)mTraatcah(eAo)phyBtary(oPBp)ahsyitdaio(mP)ycAostaco(mF)ycota (F)

0.0

Figure 3. Confusion matrix of the baseline model on the

Phylum level. The kingdoms are shown in the brackets: (A) for

Animalia, (P) for Plantae, and (F) for Fungi. We can see that the

accuracy is lower for those phylum with less species, and more

confusions come from the species under the same kingdom.

[4] Jong-Chyi Su and Subhransu Maji. The semi-supervised inaturalist-aves challenge at fgvc7 workshop. arXiv preprint arXiv:2103.06937, 2021. 1, 2
[5] Grant Van Horn, Oisin Mac Aodha, Yang Song, Yin Cui, Chen Sun, Alex Shepard, Hartwig Adam, Pietro Perona, and Serge Belongie. The inaturalist species classification and detection dataset. In CVPR, 2018. 2

We group the categories on the phylum level and plot the normalized 8×8 confusion matrix in Fig. 3. The diagonal shows that the accuracy on each phylum is proportional to the number of species and images. On off-diagonal entries, we can see more confusions within the kingdom.

Acknowlegements. This project is supported in part by NSF #1749833. We also thank the FGVC team and Kaggle for organizing the workshop; Oisin Mac Aodha and Grant van Horn for the help collecting the dataset.
References
[1] iNaturalist. https://www.inaturalist.org. 2 [2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In CVPR, 2016. 2 [3] Jong-Chyi Su, Zezhou Cheng, and Subhransu Maji. A realistic evaluation of semi-supervised learning for fine-grained classification. In CVPR, 2021. 1, 2
3

