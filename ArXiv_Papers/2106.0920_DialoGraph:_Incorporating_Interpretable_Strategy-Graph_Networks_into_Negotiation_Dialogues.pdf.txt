Published as a conference paper at ICLR 2021

arXiv:2106.00920v1 [cs.CL] 2 Jun 2021

DIALOGRAPH: INCORPORATING INTERPRETABLE STRATEGY-GRAPH NETWORKS INTO NEGOTIATION DIALOGUES
Rishabh Joshi, Vidhisha Balachandran, Shikhar Vashishth, Alan W Black, Yulia Tsvetkov Language Technologies Institute Carnegie Mellon University {rjoshi2, vbalacha, svashish, awb, ytsvetko}@cs.cmu.edu

ABSTRACT
To successfully negotiate a deal, it is not enough to communicate fluently: pragmatic planning of persuasive negotiation strategies is essential. While modern dialogue agents excel at generating fluent sentences, they still lack pragmatic grounding and cannot reason strategically. We present DIALOGRAPH, a negotiation system that incorporates pragmatic strategies in a negotiation dialogue using graph neural networks. DIALOGRAPH explicitly incorporates dependencies between sequences of strategies to enable improved and interpretable prediction of next optimal strategies, given the dialogue context. Our graph-based method outperforms prior state-of-the-art negotiation models both in the accuracy of strategy/dialogue act prediction and in the quality of downstream dialogue response generation. We qualitatively show further benefits of learned strategy-graphs in providing explicit associations between effective negotiation strategies over the course of the dialogue, leading to interpretable and strategic dialogues.1

1 INTRODUCTION

Negotiation is ubiquitous in human interaction, from e-commerce to the multi-billion dollar sales of companies. Learning how to negotiate effectively involves deep pragmatic understanding and planning the dialogue strategically (Thompson; Bazerman et al., 2000b; Pruitt, 2013).

Modern dialogue systems for collaborative tasks such as Buyer (Human)

restaurant or flight reservations have made considerable progress by modeling the dialogue history and structure

My younger bro loves old classics. I m looking to buy a vinyl player.

Family, informal

explicitly using the semantic content, like slot-value pairs

Propose I m asking 40 for it.

(Larionov et al., 2018; Young, 2006), or implicitly with encoder-decoder architectures (Sordoni et al., 2015; Li

Damn. That s too much for a student like me. How about 30?

Negative, Propose

Option 1

et al., 2016). In such tasks, users communicate explicit intentions, enabling systems to map the utterances into

w/o Strategy

Not possible. I can do 35. You ll have to pick it up.

specific intent slots (Li et al., 2020). However, such mapping is less clear in complex non-collaborative tasks like negotiation (He et al., 2018) and persuasion (Wang et al., 2019), where user intent and most effective strategies are hidden. Hence, along with the generated dialogue, the strategic choice of framing and the sequence of chosen

Option 2

Reject

w/ Strategy

Family, informal, propose, trade-in

I can do 38 and I ll throw a couple of Beatles records for your bro.
Accept

Seller (Bot)

strategies play a vital role, as depicted in Figure 1. In- Figure 1: Both options are equally plausi-

deed, prior work on negotiation dialogues has primarily ble and fluent, but a response with effective

focused on optimizing dialogue strategies--from high- pragmatic strategies leads to a better deal.

level task-specific strategies (Lewis et al., 2017), to more

specific task execution planning (He et al., 2018), to fine-grained planning of linguistic outputs given

1Code, data and a demo system is released at https://github.com/rishabhjoshi/ DialoGraph_ICLR21

1

Published as a conference paper at ICLR 2021
strategic choices (Zhou et al., 2019). These studies have confirmed that it is crucial to control for pragmatics of the dialogue to build effective negotiation systems.
To model the explicit dialogue structure, prior work incorporated Hidden Markov Models (HMMs) (Zhai & Williams, 2014; Ritter et al., 2010), Finite State Transducers (FSTs) (Zhou et al., 2020) and RNNs (He et al., 2018; Shi et al., 2019). While RNN-based models lack interpretability, HMMand FST-based approaches may lack expressivity. In this paper, we hypothesize that Graph Neural Networks (GNNs) (Wu et al., 2020) can combine the benefits of interpretability and expressivity because of their effectiveness in encoding graph-structured data through message propagation. While being sufficiently expressive to model graph structures, GNNs also provide a natural means for interpretation via intermediate states (Xie & Lu, 2019; Pope et al., 2019).
We propose DIALOGRAPH, an end-to-end negotiation dialogue system that leverages Graph Attention Networks (GAT) (Velickovic´ et al., 2018) to model complex negotiation strategies while providing interpretability for the model via intermediate structures. DIALOGRAPH incorporates the recently proposed hierarchical graph pooling based approaches (Ranjan et al., 2020) to learn the associations between negotiation strategies, including conceptual and linguistic strategies and dialogue acts, and their relative importance in predicting the best sequence. We focus on buyer­seller negotiations in which two individuals negotiate on the price of an item through a chat interface, and we model the seller's behavior on the CraigslistBargain dataset (He et al., 2018).2 We demonstrate that DIALOGRAPH outperforms previous state-of-art methods on strategy prediction and downstream dialogue responses. This paper makes several contributions. First, we introduce a novel approach to model negotiation strategies and their dependencies as graph structures, via GNNs. Second, we incorporate these learned graphs into an end-to-end negotiation dialogue system and demonstrate that it consistently improves future-strategy prediction and downstream dialogue generation, leading to better negotiation deals (sale prices). Finally, we demonstrate how to interpret intermediate structures and learned sequences of strategies, opening-up the black-box of end-to-end strategic dialogue systems.
2 DIALOGRAPH
We introduce DIALOGRAPH, a modular end-to-end dialogue system, that incorporates GATs with hierarchical pooling to learn pragmatic dialogue strategies jointly with the dialogue history. DIALOGRAPH is based on a hierarchical encoder-decoder model and consists of three main components: (1) hierarchical dialogue encoder, which learns a representation for each utterance and encodes its local context; (2) structure encoder for encoding sequences of negotiation strategies and dialogue acts; and (3) utterance decoder, which finally generates the output utterance. Formally, our dialogue input consists of a sequence of tuples, D = [(u1, da1, ST1), (u2, da2, ST2), ..., (un, dan, STn)] where ui is the utterance, dai is the coarse dialogue act and STi = {sti,1, sti,2, . . . , sti,k} is the set of k fine-grained negotiation strategies for the utterance ui.3 The dialogue context forms the input to (1) and the previous dialogue acts and negotiation strategies form the input to (2). The overall architecture is shown in Figure 2. In what follows, we describe DIALOGRAPH in detail.
2.1 HIERARCHICAL DIALOGUE ENCODER
A dialogue context typically comprises of multiple dialogue utterances which are sequential in nature. We use hierarchical encoders for modeling such sequential dialogue contexts (Jiao et al., 2019). To encode the utterance ut at time t, we use the pooled representations from BERT (Devlin et al., 2019) to obtain the corresponding utterance embedding et. We then pass the utterance embeddings through a GRU to obtain the dialogue context encoding till time t, denoted by hUt .
2We focus on the seller's side following Zhou et al. (2019) who devised a set of strategies specific to maximizing the seller's success. Our proposed methodology, however, is general.
3For example, in an utterance Morning! My bro destroyed my old kit and I'm looking for a new pair for $10, the coarse dialogue act is Introduction, and the finer grained negotiation strategies include Proposing price, Being informal and Talking about family for building rapport.
2

Published as a conference paper at ICLR 2021

Structure Encoder

u1
Inquire

u3
Affirmative

Strategies

Rapport Sentiment
u2

Thanks
u4

Graph Encoding (GAT)

Graph Pooling
GCN-ASAP

Structure Encoder

Dialogue Acts

u3

u1

Graph Pooling
GCN-ASAP

u4
Inquiry

Disagree

Agree

~ u2

Vague

Graph Encoding (GAT)

Utterance Encoder
Can t It be lower than $50 ?

Add & Norm Feed
Forward
Add & Norm Multi-Head Attention
utterance 1 (u1) utterance 2 (u2) utterance 3 (u3)

RNN-Encoder

Dialogue Context Utterance

Encoder

Embedding

How about $30 ?
Utterance Decoder
Utterance Generation

Figure 2: Overview of DIALOGRAPH. At time t, utterance ut is encoded using BERT and then passed to the Dialogue Context Encoder to generate the dialogue representation. This representation is enriched with the encodings of explicit strategy and dialogue act sequences using the structure encoders which is then used to condition the Utterance decoder. Please refer to §2 for details.

2.2 STRUCTURE ENCODER
Our structure encoder is designed to model the graph representations of the strategies and dialogue acts using GATs and output their structural representations. These structural representations are used to predict the next set of strategies and dialogue acts and enrich the encoded dialogue representation. Below we describe the structure encoder for negotiation strategies.
We model the sequence of negotiation strategies, ST = [ST1, ST2, . . . , STt] by creating a directed graph, where STi is the set of k fine-grained negotiation strategies for the utterance ui. Formally, we define a graph G(V, E, X) with |E| edges and N = |V| nodes where each node vi  V represents a particular negotiation strategy for an utterance and has a d-dimensional feature representation denoted by zi. Z  RN×d denotes the feature matrix of the nodes and A  RN×N represents the adjacency matrix, where N is the total number of nodes (strategies) that have occurred in the conversation till that point. Therefore, each node represents a strategy-utterance pair.
We define the set of edges as E = {(a, b)}; a, b  V where a and b denote strategies at utterances ua and ub, present at turns ta and tb, such that tb > ta. In other words, we make a directed edge from a particular node (strategy in an utterance) to all the consecutive nodes. This ensures a direct connection from all the previous strategies to the more recent ones.4 In the same way, we form the graph out of the sequence of dialogue acts. These direct edges and learned edge attention weights help us interpret the dependence and influence of strategies on each other.
To get the structural representations from the strategy graphs, we pass them through a hierarchical graph pooling based encoder, which consists of l layers of GAT, each followed by the Adaptive Structure Aware Pooling (ASAP) layer (Ranjan et al., 2020). As part of the ASAP layer, the model first runs GAT over the input graph representations to obtain structurally informed representations of the nodes. Then a cluster assignment step is performed which generates a cluster assignment matrix, S, which tells the model which nodes come in a similar structural context. After that, the clusters are ranked and then the graph is pooled by taking the top few clusters as new nodes and forming edges between them using the existing graph. This way the size of the graph is reduced at every step which leads to a structurally informed graph representation. We take advantage of the cluster formulation to obtain the associations between the negotiation strategies, as identified from the cluster assignment matrix, S. These association scores can later be used to interpret which strategies are associated with each other and tend to co-occur in similar contexts. Moreover, we also use the node attention scores from GAT to interpret the influence of different strategies on the
4Appendix C shows an example of the graph obtained from a sequence of strategies.
3

Published as a conference paper at ICLR 2021

representation of a particular strategy, which essentially gives the dependence information between strategies.
In this way, the structure representation is learned and accumulated in a manner that preserves the structural information (Ying et al., 2018; Lee et al., 2019). After each pooling step, the graph representation is summarized using the concatenation of mean and max of the node representations. The summaries are then added and passed through fully connected layers to obtain the final structural representation of the strategies hSt T . We employ a similar structure encoder to encode the graph obtained from the sequence of dialogue acts, to obtain hdt a.
2.3 UTTERANCE DECODER
The utterance decoder uses the dialogue context representation and structural representations of dialogue acts and negotiation strategies to produce the dialogue response (next utterance). We enrich the dialogue representation by concatenating the structural representations before passing it to a standard greedy GRU (Cho et al., 2014) decoder. This architecture follows Zhou et al. (2020), who introduced a dynamic negotiation system that incorporates negotiation strategies and dialogue acts via FSTs. We thus follow their utterance decoder architecture to enable direct baseline comparison. For the jth word of utterance ut+1, wtj+1, we condition on the previous word wtj+-11 to calculate the probability distribution over the vocabulary as pwt+j1 = softmax(GRU(ht, wtj+-11)) where ht = [hut ; hSt T ; hdt a] and [; ] represents the concatenation operator. For encoding the price, we replace all price information in the dataset with placeholders representing the percentage of the offer price. For example, we would replace $35 with < price - 0.875 > if the original selling price is $40. The decoder generates these placeholders which are then replaced with the calculated price before generating the utterance.

2.4 MODEL TRAINING

We use hSt T to predict the next set of strategies STt+1, a binary value vector which represents the k-hot representation of negotiation strategies for the next turn. We compute the probability of the jth strategy occurring in ut+1 as p(stt+1,j|hSt T ) = (hSt T ). where  denotes the sigmoid operator. We threshold the probability by 0.5 to obtain the k-hot representation. We denote the weighted negative log likelihood of strategies LST as the loss function of the task of next strategy prediction LST = - j j log(p(stt+1,j)) - k log(1 - p(stt+1,k)) where the
summation of j are over the strategies present (stt+1,j = 1) and not present (stt+1,k = 0) in
the ground truth strategies set, ST . Here j is the positive weight associated with the particular strategy. We add this weight to the positive examples to trade off precision and recall. We put j = # of instances not having strategy j/# of instances having strategy j.

Similarly, we use hdt a to predict the dialogue act for the next utterance dat+1. Given the target
dialogue act dat+1 and the class weights da for the dialogue acts, we denote the class-weighted cross entropy loss over the set of possible dialogue acts, LDA = -da log(softmax(hdt a)) . We pass ht = [hut ; hSt T ; hdt a] through a linear layer to predict the negotiation success, which is denoted by the sale-to-list ratio r = (sale price - buyer target price)/(listed price - buyer target price)

(Zhou et al., 2019). We split the ratios into 5 negotiation classes of equal sizes using the train-

ing data and use those to predict the success of negotiation. Therefore, given the predicted

probabilities for target utterance ut+1 from §2.3, target ratio class yr and the learnable param-

eters well

Wr and br, we use the cross entropy loss as the loss for the as the negotiation outcome prediction task (LR), thus LNLG =

g-enerwatjiount+t1aslkog((LpwtN+jL1G)

) as and

LR = - r[1,5] yr log(softmax(Wrht + br)). The LR loss optimizes for encoding negotiation strategies to enable accurate prediction of negotiation outcome.

We use hyperparameters ,  and  to optimize the joint loss Ljoint, of strategy prediction, dialogue act prediction, utterance generation and outcome prediction together, using the Adam optimizer (Kingma & Ba, 2014), to get Ljoint = LNLG + LST + LDA + LR.

4

Published as a conference paper at ICLR 2021
3 EXPERIMENTAL SETUP
Dataset: We use the CraigslistBargain dataset5 (He et al., 2018) to evaluate our model. The dataset was created using Amazon Mechanical Turk (AMT) in a negotiation setting where two workers were assigned the roles of buyer and seller respectively and were tasked to negotiate the price of an item on sale.The buyer was additionally given a target price. Both parties were encouraged to reach an agreement while each of the workers tried to get a better deal. We remove all conversations with less than 5 turns. Dataset statistics are listed in Table 11 in the Appendix.
We extract from the dataset the coarse dialogue acts as described by He et al. (2018). This includes a list of 10 utterance dialogue acts, e.g., inform, agree, counter-price. We augment this list by 4 outcome dialogue acts, namely, offer , accept , reject and quit , which correspond to the actions taken by the users. Negotiation strategies are extracted from the data following Zhou et al. (2019). These include 21 fine-grained strategies grounded in prior economics/behavioral science research on negotiation (Pruitt, 2013; Bazerman & Neale, 1993; Bazerman et al., 2000a; Fisher et al., 2011; Lax & Sebenius, 2006; Bazerman et al., 2000b), e.g, negotiate side offers, build rapport, show dominance. All dialogue acts and strategies are listed in Appendices A and B.
Baselines: DIALOGRAPH refers to our proposed method. To corroborate the efficacy of DIALOGRAPH, we compare it against our implementation of the present state-of-the-art model for the negotiation task: FST-enhanced hierarchical encoder-decoder model (FeHED) (Zhou et al., 2020) which utilizes FSTs for encoding sequences of strategies and dialogue acts.6 We also conduct and ablation study, and evaluate the variants of DIALOGRAPH with different ways of encoding negotiation strategies, namely, HED, HED+RNN, and HED+Transformer. HED completely ignores the strategy and dialogue act information, whereas HED+RNN and HED+Transformer encode them using RNN and Transformers (Vaswani et al., 2017) respectively. While HED+RNN is based on the dialogue manager of He et al. (2018), HED+Transformer has not been proposed earlier for this task. For a fair comparison, we use a pre-trained BERT (Devlin et al., 2019) model as the utterance encoder (§2.1) and a common utterance decoder (§2.4) in all the models, and only vary the structure encoders as described above. The strategies and dialogue acts in RNN and Transformer based encoders are fed as sequence of k-hot vectors.
Evaluation Metrics: For evaluating the performance on the next strategy prediction and the next dialogue act prediction task, we report the F1 and ROC AUC scores for all the models. For these metrics, macro scores tell us how well the model performs on less frequent strategies/dialogue acts and the micro performance tells us how good the model performs overall while taking the label imbalance into account. Strategy prediction is a multi-label prediction problem since each utterance can have multiple strategies. For the downstream tasks of utterance generation, we compare the models using BLEU score (Papineni et al., 2002) and BERTScore (Zhang et al., 2020). Finally, we also evaluate on another downstream task of predicting the outcome of negotiation, using the ratio class prediction accuracy (RC-Acc) (1 out of 5 negotiation outcome classes, as described in §2.4). Predicting sale outcome provides better interpretability over the progression of a sale and potentially control to intervene when negotiation has a bad predicted outcome. Additionally, being able to predict the sale outcome with high accuracy shows that the model encodes the sequence of negotiation strategies well.
4 RESULTS
We evaluate (1) strategy and dialogue act prediction (intrinsic evaluation), and (2) dialogue generation and negotiation outcome prediction (downstream evaluation). For all metrics, we perform bootstrapped statistical tests (Berg-Kirkpatrick et al., 2012; Koehn, 2004) and we bold the best results for a metric in all tables (several results are in bold if they have statistically insignificant differences).
Strategy and Dialogue Act Prediction: We compare DIALOGRAPH's effectiveness in encoding the explicit sequence of strategies and dialogue acts with the baselines, using the metrics described in §3. Table 1 shows that DIALOGRAPH performs on par with the Transformer based encoder in
5https://github.com/stanfordnlp/cocoa/tree/master/craigslistbargain 6We replace the utterance encoder with BERT for fair comparison. This improved slightly the performance of the FeHED model compared to results published in Zhou et al. (2020).
5

Published as a conference paper at ICLR 2021

Table 1: Performance of the next strategy and dialogue-act prediction of various models. We report the F1 and ROC AUC scores. Significance tests were performed as described in §4 and the best results (along with all statistically insignificant values) are bolded.

Model
FeHED HED+RNN HED+Transformer
DIALOGRAPH

Macro
17.6 23.2 26.3
26.1

Negotiation Strategies

F1

ROC AUC

Micro Weighted Macro Micro Weighted

25.6

36.3

55.8 61.7

54.7

26.7

42.4

65.3 65.3

60.4

32.1

43.3

68.2 71.8

61.8

34.1

43.5

68.1 73.0

61.8

Macro
20.6 33.0 32.5
33.4

Dialogue Acts

F1

ROC AUC

Micro Weighed Macro Weighed

37.4 30.6 76.9 79.2 46.2 42.8 83.1 84.2 44.6 42.0 85.6 85.1

45.8 43.7 85.6 85.4

strategy prediction macro scores and outperforms it on other metrics. Moreover, both significantly outperform the FST-based based method, prior state-of-the-art. We hypothesize that lower gains for dialogue acts are due to the limited structural dependencies between them. Conversely, we validate that for negotiation strategies, RNNs are significantly worse than DIALOGRAPH. We also observe that higher macro scores show that DIALOGRAPH and Transformers are able to capture the sequences containing the less frequent strategies/dialogue acts as well. These results supports our hypothesis of the importance to encode the structure in a more expressive model. Moreover, DIALOGRAPH also provides interpretable structures which the other baselines do not. We will discuss these findings in §5.
Automatic Evaluation on Downstream tasks: In this section, we analyze the impact of DIALOGRAPH on the downstream task of Negotiation Dialogue based on the automatic evaluation metrics described in §3. In Table 2, we show that DIALOGRAPH helps improve the generation of dialogue response. Even though DIALOGRAPH attains higher BLEU scores, we note that single-reference BLEU assumes only one possible response while dialogue systems can have multiple possible responses to the same utterance. BERTScore alleviates this problem by scoring semantically similar responses equally high (Zhang et al., 2020). We also find that both Transformer and DIALOGRAPH have a comparable performance for negotiation outcome prediction, which is significantly better than the previously published baselines (FeHED and HED+RNN). A higher performance on this metric demonstrates that our model is able to encode the strategy sequence better and consequently predict the negotiation outcome more accurately. Additionally, ablation results in Table 3 show that both strategy and dialogue act information helps DIALOGRAPH in improving dialogue response. The difference in BERTScore F1 scores in Tables 2 and 3 arises due to different metrics chosen for early stopping. More details in Appendix D.
Although, both HED+Transformer and DIALOGRAPH are based on attention mechanisms, DIALOGRAPH has the added advantage of having structural attention which helps encode the pragmatic structure of negotiation dialogues which in turn provides an interpretable interface. The components in our graph based encoder such as the GAT and ASAP layer provide strategy influence and cluster association information which is useful to understand and control negotiation systems. This is described in more detail in §5. Though transformers have self attention, the architecture is limited and doesn't model the structure/dependence between strategies providing only limited understanding. Further, our results show that DIALOGRAPH maintains or improves performance over strong models like Transformer and has much more transparent interpretability. We later show that DIALOGRAPH performs significantly better than HED+Transformer in human evaluation.
Human Evaluation: Since automatic metrics only give us a partial view of the system, we complement our evaluation with detailed human evaluation. For that, we set up DIALOGRAPH and the baselines on Amazon Mechanical Turk (AMT) and asked workers to role-play the buyer and negotiate with a single bot. After their chat is over, we ask them to fill a survey to rate the dialogue on how persuasive (My task partner was persuasive.), coherent (My task partner's responses were on topic and in accordance with the conversation history.), natural (My task partner was humanlike.) and understandable (My task partner perfectly understood what I was typing.) the bot was 7. Prior research in entailment has shown that humans tend to get better as they chat (Mizukami et al., 2016; Benus et al., 2011) and so we restrict one user to chat with just one of the bots. We further
7We use the setup of https://github.com/stanfordnlp/cocoa/. Screenshots in Appendix H.
6

Published as a conference paper at ICLR 2021

Table 2: Downstream evaluation of negotiation dialogue generation and negotiation outcome prediction. The best results (along with all statistically insignificant values to those) are bolded.

Model
HED FeHED HED+RNN HED+Transformer
DIALOGRAPH

BLEU
20.9 23.7 22.5 24.4
24.7

Generation

BERTScore

Precision Recall F1

21.8

22.3 22.1

27.1

26.8 27.0

22.9

22.7 22.8

27.4

28.1 27.7

27.8

28.3 28.1

Outcome
Prediction
RC-Acc
35.2 42.3 47.9 53.7
53.1

Table 3: DIALOGRAPH ablation analysis. This shows that all the different components provide complementary benefits. We also evaluate without BERT for comparison with previously published works.

Model
DIALOGRAPH w/o Strategy (ST) w/o ST, Dialogue Acts (DA) w/o ST, DA, BERT

BERT Score F1
27.4 26.8 26.3 22.7

Seller (Bot)

Hey, you need a router? u1 u2 Yeah, I was looking at the Apple router. Oh, it supports multiple devices ... u3
u4 Great, will it support laptop? Definitely both .... $X and we re square u5 u6 Great! Is there any scratch/damage to it? Nah.. few months only. We re moving... u7

Informal 3rd Person
u3 1

Buyer (Human)

1 1 0.96
Positive
u4

0.01 Trade In

Propose 1
Informal

u5
0.87

0.34 0.37

0.01

1 0.31 1
Positive Concern
u6

Hedge Family u7
0.93

Figure 3: Visualization of the learnt latent strategy sequences in DIALOGRAPH where bolder edges represent higher influence. Here we present only a few edges for brevity and visualize min-max normalized attention values as edge weights to analyze the relative ranking of strategies. For example, for family at u7, informal of u5 has the most influence followed by propose. We present the full attention map for this example in Figure 5 in the Appendix.

prune conversations which were incomplete potentially due to dropped connections. Finally, we manually inspect the conversations extracted from AMT to extract the agreed sale price and remove conversations that were not trying to negotiate at all.
The results of human evaluations of the resulting 90 dialogues (about 20 per model) are presented in Table 4. We find that baselines are more likely to accept unfair offers and apply inappropriate strategies. Additionally, DIALOGRAPH bot attained a significantly higher Sale Price Ratio, which is the outcome of negotiation, showing that effectively modeling strategy sequences leads to more effective negotiation systems. Our model also had a higher average total number of turns and wordsper-turn (for just the bots) compared to all baselines, signifying engagement. It was also more persuasive and coherent while being more understandable to the user. From qualitative inspection we observe that the HED model generates utterances that are shorter and less coherent. They are natural responses like "Yes it is", but generic and contextually irrelevant. We hypothesize that this is due to the HED model not being optimized to encode the sequence of negotiation strategies and dialogue acts. We believe that this is the reason for the high natural score for HED. From manual inspection we see that HED is not able to produce very persuasive responses. We provide an example of a dialogue in Appendix F. We see that although HED+Transformer model performs well, DIALOGRAPH achieves a better sale price outcome as it tries to repeatedly offer deals to negotiate the price. We see that the HED is unable to understand the user responses well and tends to repeat itself. Both the FeHED and HED baselines tend to agree with the buyer's proposal more readily whereas HED+Transformers and DIALOGRAPH provide counter offers and trade-ins to persuade the user.
5 INTERPRETING LEARNED STRATEGY GRAPHS
We visualize the intermediate attention scores generated by the GATs while obtaining the strategy node representations. These attention scores tell us what strategies influenced the representation of a particular strategy and can be used to observe the dependence between strategies (cf. Xie & Lu,
7

Published as a conference paper at ICLR 2021

Table 4: Human evaluation ratings on a scale of 1-5 for various models. We also provide the average sale price ratio (§2.4). Negative ratio means that average sale price was lower than the buyer's target.

Model
HED FeHED HED+RNN HED+Transformer
DIALOGRAPH

Persuasive
2.50 3.30 2.81 3.50
3.58

Coherent
2.50 3.75 3.27 3.50
3.94

Natural
4.50 3.70 3.36 3.70
3.75

Understandable
2.50 3.69 3.27 3.40
3.70

Sale Price Ratio
-2.13 0.25 -3.68 -0.07
0.49

Avg Turns
11.00 14.30 13.90 11.40
15.72

Avg words/turn
4.25 5.76 3.61 4.36
5.84

Table 5: Examples of strategies and their least / highly associated strategies based on association scores extracted using the cluster attention scores given by the ASAP layer.

Negotiation Strategy
concern hedge propose negative sentiment

Least associative strategies
certainty (0.1759), trade in (0.228) trade in (0.4367), pos sentiment (0.4501) factive count (0.3878), family (0.416) trade in (0.3089), informal (0.3644)

Highly associative strategies
politeness please (0.7072), politeness gratitude (0.5859) propose (0.5427) friend (0.6218) politeness gratitude (0.5048), trade in (0.5223) family (0.6363), propose (0.6495)

2019; Norcliffe-Brown et al., 2018). We show an example in Figure 3 where for brevity, we present a subset of few turns and only the top few most relevant edges in the figure. For visualization, we re-scale the attention values for all incoming edges of a node (strategy) using min-max normalization. This is done because the range of raw attention values would differ based on the number of edges and this allows us to normalize any difference in scales and visualize the relative ranking of strategies (Yi et al., 2005; Chen & Liu, 2004). We notice that as soon as the first propose at u5 happens, the strategies completely change and become independent of the strategies before the propose point. From Figure 3, we see that the edge weight from u4 to u6 is 0.01, signifying very low influence. We noticed this trend in other examples as well, wherein, the influence of strategies coming before the first propose turn to strategies coming after that, is very low. A similar phenomenon was also observed by Zhou et al. (2019) who study the conversations by splitting into two parts based on the first propose turn. Another interesting thing we note is that the trade-in and propose strategies at u5 seem to be heavily influenced by informal from u3. Similarly, the informal of u5 was influenced by positive sentiment from u4. This indicates that the seller was influenced by previous informal interactions to propose and trade-in at this turn, and that sellers tend to be more informal if the conversation partner is positive. In other examples, we see that at a particular utterance, different strategies depend on separate past strategies and also observe that the attention maps usually demonstrate the strategy switch as soon as the first propose happens, which is similar to what has been observed by prior work. These examples demonstrate that DIALOGRAPH can model fine-grain strategies, learn dependence beyond just utterances and give interpretable representations, which previous baselines, including the FSTs, lack. Specifically, each state of the FST is explicitly represented by an action distribution which can only be used to see the sequence of strategies and not observe associations or dependence information which DIALOGRAPH provides.
We utilize these cluster attention scores from the ASAP pooling layer to observe the association between various strategies which can help us observe strategies with similar contextual behaviour and structural co-occurrence. We take the average normalized value of the cluster attention scores between two strategies to obtain the association score between them. In Table 5, we show some examples of strategies and their obtained association scores. We observe that negative sentiment tends to be most associated to propose. We hypothesize that this is because that people who disagree more tend to get better deals. We observe that people do not tend to associate negative sentiment with trade-in, which is in-fact highly associated with positive sentiment, because people might want to remain positive while offering something. Similarly, people tend to give vague proposals by hedging, for instance, I could go lower if you can pick it up, than when suggesting trade-in. Concern also seems to be least associated with certainty, and most with politeness-based strategies. Thus, we observe that our model is able to provide meaningful insights which corroborate prior observations, justifying its ability to learn strategy associations well.
8

Published as a conference paper at ICLR 2021
6 RELATED WORK
Dialogue Systems: Goal-oriented dialogue systems have a long history in the NLP community. Broadly, goal-oriented dialogue can be categorized into collaborative and non-collaborative systems. The aim of agents in a collaborative setting is to achieve a common goal, such as travel and flight reservation (Wei et al., 2018) and information-seeking (Reddy et al., 2019). Recent years have seen a rise in non-collaborative goal-oriented dialogue systems such as persuasion (Wang et al., 2019; Dutt et al., 2020; 2021), negotiation (He et al., 2018; Lewis et al., 2017) and strategy games (Asher et al., 2016) due to the challenging yet interesting nature of the task. Prior work has also focused on decision-making games such as Settlers of Catan (Cuaya´huitl et al., 2015) which mainly involve decision-making skills rather than communication. Lewis et al. (2017) developed the DealOrNoDeal dataset in which agents had to reach a deal to split a set of items. Extensive work has been done on capturing the explicit semantic history in dialogue systems (Kumar et al., 2020; Vinyals & Le, 2015; Zhang et al., 2018). Recent work has shown the advantage of modeling the dialogue history in the form of belief span (Lei et al., 2018) and state graphs (Bowden et al., 2017). He et al. (2018) proposed a bargaining scenario that can leverage semantic and strategic history. Zhou et al. (2020) used unsupervisedly learned FSTs to learn dialogue structure. This approach, however, although effective in explicitly incorporating pragmatic strategies, does not leverage the expressive power of neural networks. Our model, in contrast, combines the interpretablity of graph-based approaches and the expressively of neural networks, improving the performance and interpretability of negotiation agents.
Graph Neural Networks: The effectiveness of GNNs (Bruna et al., 2013; Defferrard et al., 2016; Kipf & Welling, 2017) has been corroborated in several NLP applications (Vashishth et al., 2019), including semantic role labeling (Marcheggiani & Titov, 2017), machine translation (Bastings et al., 2017), relation extraction (Vashishth et al., 2018), and knowledge graph embeddings (Schlichtkrull et al., 2018; Vashishth et al., 2020). Hierarchical graph pooling based structure encoders have been successful in encoding graphical structures (Zhang et al., 2019). We leverage the advances in GNNs and propose to use a graph-based explicit structure encoder to model negotiation strategies. Unlike HMM and FST based encoders, GNN-based encoders can be trained by optimizing the downstream loss and have superior expressive capabilities. Moreover, they provide better interpretability of the model as they can be interpreted based on observed explicit sequences (Tu et al., 2020; NorcliffeBrown et al., 2018). In dialogue systems, graphs have been used to guide dialogue policy and response selection. However, they have been used to encode external knowledge (Tuan et al., 2019; Zhou et al., 2018) or speaker information (Ghosal et al., 2019), rather than compose dialogue strategies on-the-fly. Other works (Tang et al., 2019; Qin et al., 2020) focused on keyword prediction using RNN-based graphs. Our work is the first to incorporate GATs with hierarchical pooling, learning pragmatic dialogue strategies jointly with the end-to-end dialogue system. Unlike in prior work, our model leverages hybrid end-to-end and modularized architectures (Liang et al., 2020; Parvaneh et al., 2019) and can be plugged as explicit sequence encoder into other models.
7 CONCLUSION
We present DIALOGRAPH, a novel modular negotiation dialogue system which models pragmatic negotiation strategies using Graph Attention Networks with hierarchical pooling and learns an explicit strategy graph jointly with the dialogue history. DIALOGRAPH outperforms strong baselines in downstream dialogue generation, while providing the capability to interpret and analyze the intermediate graph structures and the interactions between different strategies contextualized in the dialogue. As future work, we would like to extend our work to discover successful (e.g.: good for the seller) and unsuccessful strategy sequences using our interpretable graph structures.
ACKNOWLEDGMENTS
The authors are grateful to the anonymous reviewers for their invaluable feedback, and to Alissa Ostapenko, Shruti Rijhwani, Ritam Dutt, and members of the Tsvetshop at CMU for their helpful feedback on this work. The authors would also like to thank Yiheng Zhou for helping with negotiation strategy extraction and FeHED model. This material is based upon work supported by the National Science Foundation under Grant No. IIS2007960 and by the Google faculty research award. We would also like to thank Amazon for providing GPU credits.
9

Published as a conference paper at ICLR 2021
REFERENCES
Nicholas Asher, Julie Hunter, Mathieu Morey, Benamara Farah, and Stergos Afantenos. Discourse structure and dialogue acts in multiparty dialogue: the STAC corpus. In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16), pp. 2721­ 2727, Portoroz, Slovenia, May 2016. European Language Resources Association (ELRA). URL https://www.aclweb.org/anthology/L16-1432.
Joost Bastings, Ivan Titov, Wilker Aziz, Diego Marcheggiani, and Khalil Sima'an. Graph convolutional encoders for syntax-aware neural machine translation. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 1957­1967, Copenhagen, Denmark, September 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1209. URL https://www.aclweb.org/anthology/D17-1209.
Max H Bazerman and Margaret Ann Neale. Negotiating rationally. Simon and Schuster, 1993.
Max H Bazerman, Jared R Curhan, Don A Moore, and Kathleen L Valley. Negotiation. Annual review of psychology, 51(1):279­314, 2000a.
Max H. Bazerman, Jared R. Curhan, Don A. Moore, and Kathleen L. Valley. Negotiation. Annual Review of Psychology, 51(1):279­314, 2000b. doi: 10.1146/annurev.psych.51.1.279. URL https://doi.org/10.1146/annurev.psych.51.1.279. PMID: 10751973.
S tefan Benus, Agust´in Gravano, and Julia Hirschberg. Pragmatic aspects of temporal accommodation in turn-taking. Journal of Pragmatics, 43(12):3001­3027, 2011.
Taylor Berg-Kirkpatrick, David Burkett, and Dan Klein. An empirical investigation of statistical significance in NLP. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pp. 995­1005, Jeju Island, Korea, July 2012. Association for Computational Linguistics. URL https://www. aclweb.org/anthology/D12-1091.
Kevin K Bowden, Shereen Oraby, Jiaqi Wu, Amita Misra, and Marilyn Walker. Combining search with structured data to create a more engaging user experience in open domain dialogue. ICTIR' 17 Workshop on Search-Oriented Conversational AI (SCAI' 2017), 2017.
Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. Spectral networks and locally connected networks on graphs. CoRR, abs/1312.6203, 2013. URL http://arxiv.org/ abs/1312.6203.
Keke Chen and Ling Liu. Clustermap: Labeling clusters in large datasets via visualization. In Proceedings of the Thirteenth ACM International Conference on Information and Knowledge Management, CIKM '04, pp. 285­293, New York, NY, USA, 2004. Association for Computing Machinery. ISBN 1581138741. doi: 10.1145/1031171.1031233. URL https://doi.org/ 10.1145/1031171.1031233.
Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder­decoder for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1724­1734. Association for Computational Linguistics, 2014. doi: 10.3115/v1/D14-1179. URL http://www.aclweb.org/anthology/ D14-1179.
Heriberto Cuaya´huitl, Simon Keizer, and Oliver Lemon. Strategic dialogue management via deep reinforcement learning. NIPS'15 Workshop on Deep Reinforcement Learning, 2015.
Michae¨l Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. CoRR, abs/1606.09375, 2016. URL http: //arxiv.org/abs/1606.09375.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language
10

Published as a conference paper at ICLR 2021
Technologies, Volume 1 (Long and Short Papers), pp. 4171­4186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https: //www.aclweb.org/anthology/N19-1423.
Ritam Dutt, Rishabh Joshi, and Carolyn Rose. Keeping up appearances: Computational modeling of face acts in persuasion oriented discussions. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 7473­7485, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.605. URL https://www.aclweb.org/anthology/2020.emnlp-main.605.
Ritam Dutt, Sayan Sinha, Rishabh Joshi, Surya Shekhar Chakraborty, Meredith Riggs, Xinru Yan, Haogang Bao, and Carolyn Penstein Rose´. Resper: Computationally modelling resisting strategies in persuasive conversations. In 16th Conference of the European Chapter of the Association for Computational Linguistics (EACL), 2021.
Roger Fisher, William L Ury, and Bruce Patton. Getting to yes: Negotiating agreement without giving in. Penguin, 2011.
Deepanway Ghosal, Navonil Majumder, Soujanya Poria, Niyati Chhaya, and Alexander Gelbukh. DialogueGCN: A graph convolutional neural network for emotion recognition in conversation. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 154­164, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1015. URL https://www.aclweb.org/anthology/D19-1015.
He He, Derek Chen, Anusha Balakrishnan, and Percy Liang. Decoupling strategy and generation in negotiation dialogues. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018. URL https://www-nlp.stanford.edu/pubs/ he2018decouple.pdf.
Wenxiang Jiao, Haiqin Yang, Irwin King, and Michael R. Lyu. HiGRU: Hierarchical gated recurrent units for utterance-level emotion recognition. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 397­406, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1037. URL https://www.aclweb.org/anthology/N19-1037.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2014.
Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations (ICLR), 2017.
Philipp Koehn. Statistical significance tests for machine translation evaluation. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pp. 388­395, Barcelona, Spain, July 2004. Association for Computational Linguistics. URL https://www. aclweb.org/anthology/W04-3250.
Gaurav Kumar, Rishabh Joshi, Jaspreet Singh, and Promod Yenigalla. AMUSED: A multi-stream vector representation method for use in natural dialogue. In Proceedings of The 12th Language Resources and Evaluation Conference, pp. 750­758, Marseille, France, May 2020. European Language Resources Association. ISBN 979-10-95546-34-4. URL https://www.aclweb. org/anthology/2020.lrec-1.94.
George Larionov, Zachary Kaden, Hima Varsha Dureddy, Gabriel Bayomi T Kalejaiye, Mihir Kale, Srividya Pranavi Potharaju, Ankit Parag Shah, and Alexander I Rudnicky. Tartan: A retrieval-based socialbot powered by a dynamic finite-state machine architecture. arXiv preprint arXiv:1812.01260, 2018.
David A Lax and James K Sebenius. 3-D Negotiation: Powerful tools to change the game in your most important deals. Harvard Business Press, 2006.
11

Published as a conference paper at ICLR 2021
Junhyun Lee, Inyeop Lee, and Jaewoo Kang. Self-attention graph pooling. In Proceedings of the 36th International Conference on Machine Learning, 09­15 Jun 2019.
Wenqiang Lei, Xisen Jin, Min-Yen Kan, Zhaochun Ren, Xiangnan He, and Dawei Yin. Sequicity: Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1437­1447, Melbourne, Australia, July 2018. Association for Computational Linguistics. doi: 10.18653/v1/P18-1133. URL https://www.aclweb.org/anthology/ P18-1133.
Mike Lewis, Denis Yarats, Yann Dauphin, Devi Parikh, and Dhruv Batra. Deal or no deal? endto-end learning of negotiation dialogues. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 2443­2453, Copenhagen, Denmark, September 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1259. URL https: //www.aclweb.org/anthology/D17-1259.
Jiwei Li, Michel Galley, Chris Brockett, Georgios Spithourakis, Jianfeng Gao, and Bill Dolan. A persona-based neural conversation model. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 994­1003, Berlin, Germany, August 2016. Association for Computational Linguistics. doi: 10.18653/v1/P16-1094. URL https://www.aclweb.org/anthology/P16-1094.
Yu Li, Kun Qian, Weiyan Shi, and Zhou Yu. End-to-end trainable non-collaborative dialog system. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The ThirtySecond Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, pp. 8293­8302. AAAI Press, 2020. URL https://aaai.org/ojs/ index.php/AAAI/article/view/6345.
Weixin Liang, Youzhi Tian, Chengcai Chen, and Zhou Yu. MOSS: end-to-end dialog system framework with modular supervision. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, pp. 8327­8335. AAAI Press, 2020. URL https://aaai.org/ojs/index.php/AAAI/article/view/6349.
Diego Marcheggiani and Ivan Titov. Encoding sentences with graph convolutional networks for semantic role labeling. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 1506­1515, Copenhagen, Denmark, September 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1159. URL https://www.aclweb. org/anthology/D17-1159.
Masahiro Mizukami, Koichiro Yoshino, Graham Neubig, David Traum, and Satoshi Nakamura. Analyzing the effect of entrainment on dialogue acts. In Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pp. 310­318, Los Angeles, September 2016. Association for Computational Linguistics. doi: 10.18653/v1/W16-3640. URL https: //www.aclweb.org/anthology/W16-3640.
Will Norcliffe-Brown, Stathis Vafeias, and Sarah Parisot. Learning conditioned graph structures for interpretable visual question answering. In Advances in neural information processing systems, pp. 8334­8343, 2018.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311­318, Philadelphia, Pennsylvania, USA, July 2002. Association for Computational Linguistics. doi: 10.3115/1073083.1073135. URL https: //www.aclweb.org/anthology/P02-1040.
Amin Parvaneh, Ehsan Abbasnejad, Qi Wu, and Javen Shi. Show, price and negotiate: A hierarchical attention recurrent visual negotiator. CoRR, abs/1905.03721, 2019. URL http://arxiv. org/abs/1905.03721.
12

Published as a conference paper at ICLR 2021
P. E. Pope, S. Kolouri, M. Rostami, C. E. Martin, and H. Hoffmann. Explainability methods for graph convolutional neural networks. In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10764­10773, 2019.
Dean G Pruitt. Negotiation behavior. Academic Press, 2013.
Jinghui Qin, Zheng Ye, Jianheng Tang, and Xiaodan Liang. Dynamic knowledge routing network for target-guided open-domain conversation. Proceedings of the AAAI Conference on Artificial Intelligence, 34(05):8657­8664, Apr 2020. ISSN 2159-5399. doi: 10.1609/aaai.v34i05.6390. URL http://dx.doi.org/10.1609/aaai.v34i05.6390.
Ekagra Ranjan, Soumya Sanyal, and Partha P. Talukdar. ASAP: adaptive structure aware pooling for learning hierarchical graph representations. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, pp. 5470­5477. AAAI Press, 2020. URL https://aaai.org/ojs/index.php/AAAI/article/view/5997.
Siva Reddy, Danqi Chen, and Christopher D. Manning. CoQA: A conversational question answering challenge. Transactions of the Association for Computational Linguistics, 7:249­266, March 2019. doi: 10.1162/tacl a 00266. URL https://www.aclweb.org/anthology/ Q19-1016.
Alan Ritter, Colin Cherry, and Bill Dolan. Unsupervised modeling of twitter conversations. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pp. 172­180, Los Angeles, California, June 2010. Association for Computational Linguistics. URL https://www.aclweb.org/anthology/ N10-1020.
M. Schlichtkrull, Thomas Kipf, P. Bloem, R. V. Berg, Ivan Titov, and M. Welling. Modeling relational data with graph convolutional networks. In ESWC, 2018.
Weiyan Shi, Tiancheng Zhao, and Zhou Yu. Unsupervised dialog structure learning. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 1797­1807, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/ v1/N19-1178. URL https://www.aclweb.org/anthology/N19-1178.
Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji, Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. A neural network approach to context-sensitive generation of conversational responses. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 196­205, Denver, Colorado, May­June 2015. Association for Computational Linguistics. doi: 10.3115/v1/N15-1020. URL https://www.aclweb.org/anthology/N15-1020.
Jianheng Tang, Tiancheng Zhao, Chenyan Xiong, Xiaodan Liang, Eric Xing, and Zhiting Hu. Targetguided open-domain conversation. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 5624­5634, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1565. URL https://www.aclweb.org/ anthology/P19-1565.
Leigh L Thompson. The mind and heart of the negotiator, volume 3.
Ming Tu, Kevin Huang, Guangtao Wang, Jing Huang, Xiaodong He, and Bowen Zhou. Select, answer and explain: Interpretable multi-hop reading comprehension over multiple documents. In AAAI 2020 (accepted), 2020.
Yi-Lin Tuan, Yun-Nung Chen, and Hung-yi Lee. DyKgChat: Benchmarking dialogue generation grounding on dynamic knowledge graphs. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 1855­1865, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1194. URL https://www. aclweb.org/anthology/D19-1194.
13

Published as a conference paper at ICLR 2021
Shikhar Vashishth, Rishabh Joshi, Sai Suman Prayaga, Chiranjib Bhattacharyya, and Partha Talukdar. RESIDE: Improving distantly-supervised neural relation extraction using side information. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1257­1266, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. URL http://aclweb.org/anthology/D18-1157.
Shikhar Vashishth, Naganand Yadati, and Partha Talukdar. Graph-based deep learning in natural language processing. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): Tutorial Abstracts, Hong Kong, China, November 2019. Association for Computational Linguistics.
Shikhar Vashishth, Soumya Sanyal, Vikram Nitin, and Partha Talukdar. Composition-based multirelational graph convolutional networks. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=BylA_C4tPr.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, L ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems 30, pp. 5998­6008. Curran Associates, Inc., 2017. URL http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf.
Petar Velickovic´, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio`, and Yoshua Bengio. Graph Attention Networks. International Conference on Learning Representations, 2018. URL https://openreview.net/forum?id=rJXMpikCZ. accepted as poster.
Oriol Vinyals and Quoc Le. A neural conversational model. arXiv preprint arXiv:1506.05869, 2015.
Xuewei Wang, Weiyan Shi, Richard Kim, Yoojung Oh, Sijia Yang, Jingwen Zhang, and Zhou Yu. Persuasion for good: Towards a personalized persuasive dialogue system for social good. arXiv preprint arXiv:1906.06725, 2019.
Wei Wei, Quoc Le, Andrew Dai, and Jia Li. AirDialogue: An environment for goal-oriented dialogue research. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 3844­3854, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1419. URL https://www.aclweb. org/anthology/D18-1419.
Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S. Yu. A comprehensive survey on graph neural networks. IEEE Transactions on Neural Networks and Learning Systems, pp. 1­21, 2020. ISSN 2162-2388. doi: 10.1109/tnnls.2020.2978386. URL http://dx.doi.org/10.1109/TNNLS.2020.2978386.
Shangsheng Xie and Mingming Lu. Interpreting and Understanding Graph Convolutional Neural Network using Gradient-based Attribution Method. arXiv e-prints, art. arXiv:1903.03768, March 2019.
Ji Soo Yi, Rachel Melton, John Stasko, and Julie A. Jacko. Dust & magnet: Multivariate information visualization using a magnet metaphor. Information Visualization, 4(4):239­ 256, 2005. doi: 10.1057/palgrave.ivs.9500099. URL https://doi.org/10.1057/ palgrave.ivs.9500099.
Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. Hierarchical graph representation learning with differentiable pooling. In Advances in neural information processing systems, pp. 4800­4810, 2018.
S. Young. Using pomdps for dialog management. In 2006 IEEE Spoken Language Technology Workshop, pp. 8­13, 2006.
Ke Zhai and Jason D. Williams. Discovering latent structure in task-oriented dialogues. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 36­46, Baltimore, Maryland, June 2014. Association for Computational Linguistics. doi: 10.3115/v1/P14-1004. URL https://www.aclweb.org/anthology/ P14-1004.
14

Published as a conference paper at ICLR 2021
Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. Personalizing dialogue agents: I have a dog, do you have pets too? In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2204­2213, Melbourne, Australia, July 2018. Association for Computational Linguistics. doi: 10.18653/v1/P18-1205. URL https://www.aclweb.org/anthology/P18-1205.
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. Bertscore: Evaluating text generation with bert. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=SkeHuCVFDr.
Zhen Zhang, Jiajun Bu, Martin Ester, Jianfeng Zhang, Chengwei Yao, Zhi Yu, and Can Wang. Hierarchical graph pooling with structure learning. arXiv preprint arXiv:1911.05954, 2019.
Hao Zhou, Tom Young, Minlie Huang, Haizhou Zhao, Jingfang Xu, and Xiaoyan Zhu. Commonsense knowledge aware conversation generation with graph attention. In Proceedings of the 27th International Joint Conference on Artificial Intelligence, IJCAI'18, pp. 4623­4629. AAAI Press, 2018. ISBN 9780999241127.
Yiheng Zhou, He He, Alan W Black, and Yulia Tsvetkov. A dynamic strategy coach for effective negotiation. In Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue, pp. 367­378, Stockholm, Sweden, September 2019. Association for Computational Linguistics. doi: 10.18653/v1/W19-5943. URL https://www.aclweb.org/anthology/W19-5943.
Yiheng Zhou, Yulia Tsvetkov, Alan W Black, and Zhou Yu. Augmenting non-collaborative dialog systems with explicit semantic and strategic dialog history. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=ryxQuANKPB.
15

Published as a conference paper at ICLR 2021

A DIALOGUE ACTS
Here we provide the details about the dialogue acts that we have used to annotate the utterances. 10 are taken from He et al. (2018) and 4 are based on the actions taken by the users. The rule based acts are extracted using the code provided by them8. The details are in Table 6.
Table 6: The list of dialogue acts that we use to annotate the data.

Meaning
Greetings Ask a question Propose the first price Proposing a counter price Unknown Agree with the proposal Disagree with a proposal Answer a question Using comparatives with existing price Insist on an offer Offer the price Accept the offer Reject the offer Quit the session

Dialogue Act
intro inquiry init-price counter-price unknown agree disagree inform vague-price insist offer accept reject quit

Example
I would love to buy Sure, what's your price I'm on a budget so i could do $5 How about $15 and I'll waive the deposit Hmm, let me think That works for me Sorry I can't agree to that This bike is brand new That offer is too low Still can I buy it for $ 5. I'm on a tight budget

Detector
rule rule rule rule rule rule rule rule rule rule agent action agent action agent action agent action

B NEGOTIATION STRATEGIES
Here we provide the details about the 15 Negotiation Strategies (Zhou et al., 2019) and 21 Negotiation Strategies (Zhou et al., 2020) in Tables 7 and 8.
Table 7: The details of 15 Negotiation Strategies proposed by Zhou et al. (2019).

High level Negotiation Rules Focus on interests, not positions
Invent options for mutual gain Build Trust Insist on your position

Sub Strategy
Describe Product Rephrase product Embellish product Address concerns Communicate interests Propose Price Do not propose first Negotiate side offers Hedge Communicate Politely Build rapport Talk informally Show dominance Negative Sentiment Certainty words

Example
The car has leather seats 45k miles - less than 50k miles a luxury car with attractive leather seats I've just taken it to maintenance I'd like to sell it asap. How about 9k? n/a I can deliver it for you I could come down a bit Greetings, gratitude, apology, please My kid really liked this bike, but he outgrew it Absolutely, ask away! The absolute highest I can do is 640 Sadly, I simply cannot go under 500 It has always had a screen protector

Detector
classifier classifier classifier classifier classifier classifier rule rule rule rule rule rule rule rule rule

8https://github.com/stanfordnlp/cocoa/ 16

Published as a conference paper at ICLR 2021

Negotiation Strategies
first person singular count pos sentiment number of diff dic pos third person singular hedge count number of diff dic neg personal concern propose politeness greet assertive count neg sentiment factive count politeness gratitude first person plural count liwc certainty liwc informal third person plural trade in politeness please family friend <start>

Train set frequency
26,121 24,862 18,610 17,000 12,227 10,402 9,135
8,449 6,639 4,437 3,680 3,429 3,171 2,876 2,530 2,396 1,721
883 372 201 149 5,383

Table 8: The details of 21 Negotiation Strategies (<start> added by us) used by Zhou et al. (2020). These are used to operationalize the 15 strategies using a rule based system (https: //github.com/zhouyiheng11/augmenting-non-collabrative-dialog/). The frequency statistics on the train set (5383 conversations) is given. A detailed description regarding the rules used by prior work to extract these are out of scope of this work, however, we intend to provide the code and extracted strategies, along with the rule based mapping to the 15 strategies upon acceptance of this work.

C STRATEGY-GRAPH VISUALIZATION

A visualization of a strategy sequence graph. Refer to §2.2 for more details. We also provide additional details regarding the number of nodes and edges in our strategy graphs in Table 9.

u2 Greet

u4
Dominant

u6
Affirmative

Customer

Seller (Bot)

Greet u1

Polite Appeal u3

Build Rapport
Sentiment
u5

Thanks u7

Figure 4: Visualization of a strategy sequence graph. The graph connects each strategy with all previously occurring strategies. Here we present only a few edges for brevity. For example, there would be two more additional edges from u4 to the strategies of u5.

17

Published as a conference paper at ICLR 2021

Table 9: We report the number of nodes and edges in our strategy-graphs. Each node corresponds to a particular utterance-strategy pair.

Feature
Max no. of nodes in graph (total strategies) Avg no. of nodes in graph Max no. of edges in graph Avg no. of edges in graph

Value
86 21 3589 308

D HYPERPARAMETERS

We present the hyper-parameters for all the experiments, their corresponding search space and their final values in Table 10. We also present additional details of our experiments below. We use most of the hyperparameters from Zhou et al. (2020). Each training run took at most 3 hours on a single Nvidia GeForce GTX 1080Ti GPU and all the models were saved based on Strategy Macro F1 performance.
For experiments for Table 1 and 2 we saved the best models on best Strategy Macro F1 performance (HED being saved on outcome class prediction). This is because we wanted to prioritize and optimize our final model to capture sequence-structural information owing to our focus on interpretability. While performing ablation studies for Table 3, not all models have structure encoders, and hence for a fair comparison we chose a metric independent of the different modules for all the models in ablations. We use the negotiation outcome class prediction (RC-Acc) scores as that optimizes the dialogue for good negotiation outcome, which indirectly helps train the model to capture the sequence of strategies.
Table 10: Here we describe the search-space of all the hyper-parameters used in our experiments.

Model
All All All All All All All All All All All All All HED+RNN HED+Transformer HED+Transformer HED+Transformer HED+Transformer DIALOGRAPH DIALOGRAPH DIALOGRAPH DIALOGRAPH

Hyper-parameter
BERT BERT Dropout Dialogue context embedding Dialogue context dropout learning-rate (lr) max utterances in batch weighted strategy loss decay rate (l2) loss alpha loss beta loss gamma projection layers for strategy projection layers for DA hidden size hidden size decoder layers attention heads dropout ASAP pooling ratio hidden dim Graph layers Graph dropout

Search space
5e-3, 1e-3, 5e-4 64,128,256 True,False 1,5 64, 300 64,300 1,2 0.0, 0.1 0.2,0.5,0.8 64,128 1,2,3 0.0,0.2

Final Value
bert-base-uncased no fine tuning 0.3 300 0.1 1e-3 128 True 1e-3 1 10 10 64 64 64 300 6 2 0.0 0.8 64 2 0.0

18

Published as a conference paper at ICLR 2021

E NEGOTIATION DATASET STATISTICS

In Table 11 we provide the CraiglistBargain dataset statistics along with data sizes after filtering conversations with less than 5 turns. The maximum and average number of turns in any conversation is 47 and 9.2 respectively. Also, the maximum and average number of strategies in an utterance is 13 and 3 respectively.

Table 11: Dataset statistics.

Data split
Train conversations Valid conversations Test conversations Filtered train conversations Filtered valid conversations Filtered test conversations Vocabulary size

Size
5383 643 656
4828 561 567
13339

F EXAMPLE CONVERSATIONS

Table 12: Examples of the generated dialogues of various models when we keep the buyer utterances same. We see that DIALOGRAPH gets the best deal for the same dialogue context and is more persistent. The FeHED and HED models accept offers more readily. We provide more examples of DIALOGRAPH in Table 13.

Listing Price: 40 Buyer's Target Price: 36 Title: 2017 NEW Stans 24 and 26 Tubeless Tire Kit
: DIALOGRAPH : Human
: Hello : Hi. Is the tire kit new? : Yes it is. : Great. My bro destroyed my old kit and I'm looking for new tires. : I am asking 40 for it. : That's too much for a student like me. How about 35? : I can't go that low. I could do 38.8 and I will deliver it to you. : I can come pick it up for 36. : I can do 37.2 and you have a deal. : Okay great. Thanks. < offer > 37.2
: FeHED : Human
: Hello : Hi. Is the tire kit new? : Hi there! Are you interested in the bike? : Great. My bro destroyed my old kit and I'm looking for new tires. : I am asking 40 for it. : That's too much for a student like me. How about 35? : I can do that. : Okay great. Thanks. < offer > 35
Final Deal: Graph = 37.2, Trans = 36, FeHED = 35, HED = 35

: HED+Transformer : Human
: Hello : Hi. Is the tire kit new? : Yes it is. : Great. My bro destroyed my old kit and I'm looking for new tires. : I am asking 40 for it. : That's too much for a student like me. How about 35? : I can't go that low. I could do 38 and throw in a warranty. : I can come pick it up for 36. : I can do that. : Okay great. Thanks. < offer > 36
: HED : Human
: Hello : Hi. Is the tire kit new? : Yes it is. : Great. My bro destroyed my old kit and I'm looking for new tires. : Yes it is. : That's too much for a student like me. How about 35? : I can do that. : Okay great. Thanks. < offer > 35

19

Published as a conference paper at ICLR 2021
Table 13: More examples of the generated dialogues of DIALOGRAPH.
Listing Price: 40 Buyer's Target Price: 36 Title: 2017 NEW Stans 24 and 26 Tubeless Tire Kit
: DIALOGRAPH : Human : Hello : Hi. : Are you interested in the kit? : Yes I am interested. : I am looking for 40 for it. : No I am willing to pay 35 for it. : I can't go that low : What can you take? : I could do 38.8 and I will deliver it to you. : I only have 36 please. : I can do 37.2 and you can pick it up yourself. : Sorry i only have 36 : I can do that. : Okay thank you. : < offer > 37.2 : Hello : Hi how are you. : I am good. : Is the kit good? : yes it is. : are you sure? : yes. i am willing to negotiate the price. : okay how much you willing to sell. : it is in great condition. i am asking 40 for it. : i will give you 25. : i can do 38.8 and you can pick it up. : 35 : i can do 37.2 and you can pick it up. : 36 last : ok i can do that. : < offer > 36 : Hello : Hi : Hi i see you are interested in my apartment : i was interested in the tire kit : i m asking 40 for it. : would you be able to do 35? : i m willing to negotiate a little bit. what is your budget? : the highest i can go is 36 : i cant go that low i could do 38.8 : okay that works : < offer > 38.8
G INFLUENCE VISUALIZATION
Refer to Figure 5.
20

Published as a conference paper at ICLR 2021
Figure 5: Visualization of the attention map learned by DIALOGRAPH for the example depicted in Figure 3 in the main paper. We only show it for a few turns for brevity. Here the axis labels represent the turn and the strategy. Refer to the Figure 3 in the main paper for description.
H HUMAN EVALUATION INTERFACE
Figure 6: Screenshot of the introduction for the human evaluation interface. 21

Published as a conference paper at ICLR 2021 Figure 7: Screenshot of the chat window for the human evaluation interface.
Figure 8: Screenshot of the survey for the human evaluation interface. 22

