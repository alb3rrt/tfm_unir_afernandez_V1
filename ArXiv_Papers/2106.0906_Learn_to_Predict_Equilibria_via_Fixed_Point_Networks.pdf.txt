Learn to Predict Equilibria via Fixed Point Networks

arXiv:2106.00906v1 [cs.LG] 2 Jun 2021

Howard Heaton,,1Daniel McKenzie,,1Qiuwei Li1, Samy Wu Fung1, Stanley Osher1, Wotao Yin2

1Department of Mathematics

2Damo Academy

University of California, Los Angeles

Alibaba US

Abstract
Systems of interacting agents can often be modeled as contextual games, where the context encodes additional information, beyond the control of any agent (e.g. weather for traffic and fiscal policy for market economies). In such systems, the most likely outcome is given by a Nash equilibrium. In many practical settings, only game equilibria are observed, while the optimal parameters for a game model are unknown. This work introduces Nash Fixed Point Networks (N-FPNs), a class of implicit-depth neural networks that output Nash equilibria of contextual games. The N-FPN architecture fuses data-driven modeling with provided constraints. Given equilibrium observations of a contextual game, N-FPN parameters are learnt to predict equilibria outcomes given only the context. We present an end-to-end training scheme for N-FPNs that is simple and memory efficient to implement with existing autodifferentiation tools. N-FPNs also exploit a novel constraint decoupling scheme to avoid costly projections. Provided numerical examples show the efficacy of N-FPNs on atomic and non-atomic games (e.g. traffic routing).2

1 Introduction

Many recent works in deep learning have highlighted the power of using end-to-end learning in conjunction with known analytic models and constraints [9, 13, 16, 30, 34, 36, 37]. This best-of-both worlds approach fuses the flexibility of learning-based approaches with the interpretability of models derived by domain experts. Moreover, hard-coding constraints into a data-driven algorithm can be used to guarantee safety and fairness. We further this line of research by proposing a new framework for learning to predict the outcomes of contextual (i.e. parametrized) multi-player games from historical data while respecting constraints on players' actions.

1

2

=

3

Utilization ­ 250% ­ 125% ­ 0%
4

1

2

=

3

4

Width shows edge capacity

Figure 1: Proposed N-FPNs can predict traffic flow given contextual information (e.g. weather). For example, road capacities reduce on rainy days and light/dark red edges show light/heavy traffic.

Many social systems can profitably be analyzed as games, including competitive market economies [4], traffic routing [51], anti-poaching initiatives [54] and deployment of security resources [42]. Loosely speaking, any situation with multiple intelligent agents attempting to achieve conflicting aims may be viewed through a game-theoretic lens. Games with parameters depending on contextual information d that is beyond the control of the players are called contextual games [48]. For example, in traffic routing d may encode factors like weather, local sporting events or tolls influencing players' (i.e. drivers') commutes.
Equal contribution 2Codes are available on Github: github.com/howardheaton/nash_fixed_point_networks

Preprint. Under review.

Attribute Output is Equilibria
Data-Driven Constraint Decoupling
Simple Backprop

Analytic NA

Traditional

Existing Implicit

Proposed N-FPNs

Table 1: Comparison of different equilibria prediction methods. Analytic modeling algorithms yield VI solutions that are not data-driven. Traditional feed-forward networks are data-driven and easy to train, but may not output a VI solution. Existing VI-based implicit models are nontrivial to train (backpropagate) and require intricate forward propagation.

Game-theoretic analyses frequently assume players' cost functions are known a priori and seek to predict how players will act, typically by computing a Nash equilibrium [39]. Informally, a Nash equilibrium is a choice of strategy for each player such that no player can improve their outcomes by unilaterally deviating from this strategy. We consider the problem of predicting equilibria, given only contextual information, without knowing the players' cost functions. Although the players' cost functions are unknown, historical data pairs (d, xd) can be utilized, consisting of contexts d and the resulting equilibrium xd [9, 34, 36, 37, 57]. This work proposes a new framework: Nash Fixed Point Networks (N-FPNs). Each N-FPN "learns to predict the appropriate game from context and then output game equilibria" by defining a tunable operator with fixed points that coincide with Nash equilibria. Forward propagation in N-FPNs is formed by repeated application of the operator until a fixed point condition is satisfied. Thus, by construction, N-FPNs are implicit-depth models -- neural networks containing an arbitrary number of layers [5, 21, 22, 53] -- and the operator weights can be efficiently trained using Jacobian-free backpropagation [21]. Importantly, N-FPNs can also avoid direct, costly projections onto sets of constraints for players' actions, which is the computational bottleneck of multiple prior works [34, 36, 37].
Our framework applies equally to atomic games (i.e. the set of players is finite) and certain nonatomic games, particularly traffic routing [45]. As pointed out in [34, 36], learning to predict players' behaviours given the context is an important first step in manipulating the game towards a desirable outcome. For example, in traffic routing problems a central controller may seek to discourage motorists from over-utilizing a road through a quiet neighborhood. Using our framework, and sufficient historical data, this hypothetical controller could predict the effect that exogenous variables (e.g. weather, a local sporting event) will have on traffic flow and then take corrective measures (e.g. increasing tolls) to decrease the predicted flow along this residential road.
Contributions We provide a scalable data-driven framework for efficiently predicting equilibria in systems modeled as contextual games. Specifically, we contribute the following.
Provide an end-to-end trained N-FPN architecture that outputs game equilibria. Present a scheme with decoupled constraints, giving easy forward and backward propagation. Demonstrate empirically the efficacy of N-FPNs on large-scale traffic routing problems. Create a contextual traffic routing benchmark dataset and TRAFIX scoring system.
2 Preliminaries
To establish notation, we begin with a review of variational inequalities (VI). VIs formally characterize equilibria. This formulation is then used to describe Nash equilibria in games.
2.1 Variational Inequalities
We adopt the following notation and naming conventions. The action space is denoted by X , which is a finite dimensional Hilbert space3. The data space is denoted by D and may take the form of any set (e.g. a Hilbert space, Boolean and/or categorical values). For closed and convex set C  X , the
3Throughout, we use ·, · , and · to denote all scalar products and norms, respectively.
2

projection PC onto C is given by PC(x) argminyC y - x 2. Also, C : X  R  {+} denotes the indicator function defined such that C(x) = 0 in C and + elsewhere. The subgradient of the indicator function (also known as the normal cone of C) is denoted by C. Throughout this work, all
sets are assumed to be closed, convex and nonempty. The following definitions describe this work's
primary operator F of interest and the problem used to model equilibria.

Definition 2.1 (Monotonicity). For  > 0, d  D, and a mapping F : X × D  X , if

F (x; d) - F (y; d), x - y   F (x; d) - F (y; d) 2, for all x, y  X ,

(1)

then F (· ; d) is -cocoercive4. If (1) holds taking  = 0, then F (· ; d) is monotone.

Definition 2.2 (VI Problem). Given d  D, find xd  C (called a solution of the VI) such that

F (xd; d), x - xd  0, for all x  C.

(2)

The solution set to this VI problem is denoted by VI(F (· ; d), C).

One approach for computing VI solutions is to reformulate the optimality condition into a fixed point condition. Indeed, for  > 0, the projected gradient-type operator defined by

R(x; d) PC(x - F (x; d)),

(3)

satisfies the equivalence relation [19]

xd  VI(F (· ; d), C)  0  F (xd; d) + C(x)  xd = R(xd; d).

(4)

This shows xd solves the VI if and only if it is a fixed point of the operator R. In practice, it can be beneficial to express the constraint set C as an intersection of two (simpler) sets C1 and C2 (i.e.

C = C1  C2). In this case, defining

T (x; d) x - PC1 (x) + PC2 (2PC1 (x) - x - F (PC1 (x); d)))

(5)

yields the equivalence (see Lemma A.1 in Appendix A)

xd  VI(F (· ; d), C)  0  F (xd; d) + C1 (xd) + C2 (xd)

(6a)

 xd = PC1 (z), where z = T (z, d).

(6b)

The equivalences in (6) generalize (4) since R is a special case of T obtained by taking C1 = X and C2 = C. This fixed point formulation enables elements of VI(F (· ; d), C) to be obtained by iteratively

applying T , as justified by the following extension of the classic results by Krasnosel'skii [32] and

Mann [38] and the operator splitting scheme of Davis and Yin [15] (proved in the Appendix).

Theorem 2.1. For T as in (5), if a sequence {zk} satisfies zk+1 = T (zk, d) with -cocoercive F (·, d) and polyhedral sets5 Ci such that C = C1  C2, then PC1 (zk)  xd  VI(F (· ; d), C).

2.2 Games and Equilibria

Contextual games model the interactions of a finite or infinite number of agents (i.e. atomic or

non-atomic, respectively). Formally, each K-player normal form contextual game is defined by

action sets6 Vk and cost functions uk : X × D  R for k  [K], where C V1 × . . . × VK and D

denotes the set of contexts (i.e. data space). The k-th player's actions xk are constrained to the action

set Vk, yielding an action profile x = (x1, . . . , xK )  C  X . The actions of all players other than

k are denoted by x-k = (x1, . . . , xk-1, xk+1, . . . , xK ). We assume uk(·, x-k; d) is convex for any

fixed x-k and d. Assuming rationality, each player seeks to minimize their own cost function uk by

controlling only xk while explicitly knowing uk is impacted by the other players' actions x-k. An

action profile xd is a Nash equilibrium if

uk(xk, xd,-k; d)  uk(xd,k, xd,-k; d) for all xk  Vk and k  [K].

(7)

In words, xd is a Nash equilibrium if no player can lower their cost by unilaterally deviating from xd. When each uk is differentiable with respect to x, the game gradient is defined by

F (x; d) x1 u1(x; d) , . . . , xK uK (x; d) ,

(8)

and Nash equilibria may be characterized using variational inequalities [19, Prop. 1.4.2]; namely,

xd is a Nash Equilibrium  xd  VI(F (· ; d), C).

(9)

In summary, xd is a Nash equilibrium if no unilateral change lowers any individual cost and a VI

solution if no feasible update reduces the sum of individual costs. By (9), these views are equivalent.

4This is also known as -inverse strongly monotone 5Polyhedral sets take the form {x : x, ai  bi, for all i  [p]}, for p  N. 6This is also known as the decision set and/or the strategy set.

3

Algorithm 1 Nash Fixed Point Network (Abstract Form)

1: N(d) :

2: z1  z~, z0  z~, n  1

3: while zn - zn-1 >  or n = 1

4:

xn+1  PC1 (zn)

5:

yn+1  PC2 (2xn+1 - zn - F(xn+1; d))

6:

zn+1  zn - xn+1 + yn+1

7: n  n + 1 8: return PC1 (zn)

Input data is d Initialize iterates and counter Loop to convergence at fixed point Project onto constraint set Project reflected gradient Combine auxiliary sequences Increment counter Output inference

3 Proposed Method: Nash-FPNs

Suppose observations of multi-agent behavior are available in the form (d, xd) for context data d and agent action profile xd. Assume the action set C = C1  C2 is known a priori and xd  C. To predict the true action profile xd from d, this action profile xd is modeled as the unique solution7 to a parameterized VI. By constructing a tunable operator F : X × D  X and setting

T(x; d) x - PC1 (x) + PC2 (2PC1 (x) - x - F(PC1 (x); d)) ,

(10)

a Nash Fixed Point Network (N-FPN) is defined by

N(d) PC1 (zd) where zd = T(zd; d).

(11)

By (6), this definition implies N(d)  VI(F (· ; d), C), i.e. N(d) is the solution to a "learned" VI. In other words, N(d) outputs an equilibria prediction. For the particular structure of T given
in (10), iteratively applying T to find a VI solution can be simplified to a three step iteration by introducing auxiliary sequences {xk} and {yk}, as illustrated in Algorithm 1. Although we find

Algorithm 1 to be most practical, other operator-based methods (e.g. ADMM and PDHG) can be

used within the N-FPN framework via equivalences following the form of (6).

Constraint Decoupling The provided formulation assumes C
is expressed as the intersection of two sets C1 and C2. When

Algorithm 2 N-FPN ­ Projected Gradient (Special Case)

1: N(d) : 2: x1  x~, n  2,

Input data is d Initializations

an explicit and relatively simple 3: x2  PC(x1 - F(x1; d)) formula exists for PC (e.g. C is the 4: while xn - xn-1 > 

Apply T update Loop to fixed point

probability simplex [18, 50]), one can set C1 = X and C2 = C so
that the iteration in Algorithm 1
performs updates via the projected

5: xn+1  PC(xn -F (xn; d)) 6: n  n + 1 7: return xn

Apply T update Increment counter Output inference

gradient operator in (3) (see Algorithm 2). However, it is often the case that PC does not admit a closed form while PC1 and PC2 admit explicit and computationally cheap expressions (e.g. C1 = Rn0

and C2 an affine hyperplane). Loosely speaking, using T as in (10) enables replacement of a potentially "difficult" projection onto C with "easy" projections onto individual constraints Ci. More

generally, in some real-world applications (e.g. traffic routing), the set C is a Minkowski sum of

intersections of simple sets, i.e. C = C1 + · · · + CK where Ck = Ck1  Ck2. By using a product space, the constraints may be further decoupled (see Lemma B.2), thereby avoiding an iterative subroutine

to compute PC for each update. In particular, our decoupled scheme updates only require a single

application of each PCki . See Appendix B for a fully decoupled formulation of Algorithm 1 and a related extension to the case where C is the intersection of several sets i.e. C = C1  · · ·  CK.

Crucially, decoupling projections onto C into projections onto each Cki that possess analytic formulas enables efficient forward propagation (i.e. evaluation of N) and backward propagation (to tune weights ) through the projections. These projection formulas can be directly coded into the feed forward operation for N, enabling built-in autodifferentation packages to perform backpropagation.
Further discussion on the resulting implications is provided in Section 4.

7In practice, the learned VI problem may not admit a unique solution. However, this is of little practical significance since the initializations in Algorithms 1 and 2 are held fixed, thereby yielding consistent outputs that are stable with respect to changes in the weights .

4

Backpropagation Consider a smooth loss function : X × X  R and the training problem

min EdD


[

(N(d), xd)] ,

(12)

where we abusively interpret the data space D as a distribution. Evaluation of an N-FPN consists of a

fixed-point iteration, which may entail many iterations. To circumvent backpropagating through each forward step, the gradient d /d may be expressed by8

d d

=

d dN dx d

=

d dx

dPC1 (zd) dz

dzd d

,

(13)

where the implicit function theorem [31] is used to obtain the Jacobian-based equation

dzd d

=

J-1

T 

,

with J

Id

-

dT dz

.

(14)

For large-scale games, solving (14) is computationally intensive. Instead, we employ the Jacobian-free
backpropagation (JFB) of [21], which consists of replacing J-1 in (14) with the identity matrix. This substitution yields a preconditioned gradient and is effective for training in image classification [21]

and data-driven CT reconstructions [26]. Importantly, computing this preconditioned gradient only requires backpropagating through a single application of T (i.e. the final forward step).

Limitations Our approach tunes an operator so that its fixed points match given contextual Nash equilibria, but says little about the players' cost functions. Thus, T cannot be used to design interventions to increase social welfare (i.e. the negative of the sum of all players costs) [29, 34, 43]. However, T can be used to design interventions to discourage agents from playing a given action.

4 Related Works

There are two distinct learning problems for games. The first considers repeated rounds of the same game and operates from the player's perspective. The players are assumed to have imperfect knowledge of the game, and the goal is to learn the optimal strategy (i.e. the Nash equilibrium or, more generally, a coarse correlated equilibrium), given only the cost incurred in each round. This problem is not investigated in this work, and we refer the reader to [24, 25, 48, 49] for further details.
The second problem supposes historical context-action data pairs (d, xd) are available to an external observer. The observer wishes to learn something about the players' cost functions, assuming each xd is (approximately) a Nash equilibrium. The works [2, 9, 29, 43, 52, 55­57] and many others approach this as an inverse problem, positing a parametrized form of each players cost function and then tuning these weights to minimize empirical risk. Several recent works [34, 36, 37] abandon learning cost functions directly in favor of learning an operator approximating the game gradient within an implicit deep learning framework, which is in line with our approach. A differentiable game solver for two player games is proposed in [36]. Backpropagation is done by solving a p × p linear system9 for each (d, xd). As pointed out in [37], this is prohibitively expensive for high dimensional games. In [37], this approach was modified, leading to a fast backpropagation algorithm, but only for two-player games admitting a compact extensive form representation. Moreover, both [36] and [37] only consider the case where C is a product of simplices, and these works avoid projections by only considering particular types of games10. The approach of [34] is most similar to ours, but crucially they do not exploit constraint decoupling or Jacobian-free backpropagation. Instead, they use an iterative O(p3) algorithm [3] to compute PC and dPC/dz and solve a Jacobian-based equation (similar to (13)) in every backward pass.
We also highlight recent work applying deep learning to traffic flow prediction [14, 23, 35, 47]. Unlike us, these works consider non-equilibrium traffic flows and use fine-grained spatiotemporal data (e.g. traffic densities on every road segment at five minute intervals [14]) to predict the traffic flow in the near future. This is in contrast with our approach of using coarse-grained data (e.g. weather) to predict the equilibrium traffic flow. A common method for solving the VI arising in traffic routing (see Section 5.2) is the Frank-Wolfe algorithm [20]. More sophisticated approaches are given in [6, 17] and [7]. Although the equivalence (3) is well-known in this community (see, e.g. [7, 41]), we are not aware of any prior works utilizing operator splitting to decouple the constraints.
8All arguments are implicit and correspond to the N-FPN definition in (11). 9In this section, p denotes the dimension of the action space X . 10Precisely, they add an entropic regularizer, which guarantees xd is in the interior of C.

5

R

P

S

R

0

- w1, d

w2, d

P

w1, d

0

- w3, d

S - w2, d

w3, d

0

- B(d)

0  w1, d
- w2, d

- w1, d
0 w3, d

w2, d  - w3, d 
0

Table 2: Payoff matrix B(d) for contextual Rock-Paper-Scissors (RPS).

Test MSE Abs. Ave. Cost yk

10-2 10-4

101 100 10-1

Optimal vs Uniform Optimal vs N-FPN

10-6 0

250 500 750 1 000 Epoch

10-2 Optimal vs Optimal

0

5 000

Games Played k

10 000

Figure 2: Rock-paper-scissors example. Left plot shows N-FPN test loss during training. Right plot shows the cost expression yk over the course of k games in three settings. The first player always acts optimally, knowing both the true cost u1(·; d) and the second player's strategy. The second player either also acts optimally, chooses uniformly randomly, or uses N-FPN predictions only knowing d. Both players acting optimally yields a Nash equilibrium, making yk  0. When the second player is
uniform, the first player typically wins. This plot shows the N-FPN player chooses nearly optimally.

5 Numerical Examples

We show the efficacy of N-FPNs on two games types: rock-paper-scissors and traffic routing.

5.1 Rock Paper Scissors

We perform a rock-paper-scissors experiment similar to [36]. Each player's actions are restricted
to the unit simplex 3 {x  R30 : x 1 = 1}  R3 so that C = 3 × 3 and actions xi are interpreted as probability distributions over three choices: "rock", "paper" and "scissors." Equilibria xd are drawn from VI(F (· ; d), C), using the game gradient F in (8) with cost functions given by

u1(x; d) x1, B(d)x2 and u2(x; d) - x1, B(d)x2 ,

(15)

where the payoff matrix B(d)  R3×3 (see Table 2) defines the players' cost functions using wi  R30. Contextual data d are drawn from a distribution D that is uniform over [0, 1]3. An NFPN is trained to predict xd from d using training data context-action pairs {(di, xdi )}1i=0010, without using knowledge of F . The tunable operator F in (10) consists of a residual update with two
fully connected layers and a leaky ReLU activation. Forward propagation uses Algorithm 2. For

illustration, we simulate play between two players. The first player acts optimally using knowledge

of B(d) and the second player's strategy. Three options are used for the second player: another

optimal player, an N-FPN player that only has access to d, and uniform choices. With two optimal

players, a Nash equilibria is obtained where the expected cost after each game is zero. If the N-FPN

is well-trained, then the second case yields the same result. In the final case, the optimal player has

an advantage, yielding first player costs less than zero (i.e. the first player usually wins). Here

(Expected Abs. Nash Player k-Game Average Cost)  yk

EdD

1 k

k

u1 s ; d

=1

, (16)

where sk is a tuple of two one-hot vectors (e.g. sk1  xd and sk2  N(d)). If N(d) = xd, then the expected cost u1 is zero and yk  0 (n.b. simulated games have nonzero variance due to one-hot sampling ski whereas xd is continuous). This behavior is illustrated in Figure 2.

5.2 Contextual Traffic Routing

Setup Consider a road network represented by a directed graph with vertices V and arcs E. Let N  R|V |×|E| denote the vertex-arc incidence matrix (see Appendix C.1). An origin-destination pair

6

origin

1

2

Utilization origin

­ 250%

1

2

­ 125%

Utilization ­ 250%
­ 125%

­ 0%

­ 0%

3

4

Width shows edge capacity

destination

(a) True traffic flow for "sunny" context

origin

1

2

Utilization ­ 250%
­ 125%

3

4

Width shows edge capacity

destination

(b) Predicted traffic by N for "sunny" context

origin

1

2

Utilization ­ 250%
­ 125%

­ 0%

­ 0%

3

4

3

4

Width shows edge capacity

destination

Width shows edge capacity

destination

(c) True traffic flow for "rainy" context

(d) Predicted traffic by N for "rainy" context

Figure 3: Toy traffic routing models. Subfigures (a) and (c) show traffic flow and in two situations: "sunny" and "rainy" days. Subfigures (b) and (d) show predictions by N-FPN N from "sunny" and "rainy" contexts, demonstrating nearly perfect inferences. Further details are in Appendix C.

(OD-pair) is a triple (v1, v2, q) with vi  V and q  R>0, encoding the constraint of routing q units of traffic from v1 to v2. Each OD-pair is encoded by a vector b  R|V | with bv1 = -q, bv2 = q and all other entries zero. A valid traffic flow x  R|E| for an OD-pair has nonnegative entries satisfying the flow equation N x = b. The e-th entry xe represents the traffic density along the e-th arc. The
flow equation ensures the number of cars entering an intersection equals the number leaving, except a
net movement of q units of traffic from v1 to v2. For K OD-pairs, a valid traffic flow x is the sum of
traffic flows for each OD-pair, which is in the Minkowski sum

C = C1 + · · · + CK , with Ck = {x : N x = bk} {x : x  0} for all k  [K]. (17)

Ck1

Ck2

A contextual travel time function11 te(xe; d) is associated with each arc, where d encodes contextual data. Here the equilibrium of interest is, roughly speaking, a flow configuration xd where the travel time between each OD-pair is as short as possible when taking into account congestion effects [11].

This is known as a Wardrop equilibrium (also called the user equilibrium) [51], a special case of

Nash equilibria where F = [t1(x1; d) · · · t|E|(x|E|; d) ] . In certain cases, a Wardrop equilibrium is the limit of a sequence of Nash equilibria as the number of drivers goes to infinity [40].

TRAFIX Scores Accuracy of traffic routing predictions are measured by a TRAFIX score. This
score forms an intuitive alternative to mean squared error. An error tolerance  > 0 is chosen (n.b.  = 5 × 10-3 in our experiments). For an estimate x of x , the TRAFIX score with parameter  is the percentage of edges for which x has relative error (with tolerance12  > 0) less than , i.e.

(relative error of edge e) TRAFIX(x, x ; ,  )

|xe |xe

- xe |+

|

,

(number of edges with relative error < ) × 100%. (number of edges)

(18a) (18b)

Our plots and tables show the expected TRAFIX scores over the distributions of testing data.

11This time is monotonically increasing as a function of the traffic density xe (for any fixed d). 12The parameter  is added to handle the case when the e-th component of x is zero, i.e. xe = 0.

7

Test Rel. MSE TRAFIX Score

10-2

100

98

96

10-3

94

92

10-4 0

90

100

200

0

Epoch

100

200

Epoch

Figure 4: Plots for N-FPN performance on Eastern Massachusetts testing data. The left plot shows convergence of expected relative mean squared error on testing data after each training epoch and the right shows the expected TRAFIX score on testing data after each training epoch.

dataset
Sioux Falls Eastern Massachusetts Berlin-Friedrichshain
Berlin-Tiergarten Anaheim

edges/nodes
76/24 258/74 523/224 766/361 914/416

OD-pairs
528 1113 506 644 1406

# params
46K 99K 179K 253K 307K

rel. MSE
1.9 × 10-3 4.7 × 10-4 5.3 × 10-4 7.6 × 10-4 2.4 × 10-3

TRAFIX score
94.42% 97.94% 97.42% 95.95% 95.28%

Table 3: Expected values of N-FPN predictions on traffic routing test data. First and second columns show the number of edges, nodes, and origin-destination pairs for corresponding dataset. Second column shows number of tunable parameters. Further details may be found in Appendix C.4.

Datasets and Training We construct datasets for a (collection of) large scale datasets constructed from the traffic networks of real-world cities curated by the Transportation Networks for Research Project [1]. We construct this data by fixing a choice of te(x; d) for each arc e, randomly generating a large set of contexts d  [0, 1]10 and then, for each d, finding a solution xd in VI(F (· ; d), C). Further details are in Appendix C. For illustrative purposes, we also consider a toy example, illustrated in Figure 3. We train an N-FPN using Algorithm 3 for forward propagation to predict xd from d for each data set with architectures as described in Appendix C.4. Additional training details are in Appendix C.5.
Results Table 3 shows a description of the traffic networks datasets, including the numbers of edges, nodes, and OD-pairs. To illustrate the effectiveness of N-FPNs for each setting, this table also shows the number of tunable parameters in column four, relative mean squared error (MSE) in column five and the TRAFIX score in column six for the testing dataset. The convergence during training of the relative MSE and TRAFIX score on the Eastern-Massachusetts testing dataset is shown in Figure 4. Additional plots can be found in Appendix E.

6 Conclusions
The fusion of big data and optimization algorithms offers potential for predicting equilibria in systems with many interacting agents. The proposed N-FPNs form a scalable data-driven framework for efficiently predicting equilibria for such systems that can be modeled as contextual games. The N-FPN architecture yields equilibria outputs that satisfy constraints while also being trained end-toend. Moreover, the provided constraint decoupling schemes enable simple forward and backward propagation using explicit formulae for each projection. The efficacy of N-FPNs is illustrated on large-scale traffic routing problems using a contextual traffic routing benchmark dataset and TRAFIX scoring system. Future work will investigate applications on larger datasets, convergence acceleration, and incorporation of distributed algorithms for training.

8

Broader Impact
Our work proposes a scalable method for learning to predict Nash equilibria from historical data. Although our work is mostly a proof-of concept, the scalability means that practitioners can use our tools on real-world problems. For example, a city planner could use our framework to predict how major events will change traffic flows in their city and make adjustments to lower commute times, while fiscal policymakers could study the effect of new taxes on production levels. As with many new technologies, there is also potential for negative applications; perhaps, a large firm could predict the effect of certain regulatory changes on the equilibrium wage in the labor market and act to decrease it. Thus, care must be taken in weighing the impact of a shift in equilibrium on all agents in a game.
References
[1] Transportation Networks for Research Core Team. Transportation Networks for Research. https://github.com/bstabler/TransportationNetworks. Accessed: 2021-05-24.
[2] S. Allen, J. P. Dickerson, and S. A. Gabriel. Using inverse optimization to learn cost functions in generalized Nash games. arXiv preprint arXiv:2102.12415, 2021.
[3] B. Amos and J. Z. Kolter. Optnet: Differentiable optimization as a layer in neural networks. In International Conference on Machine Learning, pages 136­145. PMLR, 2017.
[4] K. J. Arrow and G. Debreu. Existence of an equilibrium for a competitive economy. Econometrica: Journal of the Econometric Society, pages 265­290, 1954.
[5] S. Bai, J. Z. Kolter, and V. Koltun. Deep equilibrium models. In Advances in Neural Information Processing Systems, pages 690­701, 2019.
[6] H. Bar-Gera. Origin-based algorithm for the traffic assignment problem. Transportation Science, 36(4):398­417, 2002.
[7] H. Bar-Gera. Traffic assignment by paired alternative segments. Transportation Research Part B: Methodological, 44(8-9):1022­1046, 2010.
[8] H. H. Bauschke, P. L. Combettes, et al. Convex Analysis and Monotone Operator Theory in Hilbert Spaces. Springer, 2nd edition, 2017.
[9] D. Bertsimas, V. Gupta, and I. C. Paschalidis. Data-driven estimation in equilibrium using inverse optimization. Mathematical Programming, 153(2):595­633, 2015.
[10] E. Bisong. Google colaboratory. In Building Machine Learning and Deep Learning Models on Google Cloud Platform, pages 59­64. Springer, 2019.
[11] G. Carlier and F. Santambrogio. A continuous theory of traffic congestion and Wardrop equilibria. Journal of Mathematical Sciences, 181(6):792­804, 2012.
[12] A. Cegielski. Iterative methods for fixed point problems in Hilbert spaces, volume 2057. Springer, Berlin, Germany, 2012.
[13] T. Chen, X. Chen, W. Chen, H. Heaton, J. Liu, Z. Wang, and W. Yin. Learning to optimize: A primer and a benchmark. arXiv preprint arXiv:2103.12828, 2021.
[14] Z. Cui, K. Henrickson, R. Ke, and Y. Wang. Traffic graph convolutional recurrent neural network: A deep learning framework for network-scale traffic learning and forecasting. IEEE Transactions on Intelligent Transportation Systems, 21(11):4883­4894, 2019.
[15] D. Davis and W. Yin. A three-operator splitting scheme and its optimization applications. Set-valued and variational analysis, 25(4):829­858, 2017.
[16] F. de Avila Belbute-Peres, K. Smith, K. Allen, J. Tenenbaum, and J. Z. Kolter. End-to-end differentiable physics for learning and control. Advances in neural information processing systems, 31:7178­7189, 2018.
9

[17] R. B. Dial. A path-based user-equilibrium traffic assignment algorithm that obviates path storage and enumeration. Transportation Research Part B: Methodological, 40(10):917­936, 2006.
[18] J. Duchi, S. Shalev-Shwartz, Y. Singer, and T. Chandra. Efficient projections onto the l 1-ball for learning in high dimensions. In Proceedings of the 25th international conference on Machine learning, pages 272­279, 2008.
[19] F. Facchinei and J.-S. Pang. Finite-dimensional variational inequalities and complementarity problems. Springer Science & Business Media, 2007.
[20] M. Frank and P. Wolfe. An algorithm for quadratic programming. Naval research logistics quarterly, 3(1-2):95­110, 1956.
[21] S. W. Fung, H. Heaton, Q. Li, D. McKenzie, S. Osher, and W. Yin. Fixed point networks: Implicit depth models with Jacobian-free backprop. arXiv preprint arXiv:2103.12803, 2021.
[22] L. E. Ghaoui, F. Gu, B. Travacca, A. Askari, and A. Y. Tsai. Implicit deep learning. arXiv preprint arXiv:1908.06315, 2019.
[23] S. Guo, Y. Lin, N. Feng, C. Song, and H. Wan. Attention based spatial-temporal graph convolutional networks for traffic flow forecasting. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 922­929, 2019.
[24] J. Hannan. Approximation to Bayes risk in repeated play. Contributions to the Theory of Games, 21(39):97, 1957.
[25] S. Hart and A. Mas-Colell. A simple adaptive procedure leading to correlated equilibrium. Econometrica, 68(5):1127­1150, 2000.
[26] H. Heaton, S. W. Fung, A. Gibali, and W. Yin. Feasibility-based fixed point networks. arXiv preprint arXiv:2104.14090, 2021.
[27] O. Jahn, R. H. Möhring, A. S. Schulz, and N. E. Stier-Moses. System-optimal routing of traffic flows with user constraints in networks with congestion. Operations research, 53(4):600­616, 2005.
[28] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In ICLR (Poster), 2015.
[29] I. C. Konstantakopoulos, L. J. Ratliff, M. Jin, S. S. Sastry, and C. Spanos. Social game for building energy efficiency: Utility learning, simulation, and analysis. arXiv preprint arXiv:1407.0727, 2014.
[30] J. Kotary, F. Fioretto, P. Van Hentenryck, and B. Wilder. End-to-end constrained optimization learning: A survey. arXiv preprint arXiv:2103.16378, 2021.
[31] S. G. Krantz and H. R. Parks. The implicit function theorem: history, theory, and applications. Springer Science & Business Media, 2012.
[32] M. Krasnosel'skii. Two remarks about the method of successive approximations. Uspekhi Mat. Nauk, 10:123­127, 1955.
[33] L. J. LeBlanc, E. K. Morlok, and W. P. Pierskalla. An efficient approach to solving the road network equilibrium traffic assignment problem. Transportation research, 9(5):309­318, 1975.
[34] J. Li, J. Yu, Y. Nie, and Z. Wang. End-to-end learning and intervention in games. Advances in Neural Information Processing Systems, 33, 2020.
[35] Y. Li, R. Yu, C. Shahabi, and Y. Liu. Diffusion convolutional recurrent neural network: Datadriven traffic forecasting. In International Conference on Learning Representations, 2018.
[36] C. K. Ling, F. Fang, and J. Z. Kolter. What game are we playing? end-to-end learning in normal and extensive form games. arXiv preprint arXiv:1805.02777, 2018.
[37] C. K. Ling, F. Fang, and J. Z. Kolter. Large scale learning of agent rationality in two-player zero-sum games. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 6104­6111, 2019.
10

[38] R. Mann. Mean Value Methods in Iteration. 4(3):506­510, 1953.
[39] J. F. Nash. Equilibrium points in n-person games. Proceedings of the national academy of sciences, 36(1):48­49, 1950.
[40] D. Paccagnan, B. Gentile, F. Parise, M. Kamgarpour, and J. Lygeros. Nash and Wardrop equilibria in aggregative games with coupling constraints. IEEE Transactions on Automatic Control, 64(4):1373­1388, 2018.
[41] M. Patriksson and R. T. Rockafellar. Sensitivity analysis of variational inequalities over aggregated polyhedra, with application to traffic equilibria. Transportation Science, 37(1):56­ 68, 2003.
[42] J. Pita, M. Jain, J. Marecki, F. Ordóñez, C. Portway, M. Tambe, C. Western, P. Paruchuri, and S. Kraus. Deployed armor protection: The application of a game theoretic model for security at the Los Angeles International Airport. In Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems: industrial track, pages 125­132, 2008.
[43] L. J. Ratliff, M. Jin, I. C. Konstantakopoulos, C. Spanos, and S. S. Sastry. Social game for building energy efficiency: Incentive design. In 2014 52nd Annual Allerton Conference on Communication, Control, and Computing (Allerton), pages 1011­1018. IEEE, 2014.
[44] R. T. Rockafellar. Convex analysis, volume 36. Princeton university press, 1970.
[45] T. Roughgarden. Routing games. Algorithmic game theory, 18:459­484, 2007.
[46] E. Ryu and W. Yin. Large-Scale Convex Optimization: Algorithm Designs via Monotone Operators. Cambridge University Press, Cambridge, England, 2022.
[47] R. Sen, H.-F. Yu, and I. S. Dhillon. Think globally, act locally: A deep neural network approach to high-dimensional time series forecasting. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.
[48] P. G. Sessa, I. Bogunovic, A. Krause, and M. Kamgarpour. Contextual games: Multi-agent learning with side information. Advances in Neural Information Processing Systems, 33, 2020.
[49] G. Stoltz and G. Lugosi. Learning correlated equilibria in games with compact sets of strategies. Games and Economic Behavior, 59(1):187­208, 2007.
[50] W. Wang and M. A. Carreira-Perpinán. Projection onto the probability simplex: An efficient algorithm with a simple proof, and an application. arXiv preprint arXiv:1309.1541, 2013.
[51] J. G. Wardrop. Some theoretical aspects of road traffic research. Proceedings of the institution of civil engineers, 1(3):325­362, 1952.
[52] K. Waugh, B. D. Ziebart, and J. A. Bagnell. Computational rationalization: the inverse equilibrium problem. In Proceedings of the 28th International Conference on International Conference on Machine Learning, pages 1169­1176, 2011.
[53] E. Winston and J. Z. Kolter. Monotone operator equilibrium networks. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 10718­10728. Curran Associates, Inc., 2020.
[54] R. Yang, B. J. Ford, M. Tambe, and A. Lemieux. Adaptive resource allocation for wildlife protection against illegal poachers. In AAMAS, pages 453­460, 2014.
[55] J. Zhang and I. C. Paschalidis. Data-driven estimation of travel latency cost functions via inverse optimization in multi-class transportation networks. In 2017 IEEE 56th Annual Conference on Decision and Control (CDC), pages 6295­6300. IEEE, 2017.
[56] J. Zhang, S. Pourazarm, C. G. Cassandras, and I. C. Paschalidis. The price of anarchy in transportation networks by estimating user cost functions from actual traffic data. In 2016 IEEE 55th Conference on Decision and Control (CDC), pages 789­794. IEEE, 2016.
[57] J. Zhang, S. Pourazarm, C. G. Cassandras, and I. C. Paschalidis. The price of anarchy in transportation networks: Data-driven evaluation and reduction strategies. Proceedings of the IEEE, 106(4):538­553, 2018.
11

A Variational Inequalities

Below we provide a lemma justifying the decoupling of constraints in the action set C. Here we make use of polyhedral sets13; however, this result also holds in a more general setting utilizing relative interiors of C1 and C2.
Lemma A.1. If14 F : X  X is an -cocoercive operator and C1, C2  X are polyhedral sets such that C = C1  C2, then

xd  VI(F (· ; d), C)  0  F (xd; d) + C1 (xd) + C2 (xd)  xd = PC1 (z), where z = T (z ; d).

(19a) (19b)

Proof. We begin with the well-known equivalence relation [19]

xd  VI(F (· ; d), C)  0  F (xd ; d) + C(xd).

(20)

Because C1 and C2 are polyhedral sets, we may apply [44, Theorem 23.8.1] to assert

C = C1 + C2 .

(21)

Next consider three maximal15 monotone operators A, B and C, with C single-valued. For each  > 0, let JA and RA be the resolvent of A and reflected resolvent of A, respectively, i.e.

JA (I + A)-1 and RA 2JA - I.

(22)

In particular, note the resolvent of Ci is precisely the projection operator PCi [8, Example 23.4]. Using three operator splitting (e.g. see [15, Lemma 2.2] and [46]), we obtain the equivalence

0  (A+B+C)(x)  x = JB(z), where z = z-JB(z)+JA(RB -CJB)(z). (23)

Setting A = C2 , B = C1 , and C = F , (23) reduces to

0  F (xd; d) + C1 (xd) + C2 (xd)  xd = PC1 (z), where z = T (z; d).

(24)

Combining (20), (21), and (24) yields (19), as desired.

We next restate and provide a brief proof for the main convergence theorem.

Theorem 2.1. For T as in (5), if a sequence {zk} satisfies zk+1 = T (zk, d) with -cocoercive F (· ; d) and polyhedral sets Ci such that C = C1  C2, then PC1 (zk)  xd  VI(F (· ; d), C).
Proof. Because all sets considered in this work are closed and convex, the projection operators PC1 and PC2 are averaged [12, Theorem 2.2.21]. Combined with the fact that F is -cocoercive, the operator T is averaged [15, Proposition 2.1]. The classic result of Krasnosel'skii [32] and Mann [38] asserts if, given any z1, a sequence {zk} is generated using updates of the form zk+1 = T (zk) for an averaged operator T , then {zk} converges to a fixed point z  {z : T (z) = z}. Because the projection operator is 1-Lipschitz, it necessarily follows that {PC1 (zk)} converges to PC1 (z). By Lemma A.1, we conclude PC1 (z)  VI(F (·; d), C).

13A set is polyhedral if it is of the form {x : x, ai  bi, for i  [p]}, for p  N. 14Here and in Appendix B we suppress the dependence of F on d for brevity. 15A monotone operator M is maximal if there is no other monotone operator S such that Gra(M )  Gra(S) properly [46]. This is a technical assumption that holds for all cases of our interest.
12

B Constraint Decoupling

B.1 Minkowski Sum

This subsection provides a decoupling scheme for constraints structured as a Minkowski sum,16 i.e.

C C1 + · · · + CK ,

(25)

where Ck  X and Ck = Ck1  Ck2 for all k  [K]. The core idea is to avoid attempting to directly project onto C and instead perform simple projections onto each set Cki , assuming the projection onto Cki admits an explicit formula. First, define the product space

X X ×X ×...×X .

(26)

K times

For notational clarity, we denote elements of X by overlines so each element x  X is of the form x = (x1, . . . , xK ) with xk  X for all k  [K]. Because X is a Hilbert space, X is naturally endowed with a scalar product ·, · X defined by

K

x, y X

xk, yk .

(27)

k=1

Between X and the product space X we define two natural maps Q- : X  X and Q+ : X  X by

K

Q-(x)

xk and Q+(x) (x, x, . . . , x).

(28)

k=1

K copies

In words, Q-(x) maps down to X by adding together the blocks of x and Q+(x) maps up to X by making K copies of x, thus motivating the use of "+" and "-" signs. Define the Cartesian product

A C1 × . . . × CK  X ,

(29)

and note Q- (A) = C. To further decouple each set Ck, also define the Cartesian products

Ai C1i × . . . × CKi for all i  [2].

(30)

so A = A1  A2. Note the projection onto Ai can be computed component-wise; namely,

PAi (x) = PC1i (x1), . . . , PCK i (xK ) for all i  [2].

(31)

We now rephrase Algorithm 1, applied to a VI in the product space VI (Q+  F  Q-, A), into Algorithm 3 using Ai in lieu of Ci. The use of Algorithm 3 is justified by the following two lemmas. The first shows the product space operator is monotone whenever F is. The second shows the solution sets to the two VIs coincide, after applying Q- to map down from X to X .

Lemma B.1. If F : X  X is -cocoercive, then Q+  F  Q- on X is (/K)-cocoercive.

Proof. Fix any x, y  X and set Rx (F  Q-)(x) and Ry (F  Q-)(y). Then observe

K

Q+(Rx) - Q+(Ry), x - y X =

Rx - Ry, xk - yk

k=1

= Rx - Ry, Q-(x) - Q-(y) .

(32a) (32b)

Substituting in the definition of Rx and Ry reveals

Q+(Rx) - Q+(Ry), x - y X = F (Q-(x)) - F (Q-(y)), Q-(x) - Q-(y)

  F (Q-(x)) - F (Q-(y)) 2

=

 K

Q+  F  Q-(x) - Q+  F  Q-(y)

2 X

,

(33a) (33b) (33c)

where the final equality follows from the definition of the norm on X . Because (33) holds for arbitrary x, y  X , the result follows.

16This arises in the modeling Wardrop equilibria in traffic routing problems.

13

Algorithm 3 Nash Fixed Point Network (Minkowski Sum Contraints C = C1 + · · · + CK)

1: N(d) : 2: n  1

3: for k = 1, 2, . . . , K

4:

z1k  z^

5:

while

K k=1

z

n k

-

z

n-1 k

>  or n = 1

Input data is d Initialize counter
Initialize iterates to z^  X Loop until convergence at fixed point

6: for k = 1, 2, . . . , K

7:

xnk +1



PCk1

(z

n k

)

Loop over constraints Ck1 Project onto constraint set

8:

vn+1 

K k=1

xnk +1

Combine projections

9: for k = 1, 2, . . . , K

Loop over constraints Ck2

10:

y nk +1



PCk2 (2xnk+1

-

z

n k

-

F(vn+1; d))

Block-wise project reflected gradients

11:

znk+1  znk - xnk+1 + ynk+1

Apply block-wise updates

12: n  n + 1

Increment counter

13: return vn

Output inference

Lemma B.2. For F : X  X , x  VI (Q+  F  Q-, A) if and only if Q-(x)  VI (F, C).

Proof. Fix y  A and x  VI (Q+  F  Q-, A). Similarly to the proof of Lemma B.1, observe

K

(Q+  F  Q-)(x), y - x X =

(F  Q-)(x), yk - xk

k=1

= F (Q-(x)), Q-(y) - Q-(x) .

(34a) (34b)

Because Q-(A) = C, it follows that x Q-(x)  C and w Q-(y)  C. Consequently,

0  (Q+  F  Q-)(x), y - x X = F (x), w - x .

(35)

Because y was arbitrarily chosen, (35) holds for all w  C and, thus, Q-(x)  VI (F, C).

Conversely, fix y  A and x  X such that Q-(x)  VI(F, C). Then Q-(y)  C and

0  F (Q-(x)), Q-(y) - Q-(x)

(36a)

K

=

F (Q-(x)), yk - xk

k=1

= (Q+  F  Q-)(x)), y - x X .

(36b) (36c)

Together the inequality (36) and the fact y  A was arbitrarily chosen imply x  VI(Q+  F  Q-, A). This completes the proof.

14

Algorithm 4 Nash Fixed Point Network (Intersection Contraints C = C1  · · · CK)

1: N(d) : 2: n  1

3: for k = 1, 2, . . . , K

4:

z1k  z^

5:

while

K k=1

znk - znk-1

>  or n = 1

Input data is d Initialize counter
Initialize iterates to z^  X Loop until convergence at fixed point

6: for k = 1, 2, . . . , K

7:

xnk +1



PCk

(z

n k

)

Project xn onto B1

8:

vn+1



1 K

K k=1

2xnk+1 - znk - F(xnk+1; d)

Project reflected gradient onto B2

9: for k = 1, 2, . . . , K

10:

z nk +1



z

n k

-

xnk +1

+

vn+1

to obtain yn+1 = Q+(vn+1) Combine auxiliary sequences

11:

nn+1

Increment counter

12: return xn1

Output inference

B.2 Intersections of Constraints

For completeness, we also consider constraints C that may be expressed as the intersection of several sets, i.e. C = C1  C2 · · ·  CK . Let X , ·, · X , Q+ and Q- be as in Appendix B.1. Next define17

B1 C1 × · · · × CK and B2 Q+(X ) = {x  X : x1 = · · · = xK },

(37)

and B B1  B2. Note Q-(B) = C. The logic is now the same as before; rephrase Algorithm 1 using Bi in place of Ci. The projection PB1 can be computed component-wise via

PB1 (x) = (PC1 (x1), . . . , PCK (xK )) ,

(38)

and PB2 (x) has a simple closed form given in the following lemma.

Lemma B.3. With notation as above, PB2 (x) = Q+

1 K

K k=1

xk

.

Proof. By the definition of a projection and the norm on X ,

PB2 (x)

argmin
zB2

z-x

2 X

K

= argmin

zk - xk 2

zB2 k=1

= Q+(z#),

K
where z# = argmin z - xk 2,
zX k=1

so z# satisfies the following optimality condition

0

=

d dz

K
z - xk 2

K
= 2(z# - xk) = 2K

z#

-

1 K

K

xk

.

k=1

z=z# k=1

k=1

This implies

z#

=

1 K

K

xk .

k=1

Together (39) and (41) yield the result, completing the proof.

17Note A in Appendix B.1 is the same as B1 in (37), i.e. B1 = A.

(39a) (39b) (39c)
(40) (41)

15

For each operator F : X  X , we define a corresponding product space operator F : X  X via

F (x) (F (x1), . . . , F (xK ).

(42)

This definition enables us to show a direct equivalence between a VI in the original space X and the

product space X . That is, we complete the analysis in the following lemmas by showing the solution

set of an appropriate VI in the product space coincides with that of the original VI.

Lemma B.4. If F : X  X is -cocoercive, then the operator F : X  X is -cocoercive.

Proof. Fix any x, y  X . Then observe

K

F (x) - F (y), x - y X =

F (xk) - F (yk), xk - yk

k=1

K



F (xk) - F (yk) 2

k=1

=

F (x) - F (y)

2 X

.

Because (43) holds for arbitrarily chosen x, y  X , we conclude F is -cocoercive.

(43a) (43b) (43c)

Lemma B.5. For -cocoercive F : X  X , x  VI (F, C) if and only if Q+(x)  VI F , B .

Proof. Fix any x  VI(F, C) and set x = Q+(x). An elementary proof shows Q+ : C  B is a bijection. Together with the fact x is a VI solution, this implies

K
0  K F (x), y - x , for all y  C  0  F (x), yk - x , for all y  B (44a)

k=1

K

 0 

F (xk), yk - xk , for all y  B (44b)

k=1

 0  F (x), y - x X , for all y  B. (44c)

By the transitive property, the first and final expressions in (44) are equivalent, and we are done.

B.3 Projections onto Intersections of Hyperplanes

Consider the set C {x : N x = b}  X , and note C is closed and convex so the projection operator onto C is well-defined and given by

PC (z )

=

argmin
xC

1 2

x-z

2

=

argmin
xX

1 2

x-z

2

s.t.

N x = b.

(45)

For completeness we express (and prove) a projection formula for C via the following lemma.

Lemma B.6. For nonempty C {x : N x = b}, the projection PC is given by

PC(z) = z - N (N z - b),

(46)

where N  U -1V and U V is the compact singular value decomposition of N such that U and V have orthonormal columns and  is invertible.

Proof. Referring to (45), we see the associated Lagrangian is given by

L(x, )

1 2

x-z

2+

, N x - b

.

(47)

The optimizer x# PC(z) satisfies the optimality condition 0 = L(x#, #) for some #, which can be expanded as

0 = x L(x, )

= x# - z + N #,

(x,)=(x# ,# )

0 =  L(x, )

= N x# - b.

(x,)=(x# ,# )

(48a) (48b)

16

We claim it suffices to choose

# = (U -2U )(N z - b).

(49)

By (48a), this choice yields

x# = z - N # = z - N (U -2U )(N z - b) = z - (V U )(U -2U )(N z - b) = z - (V -1U )(N z - b) = z - N (N z - b).

(50a) (50b) (50c) (50d) (50e)

To prove this formula for x# gives the projection, it suffices to show the remaining condition N x# = b is satisfied. Decomposing N into its singular value decomposition, observe

N x# = N (z - (V -1U )(N z - b)) = N z - (U V )(V -1U )(N z - b) = N z - (U V )(V -1U )(U V z - b) = N z - U V z + U U b = U U b.

(51a) (51b) (51c) (51d) (51e)

The range of N is contained in the subspace spanned by the orthonormal columns of U , i.e. range(N )  span(u1, . . . , ur), where ui is the i-th column of U and r is the rank of N . Because C is nonempty, b  range(N ) and it follows that there exists scalars 1, . . . , r such that

r

b = iui.

(52)

i=1

Through direct substitution, we deduce



r

r



r

r

UU b = UU

iui = U  i uj, ui  = U iei = iui = b. (53)

i=1

i,j=1

i=1

i=1

Thus, (51) and (53) together show the final optimality condition is satisfied, proving the claim.

Remark B.1. In our traffic routing experiments, we use the built-in SVD function in Pytorch, threshold the tiny singular values to be zero, and invert the remaining entries.

C Experimental Supplementary Material

C.1 Incidence Matrix

For a directed graph with vertices V and arcs E the vertex-arc incidence matrix N  R|V |×|E| is defined by

+1 if (i, j)  E

Nij

-1 if (j, i)  E

(54)

0 otherwise

For example, for the simple road network shown in Figure 3 the incidence matrix is

-1 0 -1 0 0 

N

=

 

0 1

0 -1

1 0

-1 1

-1 0

.

(55)

01001

17

C.2 Toy Traffic Routing Model

We consider the traffic network shown in Figure 3 (with incidence matrix given in (55)) and a single OD pair: (v1, v4, 1). We use the contextual travel-time functions18

te(xe; d)

fe ·

1+

xe 4 c(d)e

,

(56)

 where f = (1, 2, 2, 3, 1) and

c(d) c~ 1 + P[-,](W d) ,

(57)

for  = 0.4 and c~ = (0.4, 0.8, 0.8, 0.6, 0.3), and denoting element-wise (i.e Hadamard) product.
The matrix W is constructed by sampling the entries of the first column uniformly and i.i.d. on (-10, 0], and sampling the entries of the remaining columns uniformly and i.i.d on [0, 1). This form
of W implies that d1 > 0 decreases the capacity of each road segment, albeit by varying amounts. Thus d1 could be interpreted as, for example, inches of rainfall. We use this interpretation to generate Figures 1 and 3; taking any d with d1 large corresponds to a rainy day while if d1 small it can be interpreted as a sunny day. We generate training data by sampling d i.i.d and uniformly from [0, 0.25]5 and then solving for xd  VI(F, C) using Algorithm 1 with

F (x; d) [t1(x1; d), . . . , t5(x5; d)] ,

(58)

C1 = {x : N x = b}, b [-1, 0, 0, 1, 0] , and C2 = R50. The projection onto C2 is given by a component-wise ReLU and the projection onto C2 is given in Appendix B.3.

C.3 Real-World Traffic Routing Model

Similarly to Appendix C.2, we consider a traffic network for the real data described in Table 3. For each dataset, we obtain the OD pairs bk, the free-flow time fe, the incidence matrix N , and the capacity values c~ on each edge from the Transportation Networks website [1]. To generate the data,
we use the contextual travel-time function

te(xe; d)

fe ·

1 + 0.5

xe 4 c(d)e

,

(59)

where we contextualize the capacities with

c(d) c~ 1 + P[-,](W d) .

(60)

Here, we set = 0.8 for the Anaheim dataset and = 0.3 for the remaining four datasets. We choose for the Anaheim dataset as we found the resulting actions xd were too similar for = 0.3 (making
it too easy to train an operator fitting this dataset). Similarly to the toy traffic problem, the matrix W is constructed by sampling the entries of the first column uniformly and i.i.d. on (-10, 0], and sampling the entries of the remaining columns uniformly and i.i.d on [0, 1). Since we have multiple
OD pairs, the constraints are given by the Minkowski sum of polyhedral sets. Thus, we generate the 5500 training data pairs (d, xd) using Algorithm 3.

C.4 Network Architecture for Traffic Routing

We describe the architectures used to generate Table 3. We use fully-connected layers to parameterize F. We have an opening layer, which maps from context (in our experiments, the context dimension is 10) to a 100-dimensional latent space. In the latent space, we use either one or two hidden layers (depending on the dataset) with 100-dimensional inputs and ouputs. The last layer maps from the hidden dimension to the action space, i.e. , number of edges. Since the number of edges vary per dataset, the number of tunable parameters also vary. Finally, we use a maximum depth of 50 iterations in our N-FPN architecture with a stopping tolerance of = 10-4.
18The form of this function is motivated by the well-known Bureau of Public Roads (BPR) function

18

C.5 Training Details
As described in Section 5.2, we generate 5000 training samples and 500 testing samples for all datasets. For all datasets, we use batch size of 500 and Adam [28] with constant learning rates and 200 epochs. The learning rates are chosen to be 5 × 10-5 for Berlin-Tiergarten and 10-3 for the remaining datasets. All networks are trained using Google Colaboratory [10].

D Data Provenance
For the Rock, Paper, Scissors experiment, we generated our own data following the experimental set-up described in [36]. For the toy traffic routing problem, we also our own data, using the same traffic network as [34] but modifying their experiment so as to make road capacities contextual. The Sioux Falls, Berlin-Tiergarten and Berlin Friedrichshain and Eastern Massachussetts and datasets are from [27, 33] and [56] respectively. The Anaheim dataset was provided by Jeff Ban and Ray Jayakrishnan and was originally hosted at https://www.bgu.ac.il/~bargera/tntp/. All datasets were downloaded from [1] and are used under the "academic use only" license described therein.

E Additional Plots

Test Rel. MSE

10-2
10-3
0

100 Epoch

TRAFIX Score

100

90

80

70

200

0

100

200

Epoch

Figure 5: Plots for N-FPN performance on Sioux Falls testing data. The left plot shows convergence of expected mean squared error on testing data after each training epoch and the right shows the expected TRAFIX score on testing data after each training epoch.

TRAFIX Score

Test Rel. MSE

10-2 10-3
0

100 Epoch

100

80

60

40

20

200

0

100

200

Epoch

Figure 6: Plots for N-FPN performance on Berlin Friedrichshain testing data. The left plot shows convergence of expected relative mean squared error on testing data after each training epoch and the right shows the expected TRAFIX score on testing data after each training epoch.

19

TRAFIX Score

Test Rel. MSE

100 10-2
80

10-3
0

60

100

200

0

Epoch

100

200

Epoch

Figure 7: Plots for N-FPN performance on Anaheim testing data. The left plot shows convergence of expected relative mean squared error on testing data after each training epoch and the right shows the expected TRAFIX score on testing data after each training epoch.

TRAFIX Score

Test Rel. MSE

10-2
10-3
0

100

200

Epoch

100 80 60 40 20
0

100

200

Epoch

Figure 8: Plots for N-FPN performance on Berlin Tiergarten testing data. The left plot shows convergence of expected relative mean squared error on testing data after each training epoch and the right shows the expected TRAFIX score on testing data after each training epoch.

20

