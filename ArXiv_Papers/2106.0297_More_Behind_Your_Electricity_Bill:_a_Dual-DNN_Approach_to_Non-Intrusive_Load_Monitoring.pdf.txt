1
More Behind Your Electricity Bill: a Dual-DNN Approach to Non-Intrusive Load Monitoring
Yu Zhang, Guoming Tang, Qianyi Huang, Yi Wang, Hong Xu

arXiv:2106.00297v1 [cs.LG] 1 Jun 2021

Abstract--Non-intrusive load monitoring (NILM) is a wellknown single-channel blind source separation problem that aims to decompose the household energy consumption into itemised energy usage of individual appliances. In this way, considerable energy savings could be achieved by enhancing household's awareness of energy usage. Recent investigations have shown that deep neural networks (DNNs) based approaches are promising for the NILM task. Nevertheless, they normally ignore the inherent properties of appliance operations in the network design, potentially leading to implausible results. We are thus motivated to develop the dual Deep Neural Networks (dual-DNN), which aims to i) take advantage of DNNs' learning capability of latent features and ii) empower the DNN architecture with identification ability of universal properties. Specifically in the design of dualDNN, we adopt one subnetwork to measure power ratings of different appliances' operation states, and the other subnetwork to identify the running states of target appliances. The final result is then obtained by multiplying these two network outputs and meanwhile considering the multi-state property of household appliances. To enforce the sparsity property in appliance's state operating, we employ median filtering and hard gating mechanisms to the subnetwork for state identification. Compared with the state-of-the-art NILM methods, our dual-DNN approach demonstrates a 21.67% performance improvement in average on two public benchmark datasets.
Index Terms--Non-intrusive load monitoring, energy breakdown, deep neural networks, multi-task DNN
I. INTRODUCTION
According to the statistic from UN, residential and commercial buildings consume almost 60% of the world electricity [1]. In the United States, particularly, more than 70% of the national electricity is consumed by the building sector [2]. Meanwhile, with the explosion of high-rise building construction along with the worldwide urbanization, the building energy consumption continues increasing dramatically. Hence, energy saving in buildings is of vital importance to the reduction of overall energy consumption.
Effective and efficient energy saving in buildings can be achieved through real-time power monitoring of the enduse appliances. On the one hand, with appliances' energy consumption information in real-time, households could learn more about where their power are draining, and thus engage in sustainable energy usage campaigns more actively. It has been demonstrated that the fine-grained power consumption feedback of individual appliances could stimulate households to save 5%15% energy usage [3]. On the other hand, the
Y. Zhang, G. Tang, Q. Huang and Y. Wang are with Peng Cheng Laboratory, Shenzhen, China. H. Xu is with the Chinese University of Hong Kong, Hong Kong, China.
Corresponding author: G. Tang (tanggm@pcl.ac.cn).

Mains Meter
Fig. 1. Power readings of a whole household and two appliances based on a real-world dataset. The pie chart illustrates the energy disaggregation results of the household appliances.
disaggregated energy consumption of household appliances could be leveraged to provide references for various power management strategies [4]. For example, in demand-side management programs, with real-time information of disaggregated power, utilities are able to target particular appliances (e.g., air conditioners and fridges) and suggest them to turn off or switch to energy saving modes, to shave the overall power demand in peak hours [4].
Nevertheless, current power meters are incapable to reveal any fine-grained information but merely report the wholebuilding energy consumption. To install sensors (like smart plugs) for each sub-meter or appliance is financially prohibited, e.g., it may cost up to $500 per house for individual sub-metering [5]. This triggers the demand of computational techniques to infer the appliance-specific energy consumption from only the mains power reading, which is referred to as non-intrusive load monitoring (NILM) [6]. The most prominent advantage of this technique is that it can be easily adopted in existing buildings without introducing any inconvenience to households, namely being non-intrusive. However, as NILM is essentially a single-channel blind source separation (BSS) problem, i.e., to extract separated power readings of individual appliances from the single aggregated signals (as illustrated in Fig. 1), it is inherently unidentifiable and theoretically intractable [7].
Recently, it has been shown that the single-channel BSS

2

problem can be tackled by using sequence-to-sequence (seq2seq) learning with deep neural networks [8], [9]. In particular, both deep convolutional (CNN) and recurrent neural networks (RNN) have been applied to the NILM problem [10], [7], among which the CNN architecture performs better. Specifically, the CNN structure in [7] is demonstrated to be able to automatically learn instrumental features in energy disaggregation, resulting in a significant (up to 83%) reduction rate of the estimation error. Although with decent performance, most approaches do not exploit the inherent state switching property of electric devices, and thus are not guaranteed to identify the actual operation status of end-use appliances (refer to § VI for detailed demonstrations).
Based on our observations of modern appliances' power usage (see snippets of several household appliances in Fig. 2), there are two common properties in their operations. We name the first one as multi-state property: although with some transients, the power readings of appliances are usually stable at several values, each corresponding to the power rate of one operation state. The other property from our observation is sparsity property: at most of the time, an appliance works under the "stand-by" mode, and infrequently it switches between operation states. In other words, it is impractical for most appliances to change states frequently in a short time interval. Thus their energy consumption is largely piecewise constant over the time. However, few DNN based NILM algorithms took these important and universal properties into consideration, to say nothing of incorporating them in the network modelling. Instead, they expected that the deep neural networks could automatically learn everything (including the above properties) from scratch, which proves to be largely inefficient and sometimes impossible. Based on our analysis in § II, DNNs are normally effective in learning the latent features which cannot be explicitly formulated (which is also the key to DNN's success in solving general machine learning problems), whereas for the NILM problem they are insufficient in ensuring those universal features of appliances' operations.
To address the aforementioned challenges, we borrow the idea from the multi-task neural networks and propose a dualDNN approach to the NILM problem, by adopting one DNN for estimating power ratings of individual appliances with multiple operation modes, and the other one for identifying the correct operation states of corresponding appliances. The outputs from the dual-DNN are thus formed by multiplying the estimated power ratings with corresponding identified states. Specifically, the dual-DNN approach leverages the multi-state property to breakdown the whole regression task into two subtasks, i.e., the power estimated task and state identification task, and guarantees the sparsity property of appliance operation through median filtering.
As the major contribution of this work, we make the first step to incorporate universal properties in appliance operations with the design of NILM algorithms and present a novel dual-DNN approach to the NILM problem. The dual-DNN approach tailored for NILM is capable to ensure unique appliance-specific properties and thus could further improve the energy disaggregation performance. We also investigate several variants of the proposed model that exploit both

)ULGJH
0LFURZDYH
'LVKZDVKHU
(OHFWULFVSDFHKHDWHU
(OHFWULFVWRYH
(OHFWULFRYHQ
:DVKHUGU\HU

Fig. 2. Several household appliances' operation frequency during one week.
median filtering and hard gating mechanisms, which are more compliant with the practical settings. Compared with the stateof-the-art NILM methods, our dual-DNN approach shows 24.61% and 27.89% performance improvements in average on the REDD and UK-DALE datasets, respectively.
The rest of this paper is organized as follows. § II introduces how we investigate the two universal properties from modern appliances' operations. § III shows the basic formulation of NILM problem and sequence-to-sequence learning. In § IV, we formally present the general framework and detailed design of the dual-DNN approach, and then present three of its variants in § V. The implementations of this algorithm on realworld datasets and performance evaluations are shown in § VI. § VII reviews the related work for NILM and § VIII concludes the paper.
II. OBSERVATION AND INSPIRATION In this section, we show our observations on two general properties from modern appliances' operations and give our insights on why and how to leverage them in solving the NILM problem with a novel dual-DNN model.
A. Observations from appliance operations 1) Multi-State Property: A universal property we have
observed for most household appliances is their multi-state operation. Based on Fig. 3, we find that typical household appliances, such as the fridge and dish washer, usually have multiple operation states, each of which corresponds to a different power rate. Normally, the multi-state appliances only work under one specific mode at any given time. Therefore, despite of some transient impulses, the power readings of an individual appliance would always be equal or approximate to the power rate of corresponding operation mode. In other words, with the power rate information of a multi-state appliance, by identifying its current state, we can readily estimate the appliance's power consumption in real-time.
2) Sparsity Property: This property refers to the sparsity in both operation and variation of household appliances. On the one hand, appliances such as microwave and dish washer mostly operate in its OFF state (as illustrated in Fig. 2).

3

Power(W)

1200 1000
800 600 400 200
0 0


 
20 40 60 80 100 120 Time(min)

Power(W)

500 400 300 200 100
0 0

 

20

40

60

80

Time(min)

(a) Dish washer

(b) Fridge

Power(W)

1500 1250 1000
750 500 250
0 0

2

4

6

Time(min)

Power(W)

3000 2500 2000 1500 1000
500 0 0 2 4 6 8 10 12 14 Time(min)

(c) Microwave

(d) Washing machine

Fig. 3. Snippets of four typical household appliances in the REDD dataset. The different operation states of (a) the dish washer and (b) the fridge are annotated above the curves, respectively.

Particularly, the stand-by state could take up to 95% of the whole appliances' working time. This implies that only a small number of appliances are under the ON state across the building, demonstrating the operation sparsity of household appliances in the spatial dimension. On the other hand, for one specific appliance, although any of its state transitions is possible, it is rare to switch modes frequently in a short time interval. For example, as the real-world trace data shown in Fig. 3(c) and Fig. 3(d), initially at the stand-by mode, the appliances first switch to their active modes and operate in these states for several sampling intervals, then return to the OFF state and stay there for a certain period of time. Thus, we can infer the operation (i.e., state switching) sparsity of appliances in the temporal dimension. Generally speaking, a majority of the household appliances continuously stay at the stand-by mode, with each infrequently switching between its multiple states and resulting in piece-wise constant power readings over the time.

B. Inspirations for dual-DNN
In light of the multi-state property, we develop a dual-DNN framework in tackling NILM: one power estimation neural network to specifically measure power readings of different states of appliances, and the other state classification neural network to explicitly identify the current appliance's operating state. The dual-DNN framework virtually follows the multitask DNN principles while it is tailored in this work for the specific purpose of energy disaggregation (ED)1.
To leverage the sparsity property, we further enforce a median filtering mechanism into the proposed dual-DNN framework, specifically in the state classification neural network to encourage the continuity of appliance states as well as (switching) operation sparsity.
1The NILM task is also well known as energy disaggregation or ED, and we interchangeably use the two terms in this paper.

C. Rationale behind dual-DNN
As we have mentioned, the DNN was demonstrated to be able to automatically learn instrumental features for ED, including change points, typical durations and power demands of appliances [7], all of which contribute to the performance improvements in DNN based NILM algorithms. Thus, we may assume that the DNN is capable to automatically learn the aforementioned properties during model training, and thus to enforce the aforementioned properties into our model seems unnecessary. In tackling the NILM task in practice, however, things get much more complicated and the above assumption turns to be problematic.
As a matter of fact, deep neural networks are promising for the ability to extract latent features, which might be the appliance-specific features or household specialized usage patterns in NILM. Such hidden features cannot be explicitly formulated in any equations, so the only way to obtain them is through the way of deep learning. Nevertheless, household appliances also possess some general practical features, namely the aforementioned multi-state property and sparsity property. For one thing, there is no need to extract these appliancegeneral features through deep neural networks, as we have already learnt them as empirical knowledge in practice; for another, the performance of DNNs on learning such common features is not guaranteed, according to the results of previous DNN based NILM algorithms.
Therefore, we develop the dual-DNN approach, which is expected to automatically learn the latent features while explicitly ensure the general features (university properties) from the appliance operations.

III. PRELIMINARY

A. Problem formulation of NILM

The goal of non-intrusive load monitoring is to recover the
energy consumption of individual appliances from the mains
readings which measure the aggregated energy consumption
of the whole household. Given the aggregated power con-
sumption for time T periods as X = (x1, x2, ..., xT ), where xt  R+. Let Y i = (y1i , y2i , ..., yTi ) where yti  R+ denote the power readings of i-th appliance. Therefore, at each time t, xt is assumed to be the sum of several individual power readings, plus a Gaussian noise t with zero mean and variance 2, which is formulated as follows:

xt = yti + t

(1)

i

Suppose that we are only interested in the top I appliances, i.e., the ones that consume the most energy and are widely used in most of households. Then, other (unknown or low-

power) appliances' energy consumption can be represented as U = (u1, u2, ..., uT ), and Eq. (1) can be updated as:

I

xt = yti + ut + t

(2)

i

The NILM problem is thus formulated to extract power
readings of individual appliances from the mains readings, i.e., to infer Y 1, Y 2, ..., Y I from X.

4

B. Seq2seq learning for NILM
The so-called sequence-to-sequence (seq2seq) learning approach in energy disaggregation is referred to as learning a nonlinear regression between the sequence of mains readings and the sequence of a specific appliance's power readings at the same time instances [10], [7], [11]. Both CNN and RNN architectures have been employed for the seq2seq learning in NILM.
To be specific, seq2seq architectures define a neural network fpiower that maps a partial sequence x~t,s = (xt, ..., xt+s-1) of the mains readings (as input) to the corresponding window y~ti,s = (yti, ..., yti+s-1) of an individual appliance's power readings (as output). In addition, the input sequences are generally padded with two additional windows of length w at the beginning and the end, respectively, to fully leverage the context information. Therefore, the input sequence is further modified as x~t,s,w = (xt-w, ..., xt+s+w-1), and the power estimation model for each individual appliance can be denoted as fpiower : Rs++2w  Rt+ in the seq2seq learning.
IV. DESIGN OF DUAL-DNN
Recently, it has been shown in recent literature that deep neural networks are able to automatically detect specific appliance features and thus achieve better energy disaggregation performance than the optimization based NILM approaches [10], [7], [11]. However, previous DNN based approaches did not take the appliance inherent state properties into consideration and thus yielded impractical state estimations for appliances, as introduced in § II.
A. Framework
To better leverage the multi-state and sparsity properties of appliance operations, we propose the dual deep neural networks (dual-DNN) that are tailored to perform NILM. Specifically, we first decompose a multi-state appliance into several virtual devices with just two states of "ON" and "OFF". Then, the sigmoid cross entropy loss is used to ensure that only one virtual device could operate at each time instant. By doing this, we are able to convert the one-at-a-time constraint to a classification problem.
The design of the dual-DNN framework is illustrated in Fig. 4. As we can see, this framework combines two DNNs: i) the power estimation subnetwork that aims to measure the power ratings of appliance in different operation states, and ii) the state classification subnetwork that is responsible for identifying the ON/OFF states of the decomposed virtual devices.
B. Theoretical basis
We then introduce the detailed design and theoretical basis of the dual-DNN model.
1) Left DNN Design: For the left DNN in Fig. 4, the power estimation subnetwork performs to learn a nonlinear regression between the sequence of the main power readings x~t and the appliance power readings in different states p~i. Supposing that the i-th appliance has li states (include the OFF

yti

pi

oti

Fully Connected Layer Fully Connected Layer
Conv Layer4

Fully Connected Layer Fully Connected Layer
Conv Layer4

... ...

Conv Layer1 Power Estimation Subnetwork

Conv Layer1 State Classification Subnetwork

xt Fig. 4. Framework of the dual-DNN approach to NILM.

state), the power ratings of this appliance can be represented as
p~i = [pi1, ..., pili ], i = 1, ..., I. As mentioned before, we further expand the input sequence with fixed windows of length w

on both end sides. Therefore, for each time instant t, given

a fixed sequence length s, the power estimation subnetwork

uses the main power sequence x~t,s,w = [xt-w, ..., xt+s+w-1]

as the input and then estimates appliance power ratings

p~i = [pi1, ..., pili ] as the output. Overall, the appliance power

estimation

part

can

be

modelled

as

fpiower

:

s+2w
R+



Rl+i .

Note that in spite of the input sequence length, the length

of output sequence is fixed as it represents the predefined

operation modes of a specific appliance. Hence, the power

regression model of an individual appliance can be formulated

as:

fpiower(x~t) = p~i

(3)

2) Right DNN Design: For the right DNN in Fig. 4,
the state classification subnetwork serves as the choosing
unit for the main estimation task, in light of the inherent state property of household appliances. For appliance i, let oit(j)  {0, 1}, j = 1, .., li, denotes the ON/OFF state of a decomposed virtual appliance j at time t, and:

oit(j) =

1, 0,

if yti = pij , otherwise.

(4)

Same as the power estimation subnetwork, we utilize x~t,s,w = [xt-w, · · · , xt+s+w-1] as the input sequence. However, unlike the fixed output length in power estimation subnetwork, the

length of output sequences in state classification subnetwork

largely depends on the sequence length s, since it aims

to predict which virtual device would be active at time t.

The virtual ON/OFF state sequence could be denoted as

o~t,s,j = (ot(1), · · · , ot(lj ), · · · , ot+s-1(l), · · · , ot+s-1(lj )).
Hence, the ON/OFF state subnetwork could be defined as fOi N : Rs++2w  {0, 1}sli and the mapping model is:

fOi N(x~t) = o~it

(5)

Here the state identification subnetwork is indeed a classification model, with oit(j) denoting the probability that virtual

5

appliance j is at ON state at time t. With Eq. (3) and Eq. (5), we then can obtain the final output of the dual-DNN by:

foiutput = fpiower(x~t)  fOi N(x~t)

(6)

where foiutput(t) is the output of dual-DNN at time t, and  represents the matrix multiplication.
3) Loss Functions Design: With the above design, naturally, the loss function of the dual-DNN architecture can be formulated as follows:

Lioutput

=

1 T

T
(yti - o~itp~i)2

(7a)

t=1

Lipower

=

1 li

li
(pij
j=1

- p~ij )2

(7b)

LiON

=

-

1 T

T

li
oit(j) log o~it(j)

(7c)

t=1 j=1

Note that the power estimation subnetwork and the whole

dual-DNN both aim to estimate the power consumption metric,

so the mean squared error (MSE) loss is used in both loss

functions Lipower and Lioutput. Meanwhile, the state identification subnetwork is responsible to learn the running state of each

(virtual) appliance, namely to identify whether the appliance

is currently at ON or OFF state, and therefore LiON is indeed the sigmoid cross entropy loss.

For the whole dual-DNN architecture, we leverage the sum

of the overall network loss and the state classification network

loss for joint optimization, and thus define the whole loss

function as:

L = Lioutput + LiON

(8)

Note that the cross entropy loss term Lion is of vital importance to the whole loss function as it not only explicitly reflects the state classification error, but also guarantee an appliance operation rule that household appliances can only operate in one mode at any given time. Hence, only through joint optimization can we obtain accurate and practical ED results.

V. VARIANTS OF DUAL-DNN
In this section, we further modify our approach by enforcing the sparsity property to the dual-DNN and propose several variants, which are expected to enhance the performance of original model on energy disaggregation.

A. Median dual-DNN
Based on the sparsity property of appliance operations, it is not realistic for home appliances to changes states at each time instance. Therefore, we propose to employ the median filtering, which is commonly employed in image processing to filter out pepper noise [12]. Specifically, we perform the median filtering operation for the outputs from the state classification subnetwork (i.e., right DNN of the dual-DNN). Without loss of generality, we consider a particular appliance with two states: s1 and s2, and we do not expect the transition between these two states occurring frequently in short intervals, namely its power readings are expected to be piece-wise constant over the

TABLE I APPLIANCE PARAMETERS FOR THE EXPERIMENTS. POWER UNIT IS WATT.

Window REDD Length UK-
DALE State REDD Number UK-
DALE Power Mean Standard Deviation

Kettle -
432 3
700 1000

Micro wave 864
432
3
3
500 800

Fridge 864 432
4 4 200 400

Dish Washer
864
432
4
3
700 1000

Washing Machine
864
432
3
4
400 700

time. With ot denoting the estimated appliance state at time instance t, the median filtering is applied as follows:

ot-L =

s1, s2,

if ot-L = s2 and med(ot, ..., ot-L) = s1 if ot-L = s1 and med(ot, ..., ot-L) = s2

(9)

B. Hard dual-DNN
From another viewpoint, the outputs of state identification subnetwork are essentially the probabilities of virtual appliances at ON/OFF states. Therefore, instead of multiplying the estimated power ratings with the probability outputs, it is intuitive to multiply the power ratings by 1 or 0 (i.e., the ON or OFF state). This kind of "hard gating" seems more compliant to the practical appliance operation. In implementation, the hard gating goal can be achieved simply by replacing the greatest probability as 1 and other smaller probabilities as 0. A condition function for hard gating can be formulated accordingly:

1, if x is the greatest probability

h(x) =

(10)

0, otherwise

Then the final output, given by Eq. (6), can be updated by:

foiutput = fpiower(x~t)  h(fOi N(x~t))

(11)

Specifically, we employ the gumbel softmax2 to convert probabilities to one-hot codes, while ensuring the derivability of networks.
Furthermore, we also consider dual-DNN with both hard gating and median filtering, i.e., first modify the original outputs with hard gating function h(x), and then filter out implausible impulses through median filtering. Accordingly, we name such a variant as hard median dual-DNN.

VI. EXPERIMENTS
A. Datasets
We evaluate the proposed dual-DNN for NILM tasks on two public datasets, namely REDD [14] and UK-DALE [15] datasets, both of which contain not only the aggregate power consumption but also the individual appliance power readings.
2Gumbel softmax technique is based on Gumbel-Softmax distribution that is smooth and has a well-defined gradient. In this way, the discrete one-hotencoded categorical distributions can be further replaced by gumbel softmax samples to compute gradients [13].

6

Fig. 5. Detailed architecture of Dual-DNN implemented in experiments for UK-DALE dataset.

REDD dataset: The REDD dataset contains power sequence data for six US houses, with 1 Hz sampling frequency for mains meter and 3 Hz for 10-25 types of appliances meter. Since there is no kettle data, we only consider microwave, fridge, dish washer and washing machine, as these appliances are normally used in previous work [16], [10], [7], [11]. In this way, we can compare our performance with existing solutions.
UK-DALE dataset: In UK-DALE, the mains readings were recorded every 1 second and appliances power readings were recorded every 6 seconds from November 2012 to January 2015. This dataset contains aggregate power consumption and measurements of 4 - 54 appliances from five UK houses. In this paper we also focus on kettle, microwave, fridge, dish washer and washing machine for the same reason mentioned above.
B. Data preprocessing
Filling: After inspection, we find that it is not uncommon to see chunks of missing values, range from seconds to minutes, in mains and appliances power readings, possibly due to switched-off sensors or dead batteries. Therefore, for gaps shorter than 3 minutes, they are filled by the backward filling method, and for gaps longer than 3 minutes, they are assumed to be due to the appliance and meter being switched off and thus are filled with zeros.
Normalization: For both REDD and UK-DALE data, the aggregate power consumptions and individual appliances' power consumptions are preprocessed by subtracting the mean values and dividing by the standard deviations. The mean and standard deviation values of individual appliances are given in Table I, both of which are obtained via statistical analysis in NILMTK [17]. After normalization, this data can be fed into DNN models for training.
State identification: A rough knowledge of appliance operation modes, i.e., the number of states for each appliance, is required to build the dual-DNN. This information can be obtained from appliances' power readings in training datasets through k-means clustering or a simple visual detection. In this paper, we leverage k-means clustering to determine the state information of selected appliances in REDD and UKDALE datasets. Moreover, in order to save clustering time and enhance accuracy, we first use 15 watts as the ON state threshold, and merely cluster power rating that are larger than this threshold. The state information will be utilized in the last fully connected (FC) layers of both subnetworks to regulate the length of network outputs (refer to FC Layer2 in Fig. 5).

In real world, such state information can be readily acquired from user manuals of household appliances.

C. Networks training
As benchmarks, the performance of Factorial Hidden Markov Models (FHMM) [18], [16], denoising autoencoder (DAE) [10] and Seq2Point [7] (a variant of Seq2Seq) are evaluated. We implement the above benchmarks with NILMTK [17], an open toolkit for analysis on non-intrusive load monitoring. As the most relevant work to ours, SGNN is also implemented according to the architectures and training details in [11].
The detailed dual-DNN structure is shown in Fig. 5, which adopts convolutional neural network (CNN) as basic architecture for each subnetwork, as empirical studies have demonstrated that CNNs outperform RNNs in NILM [10]. Our network has the following hyperparameters: the batch size is 16, the leaning rate is 1.0  10-3, and the number of epoch is 10. The dual-DNN model is trained on Tesla T4 with 16GB of RAM using Pytorch. For evaluation, we leverage the last week data of each dataset for testing and the data before last week as the training set.
As shown in Fig. 5, the input sequence length for both power estimation subnetwork and state classification subnetwork is 432 for UK-DALE dataset, which is made up of partial sequence s = 32 and additional window w = 200 on both sides. The only difference in subnetwork structure is the number of neurons in the last fully connected layer, which is li for the power estimation subnetwork and 32  li for the state classification subnetwork. Then, we further reshape the outputs of these two subnetworks and conduct matrix multiplication to obtain the final output. The input window lenth of REDD dataset is 864, with partial sequence s = 64 and additional window w = 400. The input mains sequence for both REDD and UK-DALE datasets is of 43.2 minutes and the output sequence is 3.2 minutes as in the previous work [11].

D. Evaluation metrics

We apply the mean absolute error (MAE) and signal aggregate error (SAE) to evaluate the performance of different approaches, both of which are commonly used metrics for NILM approaches. Denoting yti as the ground truth and y~ti as the estimated power consumption for appliance i at time t, the MAE for appliance i can be defined as:

M AEi = 1 T T

yti - y~ti

(12)

t=1

7

TABLE II EXPERIMENT RESULTS ON UK-DALE AND REDD DATASETS, RESPECTIVELY, WITH BEST RESULTS HIGHLIGHTED IN BOLD.

Metric MAE SAE

Model
FHMM DAE
Seq2Point SGNN
Dual-DNN Median Dual-DNN
Hard Dual-DNN Hard Median Dual-DNN
FHMM DAE
Seq2Point SGNN
Dual-DNN Median Dual-DNN
Hard Dual-DNN Hard Median Dual-DNN

Kettle
38.44 22.52 13.43 11.07 17.60 9.05 8.56 8.80 1.85 1.35 1.21 0.99 0.86 0.94 0.77 0.78

Fridge
60.93 26.72 16.77 16.71 17.67 19.72 14.55 18.30 0.98 0.77 0.56 0.52 0.50 0.47 0.37 0.36

UK-DALE

Microwave

Dish Washer

47.83

48.25

19.47

29.44

10.61

27.42

9.87

23.16

12.15

17.31

11.84

17.04

10.89

14.18

11.67

13.40

1.04

2.50

1.14

1.98

0.69

1.59

0.70

0.78

0.78

0.98

0.77

0.92

0.65

0.83

0.59

0.79

Washing Machine
66.94 18.35 14.55 12.31 13.11 13.16 12.46 11.49 5.50 3.83 2.45 2.28 2.66 2.05 1.45 1.28

Fridge
78.67 56.82 20.89 22.86 18.47 16.72 12.26 10.89 1.46 1.06 0.89 0.62 0.73 0.54 0.45 0.39

REDD

Microwave

Dish Washer

87.00

98.30

25.47

29.38

17.61

27.70

15.98

14.97

13.24

17.20

14.18

18.08

10.15

16.84

12.67

16.40

1.35

0.98

1.04

0.78

0.86

0.65

0.70

0.45

0.78

0.72

0.77

0.57

0.62

0.35

0.57

0.33

Washing Machine
86.24 36.25 22.67 18.24 18.57 19.22 18.66 17.49 4.50 2.84 1.35 0.83 0.85 0.83 0.66 0.67

AVG Improve
0.00% -1.03% 4.24% 18.34% 16.57% 0.00% -12.64% 0.76% 21.82% 26.77%

We utilize the normalised signal aggregate error (SAE) to evaluate the aggregate estimation error over a certain period of time. Let ri and r~i represent the ground truth and inferred total energy consumption of appliance i in the total time period. Thus, the SAE can be formulated as:

SAEi =

r~i - ri ri

(13)

A method could be accurate enough to estimate the daily appliance energy consumption (i.e., high SAE) yet may fail to achieve per-timestep prediction (i.e., low MAE). Hence, only by jointly considering MAE and SAE can we find the most practical NILM approach.

Power(W)

Power(W)

500

250 Ground truth

250

400

dual-DNN 200

200

300

150

Ground truth 150

Ground truth

200

100

Median DDNN 100

Hard MDDNN

100

50

50

0 0 5 10 15 20

00

5 Tim1e0(min)15 20

0 0 5 10 15 20

(a) Fridge

1500 1000 500
0 0

1500

Ground truth 1000 dual-DNN
500

0

2

4

0

1500

Ground truth 1000 Median DDNN
500

0

2

4

0

Time(min)

Ground truth Hard MDDNN

2

4

E. Experiment results
1) Overall Results: Table II demonstrates the performance of benchmarks and our dual-DNN approach on REDD and UK-DALE datasets, respectively. The bold numbers denotes the best ED algorithms, which show that dual-DNN has surpassed the state-of-the-art performance in most cases. Specifically, our hard median dual-DNN reduces MAE by up to 16.57% and SAE by up to 26.77%, with improvements for 8 out of 9 cases in MAE and all 9 cases in SAE, respectively. On average, hard dual-DNN and hard median dual-DNN demonstrate approximately 16%-27% reduction in errors compared with the best of previous works. Median dual-DNN tends to perform worse than hard dual-DNN but still slightly outperforms the state-of-the-arts, and significant error deduction could be achieved by hard median dual-DNN. Therefore, in reality, we can choose from hard dual-DNN or hard median dual-DNN based on the appliance types.
2) Detailed Results: Figure. 6 shows three examples of the proposed dual-DNN, median dual-DNN (MDDNN in the figure) and hard median dual-DNN (HMDNN in the figure). In the case of fridge, median filtering mainly works for filtering out the noises at the beginning of operation and hard gating mechanism helps to regulate the power estimation, i.e., to avoid the influence of higher power states. In the case of microwave, median filtering again takes the responsibility to

(b) Microwave

Power(W)

Ground truth

Ground truth

Ground truth

800

dual-DNN 800

Median DDNN 800

Hard MDDNN

600

600

600

400

400

400

200

200

200

0 0 5 10 15

0 0 5 10 15 Time(min)

0 0 5 10 15

(c) Dish Washer
Fig. 6. Disaggregation results of the fridge, microwave and dish washer, respectively, in which "MDDNN" stands for median dual-DNN and "HMDNN" stands for hard median dual-DNN.

make sure power signals piece-wise constant over time. In the case of dish washer, all three algorithms demonstrate satisfied performance in estimating power consumption of dish washer during this activation. Based on our observation, we find that the state identification subnetwork in dual-DNN is capable to learn features that indicate appliances' states, and thus succeeds in estimating typical operation durations of appliances. Meanwhile, the power estimation subnetwork does its job of estimating the power rate information of a multi-state appliance.
3) Deep Dive: Seemingly, a pure dual-DNN (without median filtering and hard gating) performs worse than SGNN on

8

average. Thus, we extend our experiments to further investigate the effectiveness of dual-DNN framework. Specifically, we implement a SGNN variant by introducing both median filtering and hard gating mechanism, and perform comparison experiments among the SGNN, the SGNN variant and the dual-DNN variant. For fast validation purpose, we only use one-house load data from UK-DALE and REDD, respectively. The results from new experiments are summarized in Table. III, from which we find that: i) the SGNN variant outperforms the original SGNN with a 18% performance improvement (12.50% for MAE and 22.67% for SAE, respectively), and ii) our approach (dual-DNN with median filtering and hard gating) outperforms the SGNN variant by 11% (8.32% for MAE and 13.12% for SAE, respectively). Therefore, we can conclude that the strength of our approach indeed comes from two factors: the dual-DNN block, and the median filtering and hard gating block. The former is designed to extract appliances' latent features through deep neural networks, and the latter part is designed to enforce the general features in appliances' operations. The experimental results also verified that, only through the combination of the two parts can we achieve plausible and accurate energy disaggregation results.
VII. RELATED WORK
Non-intrusive load monitoring or energy disaggregation, was first introduced by George Hart in 1992 [6]. Since that, various approaches have been proposed to solve this single channel BSS problem. The NILM methods can be broadly classified as i) optimization based approaches and ii) DNN based approaches.
Optimization based Approaches: To begin with, optimization based algorithms generally define the load aggregation task as an optimization problem, and usually employ techniques such as evolutionary algorithms [19], [20], linear and nonlinear integer programming approaches [21], [22]. The prior knowledge of appliances, including the operation states and corresponding power ratings which can be easily acquired from users' manual, is frequently leveraged to obtain the optimal solution. The ED performance of optimization-based algorithms largely depends on the objective functions and related constraints. Apart from the most commonly employed objective function - least square error (LSE) between measured and approximated aggregate power consumption [19], there are several enhancements via median filtering [22], convex penalty term [23] and linear-programming based refinement [24]. However, such optimization based algorithms fail in practical settings as they assume the aggregate energy consumption equals the sum of considered appliances' usage. But the thing is we cannot input all the household appliance information into the model and literature shows that the energy consumption from unknown sources, such as living room usage and electric cars, can take up 51.86% of total energy [25], which limit the practicability and effectiveness of optimization based ED algorithms.
DNN based Approaches: Deep learning approaches are demonstrated to be promising for NILM with its excellent

performance. In [10], the authors take the first step to leverage various deep learning models including convolutional neural networks (CNN), recurrent neural networks (RNN), and Denoising Autoencoder (DAE) in NILM problems. In light of sequence-to-sequence (seq2seq) learning, the authors in [7] suggest a sequence-to-point learning based on CNN structure to map the single mid-point of appliance's power reading with mains reading. Also inspired by seq2seq learning, the authors in [26] propose a novel deep generative architecture for performing sequence-to-many-sequence learning, i.e., mains power consumption to several appliances' power consumption. Then, in [11], the researchers begun to utilize ON/OFF state property of electric devices to serve as a "gating unit", namely refinement, for their regression results. While demonstrating significant performance improvement, none of these deep learning based NILM methods leverage inherent operation properties of end-use appliances, leading to rather implausible energy breakdown results.
In summary, the optimization based approaches utilize appliance state information to obtain accurate ED results but suffer from practical settings; the DNN based approaches leverage deep learning to enhance NILM performance yet fail to take appliances' properties into account. To the best of our knowledge, our solution is the first DNN based approach that aims to measure the appliance's operation state and leverages underlying appliance properties to enhance ED performance.
VIII. CONCLUSIONS
In this paper, we investigated the well-known non-intrusive load monitoring problem. Our data analysis revealed that the operations of household appliances generally have notable multi-state and sparsity properties, which can be exploited for NILM. We were inspired to develop a dual-DNN for energy disaggregation. Specifically, we introduced a multitask neural network framework that consists of two parallel subnetworks, one aims to estimate the power ratings of appliances at different states, and the other is responsible to identify current operation states of devices. Empirical evaluations on benchmark datasets and algorithms validated the effectiveness and practicability of our solution. The dual-DNN approach presented in this work could be potentially applied to other learning tasks that can be divided into one estimation problem and the other classification problem.
REFERENCES
[1] UNEP, "Energy efficiency for buildings," https://www.euenergycentre. org/images/unepinfosheet-eebuildings.pdf, 2016.
[2] A. T. S. ENERGY, "Overview," https://www.ase.org/initiatives/buildings, 2018.
[3] C. Fischer, "Feedback on household electricity consumption: a tool for saving energy?" Energy Efficiency, vol. 1, no. 1, pp. 79­104, 2008.
[4] J. Froehlich, E. Larson, S. Gupta, G. Cohn, M. Reynolds, and S. Patel, "Disaggregated end-use energy sensing for the smart grid," IEEE pervasive computing, vol. 10, no. 1, pp. 28­39, 2010.
[5] TED, "The energy detective," http://bit.ly/28UKP62, 2020. [6] G. W. Hart, "Nonintrusive appliance load monitoring," Proceedings of
the IEEE, vol. 80, no. 12, pp. 1870­1891, 1992. [7] C. Zhang, M. Zhong, Z. Wang, N. Goddard, and C. Sutton, "Sequence-
to-point learning with neural networks for nonintrusive load monitoring," 2016.

9

TABLE III RESULTS FROM UK-DALE AND REDD DATASETS, RESPECTIVELY, WITH BEST RESULTS HIGHLIGHTED IN BOLD.

Metric MAE SAE

Model
SGNN Hard Median SGNN Hard Median Dual-DNN
SGNN Hard Median SGNN Hard Median Dual-DNN

Kettle
15.24 13.07 11.56 1.37 0.95 0.81

UK-DALE (One-house Data)

Fridge

Microwave

Dish Washer

20.77

12.74

26.81

17.51

10.65

23.51

15.72

10.44

19.44

0.86

1.01

1.28

0.77

0.88

0.90

0.60

0.76

0.78

Washing Machine
16.19 15.31 14.73 2.75 2.47 2.18

Fridge
25.78 22.74 19.86 0.98 0.60 0.51

REDD (One-house Data)

Microwave

Dish Washer

Washing Machine

19.05

17.38 22.15

16.38

15.14 19.78

14.78

16.03 18.71

1.10

0.79

1.18

0.88

0.57

0.73

0.77

0.49

0.70

AVG Improve
8.32% 12.50%
13.12% 22.67%

[8] E. M. Grais, M. U. Sen, and H. Erdogan, "Deep neural networks for single channel source separation," in 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2014, pp. 3734­3738.
[9] P.-S. Huang, M. Kim, M. Hasegawa-Johnson, and P. Smaragdis, "Deep learning for monaural speech separation," in 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2014, pp. 1562­1566.
[10] J. Kelly and W. Knottenbelt, "Neural nilm: Deep neural networks applied to energy disaggregation," in Proceedings of the 2nd ACM International Conference on Embedded Systems for Energy-Efficient Built Environments, ser. BuildSys '15. New York, NY, USA: Association for Computing Machinery, 2015, p. 55­64. [Online]. Available: https://doi.org/10.1145/2821650.2821672
[11] C. Shin, S. Joo, J. Yim, H. Lee, and W. Rhee, "Subtask gated networks for non-intrusive load monitoring," Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, pp. 1150­1157, 2019.
[12] B. Justusson, "Median filtering: Statistical properties," in TwoDimensional Digital Signal Prcessing II. Springer, 1981, pp. 161­196.
[13] E. Jang, S. Gu, and B. Poole, "Categorical reparameterization with gumbel-softmax," arXiv preprint arXiv:1611.01144, 2016.
[14] J. Z. Kolter and M. J. Johnson, "Redd: A public data set for energy disaggregation research," in Workshop on data mining applications in sustainability (SIGKDD), San Diego, CA, vol. 25, no. Citeseer, 2011, pp. 59­62.
[15] J. Kelly and W. Knottenbelt, "The uk-dale dataset, domestic appliancelevel electricity demand and whole-house demand from five uk homes," Scientific data, vol. 2, no. 1, pp. 1­14, 2015.
[16] J. Z. Kolter and T. Jaakkola, "Approximate inference in additive factorial hmms with application to energy disaggregation," in Artificial intelligence and statistics. PMLR, 2012, pp. 1472­1482.
[17] N. Batra, R. Kukunuri, A. Pandey, R. Malakar, R. Kumar, O. Krys-

talakos, M. Zhong, P. Meira, and O. Parson, "Towards reproducible state-of-the-art energy disaggregation," in Proceedings of the 6th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation, 2019, pp. 193­202. [18] Z. Ghahramani and M. I. Jordan, "Factorial hidden markov models," Machine learning, vol. 29, no. 2, pp. 245­273, 1997. [19] D. Egarter and W. Elmenreich, "Evonilm: Evolutionary appliance detection for miscellaneous household appliances," in Proceedings of the 15th annual conference companion on Genetic and evolutionary computation, 2013, pp. 1537­1544. [20] ----, "Load disaggregation with metaheuristic optimization," in Energieinformatik, 2015, pp. 1­12. [21] K. Suzuki, S. Inagaki, T. Suzuki, H. Nakamura, and K. Ito, "Nonintrusive appliance load monitoring based on integer programming," in 2008 SICE Annual Conference. IEEE, 2008, pp. 2742­2747. [22] M. Z. A. Bhotto, S. Makonin, and I. V. Bajic, "Load disaggregation based on aided linear integer programming," IEEE Transactions on Circuits & Systems II Express Briefs, vol. 64, no. 7, pp. 792­796, 2016. [23] D. Piga, A. Cominola, M. Giuliani, A. Castelletti, and A. E. Rizzoli, "Sparse optimization for automated energy end use disaggregation," IEEE Transactions on Control Systems Technology, vol. 24, no. 3, pp. 1044­1051, 2015. [24] Y. Liu, Y. Sun, and B. Li, "A modified ip-based nilm approach using appliance characteristics extracted by 2-sax," IEEE Access, vol. 7, pp. 48 119­48 128, 2019. [25] Y. Jia, N. Batra, H. Wang, and K. Whitehouse, "A tree-structured neural network model for household energy breakdown," in The World Wide Web Conference, 2019, pp. 2872­2878. [26] G. Bejarano, D. Defazio, and A. Ramesh, "Deep latent generative models for energy disaggregation," Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, pp. 850­857, 2019.

