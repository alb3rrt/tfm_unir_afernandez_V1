
# Dual Normalization Multitasking for Audio-Visual Sounding Object Localization

[arXiv](https://arxiv.org/abs/2106.0180), [PDF](https://arxiv.org/pdf/2106.0180.pdf)

## Authors

- Tokuhiro Nishikawa
- Daiki Shimada
- Jerry Jun Yokono

## Abstract

Although several research works have been reported on audio-visual sound source localization in unconstrained videos, no datasets and metrics have been proposed in the literature to quantitatively evaluate its performance. Defining the ground truth for sound source localization is difficult, because the location where the sound is produced is not limited to the range of the source object, but the vibrations propagate and spread through the surrounding objects. Therefore we propose a new concept, Sounding Object, to reduce the ambiguity of the visual location of sound, making it possible to annotate the location of the wide range of sound sources. With newly proposed metrics for quantitative evaluation, we formulate the problem of Audio-Visual Sounding Object Localization (AVSOL). We also created the evaluation dataset (AVSOL-E dataset) by manually annotating the test set of well-known Audio-Visual Event (AVE) dataset. To tackle this new AVSOL problem, we propose a novel multitask training strategy and architecture called Dual Normalization Multitasking (DNM), which aggregates the Audio-Visual Correspondence (AVC) task and the classification task for video events into a single audio-visual similarity map. By efficiently utilize both supervisions by DNM, our proposed architecture significantly outperforms the baseline methods.

## Comments

10 pages, 6 figures

## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{nishikawa2021dual,
      title={Dual Normalization Multitasking for Audio-Visual Sounding Object Localization}, 
      author={Tokuhiro Nishikawa and Daiki Shimada and Jerry Jun Yokono},
      year={2021},
      eprint={2106.00180},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

## Notes

Type your reading notes here...

