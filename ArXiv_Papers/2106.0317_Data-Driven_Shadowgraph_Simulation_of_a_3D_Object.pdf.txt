Published as a workshop paper at ICLR 2021 SimDL Workshop

arXiv:2106.00317v1 [cs.LG] 1 Jun 2021

DATA-DRIVEN SHADOWGRAPH SIMULATION OF A 3D OBJECT
Anna Willmann1, Patrick Stiller1, Alexander Debus1, Arie Irman1, Richard Pausch1, Yen-Yu Chang1, Michael Bussmann1,2, Nico Hoffmann1 1 Helmholtz-Zentrum Dresden - Rossendorf, Bautzner Landstrasse 400, 01328 Dresden, Germany 2 CASUS - Center for Advanced Systems Understanding, Untermarkt 20, 02826 Go¨rlitz, Germany

ABSTRACT
In this work we propose a deep neural network based surrogate model for a plasma shadowgraph - a technique for visualization of perturbations in a transparent medium. We are substituting the numerical code by a computationally cheaper projection based surrogate model that is able to approximate the electric fields at a given time without computing all preceding electric fields as required by numerical methods. This means that the projection based surrogate model allows to recover the solution of the governing 3D partial differential equation, 3D wave equation, at any point of a given compute domain and configuration without the need to run a full simulation. This model has shown a good quality of reconstruction in a problem of interpolation of data within a narrow range of simulation parameters and can be used for input data of large size.

1 INTRODUCTION
Simulations of physical processes are required in theory development and give better understanding of complex dynamics that are involved into phenomena. The more complicate system is considered the more compounded is the model of it and higher requirements to the computational power appear. For simplification of such models there are used surrogate models - models, that are created to study only certain aspects of processes that an original model represents precisely but in the same time other dynamics are excluded or have not expected behavior. Surrogate models can reduce time consumption of a research with an acceptable loss in accuracy of results. Plasma shadowgraph is one of diagnostic techniques that provides a visualization of perturbations in a transparent medium as such phenomena are not visible by human eyes. This technique is based on refraction of probe rays when they are distributing through a medium, focused and specifically filtered in order to represent differently refracted rays by light and dark zones(Traldi et al., 2018). Application of a plasma shadowgraph to some phenomena in plasma such as for example laser wakefield acceleration(Albert et al., 2014) can be not trivial due to intense interaction between particles inside plasma and the micron scale of fluctuations. For a correct analysis of the experimental data we need high quality simulations of these processes. Simulation of a plasma shadowgraph consists of two steps. At first we need to approximate the solution of Maxwell's equations and then we can calculate propagation of light in free space from Fourier optics. The model that is proposed in this paper is supposed to approximate the solution on the first step of the shadowgraph simulation, for simplification of the problem, we consider only the electric field component. The main contribution of this work is a data-driven reduced-order model for approximation of the numerical simulation of large 3D computational domains. The neural network is approximating the solution for a simplified version of Maxwell's equations in a context of the electric field propagation problem, that can be described by the following equation:

2E t2

-

1 µ

2E

=

0

1

Published as a workshop paper at ICLR 2021 SimDL Workshop
where E is the electric field, µ and are permeability and permittivity of a medium. The model is capable of reconstructing new simulations of the electric field for different parameters within a range limited by parameter values of existed simulations. Finally, we will be analysing the applicability of our approach for interpolation as well as extrapolation in parameter space compared to ground-truth data.
2 RELATED WORKS
Artificial neural network based models are widely applied in the field of radiophysics and in particular for approximation of solution for Maxwell's equations. Thus, for example physics informed neural networks, introduced in (Raissi et al., 2017) were applied in (Fang & Zhan, 2020) for approximation of solution of the frequency domain Maxwell's equation in the context of metamaterial design and for approximation of time-domain electromagnetic simulations derived by Maxwell's equations in (Zhang et al., 2020). Another example of a surrogate model for Maxwell's equations is presented in the paper (Bartlett, 2018), as opposed to previous two works, there authors use not only fully connected architecture but also convolutional architecture to archive better quality solution approximation of Maxwell's equations over an arbitrary dielectric permittivity. In these works models approximate a solution directly based on the input parameters. Such method is intuitive but with increasing of outputs' size one can encounter a problem of high resource consumption. Another kind of methods, projection based models that reduce dimensionality of the original model and approximate solution in a reduced space. In (Noakoasteen et al., 2020) authors proposed an autoencoder based architecture for approximation of Maxwell's equations solution. A convolutional autoencoder decreases dimensionality of input data and evolution in time is recurrently computed by a modified LSTM(Hochreiter & Schmidhuber, 1997) network on the reduced space. Another work that proposes an autoencoder based solver for Maxwell's equations is (Cheng et al., 2020) for the problem of wave propagation. The model proposed in our work solves the problem of approximation using architecture of an autoencoder in order to reduce number of operations at approximation itself and in the same time replaces recurrent computations of each next time point by a direct mapping of parameters to a solution approximation in a reduced space.
3 METHOD
The model consists of two parts, the first one, autoencoder, reduces dimensionality of input data and transforms it back to the original size and the second one, projection approximator, approximates the solution in a reduced space. The structure of the autoencoder is adopted from (Kim et al., 2019), where it is used as a part of a reduced order model for fluid dynamics simulations. The encoder consists of convolutional downsamling layers, each is preceded by a block of convolutional layers and an additive skip connection between them, the decoder is structured in the same way but layers are arranged in a reverse order. In addition, the last downsampling layer is followed by one more block of convolutional layers and afterwards there is applied a linear layer to reduce vector size to the desirable size of the latent space. In this work we define number of downsampling layers by the formula proposed in (Kim et al., 2019) depending on a size of input, number of preceded convolutional layers is set to 4. Each layer in the network is followed by the activation function LeakyReLU(Maas, 2013) with leak of 0.2. The projection approximator can be seen as multi-layer perceptron architecture consisting of 4 fully connected layers: the input layer of size k + 1, 2 hidden layers and the output layer of latent size l, each hidden layer is followed by sin(x) activation function that captures the functional relationship of adjacent latent codes. Compression of 3D simulation data: let us denote the encoder by R : Rh × w × d  Rl, where h, w, d - height, width and depth of an input volume E(t) at time point t, l is a size of its latent representation. Then the decoder is denoted by G : Rl  Rh × w × d. This autoencoder is trained by minimizing the supervised reconstruction loss LR,G of an original volume E(t) and a
2

Published as a workshop paper at ICLR 2021 SimDL Workshop

reconstructed one E(t) = G(R(E(t))): LR,G(E(t)) = ||E(t) - E(t)||1

Projection approximation in Latent Space: the projection approximator is learning the mapping F : Rk + 1  Rl, where k is a number of simulation parameters and one additional parameter is a time point at which a solution is to be approximated. The objective function of this network is the supervised approximation error,
LF (R(E(t)), p, t) = ||R(E(t)) - F (p, t)||2
where p is a vector of simulation parameters and t some point in time. Pretrained autoencoder and projection approximator allows us to reconstruct the solution of our system for different points as of E(ptr)edicted = G(F (p, t)).

4 RESULTS

For validation of the proposed model there are used simulations of beam propagation. Each simulation is an approximation of electric field propagation through a cell with a sphere in the middle that is defined by a radius r and a refractive index n, calculated by finite-difference time-domain method(Kane Yee, 1966) using a library Meep(Oskooi et al., 2010). An example of such simulation is shown in figure 1. Surfaces of a cube represent middle slices of the cell from corresponding planes.

The cell has physical size of 12µm in each dimension with perfectly matched layer of 2µm for the absorption at the boundary, proposed in (Berenger, 1994). Beam propagates in direction of axes Z, time points are given in units, one unit corresponds to 104.17µs. All parameters of simulations are given in supplementary material.

For training of the autoencoder such simulations were

used with the following ranges of varying parameters: ra-

dius in [2.0µm, 4.0µm] with a step of 0.5µm and refrac-

tive index in [1.1, 1.7] with a step of 0.1. The same data

in the reduced space is used for training of the projection

approximator. Permutations of these values bring to 35

simulations that were used as training data for the autoen-

coder, one simulation approximates the electric field at each time point in range [0.0, 10.0] with a step of 0.03125

Figure 1: Example of simulation

time units, in total each simulation consists of 321 files where each file is a 3D array of size

193 × 193 × 193 and takes 55Mb of memory and ca. 18Gb for a one full simulation.

4.1 TRAINING OF MODEL The networks were trained sequentially since the projection approximator requires a large number of epochs for convergence which would be computationally unfeasible in an end-to-end setting. Therefore, the autoencoder was trained first allowing us to precomputed the latent codes of all volumes of our training. The precomputed latent codes are then used for further training of the projection approximator. Parameters of networks were optimized by Adam optimizer(Kingma & Ba, 2017) with learning rate of 0.0001 over 160 iterations (autoencoder) and 0.001 over 18400 iterations (projection approximator). Training of autoencoder was performed on 28 GPUs NVIDIA V100 for 29 h and of projection approximator on 8 GPUs for 6 h.

4.2 ANALYSIS OF LATENT CODE The analysis of temporal evolution of certain latent codes in the reduced space can give us better understanding and interpretation of the compressed representation.

3

Published as a workshop paper at ICLR 2021 SimDL Workshop

Figure 2 illustrates two series: one series shows the time evolution of a single voxel of our original input volume while the other series shows the time evolution of a certain latent dimension of the very same dataset. There we see that the wave pattern with its period is preserved over encoding, then we can conclude that the field is compressed with maintaining certain physical dependencies from the original volume while parameters of simulation correspond to the range of values in latent representation.

Figure 2: Evolution of components in the original and reduced spaces

4.3 GENERATION OF SIMULATIONS
The interpolation of simulations between known parameter values was performed successfully for the described model. Figures 3, 4 show several examples of reconstruction. The model has shown an ability to reconstruct propagation of the field for all considered time points in the training set maintaining the structure of the field including refraction of the field in the location of a sphere as well as a distance on which the field is propagated until a certain point in time.

Figure 3: The reconstructed volumes clearly resemble the field data of the 3D wave equation.

Examples from figure 3 relate to time points 3.0, 6.0 and 9.0 respectively for a simulation with the same radius and refractive index. Examples from figure 4 show that the model is able to recognize different input radii of a sphere as well as different refractive indices respectively. Table 1 provides average reconstruction errors over each simulation.

Table 1: Reconstruction error for interpolation Parameters r, n L1 error

The model can handle parameter values beyond the considered ranges (extrapolation) for training only within a small distance as new simulations contain features that did not appear in the training set.

2.25µm, 1.65 0.01639

The time consumption for approximation of a sin-

3.25µm, 1.25 0.01595

gle 3D volume is reduced by a factor of four

3.25µm, 1.65 0.01813

compared to the computational time of conven-

3.75µm, 1.65 0.01823

tional numerical method: the FTDT method im-

plemented in Meep takes ca. 0.8 s per time point

while for the developed model it takes ca. 0.18 s. An even larger improvement in runtime can be

gained as the projection approximator network not only allows us to recover certain subsequent time

points but also enables us to fast-forward to any given time point of compute domain in 0.18 s.

4

Published as a workshop paper at ICLR 2021 SimDL Workshop
Figure 4: Examples of reconstruction
5 CONCLUSIONS
The fast reconstruction of experimentally accessible diagnostics is a crucial task for understanding very complex systems such as Laser plasma accelerators. A general strategy for solving the involved ill-posed inverse problems requires the optimisation of numerical simulations which is computationally very demanding. We are tackling that issue by a projection-based surrogate model that successfully approximates the governing 3D field propagation with stable behavior for interpolation in parameter space. Interestingly, we found that the autoencoder part of our architecture preserves time-dependent physical properties while also encoding information about the parameters describing the system. The surrogate model promises significant acceleration compared to numerical methods by allowing direct access to the solutions of the governing equation at any point in time without the need of time-stepping schemes. Additionally, the surrogate model promises an speedup by factor of four comparing to the conventional FTDT method even for simple time-stepping.
5

Published as a workshop paper at ICLR 2021 SimDL Workshop
REFERENCES
Felicie Albert, Alec Thomas, Stuart Mangles, S Banerjee, Se´bastien Corde, A. Flacco, Michael Litos, D Neely, J. Vieira, Zulfikar Najmudin, Robert Bingham, Chandrashekhar Joshi, and T Katsouleas. Laser wakefield accelerator based light sources: Potential applications and requirements. Plasma Physics and Controlled Fusion, 56:084015, 07 2014.
Ben Bartlett. A "generative" model for computing electromagnetic field solutions. Stanford CS229 Projects, 2018(233), 2018.
Jean-Pierre Berenger. A perfectly matched layer for the absorption of electromagnetic waves. Journal of Computational Physics, 114(2):185 ­ 200, 1994. ISSN 0021-9991.
X. Cheng, Z. Y. Zhang, and W. Shao. A surrogate model based on artificial neural networks for wave propagation in uncertain media. IEEE Access, 8:218323­218330, 2020.
Z. Fang and J. Zhan. Deep physical informed neural networks for metamaterial design. IEEE Access, 8:24506­24513, 2020.
Sepp Hochreiter and Ju¨rgen Schmidhuber. Long short-term memory. Neural Computation, 9(8): 1735­1780, 1997.
Kane Yee. Numerical solution of initial boundary value problems involving maxwell's equations in isotropic media. IEEE Transactions on Antennas and Propagation, 14(3):302­307, 1966.
Byungsoo Kim, Vinicius Azevedo, Nils Thuerey, Theodore Kim, Markus Gross, and Barbara Solenthaler. Deep fluids: A generative network for parameterized fluid simulations. Computer Graphics Forum, 38:59­70, 05 2019.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2017.
Andrew L. Maas. Rectifier nonlinearities improve neural network acoustic models. 2013. O. Noakoasteen, S. Wang, Z. Peng, and C. Christodoulou. Physics-informed deep neural networks
for transient electromagnetic analysis. IEEE Open Journal of Antennas and Propagation, 1:404­ 412, 2020. Ardavan F. Oskooi, David Roundy, Mihai Ibanescu, Peter Bermel, J.D. Joannopoulos, and Steven G. Johnson. Meep: A flexible free-software package for electromagnetic simulations by the fdtd method. Computer Physics Communications, 181(3):687 ­ 702, 2010. ISSN 0010-4655. Maziar Raissi, Paris Perdikaris, and George Em Karniadakis. Physics informed deep learning (part i): Data-driven solutions of nonlinear partial differential equations. arXiv preprint arXiv:1711.10561, 2017. E. Traldi, M. Boselli, E. Simoncelli, A. Stancampiano, M. Gherardi, V. Colombo, and Gary S. Settles. Schlieren imaging: a powerful tool for atmospheric plasma diagnostic. EPJ Techniques and Instrumentation, 4:4, 05 2018. P. Zhang, Y. Hu, Y. Jin, S. Deng, X. Wu, and J. Chen. A maxwell's equations based deep learning method for time domain electromagnetic simulations. pp. 1­4, 2020.
6

arXiv:2106.00317v1 [cs.LG] 1 Jun 2021

SUPPLEMENTARY MATERIAL
PARAMETERS OF SIMULATIONS USED FOR TRAINING DATA The cell has physical size of 12µm in each dimension and resolution of simulation is 16 pixels per µm. Boundary condition is a perfectly matched layer for the absorption with width of 2µm on each side of the cell. The source of the current starts to distribute the field in direction of axes Z from the starting point with coordinates (-4, 0, 0) w.r.t. the center of the cell(coordinates of center are (0, 0, 0)), wavelength of the source is 1.0µm, size of the source is (0, 8, 8), i.e. a flat source in space between absorbing layers. Center of a sphere is located in the middle of the cell (0, 0, 0), with defined radius and refractive index of material. Time points are given in units, one unit corresponds to 104.17µs. ADDITIONAL PLOTS TO LATENT SPACE ANALYSIS
Figure 1: Evolution of a single component from simulations with different parameters in the reduced space ADDITIONAL RESULTS
Figure 2: Reconstruction of simulation: r = 3.25µm, n = 1.65 1

Figure 3: Examples of reconstruction: interpolation
Figure 4: Examples of reconstruction: extrapolation of radius
Figure 5: Examples of reconstruction: extrapolation of refractive index 2

Table 1: Reconstruction error for extrapolation

Parameters: r, n (L1) error

4.25µm, 1.65 4.50µm, 1.65 4.75µm, 1.65

0.01639 0.01826 0.01813

3.25µm, 1.75 3.25µm, 1.90 3.25µm, 2.00

0.01877 0.02161 0.02421

3

