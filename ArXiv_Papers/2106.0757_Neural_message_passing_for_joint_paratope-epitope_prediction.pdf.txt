Neural message passing for joint paratope-epitope prediction

arXiv:2106.00757v1 [q-bio.QM] 31 May 2021

Alice Del Vecchio 1 Andreea Deac 2 3 4 Pietro Lio` 1 Petar Velickovic´ 4

Abstract
Antibodies are proteins in the immune system which bind to antigens to detect and neutralise them. The binding sites in an antibody-antigen interaction are known as the paratope and epitope, respectively, and the prediction of these regions is key to vaccine and synthetic antibody development. Contrary to prior art, we argue that paratope and epitope predictors require asymmetric treatment, and propose distinct neural message passing architectures that are geared towards the specific aspects of paratope and epitope prediction, respectively. We obtain significant improvements on both tasks, setting the new state-of-the-art and recovering favourable qualitative predictions on antigens of relevance to COVID-19.
1. Introduction
Antibody binding site prediction is an important unsolved problem in immunology and is a prerequisite for in silico vaccine and synthetic antibody design. Currently, the most accurate method for determining these regions is by observing the residues which are spatially close in the 3D bound structure, obtainable by experimental techniques such as X-ray crystallography (Smyth & Martin, 2000). However, these experimental methods are time consuming and expensive, so there is a need to develop computational methods which can overcome these problems to aid faster development of therapeutics. For example, in the ongoing COVID19 pandemic, mutations in the antigen have been shown to cause changes to the binding mechanism (Thomson et al., 2021), potentially impacting the efficacy of existing vaccines. Such a computational tool would allow for quick determination of the impact of these mutations, allowing for vaccine development to keep up with fast occurring mutants.
We only consider scenarios where the antigen is a protein. Hence, both the antibody and the antigen may be viewed as sequences of amino acid residues. Their binding site
1University of Cambridge 2Mila 3Universite´ de Montre´al 4DeepMind. Correspondence to: Alice Del Vecchio <ard69@cam.ac.uk>.
, Preprint. Work in progress. Copyright 2021 by the author(s).

consists of two regions: the paratope on the antibody, and the epitope on its corresponding antigen. Predicting them can therefore be posed as a binary classification problem: for each amino acid residue in the antibody and antigen, respectively, do they participate in the binding?
However, proteins can also be considered as graphs with its residues as nodes, with two nodes sharing an edge if their residues are spatially close. Recently, such contact graphs have been directly leveraged for protein function prediction by Gligorijevic et al. (2020).
The advantage of considering a sequence based approach over a graph-based approach is that structural information is much harder to obtain. However, recent advancements in single-protein structure prediction from AlphaFold 2 (Jumper et al., 2020) have comparable accuracy to experimental methods. This makes the incorporation of structure justifiable as obtaining this information is becoming easier.
In this work we study the joint epitope-paratope prediction task in detail, identify an inherent asymmetry between the two tasks, and propose epitope-paratope message passing (EPMP), a hybrid method that explicity leverages this asymmetry to design potent predictors for both tasks. We set the new state-of-the-art on both tasks, and illustrate qualitatively meaningful predictions on antigens of present importance.
2. Related work
Of the two tasks, paratope prediction has seen much more success. This is because the paratope is necessarily tightly localised on the tips of the Y-shaped antibody (the so-called Fv region). In fact, many early works on paratope prediction (e.g. Liberis et al. (2018)) consider an even narrower region, the complementarity-determining region (CDR)--which rarely exceeds 30 residues. This allowed for discarding most of the antibody sequence, leading to a better-balanced prediction problem. In rare cases, the paratope can be located outside of the CDR; accordingly, we will utilise the entire Fv region as input.
Paratope prediction was tackled both by sequential (Liberis et al., 2018; Deac et al., 2019; Honda et al., 2020) and structural (Krawczyk et al., 2013; Daberdaku & Ferrari, 2019; Pittala & Bailey-Kellogg, 2020) approaches in prior art. The sequence-based models offer a strong and fast

Neural message passing for joint paratope-epitope prediction

baseline in this setting, as the median gap between paratope residues in a CDR is 1­2 residues (Akbar et al., 2021)-- hence the paratope is reasonably sequentially located within the CDR.
On the other hand, there is no Fv-like region for epitopes, and as a result the entire antigen needs to be considered. This gives epitope predictions a high degree of class imbalance: as no part of the antigen can be easily discarded at the input stage, most antigen residues will not belong to an epitope. Further, epitope residues may be far apart in the antigen sequence, implying that sequential epitope models are likely to be weak baselines. Epitopes are also specific to the antibody that targets them, implying that antibody information needs to be carefully leveraged within an epitope predictor (Krawczyk et al., 2014; Andersen et al., 2006).
3. Present work
Clear asymmetry arises between paratope and epitope prediction: paratopes are highly sequential and can be predicted well in isolation, while epitopes are structural in nature and are inherently conditioned by the paratope. Hence, we conclude that a joint paratope-epitope predictor should ideally have separately tuned architectures for the two tasks. However, the present state-of-the-art for joint paratope-epitope prediction, PECAN (Pittala & Bailey-Kellogg, 2020), uses an entirely symmetric architecture for both.
Accordingly, here we propose epitope-paratope message passing (EPMP), which designs highly asymmetrical neural networks for paratope (Para-EPMP) and epitope (EpiEPMP) predictors.
Para-EPMP is designed to exploit the sequentiality of the paratope (using a` trous convolutional neural networks), while also leveraging structural cues with graph neural networks (GNNs). We use the most expressive class of spatial GNN architectures to further take advantage of the rich and balanced paratope label information.
Conversely, Epi-EPMP is purely structural, and extensively enforces exploiting the contextual cues from the antibody, along with a multi-task approach that ensures the model's predictions are adequately regularised. Given the high potential for overfitting, we leverage the more versatile attentional class of GNNs.
4. Data
The preprocessed datasets are taken from PECAN (Pittala & Bailey-Kellogg, 2020). Different datasets are used for paratope and epitope prediction, as complexes have been filtered to ensure that no two antibodies/antigens are similar in their respective datasets.

As in other works, the paratope is defined to include the residues on the antibody which are less than 4.5A° away from any heavy atom in the antigen (non hydrogen atoms). The epitope is defined similarly, but for antigen residues.
The paratope dataset is a subset of the AbDb database (Ferdous & Martin, 2018), containing 308 complexes in the training and validation sets and 152 complexes in the test set. The Fv regions of the antibodies are used. In the test set, 9.4% of antibody residues are part of the positive class.
The epitope dataset is a subset of the SAbDab database (Dunbar et al., 2014) and the Docking Benchmark v5 (Vreven et al., 2015). There are 132 complexes in the combined training/validation set, and 30 complexes in the test set. The CDR regions of the antibodies are used, to provide highly targeted context. In the test set, 7.8% of antigen residues were part of the positive class.
The same features as in PECAN are used: a 62-dimensional feature vector for each residue, containing a one-hot encoding of the amino acid, alignment based features from the Position Specific Scoring Matrix (PSSM), surface accessibility scores and a profile counting the number of amino acid types in a sphere of radius 8A° around the residue. The graphs in PECAN are restricted to a neighbourhood of the closest 15 neighbours (up to a distance of 10A° ). To allow these to be used as undirected graphs, we symmetrise the adjacency matrices. This diversifies the structure in the graph, as residue nodes will have varying numbers of neighbours.
5. Methods
We now present our two predictors within EPMP, by considering paratope and epitope prediction in turn.
5.1. Paratope model (Para-EPMP)
For our paratope model, the input features are initially processed sequentially, with graph structure incorporated later. This model and its hyperparameters are outlined in Figure 1, and closely echoes our previous discussion.
The residue features are first passed through three a` trous CNNs (Kalchbrenner et al., 2016), as used in the sequencebased paratope predictor AG-Fast-Parapred (Deac et al., 2019), as well as the recent Tail-GNN model (Spalevic´ et al., 2020). A` trous CNNs have a dilation term which creates gaps in the convolution kernel, allowing the entire sequence to be covered in fewer layers, preventing overfitting.
The output embeddings from the CNN are then passed through two MPNN layers (Gilmer et al., 2017) over the proximity-based residue graph. These layers have single linear layers as their message and update functions and use the sum aggregation. MPNNs correspond to the most expressive class of spatial GNNs, making them highly appropriate

Neural message passing for joint paratope-epitope prediction

for the kind of data available for the paratope task.
We further leverage a skip connection (He et al., 2016) across the MPNNs, allowing the model to circumvent any graph-based processing. A final linear layer, with logistic sigmoid activations, produces the predictions.

is attending over every antibody residue, and vice-versa).
The attention coefficients are used to combine the neighbourhood of a node in a learned weighted manner. Within the GAT, we utilise edge dropout (Rong et al., 2019) to allow the network to learn a more robust neighbourhood to attend over. This is similar to the cross-modal attention mechanism of AG-Fast-Parapred (Deac et al., 2019), but we do not feed any privileged information into its connections.
Once attention is performed, the network then predicts both the paratope and epitope residues at once. Without such a multi-task objective, antibody residues would remain unlabelled, and hence the GAT would have to learn in an unsupervised manner which antibody residues are the most important in the attention layers. Instead, by leveraging multitasking, the network is given explicit cues as to which parts of the antibody are actually relevant to the binding site. Furthermore, it allows for knowledge transfer between the two tasks, regularising the epitope representations.

Figure 1. The Para-EPMP architecture. The output feature dimension for each layer is the first term in the bracket. For the convolutional layers, the second term is the kernel size.

5.2. Epitope model (Epi-EPMP)
Our epitope model, in contrast, is purely structural--uses only GNN layers--and incorporates substantial context from the antigen. Given the large potential for overfitting in this setting, we use two graph convolutional network (GCN) encoders from Kipf & Welling (2017) to process the antibody and antigen graphs in isolation. GCNs feature a fully nonparametric aggregation process, only learning point-wise shared linear transformations. This makes them resistant to overfitting, and scalable to larger graphs.
To combine information from the two representations, we allow the residue representations to interact across the antibody-antigen boundary. For this purpose, we used a graph attention network (GAT) (Velickovic´ et al., 2018) over the fully connected bipartite graph between the antigen residues and the antibody residues (i.e. each antigen residue

Figure 2. The Epi-EPMP multitask architecture. The output feature dimensions for each layer are given.
5.3. Training
The networks have been trained by optimising the classweighted binary cross-entropy loss, which is common for imbalanced binary classification tasks. In the training phase for Epi-EPMP, the losses from both tasks (paratope and epitope prediction) are added together.

Neural message passing for joint paratope-epitope prediction

We optimise the cross-entropy using the Adam SGD optimiser (Kingma & Ba, 2014), with an initial learning rate of 10-4 for Para-EPMP. To account for the unstable learning dynamics on Epi-EPMP, an initial learning rate of 10-5 was used to train its GCN layers, while an initial learning rate of 10-3 was used for all other layers.
We optimise the model over minibatches containing one antibody/antigen complex at a time.
5.4. Evaluation
Due to the large class imbalance, the area under the precision-recall curve (AUC PR) is the primary metric we use for benchmarking our models--matching the evaluation of PECAN. Prior art also reports the area under the receiver operating characteristic curve (AUC ROC), which we report as well for easier comparisons. The values reported are aggregated across five random seeds.
6. Results
Table 1. Models benchmarked on paratope prediction. The values from the first three models are reprinted from Pittala & BaileyKellogg (2020). Para-MPNN and Para-GCN are ablations of our model without the sequential (CNN) component, using either an MPNN or a GCN as the structural component.

it is important to emphasise the benefits of our asymmetric approach. We additionally provide ablation studies of variants of our model that are less asymmetric, demonstrating that the exact combination of architectural changes we introduced is necessary to recover peak performance.
It is worth noting that PECAN also performs transfer learning experiments, using a dataset of general protein-protein interactions. While they report slightly improved results from this (epitope AUC PR: 0.242; paratope AUC PR: 0.703), our models are still outperforming, using only the original dataset. We defer investigations of transfer learning objectives for EPMP to future work.
Qualitative study While there is substantial ground left to cover for robust epitope predictions, we demonstrate that our joint predictor can already produce actionable predictions, especially when the antigen is small. We evaluated EPMP's ability to predict the binding interface between a COVID-19 neutralising antibody (B38) and the RBD (Receptor Binding Domain) of the Spike protein, S1 of SARS-CoV-2 (Wu et al., 2020). From Figure 3, we can observe that the model is able to identify the correct localised region for the epitope, with any false positives being close to the binding interface.

MODEL
ANTIBODY I-PATCH DABERDAKU ET AL. PECAN
PARA-EPMP (OURS)
PARA-MPNN PARA-GCN

AUC ROC
0.840 0.950 0.957±0.000
0.966±0.000
0.964±0.000 0.956±0.000

AUC PR
0.376 0.658 0.700±0.001
0.752±0.003
0.744±0.003 0.681±0.004

Table 2. Models benchmarked on epitope prediction. The performance reported for PECAN is reprinted from Pittala & BaileyKellogg (2020). Epi-GCN and Epi-MPNN predict the epitope in a single-task setting (without the antibody), using either a GCN or an MPNN encoder on the antigen. Epi-CNN-GCN does the same, while incorporating a sequential (CNN) component.

MODEL
PECAN
EPI-EPMP (OURS)
EPI-GCN EPI-MPNN EPI-CNN-GCN

AUC ROC
NOT REPORTED
0.710± 0.003
0.671±0.004 0.650±0.003 0.634±0.003

AUC PR
0.212±0.007
0.277± 0.002
0.229±0.007 0.206±0.005 0.210±0.001

The results from our quantitative evaluation are shown in Tables 1­2. While it may be observed that our model significantly outperforms the prior state-of-the-art (PECAN),

Figure 3. B38-RBD (PDB: 7bz5). The red surface denotes the receptor binding domain of the SARS-CoV-2 spike protein, and the blue surface denotes its corresponding antibody (B38). Top: Ground-truth binding interface. Darker residues denote the binding region. Bottom: Predicted binding interface from running ParaEPMP on the antibody and Epi-EPMP on the antigen. Probabilities are coloured on a gradient scale, where the darkest residues are given the highest probability of participating in the binding.

Neural message passing for joint paratope-epitope prediction

References
Akbar, R., Robert, P. A., Pavlovic´, M., Jeliazkov, J. R., et al. A compact vocabulary of paratope-epitope interactions enables predictability of antibody-antigen binding. Cell Reports, 34(11):108856, 2021.
Andersen, P. H., Nielsen, M., and Lund, O. Prediction of residues in discontinuous b-cell epitopes using protein 3d structures. Protein Sci., 15(11):2558­67, 2006.
Daberdaku, S. and Ferrari, C. Antibody interface prediction with 3d zernike descriptors and svm. Bioinformatics, 35 (11):1870­1876, 2019.
Deac, A., Velickovic´, P., and Sormanni, P. Attentive crossmodal paratope prediction. J Comput Biol., 26(6):536­ 545, 2019.
Dunbar, J., Krawczyk, K., Leem, J., Baker, T., Fuchs, A., Georges, G., Shi, J., and Deane, C. M. Sabdab: the structural antibody database. Nucleic Acids Res., 42(Database issue):D1140­D1146., 2014.
Ferdous, S. and Martin, A. Abdb: antibody structure database-a database of pdb-derived antibody structures. Database (Oxford), 2018:bay040, 2018.
Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., and Dahl, G. E. Neural message passing for quantum chemistry. In International Conference on Machine Learning (ICML), 2017.
Gligorijevic, V., Renfrew, P. D., Kosciolek, T., Leman, J. K., Berenberg, D., Vatanen, T., Chandler, C., Taylor, B. C., Fisk, I. M., Vlamakis, H., et al. Structure-based function prediction using graph convolutional networks. bioRxiv, pp. 786236, 2020.
He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770­778, 2016.
Honda, S., Koyama, K., and Kotaro, K. Cross attentive antibody-antigen interaction prediction with multi-task learning. In ICML Workshop on Computational Biology, 2020.
Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Tunyasuvunakool, K., Ronneberger, O., et al. High Accuracy Protein Structure Prediction Using Deep Learning. Fourteenth Critical Assessment of Techniques for Protein Structure Prediction (Abstract Book), 2020.
Kalchbrenner, N., Espeholt, L., Simonyan, K., Oord, A. v. d., Graves, A., and Kavukcuoglu, K. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099, 2016.

Kingma, D. P. and Ba, J. Adam: A method for stochastic optimization. In Proceedings of the 3rd International Conference on Learning Representations (ICLR), 2014.
Kipf, T. and Welling, M. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations (ICLR), 2017.
Krawczyk, K., Baker, T., Shi, J., and Deane, C. Antibody i-patch prediction of the antibody binding site improves rigid local antibody-antigen docking. Protein Eng Des Sel, 26(10):621­9, 2013.
Krawczyk, K., Liu, X., Baker, T., Shi, J., and Deane, C. M. Improving B-cell epitope prediction and its application to global antibody-antigen docking. Bioinformatics, 30 (16):2288­2294, 2014.
Liberis, E., Velickovic´, P., Sormanni, P., Vendruscolo, M., and Lio`, P. Parapred: antibody paratope prediction using convolutional and recurrent neural networks. Bioinformatics, 34(17):2944­2950, 2018.
Pittala, S. and Bailey-Kellogg, C. Learning context-aware structural representations to predict antigen and antibody binding interfaces. Bioinformatics, 36(13):3996­4003, 2020.
Rong, Y., Huang, W., Xu, T., and Huang, J. Dropedge: Towards deep graph convolutional networks on node classification. In International Conference on Learning Representations, 2019.
Smyth, M. and Martin, J. X ray crystallography. Molecular Pathology, 53(1):8, 2000.
Spalevic´, S., Velickovic´, P., Kovacevic´, J., and Nikolic´, M. Hierachial protein function prediction with tail-gnns. arXiv preprint arXiv:2007.12804, 2020.
Thomson, E. C., Rosen, L. E., Shepherd, J. G., Spreafico, R., da Silva Filipe, A., et al. Circulating sars-cov-2 spike n439k variants maintain fitness while evading antibodymediated immunity. Cell, 184(5):1171­1187, 2021.
Velickovic´, P., Cucurull, G., Casanova, A., Romero, A., Lio`, P., and Bengio, Y. Graph attention networks. 6th International Conference on Learning Representations (ICLR), 2018.
Vreven, T., Moal, I. H., Vangone, A., Pierce, B. G., Kastritis, P. L., et al. Updates to the integrated protein-protein interaction benchmarks: Docking benchmark version 5 and affinity benchmark version 2. J Mol Biol., 427(19): 3031­3041, 2015.
Wu, Y., Wang, F., Shen, C., Peng, W., Li, D., Zhao, C., et al. A noncompeting pair of human neutralizing antibodies block COVID-19 virus binding to its receptor ACE2. Science, 368(6496):1274­1278, 2020.

