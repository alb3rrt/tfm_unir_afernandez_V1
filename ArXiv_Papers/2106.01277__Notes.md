
# Data augmentation and pre-trained networks for extremely low data regimes unsupervised visual inspection

[arXiv](https://arxiv.org/abs/2106.01277), [PDF](https://arxiv.org/pdf/2106.01277.pdf)

## Authors

- Pierre Gutierrez
- Antoine Cordier
- Thaïs Caldeira
- Théophile Sautory

## Abstract

The use of deep features coming from pre-trained neural networks for unsupervised anomaly detection purposes has recently gathered momentum in the computer vision field. In particular, industrial inspection applications can take advantage of such features, as demonstrated by the multiple successes of related methods on the MVTec Anomaly Detection (MVTec AD) dataset. These methods make use of neural networks pre-trained on auxiliary classification tasks such as ImageNet. However, to our knowledge, no comparative study of robustness to the low data regimes between these approaches has been conducted yet. For quality inspection applications, the handling of limited sample sizes may be crucial as large quantities of images are not available for small series. In this work, we aim to compare three approaches based on deep pre-trained features when varying the quantity of available data in MVTec AD: KNN, Mahalanobis, and PaDiM. We show that although these methods are mostly robust to small sample sizes, they still can benefit greatly from using data augmentation in the original image space, which allows to deal with very small production runs.

## Comments

16 pages, 8 figures, 9 tables, SPIE proceedings of Optical Metrology conference ( this https URL )

## Source Code

Official Code



Community Code

- [https://paperswithcode.com/paper/data-augmentation-and-pre-trained-networks](https://paperswithcode.com/paper/data-augmentation-and-pre-trained-networks)

## Bibtex

```tex
@misc{gutierrez2021data,
      title={Data augmentation and pre-trained networks for extremely low data regimes unsupervised visual inspection}, 
      author={Pierre Gutierrez and Antoine Cordier and Thaïs Caldeira and Théophile Sautory},
      year={2021},
      eprint={2106.01277},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

## Notes

Type your reading notes here...

