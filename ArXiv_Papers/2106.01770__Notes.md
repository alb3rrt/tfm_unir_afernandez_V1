
# A Normative Model of Classifier Fusion

[arXiv](https://arxiv.org/abs/2106.01770), [PDF](https://arxiv.org/pdf/2106.01770.pdf)

## Authors

- Susanne Trick
- Constantin A. Rothkopf

## Abstract

Combining the outputs of multiple classifiers or experts into a single probabilistic classification is a fundamental task in machine learning with broad applications from classifier fusion to expert opinion pooling. Here we present a hierarchical Bayesian model of probabilistic classifier fusion based on a new correlated Dirichlet distribution. This distribution explicitly models positive correlations between marginally Dirichlet-distributed random vectors thereby allowing normative modeling of correlations between base classifiers or experts. The proposed model naturally accommodates the classic Independent Opinion Pool and other independent fusion algorithms as special cases. It is evaluated by uncertainty reduction and correctness of fusion on synthetic and real-world data sets. We show that a change in performance of the fused classifier due to uncertainty reduction can be Bayes optimal even for highly correlated base classifiers.

## Comments

12 pages, 4 figures

## Source Code

Official Code



Community Code

- [https://paperswithcode.com/paper/a-normative-model-of-classifier-fusion](https://paperswithcode.com/paper/a-normative-model-of-classifier-fusion)

## Bibtex

```tex
@misc{trick2021normative,
      title={A Normative Model of Classifier Fusion}, 
      author={Susanne Trick and Constantin A. Rothkopf},
      year={2021},
      eprint={2106.01770},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```

## Notes

Type your reading notes here...

