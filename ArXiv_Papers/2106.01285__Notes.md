
# Sample-based Approximation of Nash in Large Many-Player Games via Gradient Descent

[arXiv](https://arxiv.org/abs/2106.01285), [PDF](https://arxiv.org/pdf/2106.01285.pdf)

## Authors

- Ian Gemp
- Rahul Savani
- Marc Lanctot
- Yoram Bachrach
- Thomas Anthony
- Richard Everett
- Andrea Tacchetti
- Tom Eccles
- J치nos Kram치r

## Abstract

Nash equilibrium is a central concept in game theory. Several Nash solvers exist, yet none scale to normal-form games with many actions and many players, especially those with payoff tensors too big to be stored in memory. In this work, we propose an approach that iteratively improves an approximation to a Nash equilibrium through joint play. It accomplishes this by tracing a previously established homotopy which connects instances of the game defined with decaying levels of entropy regularization. To encourage iterates to remain near this path, we efficiently minimize \emph{average deviation incentive} via stochastic gradient descent, intelligently sampling entries in the payoff tensor as needed. This process can also be viewed as constructing and reacting to a polymatrix approximation to the game. In these ways, our proposed approach, \emph{average deviation incentive descent with adaptive sampling} (ADIDAS), is most similar to three classical approaches, namely homotopy-type, Lyapunov, and iterative polymatrix solvers. We demonstrate through experiments the ability of this approach to approximate a Nash equilibrium in normal-form games with as many as seven players and twenty one actions (over one trillion outcomes) that are orders of magnitude larger than those possible with prior algorithms.

## Comments



## Source Code

Official Code



Community Code

- [https://paperswithcode.com/paper/sample-based-approximation-of-nash-in-large](https://paperswithcode.com/paper/sample-based-approximation-of-nash-in-large)

## Bibtex

```tex
@misc{gemp2021samplebased,
      title={Sample-based Approximation of Nash in Large Many-Player Games via Gradient Descent}, 
      author={Ian Gemp and Rahul Savani and Marc Lanctot and Yoram Bachrach and Thomas Anthony and Richard Everett and Andrea Tacchetti and Tom Eccles and J치nos Kram치r},
      year={2021},
      eprint={2106.01285},
      archivePrefix={arXiv},
      primaryClass={cs.GT}
}
```

## Notes

Type your reading notes here...

