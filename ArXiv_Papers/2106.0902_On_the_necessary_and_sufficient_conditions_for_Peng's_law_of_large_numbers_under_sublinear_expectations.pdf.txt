arXiv:2106.00902v1 [math.PR] 2 Jun 2021

On the necessary and sufficient conditions for Peng's law of
large numbers under sublinear expectations
Xinpeng LI Gaofeng ZONG Reserach Center for Mathematics and Interdisciplinary Sciences
Shandong University 266237, Qingdao, China; School of Mathematics and Quantitative Economics, Shandong University of Finance and Economics,
250014, Jinan, China Email: gf zong@126.com
¯ June 3, 2021

Abstract. Given the independent and identical distributed random variables {Xi} under sublinear expectation E, Peng [12] proved the following law of large numbers:

lim E[( Sn )] =

max

(µ),

n

n

-E[-X1]µE[X1]

  Cb(R),

under uniformly convergence condition limn E[(|X1| - n)+] = 0. This paper shows that above uniformly convergence condition is not necessary, and provides the necessary and sufficient conditions for X1 such that Peng's law of large numbers holds. Keywords: Peng's law of large numbers; sublinear expectation; conditional expectation MSC2010:Primary 60B05; Secondary 60F05, 60A86

1 Introduction

The law of large numbers (LLN for short) is a fundamental limit theorem in probability theory which

plays an important role in the development of probability and statistics. It is well-known that if

{Xi} is an independent and identically distributed (i.i.d. for short) random variables sequence on

probability space (, F , P ) with finite mean E[X1] = µ, the weak law of large numbers means that

1 n

n i=1

Xi

converges

to

µ

in

probability.

We

note

that

the

probability

P

is

additive.

However,

in

some

areas this apparently quite natural property has been abandoned in favor of non-additive probabilities

(expectation). One typical example of non-additive probabilities (expectation) is Choquet's theory

Partially supported by National Key R&D Program of China (No.2018YFA0703900), NSF of China (No.11601281), the Young Scholars Program of Shandong University, the China Postdoctoral Science Foundation (Grant No.2018T110706, No.2018M642641)). Corresponding author: Gaofeng Zong, Email: gf¯zong@126.com

1

of capacities and expectation. Marinacci [8] proved the weak law of large numbers for i.i.d. random variables under convex and continuous capacities, that is for all  > 0,

lim
n

v(Cv

[X1]

-



<

1 n

n

Xi < CV [X1] + ) = 1.

i=1

(1.1)

where Cv[X1] and CV [X1] are lower and upper Choquet integral associated with the given lower and

upper capacities v and V .

Recently, to deal with the problems in risk measures, super-hedge pricing and modeling uncertainty

in finance, Peng [12] systematically studied the sublinear expectation theory. The new notions of

independence and identical distribution are introduced by Peng, and the weak form of the law of

large numbers for i.i.d. sequence {Xi} under sublinear expectation E is obtained under uniformly

convergence condition. If

lim
n

E[(|X1|

-

n)+]

=

0.

(1.2)

then

1n

lim E
n

( n

Xi)

i=1

=

max

(µ),

-E[-X1]µE[X1]

  Cb(R).

(1.3)

In fact, from (1.3), it is easy to see that, for any  > 0,

lim
n

v(-E[-X1

]

-



<

1 n

n

Xi < E[X1] + ) = 1,

i=1

(1.4)

where v is the lower capacity associated with subliear expectation E.

We recall that the classical weak LLN shows that, for i.i.d. sequence {Xi} on the probability space

(, F , P ),

n i

Xi

n

converges to

µ

in

probability

if

and

only

if

lim
n

nP

(|X1|



n)

=

0

and

lim
n

EP

[X1 I{|X1 |n} ]

=

µ.

(1.5)

The typical example of sublinear expectation is the upper expectation, where E can be represented
by E[X] = supP P EP [X], in which P is some set of probability measures. In this case, for each P  P, the conditional expectation EP [Xi|X1, · · · , Xi-1] is dominated by the sublinear expectation E[Xi] for independent random variables {Xi}. Based on this fact, we can give a simple proof of Peng's LLN with the necessary and sufficient conditions. Compared with the classical condition (1.5), Peng's
LLN (1.3) holds if and only if the following three conditions hold:

(i) limn nV (|X1|  n) = 0.

(ii) limn E[X1I{|X1|n}] = E[X1].

(iii) limn -E[-X1I{|X1|n}] = -E[-X1].
Here V is the upper capacity induced by the set of probability measures P in (i). This theorem is a natural generalization of the classical LLN to the sublinear expectation the-
ory. But unlike the classical case, the weak LLN (1.3) maybe not hold even if E[|X1|] < . The counterexample will be provided in the end of this paper.
The rest of this paper is organized as follows. Section 2 describes some settings of the sublinear expectation theory and the properties of independent random variables. Section 3 provides some inequalities for independent random variables, which are useful tools to prove the main theorem. In Section 4, we study the necessary and sufficient conditions for Peng's LLN. In Section 5, we provide some examples.

2

2 Preliminaries

Let  be a complete separable metric space, B() be the Borel -algebra of  and M the collection of all probability measures on (, B()). Given a subset P  M, the upper expectation of P is defined as follows: for each random variable X such that EP [X] exists for each P  P,

E[X] := sup EP [X].
P P
It is easy to verify that the upper expectation E[·] of the family P is a sublinear expectation, i.e., it satisfies the following properties:

(1) Monotonicity: E[X]  E[Y ], if X  Y ;

(2) Constant preserving: E[c] = c, c  R;

(3) Sub-additivity: E[X + Y ]  E[X] + E[Y ];

(4) Positive homogeneity: E[X] = E[X],   0.

We can also define the upper probability

V (A) := sup P (A), A  B(),
P P

and the lower probability

v(A) := inf P (A), A  B().
P P

Obviously, V (·) and v(·) are conjugate to each other, that is

V (A) + v(Ac) = 1,

where Ac is the complement set of A. For upper probability V , we can also define the corresponding Choquet expectation CV by



0

CV [X] = V (X > t)dt + (V (X > t) - 1)dt.

0

-

It is easy to see that E[X]  CV [X].

Definition 2.1. A linear expectation EP is dominated by a sublinear expectation E, if

EP []  E[],   Cb().

Remark 2.2. In general, we can not imply that P  P when EP is dominated by E. If P is convex and weakly compact, then EP is dominated by E is equivalent to P  P, see Li and Lin [7].
We recall the notions of identical distribution and independence in sublinear expectation space, which introduced by Peng [10].

Definition 2.3. Let X and Y be two random variables on (, B()). They are called identically distributed under E, if for each   Cb,Lip(R),

E[(X)] = E[(Y )],

where Cb,Lip(R) is the set of all bounded and Lipschitz functions on R.

3

Definition 2.4. Let X1, X2, · · · , Xn be a sequence of random variables on (, B()). Xn is said to be independent of (X1, · · · , Xn-1) under E, if for each   Cb,Lip(Rn),

E[(X1, · · · , Xn)] = E[E[(x1 , · · · , xn-1, Xn)]|(x1,··· ,xn-1)=(X1,··· ,Xn-1)].

The sequence of random variables {Xk} k=1 is said to be independent, if Xk+1 is independent of (X1, · · · , Xk) for each k  N.

Proposition 2.5. Let {Xk} be independent sequence of random variables. Then for each nonnegative bounded lower semi-continuous function i,

n

n

E[ i(Xi)] = E[i(Xi)],

i=1

i=1

(2.1)

In particular, where ci is constant.

n
V (|X1|  c1, · · · , |Xn|  cn) = V (|Xi|  ci),
i=1
n
v(|X1| < c1, · · · , |Xn| < cn) = v(|Xi| < ci),
i=1

EPE[[rookinif(=.X1Fi)o]kir(eXaiEc)h[]=i(iX, tinih)=]e1raEen[edxkiiEt(sX[ ni)oni]=n, 1nleetgkiak(tXivie)]fu,ntcEht[iuosnni(=21.ki1)i(hXCoblid,)L]s.i.p

(R) By

such that ki  Definition 2.4,

i, which for each

implies k  N,

3 Inequalities for independent random variables

In this section, we provide some inequalities for independent random variables {Xi}. From now on, we say that a linear expectation EP which associates with some probability measure P is dominated by E, if for each n,
EP [(X1, · · · , Xn)]  E[(X1, · · · , Xn)],   Cb(Rn).
Proposition 3.1. Let {Xi} be an independent sequence of random variable under E which satisfies limC E[(|Xi| - C)+] = 0 for i  N and Fi = (X1, · · · , Xi-1) (F1 = {, }). Then for each EP dominated by E, we have

-E[-Xi]  EP [Xi|Fi-1]  E[Xi], i  N.

Proof. Since i = 1 is obvious, we only consider the case of i > 1.

We firstly show that EP [Xi|Fi-1]  E[Xi]. Without loss of generality, assuming E[Xi] = 0, then

for every A  Fi-1 and  > 0, we can choose C large enough

0







2

such

that

EP [|(X1, · · ·

, Xi-1)

- IA|]

<

 2C

,

then

such

that

E[(|Xi| - C)+]



 6

and

EP [IAXi]  EP [(X1, · · · , Xi-1)Xi] + EP [|(X1, · · · , Xi-1) - IA||Xi|]  E[E[(x1, · · · , x1-1)Xi]|(x1,··· ,xi-1)=(X1,··· ,Xi-1)]

4

+ EP [|(X1, · · · , Xi-1) - IA|(|Xi| - C)+] + CEP [|(X1, · · · , Xi-1) - IA|]  3E[(|Xi| - C)+] + CEP [|(X1, · · · , Xi-1) - IA|] < .

Thus, EP [Xi|Fi-1]  0. Similarly, we can prove that EP [Xi|Fi-1]  -E[-Xi].

The following proposition is the Ottaviani's inequality in the framework of sublinear expectation theory.

Proposition 3.2. Let X1, · · · , Xn be independent random variables under E, Sn =

n i=1

Xi,

and

0 < c < 1 be a real number. If there exist real constants n such that

max
kn

V

(|Sn

-

Sk |



n)



c,

then,

V

(max
kn

|Sk

|



2n)



1 1-

cV

(|Sn|



n).

Proof. For k = 1, · · · , n, let Then We have

Ak = { max |Sl| < 2n, |Sk|  2n},
lk-1

n

V (max |Sk|  2n) = E[
kn

IAk ].

k=1

n

n

I{|Sn|n} 

IAk I{|Sn|n} 

IAk I{|Sn-Sk|<n}

k=1

k=1

n

n

n

=

IAk (1 - I{|Sn-Sk|n}) = (1 - c)

IAk +

IAk (c - I{|Sn-Sk|n})

k=1

k=1

k=1

which implies that

n

n

(1 - c)

IAk  I{|Sn|n} +

IAk (I{|Sn-Sk|n} - c).

k=1

k=1

For fixed k, let (X) = IAk and (X¯ ) = I{|Sn-Sk|n} - c, where X¯ = (Xk+1, · · · , Xn) is independent of X = (X1, · · · , Xk), then we can see that  is a bounded lower semi-continuous function on Rn-k and E[(X¯ )]  0. For each  > 0, there exists P  P and 0    Cb,Lip(R) such that

E[(X)(X¯ )]  EP [(X)(X¯ )] + ,

and Then we have,

EP [|(X) - (X)|] < .

E[(X)(X¯ )]  EP [(X)(X¯ )] + 

5

 EP [|(X) - (X)|(X¯ )] + EP [(X)(X¯ )] +   (1 - c)EP [|(X) - (X)|] + EP [(X)(X¯ )] +   (2 - c) + E[(X)(X¯ )] = (2 - c) + sup{E[(X)¯(X¯ )] : ¯  , ¯  Cb,Lip(Rn-k)} = (2 - c) + sup{E[(X)]E[¯(X¯ )] : ¯  , ¯  Cb,Lip(Rn-k)} = (2 - c) + E[(X)]E[(X¯ )]
 (2 - c),

which implies that E[(X)(X¯ )]  0. Finally, by the sub-additivity of E, it follows that

n

(1 - c)V (max |Sk|  2n)  V (|Sn|  n) +
kn

E[IAk (I{|Sn-Sk|n} - c)]

k=1

 V (|Sn|  n).

The proof is complete.

Remark 3.3. Zhang [14] prove the following Levy maximal inequality, which is used to obtain the
sufficient and necessary conditions for Peng's central limit theorem. Let 0 <  < 1 be a real number and there exist real constants n,k such that V (|Sk - Sn|  n,k + )   for any  > 0, then for every x  R, (1 - )V (maxkn(|Sk| - n,k) > x + )  V (|Sn| > x). Thanks to Proposition 2.5, the -condition can be removed, we have (1 - )V (maxkn(|Sk| - n,k)  x)  V (|Sn|  x) if V (|Sk - Sn|  n,k)   by the similar argument.

4 Law of large numbers

In this section, we complete the proof of Theorem 4.4. We firstly give some lemmas.

Lemma 4.1. Let {X} be a random variable such that limn nV (|X|  n) = 0, then

lim
n

1 n

E[|X

|2

I{|X

|n}]

=

0.

Proof. The proof is very similar to the classical case. Indeed,

(4.1)

as nV (|X|  n)  0.

1 n

E[|X

|2

I{|X

|n}]

=

1 n

sup EP [|X |2I{|X|n}]
P P

 2 sup

n
tP (|X|  t)dt

n P P 0

2

n
tV (|X|  t)dt  0,

n0

The next lemma is the law of large numbers without the moment condition, which was proved in Chen et al. [2]. Thanks to Proposition 3.1, here we give a very simple proof.

6

Lemma 4.2. Let {Xi} be an i.i.d. sequence under sublinear expectation E, such that

lim
n

nV

(|X1|



n)

=

0.

Then for any  > 0,

lim
n

v (-E[-X1 1{|X1 |n} ]

-



<

1 n

n

Xi < E[X11{|X1|n}] + ) = 1.

i=1

Proof. Let Yn,i = XiI{|Xi|<n} and Tn =

n i=1

Yn,i.

For

each

P



P,

obviously,

EP [Yn2,i]



E[Xi2],

and

Proposition 3.1 implies that -E[-Yn,i]  EP [Yn,i|Fi-1]  E[Yn,i], where Fi-1 = (X1, · · · , Xi-1).

Firstly, by Chebyshev's inequality and Jensen's inequality, we have

P(

n i=1

(Yn,i

- EP [Yn,i|Fi-1])

>

)



n

ni=1(EP [Yn2,i] + EP [(EP [Yn,i|Fi-1])2]) n22



2

n i=1

EP

[Yn2,i]

n22

2 

n i=1

E[Yn2,i]

n22

=

2E[Yn2,i] n2

.

Noting that, thus

n

n

P (Sn = Tn)  P (|Xi|  n)  V (|Xi|  n) = nV (|X1|  n),

i=1

i=1

P ( Sn n

>

E[Yn,1] + ) 

P (Sn

=

Tn) + P (

n i=1

(Yn,i

- E[Yn,i|Fi-1]) n

>

 2

)

+ P(

n i=1

E

[Yn,i

|Fi-1

]

n

>

E[Yn,1] +

 2

)



nV

(|X1|



n)

+

8 n2

E[Yn2,1]

+

P(

n i=1

E[Yn,i

]

n

>

E[Yn,1]

+

 2

)

Combining with Lemma 4.1, we can imply that

V ( Sn n

> E[Yn,1] + )



0,

Similarly,

we

can

prove

that

V

(

Sn n

<

-E[-Yn,1] - )



0,

the

proof

is

completed.

Lemma 4.3.

Let {Xi}

be an

i.i.d.

sequence under E with

µn

=

E[X1I{|X1|n}] and

µ
n

=

-E[-X1I{|X1|n}].

If  > 0,

lim
n

v(µn

-



Sn n



µn + )

=

1.

(4.2)

then we have

lim |E[( Sn )] - max (µ)| = 0,

n

n

µ
n

µµn

  Cb,Lip(R).

(4.3)

Proof. For each  > 0, we have

E[( Sn )] n



max (µ) + max (µ)(V ( Sn

µ
n

-µµn

+

µR

n

>

µn

+

)

+

V

(

Sn n

<

µ - )).
n

7

If (4.2) holds, letting n  , then we have

lim sup{E[( Sn )] - max (µ)}  0,

n

n

µ
n

-µµn

+

  Cb,Lip(R).

Since  is Lipschitz function, let   0, we obtain that,

lim sup{E[( Sn )] - max (µ)}  0,

n

n

µ
n

µµn

  Cb,Lip(R).

(4.4)

On the other hand, for fixed   Cb,Lip(R) with Lipschitz constant L and bound C, and for each ~ > 0, there exists µn  (µn, µn) such that (µn)  maxµnµµn (µ) - ~, we can find EP which dominated by E such that {Xi} is an i.i.d. sequence under EP with EP [X1I{|X1|n}] = µn. In this case, by the classical weak law of large numbers, for each  > 0,

P (| Sn n

-

µn|

>

)



0.

Then

|EP

[(

Sn n

)]

-

(µn)|



L

+

2C

P

(|

Sn n

-

µn|

>

),

We can obtain that

lim
n

|EP

[(

Sn n

)]

-

(µn)|

=

0,

which implies that, for each ~ > 0,

lim inf{E[(
n

Sn n

)]

-

max

µ
n

µµn

(µ)}



lim inf
n

{EP

[( Sn n

)]

-

(µn)}

-

~

=

-~,

Combining (4.4) with (4.5), we can see that (4.3) holds.

(4.5)

Now we study the sufficient and necessary conditions for Peng's LLN.

Theorem 4.4. Let {Xi} be an i.i.d. sequence under E. Then

lim E[( Sn )] = max (µ),

n

n

µµµ

  Cb(R).

(4.6)

if and only if the following three conditions hold:

(i) limn nV (|X1|  n) = 0.
(ii) limn E[X1I{|X1|n}] = µ.
(iii) limn -E[-X1I{|X1|n}] = µ.
Proof. If (i)-(iii) holds, then by Lemma 4.2 and Lemma 4.3, (4.6) holds. Conversely, we assume that (4.6) holds.
Let µ^ = 2[µ] + 2 > 2µ, which is a integer. By (4.6), there exists N such that

V

(|Sn|



nµ^ 2

)



1 4

,

n

>

N.

8

Then for N  k  n, we have

V (|Sk

-

Sn|



nµ^)



V (|Sk|



nµ^ 2

)

+ V (|Sn|



nµ^ 2

)



V

(|Sk |



kµ^ 2

)

+

V

(|Sn

|



nµ^ 2

)



1 2

.

Applying Ottaviani's inequality, we obtain

which implies that

V ( max |Sk|  2nµ^)  2V (|Sn|  nµ^),
N kn

V

( max
N +1kn

|Xk|



4nµ^)



V

( max
N +1kn

|Sk |



2nµ^)

+

V

( max
N kn-1

|Sk |



2nµ^)

 4V (|Sn|  nµ^).

On other hand, by Proposition 2.5,

V ( max |Xk|  4nµ^) = 1 - v( max |Xk| < 4nµ^)

N +1kn

N +1kn

= 1 - nk=N+1v(|Xk| < 4nµ^)

= 1 - (1 - V (|X1|  4nµ^))n-N

 1 - e-(n-N )V (|X1|4nµ^).

Thus

(n - N )V (|X1|  4nµ^)  - ln(1 - 4V (|Sn|  nµ^)).

Since

V

(

|Sn| n



µ^)



0,

as

n



,

if

n

>

2N ,

we

have

n 2

V

(|X1|



4nµ^)



(n

-

N

)V

(|X1|



4nµ^)



0,

which implies that

lim
n

nV

(|X1|



n)

=

0.

Then by Lemma 4.2, we can deduce that

lim
n

v(µn

-



Sn n



µn

+ )

=

1,

 > 0,

where µn = E[X1I{|X1|n}] and µn = -E[-X1I{|X1|n}]. Thus

lim |E[( Sn )] - max (µ)| = 0.

n

n

µ
n

µµn

Combining with (4.6), we can see that (ii) and (iii) hold.

5 Examples
We firstly give an example to show that there exists a random variable X such that nV (|X|  n)  0 but E[(|X| - n)+]  0.

9

Example 5.1.

1 n3

,

k

=

1, 2, . . .

We have E[|X|]

Let  = N, P = {Pn : n 

, n, for n = 2, 3, · · · . We

=

25 16

and

nV (|X|  n) =

N} where P1({1}) = 1 and Pn({1})

consider a function X on N defined

1 n



0,

but

E[(|X |

-

n)+]

=

1 2



0.

=1 by

-

1 n2

,

X (n)

Pn({kn}) = = n, n  N.

The next example shows that the Peng's LLN may fail only with the first moment condition, which is different from the classical LLN.

Example

5.2.

Let



=

N,

P

=

{Pn

:

n



N},

where

Pn({0})

=

1-

1 n

and

Pn({n})

=

1 n

for

n = 1, · · · ,. Consider a function X on N defined by X(n) = n, n  N. We have E[X] = -E[-X] = 1.

By Peng [11], we can construct i.i.d sequence {Xi} under E such that Xi have the same distribution

with X. But the weak law of large numbers does not hold, i.e., we can find   Cb(R), such that

lim E[( Sn )] = (1).

n

n

Indeed, we consider (x) = (1 - x)+. In this case,

x EPi [(

+X n

)]

=

(1

-

1 i

)(

x n

)

+

1 i

(

x

+ n

i)

=

(

x n

)

-

1 i

((

x n

)

-

( x

+ n

i )),

thus

(

x n

)

-

2 i



EPi [( x

+ n

X

)]



(

x n

),

we

can

obtain

E[(

x+X n

)]

=

(

x n

).

Then,

E[(

X1

+

··· n

+

Xn

)]

=

E[E[(

x

+ Xn n

)]|x=X1+···+Xn-1 ]

= E[( X1 + · · · + Xn-1 )] = · · · = E[( X1 )] = (0) = 1.

n

n

which implies that,

lim E[( X1 + · · · + Xn )] = 1 = (1) = 0.

n

n

References

[1] Chen, Z. (2016). Strong laws of large numbers for sub-linear expectations, Science China Mathematics, 59: 945-954.
[2] Chen, Z., Liu, Q. and Zong, G. (2018). Weak laws of large nunbers for sublinear expecatation. Mathematical Control and Related Fields, 8(3&4): 637-651.
[3] Chen, Z., Wu, P. and Li, B. (2013). A strong law of large numbers for non-additive probabilities. International Journal of Approximate Reasoning, 54(3): 365-377.
[4] Hall, P. and Hedye, C. (1980). Martingale limit theorem and its application. Academic Press.
[5] Hu, C. (2018) Strong laws of large numbers for sublinear expectation under controlled 1st moment condition. Chinese Annals of Mathematics, Series B, 39(5): 791-804.

10

[6] Krylov, N. V. (2020). On Shige Peng¡¯s central limit theorem. Stochastic Processes and Their Applications, 130(3), 1426-1434.
[7] Li, X. and Lin, Y. (2017). Generalized Wasserstein distance and weak convergence of sublinear expectations. Jounral of Thereoitical Probability, 30: 581-593.
[8] Marinacci, M. (1999). Limit Laws of non-additive probabilites and their frequentist interpretation. Journal of Economic Theory, 84:145-195.
[9] Maccheroni, F. and Marinacci, M. (2005). A strong law of large numbers for capacites. Annals of Probability, 33: 1171-1178.
[10] Peng, S. (2007). Law of large numbers and central limit theorem under nonlinear expectations, in arXiv:math.PR/0702358v1 13 Feb 2007.
[11] Peng, S. (2010). Nonlinear Expectations and Stochastic Calculus under Uncertainty, arXiv:1002.4546v1 [math.PR] 24 Feb 2010.
[12] Peng, S. (2019). Nonlinear Expectations and Stochastic Calculus under Uncertainty, Springer. [13] Zhang, L. (2016). Rosenthal's inequalities for independent and negatively dependent random
variables under sub-linear expectations with applications. Science China Mathematics, 59(4): 751-768. [14] Zhang, L. (2020). The convergence of the sums of independent random variables under the sublinear exepctations. Acta Mathematica Sinica, English Series, 36(3):224-244.
11

