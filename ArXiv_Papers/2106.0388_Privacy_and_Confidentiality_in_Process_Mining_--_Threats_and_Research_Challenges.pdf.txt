arXiv:2106.00388v1 [cs.CR] 1 Jun 2021

Privacy and Confidentiality in Process Mining - Threats and Research Challenges
GAMAL ELKOUMY, University of Tartu, Estonia STEPHAN A. FAHRENKROG-PETERSEN, Humboldt-Universität zu Berlin, Germany MOHAMMADREZA FANI SANI, RWTH-Aachen University, Germany AGNES KOSCHMIDER, Kiel University, Germany FELIX MANNHARDT, Eindhoven University of Technology, The Netherlands SASKIA NUÑEZ VON VOIGT, Technische Universität Berlin, Germany MAJID RAFIEI, RWTH-Aachen University, Germany LEOPOLD VON WALDTHAUSEN, Magdalen College, University of Oxford, United Kingdom
Privacy and confidentiality are very important prerequisites for applying process mining in order to comply with regulations and keep company secrets. This paper provides a foundation for future research on privacy-preserving and confidential process mining techniques. Main threats are identified and related to an motivation application scenario in a hospital context as well as to the current body of work on privacy and confidentiality in process mining. A newly developed conceptual model structures the discussion that existing techniques leave room for improvement. This results in a number of important research challenges that should be addressed by future process mining research.
CCS Concepts: · Applied computing  Business intelligence; · Security and privacy  Domain-specific security and privacy architectures.
Additional Key Words and Phrases: process mining, privacy, confidentiality, research challenges
ACM Reference Format: Gamal Elkoumy, Stephan A. Fahrenkrog-Petersen, Mohammadreza Fani Sani, Agnes Koschmider, Felix Mannhardt, Saskia Nuñez von Voigt, Majid Rafiei, and Leopold von Waldthausen. 2021. Privacy and Confidentiality in Process Mining - Threats and Research Challenges. ACM Trans. Manag. Inform. Syst. 1, 1, Article 1 (January 2021), 17 pages. https://doi.org/10.1145/3468877

1 INTRODUCTION
Process mining [51] has been successfully applied in analysing and improving processes based on event logs in all kinds of environments. However, the impact of privacy and confidentiality aspects on process mining has received
Authors in alphabetic order with equal contribution to this research.
Authors' addresses: Gamal Elkoumy, gamal.elkoumy@ut.ee, University of Tartu, Tartu, Estonia; Stephan A. Fahrenkrog-Petersen, Humboldt-Universität zu Berlin, Berlin, Germany, stephan.fahrenkrog-petersen@hu-berlin.de; Mohammadreza Fani Sani, RWTH-Aachen University, Aachen, Germany, fanisani@pads.rwth-aachen.de; Agnes Koschmider, Kiel University, Kiel, Germany, ak@informatik.uni-kiel.de; Felix Mannhardt, Eindhoven University of Technology, Eindhoven, The Netherlands, f.mannhardt@tue.nl; Saskia Nuñez von Voigt, Technische Universität Berlin, Berlin, Germany, saskia. nunezvonvoigt@tu-berlin.de; Majid Rafiei, RWTH-Aachen University, Aachen, Germany, majid.rafiei@pads.rwth-aachen.de; Leopold von Waldthausen, Magdalen College, University of Oxford, Oxford, United Kingdom, leopold.vonwaldthausen@magd.ox.ac.uk.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). © 2021 Copyright held by the owner/author(s). Manuscript submitted to ACM

Manuscript submitted to ACM

1

2

Elkoumy, et al.

less attention. Both topics are closely related to the responsible application of data science, a topic that has gotten more attention in recent years as data-driven methods start to permeate our society. While privacy concerns informal self-determination, which means the ability to decide what information about a person goes where [3], confidentiality refers to protecting information from an unauthorized disclosure.
A recent study on privacy re-identification risks in event logs showed that there are serious privacy leakages in the vast majority of the event logs used widely in the community [52]. This highlights the need to develop techniques for event logs with an emphasis on privacy and confidentiality preservation. This need was also noted from industry in a recent panel discussion [30]. Although some initial fragmented overview of the research on privacy and confidentiality exist [14, 31], no comprehensive structuring of the field exists. To address this issue, it is essential to understand what kind of privacy and confidentiality requirements have to be addressed by privacy and confidentiality preserving process mining techniques. In this light, our paper provides the following main contributions:
· We identify a set of threats for privacy and confidentiality and illustrate them according to an example application scenario (Section 2).
· We define a conceptual model for requirements and threats and provide a structured discussion of the current literature (Section 3).
· We use the literature review to identify a number of research challenges for privacy and confidentiality in process mining (Section 4).
Upfront, we provide a definition of privacy and confidentiality for the purpose of this paper and introduce process mining based on a motivational example scenario.

1.1 Privacy and Confidentiality
Privacy and confidentiality have a lot in common that may lead to confusion; however, each of them has a specific meaning.
Privacy. In our current data-driven society, privacy has received much attention through frequent data breaches as well as through regulations such as Europe's General Data Protection Regulation (GDPR) [44]. Generally, privacy is seen as the right of individuals to control how their personal data is collected, used, and/or disclosed to other individuals, organizations or governments [54]. GDPR defines personal data as: "Personal data means any information relating to an identified or identifiable natural person (`data subject'); an identifiable natural person is one who can be identified, directly or indirectly [..]"[44]. Besides GDPR, privacy is subject to other international laws such as the UN Declaration of Human Rights [5], and Asia-Pacific Economic Cooperation [7]. We follow the definitions of GDPR in this paper.
Confidentiality. Whereas there is some overlap and the concepts are often used interchangeably, the focus of confidentiality is making sure that only authorized individuals have access to the protected data and information. For example, in [21], confidentiality is defined as an agreement about maintenance and who has access to classified/sensitive data. Thus, confidentiality is concerned with data access, while privacy is focused on individuals and their rights. When the data are personal data, the confidentiality challenges coincide with the privacy challenges. Here, we distinguish privacy from confidentiality based on the listed differences. When the main concern is an individuals' rights, e.g., process workers, customers, or patients, then it is considered a privacy issue. Otherwise, if the concern is more relevant to general data protection, it is assumed as a confidentiality issue.
Manuscript submitted to ACM

Privacy and Confidentiality in Process Mining

3

Table 1. A fragment of a simplified event log obtained from a hospital: each row corresponds to an event.

Patient Activity Timestamp Resource Role

Age Disease

1

Register 07.01.2020-08:30 ResA

Administrative 22 Flu

1

Visit

07.01.2020-08:45 ResB

Doctor

22 Flu

2

Register 07.01.2020-08:46 ResA

Administrative 30 Infection

3

Register 07.01.2020-08:50 ResA

Administrative 32 Infection

1

Blood Test 07.01.2020-08:57 ResE

Administrative 22 Flu

1

Discharge 07.01.2020-08:58 ResC

Administrative 22 Flu

2

Hospitalize 07.01.2020-09:01 ResD

Administrative 30 Infection

3

Hospitalize 07.01.2020-10:00 ResD

Administrative 32 Infection

2

Blood Test 07.01.2020-10:02 ResE

Nurse

30 Infection

3

Blood Test 07.01.2020-10:15 ResE

Nurse

32 Infection

2

Blood Test 07.02.2020-08:00 ResE

Nurse

30 Infection

2

Visit

07.02.2020-09:30 ResF

Doctor

30 Infection

3

Visit

07.02.2020-13:55 ResF

Doctor

32 Infection

2

Discharge 07.02.2020-14:00 ResG

Administrative 30 Infection

3

Discharge 07.02.2020-14:15 ResG

Administrative 32 Infection

1.2 Process Mining: Preliminaries and Motivational Scenario
The foundation of process mining is to use events to provide insights about the real execution of business processes. Each event is assumed to be related to certain activities of the process. We introduce process mining and the typical components of a process mining system based on an example scenario in a hospital setting. Health care has seen many process mining applications [33, 45] which makes this a representative example. The goal of analysing processes with process mining in our scenario is to prevent rework, decrease waiting time for patients, and improve documentation by discovering cases of non-compliance. The hospital is also interested in benchmarking, i.e., investigating how their processes and their performance differ from other hospitals.
Concretely, the hospital wants to apply process mining to discover the trajectory of different patients from the moment they are admitted until their discharge from the hospital. Each visit of a patient to the hospital forms a process instance or case, and the individual events of each case are sourced from the Hospital Information System (HIS). The HIS records information on logistical and treatment activities conducted for specific patients and who of the hospital staff performed them. In addition, a part of the process is performed via e-mails, e.g., referrals to other care institutions and the request of previous medical documentation. Therefore, certain events are collected from the e-mail server of the hospital. E-mails are associated with certain process activities using text mining and the metadata (sender, recipient) is used to identify the staff responsible. Finally, to benchmark the hospital wants to share some of this data over organizational boundaries and perform inter-organizational process mining [46, 58].
Based on this scenario, we describe the elements of such a typical process mining application. We organize the elements into three layers: data, application, and presentation layer.
Data Layer. Process mining starts from event data, a collection of events or event log representing the execution of several instances of a business process. Table 1 shows an example of such an event log extracted from the HIS and e-mail system of the hospital. Here, each row represents an event that indicates when an activity was performed (Timestamp) and by whom it was performed (Resource). Furthermore, each event is associated with a running process instance or case (Patient), which in our case is a unique identifier of the patient visit. By grouping events based on their case and
Manuscript submitted to ACM

4

Elkoumy, et al.

Discovery
Event Log

Conformance

Trace for Patient 1

Register

Blood Test

Visit

Invalid Event

Discharge

Fig. 1. Process discovery and conformance checking shown based on the event log from Table 1. A process model in BPMN was discovered and used for conformance checking towards the first trace of the log. One of the events of the trace (Blood Test) should not have occurred according to the model.

ordering them according to their timestamp, we obtain sequences of events: one trace for each process instance. For example, in Table 1, the trace for case 1 is the sequence of activities: Register, Visit, Blood Test, and Discharge. In addition event logs often include additional domain specific attributes, which are not strictly required for the application of basic process mining techniques, but may provide additional context. In our hospital scenario, these attributes are Age and Disease.
Application Layer. Algorithms that process event logs and compute representations are an important part of process mining. Two of the most important applications of process mining are process discovery [1] and conformance checking [4]. Process discovery receives an event log and returns a process model that describes the process behavior in an abstract model defining the possible sequences of activities. An example of such model that could be discovered from the log in Table 1 would be the BPMN1 model shown in Figure 1. Here the process discovery algorithm inferred from the event log that each trace starts with activity Register. Then, activity Hospitalize must be performed in parallel with one or multiple Blood Tests. Finally, each case of our simplified process is concluded by a Visit in sequence with Discharge. Conformance checking aims to quantify deviations between the process model and real execution data as observed through the event log. The output of a conformance checking algorithm is usually information about how individual traces in the given event log deviate from that reference model. In Figure 1, a conformance checking technique has identified that the activity Blood Test, which occurred according to an event in the trace for patient 1, should not have been performed since the patient was not hospitalized. Many other tasks are possible such as the mining of resource profiles of the employees [35], the mining of decision rules [51] based on the characteristics of cases captured in additional attributes, or the automated prediction of the next step in a running case [49] with the goal of acting on cases leading to a bad process outcome or performance.
1Business Process Model and Notation (BPMN) standard: https://www.omg.org/spec/BPMN/. Manuscript submitted to ACM

Privacy and Confidentiality in Process Mining

5

3 3

1
3 3
2 2 2 1

3

3

3

3

Fig. 2. A frequency annotated process model based on the combined results of process discovery and conformance checking. When only considering the presentation layer of the process mining application, the analyst may only see such a visualization of the underlying event log. Occurrence frequencies of activities (in black) and of the transitions between activities (in grey) are added as annotation to the model.

Presentation Layer. Generated artifacts such as the discovered process models or the deviations detected by conformance checking, or other analytical outputs need to be presented to the process analyst or business user. Often these outputs are aggregated representations, e.g., a process model with projected frequencies as shown in Figure 2. In many cases, these representations also include additional information, e.g., the average waiting or processing times of activities. Regarding privacy and confidentiality, it is important to note that these artefacts do not directly reveal the exact underlying event logs and only provide an aggregated view on the process reality. In many cases, process analysts or domain users could use these refined results to obtain insights on the process without getting access to the underlying event data or algorithmic results. However, also in the presentation layer, results can be specific to single events or cases. They may be infrequent paths in a frequency annotated process model, e.g., the path from Register to Visit annotated with frequency 1 in Figure 2. Many process mining tools also provide the option to drill down to, e.g., a single process prediction, a compliance violation, or simply give direct access to the source events.
We briefly introduced the major elements of process mining relevant to the discussion of privacy and confidentiality threats along with three layers. In the following sections, we will show how these elements are related to the design of privacy-preserving and confidential process mining techniques.
2 THREATS FOR PRIVACY AND CONFIDENTIALITY IN PROCESS MINING
This section presents threats to confidentiality and privacy in process mining. We collected the threats based on, first, developing a list of concrete attacks among the authors and, then, cross-referencing this list with generic attacks from the literature.
In this paper, we do not focus on attacks with malicious adversaries that control the information flow. We assume an honest-but-curious attacker who follows the protocol and has legitimate access to the data. An attacker might be the process analysts or business user who obtains sensitive information from supposedly anonymized event data provided to her. Inside or outside attacks to bypass access control are outside our scope.
Manuscript submitted to ACM

6

Elkoumy, et al.

Overall, the identified threats can be categorized into four categories: re-identification, reconstruction, membership disclosure, cryptanalysis; each of which is described in more detail based on the literature and is instantiated in the context of our hospital scenario.
2.1 Re-identification Threats (T1)
Re-identification or de-anonymization threats are those where the identity of an information (data) subject is at risk to be disclosed by singling-out individuals from the supposedly anonymized event logs [11]. This threat of reidentification is currently most dominant at the data layer. Here an information subject may be directly linked to the process case, e.g., the patient in Table 1, or linked to a certain activity, e.g., a resource (employee) of the hospital. There are several possible attack methods described in the literature that constitute re-identification threats.
In a linkage attack, an attacker uses background or context knowledge on the process or on the individuals and combines it with the released artefact. A pseudonimized event log in the data layer of the process mining application may be such an artefact to which an analyst, or the general public in case of research data, has access. At first glance, Table 1 does not allow to re-identify patients or employees, all direct identifiers have been replaced. However, based on equal unique attributes, events can be linked to a case and thus to an identity. For instance, assume an attacker knows that Alice is 32 years old and has visited the hospital in a certain timeframe. By linking this very basic information with Table 1 only patient 3 is 32 years old, an attacker can infer the corresponding events of this patient and the sensitive disease. Such linkage attack can also be based on unique combinations of activities that are performed in a sequence for a certain process case. For example, the process case for the patient with identifier 2 is the only one containing two occurrences of the activity Blood Test. Thus, the uniqueness of cases in an event log can indicate the risk of reidentification. It was shown in [52] that there is serious potential for privacy leaks in published event log data, as the vast majority of public research event logs contain many unique cases.
When several organizations independently release generalized event logs about overlapping populations, re-identification is possible by an intersection attack. This may happen in the inter-organizational process mining setting as illustrated with the benchmarking use case in our hospital example or, e.g., when several government agencies release event log data, which is likely to be containing information about the same population of citizens. If we assume that an adversary knows that a target is contained in several event logs, the identity may be disclosed by taking the intersection. Assume two hospitals independently publish event logs of patient trajectories in which age is generalized to prevent a linkage attack, i.e., Table 1 would only contain age groups 0­20, 21­40, and so on. Patient Alice would not be easily re-identifiable anymore. However, let us assume that an adversary knows that she was transferred from hospital A to hospital B. Even though the age group is generalised, there may only be one process case in that age group in each of the hospital event logs such that it is consistent with the transfer scenario. So, the intersection set is a single record and we have re-identified Alice. Of course, such an attack may also be performed on other event log attributes and not only be based on the time relation between process cases.
2.2 Reconstruction Threats (T2)
The threat of reconstruction is the risk of recreating the (partial) original event log from a released process model or aggregated statistics [8]. Reconstruction is a threat to privacy when attributes from individuals are reconstructed, and a threat to confidentiality when reconstructing non-personal data. This threat is closely linked to the presentation layer of the process mining application. The individuals in the event log are seemingly protected by only releasing aggregate statistics.
Manuscript submitted to ACM

Privacy and Confidentiality in Process Mining

7

If an individual cannot be linked directly, attributes can be reconstructed, for example, from aggregated statistics by a difference attack. In this attack, an adversary isolates a single value by combining multiple aggregated statistics about a dataset. Assume the process analyst can only pose queries to obtain aggregate statistics, e.g., by obtaining process model visualizations such as the one in Figure 2. The analyst could obtain the frequency visualization grouped per disease and, therefore, know the number of patients (unique cases) for each disease. In a second query, the analyst could exclude 32-year-old patients in the query and obtain the same statistics. From the difference, an adversary can infer that Alice, the only 32-year-old patient, has an infection.
Adversaries may also attempt to reconstruct training or source data from a published model, which is called modelinversion [18]. The training data is estimated by observing the input and output of a model. This attack only creates a probabilistic version of the training data. The models used for predictive and prescriptive process monitoring [15, 28] use machine learning models that could be directly vulnerable to this attack. In our application scenario, however, even a probabilistic version of the original event log can reveal private information such as the diagnosis of a specific patient or the responsible resources treating a patient. While model-inversion attacks have not yet been well studies for process mining, for instance, from the process model in Figure 2, we can infer that the underlying training event log consists of a single trace in which the patient left without being hospitalized and also that there is a single patient that had two blood tests taken.
2.3 Membership Disclosure Threats (T3)
Membership disclosure threats entail uncovering the knowledge of whether a specific individual was included in the source data for a particular model or analysis. So, differently to a re-identification attack only the fact that an individual was part of the dataset is disclosed.
In a membership inference attack, an adversary aims to determine whether an individual was included in the source data. An adversary who only has access to the released model can train shadow models to predict membership [47]. These models capture the misclassification difference between samples that are likely to be in or outside the training data. By checking if a process model allows the behavior of a certain trace, an adversary can try to predict, if the trace was included in the data underlying the process discovery. In our hospital example, depending on the scope of a process mining analysis, such knowledge could reveal that a specific individual visited the hospital for a specific treatment. For instance, assume an attacker knows that a target patient Bob has made a blood test twice and has access to the process model (cf. Figure 2). It is very likely that Bob is included since he made a blood test twice. However, in this case, an adversary cannot identify that Bob is patient 2, i.e., the exact process case identifier remains protected. Still, this knowledge may leak sensitive information, e.g., if the dataset was extracted for a set of patients with a specific disease membership disclosure would also disclose the disease information.
2.4 Cryptanalysis Threats (T4)
Often, data is pseudonymized, as in our example, or event encrypted to provide confidentiality. However, pseudonymized or even fully encrypted event logs are vulnerable to attacks based on the analysis of the frequency.
A frequency analysis takes advantage of the characteristics of the encrypted data. Such analysis could rely on background knowledge of the process, e.g. the frequency of certain activities within one trace and their position in the trace. For example, when considering our hospital process example, certain diagnostic steps, such as blood test, might appear more than once in a trace, while the registration and release of a patient usually happen at the beginning and end of each trace. In other words, even if the activity in Table 1 had been encrypted an attacker might decode the
Manuscript submitted to ACM

8

Elkoumy, et al.

start and end activity. In this case, an attacker has both the plaintext and its encrypted version, which can be used to reveal the total cipher. This is also possible for the resource. Here, the adversary's background knowledge may be that, for example, only Natsa was working on the registration on January 07, 2020. In this case, an adversary can link the activities Register with the pseudonymized resource identifier ResA. It is not difficult to gain this knowledge, especially in public places like a hospital.
We identified four main threats and sketched the related attack methods in a process mining scenario. In the remainder of this paper, we review and discuss possible solutions and identify the open challenges.

3 PRIVACY-PRESERVING PROCESS MINING
In this section, we discuss requirements that address the threats discussed in Section 2. The requirements are taken from a systematic synthesis of the current privacy and confidentiality landscape conducted by Gharib et al. [20], who themselves based their work on a previous literature review [19]. The mentioned requirements are legislature agnostic but nonetheless present the opportunity to incorporate demands and elements of multiple common protection models such as the European (GDPR), Australian (Privacy Act 1988), Canadian (PIPEDA), and US legislation. We will particularly focus on GDPR as an example to explain the origin of the requirements.

3.1 Conceptual Model and Requirements
Figure 3 shows a UML class diagram of how the concepts of privacy and confidentiality relate, both to the discussed threats and to the requirements taken from [20]. In Section 1.1, we note that confidentiality has direct overlap with privacy. Therefore, confidentiality could, as in Gharib et al. [20], solely be seen as a requirement of privacy. However, following our definition in Section 1.1, we raise confidentiality beyond just its overlap with privacy and make it a separate concept, therefore slightly adjusting the model in Gharib et al. [20]. The purpose of our privacy and confidentiality requirements is to address potential threats and mitigate potential vulnerabilities. In the following, we explain the requirements.
· R1 - Anonymity deals with personal information, and it ensures that personal data can only be used without disclosing identities of information subjects [9, 34]. This is a privacy requirement since it concerns personal information. According to Recital 26 of GDPR, the principles of data protection should not apply to anonymous information where the information subject is not identifiable. Therefore, anonymity is a big step towards privacy regulations compliance.
· R2 - Unlinkability describes that it should not be possible to link personal information to their corresponding owners [34]. This requirement complements R1 in the sense that preventing identity disclosure cannot be guaranteed by only making identifiers unreadable. Furthermore, all identifiers for linkage also need to be removed. Unlinkability includes that data cannot be re-identified by linkage attacks.
· R3 - Unobservability means that it should not be possible to observe the identities of information subjects that perform any action [34]. It should be noted that unlike anonymity and unlinkability, which keep the identity of the actor hidden, the goal here is to ensure that the actions themselves are hidden. Thus, we categorize this requirement as a confidentiality requirement. This requirement mostly concerns continuous monitoring and processing of the data generated by running systems. It is intended to protect personal data against unauthorized processing, as described in Article 5 of GDPR.
Manuscript submitted to ACM

Privacy and Confidentiality in Process Mining

9

(Event) Data

Application

Presentation

Process mining requirements

need to meet

Process mining techniques

is used by

Information subject (owner)

belongs to

Information

Non-sensitive information

Sensitive

has

information

Situation determines Sensitivity

is subject to

Personal

mitigates Vulnarablity

mitigates

Non-personal

concerning

Privacy policy

Privacy requirement

realised by

exploits
Threat
generates Attack method

Confidentiality policy

concerning

realised by

Confidentiality requirement

Unlinkability Anonymity

Unobservability
Accountability Notice
Transparency

Fig. 3. A UML class diagram linking threats and requirements to the remaining concepts used.

Manuscript submitted to ACM

10

Elkoumy, et al.

· R4 - Notice means that information subjects should be notified when their information is gathered [9]. A notice should include the detailed information which is to be gathered, disclosure risks and data quality concerns. The notice requirement can be categorized as both privacy and confidentiality requirement depending on the information owner, which could be both an individual or a company. This requirement relates to the concept of consent in GDPR. The data processing often needs to be based on consent. As mentioned in Article 7 of GDPR, the data controller/processor should demonstrate that the information subject has consented to processing of his/her data. Note that the consent needs to be kept updated based on the purpose of data processing.
· R5 - Transparency means information owners should be able to know who uses their information, how, and for what purposes [9]. This requirement can also be categorized as both privacy and confidentiality requirement depending on the nature of the information owner. The principle of transparency is described in Recital 58 of GDPR.
· R6 - Accountability describes that information subjects should be able to hold information users accountable for their activities and the consequences of misusing their data [9]. This requirement concerns both personal and non-personal information. It is mentioned in Article 5 GDPR as one of the principles of processing personal data, where it is described that the personal data should be protected against unlawful processing, accidental loss, destruction, or damage.
When information is exploited by process mining techniques, protecting privacy and confidentiality should not compromise the requirements of process mining techniques. There are three types of additional requirements:
· R7 - Data requirements are that process mining techniques should support different data storage formats, e.g., centralized in a single organization and distributed among different parties. On top of that, processing different types of data should not lead to any privacy leakage.
· R8 - Application requirements mean that the algorithms which are applied should be computationally acceptable, and fulfilling privacy and confidentiality requirements should not impose an unreasonable load on the time or resource consumption of the algorithms.
· R9 - Presentation requirements are that the reported results should be interpretable by users. This includes fulfilling privacy and confidentiality requirements without leading to a utility loss of the anonymized data and having the ability to repeat different types of queries without privacy disclosure.

3.2 Existing Protection Models
Here, we introduce the main strategies of existing protection models [53] that are designed to provide technical solutions for the requirements. There are three main categories:
· (M1) Group-based models based on data similarity like -anonymity [48] and its extensions, e.g., -diversity [27] and -closeness [26]. These types of models are aimed to provide R1 - Anonymity and R2 - Unlinkability requirements. Here, cases are grouped such that each case shares the quasi-identifier values with a group of cases. However, this protection-based model makes assumptions about the background knowledge of an adversary.
· (M2) Indistinguishability-based models introduce noise to provide uncertainty of whether an individual's data is included in the dataset. The best-known models comply with differential privacy [10] as a provable guarantee to ensures that removal or addition of a single case does not significantly impact the result of analysis regardless of an adversary's knowledge. This type of models is also focused on R1 - Anonymity and R2 Unlinkability requirements.
Manuscript submitted to ACM

Privacy and Confidentiality in Process Mining

11

· (M3) Confidentiality frameworks [42] are often based on encryption methods and access control requirements, where different encryption techniques are applied to data based on their sensitivity and the authorization of users who need to access the data. Confidentiality frameworks could support R1 - Anonymity, R3 - Unobservability, and R5 - Transparency requirements.
Additional orthogonal models, such as those based on the idea of information gain [24] or time [55], are important for confidentiality and privacy alike.

4 RESEARCH CHALLENGES
Based on the identified threats, requirements, and protection models, we review the literature and synthesise a set of research challenges.

4.1 Current work
Previous studies on privacy-preserving and confidential process mining addressed some of the requirements and attempts to mitigate the threats.
Rafiei et al. [43] propose a privacy model called TLKC for publishing event logs, which provides group-based anonymization (M1) based on k-anonymity, and quantifies the risk based on the attacker's background knowledge. Their model fulfills R1 - Anonymity and R2 - Unlinkability). The k-anonymity model is secure against the reconstruction threat (T2). However, k-anonymity partially mitigates the re-identification threats (T1) and the membership disclosure threat (T3) [6]. The adoption of k-anonymity makes the model interpretable (R9 - Presentation).
Also, Fahrenkrog-Petersen et al. [2, 16] use the k-anonymity privacy model (M1) for publishing event logs but add the use of t-closeness to protect attribute values. Similar to TLKC, R1 - Anonymity, R2 - Unlinkability requirements are fulfilled. Again, the privacy model is interpretable (R9 - Presentation). The authors suppress events or cases that would result in privacy leakage. However, data suppression is correlated with utility loss and no explicit utility measure is considered.
The differential-privacy model (M2) is adopted, e.g., by Mannhardt et al. [29] for controlling disclosure of two types of queries: the frequencies of directly-follows relations and the trace variant frequencies. Re-identification threats T1, reconstruction threats T2, and membership disclosure threats T3 are mitigated and requirements R1 and R2 are fulfilled. Neither transparency nor accountability is considered, and no guarantees are given for the utility (R9 - Presentation) of the obtained DFG.
Fahrenkrog-Peterson et al. [17] use a differential privacy mechanism as well for event log anonymization in a framework called PRIPEL. They ensure privacy guarantees on the basis of individual cases. Also, they consider anonymizing event log attributes with different values, adapted with respect to the sensitivity of their values. Furthermore, they propose timestamp shifts to anonymize the timestamp attribute. The use of differential privacy fulfills the requirements R1 - Anonymity and R2 - Unlinkability to mitigate threats T1, T2, and T3. However, PRIPEL does not optimize the disclosure for a certain level of utility (R9 - Presentation).
Cryptographic privacy models (M3) have been considered for both centralized and distributed event logs settings. Rafiei et al. [41, 42] introduced an encryption framework for ensuring confidentiality in process mining to secure against the threat T4. The framework is divided into three processing environments and provides user access control thereby addressing R6 - Accountability. The framework gives a data analyst access to the internal partially secure event logs, which makes the framework vulnerable against T1, T2, and T3. Only centralized event logs are considered failing
Manuscript submitted to ACM

12

Elkoumy, et al.

to provide support for distributed event logs (R7 - Data). A cross-organizational setting is considered, e.g., by Tillem et al. [50] who propose a secure processing protocol to execute the Alpha algorithm over distributed event logs (R7 Data). However, their protocol does not mitigate attacks on confidentiality described in T4.
Elkoumy et al. [12, 13] adopt secure multi-party computation protocols to jointly calculate directly-follows relations securely between several organizations without the need to share private data in order to fulfill R7 - Data. Their framework is secure against the attacks on confidentiality T4. They added a differential-privacy layer [13] in order to mitigate the threat on privacy T1 to fulfill the requirement R1 - Anonymity. However, the effect on the utility loss has not been studied (R9 - Presentation).
Other studies on privacy-preserving process mining do not fulfill any of the above requirements as they do not provide a concrete mechanism of disclosure control. Rafiei et al. [38, 39] provide privacy metadata by extending the XES standard. Pika et al. [36] studied the impact of anonymization on process mining in healthcare without providing a concrete mechanism. In this line, Rafiei et al. [40] provide privacy quantifications for both the disclosure risk and the utility loss and Nuñez von Voigt et al. [52] quantify the re-identification risk resulted from the disclosure of event logs based on individual uniqueness. Both do not provide a solution. Finally, other works offer only one specific task, for example, Rafiei et al. [37] provide privacy-preserving role mining adopting a substitution method that secures the activities with sensitive frequencies.
We summarize the studies in Table 2 and observe that most of the previous studies fulfill the requirements: R1, R2, and R3. However, some of the requirements have not been addressed in the literature, e.g., R4, R5, R8, and R9. Furthermore, the literature either mitigates threats on privacy or threats on confidentiality, but it does not mitigate both types of the attacks together.

Table 2. Summary of privacy-preserving process mining approaches w.r.t. the requirements, the protection models, and the threats (the symbol means fulfillment,  means partial fulfillment, and - means does not fulfill)

Paper TLKC [43] Fahrenkrog-Petersen et al. [2, 16] Mannhardt et al. [29] PRIPEL [17] Rafiei et al. [41, 42] Tillem et al. [50] Elkoumy et al. [12, 13]

R1 R2 R3 R4 R5 R6 R7 R8 R9  - - - - - -   - - - - - - 
 - - - - - -  - - - - - - - -- -- - - - - - - -- - - - - -- -

M1 M2 M3 - - -
--- - - - - -

T1 T2 T3 T4   -
  - - - ---- -

4.2 Research Challenges for Process Mining
Our analysis of state-of-the-art work addressing privacy and confidentiality gives rise to a number of research challenges.
(1) Interpretable Quantification of Privacy Disclosure In real life, there is always privacy loss with any information disclosure. Organizations need more reliable and interpretable metrics of privacy disclosure (R9 Presentation). Interpretable disclosure metrics of the applied privacy models are needed that a user can understand in business terminology [53]. Translated to our hospital example, the managers need risk indicators that
Manuscript submitted to ACM

Privacy and Confidentiality in Process Mining

13

they can understand. A probabilistic percentage indicator may help address this challenge as they are easier to understand by end-users. Such risk metric would need to consider disclosure at several levels and under different assumptions: the entire event log, specific cases or events, random cases or events, multiple or single cases per individual. Specifically, how many cases are recorded for a single individuals is an important factor for M3 models [23]. Concretely, the hospital in our example may have a highly sensitive patient (e.g., a politician) that has higher privacy requirements than the other patients, or a specific treatment (activity) can be riskier than the other treatments, e.g., treatments directly related to rare diseases. Personalized privacy quantification may help to address this challenge. The -value for differential privacy, often guaranteed by M3 models, may be used as indicator, but is hardly interpretable by the general public. K-anonymity based models such as [43] are interpretable, but only partly mitigate some threats. (2) Balancing Risk and Utility The perfect way to protect private data is to avoid sharing it. However, insights are being missed when necessary data is not available. Thus, there is always a trade-off between the disclosure risk and the utility of using the disclosed data [22, 25], as discussed in R9. Hence, it is a challenge to perform privacypreserving process mining without losing the utility of the anonymized event log. In our example, hospital managers need to estimate the amount of noise to be added to an event log to achieve a certain level of utility with acceptable risks. This estimation depends highly on the kind of analysis that is to be performed. Moreover, in line with the concepts of consent in GDPR, it is important to decide upfront on what risk can be accepted. However, process mining is often used for exploratory analysis in the hope to identify patterns in the event data, which makes this trade-off challenging. (3) Level of Granularity Process mining tools enable the user to perform analysis from different perspectives, e.g., activity-centric, to study the directly-follows relations, and resource-centric to study the hand-offs between resources. Moreover, other types of analysis, such as task mining enable the assessment of specific processes and offer their best automation opportunities. For instance, the hospital can apply a privacy model to the activity perspective; however, this does not protect the disclosure of how many resources are being utilized per hour. The privacy of patients would be protected, but events could be used for work surveillance. A clear research gap is that current work focuses on specific perspectives and attack scenarios and, due to the richness of event data, many threats and perspectives, e.g., the work surveillance perspective, have not yet been addressed. Granularity is also an opportunity. Many process mining tools enable the user to control the level of abstraction and apply filters on the discovered process model in order to fulfill the presentation layer requirement R9. Hence, such dashboards and business process filtering [56] could be provided to the process analyst while achieving an acceptable level of privacy. For instance, the hospital may decide to disclose the process map with the most frequent 10% of edges because that implies lower risk. Research on such systems and scenarios is currently missing. (4) Distributed Privacy Distributed privacy-preserving process mining aims to get insights from several event logs originating from several business organizations with a disclosure control mechanism. Different parties could be competitors and may not want to provide their full local private data to one another. However, they expect a mutual benefit by analysing global insights with process mining. For example, two hospitals may share mutual patients and they need to optimize their inter-organizational processes. Furthermore, an inter-organizational conformance checking or inter-organizational variant analysis may be needed to fulfill new business collaboration needs. A common solution to this problem is security protocols. However, such techniques have high
Manuscript submitted to ACM

14

Elkoumy, et al.

latency and massive communication overhead and require special deployments among organizations [12]. There is still a gap between the developed techniques and their real-life usability, also evident from the complete lack of related business studies for process mining. (5) Computational Challenges The optimal k-anonymization is NP-hard [32]. Hence, with increasing the dimensionality of the attributes of the event log, it becomes more unpractical to achieve privacy-preserving process mining. Similar arguments hold for both t-closeness and l-diversity models. Therefore, achieving an optimal privacy-preserving process mining with sufficient execution time (R8 - Application) is challenging. We need more efficient and scalable computational models for privacy-preserving process mining. Often, privacy and confidentiality is an afterthought since the value-adding business requirements are considered first. This, makes is imperative to provide techniques that are usable in practice. (6) Traceability Challenge Due to privacy regulations, such as GDPR, it is essential for an organization to provide individual to provide consent (right to consent), to access (right to access), and to remove (right to be forgotten) their personal data. Hence, organizations need to trace the data life-cycle starting from the data collection to the data removal from their databases [56]. There is an inherited challenge to provide traceability, primarily when data is distributed across information systems, specifically with process mining, where analysts look at processes across silos. While the application of process mining to verify the compliance with privacy regulations has been reported [57], there has not yet been research on the usage of recorded data for the purpose of process mining, which is often a secondary use of already collected data. (7) Transparency Challenge. According to regulations, the information subject should be notified when their data is used (R4 - Notice), and they should be able to know who is using the data and for what purposes (R5 - Transparency). Techniques need to be developed to support transparency, such as authentication and authorization, and audit-log mechanisms. Audit-log mechanisms record information such as the involved user, date and time, and the action executed by the user. This includes that organizations inform the information subjects when and for what purpose their data was used. Full traceability is a requirement for achieving transparency, but not sufficient by itself. Event logs are often collected from distributed data sources making it challenging to achieve transparency. Research on such mechanisms and systems is missing in the process mining domain.

5 CONCLUSION
According to regulations, organizations are obliged to adhere to privacy compliance and responsible usage of data. Additionally, confidentiality is of great importance in any professional setting. This poses challenges that require extensions of current state-of-the-art process mining techniques, which are often applied to potentially sensitive data. Designing appropriate techniques requires knowing the existing threats and challenges. This paper presents a conceptual model for threats and requirements that must be fulfilled by privacy and confidentiality preserving process mining techniques. Our literature survey highlights a need for future techniques that comprehensively address those threats and requirements.
In the future, we plan to evaluate existing process mining techniques addressing privacy and confidentiality according to minimum loss of utility for process mining. Such an analysis would improve the selection of suitable techniques.

REFERENCES
[1] Adriano Augusto, Raffaele Conforti, Marlon Dumas, Marcello La Rosa, Fabrizio Maria Maggi, Andrea Marrella, Massimo Mecella, and Allar Soo. 2019. Automated Discovery of Process Models from Event Logs: Review and Benchmark. IEEE Trans. Knowl. Data Eng. 31, 4 (2019), 686­705.
Manuscript submitted to ACM

Privacy and Confidentiality in Process Mining

15

[2] Martin Bauer, Stephan A. Fahrenkrog-Petersen, Agnes Koschmider, Felix Mannhardt, Han van der Aa, and Matthias Weidlich. 2019. ELPaaS: Event Log Privacy as a Service. In BPM (PhD/Demos) (CEUR Workshop Proceedings, Vol. 2420). CEUR-WS.org, 159­163.
[3] Eric Bergeron. 2000. The difference between security and privacy. In Joint Workshop on Mobile Web Privacy WAP Forum & World Wide Web Consortium, Vol. 7.
[4] Josep Carmona, Boudewijn F. van Dongen, Andreas Solti, and Matthias Weidlich. 2018. Conformance Checking - Relating Processes and Models. Springer.
[5] David A Catania. 1993. The universal declaration of human rights and sodomy laws: A federal common law right to privacy for homosexuals based on customary international law. Am. Crim. L. Rev. 31 (1993), 289.
[6] Aloni Cohen and Kobbi Nissim. 2020. Towards formalizing the GDPR's notion of singling out. Proceedings of the National Academy of Sciences 117, 15 (2020), 8344­8352.
[7] Asia-Pacific Economic Cooperation. 2005. APEC privacy framework. Asia Pacific Economic Cooperation Secretariat 81 (2005). [8] Irit Dinur and Kobbi Nissim. 2003. Revealing information while preserving privacy. In Proceedings of the Twenty-Second ACM SIGACT-SIGMOD-
SIGART Symposium on Principles of Database Systems, June 9-12, 2003, San Diego, CA, USA. ACM, 202­210. [9] S Dritsas, L Gymnopoulos, M Karyda, T Balopoulos, S Kokolakis, C Lambrinoudakis, and S Katsikas. 2006. A knowledge-based approach to security
requirements for e-health applications. Electronic Journal for E-Commerce Tools and Applications (2006), 1­24. [10] Cynthia Dwork. 2008. Differential privacy: A survey of results. In International conference on theory and applications of models of computation.
Springer, 1­19. [11] Cynthia Dwork, Adam Smith, Thomas Steinke, and Jonathan Ullman. 2017. Exposed! A Survey of Attacks on Private Data. Annual Review of
Statistics and Its Application 4, 1 (2017), 61­84. [12] Gamal Elkoumy, Stephan A. Fahrenkrog-Petersen, Marlon Dumas, Peeter Laud, Alisa Pankova, and Matthias Weidlich. 2020. Secure Multi-party
Computation for Inter-organizational Process Mining. In BPMDS/EMMSAD@CAiSE. Lecture Notes in Business Information Processing, Vol. 387. Springer, 166­181. [13] Gamal Elkoumy, Stephan A. Fahrenkrog-Petersen, Marlon Dumas, Peeter Laud, Alisa Pankova, and Matthias Weidlich. 2020. Shareprom: A Tool for Privacy-Preserving Inter-Organizational Process Mining. In BPM (PhD/Demos) (CEUR Workshop Proceedings, Vol. 2673). CEUR-WS.org, 72­76. [14] Stephan A. Fahrenkrog-Petersen. 2019. Providing Privacy Guarantees in Process Mining. In Proceedings of the Doctoral Consortium Papers Presented at the 31st International Conference on Advanced Information Systems Engineering (CAiSE 2019), Rome, Italy, June 3-7, 2019 (CEUR Workshop Proceedings, Vol. 2370). CEUR-WS.org, 23­30. http://ceur-ws.org/Vol-2370/paper-03.pdf [15] Stephan A Fahrenkrog-Petersen, Niek Tax, Irene Teinemaa, Marlon Dumas, Massimiliano de Leoni, Fabrizio Maria Maggi, and Matthias Weidlich. 2019. Fire Now, Fire Later: Alarm-Based Systems for Prescriptive Process Monitoring. arXiv preprint arXiv:1905.09568 (2019). [16] Stephan A Fahrenkrog-Petersen, Han van der Aa, and Matthias Weidlich. 2019. PRETSA: event log sanitization for privacy-aware process discovery. In 2019 International Conference on Process Mining (ICPM). IEEE, 1­8. [17] Stephan A. Fahrenkrog-Petersen, Han van der Aa, and Matthias Weidlich. 2020. PRIPEL: Privacy-Preserving Event Log Publishing Including Contextual Information. In BPM (Lecture Notes in Computer Science, Vol. 12168). Springer, 111­128. [18] Matt Fredrikson, Somesh Jha, and Thomas Ristenpart. 2015. Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures. In Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, Denver, CO, USA, October 12-16, 2015. ACM, 1322­1333. [19] Mohamad Gharib, Paolo Giorgini, and John Mylopoulos. 2017. Towards an Ontology for Privacy Requirements via a Systematic Literature Review. In ER (Lecture Notes in Computer Science, Vol. 10650). Springer, 193­208. [20] Mohamad Gharib, John Mylopoulos, and Paolo Giorgini. 2020. COPri - A Core Ontology for Privacy Requirements Engineering. In RCIS (Lecture Notes in Business Information Processing, Vol. 385). Springer, 472­489. [21] Laurinda B Harman, Cathy A Flite, and Kesa Bond. 2012. Electronic health records: privacy, confidentiality, and security. AMA Journal of Ethics 14, 9 (2012), 712­719. [22] Justin Hsu, Marco Gaboardi, Andreas Haeberlen, Sanjeev Khanna, Arjun Narayan, Benjamin C Pierce, and Aaron Roth. 2014. Differential privacy: An economic method for choosing epsilon. In 2014 IEEE 27th Computer Security Foundations Symposium. IEEE, 398­410. [23] Hasan B. Kartal, Xiaoping Liu, and Xiao-Bai Li. 2019. Differential Privacy for the Vast Majority. ACM Trans. Manag. Inf. Syst. 10, 2 (2019), 8:1­8:15. [24] Krishnaram Kenthapadi, Nina Mishra, and Kobbi Nissim. 2005. Simulatable auditing. In Proceedings of the twenty-fourth ACM SIGMOD-SIGACTSIGART symposium on Principles of database systems. ACM, 118­127. [25] Jaewoo Lee and Chris Clifton. 2011. How much is enough? choosing for differential privacy. In International Conference on Information Security. Springer, 325­340. [26] Ninghui Li, Tiancheng Li, and Suresh Venkatasubramanian. 2007. t-closeness: Privacy beyond k-anonymity and l-diversity. In 2007 IEEE 23rd International Conference on Data Engineering. IEEE, 106­115. [27] Ashwin Machanavajjhala, Daniel Kifer, Johannes Gehrke, and Muthuramakrishnan Venkitasubramaniam. 2007. l-diversity: Privacy beyond kanonymity. ACM Transactions on Knowledge Discovery from Data (TKDD) 1, 1 (2007), 3­es. [28] Fabrizio Maria Maggi, Chiara Di Francescomarino, Marlon Dumas, and Chiara Ghidini. 2014. Predictive monitoring of business processes. In International conference on advanced information systems engineering. Springer, 457­472.
Manuscript submitted to ACM

16

Elkoumy, et al.

[29] Felix Mannhardt, Agnes Koschmider, Nathalie Baracaldo, Matthias Weidlich, and Judith Michael. 2019. Privacy-preserving process mining. Business & Information Systems Engineering 61, 5 (2019), 595­614.
[30] Felix Mannhardt, Agnes Koschmider, Lars Biermann, Jana Lange, Florian Tschorsch, and Moe Thandar Wynn. 2020. Trust and Privacy in Process Analytics. Enterp. Model. Inf. Syst. Archit. Int. J. Concept. Model. 15 (2020), 8:1­8:4.
[31] Felix Mannhardt, Sobah Abbas Petersen, and Manuel Fradinho Oliveira. 2018. Privacy challenges for process mining in human-centered industrial environments. In 2018 14th International Conference on Intelligent Environments (IE). IEEE, 64­71.
[32] Adam Meyerson and Ryan Williams. 2004. On the complexity of optimal k-anonymity. In Proceedings of the twenty-third ACM SIGMOD-SIGACTSIGART symposium on Principles of database systems. ACM, 223­228.
[33] Andrew Partington, Moe Thandar Wynn, Suriadi Suriadi, Chun Ouyang, and Jonathan Karnon. 2015. Process Mining for Clinical Processes: A Comparative Analysis of Four Australian Hospitals. ACM Trans. Manag. Inf. Syst. 5, 4 (2015), 19:1­19:18.
[34] Andreas Pfitzmann and Marit Köhntopp. 2000. Anonymity, Unobservability, and Pseudonymity - A Proposal for Terminology. In Designing Privacy Enhancing Technologies, International Workshop on Design Issues in Anonymity and Unobservability, Berkeley, CA, USA, July 25-26, 2000, Proceedings (Lecture Notes in Computer Science, Vol. 2009), Hannes Federrath (Ed.). Springer, 1­9.
[35] Anastasiia Pika, Michael Leyer, Moe Thandar Wynn, Colin J. Fidge, Arthur H. M. ter Hofstede, and Wil M. P. van der Aalst. 2017. Mining Resource Profiles from Event Logs. ACM Trans. Manag. Inf. Syst. 8, 1 (2017), 1:1­1:30.
[36] Anastasiia Pika, Moe T Wynn, Stephanus Budiono, Arthur HM Ter Hofstede, Wil MP van der Aalst, and Hajo A Reijers. 2020. Privacy-preserving process mining in healthcare. International journal of environmental research and public health 17, 5 (2020), 1612.
[37] Majid Rafiei and Wil M. P. van der Aalst. 2019. Mining Roles from Event Logs While Preserving Privacy. In Business Process Management Workshops - BPM 2019 International Workshops, Vienna, Austria, September 1-6, 2019, Revised Selected Papers. Springer, 676­689.
[38] Majid Rafiei and Wil M. P. van der Aalst. 2020. Practical Aspect of Privacy-Preserving Data Publishing in Process Mining. In BPM (PhD/Demos) (CEUR Workshop Proceedings, Vol. 2673). CEUR-WS.org, 92­96.
[39] Majid Rafiei and Wil M. P. van der Aalst. 2020. Privacy-Preserving Data Publishing in Process Mining. In BPM (Forum) (Lecture Notes in Business Information Processing, Vol. 392). Springer, 122­138.
[40] Majid Rafiei and Wil M. P. van der Aalst. 2020. Towards Quantifying Privacy in Process Mining. In Process Mining Workshops - ICPM 2020 International Workshops, Padua, Italy, October 5-8, 2020, Revised Selected Papers (Lecture Notes in Business Information Processing, Vol. 406). Springer, 385­397. https://doi.org/10.1007/978-3-030-72693-5_29
[41] Majid Rafiei, Leopold von Waldthausen, and Wil M. P. van der Aalst. 2018. Ensuring Confidentiality in Process Mining. In SIMPDA (CEUR Workshop Proceedings, Vol. 2270). CEUR-WS.org, 3­17.
[42] Majid Rafiei, Leopold von Waldthausen, and Wil M. P. van der Aalst. 2019. Supporting Condentiality in Process Mining Using Abstraction and Encryption. In Data-Driven Process Discovery and Analysis - 8th IFIP WG 2.6 International Symposium, SIMPDA 2018, and 9th International Symposium, SIMPDA 2019, Revised Selected Papers (Lecture Notes in Business Information Processing, Vol. 379). Springer International Publishing, 101­123.
[43] Majid Rafiei, Miriam Wagner, and Wil M. P. van der Aalst. 2020. TLKC-Privacy Model for Process Mining. In RCIS (Lecture Notes in Business Information Processing, Vol. 385). Springer, 398­416.
[44] EU General Data Protection Regulation. 2016. Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing directive 95/46/EC (General Data Protection Regulation) 2016. OJ L 119, 1 (2016).
[45] Eric Rojas, Jorge Munoz-Gama, Marcos Sepúlveda, and Daniel Capurro. 2016. Process mining in healthcare: A literature review. Journal of Biomedical Informatics 61 (2016), 224­236.
[46] Karsten A. Schulz and Maria E. Orlowska. 2004. Facilitating cross-organisational workflows with a workflow view approach. Data & Knowledge Engineering 51, 1 (2004), 109 ­ 147.
[47] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 2017. Membership Inference Attacks Against Machine Learning Models. In 2017 IEEE Symposium on Security and Privacy, SP 2017, San Jose, CA, USA, May 22-26, 2017. IEEE Computer Society, 3­18.
[48] Latanya Sweeney. 2002. k-anonymity: A model for protecting privacy. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems 10, 05 (2002), 557­570.
[49] Irene Teinemaa, Marlon Dumas, Marcello La Rosa, and Fabrizio Maria Maggi. 2019. Outcome-Oriented Predictive Process Monitoring: Review and Benchmark. ACM Trans. Knowl. Discov. Data 13, 2, Article 17 (2019), 57 pages. https://doi.org/10.1145/3301300
[50] Gamze Tillem, Zekeriya Erkin, and Reginald L Lagendijk. 2017. Mining Encrypted Software Logs using Alpha Algorithm.. In SECRYPT. SciTePress, 267­274.
[51] Wil M. P. van der Aalst. 2016. Process Mining - Data Science in Action, Second Edition. Springer. [52] Saskia Nuñez von Voigt, Stephan A. Fahrenkrog-Petersen, Dominik Janssen, Agnes Koschmider, Florian Tschorsch, Felix Mannhardt, Olaf Land-
siedel, and Matthias Weidlich. 2020. Quantifying the Re-identification Risk of Event Logs for Process Mining - Empiricial Evaluation Paper. In CAiSE (Lecture Notes in Computer Science, Vol. 12127). Springer, 252­267. [53] Isabel Wagner and David Eckhoff. 2018. Technical privacy metrics: a systematic survey. ACM Computing Surveys (CSUR) 51, 3 (2018), 1­38. [54] Alan F Westin. 1968. Privacy and freedom. Washington and Lee Law Review 25, 1 (1968), 166. [55] Matthew K Wright, Micah Adler, Brian Neil Levine, and Clay Shields. 2002. An Analysis of the Degradation of Anonymous Protocols.. In Proceedings of the Network and Distributed System Security Symposium, NDSS, Vol. 2. The Internet Society, 39­50.
Manuscript submitted to ACM

Privacy and Confidentiality in Process Mining

17

[56] Rashid Zaman and Marwan Hassani. 2019. Process mining meets GDPR compliance: the right to be forgotten as a use case. In 2019 international conference on process mining doctoral consortium, ICPM-DC. CEUR-WS.org, 1­9.
[57] Rashid Zaman and Marwan Hassani. 2020. On Enabling GDPR Compliance in Business Processes Through Data-Driven Solutions. SN Comput. Sci. 1, 4 (2020), 210.
[58] Qingtian Zeng, Sherry X. Sun, Hua Duan, Cong Liu, and Huaiqing Wang. 2013. Cross-organizational collaborative workflow mining from a multi-source log. Decision Support Systems 54, 3 (2013), 1280­1301.

Manuscript submitted to ACM

