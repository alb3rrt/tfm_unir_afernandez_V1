arXiv:2106.00570v1 [cs.CE] 1 Jun 2021

Noname manuscript No. (will be inserted by the editor)
Robust design optimisation of continuous flow polymerase chain reaction thermal flow systems
Yongxing Wang · Hazim A. Hamad · Jochen Voss · Harvey M. Thompson
Received: date / Accepted: date
Abstract This paper presents an efficient methodology for the robust optimisation of Continuous Flow Polymerase Chain Reaction (CFPCR) devices. It enables the effects of uncertainties in device geometry, due to manufacturing tolerances, on the competing objectives of minimising the temperature deviations within the CFPCR thermal zones, together with minimising the pressure drop across the device, to be explored. We first validate that our training data from conjugate heat transfer simulations of the CFPCR thermal flow problems is noise free and then combine a deterministic surrogate model, based on the mean of a Gaussian Process Regression (GPR) simulator, with Polynomial Chaos Expansions (PCE) to propagate the manufacturing uncertainties in the geometry design variables into the optimisation outputs. The resultant probabilistic model is used to solve a series of robust optimisation problems. The influence of the robust problem formulation and constraints on the design conservatism of the robust optima in comparison with the corresponding deterministic cases is explored briefly.
Keywords Robust optimisation · Multi-objective optimisation · Gaussian process regression · Polynomial chaos expansion · Computational fluid dynamics
Yongxing Wang School of Mechanical Engineering, University of Leeds, Leeds, UK E-mail: scsywan@leeds.ac.uk Hazim A. Hamad School of Mechanical Engineering, University of Leeds, Leeds, UK E-mail: mnhsh@leeds.ac.uk Jochen Voss School of Mathematics, University of Leeds, Leeds, UK E-mail: J.Voss@leeds.ac.uk Harvey M. Thompson School of Mechanical Engineering, University of Leeds, Leeds, UK E-mail: H.M.Thompson@leeds.ac.uk

2

Yongxing Wang et al.

1 Introduction
Precision control of the heat transfer to and from small volumes of liquid flowing in fluidic channels underpins many important practical applications. Examples include environmental pollution monitoring systems, fuel cells and pharmaceutical manufacturing systems [36, 40]. There are also several examples in electronics cooling, where numerous heat sink configurations employ single phase flows in fluidic channels to dissipate high heat fluxes encountered in e.g. radio frequency and microwave applications [1]. This paper is motivated by single phase flow in fluidic channels that form part of Continuous Flow Polymerase Chain Reaction (CFPCR) systems used for the rapid amplification of DNA segments. These have played a pivotal role in the public health response to detecting and monitoring COVID-19.
In CFPCR systems the channels are arranged in a serpentine format to perform a rapid thermal cycling, where each straight component incorporates three distinct thermal zones: denaturation at  95C, annealing between 40C  50C and extension between 60C  70C. Recent studies have demonstrated that CFPCR systems present challenging, multi-objective optimisation problems with key objectives such as the minimisation of total processing time and heating power requirements, and the maximisation of temperature uniformity and DNA amplification efficiency [28, 17]. In addition to the channel geometry, flow speeds, distances between thermal zones, heating arrangements and the thickness, thermal conductivity and biological compatibility of the chip materials all have major influences on the DNA amplification and power consumption.
In these, and indeed all, fluidic channel systems, the geometry of the fluidic channel has a vital influence on thermo-fluid performance. Heat sinks, for example, employ a wide range of vortex generator systems to improve heat transfer and reduce pressure drop [2], while for CFPCR systems, channel sizes, inter-zone spacing and channel cross-sectional shape have all been found to useful variables for manipulating performance [41]. Channel cross-sectional shape can also be useful variables for manipulating performance. For example, adopting spiral [18] or radial cross-sections [32] have been proposed as an effective means of reducing the PCR reaction time, while [12] showed that employing diverging fluidic channels can improve the overall temperature uniformity within the PCR stages, ultimately enhancing DNA amplification efficiency.
All flow systems using fluidic channels are, however, subject to aleatory uncertainties, due to variations in geometric dimensions or operating conditions, each of which can affect overall performance significantly. Most previous studies have either used deterministic approaches which ignore uncertainties altogether or simply account from them using factors of safety [46, 22, 45]. This paper is the first to explore the effect of uncertainties in channel dimensions, arising from manufacturing tolerances, on the performance and optimisation of CFPCR systems.
Techniques for Optimisation Under Uncertainty (OUU) aim to enable designers to produce robust, reliable designs which account for the impact of uncertainties in the input and operating variables on the resultant uncertainties in performance [5]. The two main approaches to OUU are Robust Design Optimisation (RDO) and reliability-based optimisation methods [8]. Reliability-based ones focus on the probability of failure and are particularly important in the design of safety-critical systems, such as in the aerospace industry [34], and in other industries where the consequences of failure can be disastrous, e.g. the financial system [30]. [45] recently

Robust Optimisation of CFPCR

3

considered the reliability-based optimisation of heat sinks for cooling electronics based on liquid flows through micro-fluidic channels. Using a performance measure approach to reliability, they consider the influence of Gaussian uncertainties in flow rate and heat flux on critical temperature constraints, the violation of which are known to lead to increased component failures. They found that, compared to deterministic designs, higher pumping power is needed under design uncertainties to maintain the same thermal performance.
Inspired by the pioneering work of [38], RDO methods aim to produce optimal designs that are less sensitive to variable inputs, usually by enforcing a low standard deviation in the output quantities [23]. They generally use optimisation objectives and constraints based on the mean and standard deviation of performance, formulated in a number of ways, either by using objective functions which are specified in terms of weighted sums, compromise or aggregation approaches [24]. These have been used to account successfully for uncertainties in a range of challenging engineering problems. These include the effects of variations in material properties during sheet metal forming [39], the effect of manufacturing tolerances and variable operating conditions on air-cooled heat sinks [7], the influence of manufacturing errors caused by milling and etching on gripper mechanisms and heat sinks [33], and in lifecycle assessment methods [42].
Although used widely in the aerospace and automotive industries for many years, the use of optimisation methods employing physics-based flow simulations has expanded rapidly into many other application areas recently [21]. For deterministic optimisation methods, the key challenges are to develop efficient numerical methods for both flow simulations and design space exploration. When uncertainties are accounted for too, as needed in RDO methods, the computational burden can be increased many-fold since additional sampling is required in order to find information about the Probability Density Function (PDF) of performance objectives (usually the mean and standard deviation) at specific design points [24]. The use of surrogate modelling of the performance objectives is usually a key component of any feasible optimisation approach­using techniques such as Radial Basis Functions (RBF) [8], Moving Least Squares (MLS) [15] or supervised machine learning methods such as Artificial Neural Networks (ANN) [17] - to create inexpensive surrogates for mapping between input design variables and output objectives which can be used within optimisation algorithms [16]. For RDO the PDF of objectives can be generated using simple approaches such as Monte Carlo and Latin Hypercube sampling, but these may require thousands of numerical simulations in order to generate the statistical information and are often simply unfeasible.
In this study we will explore the effects of aleatoric uncertainties in the fluidic channel geometry, caused by manufacturing tolerances, on the design and optimisation of CFPCR systems. We will use an efficient approach to RDO by combining surrogate modelling based on Gaussian Process Regression (GPR) and Polynomial Chaos Expansion (PCE) to develop the required statistical information around design points. GPR is an efficient probabilistic machine learning approach [43] that can learn the mean and probability density function of outputs and has been shown to provide effective statistical surrogates for many problems [20, 11, 14, 27] and is therefore well-suited to RDO. We will alleviate the additional cost of multiple flow simulations, needed to generate statistical moments of the objectives, using generalised polynomial chaos expansion, which provides a rigorous approach to

4

Yongxing Wang et al.

propagating the uncertainties in input design variables into the output variables of interest [44, 13]. PCE provides much better convergence rates than random sampling [7], and has been used successfully in numerous RDO studies ­ see e.g. [7] RDO applied to heat sink design.
The paper is organised as follows. Section 2 describes the propotype CFPCR system being investigated, the specification of the conjugate heat transfer problem, the numerical methods for its solution and the validation of the methods. Section 3 presents the formulation of the RDO problems, together with the surrogate modelling and PCE methods used for generating the statistical information used within the RDO. Section 4 contains a series of results which explore the effect of uncertainty in fluidic channel geometry on CFPCR performance and compare the results of the RDO with those from a corresponding deterministic approach. Conclusions are drawn in section 5.

2 Numerical methods
The thermal flow problem considered is based on the prototypical CFPCR flow analysed in our recent paper [17], so only brief details are given here.

2.1 Problem description
Continuous Flow Polymerase Chain Reaction (CFPCR) systems are typically based on a serpentine fluidic channel arrangement, see Figure 1, in order to create a thermal cycling procedure which amplifies DNA segments, allowing detection and identification of gene sequences. Within each straight channel component there are three thermal stages of denaturation ( 95oC), annealing ( 56oC) and extension ( 72oC) and these are represented by the prototypical CFPCR thermal flow problem shown in Figure 2.
The fluidic geometry with a glass substrate and PMMA cover material, where Wc, Hc, Ww, Hb and L are the channel width, height, wall thickness (the spacing between the channels), the bottom height and total length respectively. Three individual heaters are placed under the glass chip with a constant separation S = 1mm, and the length of the denaturation, annealing and extension zones are chosen to give residence time ratios of 1 : 1 : 4 respectively.

2.2 Conjugate heat transfer modelling

We adopt a conjugate heat transfer model of a steady, single-phase, laminar flow employed by previous studies [26, 9, 3, 10]. The liquid is water, with temperature dependent density, thermal conductivity and viscosity. The effects of radiation and buoyancy are neglected and there is no internal heat source. The governing equations include the Navier-Stokes equations

f (T ) (u · ) u =  · µf Tf

u + (u)T

2 - pI - 3 µf

Tf

( · u)I

,

(1)

 · f u = 0,

(2)

Robust Optimisation of CFPCR

5

Fig. 1: A schematic diagram of the serpentine microfluidic channel and heating arrangements and
the hydrodynamic and thermal boundary conditions.

Fig. 2: Schematic diagram of a prototype of PCR channel representing a section of the serpentine
microfluidic channel.

with u and p being the fluid velocity and pressure respectively. The governing equations also include the heat transfer equations in the fluid

f (T )Cf (T ) u · Tf =  · kf (T )Tf ,

(3)

and in the solid

 · (ksTs) = 0,

(4)

where Cf , kf and ks represent the specific heat and thermal conductivities of the fluid and solid respectively. The thermo-physical properties f (T ), µf (T ), Cp(T ) and kf (T ) depend on the temperature as follows [4]:

f (T ) = 838.466 + 1.4T - 0.003T 2 + 3.72 × 10-7T 3,

(5)

µf (T ) = 1.38 - 0.02T - 1.36 × 10-4T 2 - 4.64 × 10-7T 3 + 8.9 × 10-10T 4, (6)

Cf (T ) = 12010.15 - 80.41T + 0.31T 2 - 5.38 × 10-4T 3 + 3.63 × 10-7T 4, (7)

kf (T ) = -0.869 + 0.00895T - 1.584 × 10-4T 2 - 7.975 × 10-9T 3.

(8)

6

Yongxing Wang et al.

The thermal conductivity of copper is ks = 400W/(m · K) and the target temperatures in the denaturation, annealing and extension zones are 95C, 55C and 72C
respectively. The governing equations are solved using COMSOL Multiphysics 5.4,
see [17] for further details.

2.3 Performance metrics

The metrics used in the optimisation are the temperature uniformity in the zones and the pressure drop along the channel. High temperature uniformity leads to high levels of DNA amplification within the PCR process, while minimising the latter reduces both the structural stresses in the chip and the hydraulic power input needed to pump the liquid through the chip. Temperature uniformity is quantified in terms of deviations from the target temperature Ttarget in the zones by the following discrete L2-error in the corresponding zone:

Tdev = Tf - Ttarget ,

(9)

where

·

=

1 N

N k=1

(·)2

,

with

N

being

the

number

of

discrete

points

of

our

numerical experiments. The pressure drop along the channel is simply

p = pin - pout.

(10)

2.4 Numerical validation
The mesh convergence is examined by obtaining numerical solutions on a series of structured finite element grids of increasing refinement, on a desktop PC with Microsoft Windows 10 and 32GB physical RAM. Table 1 shows the number of Degrees Of Freedom (DOF), physical memory (PM), Virtual Memory (VM), execution time and calculated Tdev and p for each mesh. There is only a small change (< 0.2%) in the obtained results if the number of mesh is above 877552. The numerical results presented below have been obtained on the mesh with 877552 elements as an appropriate compromise between computational expense and accuracy.

NO. of elements 93024 216096 380480 448686 877552
1026602 1171632

DOF (×105) 2.52
5.1679 8.3090 14.485 17.763 20.373 23.329

PM (GB) 2.71 3.17 3.89 4.47 6.56 8.23 7.93

VM (GB) 3.28 3.92 4.67 5.26 7.42 9.52 8.92

Time (s) 119 303 553 677 1839 3849 4050

p(P a) 51.31 51.00 50.64 50.58 50.48 50.45 50.43

Tdev (C) 27.98 27.81 27.70 27.58 27.57 27.50 27.52

Table 1: Effect of mesh density for the case of Hc = Wc = 500µm.

The numerical model is first compared with the experimental results in [29] for thermal flow in diverging channels. Figure 3 shows a generally very good agreement between the experimental and numerical results. The next comparison is with

Robust Optimisation of CFPCR

7

the numerical results in [9] where Hc = 150µm and Wc = 50µm. The numerical predictions of the temperature profile along the three temperature zones, shown in Figure 4, are also in very good agreement with the published results.

Fig. 3: Comparison of surface temperature
variation along flow direction in a diverging microchannel.

Fig. 4: Comparison of fluid average temperature
profile along the centreline.

3 Gaussian process regression and polynomial chaos expansions
We briefly introduce the Gaussian Process Regression (GPR) and Polynomial Chaos Expansion (PCE) methods used to generate the statistical information used within the RDO.
3.1 Gaussian process regression
One Conjugate Heat Transfer (CHT) simulation provides one data point: (Wc, Hc, p, Tdev). We generate simulation data at n = 100 input points (Wc, Hc)  [0.015, 0.5] × [0.05, 0.15], including 20 evenly spaced points at boundaries and 80 random, uniformly distributed points inside the domain. These generate the corresponding output variables (p, Tdev) which are found to lie within [50.87, 1437] × [12.87, 16.29]. We deliberately use data at the boundaries to improve the accuracy of extrapolation outside of the domain, which is required when applying the PCE method, as discussed in the following section 3.2.
For notation's convenience, let (x1, x2, y1, y2)j (j = 1, 2, . . . , n) denote the n data points from the CHT simulations with input x = (x1, x2) and corresponding output (y1, y2). The GPR can learn the relation fi(·) between x and yi (i = 1, 2) from these n training data points, i.e. it computes a surrogate model fi(x)  N µgfipr, (fgipr)2 with the superscript "gpr" denoting the mean or stan-

8

Yongxing Wang et al.

dard deviation from the GPR model:

µgfip(rx) = kT (K + I)-1 yi,

(11)

and

fgip(rx) = k(x, x) - kT (K + I)-1 k.

(12)

In the above, yi = (yi1, yi2, . . . , yin)T (i = 1, 2) is a column vector from the observations of the ith component of the output variables, and  is a specified noise

in

this

observation

yi.

k

=

k (xp, xq)

=

f2 exp

-

1 2l2

|xp

-

xq |2

is the squared-

exponential covariance function, with f and l being hyperparameters, which can

be determined by cross validation [43, 25] or maximising the marginal likelihood

[43], and

k = [k(x, x1), k(x, x2), . . . , k(x, xn)]T ,

(13)

k(x1, x1) k(x1, x2) . . . 

K= 

...

...

. 

(14)

k(xn, x1)

k(xn, xn)

The output standard deviation in (12) of the GPR model can be interpreted as uncertainties from two different sources: one is the noise  of our input training data (y1, y2), and the other one is the discrete error of our training data themselves, due to the finite dataset. It is reasonable to assume that data points from CHT simulations are clean and noise free [31, 35], so that we will be able to specify a very small  when training our GPR model in Section 4.1. For the second type of uncertainty, we shall demonstrate in Section 4.2 (see Figure 9) that it is much smaller than the manufacturing errors considered in this paper. We can therefore use the GPR method to create a deterministic surrogate model for analysing the propagation of manufacturing errors.

3.2 Polynomial chaos expansions
Real manufacturing processes create inevitably a certain level of noise in the input geometrical parameters. Our approach is to assume a reasonable control error in the input parameters and use the PCE method to propagate this noise to the output variables. These resultant probabilistic surrogate models are then used to solve optimisation problems in Section (4.3).
Considering an error ex around an input point x = (x1, x2), we need to know the corresponding error ey in the outputs yi = fi(x) (i = 1, 2). A fast analysis of this problem is to use the Taylor expansion to express yi around x if the derivative of fi is available. Alternatively, a convenient approach might be to create random points (based upon a distribution assumption such as ex  N (0, n2 )) around the input x, and calculate the corresponding statistics around the output yi = fi(x). The former is an efficient approach, but unfortunately we cannot easily access the derivative of fi for our problem. The latter Monte Carlo method is very slow (see Appendix A for two tests using this method).
The PCE method is much more efficient than the Monte Carlo approach (see A), and only needs a few data points around x in order to calculate the error at the

Robust Optimisation of CFPCR

9

output ­ this is available at any point in the design space using our deterministic

GPR surrogate model discussed in Section 3.1. The PCE method approximates

the output yi (i = 1, 2) as a linear combination of orthogonal polynomial basis k(x) = k1 (x1)k2 (x2),
m

yi  kk(x).

(15)

k=0

Both xi and yi (i = 1, 2) are regarded as random variables. We assume our input variables satisfy Gaussian distribution, which requires Hermite PCE basis functions. Other distributions require different basis functions [13].
There are intrusive and non-intrusive PCE methods to compute the PCE coefficients k (k = 0, . . . , m). The former requires modification of the governing equations of the system under study, while the latter are sampling-based methods requiring solutions of the governing equations for specific values of the random variables considered [37]. Non-intrusive methods provide data-driven models based on experimental or simulation data. Here, we use a non-intrusive method, for which there are pseudo-spectral projection and linear regression methods to compute the coefficients based on design variable sampling. Both of these methods are implemented in ChaosPy [13], which is used in this paper.

4 Implementation

The software packages used to implement the GPR method is GPy [19], the software package to implement the PCE method is ChaosPy [13], and the software package to implement the optimisation problem is SciPy [6]. All the Python codes are available in Appendices A to C. For presentational convenience, all the design variable training points and outputs (x1, x2, y1, y2)j (j = 1, 2, . . . , n) are normalised to the range [0, 1] by

xi - xm i in xm i ax - xm i in

,

yi - yimin yimax - yimin

,

i = 1, 2

(16)

before feeding the training data to the GPR or PCE codes. We have n = 100 training data points as shown in Figure 5. The results can be easily transformed from normalised space to physical space using (16). The corresponding scales in the physical domain are given when necessary. We also generate a test dataset of Ntest = 100 × 100 evenly spaced points in the domain  = [-0.1, 1.1] × [-0.1, 1.1] in order to test the surrogate model. The domain is extended by 0.1 around the boundary of the original domain 0 = [0, 1] × [0, 1], so that we can extrapolate values to compute the error propagation at the boundaries using the PCE method as discussed in Section 3.2.

4.1 Deterministic surrogate model
As discussed in Section 3.1 one can specify a small noise parameter  for data from the CHT simulations [31, 35]. Here, we investigate the effect of varying  from 10-14 to 10-10 on the accuracy and stability of the GRP algorithm by comparing the predicted mean and standard deviation. We plot the predicted norm of the

10

Yongxing Wang et al.

Fig. 5: Training data points: 20 evenly spaced points on boundaries and 80 random, uniformly
distributed points inside the domain.

mean and standard deviation as a function  in Figure 6, from which it can be

seen that the mean effectively constant, and there is no instability issue when using such small values of . Therefore, we will use  = 10-12 in the following to

create the deterministic GPR model. The mean and standard deviation response

surfaces are plotted in Figure 7. Notice from (12) that the standard deviation only

depends 4.2, that

otnhitshsetainnpduartdddateav,iastoiownehfg1apvr e(orfg1prfg2p=r

fg2pr. We will also show, ) from the GRP model is

in Section negligible

compared with the noise induced from the manufacturing errors.

4.2 Probabilistic surrogate model
We assume a manufacturing error ex = 0.05 in the input training data set, so that we have 95% confidence that an input data point xi (i = 1, 2) lies in [xi - ex, xi + ex]. Under the assumption of ex  N (0, n2 ), we have n = ex/2 = 0.025. We then use the PCE method to propagate this error to the outputs and create a probabilistic surrogate model, using the deterministic GPR surrogate model to calculate function values around point x = (x1, x2). However, before doing this we have to answer two questions:
­ what is the appropriate order for the polynomial basis used in the PCE method? ­ is the standard deviation (uncertainty from discrete data) of the GPR surrogate
model small enough, so that we can use the mean µgfipr (as a deterministic model) to calculate function values?
These two questions will be answered in the following section 4.2.1.
4.2.1 Convergence of the PCE method
In order to compute the PCE coefficients at a point x  0, we need several quadrature points x~ around x (pseudo-spectral projection method [13]). The input

Robust Optimisation of CFPCR

11

Fig. 6: Mean and standard deviation for f1 (top) and f2 (bottom) as a function , where

·

=

1 Ntest

Ntest k=1

(·)2

.

of these quadrature points are determined by x and the order of the polynomial
basis of the PCE method, and the outputs are computed by our GPR surrogate model. However, instead of using µgfip(rx~) to directly compute the ouptut values, we should consider the uncertainty fgip(rx~) as well; we cannot neglect fgip(rx~) by directly comparing its magnitude with the manufacturing error n = ex/2, because n is from the input space while fgip(rx~) is in the output space.
We test the PCE method at several different points inside the domain 0 as well as on its boundaries. In order to test the influence of fgipr on the error propagation, we add Gaussian noise, generated by N 0, fgip(rx~) 2 , to µgfip(rx~) for
every point x~ to compute the PCE coefficients as discussed in Section 3.2 ­ the
Python implementation is given in Appendix A.
We report in Figure 8 the error at three particular points for six cases of random noise, from which it can be seen that a 3rd order polynomial basis would be
sufficiently accurate to approximate the error propagation. Notice that in Figure 8
the superscript "pce" denotes the mean or standard deviation computed using the
PCE method, corresponding to the superscript "gpr" (used through this paper) for the GPR model. In order to compute the coefficients of this 3rd order polynomial (using the pseudo-spectral projection method [13]), we need to evaluate µgfipr at points 0.05836 away from the boundary of 0, which can be achieved by the extrapolation of our GPR model. Also notice that higher order PCE polynomial basis is needed to evaluate µgfipr at points further away from the boundary. This

12

Yongxing Wang et al.

Fig. 7: The mean (top) of f1(x) and f2(x), and standard deviation plotted on  (left-bottom)
and 0 (right-bottom).

introduces extrapolation errors as well, and this can be observed from Figure 8 (a) and (d) using a 7th and 6th order of polynomials respectively. We also present

the corresponding standard deviation of the GPR model in the captions in Figure

8, from which we can see this standard deviation of the GPR model is negligi-

ble compared with the standard deviation induced by the manufacturing errors.

This observation is further validated in Figure 9 where the ratio of the standard

deviation of the GPR model to the standard deviation of the PCE model (where

the random noise is considered as described above) is less than 0.1 for f1 and

0.001 for f2. Although not shown here, this is found to be the case for all ex-

amples considered. In order to further demonstrate that the uncertainty of the

GRP model is negligible, we compare the case of adding noise N 0, fgip(rx~) 2

to µgfip(rx~) and the case which directly uses µgfip(rx~) without noise. Let µpficen (fpicen )

and µpfice (fpice) model with and

denote the corresponding mean (standard deviation) of the without noise respectively. We find that both µpfice - µpficen

PCE and

fpice - fpicen

with

·

=1
Ntest

Ntest k=1

(·)2

are negligibly small. For a spe-

Robust Optimisation of CFPCR

13

(a) At point (0.5, 0.5) and fp1gr (0.5, 0.5) = 4.9814 × 10-5.

(b) At point (1, 0) and fp1gr (1, 0) = 9.9812 × 10-5.

(c) At point (0.5, 0.5) and fp2gr (0.5, 0.5) = 4.9814 × 10-5.

(d) At point (1, 1) and fp2gr (1, 1) = 9.9805 × 10-5.

Fig. 8: Error propagation using the PCE method at different points for six cases of random noise
in each figures.

cific random noise, we have µpf1ce - µpf1cen = 5.7263 × 10-7, µpf2ce - µpf2cen = 5.6831 × 10-7, fp1ce - fp1cen = 4.5739 × 10-7 and fp2ce - fp2cen = 4.5521 × 10-7. Therefore, we shall neglect the uncertainty of the GPR model and use its mean as a deterministic surrogate model in the following sections.

4.2.2 Noise propagation and response surface with confidence region
We can now use the 3rd order polynomial, the mean of the GPR model, and propagate the input errors to the outputs and create a probabilistic surrogate model, which incorporates the uncertainty from manufacturing process. The response surfaces with a 95% (two standard deviation) confidence region are plotted in Figure 10, from which it can be seen that the input error is amplified where the response surface is steep. This is consistent with analysis using Taylor expansions. We also notice that the second design variable x2 has less influence on objective f1 as shown in Figure 10: f1(x1, x2) is almost constant for the same x2, and the two design variables have almost equal influences on objective f2: f2(x1, x2) is visually

14

Yongxing Wang et al.

Fig. 9: The ratio of the standard deviation of the GPR model to the standard deviation of the
PCE model.
symmetric along x1 = x2. We plot in Figure 11 the projection of this mean surface of f1(x1, x2) to x1 = 0 with a confidence interval for increased clarity.

Fig. 10: Response surfaces with 95% confidence region using the PCE method to propagate an
error of 5% (of the maximum: 1 in the normalised space, and 0.5 for Wc and 0.15 for Hc in the physical space) from the input to the output.

4.3 Robust optimisation

The probabilistic surrogate model is now used to solve the following three robust optimisation problem.

Problem 1 Given the probabilistic models f1(x) and f2(x),

minimize
x0
subject to

µ(x) =: µpf1c(ex) + (1 - )µpf2c(ex), fp1c(ex) < 1, fp2c(ex) < 2.

(17)

Robust Optimisation of CFPCR

15

Fig. 11: Response surfaces projected to x1 = 0 with 95% confidence interval.

with   [0, 1].

The Pareto curve p() =

µpf1c(ex()), µpf2c(ex())

with x() = argminµ(x) is
x0

plotted in Figure 12 (a) for four different constrained cases and one unconstrained

case. First, we observe that the Pareto curve is pushed away from the origin

as the constraints equally become more stringent, noting also this has a greater influence on the second objective µpf2ce. Consequently, the corresponding optimal design space is pushed away form the boundaries of the original design space 0

as shown in Figure 12(b). Secondly, the marked points in Figure 12 indicate a compromise minimisation between the two objectives µpf1ce and µpf2ce, where both
objectives achieve a minimum of around 0.2 (328.096P a for pressure drop and 13.554C for the temperature deviation in the physical space) with corresponding

 = 0.45 in (17). The optimal design point (0, 0.4484) as shown in Figure 12(b) has

95% confidence intervals (0.166, 0.237) = 0.2015 ± 0.071 for f1 and (0.158, 0.247) =

0.2025 ± 0.089 for f2 as indicated by the marked points in Figure 11. Thirdly, if

16

Yongxing Wang et al.

want to shrink the confidence intervals so that our prediction is more robust, such

as with a 95% confidence interval of ±0.04 (standard deviation of 0.02) for both

objectives, we can move from point (0.1991, 0.2019) on the blue curve in Figure

r(t1uhe2dna(autc)hcweatenoµgwpfte1chodeue)(lµdgarpfnbe2cdeee)n0,a.cbt3huleerfovtlreoesµwaspfciw2cthehei.ewtvWheoeeuthlsbdaarmtireeoefldbyuµjcepfse1ccuetmµ.ivpfIme2cn,eawtr(hiµhsipfeis1ccehac)asis­sfeo,mnllowoowwveisana:rrgotehufrmenodmomr0eoo.r2nceoefnwoerfiendµdcepfant1cnoet

other on each curve in Figure 12 (a); the more confident we are in the reduction

of µpf1ce (moving curve at a fixed in µpf2ce. We can

from the blue curve across the green one, and towards the purple µpf1ce in Figure 12(a)), the less confident we are in the reduction achieve this by keeping the second design variable constant and

increasing only the first design variable as shown in 12 (b). The reason we can

do this is because the response surface for f1 is almost constant for a fixed x2 as

shown in Figure 10.

(a) Pareto curve.

(b) Opimal design space.

Fig. 12: Pareto curve p() and the corresponding designs for different cases of constraints.

We test another case of constraints in Figure 13, where the upper bound of fp1ce varies while the upper bound of fp2ce stays the same. It can be seen from Figure 13 that the first parameter x1 of the optimal designs is almost unchanged while the second one x2 varies rapidly as the upper bound of 1 varies. This is different in the first test case shown in Figure 12 where the main variation of the
optimal designs lies in the first parameter x1.

Problem 2 Given the probabilistic models f1(x) and f2(x),

minimize
x0
subject to

fw(x) =: µf2(x) + 2f2(x), µf1(x) + 2f1(x) < f¯1.

(18)

The objective function fw(x) in Problem 2 defines the"worst case" for f2 with 95% confidence, and a minimisation of fw(x) given a safe (95% confidence) up-

Robust Optimisation of CFPCR

17

(c) Pareto curve.

(d) Opimal design space.

Fig. 13: Pareto curve p() and the corresponding designs for different cases of constraints.

per

bound

f¯1

for

f1.

We

plot,

in

Figure

14,

fw

=

min f(x1, x2)
x0

and

(x1, x2)

=

argminf(x1, x2) as functions of f¯1, i.e.: fw f¯1 , x1 f¯1 and x2 f¯1 . It can be

x0

seen from Figure 14 that minimising fw is always accompanied with an increasing

upper bound f¯1. The meaning of the marked points (which correspond to the same

points in the design space) shown in Figure 14 is: we can reduce fw to fw = 0.2418

by choosing x1 = x1 = 0 and x2 = x2 = 0.4354, at the same time we also have

95% confidence that f1 < 0.2424.

Problem 3 Given the probabilistic models f1(x) and f2(x),

minimize
x0
subject to

fw(x) =: µf1(x) + 2f1(x), µf2(x) + 2f2(x) < f¯2.

(19)

Similar to Problem 2, Problem 3 can be interpreted as minimising the "worst
case" of f1 given a stringent (95% guaranteed) constraint for f2. It can be seen from Figure 15 that we can reduce f1, with 95% confidence, to fw = 0.2414 by choosing x1 = x1 = 0 and x2 = x2 = 0.4367, at the same time we also have 95% confidence that f2 < 0.2424. This is consistent with the result obtained by solving
Problem 2.

5 Conclusion
PCR systems provide effective methods for rapid diagnosis of infectious diseases and are playing a vital role in the public health response to COVID-19. Thermal flows in PCR systems presents complex, multi-objective optimisation problems which need to account for uncertainties caused by manufacturing errors as well as variations in flow rate and heat flux. This paper demonstrates that combining

18

Yongxing Wang et al.

Fig. 14: Solution of Problem 2 as a function of upper bound f¯1.

Fig. 15: Solution of Problem 3 as a function of upper bound f¯2.
accurate conjugate heat transfer simulations with Gaussian Process Regression (GPR) and Polynomial Chaos Expansions (PCE) can create an efficient probabilistic surrogate model for the robust optimisation of CFPCR systems with respect to temperature uniformity and pressure drop. The methodology can be extended to incorporate other important PCR objectives such as maximising the DNA amplification efficiency or minimising heating power requirements. This approach is relatively easy to implement using the existing free libraries GPy, ChaosPy and SciPy.

Robust Optimisation of CFPCR

19

The three different robust design optimisation formulations considered result in a series of Pareto fronts of non-dominated solutions which vary depending on the relative importance of the standard deviation to mean performance. These provide a convenient means of balancing competing objectives and demonstrate how the inclusion of robustness requirements, where the standard deviation and mean of objectives must be accounted for simultaneously, leads to increased design conservatism and reductions in performance compared to deterministic design optima. This study will be extended to consider other sources on uncertainty in PCR design, for example due to flow and thermal operating conditions.

Conflicts of interest
On behalf of all authors, the corresponding author states that there is no conflict of interest.

Replication of results
All the Python code of implementing the numerical tests in this paper are attached to the following appendices of this paper.

A Python code for testing the convergence of PCE method and its
validation
In this appendix, we present the Python code for testing the PCE method's convergence in terms of the order of the orthogonal polynomial basis. We also validate the PCE by combination of two normal distributions, and compare its efficiency against the Monte Carlo method.
1 import numpy as np 2 import chaospy as cp 3 import pandas as pd 4 import GPy 5 ################### 6 dim_in=2 7 dim_out=2 8 dim=dim_in+dim_out 9 ################### 10 pd . set_option ( ' precision ' ,16) 11 data = pd . read_csv ( ' train . txt ' , header = None ) 12 13 x = data . iloc [: , 0: dim_in ]. values 14 y = data . iloc [: , dim_in : dim ]. values 15 16 rbf = GPy . kern . RBF ( input_dim = dim_in , variance =1 , lengthscale =1) 17 gp = GPy . models . GPRegression (x , y , rbf ) 18 19 gp . optimize () 20 gp = GPy . models . GPRegression (x , y , rbf , noise_var =1. e -10) 21 22 c0 = cp . Normal (0.5 , 0.025) 23 c1 = cp . Normal (0.6 , 0.025) 24 25 distribution = cp . J ( c0 , c1 )

20

Yongxing Wang et al.

26

27 def pce ( poly_order ):

28

nodes ,weights = cp.generate_quadrature(poly_order ,

29

distribution ,rule="Gaussian")

30

31

x= np . transpose ( nodes )

32

y_pred , var = gp.predict(x)

33

34

f1 = y_pred [: ,0]

35

f2 = y_pred [: ,1]

36

'''

37

sd=np.sqrt(var)

38

f1 = y_pred [: ,0]

39

f2 = y_pred [: ,1]

40

for i in np.arange(np.size(f1)):

41

noise = np.random.normal(0, sd[i,0], 1)

42

f1[i] += noise

43

f2[i] += noise

44

'''

45

polynomials = cp.orth_ttr(order=poly_order ,dist=distribution)

46

47

model_approx = cp.fit_quadrature(polynomials ,nodes ,weights ,f1)

48

#model_approx = cp.fit_quadrature(polynomials ,nodes ,weights ,f2)

49

50

mean = cp.E(model_approx , distribution)

51

deviation = cp.Std(model_approx , distribution)

52

53

print("mean , deviation=",mean ,deviation)

54

55

file=open(" pce_convergence.txt","a")

56

file.write ("%.16f %.16f\n" % (mean ,deviation))

57

file . close ()

58

59 for i in np . arange (6):

60

poly_order =i +1

61

pce ( poly_order )

A.1 Linear combination of two normal distributions
We first test the PCE code using aX1 + bX2  N (aµ1 + bµ2, (a1)2 + (b2)2), given X1  N (µ1, 12) and X2  N (µ2, 22). Since this is a linear relation, the PCE code exactly computes the mean and standard deviation, using a first order basis. For example, a = b = 1, µ1 = 0.5, µ2 = 0.7, 1 = 3 and 2 = 4, the PCE model gives exact E(X1 +X2) = 1.2 and (X1 +X2) = 5 using a first order (or higher) basis, or a = 1, b = 2, µ1 = 0.3, µ2 = 0.5, 1 = 0.3 and 2 = 0.2, the PCE model gives exact E(X1 + 2X2) = 1.3 and (X1 + 2X2) = 0.5.
If we use the Monte Carlo method to compute the statistics of X1 + 2X2, a random test gives: µ = 1.2993 and  = 0.5013 using 105 samples, µ = 1.3007 and  = 0.4965 using 106 samples, and µ = 1.3282 and  = 0.5002 using 107 samples. A convergence of this sampling is shown in Figure 16, from which we can see how poorly the Monte Carlo method converges: one needs a very large number of the sampling points in order to gain an accurate approximation.

A.2 An example of non-linear function

We generate data using the following example function:

Y = sin(X1)/cos(X2) + X2X2,

(20)

Robust Optimisation of CFPCR

21

Fig. 16: Convergence of the mean (left) and standard deviation (right) as a function of the
number of sampling points.
with X1  N (µ1, 12) and X2  N (µ2, 22). For µ1 = 0.3, µ2 = 0.5, 1 = 0.3 and 2 = 0.2, the convergence of the PCE method together with the convergence of Monte Carlo method are shown in Figure 17, from which it can be seen that the PCE is much cheaper.

Fig. 17: Convergence of the mean (left) and standard deviation (right) as a function of the
polynomial order of the PCE method.
One should notice that assuming a Gaussian input (or other distribution) is the prerequisite for using the PCE method, while Monte Carlo method needs no assumption of the input variables. This is the essential reason why the PCE method is more efficient than the Monte Carlo method.
B Python code to predict on uniform grids using PCE method
1 import numpy as np 2 import chaospy as cp 3 import pandas as pd 4 import GPy 5 ################### 6 dim_in=2 7 dim_out=2

22

Yongxing Wang et al.

8 dim=dim_in+dim_out

9 ###################

10 pd . set_option ( ' precision ' ,16)

11 data = pd . read_csv ( ' train . txt ' , header = None )

12

13 x = data . iloc [: , 0: dim_in ]. values

14 y = data . iloc [: , dim_in : dim ]. values

15

16 rbf = GPy . kern . RBF ( input_dim = dim_in , variance =1 , lengthscale =1)

17 gp = GPy . models . GPRegression (x , y , rbf )

18

19 gp . optimize ()

20 gp = GPy . models . GPRegression (x , y , rbf , noise_var =1. e -10)

21

22 poly_order =4

23 def pce ( distribution ):

24

nodes ,weights = cp.generate_quadrature(poly_order ,

25

distribution ,rule="Gaussian")

26

27

y_pred , var = gp.predict(np.transpose(nodes))

28

29

f1 = y_pred [: ,0]

30

f2 = y_pred [: ,1]

31

32

polynomials = cp.orth_ttr(order=poly_order ,dist=distribution)

33

34

model_approx = cp.fit_quadrature(polynomials ,nodes ,weights ,f1)

35

#model_approx = cp.fit_quadrature(polynomials ,nodes ,weights ,f2)

36

37

mean = cp.E(model_approx , distribution)

38

deviation = cp.Std(model_approx , distribution)

39

40

print("mean , deviation=",mean ,deviation)

41

42

file=open(" pce_predict.txt","a")

43

file.write ("%.16f %.16f\n" % (mean ,deviation))

44

file . close ()

45

46 xset = np . linspace (0 , 1 , 100)

47 yset = np . linspace (0 , 1 , 100)

48 for xm in xset :

49

for ym in yset:

50

c0 = cp.Normal(xm , 0.025)

51

c1 = cp.Normal(ym , 0.025)

52

distribution = cp.J(c0 ,c1)

53

pce ( distribution )

C Python code for optimisation based up the PCE model

We only provide in this section the Python code for solving Problem 1, which is also a template for Problems 2 and 3.
1 import numpy as np 2 import pandas as pd 3 import GPy 4 from scipy.optimize import minimize 5 ################### 6 dim_in=2 7 dim_out=4 8 dim=dim_in+dim_out 9 ###################

Robust Optimisation of CFPCR

23

10 def gpr ( x ):

11

x=x. reshape (1 , len (x ))

12

yp = gp.predict(x)[0]

13

return yp[0,0]*omega+yp[0,1]*(1.-omega)

14 def gpr_mean ( x ):

15

x=x. reshape (1 , len (x ))

16

yp = gp.predict(x)[0]

17

return [yp[0,0],yp[0,1]]

18 def gpr_sigma ( x ):

19

x=x. reshape (1 , len (x ))

20

yp = gp.predict(x)[0]

21

return [yp[0,2],yp[0,3]]

22

23 pd . set_option ( ' precision ' ,16)

24 data = pd . read_csv ( ' pce_predict . txt ' , header = None )

25

26 x_train = data . iloc [: , 0: dim_in ]. values

27 y_train = data . iloc [: , dim_in : dim ]. values

28

29 rbf = GPy . kern . RBF ( input_dim = dim_in , variance =1 , lengthscale =1)

30 gp = GPy . models . GPRegression ( x_train , y_train , rbf )

31

32 ''' Run optimization '''

33 gp . optimize ()

34

35 ''' Obtain optimized kernel parameters '''

36 noise = gp . Gaussian _noise . variance

37 print (" optimized noise : \ n " , noise [0])

38 l = gp . rbf . lengthscale . values

39 sigma_f = np . sqrt ( gp . rbf . variance . values )

40 print (" optimized kernel parameters : \ n " ,l , sigma_f )

41

42 rbf = GPy . kern . RBF ( input_dim = dim_in , variance = sigma_f **2 ,

43 lengthscale = l )

44 ''' Fix the noise variance to known value '''

45 gp . Gauss ian_noi se . variance = noise

46 gp . Gauss ian_noi se . variance . fix ()

47 gp = GPy . models . GPRegression ( x_train , y_train , rbf )

48

49 x0 =[0.5 ,0.5]

50 bb =((0 ,1) ,(0 ,1))

51 sigma1 =0.08

52 sigma2 =0.02

53

54 from scipy . optimize import N o n l i n ea r C o n s t r a in t

55 n o n l i n e a r _ c o n s t r a i n t = N o n l i n e ar C o n s t r a i nt ( gpr_sigma ,

56 [ - np . inf , - np . inf ] , [ sigma1 , sigma2 ])

57

58 OmegaSet = np . linspace (0 , 1 , 100)

59 f = open (" pareto . txt " ," w +")

60 for omega in OmegaSet :

61

#res=minimize(gpr , x0 , bounds=bb})

62

res = minimize(gpr , x0 , method='trust -constr ',

63

constraints=[ nonlinear_constraint],

64

options={'xtol ': 1e-12,'verbose ': 1}, bounds=bb)

65

print('minimum:', omega , res.x, res.fun ,'\n')

66

mean=gpr_mean(res.x)

67

f.write("%.10f %.10f %.10f %.10f\n" %

68

(res.x[0],res.x[1],mean[0],mean [1]))

69

24 70 f . close ()

Yongxing Wang et al.

References
1. Agarwal, G., Kazior, T., Kenny, T., Weinstein, D.: Modeling and analysis for thermal management in gallium nitride HEMTs using microfluidic cooling. Journal of Electronic Packaging 139(1) (2017)
2. Al-Asadi, M.T., Alkasmoul, F.S., Wilson, M.C.: Benefits of spanwise gaps in cylindrical vortex generators for conjugate heat transfer enhancement in micro-channels. Applied Thermal Engineering 130, 571­586 (2018)
3. Aziz, I., Jamshaid, R., Zaidiand, T., Akhtar, I.: Numerical simulation of heat transfer to optimize DNA amplification in polymerase chain reaction. In: 2016 13th International Bhurban Conference on Applied Sciences and Technology (IBCAST), pp. 456­462. IEEE (2016)
4. Bergman, T.L., Incropera, F.P., DeWitt, D.P., Lavine, A.S.: Fundamentals of heat and mass transfer. John Wiley & Sons (2011)
5. Beyer, H.G., Sendhoff, B.: Robust optimization­a comprehensive survey. Computer Methods in Applied Mechanics and Engineering 196(33-34), 3190­3218 (2007)
6. Beyreuther, M., Barsch, R., Krischer, L., Megies, T., Behr, Y., Wassermann, J.: Obspy: A python toolbox for seismology. Seismological Research Letters 81(3), 530­533 (2010)
7. Bodla, K.K., Murthy, J.Y., Garimella, S.V.: Optimization under uncertainty applied to heat sink design. Journal of Heat Transfer 135(1) (2013)
8. Cavazutti, M.: Optimization methods: from theory to design (2013) 9. Chen, P.C., Nikitopoulos, D.E., Soper, S.A., Murphy, M.C.: Temperature distribution
effects on micro-cfpcr performance. Biomedical Microdevices 10(2), 141­152 (2008) 10. Chiu, D.T., deMello, A.J., Di Carlo, D., Doyle, P.S., Hansen, C., Maceiczyk, R.M., Woot-
ton, R.C.: Small but perfectly formed? successes, challenges, and opportunities for microfluidics in the chemical and biological sciences. Chem 2(2), 201­223 (2017) 11. Domingo, D., Malmierca-Vallet, I., Sime, L., Voss, J., Capron, E.: Using ice cores and gaussian process emulation to recover changes in the greenland ice sheet during the last interglacial. Journal of Geophysical Research: Earth Surface 125(5), e2019JF005237 (2020) 12. Duryodhan, V., Singh, A., Singh, S.G., Agrawal, A.: A simple and novel way of maintaining constant wall temperature in microdevices. Scientific Reports 6, 18230 (2016) 13. Feinberg, J., Langtangen, H.P.: Chaospy: An open source tool for designing methods of uncertainty quantification. Journal of Computational Science 11, 46­57 (2015) 14. Gao, W., Karbasi, M., Hasanipanah, M., Zhang, X., Guo, J.: Developing GPR model for forecasting the rock fragmentation in surface mines. Engineering with Computers 34(2), 339­345 (2018) 15. Gilkeson, C., Toropov, V., Thompson, H., Wilson, M., Foxley, N., Gaskell, P.: Multiobjective aerodynamic shape optimization of small livestock trailers. Engineering Optimization 45(11), 1309­1330 (2013) 16. Haftka, R.T., Villanueva, D., Chaudhuri, A.: Parallel surrogate-assisted global optimization with expensive functions­a survey. Structural and Multidisciplinary Optimization 54(1), 3­13 (2016) 17. Hamad, H.S., Kapur, N., Khatir, Z., Querin, O., Thompson, H.M., Wang, Y., Wilson, M.: Computational fluid dynamics analysis and optimisation of polymerase chain reaction thermal flow systems. Applied Thermal Engineering 183, 116122 (2021) 18. Hashimoto, M., Chen, P.C., Mitchell, M.W., Nikitopoulos, D.E., Soper, S.A., Murphy, M.C.: Rapid PCR in a continuous flow device. Lab on a Chip 4(6), 638­645 (2004) 19. Hensman, J., Fusi, N., Andrade, R., Durrande, N., Saul, A., Zwiessele, M., Lawrence, N.: Gpy: A gaussian process framework in python (2012) 20. Hopfe, C.J., Emmerich, M.T., Marijt, R., Hensen, J.: Robust multi-criteria design optimisation in building design. Proceedings of Building Simulation and Optimization, Loughborough, UK pp. 118­125 (2012) 21. Khatir, Z., Thompson, H.: Cfd-enabled design optimisation of industrial flows-theory and practice. International Journal of Computational Fluid Dynamics 33(6-7), 235­236 (2019) 22. Leng, C., Wang, X.D., Wang, T.H., Yan, W.M.: Multi-parameter optimization of flow and heat transfer for a novel double-layered microchannel heat sink. International Journal of Heat and Mass Transfer 84, 359­369 (2015)

Robust Optimisation of CFPCR

25

23. Li, W., Gao, L., Garg, A., Xiao, M.: Multidisciplinary robust design optimization considering parameter and metamodeling uncertainties. Engineering with Computers pp. 1­18 (2020)
24. Lopez, R.H., de Cursi, J.E.S., Lemosse, D.: Approximating the probability density function of the optimal point of an optimization problem. Engineering Optimization 43(3), 281­303 (2011)
25. McGibbon, R.T., Herna´ndez, C.X., Harrigan, M.P., Kearnes, S., Sultan, M.M., Jastrzebski, S., Husic, B.E., Pande, V.S.: Osprey: Hyperparameter optimization for machine learning. Journal of Open Source Software 1, 34 (2016)
26. Moschou, D., Vourdas, N., Kokkoris, G., Papadakis, G., Parthenios, J., Chatzandroulis, S., Tserepi, A.: All-plastic, low-power, disposable, continuous-flow PCR chip with integrated microheaters for rapid DNA amplification. Sensors and Actuators B: Chemical 199, 470­ 478 (2014)
27. Nhu, V.H., Samui, P., Kumar, D., Singh, A., Hoang, N.D., Bui, D.T.: Advanced soft computing techniques for predicting soil compression coefficient in engineering project: a comparative study. Engineering with Computers pp. 1­12 (2019)
28. Papadopoulos, V.E., Kokkoris, G., Kefala, I.N., Tserepi, A.: Comparison of continuousflow and static-chamber µpcr devices through a computational study: the potential of flexible polymeric substrates. Microfluidics and Nanofluidics 19(4), 867­882 (2015)
29. Park, J., Park, H.: Thermal cycling characteristics of a 3d-printed serpentine microchannel for DNA amplification by polymerase chain reaction. Sensors and Actuators A: Physical 268, 183­187 (2017)
30. Ramadhan, A.A., Kapur, N., Summers, J.L., Thompson, H.M.: Numerical analysis and optimization of miniature electrohydrodynamic air blowers. IEEE Transactions on Plasma Science 45(11), 3007­3018 (2017)
31. Sacks, J., Welch, W.J., Mitchell, T.J., Wynn, H.P.: Design and analysis of computer experiments. Statistical Science pp. 409­423 (1989)
32. Schaerli, Y., Wootton, R.C., Robinson, T., Stein, V., Dunsby, C., Neil, M.A., French, P.M., DeMello, A.J., Abell, C., Hollfelder, F.: Continuous-flow polymerase chain reaction of single-copy DNA in microfluidic microdroplets. Analytical chemistry 81(1), 302­306 (2009)
33. Schevenels, M., Lazarov, B.S., Sigmund, O.: Robust topology optimization accounting for spatially varying manufacturing errors. Computer Methods in Applied Mechanics and Engineering 200(49-52), 3613­3627 (2011)
34. Shahpar, S.: Challenges to overcome for routine usage of automatic optimisation in the propulsion industry. Aeronautical Journal 115(1172), 615 (2011)
35. Simpson, T., Toropov, V., Balabanov, V., Viana, F.: Design and analysis of computer experiments in multidisciplinary design optimization: a review of how far we have come-or not. In: 12th AIAA/ISSMO Multidisciplinary Analysis and Optimization Conference, p. 5802 (2008)
36. Stroock, A.D., Dertinger, S.K., Ajdari, A., Mezi´c, I., Stone, H.A., Whitesides, G.M.: Chaotic mixer for microchannels. Science 295(5555), 647­651 (2002)
37. Sudret, B.: Polynomial chaos expansions and stochastic finite element methods. Risk and Reliability in Geotechnical Engineering pp. 265­300 (2015)
38. Taguchi, G.: Introduction to quality engineering: designing quality into products and processes (1986)
39. Tang, Y., Chen, J.: Robust design of sheet metal forming process based on adaptive importance sampling. Structural and Multidisciplinary Optimization 39(5), 531 (2009)
40. Tarn, M.D., Sikora, S.N., Porter, G.C., O'Sullivan, D., Adams, M., Whale, T.F., Harrison, A.D., Vergara-Temprado, J., Wilson, T.W., Shim, J.u., et al.: The study of atmospheric icenucleating particles via microfluidically generated droplets. Microfluidics and Nanofluidics 22(5), 52 (2018)
41. Thomas, S., Orozco, R.L., Ameel, T.: Thermal gradient continuous-flow pcr: a guide to design. Microfluidics and Nanofluidics 17(6), 1039­1051 (2014)
42. Wang, R., Work, D.: Application of robust optimization in matrix-based lci for decision making under uncertainty. The International Journal of Life Cycle Assessment 19(5), 1110­1118 (2014)
43. Williams, C.K., Rasmussen, C.E.: Gaussian processes for machine learning, vol. 2. MIT press Cambridge, MA (2006)
44. Yang, S., Xiong, F., Wang, F.: Polynomial chaos expansion for probabilistic uncertainty propagation. Uncertainty Quantification and Model Calibration (2017)

26

Yongxing Wang et al.

45. Zhang, X., Jaluria, Y.: Reliability-based optimization and design limits of microchannel cooling systems. International Journal of Heat and Mass Transfer 149, 119202 (2020)
46. Zhao, J., Huang, S., Gong, L., Huang, Z.: Numerical study and optimizing on micro square pin-fin heat sink for electronic cooling. Applied Thermal Engineering 93, 1347­1359 (2016)

