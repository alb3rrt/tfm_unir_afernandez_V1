arXiv:2106.00121v1 [math.PR] 31 May 2021

Many-server asymptotics for Join-the-Shortest Queue in the Super-Halfin-Whitt Scaling Window
Zhisheng Zhao1, Sayan Banerjee2, Debankur Mukherjee3
June 2, 2021
Abstract The Join-the-Shortest Queue (JSQ) policy is a classical benchmark for the performance of many-server queueing systems due to its strong optimality properties. While the exact analysis of the JSQ policy is an open question to date, even under Markovian assumption on the service requirements, recently, there has been a significant progress in understanding its manyserver asymptotic behavior since the work of Eschenfeldt and Gamarnik (Math. Oper. Res. 43 (2018) 867­886). In this paper, we analyze the many-server limits of the JSQ policy in the super-Halfin-Whitt scaling window when load per server N scales with the system size N as limN N(1 - N ) =  for   (1/2, 1) and  > 0. We establish that the centered and scaled total queue length process converges to a certain Bessel process with negative drift and the associated centered and scaled steady-state total queue length, indexed by N, converges to a Gamma(2, ) distribution. Both the transient and steady-state limit laws are universal in the sense that they do not depend on the value of the scaling parameter , and exhibit fundamentally different qualitative behavior from both the Halfin-Whitt regime ( = 1/2) and the Non-degenerate Slowdown (NDS) regime ( = 1).
1 Introduction
1.1 Background and motivation
A canonical setup for parallel-server systems consists of N identical servers, each with a dedicated queue. Tasks arrive into the system as a Poisson process of rate (N) and must be assigned
1Georgia Institute of Technology, Email: zzhao388@gatech.edu 2University of North Carolina at Chapel Hill, Email: sayan@email.unc.edu 3Georgia Institute of Technology, Email: debankur@gatech.edu 2010 Mathematics Subject Classification. Primary: 60K25; 60J60, Secondary: 60K05; 60H20. Keywords and phrases. super-Halfin-Whitt, Join-the-Shortest Queue, diffusion limit, steady state analysis, regenerative process
1

to one of the queues instantaneously upon arrival, where they wait until executed. Tasks are as-

sumed to have unit-mean exponentially distributed service times, and the service discipline at

each server is oblivious to the actual service requirements (viz., FCFS). The Join-the-Shortest

Queue (JSQ) policy for many-server systems has been a classical quantity of interest and has

served as a benchmark for the quality of performance of task assignment policies. In the above

setup, JSQ exhibits several strong optimality properties among the class of all non-anticipative

task-assignment policies [8, 30]. In particular, it minimizes the joint queue length vector (in

a stochastic majorization sense) and stochastically minimizes the total number of tasks in the

system, and hence the mean overall delay.

While the exact analysis of the JSQ policy is intractable, the research community has made

significant progress in understanding its behavior in various asymptotic regimes, primarily when

the system is close to the boundary of its capacity region, that is, when the load per server

approaches its service capacity. The capacity region of the JSQ policy for the above homogeneous

system of N servers consists of the arrival rates (N) < N. Denote  = N - (N). In the

conventional heavy-traffic regime, for a fixed N, the behavior of the queue lengths is characterized as

  0. There is a huge body of literature on this heavy-traffic analysis, which we do not attempt

to review here. Interested readers may look at [10, 11, 26, 31] and the references therein for some

of the related works. More recently, motivated by the applications in large-scale service systems,

such as data centers and cloud networks, there has been a growing interest in understanding the

behavior the JSQ policy as the number of servers N  . In that case, if the load per server

is fixed, that is, if (N) = N for some fixed   (0, 1), then asymptotically, the fluid-scaled

steady-state occupancy process becomes degenerate. Specifically, as N  , a  proportion of

servers have queue length 1 and the number of servers with queue length 2 or more vanishes [24].

The behavior becomes intricate when (N) scales with N in a way that (N)/N  1 as N  .

This is known as the many-server heavy-traffic regime. In a breakthrough work, Eschenfeldt and

Gamarnik [9] characterized the transient limit of the occupancy process in the so-called HalfinWhitt regime when (N) = N -  N for some  > 0. Since then, over the last few years, several

works have been published investigating the many-server heavy-traffic limit of the JSQ policy,

more of which we mention in Section 1.2 below.

The situation becomes more challenging when the system load is heavier than the Halfin-

Whitt

regime,

that

is,

when

N - (N)

=

O(

N

1 2

-

)

for

some





(0, 0.5).

This is known as

the super-Halfin-Whitt regime. Note that due to ergodicity of the system and the fact that the

service times are exponentially distributed with mean 1, the expected steady-state number of

busy servers equals (N), and thus, the idleness process (the process denoting the total number

of

idle

servers)

scales

as

N

1 2

-

.

However, comparing the JSQ system with the corresponding

M/M/N system, one expects that the total number of waiting tasks centered at N, scales as

N

1 2

+

.

In

other

words,

the

idle-server

process

vanishes

on

the

scale

of

the

centered

total

number

of tasks. The basic difference between the JSQ (parallel server) dynamics and the M/M/N

(centralized queue) dynamics lies in the non-idling nature of the latter. In the JSQ dynamics,

there can be idle servers in the system, while having waiting tasks. The above observation poses

an important question: does the total number of servers exhibit same asymptotic behavior as the M/M/N

2

system in the super-Halfin-Whitt regime? If not, then what is the cost of maintaining parallel queues

instead of a centralized one? In this paper, we characterize the many-server asymptotics of the

JSQ policy in the super-Halfin-Whitt regime, and answer the above questions. We discover that

even

though

the

idle-server

process

is

negligible

in

magnitude

on

the

N

1 2

+

scale,

it

evolves

on

a

faster time scale and its local time accumulated at the reflection boundary provides a non-trivial

positive drift to the total number of tasks. For this reason, asymptotically, the centered and

scaled total number of tasks in steady state is distributed as sum of two independent exponential

random variables for the JSQ policy, as opposed to a single exponential random variable in the

M/M/N case. Moreover, both the steady state and process-level limiting behavior are universal

in the sense that they do not depend on   (0, 0.5) and are fundamentally different from what

have been observed in the Halfin-Whitt regime ( = 0) and the Non-degenerate Slowdown (NDS)

regime ( = 0.5).

1.2 Literature review

The literature on the performance analysis of the JSQ policy can be broadly categorized into two

groups: (1) Many-server heavy-traffic regime: When the number of servers, N, tends to infinity and

the relative load per server for the N-th system, (N)/N, tends to 1 as N  . (2) Conventional

heavy-traffic regime: When the number of servers is fixed and the load per server  tends to 1.

Although the focus of the current work lies in the former regime, we will discuss that the two

regimes share some commonality in performance if (N)/N, approaches 1 at a sufficiently fast

rate.

In the subcritical regime, when (N) = N for some   (0, 1), Mukherjee et al. [24] char-

acterized the transient and stationary behavior of the fluid limit for the JSQ policy using the

time-scale separation technique by Hunt and Kurtz [13]. The study of the many-server heavy

traffic regime gained momentum since the seminal work by Eschenfeldt and Gamarnik [9]. Here,

the authors considered the limit of the system occupancy process (Q1(N)(t), Q2(N)(t), . . .), where

Q(i N)(t) is the number ically, if Q3(N)(0) = 0,

of servers with queue length i then uniformly on any finite

otirmlaerginetreirnvathl,e(N(N-th-sQys1(tNe)m)/at Ntim, Qe2(tN. )S/pecNif)-

converges weakly to a certain two-dimensional reflected Ornstein-Uhlenbeck (OU) process with

singular noise. This convergence has been extended to steady state by Braverman [6] using a so-

phisticated generator expansion framework via the Stein's method, enabling the interchange of

N   and t   limits. Subsequently, the tail and bulk behavior of the stationary distribution

of the limiting diffusion have been studied by Banerjee and Mukherjee [3, 4], although an explicit

characterization of the stationary distribution is yet unknown. Convergence to the above OU pro-

cess has been extended for a class of power-of-d policies in [24] and for the Join-Idle-Queue policy

in [23].

In

the

sub-Halfin-Whitt

regime,

when

N

- (N)

=

O(

N

1 2

+

)

for

some





(0, 0.5),

Liu

and

Ying [19] considered a general class of policies, including the JSQ policy, under the assumption

that each server has a buffer size b = o(log N). They showed that in the steady state, the expected

waiting time per job is O

log N N

. As observed in [19], the results in [6, 9, 19] imply that a phase

3

transition occurs at  = 0 where the limit of the quantity log E(i=2 Q(i N)) / log N jumps from

0 for  < 0, to 1/2 for  = 0. Under the finite buffer assumption, Liu and Ying [20] further

considered

the

JSQ

policy

in

the

super-Halfin-Whitt

regime,

i.e.,

when

N

-

(N)

=

O(N

1 2

-

)

for

some   (0, 0.5). They showed that in steady state, the expected number of servers with queue

length

2

is

O(N

1 2

+

log

N)

and

with

queue

length

3

or

larger

is

o(1)

and

conjectured

that

the

true

order of E Q2(N)

should

be

N

1 2

+.

Our results confirm this conjecture as a corollary, without

having any restriction on the buffer capacity.

When N - (N) = O(1), the system load is heavier that the super-Halfin-Whitt regime.

This is known as the Non-Degenerate Slowdown (NDS) regime. The regime was introduced

by Atar [2] in the context of the M/M/N system motivated by call centers, where customers'

slowdown can be large. This regime was also considered by Maglaras et al. [21] from a revenue

maximization perspective. Gupta and Walton [12] analyzed the transient limit of the JSQ policy in

this scaling regime and proved that the total queue-length process, scaled by N, has a diffusion

limit which is similar to Bessel process with a constant drift. The interchange of t   and

N   limits in the NDS regime requires establishing the tightness of the sequence of scaled

total queue-lengths in steady state indexed by N, which is not established in [12]. However,

the results in [12], in combination with the results in the current paper that analyze the case

N

- (N)

=

O(

N

1 2

-

)

for





(0, 0.5),

hint

at

a

second

phase

transition

at



=

0.5,

where

for

all i  3, the value of Q(i N) in steady state jumps from 0 (for  < 0.5) to O(N) (for  = 0.5). In

fact, if we pretend that the interchange of limits holds for the NDS regime, then the steady-state

maximum queue length distribution has an exponential tail [12, Theorem 1], whereas for  < 0.5,

it's value is 2 with probability tending to 1 as N  .

Recently, Hurtado-Lange and Maguluri [14, 15] considered a class of power-of-d policies in the super-slowdown regime, where N - (N) = O(N1-) for some  > 1 and established state-space collapse results. In this regime, the average queue length at each server scales as N-1, which

grows with N. For the JSQ policy, the results in [14, 15] imply the total queue length in steady

state, scaled by N, converges in distribution to an exponential random variable with mean 1 as

N  , when  > 2. To the best of our knowledge, this is the first heavy-traffic scaling window

where the conventional heavy-traffic behavior coincides with the many-server heavy-traffic. For

a general many-server heavy-traffic regime ((N)/N  1), Budhiraja et al. [7] established a large

deviation principle for the occupancy process which states that for large N and T, starting from

the

state

Q1(N)(0)

=

N

and

Q(j N)(0)

=

0

for

all

j



2,

P(sup0tT

Q(i N)(t)



1)



exp(-

N

(i-2)2 4T

)

for i  3. The works in various regimes mentioned above, have been summarized in Table 1,

which is an expanded version of the one presented in [14] (associated notations are described in

Section 1.4). Also, see [28] for a recent survey on load balancing algorithms and their performance

in various asymptotic regimes.

1.3 Our contributions
In this paper, we obtain the diffusion limit for the centered and scaled total number of tasks in the system S(N)(t) = i=1 Q(i N)(t) under the super-Halfin-Whitt regime and characterize the

4

Value of  Regime

0 Meanfield

(0,

1 2

)

Sub-Halfin-Whitt

1 2

Halfin-Whitt

(

1 2

,

1)

Super-HalfinWhitt

Asymptotic behavior

Q1(N)

=

NN

±

 P( NN ),

Q(i N) = oP(1) for i  2

bi=1

Q(i N)

=

NN

+

 OP( N

log

N)

Q1(N)

=

N

-

 P( N),

Q2(N)

=

 ( N),

Q(i N) = oP(1) for i  3

Q1(N) = N - (N1-), Q2(N) = P(N), Q(i N) = oP(1) for i  3

References [24] [19] [3, 4, 6, 9] [20], current paper

1

Non-Degenerate Slowdown (NDS)

Qi = P(N) for all i  1

[12]

(1, ) Super Slowdown

Unknown for   (1, 2]. For  > 2, i=1 Q(i N) = P N

[14, 15]

Table

1:

Analysis

of

JSQ

in

various

regimes:

Load

per

server

is

N

=

1-

 N

with





(0, 1)

for

 = 0 and  > 0 for  > 0. The random variables in the third column are steady state random

variables. b  [1, ) denotes the buffer size, when it is assumed to be finite.

limit of its stationary distribution as N  . Specifically, we assume that the total arrival rate is

(N)

=

N

-

N

1 2

-

for





(0,

0.5)

and

the

service

times

are

exponentially

distributed

with

mean

1. Our main contributions are two-fold:

(a) Process-level convergence.

In

Theorem

2.4,

we

show

that

X(N)(t)

=

N-(

1 2

+)

(S(

N

)

(

N

2

t)

-

N) converges to a certain Bessel process with negative drift, uniformly on compact intervals.

Since the difference between the total arrival

rate and the maximum

departure rate is O

N

1 2

-

and

S(N)(t)

is

scaled

by

N

1 2

+,

we

needed

the

time-scaling

of

N2

to

obtain

the

process-level

convergence. From a high-level perspective, we follow the same broad approach used in [12]

to prove the transient limit result. However, our technique differs significantly in several places

as some of the estimates in [12] only apply for  values close to 0.5, but we need estimates that

uniformly apply for   (0, 0.5) (for example, the proof of Lemma A.9 requires the estimate

(A.36)).

The key challenge in establishing the diffusion limit is to obtain precise asymptotics of the fol-

lowing

integral

of

the

idleness

process

I(N)(·)

(which

equals

N

- Q1(N)(·)):

N

-(

1 2

+)

N 2 t 0

I(N)(s)ds

uniformly for t in an appropriate (random) compact interval. As it turns out, starting from suit-

able

states,

the

process

I(N)

is

negligible

in

magnitude,

on

the

scale

N

1 2

+

(Lemma

5.1).

However,

the above integral is not negligible. In fact, we show that it is asymptotically close to

t 0

X(

1
N)

(s)

ds

5

(Proposition 5.5). The proof relies on the fact that I(N)(t) evolves on a faster time scale compared

to X(N) and achieves a local stationarity for any fixed value of X(N). The (local) steady-state ex-

pectation

of

I(N)(s)

is

approximately

1 X(N)

(s)

.

Other

parts

of

the

evolution

equation

of

the

limiting

diffusion in Theorem 2.4 are obtained by standard martingale decomposition and their conver-

gence. We then show that this limiting process is ergodic and has Gamma(2, ) as the unique

stationary distribution (Proposition 2.5).

(b) Tightness of the sequence of prelimit stationary distributions. The next major challenge,

proving the interchange of t   and N   limits, requires establishing the tightness of the sequence of steady-state random variables {X(N)()}N=1. This is provided by Theorem 2.7. In fact, Theorem 2.7 tells us much more about the prelimit stationary distribution than tightness. We use the theory of regenerative processes to obtain tail probability bounds on X(N)() for

all large but fixed N. More precisely, we identify renewal times along the path of the process (I(N)(·), {Q(i N)(·)}i2) and use a representation (4.24) of the stationary measure in terms of these renewal times. Tail behavior of X(N)() is then studied by carefully analyzing these renewal

times and fluctuations of the process between these times.

Two key technical steps in the renewal time analysis are to obtain sharp asymptotics for the

following: (i) starting from

D2BowNn12-+cro(sPsirnogpeosstiitmioantes3:.1T0a)i,l-wphroebreabBiliitsyabloaurgnedsfioxnedthceontismtaenQt 2(thNa) ttadkoeesstonohtitdBeNpe12n+d

on N.

(ii) Up-crossing estimates:

Tail-probability

bounds

on

the

time

Q2(N)

takes

to

hit

2B

N

1 2

+

starting

from

BN

1 2

+

(Proposition

3.12).

Analyzing the tail behavior of X(N)() for fixed large N requires very different techniques

than ones required to prove the process level convergence. First, there is no `state space collapse' in the prelimit, in the sense that one cannot directly relate the idleness process I(N)(·) to X(N)(·)

as in Proposition 5.5. Therefore, we take an excursion-theoretic approach where one performs a piece-wise analysis of excursions of the joint process (I(N)(·), {Q(i N)(·)}i2) in different parts of the state space. This, along with some novel concentration inequalities (Lemma 3.5), leads to
quantitative probability bounds on the supremum and time integral of I(N)(·) (Lemma 3.7). This

is a crucial step in proving Theorem 2.7. Second, note that, for the process level limit, one can `ignore' the contributions of Q(i N)(·)
for i  3. This is because, if Q3(N)(0) = 0, for fixed T > 0, the probability that Q3(N)(t) > 0 for any t  [0, N2T] becomes small as N   (see (A.21)). However, for fixed N, the processes {Q(i N)(·)}i3 eventually become non-zero, and for obtaining probabilistic bounds on the renewal times discussed above (eg. Proposition 4.3), one needs precise quantitative control on i=3 Q(i N)(·) (Lemma 3.9).

1.4 Notation and organization.
For a metric space S, denote by D = D([0, ), S) the space of functions from [0, ) to S that are right continuous and have left limits everywhere. For x, y  R, x  y and x  y denote

6

max(x, y) and min(x, y), respectively. x+ = max(x, 0). For a positive deterministic sequence ( f (N))N1, a sequence of random variables (X(N))N1 is said to be OP( f (N)), oP( f (N)), respectively if the sequence (X(N)/ f (N))N1 is tight, and X(N)/ f (N) -P 0, as N  . Also, (X(N))N1 is said to be P( f (N)) if it is OP( f (N)) and there is a constant c > 0 such that lim infN( f (N))-1E(X(N))  c.
Rest of the sections are organized as follows: In Section 2 we present the model, main results,
and discuss their ramifications. Section 3 contains a sample-path analysis of the process and
several hitting time estimates. These estimates will be used in Section 4 to establish the tightness
of the sequence of random variables corresponding to appropriately centred and scaled steady-
state total number of tasks, in the number of servers N. In Section 5, we prove the process-level
convergence. Proofs of some results are moved to the appendix for better readability.

2 Model Description and main results

Consider a system with N parallel single-server queues and one dispatcher. Tasks with inde-

pendent unit-mean exponentially distributed service requirements arrive at the dispatcher as a Poisson process of rate (N). Denote the per-server load by N := (N)/N. Each arriving task is assigned instantaneously and irrevocably to the shortest queue at the time of arrival. Ties are

broken arbitrarily. The service discipline at each server is oblivious to the actual service require-

ments (viz., FCFS). We will analyze the system in the so-called super-Halfin-Whitt heavy-traffic

regime, where

N

=

1

-



N

1 2

+

(2.1)

with

fixed

parameters



>

0

and





(0,

1 2

).

Our goal is to characterize the behavior of the

queue-length process as N  . At time t, S(N)(t) denotes the total number of tasks in the

system, I(N)(t) denotes the number of idle servers, and Q(i N)(t) denotes the number of servers of queue length at least i, i  1. Note that Q1(N), Q2(N), . . . provides a Markovian description of the system state and I(N) = N - Q1(N). We introduce the scaled process X(N)(t), t  0 as

X(N)(t)

:=

S(N)(N2t) -

N

1 2

+

N.

The process X(N) is not Markovian. However, we can view it as a function of the Markov process Q1(N), Q2(N), . . . . Denote by X(N)() a random variable distributed as the centered and scaled
total number of tasks in the N-th system in steady state. Our first main result below characterizes
the weak-limit of X(N)() and convergence of its moments.

Theorem 2.1. The sequence of random variables X(N)() N1 converges weakly to the Gamma(2, ) distribution as N  , where the probability density function of Gamma(2, ) is given by f (x) = 2xe-x, x  (0, ). Moreover, for any p > 0,

E

X(N)()

p



(p + 2) p

7

as N  , where  denotes the standard Gamma function.

Let W(N) be a random variable denoting the waiting time of a typical task in steady state for

the N-th system. By Little's law [17, § 6.4 (a)], note that E W(N) = NN -1 i=2 E Q(i N)() = NN -1E S(N)() + I(N)() - N . Now, since in steady state, expected total arrival rate equals

expected

total

service

rate,

we

have

E(I(N)())

=

N(1

- N)

=

N

1 2

-

.

Therefore,

we

have

the

following immediate corollary of Theorem 2.1.

Corollary 2.2.

lim

N

1 2

-

E

W(N)

= 2.

N



Remark 2.3 (Contrast with centralized systems). An interesting aspect of the many-server limit of the JSQ policy is revealed as we compare it with the corresponding M/M/N system with the same load per server. As briefly mentioned in the introduction, the key difference between the JSQ dynamics and the M/M/N dynamics lies in the non-idling nature of the latter. In the JSQ dynamics, there can be idle servers in the system, while having waiting tasks. However, as the system load becomes closer to 1, one may expect that most of the servers must remain busy to keep the system stable. Consequently, JSQ should behave similarly to the centralized queueing system. Theorem 2.1 shows that this is not the case even in the super-Halfin-Whitt regime. The centered and scaled total number of servers for JSQ converges to Gamma(2, ) with mean 2/, instead of Exponential() with mean 1/ for the corresponding M/M/N system. Interestingly, indeed, if the load is much heavier, that is, N = 1 - O(N-) with  > 2, then the result in [15] implies that the appropriately scaled total number of tasks under the JSQ policy has the same limiting distribution as the centralized system. It will be an interesting future direction to identify the precise scaling of the system load where this transition of behavior occurs.

The proof of Theorem 2.1 is given at the end of this section. We will proceed by establishing

the process-level limit, ergodicity of the limiting process, and the tightness of the random vari-

ables {X(N)()}N1. The next result states that the sequence of processes

X(N)(t), t  0

 N=1

converges weakly to the process X, uniformly on compact time intervals, where X(t), t  0 is

a certain Bessel process with negative drift.

Theorem 2.4. Assume that X(N)(0)  x0 as N  , where x0 > 0 is a constant, and that there exist

constants

K1, K2

>

0,

such

that

I(N)(0)



K1

N

1 2

-,

Q2(N)(0)



K2

N

1 2

+

,

and

Q3(N)(0)

=

0,

for

all

N  1. Then the scaled process X(N) converges weakly to the path-wise unique solution to the following

stochastic differential equation, uniformly on compact time intervals:

dX(t) =

1 X(t)

-



 dt + 2dW(t),

(2.2)

with X(0) = x0, where W = W(t), t  0 is the standard Brownian motion.
Theorem 2.4 is proved in Section 5. Observe that the SDE in (2.2) is a certain Langevin diffusion and is ergodic. Its stationary distribution can be explicitly characterized as follows.

8

Proposition 2.5. The SDE in (2.2) has a unique stationary distribution  with probability density func-

tion

d dx

=

2 xe-x ,

x

>

0,

having

p-th

moment

(p + 2)/p.

The proof of Proposition 2.5 is given in Section 5.

Remark 2.6. The limiting diffusion in (2.2) behaves like a Bessel process of dimension 2 for small values

of X and a Brownian motion with negative drift for large values of X. In particular, this diffusion almost

surely never hits zero (see Lemma 5.6). This is a consequence of the fact that the idle process in the prelimit

moves

in

scale

N

1 2

-

and

thus

vanishes

under

the scaling

N

1 2

+

appearing

in

X(N).

Moreover,

the drift

of the above diffusion process is smooth on (0, ), unlike the diffusion limit in the NDS regime [12].

This results in the stationary density of the diffusion in [12] being C1 but not C2 on (0, ), whereas our

stationary density is smooth on (0, ).

The following theorem gives tail estimates for X(N)() for all fixed large N.

Theorem 2.7. There exist positive constants N0, B, C1, C2 such that for any N  N0,

P X(N)()  x 

C1 exp C1 exp

- C2x1/5 ,

4B



x



2N

1 2

-,

- C2x1/44 ,

x



2N

1 2

-

.

Remark 2.8. The analysis of the steady-state tail behavior is based on a renewal theoretic representation of

the stationary measure. We consider the continuous time Markov process (I(N)(·), {Q(i N)(·)}i2) starting

from

(0,

2B

N

1 2

+

,

0)

for

a

suitably

large

B

>

0.

We

then

wait

for

Q2

to

fall

to



B

N

1 2

+

,

then

for

i=3

Q(i N)

to

drop

to

zero,

and

subsequently

for

Q2

to

climb

back

to

2B

N

1 2

+

.

This

(random)

time



is

a

renewal time as the process observed from time  onward has the same distribution as the one starting from

time 0. On showing that  has finite expectation, the stationary distribution admits the representation

in (4.24). Hence, obtaining tail behavior of the stationary distribution reduces to quantifying the extremal

behavior of the process path before time . We do not believe that the exponents in the tail bounds above

are optimal; however, they show that the steady-state tails are sufficiently light to have finiteness of all

moments.

Theorem 2.7 is proved in Section 4. It implies that

X(N)()

 N=1

is

tight

in

R.

By Proposi-

tion 2.5 and Theorem 2.7, the interchangeability of the t   and N   limits in Theorem 2.1

can be established using routine arguments.

Proof of Theorem 2.1. Since

X(N)()

 N=1

is tight,

any

subsequence

X(N~ )()

 N~ =1

has a con-

vergent further subsequence X(N^ )() N^ =1. Let X(N^ )() -d X^ as N^  . Now assume that

X(N^ )(0) is distributed as X(N^ )(), the steady state of the process X(N^ )(t), t  0 . Then X(N^ )(t)

is also distributed as X(N^ )(), for all t  0. Thus, by Theorem 2.4 and Proposition 2.5, X^ is the

unique stationary distribution of {X(t)}t0. This proves the weak convergence of X(N)() in R. For the convergence of p-th moment, note that X(N)()'s are nonnegative random variables

and hence,

E

X(N)()

p
=p


xp-1P(X(N)() > x)dx.

0

9

Take B, N0 as in Theorem 2.7. From the tail-probability bound in Theorem 2.7, we have that for any p > 0 and ~ > 0,

sup E

X(N)()

p+~


sup

(4B  1)p+~ + (p + ~)



xp+~-1P(X(N)() > x)dx

NN0

NN0

(4B1) 

(2.3)

 (4B  1)p+~ + (p + ~)

xp+~-1C1 exp - C2x1/44 dx < .

(4B1)

Since X(N)() -d Gamma(2, ) and (2.3) holds, by [5, Corollary of Theorem 25.12], for any p > 0, E X(N)() p  (p + 2)/p as N  .

3 Sample-path analysis of the pre-limit process

In this section, we will obtain quantitative estimates on the sample path behavior of the prelimit process that will be useful in Sections 4 and 5. Define


 Q¯ 2(N)(t) := Q(i N)(t), i=2
and, for x, y, z  0, define the stopping times


 Q¯ 3(N)(t) := Q(i N)(t). i=3

1(N)(x) := inf 2(N)(y) := inf s(N)(z) := inf

t



0

:

I(N)(t)

=



x

N

1 2

-



,

t



0

:

Q2(N)(t)

=

yN

1 2

+



,

t



0

:

S(N)(t)

=

zN

1 2

+



.

(3.1)

Also, for any B > 0, let I¯B(N) denote a birth-death process with

I¯B(N)



I¯B(N)

+

1

at

rate

N

-

B

N

1 2

+

,

I¯B(N)



( I¯B( N )

-

1)+

at

rate

N

-



N

1 2

-

,

(3.2)

where

N

is

large

enough

so

that

N

>

B

N

1 2

+

>



N

1 2

-

.

If

Q2(N)(0)

>

B

N

1 2

+,

then

observe

that there exists a natural coupling such that I(N)(t  2(N)(B))  I¯B(N)(t  2(N)(B)), for all t  0.

Define the stopping time ¯B(N)(x) := inf

t



0

:

I¯B(N)(t)

=

x

N

1 2

-



for x  0. For  > 0, let us

introduce

the

notation

E
N

1 2

-

·

:= E

· |I¯B(N)(0)

=

N

1 2

-



.

Lemma 3.1. There exists B0  1 such that for any  > 0, B  B0, N  NB, and y  [0, ),

E


N

1 2

-

exp

BN2 8

¯B(N)(y)

 e-y.

Proof.

Let us denote

I^B(N)(t) =

I¯B( N) (t)

N

1 2

-

and (N) = ¯B(N)(y).

For  > 0 to be chosen later, define

ZB(N)(t) := exp

I^B(N)(t)

+

 2

t

.

10

For t < ¯B(N)(0),

LZB( N ) (t)

=

 2

ZB(N

)(t)

+

e

 2

t

- e I^B( N)

(t)+

N

1

1 2

-

e I^B( N) (t)

N

-

BN

1 2

+

+ - eI^B(N)

(t)-

N

1

1 2

-

eI^B(N) (t)

N

-

N

1 2

-

=

 2

ZB(N

)(t)

+

1

ZB(N)

(t)

N

(e

N

1 2

-

+ e-

N

1

1 2

-

- 2)

1

+ ZB(N)(t)

-

eN

1 2

-

-1

BN

1 2

+

-

e-

N

1

1 2

-

-1



N

1 2

-

,

where L(·) is the infinitesimal generator of the associated continuous time Markov process. Fix

two constants c, a > 0, such that for all x  (-a, a), ex + e-x - 2  cx2, and note that for all x  R,

ex

-1



x.

Now,

let

NB



1

be

such

that

N-

1 2

+

<

a

and

1 2

B

N2

>



for

all

N



NB.

Then

for

all

N  NB,

LZB(N)(t  (N))



 2

ZB(N)

(t



(N)

)

+

c

N2

ZB(N)(t



(

N))

+ ZB(N)(t  (N))

-

1

eN

1 2

-

-1

BN

1 2

+

-

e-

N

1

1 2

-

-1



N

1 2

-



 2

ZB(N)

(t



(N))

+

cN2 ZB(N)(t



(N))

-

BN

N

1 2

1 2

+

-

ZB(N

)

(t



(N))

+

ZB( N ) (t



(N))



 2

ZB(N)

(t



(N)

)

+

c

N2

ZB(N)(t



(

N))

-

B

N2 2

ZB(N)(t



(N)

).

Let

B0



1

be

such

that

c-

B 2



-

B 4

,

B



B0.

Take



=

B 4

N2.

Then

LZB(N)(t  (N))



0,

t



0,

implying for all B  B0,

E


N

1 2

-

ZB(N)(t  (N))



E
N

1 2

-

ZB(N)(0)

,

t  0.

By Fatou's lemma and the observation limt ZB(N)(t  (N)) = ZB(N)((N)) a.s., we get

E


N

1 2

-

ZB( N ) (( N ) )



lim inf
t

E
N

1 2

-

ZB(N)(t  (N))



E


N

1 2

-

ZB(N)(0)

 e,

implying that

E


N

1 2

-

e

 2

¯B(N)

(y)

 e-y.

This completes the proof of the lemma.

The following elementary lemma gives a supremum bound on the path of a compensated Poisson process.

Lemma 3.2. Suppose A(·) is a Poisson process with unit rate. For any T > 0 and x  [0, 4T],

P

sup |A(s) - s|  x



2e-

x2 8T

.

s[0,T]

11

Proof. By [18, Theorem 5, Chapter 4, Page 351], for any x  0,

P sup A(s) - s  x  exp - sup x - 2T(e - 1 - ) .

s[0,T]

>0

Since e - 1 -   2, for all   [0, 1], we have for any x  [0, 4T],

sup x - 2T(e - 1 - )
>0

 sup
[0,1]

x - 2T2

=

x2 8T

.

We can perform the same calculation with -(A(s) - s) in place of (A(s) - s). This proves the lemma.

We want to estimate

t 0

I¯B(N)(s)ds

for

large

B

and

t.

We will do so by identifying certain

excursions in the path of the process I¯B(N). The integral will then be estimated by controlling the

duration of each such excursion and the supremum of the process I¯B(N) on this excursion. Let

I¯B(N)(0) = 0. Given  > 0, define the following stopping times: ¯0(N) := 0, and for i  0,

¯2(iN+)1 := inf ¯2(iN+)2 := inf

t



¯ 2(iN )

:

I¯B(N)(t)





N

1 2

-



,

t  ¯2(iN+)1 : I¯B(N)(t) 

 2

N

1 2

-

.

Henceforth, we fix  = 1  (/8) and define:

¯i(N) := ¯2(iN) - ¯2(iN-)1, i  1,

u¯(i N) :=

sup

I¯B(N

)(s)

-



N

1 2

-

,

s[¯2(iN-)1,¯2(iN) ]

K¯ t(N) := inf k : ¯2(kN)  N2t .

i  1,

The following lemma will be used to control the integral of the process I¯B(N) over the excursion interval [¯2(iN-)1, ¯2(iN)].

Lemma 3.3. Take B0 as in Lemma 3.1. There exist positive constants c¯, c1, c2, such that for any B  B0, N~ B > 0 such that for all N  N~ B,

(i)

P

u¯1(N)¯1(N) 

x

N

1 2

-3

3
B2


 c1e-c2 x,

x  0;

(ii) E u¯1(N)¯1(N)

 . c¯N

1 2

-3

3

B2

Proof. Note that

P

u¯1(N)¯1(N) 

x

N

1 2

-3

B

3 2



 P ¯1(N) 

x B

N-2





+P

u¯1(N) 



x B

N

1 2

-,

¯1(N)

<

x B

N

-2

.

(3.3)

12

By Lemma 3.1 and Markov's inequality, for B  B0, N  NB, x  0,



P ¯1(N) 

x B

N-2



 e E e -

x BN2



N

1 2

-

¯B(N)

(

 2

)


 ee- x/8,

(3.4)

where  = BN2/8 as in Lemma 3.1. Now, for s  [0, 2(N) - 1(N)),

I¯B(N) 1(N) + s

=



N

1 2

-



+

A1

(N

-

BN

1 2

+)s

- A2

(N

-

N

1 2

-)s

=



N

1 2

-



+

A^ 1

(N

-

BN

1 2

+)s

- A^ 2

(N

-

N

1 2

-)s

-

BN

1 2

+s

+

N

1 2

-s,

where A1, A2 are i.i.d. Poisson processes with unit rate and A^ i(s) = Ai(s) - s, i = 1, 2. Therefore,

choosing

N~ B



NB

such

that

x

N

1 2

-

2B



4 B x N1-2

for

all

N



N~ B,

we

obtain

for

any

N



N~ B,

x  0,





P

u¯1(N) 

x B

N

1 2

-,

¯1(N)

<

x B

N-2





=P

sup
s[0,2( N) -1( N) )

I¯B(N)(1(N)

+

s)



N

1 2

-



+

x B

N

1 2

-

,

2(N) - 1(N)

<

x N-2 B



P

sup
s[0, x/(B

N2

))

A^ 1

(

N

-

BN

1 2

+)s

- A^ 2

(N

-

N

1 2

-)s

-

B

N

1 2

+

s

+

N

1 2

-

s





x

N

1 2

-

B



P

s[0,sxu/p(BN2)) A^ 1

(

N

-

BN

1 2

+)s



- A^ 2

(N

-

N

1 2

-)s





x

N

1 2

-

B

 2P

sup

|A^ 1

s[0, x/(BN2))

Ns

|

x

N

1 2

-

2B

 4 exp

-

x 32

,

(3.5)

where

the

second

inequality

is

due

to

B

N

1 2

+

>



N

1 2

-

that

we

assumed

while

defining

I¯B(N),

and

the last inequality is due to Lemma 3.2. Plugging (3.4) and (3.5) into (3.3), we get part (i). Part

(ii) follows directly from part (i).

The next lemma gives an upper bound in probability for the number of excursions on the time interval [0, N2t] for large enough t.

Lemma

3.4.

There

exist

c~, t0

>

0

such

that

for

all

B



1,

a



256B 2

,

N



1,

and

t



t0,

P K¯ t(N)  aN4t  exp{-c~aN4t}.

Proof.

Let

Hi(N)

=

1

¯2(iN+)1 - ¯2(iN)

>

2 64B

N

-2

,i



1.

Recall

Ai,

i

=

1, 2 as defined in the proof

of Lemma 3.3. Also, define the one-dimensional Skorohod map  as follows: for any function

x : R  R having càdlàg paths, [x](t) := x(t) + sup0st max{-x(s), 0}, t  0. Also write

x(N)(s)

:=



 2

N

1 2

-



+

A^ 1

(N

-

BN

1 2

+

)s

- A^ 2

(N

-

N

1 2

-)s

-

B

N

1 2

+

s

+



N

1 2

-

s,

s



0.

13

Then, note that

P Hi(N) = 0

=P P

sup

I¯B(N) 2(iN) + s

s[0,¯ 2(iN+)1-¯ 2(iN) ]





N

1 2

-

,

¯ 2(iN+)1

- ¯2(iN)



2 32

N-2

sup



x(N)

(s)



N

1 2

-

s[0,

2 64B

N

-2

]

P

sup

s[0,

2 64B

N

-2]

x(N)(s)



 2

N

1 2

-

,

(3.6)

where, in the last step, we used the fact that sups[0,T] [x(N)](s)  2 sups[0,T] |x(N)(s)| for any

T



0.

Now,

since

B

N

1 2

+

>



N

1 2

-

as

before

and





1,

we

have

sup

x(N)(s)  sup

A^ 1

(N

-

BN

1 2

+

)s

- A^ 2

(N

-

N

1 2

-)s

s[0,

2 64B

N

-2

]

s[0,

2 64B

N

-2

]

 sup

A^ 1

(N

-

BN

1 2

+

)s

- A^ 2

(N

-

N

1 2

-)s

s[0,

2 64B

N

-2

]

+

 2

N

1 2

-

+

2 64

N

1 2

-

+

3 4

N

1 2

-.

Using this in (3.6), we obtain

P Hi(N) = 0

P

sup

A^ 1

(N

-

B

N

1 2

+

)s

- A^ 2

(N

-

N

1 2

-)s

s[0,

2 64B

N

-2

]



2(2/64B)N1-2 (2/16)N1-2



1 2

,



 4

N

1 2

-

where the last inequality follows from Doob's L2-maximal inequality and the assumption B  1.

Then,

for

a



256B 2

we

can

write

for

t



t0

sufficiently

large,

P K¯ t(N)  aN4t

atN4

  P

(¯2(iN+)1 - ¯2(iN)) < N2t

i=1

  P

atN4 Hi(N)
i=1

<

64B 2

N4

t

  P

atN4 (Hi(N)
i=1

-

E(Hi(N)))

<

64B 2

N4

t

-

1 2

  P

atN4 (Hi(N)
i=1

-

E(Hi(N)))

<

-

1 8

atN4



exp{-

c~a2 N8t2 a N4 t

}

=

exp{-c~a N4 t}

atN4

for some c~ > 0, where the last inequality above follows from Azuma's inequality.

14

The next lemma gives a concentration bound on sums of random variables with stretched exponential tails. It is used multiple times in this article, and is of independent interest.

Lemma 3.5. Suppose {(i r) : i  1, r  R} are independent nonnegative random variables adapted to a filtration Fi(r) : i  1, r  R , where R is an arbitrary indexing set. Let F0(r)  F1(r) be an arbitrary -field. Suppose there exist deterministic constants c, c1 > 0,   (0, 1) not dependent on r such that

P (i r)  x|Fi(-r)1  ce-c1x , x  0, i  1.

Define µ :=

 0

ce-c1

x

dx

 suprR E

(i r)|Fi(-r)1

, i



1.

Then there exist c2, c3

> 0, not depending

on r, such that for any a  4µ,

 sup P n (i r)  an|F0(r)
rR i=1

 c2

1

+

n1 2+
a 2+

exp

-

c3(a2n)

 2+

,

n  1.

Proof. Let ~ (i r) := (i r)1[(i r)  d] for some d > 0 that does not depend on r, to be chosen later. Then by Azuma's inequality,

 sup P
rR

n ~ (i r)
i=1



an 2

|F0(r)

  sup P rR

n (~ (i r)
i=1

- E(~ (i r)|Fi-1))



an 2

-

nµ|F0(r)

  sup P
rR

n (~ (i r)
i=1

- E(~ (i r)|Fi-1))



an 4

|F0(r)

 exp

-

a2n 32d2

.

Moreover, using Markov's inequality and the union bound

(3.7)

 sup P
rR

n ((i r) - ~ (i r))
i=1



an 2

|F0(r)

2 a

dce-c1d +


ce-c1x dx
d

 c~de-c~d , a

(3.8)

where c~ and c~

are positive constants not depending on d.

Using

(3.7) and (3.8) with d

=

(a2

n)

1 2+

,

the lemma follows upon using

   sup P
rR

n (i r)  an|F0(r)
i=1

 sup P
rR

n ~ (i r)
i=1



an 2

|F0(r)

+ sup P
rR

n ((i r)
i=1

- ~ (i r))



an 2

|F0(r)

,

and choosing appropriate constants c2 and c3.

Lemma 3.6. Take B0 as in Lemma 3.1, N~ B for B  B0 as in Lemma 3.3, and t0 as in Lemma 3.4. There exist constants c, c, c > 0, such that the following holds for all B  B0, N  N~ B, t  t0,

 P

K¯ t(N) u¯(i N)¯i(N)
i=1



c

2

B

1 2

N

1 2

+

t



c

exp{-c

B

1 5

N

4 5

t

1 5

}.

15

Proof. Write

  P

K¯ t(N) u¯(i N)¯i(N)
i=1



c



2

B

3 2

N

1 2

+

t

 P K¯ t(N)  a N4t

+P

a N4 t
u¯(i N)¯i(N) 
i=1

c



2

B

3 2

N

1 2

+

t

.

(3.9)

For

the

first

term,

we

take

a

=

256B 2

,

and

thus,

Lemma

3.4

yields

P K¯ t(N)  a N4t  exp{-c~a N4t}.

(3.10)

For the second term, define

(i N)

:=

B3/2

N

1 2

-3

u¯ (i

N)

¯i(N

)

,

i  1,

and a sequence of filtrations FN,i := {(j N) : j  i}, i  1. Then, as {(j N) : i  N} are i.i.d., from Lemma 3.3 we know for B  B0 and N  N~ B,

P (i N)  x|FN,i-1


 c1e-c2 x,

x  0.

We will use lemma takes

Lemma 3.5 the form µ

for =

the

 0

c1

random e-c2 xdx

variables {(i N) : in our case. Write

i  1, N  N}. Note that µ in c = 4µ × 256. Applying Lemma

the 3.5

with  = 1/2, n = a N4t, and a = 4µ, we get for some constants c1 , c2 > 0,

 P

a N4 t
u¯(i N)¯i(N)
i=1



c



2

B

1 2

N

1 2

+

t|FN,0

 = P

a N4 t i=1

N

1 2

-3

B

3 2

(i

N)



c



2

B

1 2

N

1 2

+

t|FN

,0

 = P

a N4 t
(i N)
i=1



c B 2

N4

t|FN,0

 c1 exp

- c2

4µ 2a N4t 1/5 .

(3.11)

Plugging the bounds from (3.10) and (3.11) into (3.9) completes the proof of the lemma for appropriately chosen constants c and c dependent on  but not B.

The following lemma gives probability bounds on the integral and supremum of the idleness process that is crucial to the stability analysis of the prelimit total queue length process.

Lemma 3.7. Assume I¯B(N)(0) = 0. There exist t0 > 0, B1  1 such that for all B  B1, N  N~ B, and t  t0, the following hold:

(i) P

N2s 0

I¯B(N)(u)du



 2

N

1 2

+

s

for

some

s



t



c1

exp{-c2

B

1 5

N

4 5

t

1 5

};

(ii) P

supst

I¯B( N ) ( N2 s)



 16

N

1 2

+

t

  exp{-c~1BN4t} + c~2N4t exp{-c~3 BN2t}.

The above constants ci, c~i may depend on , but not on B, N, t.

Proof. (i) Recall  = 1  (/8) and note that

  N2t
0

I¯B(N)(s)ds



N

1 2

+t

+

K¯ t(N)

u¯(i N)¯i(N)

i=1



 8

N

1 2

+t

+

K¯ t(N) i=1

u¯(i N)¯i(N).

(3.12)

16

Now, choose B1  B0 (from Lemma 3.1) such that

c
1

 2 B12



 8

,

where

c

is

the

constant

from

Lemma 3.6. By Lemma 3.6 and (3.12), there exist constants c1 and c2, such that for all B  B1,

t  t0, N  N~ B,

P

N 2 t 0

I¯B(N)(s)ds



 4

N

1 2

+

t

P

K¯ t(N) u¯(i N)¯i(N)
i=1



 8

N

1 2

+

t

P

K¯ t(N) u¯(i N)¯i(N)
i=1



c

2

B

1 2

N

1 2

+

t



c1

exp{-c2

B

1 5

N

4 5

t

1 5

}.

(3.13)

For any t  t0, define sk = kt, k  1. Then, for any k  1,

P

N2s 0

I¯B(N)(u)du



s 2

N

1 2

+

for

some

s



[sk, sk+1)

P

N 2 sk+1 0

I¯B(N)(u)du



sk 2

N

1 2

+

P

N 2 sk+1 0

I¯B(N)(u)du



sk+1 4

N

1 2

+



c1

exp{-c2

B

1 5

N

4 5

1
sk5+1 }.

Therefore, (i) follows on summing over k and applying the union bound.

(ii)

Write

a

=

256B 2

,

and

note

that

P

sup I¯B(N)(N2s)
st



 16

N

1 2

+

t

 P K¯ t(N)  aN4t

+P

sup u¯(i N)
1iaN4t



 16

N

1 2

+t

-



N

1 2

-

.

(3.14)

By Lemma 3.4, for t  t0,

P K¯ t(N)  aN4t  exp{-c~aN4t}.

(3.15)

Due to Equations (3.4) and (3.5), we have that for B  B0, and large enough N  N~ B,

P

sup u¯(i N)
1i a N 4 t



 16

N

1 2

+

t

-



N

1 2

-

P

sup u¯(i N)
1i a N 4 t



 32

N

1 2

+

t

aN4t · P

u¯1(N) 

 32

N

1 2

+

t

 

a a

N4 N4

t t

· ·

P u¯1(N)  c0 exp{-c0



N

1 2

+

32

 BN2

t, ¯1(N) t} for

< t + P 32 B
some constants

¯1(N)



t 32

c0, c0 > 0.

B

(3.16)

Plugging (3.15) and (3.16) into (3.14) and choosing appropriate constants c~1, c~2, c~3 complete the proof.

17

For integers x  [0, N], y  [0, N - x] and a vector of non-negative integers z = (z1, z2, . . . )  N0 with y  z1  z2  . . . , introduce the notation
P(x,y,z)(·) := P( · | I(N)(0) = x, Q2(N)(0) = y, Q(i N)(0)) = zi-2 for i  3) and sup P(x,y,z)(·) := sup P(x,y,z)(·) : z  N0, z1  z2  . . . , z1  y .
z

Also, recall that for any t  0, S(N)(t) denotes the total number of tasks in the system at time

t,

and

2(N)(B)

denotes the first

time

Q2(N)

hits



B

N

1 2

+

.

The

next

lemma

gives

fluctuation

tail

bounds on excursions of the total queue length process.

Lemma 3.8. There exist t0, B1, such that for all B  B1, N  N~ B, and x  t0,

sup
z

P
(0,

2B

N

1 2

+

,

z)

S(N)

hits

S(N)(0)

+

xN

1 2

+

before

time

2(N)(B)

c^1

exp{-c^2

B

1 5

N

4 5

x

1 5

}

+

c^3

exp{-c^4

x},

where constants c^i, i  {1, 2, 3, 4} do not depend on B and N.

Proof. Note that there is a natural coupling between I(N)(t) and I¯B(N)(t), such that for all t  2(N)(B), I(N)(t)  I¯B(N)(t). Thus, for all t  2(N)(B),

S(N)(t)



S(N)(0)

+

A((N

-

N

1 2

-

)t)

-

D

=

S(N)(0)

+

A^ ((N

-

N

1 2

-

)t)

-

D^

t 0

(N

-

I¯B(N)

(s))ds

t 0

(N

-

I¯B(N)

(s))ds

+

t 0

I¯B(N)(s)ds

-

N

1 2

-t,

where recall A(·) and D(·) are independent unit-rate Poisson processes representing arrivals and departures respectively, and A^ (s) = A(s) - s and D^ (s) = D(s) - s. Therefore,

sup
z

P
(0,

2B

N

1 2

+

,

z)

S(N)

hits

S(N)(0)

+

xN

1 2

+

before

2(N)(B))

P

N 2 s 0

I¯B(N)(u)du



x 4

N

1 2

+

+

s 2

N

1 2

+

for

some

s



0

+P

M(t)

-

t 2

N

1 2

-

hits

3 4

x

N

1 2

+

for

some

t



0

,

(3.17)

where

M(t)

=

A^ ((N

-

N

1 2

-

)t)

-

D^ (

0t(N - I¯B(s))ds).

Recall t0, B1 from Lemma 3.7.

For

x  t0, B  B1, N  N~ B,

P

N 2 s 0

I¯B(N)(u)du



x 4

N

1 2

+

+

s 2

N

1 2

+

for

some

s



0

P

N2 x 0

I¯B(N)(u)du



x 4

N

1 2

+

+P

N 2 s 0

I¯B(N)(u)du



s 2

N

1 2

+

for

some

s



x



c^

exp{-c^

B

1 5

N

4 5

1
x5

},

(3.18)

18

for some constants c^, c^ > 0, where the last inequality follows by (3.13) and Lemma 3.7 (i). For the second term on the right-hand-side of (3.17), denote s¯k = kN2 x, k  0. For any k  0,

P

sup
s[s¯k,s¯k+1]

M(s)

-

s 2

N

1 2

-



3 4

x

N

1 2

+

P

sup M(s)
s[0,s¯k+1]



2 N -2 s¯k 4

+

3x



N

1 2

+

P

sup M(s)
s[0,s¯k+1]



2k

+ 4

5

x



N

1 2

+

 ce-c¯(k+1)x,

for some constants c, c¯ > 0, where the last inequality follows from Lemma 3.2. Summing over

k, we obtain

P

M(t) -

t 2

N

1 2

-

hits

x 2

N

1 2

+

for

some

t



0

 ce-c¯x.

(3.19)

Plugging (3.18) and (3.19) into (3.17) and choosing appropriate constants complete the proof.

Recall Q¯ 3(N)(t) := i=3 Q(i N)(t), t  0. The following lemma provides quantitative control on the excursions of Q¯ 3(N)(·). Lemma 3.9. Define

Z¯ (N) = sup

Q¯ 3(N)(s) - Q¯ 3(N)(0) +, and Z¯ (N) = Q¯ 3(N)(2(N)(B)) - Q¯ 3(N)(0).

s[0,2(N)(B)]

There exists B2 > 0, such that for all B  B2, we can obtain N~ B  N for which the following hold for all N  N~ B and x > 0.

(i) There exist constants c¯i, i  {1, 2, 3, 4}, not depending on N, x, such that

sup
z

P
(0,

2B

N

1 2

+

,

z)

Z¯ (N)



xN

1 2

+

 c¯1 exp

-

c¯2

N(

1 2

-)/5

exp{-c¯3

B

1 5

N

4 5

x

1 5

}

+

exp{-c¯4

x

}

.

(ii)

infz

P
(0,

2BN

1 2

+,

z)

Z¯ (N)

-

Q¯ 3(N)(0) 

B 4

N2



1 2

.

Proof.

(i) Recall t0 from Lemma 3.8.

Let N¯ B



N

be

such

that

N

-

2BN

1 2

+



N 2

and

N

1 2

-

/(2)

>

t0 for all N



N¯ B.

If Z¯ (N)



x



N

1 2

+,

then

there

exists

s



[0, 2(N)(B)]

such

that

Q2(N)(s)

=

N, Q¯ 3(N)(s)

=

Q¯ 3(N)(0)

+

x

N

1 2

+

,

and

I(N)(0)

=

0.

Hence,

for

all

N



N¯ B,

S(N)(s)

=N

+

N

+

Q¯ 3(N)(0)

+

xN

1 2

+

(N

-

I(N)(0)

+

Q2(N)(0)

+

Q¯ 3(N)(0))

+

(N

-

2BN

1 2

+

+

xN

1 2

+)

=S(N)(0)

+

(N

-

2BN

1 2

+

+

xN

1 2

+)

S(N)(0) +

N 2

+

x



N

1 2

+

.

19

Take B1, N~ B as in Lemma 3.8 and define N~ B := N~ B  N¯ B. Thus, for B  B1, N  N~ B , x > 0,

sup
z

P
(0,

2B

N

1 2

+

,

z)

Z¯ (N)



xN

1 2

+



sup
z

P
(0,

2B

N

1 2

+

,

z)

S(N)

hits

S(N)(0)

+

N 2

+

xN

1 2

+

before

time

2(N)(B)

c^1 exp

-

c^2

B

1 5

N

4 5

(N

1 2

-/(2)

+

x)

1 5

+

c^3

exp{-c^4(N

1 2

-/(2)

+

x)}

c¯1 exp

-

c¯2

N(

1 2

-)/5

exp{-c¯3

B

1 5

N

4 5

x

1 5

}

+

exp{-c¯4

x}

,

where

the

second

inequality

is

due

to

Lemma

3.8

upon

recalling

N

1 2

-/(2)

+

x

>

t0

by

the

definition

of

N¯ B.

The

last

inequality

is

due

to

(a

+

b)

1 5



a

1 5

+

b

1 5

,

for

all

a, b



0,

and

B1



1.

(ii) From part (i), for B  B1 and N  N~ B ,

sup
z

P
(0,

2B

N

1 2

+

,

z)

Z¯ (N) > 0

 2c¯1 exp

-

c¯2

N(

1 2

-)/5

.

(3.20)

Starting

from

I(N)(0)

=

0, Q2(N)(0)

=

2B

N

1 2

+



and

any

Q¯ 3(N)(0),

on

the event

Z¯ (N)

=

0,

Q¯ 3(N)(2(N)(B))



Q¯ 3(N)(0)

and

Q2(N)(2(N)(B))



Q2(N)(0)

-

B

N

1 2

+

+

1.

Thus,

we

have

S(N)(2(N)(B))



S(N)(0)

-

BN

1 2

+

+

1.

Also, for all t  0,

S(N)(t)

S(N)(0)

+

A((N

-

N

1 2

-

)t)

-

D(Nt)

=

S(N)(0)

+

A^ ((N

-

N

1 2

-

)t)

-

D^ (Nt)

-

N

1 2

-t,

where

A^ (s)

=

A(s) - s

and

D^ (s)

=

D(s) - s.

Let

M^ (s)

=

A^ ((N

-

N

1 2

-)s)

-

D^ (Ns).

Thus,

by

Lemma 3.2, there exists a constant c~ > 0, such that

sup
z

P
(0,

2B

N

1 2

+,

z)

2(N)(B) <

B 2

N2

,

Z¯ (N)

=

0

P

inf

M^ (s)

-



N

1 2

-

s



-BN

1 2

+

+

1

s(B/2)N2

P

inf
s(B/2)N2

M^ (s)



-

B 2

N

1 2

+

+

1

 4 exp{-c~B}.

(3.21)

Furthermore, since the instantaneous rate of decrease of Q¯ 3(N) is at least 1 when Q¯ 3(N) is positive, and that Q¯ 3(N) can only decrease when Z¯ (N) = 0, observe that, using Lemma 3.2,

sup
z

P
(0,

2B

N

1 2

+

,

z)

Q¯ 3(N)(2(N)(B)) >

Q¯ 3(N)(0)

-

B 4

N2

+, Z¯ (N) = 0, 2(N)(B) 

B 2

N2

P

Po

B 2

N2

<

B 4

N2

 2e-cBN2, for some constant c > 0 dependent on ,

(3.22)

20

where

Po(

B 2

N2

)

is

a

Poisson

random

variable

with

parameter

B 2

N2.

Inequalities

(3.20),

(3.21)

and (3.22), yield

inf
z

P

(0,

2BN

1 2

+

,

z)

Z¯ (N)  -

Q¯ 3(N)(0)



B 4

N2

=

inf
z

P
(0,

2BN

1 2

+

,

z)

Q¯ 3(N)(2(N)(B)) 

Q¯ 3(N)(0)

-

B 4

N2

+



1

-

sup
z

P
(0, 2BN

1 2

+

,

z)

Z¯ (N) > 0

-

sup
z

P
(0,

2BN

1 2

+,

z)

2(N)(B)

<

B 2

N2

,

Z¯ (N

)

=

0

-

sup
z

P
(0,

2B

N

1 2

+

,

z)

Q¯ 3(N)(2(N)(B)) >

Q¯ 3(N)(0)

-

B 4

N2

+, Z¯ (N) = 0, 2(N)(B) 

B 2

N2

 1 - 2c¯1 exp

-

c¯2 N (

1 2

-)/5

- 4 exp{-c~B} - 2e-cBN2.

Let B2  B1 such that 4 exp{-c~B}  1/4 for all B  B2. For B  B2, we can obtain N~ B  N~ B such that the lower bound above is at least 1/2. This completes the proof of the lemma.

3.1 Down-crossing estimate

Proposition 3.10. Recall B1  1 and N~ B for B  B1 from Lemma 3.7. There exist constants t0, ci > 0 , i  {0, 1, 2, 3, 4}, such that for any B  B1, N  N~ B, and x  0,

z:i

sup
zixN

1 2

+

P
(0,

2BN

1 2

+,

z)

2(N)(B)  N2t

4e-c0 t

+

c1

exp{-c2

B

1 5

N

4 5

t

1 5

}

+

c3

N4

t

exp{-c4 BN2

t},

t



t0



8 

(B

+

x).

Proof.

Starting from

I(N)(0)

=

0,

Q2( N ) (0)

=

2BN

1 2

+

,

i=3

Q(i N)(0))



x

N

1 2

+

,

for

t



2(N)(B),

Q2(N)(t) S(N)(t) - Q1(N)(t) = S(N)(t) - (N - I(N)(t))

=S(N)(0) + A

(N

-

N

1 2

-)t

-D

Nt -

t I(N)(s)ds - N + I(N)(t)

0

S(N)(0) - N + I¯B(N)(t) + A

(N

-

N

1 2

-)t

- D Nt -

t 0

I¯B(N)(s)ds

(2B

+

x)N

1 2

+

+

I¯B(N)(t)

+

A^

(N

-

N

1 2

-)t

- D^

Nt -

t 0

I¯B(N)(s)ds

+

t 0

I¯B(N)(s)ds

-

N

1 2

-t,

where A^ (s) = A(s) - s and D^ (s) = D(s) - s. Recall

M(t) =

A^

(N

-

N

1 2

-

)t

- D^ Nt -

t 0

I¯B(N)(s)ds

.

21

Thus, using the above upper bound for Q2(N), we obtain

z:i

sup
zi x N

1 2

+

P
(0,

2BN

1 2

+,

z)

2(N)(B)  N2t

=

z:i

sup
zi x N

1 2

+

P
(0,

2BN

1 2

+,

z)

Q2( N ) ( N2 t)



BN

1 2

+



and

2(N)(B)



N2 t

P

N 2 t 0

I¯B(N)(s)ds



 2

N

1 2

+

t

+P

I¯B( N ) ( N 2 t)



 16

N

1 2

+

t

+P

(2B

+

x)N

1 2

+

+

M(N2t)

-

 2

N

1 2

+

t

+

 16

N

1 2

+

t



B

N

1 2

+

.

Then, for B  B1, N  N~ B, t  t0, by Lemma 3.7(i),

(3.23)

P

N 2 t 0

I¯B(N)(s)ds

>

 2

N

1 2

+

t



c1

exp{-c2 B

1 5

N

4 5

1
t5

},

and moreover, by Lemma 3.7(ii),

P

I¯B( N ) ( N2 t)



 16

N

1 2

+

t

  exp{-c~1 BN4t} + c~2N4t exp{-c~3 BN2t}.

(3.24) (3.25)

For

t



8 

(

B

+

x),

by

Lemma

3.2,

P

(2B

+

x)N

1 2

+

+

M ( N2 t)

-

 2

N

1 2

+

t

+

 16

N

1 2

+

t



BN

1 2

+

P

M(N2t) 

 4

N

1 2

+t

-

(B

+

x)N

1 2

+

P

M(N2t) 

 8

N

1 2

+

t

 4e-ct,

(3.26)

where c is a positive constant not depending on N. Plugging (3.24), (3.25) and (3.26) into (3.23) and choosing appropriate constants complete the proof.

3.2 Up-crossing estimate

Recall

1(N)(2)

=

inf{t



0

:

I(N)(t)

=

2

N

1 2

-

}.

We

will

write

Q3(N)

:=

(Q3(N), Q4(N), . . . ).

Lemma

3.11.

Assume

I(N)(0)

=

x,

Q2(N)(0)

=

y, and

Q3(N)(0)

=

z.

For any

N

such

that

2N

1 2

-



1

and

any

x



2N

1 2

-

,

sup E(x,y,z) e1(N)(2)/2
y,z



2

x N

1 2

-



,

where E(x,y,z)(·) = E(·|I(N)(0) = x, Q2(N)(0) = y, Q3(N)(0) = z).

22

Proof.

Define

W(N)(t)

=

e

t 2

I(N)(t).

Since the rate of increase of

I(N)(t) is at most N - I(N)(t) and

the

rate

of

decrease

is

N

-



N

1 2

-

if

I(N)(t)

>

0,

therefore

LW ( N ) (t)



1 2

W

(N

)

(t)

+

e

t 2

(N

-

I(N)(t))

-

(N

-

N

1 2

-)

=

e

t 2

-

1 2

I(N)(t)

+

N

1 2

-

,

where

L(·)

is

the

infinitesimal

generator.

For

t

<

1(N)(2),



N

1 2

-



I

(N)(t) 2

,

and

so

LW(N)(t)1 t < 1(N)(2)  0.

This implies that for all y, z  0,

E(x,y,z)(W(N)(t  1(N)(2)))  E(x,y,z)(W(N)(0)) = x, t  0.
By Fatou's lemma and the observation that, almost surely, (t  1(N)(2)) = 1(N)(2) for sufficiently large t, we have that for all y, z  0,

and therefore,

E( x,y,z) (W ( N ) (1( N ) (2)))



lim inf
t

E(W ( N ) (t



1(N)(2)))



x,

sup E(x,y,z) e1(N)(2)/2
y,z



2

x N

1 2

-



.

(3.27)

Proposition 3.12. For any fixed B > 0, there exist pB, tB, NB > 0 such that t  tB, N  NB ,

sup
x,z

P

(

x,

BN

1 2

+

,

z)

2(N)(2B) > N2t



 c1 tN

1 2

+

 exp{-c2 N2 t}

+

(1

-


pB) t,

where c1, c2 are constants that do not depend on N, B, t.

Proof. The proof involves identifying excursions in the process path based on the I(N) process hit-

ting a certain threshold. The length of each excursion will then be controlled using Lemma 3.11.

During

each

excursion,

it

will

be

shown

that

Q2(N)

hits

the

level

2BN

1 2

+

with

a

positive

probabil-

ity that does not depend on N. This will lead to a geometric number of such excursions required

for

Q2(N)

to

hit

the

level

2BN

1 2

+

.

These

estimates

will

be

combined

to

complete

the

proof.

Define the stopping times: 0(N) := 0 and for k  0,

2(kN+)1

:=

inf{t



2(kN)

:

I(N)(t)



2

N

1 2

-

},

2(kN+)2 := 2(kN+)1 + N2.

23

Note

that

if

I ( N ) (2( kN ) )



2

N

1 2

-

,

then

2(kN+)1

=

2(kN);

equivalently,

if

2(kN+)1 - 2(kN)

>

0,

then

I ( N ) (2( kN ) )

>

2

N

1 2

-

.

Thus,

for

any

k



0

and

t



0,

any

N

such

that

2

N

1 2

-





1,

P 2(kN+)1 - 2(kN) > N2t



sup

P(x,y,z) 1(N)(2) > N2t

x

>2N

1 2

-

,y,z

 e-N2t/2 sup sup E(x,y,z) e1(2)/2
x y,z



N

2

N

1 2

-



exp{- N2 t/2},

(3.28)

where the last inequality is due to Lemma 3.11 and x  N. Next, we claim the following:

Claim

3.13.

Fix any

N

>

max{(5B)-(

1 2

-),

(2/

B)

1 2

}.

For any

k



0,

the

following

holds

on

the

event

sups[0,2(kN+)1]

Q2(N)(s)

<

2B

N

1 2

+

.

sup

S(N)(s)



3BN

1 2

+

+

S( N ) (2( kN+)1 )



s[2(kN+)1,2(kN+)2]

sup

Q2(N)(s)



2BN

1 2

+

,

s[2(kN+)1,2(kN+)2]

(3.29)

Proof.

Suppose that for some

k



0,

sups[0,2(kN+)1] Q2(N)(s)

<

2B

N

1 2

+

and

s



[2(kN+)1, 2(kN+)2]

such

that

S(N)(s)



3B

N

1 2

+

+

S( N ) (2( kN+)1 ).

Let

s¯

:=

inf{s



[2( kN+)1 ,

2( kN+)2 ]

:

S(N)(s)



3BN

1 2

+

+

S( N ) (2( kN+)1 )}.

Since

N

>

5B

N

1 2

+

,

we

claim

that

Q¯ 3(N)(s¯)



Q¯ 3(N)(2(kN+)1).

If

this

was

not

the

case,

s¯

>

2(kN+)1

and

there would be s~  [2k+1, s¯) such that s~ is a `point of increase' of Q¯ 3(N), that is, Q2(N)(s~) = N,

Q¯ 3(N)(s~)

=

Q¯ 3(N)(2(kN+)1)

and

I(N)(s~)

=

0.

Hence,

recalling

that

sups[0,2(kN+)1]

Q2(N)(s)

<

2B

N

1 2

+,

S(N)(s~)

=

N

+

Q¯ 3(N)(2(kN+)1)

+

N



N

-

2B

N

1 2

+

+

Q2(N)(s)

+

Q¯ 3(N)(2(kN+)1)

+

(N

-

I ( N ) (2( kN+)1 ))

=

N

-

2BN

1 2

+

+

S( N ) (2( kN+)1 )

>

3B

N

1 2

+

+

S( N ) (2( kN+)1 ),

which is a contradiction to the fact that s~

<

s¯.

Hence, we conclude that

N

>

5B

N

1 2

+

implies

Q¯ 3(N)(s¯)  Q¯ 3(N)(2(kN+)1). Using this observation and the definition of s¯, we obtain

3B

N

1 2

+

=S(N)(s¯)

-

S( N ) (2( kN+)1 )

= Q2(N)(s¯) + Q¯ 3(N)(s¯) + N - I(N)(s¯) - Q2(N)(2(kN+)1) + Q¯ 3(N)(2(kN+)1) + N - I(N)(2(kN+)1)

Q2(N)(s¯) - Q2(N)(2(kN+)1) + I(N)(2(kN+)1)

Q2(N)(s¯)

-

Q2(N)(2(kN+)1

)

+

2N

1 2

-.

Further,

note

that

2N

1 2

-

<

BN

1 2

+,

due

to

the

choice

of

N.

Thus,

the

above

yields

Q2(N)(s¯)



Q2( N ) (2( kN+)1 )

+

2BN

1 2

+



2BN

1 2

+

.

This completes the proof of the claim.

24

Therefore, due to Claim 3.13,

inf
x,z

P
(x,

B

N

1 2

+

,

z)

sup

Q2(N)(s)



2BN

1 2

+

|

Q2( N ) (2(kN+)1 )

<

2BN

1 2

+

s[2(kN+)1,2(kN+)2]



inf
x,z

P

(

x,



B

N

1 2

+

,

z)

sup

(S(N)(s)

-

S( N ) (2( kN+)1 ))



3BN

1 2

+

|

Q2( N ) (2( kN+)1 )

<

2BN

1 2

+

s[2(kN+)1,2(kN+)2]

P

sup

A

(N

-

N

1 2

-)s

-D

Ns



3BN

1 2

+

s[0,N2]

=P

sup

A^

(N

-

N

1 2

-)s

- D^

Ns

-

N

1 2

-s



3BN

1 2

+

s[0,N2]

P

A^

(N

-

N

1 2

-)N2

- D^ N1+2

-



N

1 2

+



3B

N

1 2

+

=P

N

-

1 2

-

A^

(N

-

N

1 2

-)N2

- D^ N1+2

- N-2  3B

 pB > 0, for sufficient large N.

(3.30)

Observe

that

pB

does

not

depend

on

N

since

N

-

1 2

-

A^

(N

-

N

1 2

-

)

N2

- D^ N1+2

-P

N(0, 2) by the Martingale FCLT. Therefore, for sufficiently large N,

sup
x,z

P
(x,

B

N

1 2

+

,

z)

2(N)(2B) > N2t



 t



k=0

sup
x,z

P
(x,

B

N

1 2

+

,

z)

2(kN+)1

-

2(kN)

>

 N2 t



+tsNxu,zp12 +P (exx, pB{N-21 +N2, z)ts/[2}2(skN+u+)1p,(2(kN1+)2-] Qp2(BN))(st)

< ,

2BN

1 2

+,

Q2( N ) (2( kN+)1 )

<

2B

N

1 2

+

,



k



  t

where the last inequality is due to (3.28) and (3.30).

3.3 Supremum of Q2(N)

In this section, we will give bounds on the supremum of the process Q2(N)(·) on a time interval

[0, N2 T] for fixed T > 0.

Let

I(N)(0)

=

0,

Q2(N)(0)

=

2B

N

1 2

+

,

and

Q3(N)(0)

=

0.

Define

0(N) := 0, and for i  0,

2(iN+)1

:=

inf{t



2(iN)

:

Q2(N)(t)



BN

1 2

+

},

2(iN+)2

:=

inf{t



2(iN+)1

:

Q2(N)(t)



2BN

1 2

+

},

KT(N) := inf{k : 2(kN)  N2T}.

(3.31)

Fix B  (B1  2  5), where B1 was introduced in Lemma 3.7.

25

Lemma 3.14. Recall N~ B from Lemma 3.3. There exist xB  2B such that for all i  0, N  N~ B,

N

1 2

-



x



xB,

P

sup

Q2(N)(s)



xN

1 2

+

Q3(N)(2(iN)) = 0



c1

exp{-c2 x}

+

c3

exp{-c4 N

4 5

x

1 5

},

s [2(iN ) ,2(iN+)1 ]

where cj , j  {1, 2, 3, 4}, are constants that do not depend on N, x.

Proof.

Fix

N

1 2

-



x

xB, where xB

 2B will be chosen later.

Define the stopping time

^ i( N )

:= inf{s



2(iN)

:

Q2(N)(s)



x

N

1 2

+

or

Q2(N)(s)



B

N

1 2

+

},

i



0.

Note

that,

as

x



N

1 2

-

,

when

Q3(N)(2(iN))

=

0,

Q3(N)(t)

=

0

for

all

t



[2(iN), ^i(N)],

and

in

that

case, we have S(N)(t) = N - I(N)(t) + Q2(N)(t). Therefore, we obtain for t  [0, ^i(N) - 2(iN)],

Q2(N)(t + 2(iN)) - I(N)(t + 2(iN)) - (Q2(N)(2(iN)) - I(N)(2(iN))) = S(N)(t + 2(iN)) - S(N)(2(iN))

=

A

(N

-

N

1 2

-)(t

+

2(iN))

-A

(N

-

N

1 2

-)2(iN)

-D

2(iN)+t(N - I(N)(s))ds
2(iN)

=

A^

(N

-

N

1 2

-)(t

+

2(iN))

- A^

(N

-

N

1 2

-)2(iN)

- D^

2(iN)+t(N - I(N)(s))ds
2(iN)

+

2(iN) +t 2(iN)

I(N)(s)ds

-

N

1 2

-

t,

where A^ (s) = A(s) - s and D^ (s) = D(s) - s. Using the above and the strong Markov property at time 2(iN), we can write

P

sup

Q2(N)(s)



xN

1 2

+

s [2(iN ) ,2(iN+)1 ]

Q3(N)(2(iN)) = 0

=P

sup

(Q2(N)(s)

-

I(N)(s))



xN

1 2

+

Q3(N)(2(iN)) = 0

s[2(iN),2(iN+)1]

 P ^i(N) - 2(iN)  N2t Q3(N)(2(iN)) = 0

+P

sup

(Q2(N)(s)

-

I(N)(s))



x

N

1 2

+

Q3(N)(2(iN)) = 0

s[2(iN),2(iN) +N2t]



P
(0,

2B

N

1 2

+

,

0)

2(N)(B)  N2t

+

P

(0,

2BN

1 2

+

,

0)

sup
s[0,N2t]

2BN

1 2

+

+

M^ (s)

+

s

I(N)(u)du

-

N

1 2

-s

0

(3.32)



x

N

1 2

+

,

where M^ (s) := A^

(N

-

N

1 2

-)s

- D^

s 0

(N

-

I(N)(u))du

, and the first equality above is due

to the fact that Q2(N) can increase only when I(N) = 0. Now, for the first term in the above bound,

26

observe

that

by

Proposition

3.10,

for

B



B1,

N



N~ B,

and

t



t0



8B 

,

we

have

P

(0,

2B

N

1 2

+

,

0)

2(N)(B)  N2t



4e-c0 t

+

c1

exp{-c2

B

1 5

N

4 5

t

1 5

}

+

c3 N4t

exp{-c4

 BN2

t}.

(3.33)

For the second term on the right side of (3.32),

P

(0,

2BN

1 2

+

,

0)

sup
s[0,N2t]

2BN

1 2

+

+

M^ (s)

+

s

I(N)(u)du

-

N

1 2

-s

0



x

N

1 2

+

P

N2t 0

I(N)(u)du

>

 2

N

1 2

+

t

+P

sup
s[0,N2t]

M^ (s)



(x

-

t 2

-

2B)

N

1 2

+

P

N2t 0

I(N)(u)du

>

 2

N

1 2

+

t

+P

sup
s[0,N2t]

M^ (s)



(x

-

t 2

-

2B)

N

1 2

+

.

Thus, using Lemma 3.7 (i) for the first term and Lemma 3.2 for the second term in the above

bound,

we

have

that

for

N



N~ B,

t



t0

and

x

-

t 2

-

2B



0,

P

(0,

2B

N

1 2

+

,

0)

sup
s[0,N2t]

2BN

1 2

+

+

M^ (s)

+

s

I(N)(u)du

-

N

1 2

-s

0



x

N

1 2

+

c1

exp{-c2

B

1 5

N

4 5

t

1 5

}

+

2

exp{-c3(x

-

t/2

-

2B)2/t},

(3.34)

for positive constants c1, c2, c3 not depending on x, t, N.

Thus,

taking

t

=

x 

,

for

x



xB

:=

(t0  8B),

and

putting

the

upper

bounds

in

(3.33)

and

(3.34) into (3.32), the result holds for appropriately chosen constants.

Proposition 3.15. There exist constants x, N > 0, c¯, c¯1, c¯2 and ci , i = {1, 2, 3, 4}, depending only on B, such that for all N  NB, x  xB, T  x-1,

P

(0,

2BN

1 2

+

,

0)

sup

Q2(N)(s)



xN

1 2

+

s[0, N 2 T ]

 exp{-c¯Tx} + Tx c¯1 exp

-

c¯2

N(

1 2

-)/5

+

c1

exp{-c2

x}

+

c3

exp{-c4

N

4 5

x

1 5

}

.

Proof. Define i(N) = 1[2(iN+)1 - 2(iN)  N2]. For s  0,

S(N)(s + 2(iN))

=

N

+

2BN

1 2

+



+

Q¯ 3(N)(2(iN))

+

A

(N

-

N

1 2

-)(s

+

2(iN ) )

-A

(N

-

N

1 2

-)2(iN)

-D

=

N

+

2BN

1 2

+



+

Q¯ 3(N)(2(iN))

+

2(iN) +s

I(N)(u)du

-

N

1 2

-s

2(iN)

+

A^

(N

-

N

1 2

-)(s

+

2(iN ) )

- A^

(N

-

N

1 2

-)2(iN)

- D^

( N 2(iN) +s
2(iN)

-

I(N)(u))du

( N 2(iN) +s
2(iN)

-

I(N)(u))du

.

(3.35)

27

where A^ (s) = A(s) - s and D^ (s) = D(s) - s. Recall that

M^ (s) = A^

(N

-

N

1 2

-)s

- D^

For B  (2  5),

s(N - I(N)(u))du
0

for s  0.

P i(N) = 0 Q3(N)(2(iN)) = 0

P

inf
s[2(iN) ,2(iN) + N 2 ]

Q2(N)(s)



BN

1 2

+



Q3(N)(2(iN)) = 0

P

inf
s[2(iN) ,2(iN) + N 2 ]

Q2(N)(s)



BN

1 2

+

,

sup
s[2(iN),2(iN+)1]

Q3(N)(s)

=

0

Q3(N)(2(iN)) = 0

+P

sup Q3(N)(s) > 0 Q3(N)(2(iN)) = 0

s [2(iN ) ,2(iN+)1 ]

P

inf

S(N)(s)



N

+

BN

1 2

+



s[2(iN) ,2(iN) + N 2 ]

Q3(N)(2(iN)) = 0

+

P
(0,

2B

N

1 2

+

,

0)

sup Q¯ 3(N)(s) > 0
s[0,2(N)(B)]

P

inf

(2BN

1 2

+

+

M^ (s)

-

N

1 2

-s)



BN

1 2

+



s[0,N2]

+ c¯1 exp

-

c¯2

N(

1 2

-)/5

P

inf
s[0,N2]

M^ (s)



-

B 2

N

1 2

+

+ c¯1 exp

-

c¯2

N(

1 2

-)/5



8N1+2 B2 N1+2

+ c¯1 exp

-

c¯2

N(

1 2

-)/5



1 2

,

for

sufficient

large

N,

where the third inequality uses the strong Markov property for the second term and the observation that S(N)(s)  N + Q2(N)(s) if Q3(N)(s) = 0 for the first term. The fourth inequality is due to the strong Markov property, (3.35) and Lemma 3.9, and the last inequality follows from Doob's L2-maximal inequality. Thus, E(i(N) | Q3(N)(2(iN)) = 0)  1/2 for sufficiently large N. Now, for T > 0, recall KT(N) = inf k : ¯2(kN)  N2T . By Azuma's inequality and Lemma 3.9, taking a  8, T  a-1, for sufficiently large N,

P KT(N)  aT

P P

aT
 (2(iN+)1 - 2(iN))  N2 T
i=1

aT

 i(N)  T and sup Q3(N)(s) = 0, 1  i  aT

i=1

s [2(iN ) ,2(iN+)1 ]

+ P 1  i  aT, sup Q3(N)(s) > 0
s[2(iN) ,2(iN+)1]

(3.36)

28

  P

aT
i(N) - E(i(N) | Q3(N)(2(iN)) = 0)
i=1



-

aT 8

 e-c¯aT + aTc¯1 exp

and sup Q3(N)(s) = 0, 1  i  aT
s[2(iN),2(iN+)1]

+ aT · P

sup Q3(N)(s) > 0 Q3(N)(2(iN)) = 0

s [2(iN ) ,2(iN+)1 ]

-

c¯2 N (

1 2

-)/5

.

(3.37)

Take

a

=

x.

Then,

using

(3.37),

Lemma

3.14,

and

union

bound,

for

N



N~ B,

N

1 2

-



x



(xB



8),

T  x-1,

P

sup

Q2(N)(s)



xN

1 2

+

s[0,N2T]

P KT(N)  xT + Tx · P

sup

Q2(N)



xN

1 2

+

Q3(N)(2(iN)) = 0

s[2(iN),2(iN+)1]

 exp{-c¯Tx} + Tx c¯1 exp

-

c¯2

N(

1 2

-)/5

+

c1

exp{-c2

x}

+

c3

exp{-c4

N

4 5

x

1 5

}

.

This proves the proposition.

4 Steady state analysis

Our goal is to identify points in the state space which are hit infinitely often by the process and the length between successive hitting times has a finite expectation. This will provide a renewaltheoretic representation (see (4.24)) of the stationary measure. Throughout this section, we will choose and fix a number B = B0 as the maximum of the lower bounds on B given in the results in Section 3.
Recall the stopping times 0(N) = 0, and for i  0,

2(iN+)1

=

inf{t



2(iN)

:

Q2(N)(t)





B

N

1 2

+

},

2(iN+)2

=

inf{t



2(iN+)1

:

Q2(N)(t)



2B

N

1 2

+

},

(4.1)

and define

K¯ (N) := inf{k  1 : Q¯ 3(N)(2(kN)) = 0}.

Write



:=

2(KN¯ ()N) .

Note

that

I(N)()

=

0,

Q2(N)()

=

2B

N

1 2

+



and

Q¯ 3(N)()

=

0.

Therefore,



is

a renewal time point.

Lemma 4.1. There exist N0, c1, c2 > 0, such that for all N  N0, k  1,

P
(0,

2B

N

1 2

+

,

0)

K¯ (N)



1

+

k

+

k2

N

1 2

-

 kc1 exp

-

c2

N(

1 2

-)/11

exp

- c2

k/

N

1 2

-

1 11

+ 2-k.

29

The following lemma will be used to prove Lemma 4.1. Define K¯  := inf{k  1 : Q¯ 3(N)(2(kN)) 

B 4

N2

}.

Lemma 4.2. There exist N0, c1, c2 > 0, such that for all N  N0, k  1,

sup

0z

B 4

N2

P
(0,

2BN

1 2

+,

z)

K¯ 



1

+

kN

1 2

-

 c1 exp

-

c2

N(

1 2

-)/11

exp

- c2

k/

N

1 2

-

1 11

.

Proof. Define Z¯ i(N) := Q¯ 3(N)(2(iN+)2) - Q¯ 3(N)(2(iN)), i  0. Note that

z:

i

sup

zi



B 4

N2

P
(0,

2BN

1 2

+,

z)

K¯ 



1

+

kN

1 2

-

 

z:

i

sup

zi



B 4

N2

P
(0,

2BN

1 2

+,

z)

i Z¯ j(N)
j=0

>

B 4

N2

-

Q¯ 3(N)(0),



0



i



kN

1 2

-



-

1

.

(4.2)

To estimate (4.2), define (i N) := 1 Z¯ i(N)  -

B 4

N2



Q¯ 3(N)(2(iN))

, i  0. By Lemma 3.9 (ii), for

sufficiently large N,

inf
z

E
(0,2B

N

1 2

+

,z)

(i N)|F2(iN)



1 2

,

i  0.

(4.3)

Using Azuma-Hoeffding inequality, we get for any k  1,

z:

i

sup

zi



B 4

N2

P
(0,

2BN

1 2

+

,

z)

 k

N

1 2

-

-1

(j N)

j=0



k

N

1 2

-

3



z:

i

sup

zi



B 4

N2

P
(0,

2BN

1 2

+

,

z)

k

N

1 2

-

-1



(j N) - E (j N)

j=0

F2(jN)



-

kN

1 2

-

6



e-ckN

1 2

-

,

for some c > 0, where in the first inequality, we have used (4.3). Therefore, for k  1,

(4.4)

 z:

i

sup

zi



B 4

N2

P

(0,

2BN

1 2

+

,

z)

i Z¯ j(N)
j=0

>

B 4

N2

-

Q¯ 3(N)(0),  0



i



k

N

1 2

-



-

1



z:

i

sup

zi



B 4

N2

P
(0,

2BN

1 2

+,

z)

k

N

1 2

-

-1

kN

1 2

-

-1

 [Z¯ j(N)]+ - 

j=0

j=0

B 4

N2

(j N) > 0



z:

i

sup

zi



B 4

N2

P
(0,

2BN

1 2

+,

z)

 k

N

1 2

-

-1

(j N)

j=0



k

N

1 2

-

3

+

z:

i

sup

zi



B 4

N2

P
(0,

2BN

1 2

+

,

z)

 k

N

1 2

-

-1

[Z¯ j(N)]+

j=0



B 12

N

1 2

+

k

e-ckN

1 2

-

+

sup

z:

i

zi



B 4

N2

P

(0,

2BN

1 2

+

,

z)

 kN

1 2

-

-1

[Z¯ j(N)]+

j=0



B 12

N

1 2

+

k

,

(4.5)

30

where the last inequality uses (4.4). Note that, by Lemma 3.9 (i), for any j  1, x > 0, and sufficient large N,

sup P

z:

i

zi



B 4

N2

[Z¯ j(N)]+

N

1 2

+



x

F2(jN)



c1

e-c2

N

(

1 2

-)/5

e-c3

x1/5

,

(4.6)

where c1, c2, c3 > 0 are constants. Choose N1 sufficiently large such that (4.3) and (4.6) hold, and

for N  N1,



c1e-c2

N(

1 2

-)/5

e-c3x1/5

dx

0



4

×

B 12N

1 2

-

.

Take any N  N1, and k  1. We will use Lemma 3.5 with



=

1 5

,

r

=

z,

R

=

{z

:

 zi
i



B 4

N2

},

a

=

12

B N

1 2

-

,

n

=

k

N

1 2

-

,

and

(j r)

=

[

Z¯ j( N

N)]+

1 2

+

,

with

starting

configuration

( I ( N ) (0),

Q2(N)(0),

Q¯ 3(N)(0))

=

(0,

2B

N

1 2

+

,

z),

and

associated

filtra-

tion

F

(r) j

:

j



1, r



R

being the natural filtration generated by the above random variables.

We get

z:

i

sup

zi



B 4

N2

P

(0,

2B

N

1 2

+

,

z)

 k

N

1 2

--1

[Z¯ j(N)]+

j=0



B 12

N

1 2

+

k

 sup P
rR

n (jr)  an
j=0

 c1 1 +

kN

1 2

-



5/11

B

1 11

12N

1 2

-

exp

- c2

k

N

1 2

-

1/11



c1 N

1 2

-

exp

- c2

k

N

1 2

-

1/11
.

Moreover, for any k  1, from (4.6),

(4.7)

z:

i

sup

zi



B 4

N

P
2 (0,

2B

N

1 2

+

,

z)

 kN

1 2

-

-1

[Z¯ j(N)]+

j=0



B 12

N

1 2

+

k



kN

1 2

-

sup

P

z:

i

zi

B 4

N2

[Z¯ 0(N)]+



B 12

N2



kN

1 2

-

c1

exp

-

c2

N(

1 2

-)/5

.

(4.8)

31

Hence, (4.7) and (4.8) imply

z:

i

sup

zi



B 4

N

P
2 (0,

2B

N

1 2

+

,

z)

 kN

1 2

-

-1

[Z¯ j(N)]+

j=0



B 12

N

1 2

+

k

 min

c1

N

1 2

-

exp

- c2

k

N

1 2

-

1/11

,

kN

1 2

-

c1

exp

-

c2

N(

1 2

-)/5

.

Note that, there exists a constant N2, such that for all N  N2 and k  N1-2,

and for k  N1-2,

k

N

1 2

-

c1

exp

-

c2

N(

1 2

-)/5

=

k

N

1 2

-

c1

exp

-

c2 2

N

(

1 2

-)/5

exp

-

c2 2

N

(

1 2

-)/5

 exp

-

c2 4

N

(

1 2

-)/5

exp

-

c2 2

N

(

1 2

-)/5

)

 exp

-

c2 4

k

1 10

exp

-

c2 2

N(

1 2

-)/5)

,

N

1 2

-

exp



N

1 2

-

exp

- c2

k

N

1 2

-

1/11

-

c2 2

N

(

1 2

-)/11

exp

- c2 2

k

N

1 2

-

1/11
.

Hence, there exist constants c~, c~ > 0, such that for all N  N1  N2 and k  1,

(4.9)

z:

i

sup

zi



B 4

N2

P
(0,

2BN

1 2

+,

z)

 k

N

1 2

-

-1

[Z¯ j(N)]+

j=0



B

N

1 2

+

k

12

 c~ exp

-

c~

N(

1 2

-)/11

exp

- c~

k/

N

1 2

-

1 11

.

(4.10)

Finally, using (4.2) and plugging (4.10) into (4.5), we have

z:

i

sup

zi



B 4

N2

P
(0,

2BN

1 2

+,

z)

K¯ 



1

+

k

N

1 2

-

 

z:

i

sup

zi



B 4

N2

P
(0,

2BN

1 2

+,

z)

i Z¯ j(N)
j=0

>

B 4

N2

-

Q¯ 3(N)(0),  0



i



kN

1 2

-



-

1

c1 exp

-

c2

N(

1 2

-)/11

exp

- c2

k/

N

1 2

-

1 11

,

where c1 and c2 are appropriate constants.

Proof of Lemma 4.1. Define K¯0 := 0 and for j  0,

K¯ j+1 := inf

l



K¯

 j

+1

:

Q¯ 3(N)(2(lN))



B 4

N2

.

32

Define (j N) := 1 Q¯ 3(N)(2(KN¯j)+2) = 0 , j  0. By Lemma 3.9 (ii),

P

(0,

2BN

1 2

+

,

0)

(j N)

=

|F 1

2(KN¯ j)



1 2

,

j  0.

Thus, there exist constants c2, N0 > 0, such that for k  1, N  N0,

P

(0,

2BN

1 2

+

,

0)

K¯ (N)



1

+

k

+

k2 N

1 2

-

k



j=1

P
(0,

2BN

1 2

+

,

0)

K¯

 j+1

-

K¯

 j



1

+

kN

1 2

-

+

P
(0,

2BN

1 2

+

,

0)

(j N) = 0, 0  j  k - 1

kc1 exp

-

c2

N(

1 2

-)/11

exp

- c2

k/

N

1 2

-

1 11

+ 2-k,

(4.11)

where the last inequality comes from Lemma 4.2 and the inequality in (4.11).

Recall



=

2(KN¯ ()N) .

The

next

proposition

gives

tail

estimates

for

P

(0,

2B

N

1 2

+

,

0)

 > N2t

.

Proposition 4.3. There exist constants c¯1, c¯2, N0, t0 > 0, such that for all N  N0, t  t0,

P
(0,

2B

N

1 2

+

,

0)

 > N2t



c¯1 e-c¯2 t1/5

+

c¯1

e-c¯2

N

(

1 2

-)/11

e-c¯2

t

1/44

N4(1/2-)

.

Proof. Note that for any k  1,

P
(0,

2B

N

1 2

+

,

0)

 > N2t



P

(0,

2BN

1 2

+

,

0)

2(N) > N2t/2

+

P

(0,

2BN

1 2

+

,

0)

K¯ (N)

>

1

+

k

+

k2 N

1 2

-

+

P
(0,

2BN

1 2

+,

0)

2(KN¯ ()N)

-

2(N)

>

N2t/2, 1

<

K¯ (N)



1

+

k

+

k2

N

1 2

-

.

(4.12)

We will upper bound each of the above terms. Note that there exist t0, N0 > 0, such that for all N  N0, x > 0 and t  t0  8-1(B + x),

z:

i

sup
zixN

1 2

+

P
(0,

2BN

1 2

+,

z)

2(N) > N2t/2



z:

i

sup
zixN

1 2

+

P
(0,

2BN

1 2

+,

z)

1(N) > N2t/4

+

z:

i

sup
zixN

1 2

+

P
(0,

2BN

1 2

+,

z)

2(N) > N2t/2, 1(N)  N2t/4

ce-c

 t

+

ce-c N

4 5

t1/5 ,

(4.13)

33

where the last inequality is from Proposition 3.10 and Proposition 3.12. Write l(k, N) = 1 + k +

k2

N

1 2

-

.

By

Lemma

4.1,

for

all

k



1,

P

(0,

2BN

1 2

+

,

0)

K¯ (N)  l(k, N)

 kc1 exp

-

c2

N(

1 2

-)/11

exp

- c2

k/

N

1 2

-

1 11

+ 2-k. (4.14)

Next, recall Z¯ j(N) = Q¯ 3(N)(2j+2) - Q¯ 3(N)(2j). Then we have for any x > 0,

P

(0,

2BN

1 2

+

,

0)

2(KN¯()N) - 2(N) > N2t/2, 1 < K¯ (N)  l(k, N)

 l(k,N)



j=1

P
(0,

2B

N

1 2

+

,

0)

2(jN+)2

- 2(jN)

>

N2 t 2l(k, N)

,

Z¯ 0(N)

>

0

l(k,N)

j=1

P
(0,

2B

N

1 2

+

,

0)

Z¯ j(N)

>

x

N

1 2

+

+

P

(0,

2BN

1 2

+

,

0)

2(jN+)2 - 2(jN) >

N2 t 2l(k, N

)

,

Z¯ 0(N)

>

0,

Z¯ j(N)



x

N

1 2

+

.

(4.15)

By Lemma 3.9 (i), for all large enough N,

l(k,N)

j=1

P

(0,

2B

N

1 2

+

,

0)

Z¯ j(N)

>

x

N

1 2

+



c1l(k,

N

)e-c2

N(

1 2

-)/5

e-c2

x1/5

.

(4.16)

For all N large enough, 1  j  l(k, N), x > 0 and t  [t0  8-1(B + x)]l(k, N),

P

(0,

2BN

1 2

+

,

0)

2(jN+)2 - 2(jN) >

N2 t 2l(k, N)

,

Z¯ 0(N)

>

0,

Z¯ j(N)



x

N

1 2

+



P
(0,

2B

N

1 2

+

,

0)

Z¯ 0(N) > 0

·

z:

i

sup
zi x N

1 2

+

P
(0,

2BN

1 2

+,

z)

2(N)

>

N2 t 2l(k, N)

 c e ce + ce , 1

-c2

N(

1 2

-)/5

-c

t l(k,N)

1/2

-c

N

4 5

t

1/5

l(k,N)

(4.17)

where the first inequality is due to the strong Markov property and the last inequality is due to

Lemma

3.9

and

(4.13).

Hence,

taking

x

=

t 2l(k,N)

and

using

(4.16)

and

(4.17)

in

(4.15),

we

have

for

t  2(t0 + 8-1B)l(k, N),

P
(0,

2BN

1 2

+

,

0)

2(KN¯()N) - 2(N) > N2t/2, 1 < K¯ (N)  l(k, N)

Also, for t0  t  2(t0 + 8-1B)l(k, N),



c1l(k,

N

)e-c2

N(

1 2

-)/5

e-c3

t

1/5

l(k,N)

.

(4.18)

P

(0,

2B

N

1 2

+

,

0)

2(KN¯()N) - 2(N) > N2t/2, 1 < K¯ (N)  l(k, N)



P
(0,

2B

N

1 2

+

,

0)

Z¯ 0(N) > 0



c1

e-c2

N

(

1 2

-)/5

.

(4.19)

34

Combining (4.18) and (4.19), we have for all t  t0,

P
(0,

2BN

1 2

+

,

0)

2(KN¯()N) - 2(N) > N2t/2, 1 < K¯ (N)  l(k, N)



c1 l(k,

) N

e e -c2

N(

1 2

-)/5

-c3

t l(k,N)

1/5
.

Finally,

taking

k

=

t1/4

and

l(k,

N)

=

1

+

t1/4

+

 tN

1 2

-

,

we

obtain

the

proposition

by

(4.20) plugging

(4.13), (4.14), and (4.20), into (4.12).

Corollary 4.4. There exist N0, c, c > 0 such that for all N  N0,

E
(0,

2B

N

1 2

+

,

0)

2

E
(0,

2B

N

1 2

+

,

0)



 cN4,  c N2.

Proof. Take t0 as in Proposition 4.3. Then





E
(0,

2B

N

1 2

+

,

0)

2/N4

 t20 +

t0

P

(0,

2BN

1 2

+

,

0)

 > N2

t dt.

The

upper

bound

on

E
(0,

2BN

1 2

+

,

0)

2

now follows from Proposition 4.3. To obtain the lower

bound

on

E
(0,

2B

N

1 2

+

,

0)



, recall s(N) from (3.1) and note that

E
(0,

2BN

1 2

+

,

0)





E
(0,

2BN

1 2

+

,

0)

2(N)(B)



E
(0,

2BN

1 2

+

,

0)

2(N)(B)1

2(N)(B)

<

2(N)(N

1 2

-))

=

E
(0,

2BN

1 2

+

,

0)

2(N)(B)1

2(N)(B)

<

s(N)(2N

1 2

-

))



E
(0,

2BN

1 2

+

,

0)

s(N)(B

+

N

1 2

-)1

2(N)(B)

<

s(N)(2N

1 2

-

))

=

E
(0,

2BN

1 2

+

,

0)

s(N)(B

+

N

1 2

-)

-

E
(0,

2BN

1 2

+,

0)

s(N)(B

+

N

1 2

-)1

s(N)(2N

1 2

-)

<

2(N)(B)

.

(4.21)

Now, for any t  0,

P
(0,

2B

N

1 2

+

,

0)

s(N)(B

+

N

1 2

-

)



N2 t

=

P

(0,

2BN

1 2

+

,

0)

inf

S( N ) ( N2 s)



N

+

BN

1 2

+

st

=

P

(0,

2BN

1 2

+

,

0)

inf
st

S(N)(N2s) - S(N)(0)



N

+

BN

1 2

+



-

2BN

1 2

+





P

(0,

2BN

1 2

+

,

0)

inf
st

A((N

-

N

1 2

-)N2

s

-D

N 2 s
(N - I(N)(u))du
0



-BN

1 2

+

+

1

35



P

(0,

2BN

1 2

+

,

0)

inf
st

A^

(N

-

N

1 2

-)N2

s

- D^



P

(0,

2BN

1 2

+

,

0)

inf
st

A^

(N

-

N

1 2

-)N2

s

- D^

N 2 s
(N - I(N)(u))du

0

-

N

1 2

+s



-BN

1 2

+

+

1

N 2 s
(N - I(N)(u))du

0

-

N

1 2

+s



(t

-

B)N

1 2

+

+

1

,

where A^ (s) = A(s) - s and D^ (s) = D(s) - s. Using Lemma 3.2 in the above lower bound, there exist t > 0, N > 0 such that for all t  t, N  N,

P
(0,

2B

N

1 2

+

,

0)

s(N)

B

+

N

1 2

-

> N2t



1 2

,

and consequently,

E
(0,

2B

N

1 2

+

,

0)

s(N)

B

+

N

1 2

-



1 2

t

N2

.

(4.22)

Next, we will show that the second term in the bound (4.21) is much smaller than the first

term. To show this, recall the stopping times {j(N)} from (3.31) and define K^ (N) := inf{k  0 :

Q¯ 3(N)(2(kN+)1) = 0}. Lemma 4.1 and Proposition 4.3 readily extend to K^ (N) in place of K(N) and

2(KN^()N)+1 in place of . Hence, using the same argument to bound the second moment of 2/N4,

we

obtain

E
(0,

2B

N

1 2

+

,

0)

2(KN^()N)+1 2  cN4. Now, observe that

s(N)

B

+

N

1 2

-

 2(KN^ ()N)+1.

Using this observation along with Lemma 3.8,

E
(0,

2B

N

1 2

+

,

0)

s(N)(B

+

N

1 2

-)1

s(

N

)

(2

N

1 2

-

)

<

2(N)(B)



E
(0,

2BN

1 2

+

,

0)

2(KN^ ()N)+1 2

P
(0,

2B

N

1 2

+

,

0)

s(N)(2N

1 2

-

)

<

2(N)(B)

 cN2

P
(0,

2B

N

1 2

+

,

0)

s(N)(2N

1 2

-

)

<

2(N)(B)

 cN2

c exp

-c

N4/5

N(

1 2

-)/5

+ c exp

-c

N

1 2

-

,

(4.23)

where the last inequality is from Lemma 3.8.

Finally,

the

lower

bound

on

E
(0,

2B

N

1 2

+

,

0)



claimed in the corollary is established by plugging (4.22) and (4.23) into (4.21).

We introduce the following representation of the stationary measure

 S(N)  x

=

E
(0,

2BN

1 2

+

,

0)

 0

1

S(N)(u)

E

(0,

2B

N

1 2

+

,

0)

()



x

du

.

(4.24)

This representation, combined with our estimates on  and the tail estimates for excursions of S(N)(·), translates to the steady-state tail behavior stated in Theorem 2.7.

36

Proof of Theorem 2.7. Note that due to (4.24),



S(N)



N

+

x

N

1 2

+



E
(0,

2B

N

1 2

+

,

0)

1

s(N)(x

+

N

1 2

-)

E
(0,

2BN

1 2

+

,

0)

()

<







E

(0,

2B

N

1 2

+

,

0)

(2

)

P
(0,

2B

N

1 2

+

,

0)

s(N)(x

+

N

1 2

-)

<



E
(0,

2B

N

1 2

+

,

0)

()

. (4.25)

Recall

t0

from

Lemma

3.8.

For

x



[t0 

+

2B,

N

1 2

-

],

P
(0,

2B

N

1 2

+,

0)

s(N)(x

+

N

1 2

-

)

<



=

P

(0,

2B

N

1 2

+

,

0)

s(N)(x

+

N

1 2

-

)

<

2(N)(B)

 c exp - cx + c exp - c N4/5x1/5 ,

(4.26)

where

the

inequality

is

due

to

Lemma

3.8.

The

bound

of

(4.26)

can

be

extended

to

x



[4B,

N

1 2

-

]

by

adjusting

the

constants.

Moreover,

for

x



(N

1 2

-

,

2N

1 2

-

],

by

Lemma

3.9

(i),

P

(0,

2B

N

1 2

+

,

0)

s(N)(x

+

N

1 2

-

)

<





P

(0,

2BN

1 2

+

,

0)

sup

Q¯ 3(N)(s) - Q¯ 3(N)(0)

s[0,2(N)(B)]

 c1 exp

-c2

N

(

1 2

-)/5

 c1 exp

-c2 x1/5

,

>0 (4.27)

for

positive

constants

c1,

c2,

c2 .

Next,

consider

x



2

N

1 2

-

.

Write

Z¯ (Ni ) := sup

Q¯ 3(N)(s) - Q¯ 3(N)(2(iN)) +, i  0.

s[2(iN),2(iN+)2]

Take

any

k



1.

Recall

l(k,

N)

=

1

+

k

+

k2 N

1 2

-.

Observe

that

P

(0,

2B

N

1 2

+

,

0)

s(N)(x

+

N

1 2

-

)

<





P
(0,

2BN

1 2

+, 0)

K¯ (N)  l(k, N)

+

P
(0,

2BN

1 2

+,

0)

sup

sup Q¯ 3(N)(s)

0il(k,N) s[2(iN),2(iN+)2]



x

N

1 2

2

+

,

Z¯ (N0 )

>

0

.

By Lemma 4.1, for sufficiently large N, for all k  1,

(4.28)

P
(0,

2B

N

1 2

+

,

0)

K¯ (N)  l(k, N)



c1

ke-c2

N

(

1 2

-)/11

-c2
e

k

N

1 2

-

1/11
+ 2-k.

(4.29)

37

Also, note that since Q¯ 3(N)(0) = 0,

sup Q¯ 3(N)(s)  sup

Q¯ 3(N)(s) - Q¯ 3(N)(2(iN))

s[2(iN),2(iN+)2]

s [2(iN ) ,2(iN+)2 ]

i-1
+

Q¯ 3(N)(2(jN+)2) - Q¯ 3(N)(2(jN))

j=0

i
  sup

Q¯ 3(N)(s) - Q¯ 3(N)(2(jN))

j=0 s[2(jN),2(jN+)2]

  i Z¯ (Nj ). j=0

Hence,

P
(0,

2B

N

1 2

+

,

0)

sup

sup Q¯ 3(N)(s)

0il(k,N) s[2(iN),2(iN+)2]



x

N

1 2

2

+

,

Z¯ (N0

)

>0

 

P
(0,

2BN

1 2

+, 0)

l(k,N)-1
Z¯ (Nj )
j=0



x

N

1 2

+

2

.

(4.30)

Letting

k

=

k(x)

=

  x,

we

have

l(x,

n)

:=

l(k(x),

N)

=

1

+

  x

+

 

x2

N

1 2

-

.

Note

that,

by

Lemma 3.9 (i), for any j  1, x > 0, and sufficient large N,

P

Z¯ (Nj )

N

1 2

+



x

F2(jN)



c1

e-c2

N

(

1 2

-)/5

e-c3

x1/5

,

where c1, c2, c3 > 0 are constants. Also, there exists an N such that for all N  N,



c1

e-c2

N(

1 2

e -)/5 -c3 x1/5

dx

0



4

×

x 2l  ( x,

N)

.

Take any N  N. We will use Lemma 3.5 with trivial indexing set R and

(4.31)



=

1 5

,

a

=

2l



x (x,

N)

,

n

=

l(x, N),

and

^ j

=

Z¯ (Nj )

N

1 2

+

with

starting

configuration

( I ( N ) (0),

Q2(N)(0),

Q¯ 3(N)(0))

=

(0,

2B

N

1 2

+

,

0),

and

associated

filtra-

tion Fj : j  1 being the natural filtration generated by the above random variables. Thus, we

get

P

(0,

2BN

1 2

+

,

0)

 l  ( x, N )-1
Z¯ (Nj )
j=0



x

N

1 2

+

2

=P

n
 ^ j  an
j=0

 c1 1 +

l(x, N) 5/11

x

1 11

2l  (x, N )

exp

- c2

x2

1/11

4l(x, N)



c^1 N

1 2

-

exp

- c^2

x

N

1 2

-

1/11

.

(4.32)

38

Moreover, for any k  1, from Lemma 3.9 (i),

P

(0,

2B

N

1 2

+,

0)

 l  ( x, N )-1
Z¯ (Nj )
j=0



x

N

1 2

+

2

 l(x, N)P Z¯ (N0 ) > 0



c1xN

1 2

-

exp

-

c2

N(

1 2

-)/5

.

(4.33)

Using (4.32) and (4.33) and proceeding exactly as in deriving (4.10) from (4.9), we obtain

P
(0,

2B

N

1 2

+

,

0)

 l(x,N)-1
Z¯ (Nj )
j=0



x

N

1 2

+

2

 c1 exp

-

c2

N(

1 2

-)/11

exp

- c2

x

N

1 2

-

1/11
,

(4.34)

for

positive

constants

c1, c2.

Plugging

(4.34)

into

(4.30),

we

have

that

for

all

N



N,

x



2N

1 2

-

,

P
(0,

2B

N

1 2

+

,

0)

sup

sup Q¯ 3(N)(s)

0il(k,N) s[2(iN),2(iN+)2]



x

N

1 2

2

+

,

Z¯ (N0

)

>

0

 c1 exp

-

c2

N(

1 2

-)/11

exp

- c2

x

N

1 2

-

1/11

.

(4.35)

 Moreover, plugging (4.35) and (4.29) (with k =  x) into (4.28), we have that for sufficiently

large

N,

for

x



2

N

1 2

-

,

P

(0,

2BN

1 2

+

,

0)

s(N)(x

+

N

1 2

-)

<





c¯ exp c¯ exp

- -

c¯ 2c¯

N(

1 2

-)/11

+

x1/44 + c¯e-c¯

N

1 2

x.

x
-

1/11

+

c¯e-c¯

 x

(4.36)

Equations (4.26), (4.27) and (4.36) imply that there exist N0  N and positive constants C1 , C2 such that for all N  N0,

P

(0,

2B

N

1 2

+

,

0)

s(N)(x

+

N

1 2

-

)

<





C1 exp C1 exp

- C2 x1/5 ,

4B



x



2N

1 2

-

,

- C2 x1/44 ,

x



2N

1 2

-.

(4.37)

Thus, the theorem follows upon using (4.37) and Corollary 4.4 in (4.25).

5 Proof of process-level limit
In this section, we will analyze the process-level limit of the scaled occupancy process, and in particular, prove Theorem 2.4. The main ingredient in establishing Theorem 2.4 is to analyze the idle-server process I(N). We start with the martingale representation of the process X(N).

39

Martingale representation. Let A(·) and D(·) be two independent unit-rate Poisson processes.

We will write the arrival and departure processes as random time change of A and D respectively;

see [25, Section 2.1]. Hence, the arrival and departure processes can be written as A(NNt) (recall

N

=

1-

N



1 2

+

)

and

D

N2 0

t

(

N

-

I(N)(s))ds

respectively. Let us introduce the related filtrations

F = FN,t : N  N, t  [0, ] where

FN,t :=  S(N)(0), A(N1+2N s), D

N2s
(N

-

I(N)(u))du

,0st

,

t  0,

0

(5.1)

and FN, := (t0FN,t). Recall X(N)(t) =

S(N)(N2t) - N

/

N

1 2

+

,

t



0,

where S(N)

is

the

total queue length process. We write

X(N)(t)

-

X(N)(0)

=

N

-

1 2

-

A(N1+2Nt) - D

N2t
(N

-

I(N)(s))ds

0

= M(aN)(N t) - M(dN)

t

-

1 N1+2

N2t I(N)(s)ds
0

+

1

N

1 2

+

N2t I(N)(s)ds -
0

t 0

1 X(N)(s)

ds

- t +

t 0

1 X(N)

(s)

ds

(5.2) (5.3) (5.4)

where

M(aN)(t) =

A(N1+2t) -

N

1 2

+

N1+2

t

,

M(dN)(t)

=

D(N1+2t) -

N

1 2

+

N1+2

t

.

Note that M(aN)(t) and M(dN)(t) are martingales adapted to the filtration F. We will proceed by first showing in Proposition 5.4 that the integral in (5.2) converges to 0 uniformly on any

(scaled) finite time interval. Using this, we will be able to show that the difference of martingales in (5.2) convergence weakly to 2W as N  , where W is the standard Brownian motion. The

next major challenge is to show that the difference of the two terms in (5.3) converges to 0 as

N  . This is achieved in Proposition 5.5. Finally, a continuous mapping theorem-type result

will complete the proof of Theorem 2.4.

In its core, the analysis of I(N) will be done by upper and lower bounding it with suitable

birth-and-death processes. Now, for any fixed B > 0, recall the stopping time 2(N)(B) from (3.1)

and

the

process

I¯B(N)

from

(3.2),

and

note

that

if

Q2(N)(0)

>

BN

1 2

+

,

then

for

all

t



2(N)(B),

I(N)(t)

can we

be stochastically upper bounded assume N to be large enough so

by I¯B(N that N

)>(t)BwNit21h+I¯B(>N

)

(0) N

=

1 2

-

I .

(N)(0). As before, throughout We emphasize that, unlike in

Section 3, we will be interested in small values of B for the process level limit and thus cannot

directly apply the estimates in Section 3 which deals with large values of B.

Lemma 5.1. There exist N0, a, b > 0 depending only on T, B, and , such that for all N  N0 and  > 0,

P

sup
0tN2T

I¯B(N)(t)



5 2

N

1 2

-+

I¯B(N)(0) = 0


 ae-bN 2 .

40

Proof. The proof follows in three steps: first, we upper bound the tail probability of the stationary distribution of I¯B(N). Next, we upper bound the tail probability of sup0tN2T I¯B(N)(t) when I¯B(N)(0) is a random variable having the same distribution as the steady state of I¯B(N), and finally, we consider sup0tN2T I¯B(N)(t) when I¯B(N)(0) = 0.
Claim 5.2. Let I¯B(N)() denote a random variable having stationary distribution of I¯B(N). Then there exist constants N0 , a1 and b1, that only depend on B and , such that for all N  N0 ,

P

I¯B(N)()



N

1 2

-+

 a1e-b1N .

Proof. Note that the stationary distribution of I¯B(N) is given by P(I¯B(N)(t) = k) = (1 - )k for

k



0,

where



=

N-BN N-N

1 2 1 2

+ -

.

Therefore,

there

exists

N0

>

0

such

that

for

all

N



N0 ,

P

I¯B(N)()



N

1 2

-+

=

N

-

B

N

1 2

+

N

-

N

1 2

-

N

1 2

-+

=

1

-

B

N

1 2

+

N-

-

N

1 2

-



N

1 2

-

N

1 2

-+



a1e-b1N ,

for appropriate constants a1 and b1 that depend only on B and .

Claim 5.3. Assume that {I¯B(N)(t), t  0} is an equilibrium process. Then there exist positive constants N1, a2, and b2 which only depend on T, B and  such that for all N  N1,

P

sup
0t N 2 T

I¯B(N)(t)



5 2

N

1 2

-+



a2

e-b2

N

 2

.

Proof.

Let

j

=

 N2T

N

--

1 2

+



and

consider

the

times

ti

=

i

N

--

1 2

+

,

i

=

0,

1,

...,

j

-

1.

Denote the num-

ber

of

increments

in

I¯B(N)

in

a

subinterval

[ti, ti+1)

by



(N) i

.

Then



(N) i

has

a

Poisson

distribution

with parameter

N

1 2

-+

-

BN.

For any

Poisson random variable

Po()

with parameter ,

we

have (see [22, Theorem 2.3(b)]) that for 0    1,

P(Po()

-





)



e-

3 8

2



.

Hence, for all i = 0, 1, ..., j - 1,

P

i(N) 

3 2

N

1 2

-+

P

Po(N

1 2

-+)



3 2

N

1 2

-+

 e . -

3 32

N

1 2

-+

Take N0 as in Claim 5.2. Since we are considering the equilibrium process, due to Claim 5.2, we know for all N  N0 and t  0,

P

I¯B(N)(t)



N

1 2

-+

 a1e-b1N .

Now, note that

sup I¯B(N)(t)
ti tti+1



5 2

N

1 2

-+



I¯B( N ) (ti )



N

1 2

-+





(N) i



3 2

N

1 2

-+

,

41

for i = 0, 2, ..., j - 1, and we have,

  P

sup
0tN2T

I¯B(N)(t)



5 2

N

1 2

-+

j-1



P

I¯B( N ) (ti )



N

1 2

-+

i=0

j-1
+P
i=0



(N) i



3 2

N

1 2

-+



N

1 2

+3-T

+

1

+ a1 e-b1 N 

e-

3 32

N

1 2

-+

.

Thus, there exist constants a2, b2 > 0, and N1  N0 , which depend only on B, , and T, such that

for all N  N1,

P

sup
0t N 2 T

I¯B(N)(t)



5 2

N

1 2

-+


 a2e-b2N 2 .

Finally, the proof for I¯B(N)(0) = 0 follows from Claim 5.3 by observing that for any k  1,

P

sup
0t N 2 T

I¯B(N)(t)



5 2

N

1 2

-+

I¯B(N)(0) = 0

P

sup
0t N 2 T

I¯B(N)(t)



5 2

N

1 2

-+

I¯B(N)(0) = k .

This completes the proof of the lemma.

Proposition

5.4.

Fix

any

T

>

0

and 0

<



<

1 2

+ ,

and

take

N0

as

in

Lemma

5.1.

For

any

K1

>

0,

there

exist

constants

N1,

a,

b

>

0

that

depend

only

on

B,

,

and

T,

such

that

for

all

N



N1,

x



K1 N

1 2

-,

y



B

N

1 2

+

,

sup P(x,y,z)

sup

I(N)(t)



5N

1 2

-+



ae-b

N

 2

,

(5.5)

z

0 t ( N 2 T )2( N ) ( B )

and consequently, for all ~ > 0,

lim
N

sup
z

P(x,y,z)

1 N1+2

(N2T)2(N)(B) I(N)(s)ds  ~
0

= 0.

(5.6)

Proof.

Recall N0 as in Lemma 5.1.

Take N1



N0

such

that

5 2

N

1 2

-+



K1

N

1 2

-

and

consider

N



N1.

Note

that

for

any

x



K1

N

1 2

-

,

y



B

N

1 2

+

and

z



N0

with

z1



z2



.

.

.

,

P(x,y,z)

sup

I(N)(t)



5N

1 2

-+

0 t ( N 2 T )2( N ) ( B )

P

sup

K1 N

1 2

-

+

I¯B(N)(t)



5N

1 2

-+

0t N 2 T

P

sup
0t N 2 T

I¯B(N)(t)



5 2

N

1 2

-+

ae-bN

 2

.

42

The first inequality follows from the fact that for t  2(N)(B), the process I(N)(·) starting from

x



K1

N

1 2

-

is

stochastically

dominated

by

K1

N

1 2

-

+

I¯B(N)(·).

The last inequality follows from

Lemma

5.1.

Next,

for

all

N



N1,

x



K1

N

1 2

-,

y



B

N

1 2

+,

and

feasible

z,

P(x,y,z)

1 N1+2

( N 2 T )2( N) ( B)

I(N)(s)ds



5

N

-

1 2

-+

T

0

 P(x,y,z)

sup

I(N)(s)



5N

1 2

-+

0 s ( N 2 T )2( N ) ( B )



ae-bN

 2

,

and

thus,

(5.6)

holds

for

any

0

<



<

1 2

+

.

Proposition 5.5. Under the assumptions on the initial conditions stated in Theorem 2.4, the following holds as N  :

sup
0t T ( N -22( N) ( B))

1

N

1 2

+

N2t I(N)(s)ds -
0

t 0

X

1 (N)(s)

ds

-P 0.

The proof of Proposition 5.5 is given in Appendix A.

Lemma 5.6. The stochastic differential equation

dX(t) =

1 X

-



 dt + 2dW(t),

(5.7)

with X(0) > 0, has a path-wise unique strong solution. Also, if  := inf{t > 0 : X(t)  },  > 0, and  := lim0 , then  =  almost surely.

Proof. For  > 0, the process X(t), for t   satisfies an SDE with Lipschitz coefficients. Such SDE are known to have path-wise unique strong solutions (see [27, Theorem V.11.2]).
Next, to show that  =  almost surely, consider the SDE

dX^ (t)

=

1 X^ (t)

+

 2dW(t),

and define the analogous quantities ^, 

>

0, and ^

for X^ .

Note that

X^(t) 2

is a Bessel process

of dimension 2. By Girsanov's Theorem, we can add and remove the drift t to X^ with an

exponential change of measure. Hence, the law of X and that of X^ are mutually absolutely

continuous on compact time intervals. For n  2, the n-dimensional Bessel process is transient

from its starting point with probability one, i.e., the n-dimensional Bessel process will be greater

than 0 for all t > 0 almost surely [16]. Thus, for any a > 0, P(  a) = P(^  a) = 0. Therefore,

 =  almost surely.

Proof of Theorem 2.4. We will proceed as in the proof of [12, Theorem 1], using Proposition 5.5 stated above in place of their Proposition EC.3. Recall the martingale representation of X(N)

43

in (5.2)­(5.4). First consider (5.2). By the assumption on N and Proposition B.1, we have that, as

N  ,

Nt



t

and

t

-

1 N1+2

N2t I(N)(s)ds -P t,
0

uniformly on the interval [0, T]. By the Martingale FCLT [29] and the independence of Ma and Md, we have that as N  ,

M(aN)(N t) - M(dN)

t

-

1 N1+2

N2t I(N)(s)ds
0

:t0



 2W(t) : t  0 ,

where W is a standard Brownian motion. Next, we will consider (5.3). For any fixed B > 0, define ^(N)(B) := inf{t  0 : X(N)(t)  B} and ^(B) := inf{t  0 : X(t)  B}, where X(t) is the unique strong solution to the S.D.E. (5.7) with initial value X(0) > 0. The claim below establishes a relation between ^ (N) and 2(N).
Claim 5.7. For any fixed B > 0,

lim P
N

N2^(N)(B)  (N2T)  2(N)(B)  (N2T)

= 1.

Proof. First, note that on the event 2(N)(B)  N2T , trivially,

N2^(N)(B)  (N2T)  2(N)(B)  (N2T).

Now, on the event N2 T,

2(N)(B) < N2T  sup0tN2T Q3(N)(t) = 0 , we have that for 0  t  S(N)(t) - N = Q2(N)(t) - I(N)(t)  Q2(N)(t),

and thus,

S(N)(2(N)(B))

-

N



Q2(N)(2(N)(B))

=

B

N

1 2

+

,

which implies that N2^ (N)(B)  2(N)(B). Hence, we have

P N2^(N)(B)  (N2T)  2(N)(B)  (N2T)  P sup Q3(N)(t) = 0 .
0t N 2 T

(5.8)

By Proposition 3.15, the right hand side of (5.8) tends to 1 as N  .

Using Claim 5.7 and Proposition 5.5, we can conclude

sup
0t^ ( N) ( B)T

1

N

1 2

+

N 2 t
I(N)(s)ds -
0

t 0

1 X(N)

(s)

ds

-P 0

as

N  .

Therefore, defining

(N)(t)

:=

1

N

1 2

+

N 2 t
I(N)(s)ds -
0

t 0

X

1 (N)(s)

ds,

t



0,

44

(when the integrals are well defined) we have that for any fixed B > 0, the process (N)(t  ^(N)(B)) : t  0 converges weakly to a process that is identically equal to 0, as N  .
Also, recall that X(N)(0) -P X(0) where X(0) is a positive constant. Thus, by the Skorohod representation theorem, there exists a probability space (, F , P) such that, almost surely, the following convergence holds

X(N)(0),

M(aN)(N t) - M(dN)

t

-

1 N1+2

N2t I(N)(s)ds ,
0

(N)(t  ^(N)(K-1)  ^(K-1)

-u-.o.c

 X(0), 2W(t), 0 : t  [0, T], K  N

as N  ,

: t  [0, T], K  N

(5.9) (5.10)

where `u.o.c.' denotes convergence of the associated processes uniformly on compact subsets of [0, T], and the above random variables are seen as R+ × D [0, T] : R2 N valued random
variables. For K  N, define the event

K

:=

{ inf X(s)
t[0,T]



K-1}.

By Lemma 5.6, limK P (K) = 1. Let

b(N)(t) := M(aN)(N t) - M(dN)

t

-

1 N1+2

N2t I(N)(s)ds
0



and b(t) := 2W(t). Define the following subsets of :

+ (N)(t)()

S(,NK) :=

X(N)(0) - X(0) +

sup

b(N)(s) - b(s) <  ,  > 0, K  N.

0s T ^ ( N)(K-1 )^ (K-1 )

By (5.10), for any  > 0, K  N, limN P S(,NK) = 1. Using the triangle inequality, we have that for all t  [0, T  ^(N)(B)  ^(B)],

X(N)(t) - X(t)



X(N)(0) - X(0)

+

b(N)(t) - b(t)

+

t 0

1 X(N)(s)

-

1 X(s)

ds.

Observe that, for any B > 0, the map x  x-1 is Lipschitz on [B, ) with Lipschitz constant B-2. Thus, for t  [0, T  ^(N)(K-1/2)  ^(K-1/2)],

sup X(N)(s) - X(s)

0st

 X(N)(0) - X(0) + sup b(N)(s) - b(s) + 4K2

t
sup

X(N)(s) - X(s)) dµ.

0st

0 0sµ

Applying Gronwall's inequality (see [25, Lemma 4.1]), we have on the set S(,N2K),

sup

|X(N)(t) - X(t)|  e4K2T.

0t T ^ ( N)(K-1 /2)^ (K-1 /2)

45

Set



=

K

=

X(0) 2



1 4K

e-4K2

T

.

Let

K0

:=

4/X(0).

Take

any

K



K0.

The

above

bound implies

that,

on

the

event

S(KN,2)K ,

X(N)(s)

>

1 2K

for

all

s



[0, T

 ^(N)(K-1/2)  ^ (K-1/2)].

Moreover,

on

K, ^ (K-1/2)  ^ (K-1)  T. Hence, on K  S(KN,2)K, ^(N)(K-1/2)  ^(K-1/2) > T. Thus, the

above bound gives on the event K  S(KN,2)K,

sup |X(N)(t)
0tT

-

X(t)|



1 4K

.

Therefore, for any K  K0,

lim sup P
N

sup |X(N)(t)
0tT

-

X(t)|

>

1 4K

 P (cK) + lim sup P
N

S(KN,2)K c = P (cK ) .

On recalling limK P (K) = 1, we obtain
sup |X(N)(t) - X(t)| -P 0 as N  ,
0tT
proving the theorem.

Proof of Proposition 2.5. Write the SDE as

dX(t) =

1 X

-



dt

+

 2dW(t)

=

 2dW(t)

-

V(X)dt,

where V(X) is a function with derivative

(5.11)

V(X) = - 1 + . X

The diffusion (5.11) is a Langevin diffusion and, for any B > 0, it has an invariant measure with

density

given

by

d~ dx

=

exp{-V(x)},

where

V(x) =

x B



-

1 u

du

=

(x - B) + [ln B - ln x]

=

(x - B) + ln

B x

,

x

>

0.

Therefore, we have an invariant distribution (x) with density

d = C x e-(x-B), dx B

where

C

satisfies

that

1 C

=

 0

x B

e-(x-B)dx

=

e 2

B
B

.

The

computation

of

moments

of



is

routine.

This completes the proof.

46

References
[1] Ivo Adan and Jacques Resing. Queueing Systems. Eindhoven University of Technology, 2015.
[2] Rami Atar. A diffusion regime with nondegenerate slowdown. Oper. Res., 60(2):490­500, 2012.
[3] Sayan Banerjee and Debankur Mukherjee. Join-the-shortest queue diffusion limit in HalfinWhitt regime: Tail asymptotics and scaling of extrema. Ann. Appl. Probab., 29(2):1262­1309, 2019.
[4] Sayan Banerjee and Debankur Mukherjee. Join-the-shortest queue diffusion limit in HalfinWhitt regime: Sensitivity on the heavy traffic parameter. Ann. Appl. Probab., 30(1):80­144, 2020.
[5] P. Billingsley. Probability and Measure. Wiley Series in Probability and Statistics. Wiley, 2012.
[6] Anton Braverman. Steady-state analysis of the join the shortest queue model in the HalfinWhitt regime. Math. Oper. Res., 45(3):1069­1103, 2018.
[7] Amarjit Budhiraja, Eric Friedlander, and Ruoyu Wu. Many-server asymptotics for Join-theShortest-Queue: Large deviations and rare events. arXiv:1904.04938, 2019.
[8] Anthony Ephremides, P Varaiya, and Jean Walrand. A simple dynamic routing problem. IEEE Trans. Autom. Control, 25(4):690­693, 1980.
[9] Patrick Eschenfeldt and David Gamarnik. Join the shortest queue with many servers. The heavy traffic-asymptotics. Math. Oper. Res., 43(3):867­886, 2018.
[10] G. Foschini and J. Salz. A basic dynamic routing problem and diffusion. IEEE Trans. Commun., 26(3):320­327, 1978.
[11] G J Foschini. On heavy traffic diffusion analysis and dynamic routing in packet switched networks. Comp. Perf., pages 499­513, 1977.
[12] Varun Gupta and Niel Walton. Load balancing in the non-degenerate slowdown regime. Oper. Res., 67(1):281­294, 2019.
[13] P.J. Hunt and T.G. Kurtz. Large loss networks. Stoch. Proc. Appl., 53(2):363­378, 1994.
[14] Daniela Hurtado-Lange and Siva Theja Maguluri. Load balancing system under Join the Shortest Queue: Many-server-heavy-traffic asymptotics. arXiv:2004.04826, 2020.
[15] Daniela Hurtado-Lange and Siva Theja Maguluri. Load balancing system in the many-server heavy-traffic asymptotics. Preprint, 2021.
[16] Makoto Katori. Bessel process, Schramm-Loewner evolution, and Dyson model, 2011.
47

[17] László Lakatos, Laszlo Szeidl, and Miklos Telek. Introduction to queueing systems with telecommunication applications. Springer, 2019.
[18] Robert Liptser and Albert Nikolaevich Shiryayev. Theory of martingales, volume 49. Springer Science & Business Media, 2012.
[19] Xin Liu and Lei Ying. A simple steady-state analysis of load balancing algorithms in the sub-Halfin-Whitt regime. ACM SIGMETRICS Perform. Eval. Rev., 46(2):15­17, 2019.
[20] Xin Liu and Lei Ying. On universal scaling of distributed queues under load balancing. arXiv:1912.11904, 2019.
[21] Costis Maglaras, John Yao, and Assaf Zeevi. Optimal price and delay differentiation in large-scale queueing systems. Manage. Sci., 64(5):2427­2444, 2018.
[22] Colin McDiarmid. Concentration. In Michel Habib, Colin McDiarmid, Jorge RamirezAlfonsin, and Bruce Reed, editors, Probabilistic Methods for Algorithmic Discrete Mathematics, pages 195­248. Springer Berlin Heidelberg, 1998.
[23] Debankur Mukherjee, Sem C. Borst, Johan S. H. Van Leeuwaarden, and Philip A. Whiting. Universality of load balancing schemes on the diffusion scale. J. Appl. Probab., 53(4), 2016.
[24] Debankur Mukherjee, Sem C Borst, Johan S H van Leeuwaarden, and Philip A Whiting. Universality of Power-of-d Load Balancing in Many-Server Systems. Stoch. Syst., 8(4):265­ 292, 2018.
[25] Guodong Pang, Rishi Talreja, and Ward Whitt. Martingale proofs of many-server heavytraffic limits for markovian queues. Probab. Surveys, 4:193­267, 2007.
[26] Martin I. Reiman. Some diffusion approximations with state space collapse. In Modelling and performance evaluation methodology, pages 207­240. Springer, Berlin, Heidelberg, 1984.
[27] L. C. G. Rogers and David Williams. Diffusions, Markov Processes, and Martingales, volume 1 of Cambridge Mathematical Library. Cambridge University Press, 2 edition, 2000.
[28] M. van der Boor, S.C. Borst, J.S.H. van Leeuwaarden, and D. Mukherjee. Scalable load balancing in networked systems: A survey of recent advances, 2018.
[29] Ward Whitt. Proofs of the martingale FCLT. Probab. Surveys, 4, 2007.
[30] Wayne Winston. Optimality of the shortest line discipline. J. Appl. Probab., 14(1):181­189, 1977.
[31] Hanqin Zhang, Guang-Hui Hsu, and Rongxin Wang. Heavy traffic limit theorems for a sequence of shortest queueing systems. Queueing Syst., 21(1):217­238, 1995.
48

A Proof of Proposition 5.5

In this appendix, we will prove Proposition 5.5. Recall that I(N) has instantaneous transition rates at time t as follows:

I(N)(t)  I(N)(t) + 1 at rate Q1(N)(t) - Q2(N)(t),

I(N)(t)



(I(N)(t)

-

1)+

at

rate

N

-



N

1 2

-

.

(A.1)

Note

that

I(N)(0)



K1

N

1 2

-

and

Q2(N)(0)



K2

N

1 2

+

,

as

stated

in

Theorem

2.4.

As before, fix

any

B

>

0

and

we

will

consider

N

to

be

large

enough

so

that

N

>

B

N

1 2

+

>



N

1 2

-

.

Define

the

following stopping times: 0(N) = 0 and for i  0,



(N) 2i+1

=

inf

t  2(Ni ) : I(N)(t) = 0 ,



(N) 2i+2

=

inf

t  2(Ni+)1 : I(N)(t) > 0

.

(A.2)

Also, let iN := min i  0 : 2(Ni+)3  2(N)(B)  (N2T) . For convenience, denote T(N, B) := 2(N)(B)  (N2T). In the following, the set {0, -1} is assumed to be the null set.

Lemma

A.1.

For

any

0

<



<

1 2

- ,

there

exist

constants

a1, b1, N1

>

0,

such

that

for

all

N



N1,

sup

P(x,y,0)

xK1

N

1 2

-

,

B

N

1 2

+

<yK2

N

1 2

+

i

0, ..., iN - 1

such that 2(Ni+)3 - 2(Ni+)1  2N-2



a1

e-b1

N

 5

.

(A.3)

The following technical lemma from [12] will be used in the proof of Lemma A.1.

Lemma A.2 ([12, Lemma EC.18]). Let Q be the length of an M/M/1 queue with arrival rate  and service rate µ, with µ > . Also, let T~ be the length of the renewal cycle from the queue being of length 1
to the queue being empty. Then, for t  0,

P T~  t 

µ 

e-(µ-)2

t

.

49

Proof of Lemma A.1. Note that for any i  0,

sup

P

x

K1

N

1 2

-

,

BN

1 2

+

<yK2

N

1 2

+

2(Ni+)3 - 2(Ni+)1  2N-2, i < iN



sup

P(x,y,0)

x

K1

N

1 2

-

,

BN

1 2

+

<yK2

N

1 2

+

sup

Q2(N)(t)



N

1 2

++

0tT(N,B)

+

sup

P(x,y,0)

xK1

N

1 2

-

,

B

N

1 2

+

<yK2

N

1 2

+



(N) 2i+2

-

2(Ni+)1



N-2,

sup

Q2(N)(t)

<

N

1 2

++,

i

<

iN

0tT(N,B)

+

sup

P(x,y,0)



(N) 2i+3

-

2(Ni+)2



N-2,

sup

Q2(N)(t)

<

N

1 2

++,

i

<

iN

.

xK1

N

1 2

-

,

0tT(N,B)

B

N

1 2

+

<yK2

N

1 2

+

(A.4)

For the first term of the right hand side of (A.4), take any K~  K2 large enough such that the bound in Proposition 3.15 holds with 2B there replaced by K~ for large enough N. Also assume
that N is large enough such that N > xK~/2, where the latter constant appears in Proposition 3.15. For such large enough N, we obtain constants c1 and c2 such that

sup

P(x,y,0)

xK1

N

1 2

-

,

BN

1 2

+

<yK2

N

1 2

+

sup

Q2(N)(t)



N

1 2

++

0tT(N,B)

P(0,K~ N

1 2

+

,0)

sup

Q2(N)(t)



N

1 2

++

0tT(N,B)

 exp{-c¯TN} + TN c¯1 exp c1 e-c2 N/5,

-

c¯2

N(

1 2

-)/5

+

c1

exp{-c2

N}

+

c3

exp{-c4

N

4 5

N

 5

}

(A.5)

where the second inequality is from Proposition 3.15. For the second term in (A.4), there exist constants c3 and c4 such that for large enough N and any i  0,

sup

P(x,y,0)

xK1

N

1 2

-,

B

N

1 2

+

<yK2

N

1 2

+

2(Ni+)2

-



(N) 2i+1



N-2,

sup

Q2(N)(t)

<

N

1 2

++,

i

<

iN

0tT(N,B)

P

Exp(N

-

N

1 2

++

)



N-2

 c3 e-c4 N+1-2,

(A.6)

where

Exp(N

-

N

1 2

++)

is

an

exponential

random

variable

with

rate

N

-

N

1 2

++.

The first

inequality in (A.6) is due to the fact that the rate of increase of I(N)(t) when I(N)(t) = 0 is

N - Q2(N). Now, consider the last term in the right hand side of (A.4). Recall the evolution of the

process

I(N)(t)

as

in

(A.1).

For

t



2(N)(B),

Q1(N)(t)

-

Q2(N)(t)



N

-

B

N

1 2

+

,

and

thus,

there

is

a

50

natural coupling so that the process I(N) is upper bounded by an M/M/1 queue, Q, with arrival

rate



:=

N

-

B

1 2

+

and

service

rate

µ

:=

N

-

N

1 2

-

.

Therefore,

for

any

i



0,

sup

P 2(Ni+)3 - 2(Ni+)2  t, i < iN

x

K1

N

1 2

-

,

BN

1 2

+

<yK2

N

1 2

+

 P T~  t ,

(A.7)

where T~ for the process Q is as defined in Lemma A.2. Now, note that there exists N0 > 0 such that for all N  N0,

µ= 

 µ

-

 

2

=

N

-

N

1 2

-

N

-

B

1 2

+



2

N

-

N

1 2

-

-

N

-

BN

1 2

+

2

(A.8)

=

N

-

N

1 2

-

1-

1

-

B - N-2

N

1 2

-

-

N-2

2



B2 32

N2

,

where

the

last

inequality

is

due

to

the

facts

that

 1- 1

-

x



x 2

,

for

x



(0, 1),

and

for

all

N



N0,

N

-

N

1 2

-



N 2

and

B-N-2

N

1 2

--



N

-2



B 2

N

-

1 2

.

Thus,

plugging

(A.8)

into

Lemma

A.2,

we

get

for

any

t  0, i  0,

sup

P 2(Ni+)3 - 2(Ni+)2  t, i < iN

xK1

N

1 2

-,

B

N

1 2

+

<yK2

N

1 2

+

 P T~  t



2e-

B2 32

N2t.

(A.9)

Plugging (A.5), (A.6), and (A.9), into (A.4), we obtain constants c5 and c6 such that for any i  0,

sup

P

x

K1

N

1 2

-

,

B

N

1 2

+

<yK2

N

1 2

+

2(Ni+)3 - 2(Ni+)1  2N-2, i < iN

c1 e-c2 N/5

+

c3 e-c4 N+1-2

+

2e-

B2 32

N





c5 e-c6 N/5.

(A.10)

To prove (A.3), note that the value of iN is upper bounded by the number of increments in I(N) in the interval [0, 2(N)(B)  (N2T)], which is stochastically upper bounded by a Poisson random variable with parameter N1+2T. Hence, using standard concentration inequality for Poisson random variables (see [22, Theorem 2.3(b)]), we have

sup

P

xK1

N

1 2

-

,

B

N

1 2

+

<yK2

N

1 2

+

iN



3 2

N1+2

T

P

Po( N1+2 T )



3 2

N1+2

T



e-

3 32

N1+2

T

,

(A.11)

51

and therefore, using (A.10), there exists N1  N0, depending on T, such that for all N  N1,

sup

P(x,y,0)  i 

xK1

N

1 2

-,

B

N

1 2

+

<yK2

N

1 2

+

0, ..., iN - 1

such that 2(Ni+)3 - 2(Ni+)1  N-2



sup

xK1

N

1 2

-,

P(x,y,0)

iN



3 2

N1+2

T

+

B

N

1 2

+

<yK2

N

1 2

+

3 2

N1+2

T

· c5 e-c6 N/5



e-

3 32

N1+2

T

+

3 2

N1+2

T

× c5 e-c6 N/5  a1e-b1 N/5,

(A.12)

where a1 and b1 are appropriate constants.

Now that we have proved that the time of each excursion of the idleness process is short with high probability, we can now show that the fluctuation of S(N) within each of these excursions is
not too large.

Proposition

A.3.

For

any

0

<



<

1 2

- ,

there

exist

constants

N2, a2, b2

>

0,

such

that

for

all

N



N2,

sup

P(x,y,0)

xK1

N

1 2

-

,

B

N

1 2

+

<yK2

N

1 2

+

sup

sup

S(N)(t) - S(N)(2(Ni+)1)



13N

1 2

-+

i{0,...,iN-1} 2(iN+)1t2(iN+)3


 a2e-b2N 5 .

Proof. Define the event w(N) :=

sup0tT(N,B)

Q2(N)(t)

<

N

1 2

++

. Then

sup

P(x,y,0)

xK1

N

1 2

-

,

B

N

1 2

+

<yK2

N

1 2

+

sup

sup

S(N)(t) - S(N)(2(Ni+)1)



13N

1 2

-+

i{0,...,iN-1} 2(Ni+)1t2(Ni+)3



sup

P(x,y,0)

xK1

N

1 2

-

,

B

N

1 2

+

<yK2

N

1 2

+

sup

Q2(N)(t)



N

1 2

++

0tT(N,B)

+

sup

P(x,y,0)

xK1

N

1 2

-

,

BN

1 2

+

<yK2

N

1 2

+

sup

sup

S(N)(t) - S(N)(2(Ni+)1)



3N

1 2

-+,

w(N)

i{0,...,iN-1} 2(Ni+)1t2(Ni+)2

+

sup

P(x,y,0)

xK1

N

1 2

-

BN

1 2

+

<yK2

N

1 2

+

sup

sup

S(N)(t) - S(N)(2(Ni+)2)



10N

1 2

-+,

w(N)

.

i{0,...,iN-1} 2(Ni+)2t2(Ni+)3

(A.13)

By (A.5), for all large enough N,

sup

P(x,y,0)

xK1

N

1 2

-

,

B

N

1 2

+

<yK2

N

1 2

+

sup

Q2(N)(t)



N

1 2

++

0tT(N,B)

 c1 e-c2 N/5 .

(A.14)

52

For the second term in the right hand side of (A.13),

sup

P(x,y,0)

xK1

N

1 2

-

,

B

N

1 2

+

<yK2

N

1 2

+

sup

sup

S(N)(t) - S(N)(2(Ni+)1)



3N

1 2

-+

,

w(N)

i{0,...,iN-1} 2(iN+)1t2(iN+)2



sup

P(x,y,0)

xK1

N

1 2

-

,

B

N

1 2

+

<yK2

N

1 2

+

sup

2(Ni+)2

-



(N) 2i+1



N-

1 2

-+,

w(N)

i{0,...,iN-1}

+

sup

P(x,y,0)

xK1

N

1 2

-

,

BN

1 2

+

<yK2

N

1 2

+

sup

sup

S(N)(t) - S(N)(2(Ni+)1)



3N

1 2

-+,

w(N),

w~ (N)

,

i{0,...,iN-1} 2(iN+)1t2(iN+)2

(A.15)

where w~ (N) :=

supi{0,...,iN-1}

2(Ni+)2

- 2(Ni+)1

<

N

-

1 2

-+

. Since the instantaneous rate of increase

of I(N) when I(N)(t) = 0 is N - Q2(N), then for each i  {0, ..., iN - 1}, 2(Ni+)2 - 2(Ni+)1 is upper

bounded by an exponential random variable,

Exp(N

-

N

1 2

++).

Hence, proceeding along

the

same line as (A.6), (A.11) and (A.12), there exist constants c1, c2 such that for large enough N,

sup

P(x,y,0)

xK1

N

1 2

-,

B

N

1 2

+

<yK2

N

1 2

+

sup

2(Ni+)2

-



(N) 2i+1



N

-

1 2

-+,

w(N)

i{0,...,iN-1}



P(iN



3 2

N1+2

T)

+

3 2

N1+2

T

× e-(

N-

N

1 2

++)

-
N

1 2

-+



e-

3 32

N1+2

T

+



c1

e-c2

N

1 2

-+

.

3 2

N1+2

T

× e-(

N

-N

1 2

++)

N

-

1 2

-+

(A.16)

For each i  {0, ..., iN - 1} and t  [2(Ni+)1, 2(Ni+)2),

S(N)(t) - S(N)(2(Ni+)1)



A

(N

-

N

1 2

-)t

-A

(N

-

N

1 2

-

)2(Ni+)1

+ D Nt

- D N2(Ni+)1

st Po 2N(2(Ni+)2 - 2(Ni+)1) ,

where Po() is a Poisson random variable with mean . Therefore, there exist constants c3 and c4 such that for all N large enough,

sup

P(x,y,0)

x

K1

N

1 2

-,

BN

1 2

+

<yK2

N

1 2

+

sup

sup

S(N)(t) - S(N)(2(Ni+)1)

i{0,...,iN-1} 2(Ni+)1t2(Ni+)2



P(iN



3 2

N1+2

T

)

+

3 2

N1+2

T

P

Po(2N

1 2

-+)



3N

1 2

-+



e-

3 32

N1+2

T

+

3 2

N1+2

T

×  e-

3 16

N

1 2

-+

c3

e-c4

N

1 2

-+

.



3N

1 2

-+,

w(N),

w~ (N)

(A.17)

53

Plugging (A.16) and (A.17) into (A.15), we have for all N large enough,

sup

P(x,y,0)

xK1

N

1 2

-,

BN

1 2

+

<yK2

N

1 2

+

sup

sup

i{0,...,iN-1} 2(iN+)1t2(iN+)2

c5

e-c6

N

1 2

-+

,

S(N)(t) - S(N)(2(Ni+)1)



3N

1 2

-+,

w(N)

(A.18)

where c5 and c6 are constants. Now, consider the third term of the right hand side of (A.13). For

any

x



K1

N

1 2

-

and

B

N

1 2

+

<

y



K2

N

1 2

+

,

P(x,y,0)

sup

sup

i{0,...,iN-1} 2(Ni+)2t2(Ni+)3

S(N)(t) - S(N)(2(Ni+)2)



10N

1 2

-+

 

P ( x,y,0) (iN

>

3 2

N1+2

T)

+



3 2

N 1+2 T -1 i=0

P(x,y,0)

sup

S(N)(t) - S(N)(2(Ni+)2)

2( Ni+)2 t2( Ni+)3



10N

1 2

-+

,

i  iN - 1



P ( x,y,0) (iN

>

3 2

N1+2

T)

+

P(x,y,0)

sup Q3(N)(t) > 0
t[0, N 2 T ]



3 2

N1+2

T

-1

 +

P(x,y,0)

i=0

sup

S(N)(t) - S(N)(2(Ni+)2)



10N

1 2

-+,

 2( Ni +)2  t  2( Ni +)3

sup Q3(N)(t) = 0, i  iN - 1 .
 2( Ni +)2  t  2( Ni +)3

(A.19)

Recall that, by (A.11),

sup

xK1

N

1 2

-

,

P(x,y,0)(iN

>

3 2

N1+2

T

)



e-

3 32

N

1+2

T

.

B

N

1 2

+

<yK2

N

1 2

+

(A.20)

By Proposition 3.15, there exist constants B0, c1, c2, N0 > 0, possibly depending on T, such that for all N  N0 ,

sup

P(x,y,0)

xK1

N

1 2

-

,

B

N

1 2

+

<yK2

N

1 2

+

sup Q3(N) > 0
t[0, N 2 T ]



P
(0, B0 N

1 2

+

,0)

sup Q2(N)(t) = N
t[0, N 2 T ]



c7

e-c8

N

(

1 2

-)/5

.

(A.21)

54

Next, for i  iN - 1 and t  [2(Ni+)2, 2(Ni+)3), observe that on the event supt[0,N2T] Q3(N)(t) = 0,

sup
t[2(iN+)2,2(iN+)3)

S(N)(t) - S(N)(2i+2)

 sup

I(N)(t) + Q2(N)(2(Ni+)2) - Q2(N)(2(Ni+)3)

t[ 2( Ni +)2 , 2( Ni +)3 )

 sup I(N)(t) + Q2(N)(2(Ni+)2).
t[ 2( Ni +)2 , 2( Ni +)3 )

Indeed, the inequalities are due to the fact that when there is no queue with length greater

than 3, the difference between S(N)(t) and S(N)(2i+2) is caused by the change of I(N)(t) and

the change of Q2(N)(t), and for t  [2(Ni+)2, 2(Ni+)3), I(N)(t) is always positive so Q2(N)(t) can only

decrease

during

[2(Ni+)2

,



(N) 2i+3

).

Now, consider the last term of (A.19).

For any

x



K1

N

1 2

-

and

BN

1 2

+

<

y



K2 N

1 2

+

,

any

i



0,

P(x,y,0)

sup

S(N)(t) - S(N)(2i+2)



10N

1 2

-+,

sup

Q3(N)(t) = 0, i  iN - 1

 2( Ni +)2  t  2( Ni +)3

 2( Ni +)2  t  2( Ni +)3

 P(x,y,0)

sup

I(N)(t)



5N

1 2

-+,

i



iN

-

1

 2( Ni +)2  t  2( Ni +)3

+ P(x,y,0)

Q2( N ) ( 2( Ni+)2 )



5N

1 2

-+

,

i



iN

-

1

.

(A.22)

Since



<

1 2

-

,

from

Proposition

5.4,

we

have

that

for

N



N0,

sup

P(x,y,0)

x

K1

N

1 2

-,

BN

1 2

+

<yK2

N

1 2

+

sup

I(N)(t)



5N

1 2

-+

,

i



iN

-

1

 2( iN+)2  t  2( iN+)3



sup

P(x,y,0)

xK1

N

1 2

-

,

B

N

1 2

+

<yK2

N

1 2

+

sup

I(N)(t)



5N

1 2

-+

0 t ( N 2 T )2( N ) ( B ))



ae-bN

 2

,

(A.23)

where a and b are positive constants depending on B,  and T only. Proceeding as in (A.5), by Proposition 3.15, there exist c1 , c2 , N0 > 0, such that for all N  N0 ,

sup

P(x,y,0)

xK1

N

1 2

-,

B

N

1 2

+

<yK2

N

1 2

+

sup

Q2(N)(t)



5N

1 2

++,

i



iN

-

1

 2( Ni +)2  t  2( Ni +)3



sup

P(x,y,0)

xK1

N

1 2

-,

BN

1 2

+

<yK2

N

1 2

+

sup

Q2(N)(t)



5N

1 2

++

0t( N 2 T )2( N) ( B))

 c1 e-c2 N/5 .

(A.24)

Hence, plugging (A.23) and (A.24) into (A.22), we have that for all sufficiently large N, any i  0,

P

sup

S(N)(t) - S(N)(2i+2)



10N

1 2

-+,

sup

Q3(N)(t) = 0, i  iN - 1



c1 e-c2 N

 5

,

 2( Ni +)2  t  2( Ni +)3

 2( Ni +)2  t  2( Ni +)3

(A.25)

55

where c1 and c2 are constants dependent on K2, B,  and T. Plugging (A.20), (A.21), and (A.25) into (A.19), we obtain for sufficiently large N,

P(x,y,0)

sup

sup

S(N)(t) - S(N)(2(Ni+)2)



10N

1 2

-+

i{0,...,iN-1} 2(Ni+)2t2(Ni+)3

e-

3 32

N1+2

T

+

c e7

-c8

N

(

1 2

-)/5

+

3 2

N1+2

T

×

c1

e-c2

N

 5



c3

e-c4

N

 5

.

(A.26)

Finally, plugging (A.14), (A.18) and (A.26) into (A.13), we can choose appropriate constants a2 and b2 such that for all sufficiently large N,

sup

P(x,y,0)

xK1

N

1 2

-,

B

N

1 2

+

<yK2

N

1 2

+

sup

sup

S(N)(t) - S(N)(2(Ni+)1)

i{0,...,iN-1} 2(Ni+)1t2(Ni+)3

c1 e-c2 N/5

+

c5 e-c6 N

1 2

-+

+

c3 e-c4 N

 5



a2

e-b2

N

 5

.



13N

1 2

-+

Lemma A.4. Under the assumptions on the initial state as given in Theorem 2.4, the following holds as N  :

sup

sup

i{0,...,iN-1} 2(iN+)1t2(iN+)3

1

N

1 2

+

t  2( iN+)1

I(N)(s)ds

+

1

N

1 2

+

t  2( Ni +)1

2N - S(N)(s) S(N)(s) - N

ds

-P 0.

(A.27)

Proof. Fix any 0 <  < (2) 

1 2

-

.

By Lemma A.1, for all

N



N1,

sup

P(x,y,0)

xK1

N

1 2

-

,

B

N

1 2

+

<yK2

N

1 2

+

sup 2(Ni+)3 - 2(Ni+)1  2N-2
i{0,...,iN-1}


 a1e-b1N 5 .

(A.28)

By Proposition 5.4,

P

sup

I(N)(t)



5N

1 2

-+



ae-bN

 2

.

0tT(N,B)

and similarly as in (A.21), for all N  N0 ,

(A.29)

sup

P(x,y,0)

xK1

N

1 2

-,

B

N

1 2

+

<yK2

N

1 2

+

sup Q3(N)(t) > 0
0tN2T



c1

e-c2

N

(

1 2

-)/5

.

(A.30)

Define the event

E(N) :=

sup

I(N)(t)

<

5N

1 2

-+

,

sup

Q3(N)(t) = 0, and

0tT(N,B)

0tT(N,B)

2(Ni+)3 - 2(Ni+)1 < 2N-2, i  {0, ..., iN - 1} .

56

Since  < 2, there exists NB > 0 such that for N  NB , on the event E(N), for s  [0, T(N, B)],

S(N)(s) = Q2(N)(s) + N - I(N)(s)



B

N

1 2

+

+

N

-

5

N

1 2

-+



1 2

B

N

1 2

+

+

N,

implying that for N  NB and s  [0, T(N, B)],

2N - S(N)(s) S(N)(s) - N



2

N

1 2

B

-

.

(A.31)

Hence, on the event E(N),

sup
 2( iN+)1  t  2( iN+)3

1

N

1 2

+

t  2( iN+)1

I(N)(s)ds

+

1

N

1 2

+

t  2( iN+)1

2N - S(N)(s) S(N)(s) - N

ds



10N2-4

+

4 B

N-4

 0 as N  ,

since



<

(2)



(

1 2

-

).

By

(A.28)­(A.30),

we

have

limN

P(E(N))

=

1.

Thus,

the

desired

result

holds.

Now, fix T > 0 and  < (/2) 

1 2

-

.

Define the event

E¯ (N) :=

sup

I(N)(t)

5N

1 2

-+,

sup

Q2(N)(t)



N

1 2

++,

0tT(N,B)

0tT(N,B)

sup

S(N)(t) - S(N)(2i+1)



13N

1 2

-+,

i



iN

-

1

.

 2( Ni +)1  t  2( Ni +)3

From now on, we will work under the assumptions stated in Theorem 2.4 for fixed T > 0 and

 < (/2) 

1 2

-

.

Lemma A.5. limN P(E¯ (N)) = 1.

Proof. The result follows from Proposition 3.15, Proposition 5.4, and Proposition A.3. On the event E¯(N), the following equation holds:

2N = S(N)(t) + Q1(N)(t) - Q2(N)(t) + 2I(N)(t), t  [0, T(N, B)]. Also, for t  [0, T(N, B)], the evolution of I(N) can be described as follows:

(A.32)

I(N)(t)  I(N)(t) + 1 at rate 2N - S(N)(t) - 2I(N)(t),

I(N)(t)



(I(N)(t)

-

1)+

at

rate

N

-



N

1 2

-.

Therefore, on E¯(N), for each excursion interval [2(Ni+)1, 2(Ni+)3), we construct two M/M/1 queues, Iu(N,i ) and Il(,Ni ), on the same probability space as I(N), and both starting from zero, to bound the

57

process I(N) from above and below respectively. For t  [2(Ni+)1, 2(Ni+)3), we define Iu(N,i ) and Il(,Ni ) with the following transition rates:

Iu(N,i )(t)



Iu(N,i )(t)

+

1

at

rate

(uN,i )

=

2N

-

S( N ) ( 2( Ni+)1 )

+

13N

1 2

-+,

Iu(N,i )(t)



Iu(N,i )(t)

-

1

at

rate

µ(uN,i )

=

N

-

N

1 2

-;

Il(,Ni )(t)



Il(,Ni )(t)

+

1

at

rate

(l,Ni )

=

2N

-

S( N ) ( 2( Ni+)1 )

-

23N

1 2

-+,

Il(,Ni )(t)  Il(,Ni )(t) - 1 at rate µ(l,Ni ) = N.

The following lemma is easy to check.

Lemma A.6. On the event E¯ (N), for each i  {0, ..., iN - 1} and t  [2(Ni+)1, 2(Ni+)3), we have

l,i  2N - S(N)(t) - 2I(N)(t)  u,i.

Due to Lemma A.6, we can naturally couple Iu(N,i ) and Il(,Ni ) with I(N) by setting Iu(N,i )(2(Ni )) =

Il(,Ni )(2(Ni+)1) that since

= I(N)(2(Ni+)1) (I(N)(t), t  0)

= 0,

N=1

so that for t  [2(Ni+)1, 2(Ni+)3), Il(,Ni )(t)  I(N)(t)  Iu(N,i )(t). Note are defined on the same probability space (see the representation

(5.1)), {0, ...,

iN

(-Iu(N,1i })(tN),=t1

 [2(Ni+)1, 2(Ni+)3)), are on the same

i



{0, ..., iN - 1}

 N=1

and

probability space as well.

(Il(,Ni )(t), t



[2(Ni+)1

,



(N) 2i+3

)),

i



Lemma A.7. The following holds for all large enough N:

P

iN



12T

N

1 2

+3+



 E¯(N)



1 9T

N-4-2.

Proof. On E¯(N), we have that for t  [0, T(N, B)],

2N

-

S(N)(t)

-

2I(N)(t)

=

N

-

I(N)(t)

-

Q2(N)(t)



N

-

5N

1 2

-+

-

N

1 2

++



N

-

6N

1 2

++.

On

each

[2(Ni ), 2(Ni+)1),

we

construct

an

M/M/1

queue

Mi(N)

with

rate

of

increase

N

-

6N

1 2

++

and rate of decrease N. We can couple Mi(N) with I(N) on [2(Ni ), 2(Ni+)1) by setting Mi(N)(2(Ni )) =

I(N)(2(Ni )) = 1 such that Mi(N)(t)  I(N)(t). Define m(N,i) := inf{t  2(Ni ) : Mi(N)(t) = 0} . Due to

the

coupling,

we

have



(N) m,i

-

2(Ni )



2(Ni+)1

-

2(Ni ).

Now,

we

have

P

iN



12T

N

1 2

+3+



 E¯ N

P

12T

N

1 2

+3+



i=1

2(Ni+)1 - 2(Ni )

 N2T

 E¯ N

P

12T

N

1 2

+3+



i=1

m(N,i)

-



(N) 2i

 N2T .

Let

Hi(N)

:=



(N) m,i

-

2(Ni ).

Since Hi(N) is the busy time of the M/M/1 queue Mi(N), we have

E(Hi(N))

=

1 6

N-

1 2

--

and

Var(Hi(N))

=

2 63

N

-

1 2

-3-3

-

1 62

N-1-2-2



2 63

N

-

1 2

-3-3

[1,

Section

58

7.9, Page 75]. Hence, by Doob's L2-maximal inequality, we have for all large enough N,

12T

N

1 2

+3+

P

iN



12T

N

1 2

+3+

 E¯ N

P



Hi(N) - E(Hi(N))  -N2 T

i=1



12T

N

1 2

+3+

×

2N-

1 2

-3-3

63 N4 T2



1 9T

N

-4-2.

Lemma A.8. The following hold as N  :

sup
j{0,...,iN-1}

1

N

1 2

+

j

i=0

 2( Ni +)3  2( iN+)1

(l,Ni ) µ(l,Ni ) - (l,Ni )

-

2N - S(N)(s) S(N)(s) - N

ds

-P 0,

(A.33)

sup
j{0,...,iN-1}

1

N

1 2

+

j

i=0

 2( Ni +)3  2( iN+)1

(uN,i ) µ(uN,i ) - (uN,i )

-

2N - S(N)(s) S(N)(s) - N

ds

-P 0.

(A.34)

Proof. We will prove (A.33). The proof of (A.34) is similar. Note that due to Lemma A.5, it suffices to prove that the left hand side converges to zero under the event E¯(N). Note that, for any i  {0, ..., iN - 1},

(l,Ni ) µ(l,Ni ) - (l,Ni )

=

2N

-

S( N ) ( 2( Ni+)1 )

-

23N

1 2

-+

S(N)(2(Ni+)1

)

-

N

+

23N

1 2

-+

.

Now,

x



2N-x x-N

is

Lipschitz

continuous

on

the

interval

[N

+

1 2

B

N

1 2

+

,

)

with

Lipschitz

constant

4 B2

N-2

.

Therefore,

for

any

s



[2(Ni+)1, 2(Ni+)3),

under

the

event

E¯ (N),

2N

-

S(N)(2(Ni+)1

)

-

23N

1 2

-+

S( N ) ( 2( Ni+)1 )

-

N

+

23N

1 2

-+

-

2N - S(N)(s) S(N)(s) - N



4 B2

N

-2

sup

sup

i{0,...,iN-1} 2(iN+)1s2(iN+)3

S(N)(2(Ni+)1) - S(N)(s)

+

23N

1 2

-+



144

N

1 2

-3+

B2

.

Thus,

sup
j{0,...,iN-1}

1

N

1 2

+

j

i=0

 2( iN+)3  2( Ni +)1

(l,Ni ) µ(l,Ni ) - (l,Ni )

-

2N - S(N)(s) S(N)(s) - N

ds



N

1

1 2

+

N2 T 0

144

N

1 2

-3+

B2

ds

=

144T B2

N

-2+,

which tends to 0 as n  , as  < /2.

59

Lemma A.9. The following hold:

 sup
j{0,...,iN-1}

1

N

1 2

+

j i=0

 2( Ni +)3  2( Ni +)1

Iu(N,i )(s)

-

(uN,i ) µ(uN,i ) - (uN,i )

ds -P 0,

 inf
j{0,...,iN-1}

1

N

1 2

+

j i=0

 2( Ni +)3  2( Ni +)1

Il(,Ni )(s)

-

(l,Ni ) µ(l,Ni ) - (l,Ni )

ds -P 0.

The next lemma will be used in the proof of Lemma A.9.

Lemma A.10. Suppose that Q is an M/M/1 queue with arrival rate  and service rate µ,with µ > . Let T~ be the length of the excursion of the M/M/1 queue started from zero (that is, the time taken for the queue
length to become non-zero and then zero again). Then

E

T~ 0

Q(s)

-

µ

 -



ds

= 0.

(A.35)

Moreover, there exists a universal positive constant C not depending on , µ such that for any integer a  2,

E

T~
Q(s)ds

2

 C a2

0

1 2

+

(µ

µ - )3

+

(µ/) (log(µ/))2

 a/8 µ

1 2

+

µ/ (µ -

1/4
)4

.

(A.36)

Proof. Throughout this proof, we will denote by C a universal positive constant, not depending
on , µ, whose value might change between lines. (A.35) is proved in [12, Lemma EC.19]. To prove (A.36), write Q := sup0sT~ Q(s). Note that,
for any integer a  2,

E

T~

2

Q(s)ds  E

aT~ + T~ Q1 Q  a 2  2a2E T~ 2 + 2E

T~ Q1 Q  a 2

0

 2a2E T~ 2 + 2 E T~ 4 E Q41 Q  a ,

(A.37)

where the last inequality follows from the Cauchy-Schwarz inequality. We can write T~ = T~1 + T~2 where T~1 is an Exp() random variable denoting the arrival time of the first task and T~2 denotes the time taken after T~1 for the queue to become empty again (busy time). Using E[T~12] = 2-2
and [1, Section 7.9, Page 75],

E T~ 2

 2E T~12

+ 2E T~22

4

1 2

+

(µ

µ - )3

.

(A.38)

Recall from Lemma A.2 that P T~2  t 

µ e-(µ-)2t, t  0. 

60

From this, we obtain

E T~ 4

 24E T~14

+ 24E T~24

 C

1 4

+

µ 

(µ

1 -

 )8

.

(A.39)

Moreover, using [12, Lemma EC.17], for any x  N,

P

Qx

=

1

nx=1

µ 

n-1 

From the above bound, we obtain

 µ

x-1
.

E Q41 Q  a



x=a4

 µ

x1/4-1



µ2 2

 e- log(µ/)z1/4 dz
a4 -1



C (log(µ/))4

µ2 2

 µ

a/4
.

(A.40)

Using (A.38), (A.39) and (A.40) in (A.37), we obtain

E

T~

2

Q(s)ds

0

 8a2

1 2

+

(µ

µ - )3

+ 2C

1 2

+

((µµ/-)1/4)4

µ/ (log(µ/))2



a/8
,

µ

which proves the lemma.

Proof of Lemma A.9. Throughout this proof, we will denote by C, C universal positive constants,
possibly depending on B, T but not N, whose values might change between lines.
We will only prove the first case since the second case is similar. As before, due to Lemma A.5, we will prove the convergence to zero on the event E¯(N). Note that the process Iu(N,i )(t) is defined only on the time interval [2(Ni+)1, 2(Ni+)3). However, let us assume that Iu(N,i )(t) is allowed to continue past time 2(Ni+)3, i  {0, ..., iN - 1}, and let u(N,i ) := inf{t  2(Ni+)3 : Iu(N,i )(t) = 0}. Further, let

Zi(N) =

u(N,i-) 1  2( iN-)1

Iu(N,i-) 1(s)

-

(uN,i-) 1 µ(uN,i-) 1 - (uN,i-) 1

ds, i  1.

We expand the first integral in the lemma for j  0 as follows:

 1 j

N

1 2

+

i=0

 2( Ni +)3  2( Ni +)1

Iu(N,i )(s)

-

(uN,i ) µ(uN,i ) - (uN,i )

ds

  =

N

1

1 2

+

j
Zi(+N1)
i=0

-

1

N

1 2

+

j i=0



(N) u,i

 2( Ni +)3

Iu(N,i )(s)

-

(uN,i ) µ(uN,i ) - (uN,i )

ds

  

N

1

1 2

+

j+1
Zi(N)
i=1

+

1

N

1 2

+

j i=0



(N) u,i

 2( Ni +)3

(uN,i ) µ(uN,i ) - (uN,i )

ds.

(A.41)

61

Define M0(N) = 0 and

 M(j N) :=

1

N

1 2

+

j i=1

Zi(N),

j  1.

(A.42)

Write G~i for the stopped natural filtration of the original queueing process up till time 2(Ni+)1, i  0. Define G0 := G~0 and
Gi := G~i  il-=10{Iu(N,l )(t) : t  2(Nl+)1} , i  1.

By (A.35), E Zi(+N1)|Gi = 0 for any i  0. Hence, M(N) is a martingale. We will show that, for any  > 0,

P

sup
jiN

M(j N)

>

 E¯ (N)

Define the stopping time ~ with respect to {Gi}i0 by

 0 as N  .

(A.43)

~ := inf{i  0 : 2(Ni+)1  T(N, B)

or

Q2( N ) ( 2( Ni+)1 )

>

N

1 2

++

}.

Now, we estimate E (Zi(+N1))2|Gi on the event {~  i + 1}. Note that for i  0,

 E (Zi(+N1))2|Gi  2E 



(N) u,i

 2( iN+)1

Iu(N,i )(s)ds

2

Gi

 

+

2E

 
 


(uN,i ) µ(uN,i ) - (uN,i )

2 





(N) u,i

-

2(Ni+)1

2

Gi

 

.

(A.44)

Recall (uN,i )

=

2N

-

S( N ) ( 2( Ni+)1 )

+

13N

1 2

-+

and

µ(uN,i )

=

N

-

N

1 2

-.

By (A.36), there exists a

deterministic universal constant C > 0 such that for any integer a  2,

E

u(N,i )  2( iN+)1

Iu(N,i )(s)ds

2
Gi

 C a2

1 (uN,i )

2

+

µ(uN,i ) (µ(uN,i ) - (uN,i ))3

+

1 (uN,i )

2+

µ(uN,i ) 1/4 (uN,i )

1 µ(uN,i ) -

(uN,i ) 4

1

µ(uN,i )

(log(µ(uN,i )/(uN,i )))2 (uN,i )

(uN,i ) µ(uN,i )

a/8
.

Note that, on the event {~  i + 1}, for sufficiently large N,

N

-

N

1 2

++



(uN,i )

=

N

-

Q2(N)(2(Ni+)1)

+

13N

1 2

-+



N

-

B 2

N

1 2

+

.

62

Using these bounds, on the event {~  i + 1}, for sufficiently large N,

1 (uN,i )

2+

µ(uN,i ) (uN,i )

1/4

1 µ(uN,i ) -

1 (uN,i )

2

+

µ(uN,i ) (µ(uN,i ) - (uN,i ))3



C

N

-

1 2

-3

,

(uN,i ) 4

1 (log(µ(uN,i )/(uN,i )))2

µ(uN,i ) (uN,i )



C N1-6 ,

(uN,i ) µ(uN,i )

a/8



e-C

aN

-

1 2

+

.

Therefore,

choosing

a

=

N

1 2

-+,

for

sufficiently

large

N,

on

the

event

{~



i

+

1},

E

u(N,i )  2( Ni +)1

Iu(N,i )(s)ds

2
Gi



C

N

1 2

-5+2.

Now, we estimate the second term in (A.44). Note that, for sufficiently large N,

(A.45)

(uN,i ) µ(uN,i ) - (uN,i )



4

N

1 2

-.

B

Moreover, using [1, Section 7.9, Page 75], on the event {~  i + 1}, for sufficiently large N,

E

u(N,i ) - 2(Ni+)1 2  4

1 (uN,i )

2

+

µ(uN,i ) (µ(uN,i ) - (uN,i ))3



4C

N-

1 2

-3

.

Hence, on the event {~  i + 1}, for sufficiently large N,

E

(uN,i ) µ(uN,i ) - (uN,i )

2

u(N,i ) - 2(Ni+)1 2 Gi



C

N

1 2

-5

.

(A.46)

Using the bounds (A.45) and (A.46) in (A.44), we conclude that, on the event {~  i + 1}, for

sufficiently large N,

E

( Zi(+N1) )2 |Gi



CN

1 2

-5+2.

(A.47)

The quadratic variation of the stopped martingale {M(jN~)}j0 is given by: M(N) 0 = 0 and

j~
 M(N) j~ = N-1-2 E (Zi(N))2|Gi-1 , j  1. i=1

Using (A.47), we obtain

M(N)

j~



C

N

-

1 2

-7+2

j,

j  1.

63

Hence, by Doob's L2 inequality, for any  > 0, for large enough N,

P

sup

M(j N) >  = P

sup

M(jN~) >   12CT-2 N-4+3. (A.48)

j~

12T

N

1 2

+3+

j12T

N

1 2

+3+



Note that, on the event E¯(N), ~ = iN + 1. Therefore, for any  > 0, for sufficiently large N,

P

sup
jiN

M(j N)

>

 E¯ (N)

P

sup

M(j N) > 

j~

12T

N

1 2

+3+

+P

iN



12T

N

1 2

+3+



 E¯ (N)



12CT-2 N-4+3

+

1 9T

N-4-2,

where the last bound follows from (A.48) and Lemma A.7. Recalling  < /2, (A.43) follows

from the above bound.

Now consider the second term of the right hand side of the inequality (A.41). For i  iN - 1, for sufficient large N, on E¯(N),

0

(uN,i ) µ(uN,i ) - (uN,i )



4

N

1 2

-

.

B

Additionally,

let



(N) l,1,i

:=

inf{t



2(Ni+)1

:

Il(,Ni )(t)

>

0}

and



(N) l,i

:=

inf{t



l(,N1,)i

:

Il(,Ni )(t)

=

0},

i  {0, ..., iN - 1}. We have that for sufficient large N,

j

i=1

 

(N) u,i

 2( iN+)3

(uN,i ) µ(uN,i ) - (uN,i

)

ds



j i=1

 u(N,i )



(N) l,i

(uN,i ) µ(uN,i ) - (uN,i

)

ds



4N

1 2

-

B

iN -1 i=1

u(N,i ) - l(,Ni )

,

(A.49)

where the first inequality is due to the fact that for t  [2(Ni+)1, 2(Ni+)3), Il(,Ni )(t)  I(N)(t)  Iu(N,i )(t),

which implies that l(,Ni )  2(Ni+)3  u(N,i ). For an M/M/1 with arrival rate  and departure rate µ,

E(T~ )

=

1 

+

1 µ-

where

T~

is

same

as

in

Lemma

A.10.

Then,

for

each

i



{0, ..., iN

- 1},

we

have

for all sufficiently large N, on E¯(N),

E



(N) u,i

-

l(,Ni )

=E

u(N,i )

-



(N) 2i+1

- E l(,Ni ) - 2(Ni+)1

= 2N

-

1 S( N ) ( 2( Ni+)1 )

+

13N

1 2

-+

+

S( N ) ( 2( Ni+)1 )

-

N

1

-

N

1 2

-

-

13N

1 2

-+

-

2N

-

1 S( N ) ( 2( Ni+)1 )

-

23

N

1 2

-+

-

S( N ) ( 2( Ni+)1 )

1 -N

+

23N

1 2

-+

 S(N)(2(Ni+)1)

-

N

1

-

N

1 2

-

-

13

N

1 2

-+

-

S( N ) ( 2( Ni+)1 )

1 -N

+

23

N

1 2

-+

C

N

-

1 2

-3+

64

and from (A.49),


j
E  sup  j{0,...,iN-1} i=0

u(N,i )  2( Ni +)3

(uN,i ) µ(uN,i ) - (uN,i )

 ds

1

{iN



12T

N

1 2

+3+}



E¯ (N)







CN

1 2

-+2

.

By Markov's inequality and Lemma A.7, we get that

P

 sup
j{0,...,iN-1}

1

N

1 2

+

j i=1



(N) u,i

 2( iN+)3

(uN,i ) µ(uN,i ) - (uN,i )

ds



C N-2+4

From (A.41), (A.43) and (A.50), we conclude that

 E¯ (N)

 N-.

(A.50)

 sup
j{0,...,iN-1}

1

N

1 2

+

j i=0

 2( Ni +)3  2( iN+)1

Iu(N,i )(s)

-

(uN,i ) µ(uN,i ) - (uN,i )

ds -P 0.

Proof of Proposition 5.5. Again, we will consider events within E¯(N). Observe that for any t  T(N, B), either t  1(N), or t  [2(Nj+)1, 2(Nj+)3] for some 0  j  iN, or t  [2(NiN)+1, T(N, B)]. Hence,

sup
0tT(N,B)

1

N

1 2

+

t 0

I(N)(s)

-

2N - S(N)(s) S(N)(s) - N

ds



N

1

1 2

+

 1( N ) 0

I(N)(s)

-

2N - S(N)(s) S(N)(s) - N

ds

+

sup
j{0,...,iN-1}

1

N

1 2

+

 2( Nj +)3  1( N )

I(N)(s)

-

2N - S(N)(s) S(N)(s) - N

ds

+

sup

sup

j{0,...,iN-1} 2(Nj+)1t2(Nj+)3

1

N

1 2

+

 2( Nj +)3 t

I(N)(s)

-

2N - S(N)(s) S(N)(s) - N

ds

(A.51)

+

1

N

1 2

+

T(N,B)  2( Ni N)+1

I(N)(s)

-

2N - S(N)(s) S(N)(s) - N

ds.

For t  [0, T(N, B)], I(N)(t) can be upper bounded by I¯B(N)(t) as defined in Section 3. Then, there exist constants c1 and c2 such that

P



(N) 1

 N-2

 P(inf{t > 0 : I¯B(N)(t) = 0}  N-2

I¯B(N)(0)

=

K1 N

1 2

-)



Ce-C N ,

(A.52)

where

the

first

inequality

is

due

to

the

assumption

I(N)(0)



K1

N

1 2

-

and

the

second

inequality

is due to Lemma 3.1 and Markov's inequality. Also, on the event E¯(N), we have

sup

I(N)(t)



5N

1 2

-+

0tT(N,B)

and

sup
0tT(N,B)

2N - S(N)(t) S(N)(t) - N



2

N

1 2

-

.

B

(A.53)

65

Hence, on 1(N) < N-2  E¯(N), we have

1

N

1 2

+

 1( N ) 0

I(N)(s)

-

2N - S(N)(s) S(N)(s) - N

ds 

C N -4+2

 0,

as

N  .

With limN P



(N) 1

<

N-2

= 1 due to (A.52) and limN P(E¯(N)) = 1 due to Lemma A.5,

we have

1

N

1 2

+

 1( N ) 0

I(N)(s)

-

2N - S(N)(s) S(N)(s) - N

ds -P 0,

(A.54)

as N  . Now, consider the second term in the right hand side of (A.51). For j  {0, ..., iN - 1},

 1 j

N

1 2

+

i=0

 2( Ni +)3  2( Ni +)1

Il(,Ni )(s)

-

(l,Ni ) µ(l,Ni ) - (l,Ni )

 ds

+

1

N

1 2

+

j i=0



N

1

1 2

+

 2( Nj +)3  1( N )

I(N)(s)

-

2N - S(N)(s) S(N)(s) - N

ds

 

N

1

1 2

+

j i=0

 2( Ni +)3  2( Ni +)1

Iu(N,i )(s)

-

(uN,i ) µ(uN,i ) - (uN,i )

 ds

+

1

N

1 2

+

j i=0

 2( Ni +)3  2( Ni +)1
 2( Ni +)3  2( Ni +)1

(l,Ni ) µ(l,Ni ) - (l,Ni )

-

2N - S(N)(s) S(N)(s) - N

ds

(uN,i ) µ(uN,i ) - (uN,i )

-

2N - S(N)(s) S(N)(s) - N

ds.

Thus, by Lemma A.8 and Lemma A.9,

sup
j{0,...,iN-1}

1

N

1 2

+

 2( Nj +)3  1( N )

I(N)(s)

-

2N - S(N)(s) S(N)(s) - N

ds -P 0 as N  .

By Lemma A.4, we have

(A.55)

sup
j{0,...,i-1}

sup
 2( Nj +)1  t  2( Nj +)3

1

N

1 2

+

t  2( Nj +)1

I(N)(s)

-

2N - S(N)(s) S(N)(s) - N

ds -P 0.

(A.56)

To estimate the last term in the bound (A.51), note that using the same argument used to derive

(A.6) and (A.9),

P

T(N,

B)

-



(N) 2iN +1



N-2

Ce-C N .

From this and (A.53), we conclude

1

N

1 2

+

T(N,B)  2( Ni N)+1

I(N)(s)

-

2N - S(N)(s) S(N)(s) - N

ds -P 0.

Using (A.54), (A.55), (A.56) and (A.57) in (A.51), we have

(A.57)

sup
0tT(N,B)

1

N

1 2

+

t 0

I(N)(s)

-

2N - S(N)(s) S(N)(s) - N

ds -P 0.

(A.58)

66

For any t such that N2t  T(N, B), by the triangle inequality,

1

N

1 2

+



1

N

1 2

+

N2t I(N)(s)ds -
0

t 0

X(

1
N)

(s)

ds

N2t 0

I(N)(s)ds

-

1

N

1 2

+

N2t 0

2N - S(N) S(N)(s) -

(s) N

ds

+

1

N

1 2

+

N 2 t 0

2N - S( S(N)(s)

N)(s) -N

ds

-

t 0

X

1
(N)

(s)

ds

.

(A.59)

Note that

1

N

1 2

+

N2t 0

2N - S(N)(s) S(N)(s) - N

ds

=

1

N

1 2

-

=

N

1

1 2

-

t 0

2N - S(N S(N)(N2

) ( N2 s) s) - N

ds

t 0

+ N

1 2

-

N-S(N)(N2s)

N

1 2

+

S(N)(N2s)-N

N

1 2

+

ds

=

-

N

t
1 2

-

+

t 0

X

1
(N)

ds,

which implies that for all t such that N2t  T(N, B),

1

N

1 2

+

N2t I(N)(s)ds -
0

t 0

1 X(N)

(s)

ds



1

N

1 2

+

N 2 t 0

I(N)(s)ds

-

1

N

1 2

+

N2t 2N - S(N)(s)

0

S(N)(s) - N ds

+

N

t

1 2

-

.

This, combined with (A.58), yields that as N  ,

sup
0t T ( N -22( N) ( B))

1

N

1 2

+

N2t I(N)(s)ds -
0

t1 0 X(N)(s) ds

-P 0,

which concludes the proof of Proposition 5.5.

B Upper bound on I(N)

Proposition B.1. For any fixed K1, K2, T > 0 and 0 <  < , there exist constants a, b, N1 > 0, such

that

for

all

N



N1,

x



K1

N

1 2

-,

y



K2

N

1 2

+

,

sup P(x,y,z)

sup

I(N)(t)



2N

1 2

+

 ae-bN2,

z

0tN2T

and consequently, for all ~ > 0,

lim
N

sup
z

P(x,y,z)

1 N1+2

N 2 T
I(N)(s)ds  ~
0

= 0.

(B.1)

67

Proof. Let I~(N) denote a birth-death process with

I~(N)  I~(N) + 1 at rate N - I~(N),

I~(N)



( I~( N )

-

1)+

at

rate

N

-



N

1 2

-

.

By Lemma [12, Lemma EC.17], starting from 1, the probability h1x of I~(N) hitting x before returning to 0 is given by

 h1x

=

1 nx=1 mn-=11

N

-N

1 2

-

N-m



mx-1

N

N -

-m



N

1 2

-

 exp

-



m

-



N

1 2

-

mx-1

N

= exp

-

x(x

-

1)

+



N

1 2

-

(

x

-

1)

2N

N

,

(B.2)

where the second inequality is due to 1 - z  e-z, for z  0.

Now,

recall



(N) i

for

i



1,

from (A.2). Since rate of increase of I(N) is Q1(N) - Q2(N) = N - I(N) - Q2(N)  N - I(N), in the

interval [2(Ni ), 2(Ni+)1], we can naturally couple the processes I(N)(t) and I~(N)(t) with I(N)(2(Ni )) =

I~(N)(2(Ni )) = 1, such that sample path-wise, I(N) is dominated by the process I~(N). Thus, taking

x

=

N

1 2

+

in

(B.2),

we

have

that

for

each

i



1

and

large

enough

N,

sup sup P(x,y,z)
i1 x,y,z

sup

I(N)(t)



N

1 2

+

2(Ni )t2(Ni+)1



h1N

1 2

+



e-cN2 ,

(B.3)

where c is a positive constant. This bounds I(N) on each of its excursions. Now we will consider

the interval [0, 1(N)]. Note that for all N 

Take

N1



N

such

that

N

1 2

+

N1

and

x



K1

N

1 2

-

,

y



0,



K1

N

1 2

-

and

(B.3)

holds

for

all

N



N1.

P(x,y,z)

sup

I(N)(t)



2N

1 2

+

P

I~(N)(t)

hits

2N

1 2

+

before

hitting

0

|

I~( N ) (0)

=

x

0t1(N)

P

I~(N)(t)

hits

2N

1 2

+

before

hitting

0

|

I~( N ) (0)

=

K1 N

1 2

-



P

I~(N)(t)

hits

N

1 2

+

before

hitting

0

|

I~( N ) (0)

=

1

 e-cN2,

where for the third inequality, we consider two copies of the process I~(N): I~1(N)(t), t > 0|I~1(N)(0) =

1

and

I~2(N)(t), t

> 0|I~2(N)(0)

=

K1

N

1 2

-

} which are coupled as follows:

if there is a new ar-

rival

in

I~1(N)

(that

is,

I~1(N)

increases by

1),

then there is

an

arrival

in

I~2(N)

with

probability

N N

- -

I~2( I~1(

N) N)

;

if there is a departure in I~2(N), then there is a departure in I~1(N) (or if I~1(N) was zero before the

departure,

it

stays

zero

after

it).

In

this

way,

| I~1( N ) (t)

-

I~2(N)(t)|



K1

N

1 2

-

for

all

t

which

implies

that the third inequality holds. Also, writing iN := inf{i  0 : 2(Ni+)3  N2T}, we have by the

68

same argument used to derive (A.11),

sup P

xK1

N

1 2

-

,

iN



3 2

N1+2

T

yK2

N

1 2

+



e-

3 32

N1+2

T

.

Hence,

uniformly

over

all

x



K1

N

1 2

-

,

y



K2

N

1 2

+

,

and

feasible

z,

P(x,y,z)

sup

I(N)



2N

1 2

+

0tN2T

 P(x,y,z)

iN



3 2

N1+2

T

+ P(x,y,z)

sup

I(N)(t)



2N

1 2

+

0t1(N)

+

3 2

N1+2 T

sup
i1

P(x,y,z)

sup

I(N)



N

1 2

+

2(iN) t2(iN+)1

 ae-bN2.

Moreover,

for

all

N



N1,

x



K1

N

1 2

-

,

y



K2 N

1 2

+,

sup P(x,y,z)
z

1 N1+2

N2 T

I(N)(s)ds



2N

-

1 2

+

0

 sup P(x,y,z)

sup

I(N)(s)



2N

1 2

+

z

0s N 2 T

 ae-bN2 .

This completes the proof.

69

