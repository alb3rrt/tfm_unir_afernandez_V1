
# Improving Formality Style Transfer with Context-Aware Rule Injection

[arXiv](https://arxiv.org/abs/2106.0210), [PDF](https://arxiv.org/pdf/2106.0210.pdf)

## Authors

- Zonghai Yao
- Hong Yu

## Abstract

Models pre-trained on large-scale regular text corpora often do not work well for user-generated data where the language styles differ significantly from the mainstream text. Here we present Context-Aware Rule Injection (CARI), an innovative method for formality style transfer (FST). CARI injects multiple rules into an end-to-end BERT-based encoder and decoder model. It learns to select optimal rules based on context. The intrinsic evaluation showed that CARI achieved the new highest performance on the FST benchmark dataset. Our extrinsic evaluation showed that CARI can greatly improve the regular pre-trained models' performance on several tweet sentiment analysis tasks.

## Comments

ACL2021

## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{yao2021improving,
      title={Improving Formality Style Transfer with Context-Aware Rule Injection}, 
      author={Zonghai Yao and Hong Yu},
      year={2021},
      eprint={2106.00210},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

## Notes

Type your reading notes here...

