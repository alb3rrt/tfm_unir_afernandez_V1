arXiv:2106.01474v1 [stat.ML] 2 Jun 2021

Testing Directed Acyclic Graph via Structural, Supervised and Generative Adversarial Learning
Chengchun Shi, Yunzhe Zhou, and Lexin Li
London School of Economics and Political Science University of California at Berkeley
Abstract In this article, we propose a new hypothesis testing method for directed acyclic graph (DAG). While there is a rich class of DAG estimation methods, there is a relative paucity of DAG inference solutions. Moreover, the existing methods often impose some specific model structures such as linear models or additive models, and assume independent data observations. Our proposed test instead allows the associations among the random variables to be nonlinear and the data to be time-dependent. We build the test based on some highly flexible neural networks learners. We establish the asymptotic guarantees of the test, while allowing either the number of subjects or the number of time points for each subject to diverge to infinity. We demonstrate the efficacy of the test through simulations and a brain connectivity network analysis.
Key Words: Brain connectivity networks; Directed acyclic graph; Hypothesis testing; Generative adversarial networks; Multilayer perceptron neural networks.
1 Introduction
Directed acyclic graph (DAG) is an important tool to characterize pairwise directional relations among multivariate and high-dimensional random variables. It has been frequently used in a wide range of scientific applications. One example is the gene regulatory network analysis in genetics (Sachs et al., 2005). The time-course expression data of multiple genes are measured over multiple cellular samples through microarray or RNA sequencing, and the goal is to understand the regulatory activation or repression relations among different genes. Another example is the brain effective connectivity analysis in neuroscience (Garg et al., 2011). The
1

time-course neural activities are measured at multiple brain regions for multiple experimental subjects through functional magnetic resonance imaging, and the goal is to infer the influences of brain regions exerting over each other under the stimulus.
There is a large body of literature studying penalized estimation of DAGs given the observational data (see, e.g., Spirtes et al., 2000; van de Geer and Bu¨hlmann, 2013; Zheng et al., 2018; Yuan et al., 2019, among many others). These existing works all imposed some specific model structures, most often, linear models or additive models. More recently, there have emerged a number of proposals in the computer science literature that used neural networks or reinforcement learning to estimate DAGs, which have been shown to be more effective for learning nonlinear models (Yu et al., 2019; Zheng et al., 2020; Zhu et al., 2020). While all these works have made crucial contributions to estimate directional links, DAG estimation is an utterly different problem from DAG inference. The two problems are closely related, and both can, in effect, identify directional relations, i.e., important links of a DAG. Besides, DAG inference usually relies on DAG estimation as a precedent step. Nevertheless, estimation does not produce an explicit quantification of statistical significance as inference does. Bayesian networks have been used for DAG estimation and inference. However, the difficulty of inferring Bayesian networks lies in the computational complexity of searching through all possible graph structures, which is NP-hard (Chickering et al., 2004). As a result, the dimension of the Bayesian networks is often small (Friston, 2011). There are very few frequentist inference solutions for directional relations of DAG models. Only recently, Jankova´ and van de Geer (2019) proposed a de-biased estimator to construct confidence intervals for the edge weights in a DAG, whereas Li et al. (2020) developed a constrained likelihood ratio test to infer individual links or some given directed paths of a DAG. These works are probably the most relevant to our proposal. However, both methods focused on Gaussian linear DAGs, and cannot be easily extended to more general nonlinear DAG models. Moreover, all the above works considered the setting where the data observations are independent and identically distributed. Learning DAGs from time-dependent data remains largely unexplored.
There is another body of literature studying conditional independence testing; see Li and
2

Fan (2019) for an overview and the references therein. Conditional independence testing is closely related to DAG inference, and is to serve as a building block of our proposed testing procedure. On the other hand, naively performing conditional independence test on two variables given the rest would fail to infer their directional relationships; see Section 2.2 for details. Besides, most conditional independence testing methods assume the data observations are independent, and are not suitable for the setting where the measurements are time-dependent.
In this article, we propose a new testing method for statistical inference of individual links or some given paths in a large and general DAG given the time-dependent observational data. The new test hinges upon some highly flexible neural networks-based learning techniques. The associations among the random variables can be either linear or nonlinear, and the variables themselves can be either continuous or discrete-valued. As a result, our proposal makes a number of unique and useful contributions.
First, rigorous inference of directional relations in DAGs is a vital and long-standing problem. But the existing solutions rely on particular model structures such as linear or additive models, and mostly deal with i.i.d. data. Such requirements can be restrictive in numerous applications, since the actual relations may be nonlinear and the data are correlated. By contrast, we only require an additive noise structure (Peters et al., 2014). To the best of our knowledge, our work is the first frequentist solution for general DAG inference with time-dependent data.
Second, we propose a novel testing procedure for inferring individual links or some given paths in a large and general DAG, by employing a number of state-of-the-art deep learning techniques that are highly flexible and can capture nonlinear associations among high-dimensional variables. We begin with a new characterization of pairwise directional relations under the additive noise assumption; see Theorem 1. Based on this characterization, we propose a testing procedure that integrates the following three key components: (a) A DAG structural learning method based on neural networks or reinforcement learning to
estimate the DAG; (b) A supervised learning method based on neural networks to estimate the conditional mean; (c) A distribution generator produced by generative adversarial networks (Goodfellow et al.,
3

2014, GANs) to approximate the conditional distribution of the variables in the DAG.
We remark that, we employ modern machine learning techniques such as neural networks and GANs to help address a classical statistical inference problem. Conceptually, they serve as nonparametric learners, and play a similar role as splines and reproducing kernels type learning methods. But they are often more flexible and can handle more complex data. With more and more efficient implementations, and better understanding of their statistical properties (Farrell et al., 2021; Bauer and Kohler, 2019; Chen et al., 2020; Gao and Wang, 2021), this family of deep learning methods offer a powerful set of tools for classical statistical analyses. Our proposal is an example of harnessing such power, as the use of these machine learning techniques allows us to accurately estimate the DAG structure, the conditional means, as well as the distribution functions, and to improve the power of our test.
Third, we establish the asymptotic size and power guarantees for the proposed test. We couple the three learners with the data-splitting and cross-fitting strategy to ensure the resulting test has the guaranteed theoretical properties under mild conditions on those learning methods. Actually our inferential framework is fairly general, and can work with a wide range of learning methods. Specifically, we only require the DAG learner to consistently estimate the ordering of the true DAG, and we show that the neural network-based DAG learner we choose satisfies this requirement. This is much weaker than requiring the DAG learner to be selection consistent, or to satisfy the sure screening property. Besides, we require the supervised learner and the distribution generator to converge, but at rates that are slower than the usual parametric rate. The capacity of modern neural networks-based learning methods and their successes in structural learning, prediction, and distribution modeling make these requirements achievable.
Finally, to establish the consistency of the proposed test, we introduce a bidirectional asymptotic framework that allows either the number of subjects, or the number of time points for each subject, to diverge to infinity. This is useful for different types of applications. There are plenty of studies where the interest is about the directional relations for a general population, and thus it is reasonable to let the number of subjects or samples to go to infinity. Meanwhile, there are other applications, for instance, neuroimaging-based brain networks studies,
4

where the number of subjects is almost always limited. On the other hand, the scanning time and the temporal resolution can be greatly increased. For those applications, it is more suitable to let the number of time points to diverge.
The rest of the article is organized as follows. We formally define the hypotheses, along with the model and data structure, in Section 2. We develop the testing procedure in Section 3, and establish the theoretical properties in Section 4. We study the empirical performance of the test through simulations and a real data example in Sections 5 and 6. We discuss some extensions in Section 7. All technical proofs are relegated to the supplementary appendix.
2 Problem formulation
In this section, we first present the DAG model, based on which we formally define our hypotheses. We next propose an equivalent characterization of the hypotheses, for which we develop our testing procedure. Finally, we detail the data structure.
2.1 DAG model
Consider d random variables X = (X1, . . . , Xd) , each with a finite fourth moment. We use a directed graph to characterize the directional relationships among these variables, where a node of the graph corresponds to a variable in X. For two nodes i, j  {1, . . . , d}, if Xi directly influences Xj, then an arrow is drawn from i to j, i.e., i  j. In this case, Xi is called a parent of Xj, and Xj a child of Xi. A directed path in the graph is a sequence of distinct nodes i1, . . . , id , such that there is a directed edge ik  ik+1 for all k = 1, . . . , d - 1. If there exists a directed path from i to j, then Xi is called an ancestor of Xj, and Xj a descendant of Xi. For node Xj, let PAj, DSj and ACj denote the set of indices of the parents, descendants, and ancestors of Xj, respectively. Moreover, let XM denote the sub-vector of X formed by those whose indices are in a subset M  {1, . . . , d}.
To rigorously formulate our problem, we make two assumptions. (A1) The directed graph is acyclic; i.e., no variable is an ancestor of itself. (A2) The DAG is identifiable from the joint distribution of X.
5

Assumption (A1) has been commonly imposed in directed graph analysis. It does not permit any variable to be its own ancestor. As a result, the relationship between any two variables is unidirectional. Assumption (A2) helps simplify the problem, and avoids dealing with the equivalence class of DAG. This assumption is again frequently imposed in the DAG estimation literature (Zheng et al., 2018; Yuan et al., 2019; Li et al., 2020; Zheng et al., 2020). Inference with the equivalence class is beyond the scope of this article, and we leave it as future research.
To meet the identifiability requirement, we consider a class of structural equation models that follow an additive noise structure,

Xj = fj(XPAj ) + j, for any j = 1, . . . , d,

(1)

where {fj}dj=1 are a set of continuous functions, and {j}dj=1 are a set of independent zero mean random errors. Model (1) permits a fairly flexible structure. For instance, if each fj is a linear function, then (1) reduces to a linear structural equation model. If each fj is an additive function, i.e., fj(XPAj ) = kPAj fj,k(Xk), then (1) becomes an additive model. In our test, we do not impose linear or additive model structures. Moreover, we can easily extend the proposed test to the setting of generalized linear model, where the Xj can be either continuous or discrete-valued. We discuss such an extension in Section 7.3. When (1) holds, the corresponding DAG is identifiable under mild conditions (Peters et al., 2014).

2.2 Hypotheses and equivalent characterization

We next formally define the hypotheses we target, and then give an equivalent characterization. For a given pair of nodes (j, k), j, k = 1, . . . , d, j = k, we aim at the hypotheses:

H0(j, k) : k / PAj, versus H1(j, k) : k  PAj.

(2)

When the alternative hypothesis holds, we say Xk directly influences Xj. In the following, we mainly focus on testing an individual directional relation H0(j, k). We discuss the extensions of testing a directed pathway, or a union of directional relations in Sections 7.1 and 7.2.
We next consider a pair of hypotheses that involve two variables that are conditionally independent (CI). The new hypotheses are closely related to (2), but are not exactly the same.

6

(a)

(b)

Figure 1: (a) A three-variable DAG with a v-structure. (b) Illustration of multilayer perceptron with two hidden layers, m0 = 2, m1 = m2 = 3. Here u is the input, A( ) and b( ) denote the corresponding parameters to produce the linear transformation for the ( - 1)th layer.

H0(j, k) : Xk and Xj are CI given the rest of variables, versus (3)
H1(j, k) : Xk and Xj are not CI given the rest of variables.
We point out that, testing for (3) is generally not the same as testing for (2). To elaborate this,
we consider a three-variable DAG with a v-structure.

Example 1 (v-structure). Consider three random variables X1, X2, X3 that form a v-structure, as illustrated in Figure 1(a), where X1 and X2 are the common parents of X3. Even if X1 and X2 are marginally independent, they can be conditionally dependent given X3. To better understand this, consider the following toy illustration. Either the ballgame or the rain could cause traffic jam, but they are uncorrelated. However, seeing traffic jam puts the ballgame and the rain in competition as a potential explanation. As such, these two events are conditionally dependent. Since X2 is not a parent of X1, both H0(1, 2) and H1(1, 2) hold. Consequently, testing for (3) can have an inflated type-I error for testing (2).

In the above example, we note that the reason that testing for (3) is not the same as for (2) is because the conditioning set of X1 and X2 contains their common descendant X3. This key observation motivates us to consider a variant of (3), which we show is equivalent to (2) under certain conditions. Specifically, for a given set of indices M  {1, . . . , d} such that j / M, and letting XM-{k} denote the set of variables in M - {k}, we consider the hypotheses:
7

H0(j, k|M) : Xk and Xj are CI given XM-{k}, versus (4)
H1(j, k|M) : Xk and Xj are not CI given XM-{k},
Proposition 1. For a given pair of nodes (j, k) such that j  DSk, j, k = 1, . . . , d, and for any
M such that j / M, PAj  M and M  DSj = , testing (4) is equivalent to testing (2).

Proposition 1 forms the basis for our test. That is, to infer the directional relations, we first restrict our attention to the pairs (j, k) such that j  DSk. Apparently, H0(j, k) does not hold when j / DSk. Next, when devising a conditional independence test for H0(j, k), the conditioning set M is supposed to contain the parents of node j, but cannot contain any common descendants of j, k. Under these conditions, we establish the equivalence between (4) and (2).
Next, we develop a test statistic for the hypotheses (4). We introduce a key quantity. Let h denote a square-integrable function that takes Xk and XM-{k} as the input. Define

I(j, k|M; h) = E Xj - E Xj|XM-{k} h Xk, XM-{k} - E h Xk, XM-{k} |XM-{k} .

Under the additive noise model (1), the next theorem connects this quantity with the null hypothesis H0(j, k|M) in (4). Together with Proposition 1, it shows that I(j, k|M; h) can serve as a test statistic for (4), and equivalently, for (2) that we target.

Theorem 1. Suppose (1) holds. For a given pair of nodes (j, k) such that j  DSk, j, k = 1, . . . , d, for any M such that j / M, PAj  M and M  DSj = , the null hypothesis H0(j, k|M) in (4) is equivalent to suph |I(j, k|M; h)| = 0 where the supremum is taken over all square-integrable functions h.

Theorem 1 immediately suggests a possible testing procedure for (4). That is, we first employ a DAG estimator to learn the ancestors and descendants for node j. We then consider a natural choice for h, where h Xk, XM-{k} = Xk. Then I(j, k|M; h) becomes

I(j, k|M; h) = E Xj - E Xj|XM-{k} Xk - E Xk|XM-{k} .

(5)

This measure can be estimated by plugging in the estimators of the conditional mean functions E Xj|XM-{k} and E Xk|XM-{k} . By Theorem 1, under the null hypothesis H0(j, k|M),
8

a consistent estimator for (5) should be close to zero. A Wald type test can then be devised to determine the rejection region. Such a test is similar in spirit as the tests of Zhang et al. (2018) and Shah and Peters (2018). Since it involves estimation of two conditional mean functions, we refer to it as the double regression-based test. We later numerically compare our proposed test with this test in Section 5.
However, a drawback of this test is that it may not have a sufficient power to detect H1(j, k). As an illustration, we revisit Example 1. For this example, consider the structural equation model: X1 = 1, X2 = 2, and X3 = X12 + X2 + 3. Under this model, H1(1, 3) holds. Meanwhile, I(1, 3) = E(X3 - X2)X1 = E31. When the distribution of 1 is symmetric, I(1, 3) = 0, despite the fact that X1 is a parent of X3. As such, for this example, the double regression-based test is to have no power at all.
This observation motivates us to consider multiple functions h, instead of a single h, to improve the power of the test. That is, we consider a large class of functions of h, compute {I(j, k|M; h) : h} for each h, then take the maximum of some standardized version of those measures to form our test statistic. We detail this idea in Section 3, and numerically show that the resulting test is more powerful than the double regression-based test in Section 5.
2.3 Time-dependent observational data
Throughout this article, we use X to denote the population variables, and X to denote the data realizations. Suppose the data come from an observational study, and are of the form, {Xi,t,j : i = 1, . . . , N, t = 1, . . . , Ti, j = 1, . . . , d}, where i indexes the ith subject, t indexes the tth time point, and j indexes the jth random variable. Suppose there are totally N subjects, with Ti observations for the ith subject. Write Xi,t = (Xi,t,1, . . . , Xi,t,d) , i = 1, . . . , N, t = 1, . . . , Ti. We consider the following data structure.
(B1) Across subjects, the measurements X1,t, . . ., XN,t are i.i.d. (B2) Across time points, the random vectors Xi,1, . . ., Xi,Ti are stationary. (B3) For any i, t, Xi,t,1, . . ., Xi,t,d are DAG-structured. In addition, their joint distribution is
the same as that of X1, . . . , Xd.
9

Assumption (B1) is reasonable, as the subjects are usually independent from each other. In this article, we do not study the scenario where the data come from the same families or clusters. Assumption (B2) about the stationarity is common in numerous applications such as brain connectivity analysis (Bullmore and Sporns, 2009; Kang et al., 2016; Qiu et al., 2016; Wang et al., 2016). Assumption (B3) brings the data into the DAG framework that we study. Our objective is then to test the hypotheses in (2), through (4), given the observational data Xi,t,j.
3 Testing procedure
In this section, we develop an inferential procedure for (2) through (4). We first present the main ideas and the complete procedure of our test. We then detail the major steps. Given that our test is implemented based on Structural learning, sUpervised learning, and Generative AdveRsarial networks, we call our testing method sugar.
3.1 The main algorithm
Our main idea is to construct a series of measures {I(j, k|M; hb) : b = 1, . . . , B}, for a large number of functions h1, . . . , hB, then take the maximum of some standardized version of I(j, k|M; hb). Toward that goal, we need to estimate three key quantities.
(a) The set of indices M that satisfy the conditions of Proposition 1; (b) The conditional mean function E Xj|XM-{k} ; (c) The functional that maps each hb into E hb Xk, XM-{k} |XM-{k} .
Correspondingly, our testing procedure involves three key steps. First, to estimate (a), we apply a structural learning algorithm to learn the underlying DAG
G corresponding to X. The input of this step is the observed data {Xi,t,j : i = 1, . . . , N, t = 1, . . . , Ti, j = 1, . . . , d}, and the output is the estimated DAG, denoted by G. Furthermore, let ACj and PAj denote the corresponding estimated set of ancestors and parents of Xj, respectively. Then we set M = ACj. To capture potential sparsity and nonlinear associations in G, we employ a recent DAG estimation method by Zheng et al. (2020). Other methods, e.g., Zhu et al.
10

(2020), can be used as well. We remark that we only require P(PAj  ACj  DScj -{j})  1. We show in Section 4.2 that this requirement is satisfied when using the method of Zheng et al. (2020). Meanwhile, this is much weaker than requiring the selection consistency, i.e., P(PAj = PAj)  1. See Section 3.2 for details.
Second, to estimate (b), we employ a supervised learning algorithm, as this step is essentially a regression problem. The input includes XM-{k} that serves as the "predictors", and Xj that serves as the "response", and the output is the estimated mean E Xj|XM-{k} . Numerous choices are available, ranging from boosting or random forests to neural networks methods. In our implementation, we employ a multilayer perceptron learner, which has been shown to have a good capacity of estimating the conditional mean function that is complex and involves high-dimensional covariates. The resulting estimator also has the desired consistency guarantees (Schmidt-Hieber, 2017; Farrell et al., 2021). See Section 3.3 for details.
Third, to compute (c), we propose to use generative adversarial networks (Goodfellow et al., 2014, GANs) to approximate the conditional distribution of Xk given XM-{k}. GANs provide a powerful method for generative modeling of high-dimensional datasets. They have been successfully applied in numerous applications ranging from image processing and computer vision, to modelling sequential data such as natural language, music, speech, and to medical fields such as DNA design and drug discovery; see e.g., Gui et al. (2020) for reviews of the related applications. Specifically, we learn a generator G(·, ·) that takes Xi,t,M-{k} and a set of multivariate Gaussian noise vectors as the input, and the output are a set of pseudo samples X(i,mt,k) , m = 1, . . . , M , where M is the total number of pseudo samples. The generator G(·, ·) is trained such that the divergence between the conditional distribution of Xi,t,k|Xi,t,M-{k} and that of X(i,mt,k) |Xi,t,M-{k} is minimized. Given the generated pseudo samples, we then proceed to estimate the conditional mean function E hb Xk, XM-{k} | XM-{k} , and construct the corresponding test statistic. In addition to GANs, other deep generative learning approaches such as variational autoencoders (Kingma and Welling, 2013) are equally applicable here. We also remark that, an alternative approach for this step is to separately apply a supervised learning algorithm B times to estimate E hb Xk, XM-{k} |XM-{k} , for b = 1, . . . , B. However,
11

when B is large, and in our implementation, B = 2000, this approach is computationally very expensive. Besides, in our asymptotic analysis, B is to diverge to infinity with the sample size to guarantee the power property of the test. Therefore, we choose the generative learning approach for this step. See Section 3.4 for details.
In addition to these three components, we also propose to couple the test with a datasplitting and cross-fitting strategy. This is to ensure a valid type-I error control for the test under minimal conditions for the above three learners. The same strategy has been commonly used in statistical testing; see, e.g., Romano and DiCiccio (2019). Specifically, at the beginning of our testing procedure, we randomly split all the subjects {1, . . . , N } into two equal halves I1  I2, where Is denotes the set of indices of the subsamples, s = 1, 2. We then compute the three learners in (a) to (c) using each half of the data {Xi,t : i  Is, t = 1, . . . , Ti} separately. Based on these learners, we next use cross-fitting to estimate {I(j, k|M; hb) : b = 1, . . . , B}, and their associated standard deviations. We construct our test statistic as the largest standardized version of I(j, k|M; hb) in the absolute value. This allows us to construct two Wald-type test statistics, one for each half of the data. Finally, we derive the p-values based on Gaussian approximation, and reject the null hypothesis when either one of the p-value is smaller than /2. By Bonferroni's inequality, this yields a valid -level test. See Section 3.5 for details.
A summary of the proposed testing procedure is given in Algorithm 1.
3.2 DAG structural learning
The first key component of our testing procedure is to estimate the DAG G associated with X = (X1, . . . , Xd) , so that we can construct M for the subsequent test. In our implementation, we employ the neural structural learning method of Zheng et al. (2020). Meanwhile, there are other methods available that allow complex nonlinear relationships (e.g., Yu et al., 2019).
Consider a multilayer perceptron (MLP) with L hidden layers and an activation function :
MLP u; A(1), b(1), . . . , A(L), b(L) = A(L) . . . A(2) A(1)µ + b(1) . . . + b(L-1) + b(L), (6)
where u  Rm0 is the input signal of the MLP, A(s)  Rm ×m , -1 b(s)  Rm are the parameters
12

Algorithm 1 Testing procedure for a given edge (j, k).
Step 1. Randomly split the data into two equal halves, {Xi,t,k}iIs,t=1,...,Ti, s = 1, 2. Step 2. For each half of the data, s = 1, 2,

(2a) Apply the structural learning method (7) to estimate the DAG G. Denote the

estimated

graph

by

G (s) ,

and

the

estimated

set

of

ancestors

of

j

by

(s)
ACj .

Set

M(js,k)

=

(s)
ACj

-

{k}.

(2b)

If

k

/

(s)
ACj ,

return

the

p-value,

p(s)(j,

k)

=

1.

Step 3. For s = 1, 2, apply the supervised learning method (8) to estimate the condi-

tional

mean

E

X |X j

Mj(s,k)

,

with

Xi,t,M(js,k) iIs,t=1,...,Ti as the "predictors", and

{Xi,t,j}iIs,t=1,...,Ti as the "response". Denote the estimated function by gj(,sk)(x) =

E

X |X j

Mj(s,k)

=x

.

Step 4. For s = 1, 2, apply the GANs method to learn a generator G(s) to approximate the

conditional distribution of Xi,t,k given X . i,t,M(js,k) It takes Xi,t,M(js,k) and a multivariate

Gaussian vector as the input, and returns the pseudo samples

(m)
Xi,t,k

M m=1

as

the

output.

Step 5. Construct the test statistic:

(5a) Randomly generate B functions

h(bs)

B b=1

from

the

bounded

function

class

H(s) in (10).

(5b) For each (s, b), construct two standardized measures, Tb(,sC)F and Tb(,sN)CF, with and without cross-fitting, using (11).

(5c) Select the index, b(s) = arg maxb{1,...,B} Tb(,sN)CF , based on the measure without cross-fitting.

(5d)

Set

the

test

statistic

as

T (s) b(s)

,CF

,

based

on

the

measure

with

cross-fitting.

Step 6. Return the p-value:

(6a)

Compute the p-value, p(s)(j, k) = 2P

Z0 

T (s) b(s),CF

, for each half of the

data, s = 1, 2, where Z0 is standard normal.

(6b) Return p(j, k) = 2 min p(1)(j, k), p(2)(j, k) .

that produce the linear transformation of the ( - 1)th layer, and the output is a scalar with mL = 1. The dimension m denotes the number of nodes at layer , = 0, . . . , L. See Figure
13

1(b) for a graphic illustration of an MLP. We employ MLP to approximate the functions fj in our DAG model (1). Specifically, let
j = A(j1), b(1) collect all the parameters for the jth MLP that approximates fj, j = 1, . . . , d. For each half of the data, s = 1, 2, we estimate the DAG via the following optimization,

min

{Xi,t,j - MLP(Xi,t; j)}2 , subject to G()  DAGs,



iIs t,j

where G() denotes the graph induced by . This optimization problem is challenging to solve,

however, due to the fact that the search space scales super-exponentially with the dimension d.

To resolve this issue, Zheng et al. (2020) proposed a novel characterization of the acyclic con-

straint, and showed that the DAG constraint can be represented by trace[exp{W ()W ()}] =

d, where  denotes the Hadamard product, exp(W ) is the matrix exponential of W , trace(W )

is the trace of W , and W () is a d × d matrix whose (k, j)th entry equals the Euclidean norm of the kth column of A(j1). Based on this characterization, the optimization problem becomes,

d

Ti

min 

{Xi,t,j - MLP(Xi,t; j)}2 + ns A(j1) 1,1 ,

j=1 iIs t=1

(7)

subject to trace[exp{W ()  W ()}] = d,

where ns = iIs Ti is the number of observations in Is, A(j1) 1,1 is the sum of all elements in A(j1) in absolute values, and  > 0 is a sparsity tuning parameter. Note that the sparsity penalization is placed only on A(j1), since this is the only layer that determines the sparsity of

the input variables X1, . . . , Xd. The optimization problem in (7) can be efficiently solved using

the augmented Lagrangian method (Zheng et al., 2020). Denote the estimated graph by G(s),

(s)
and the estimated set of ancestors of j by ACj .

(s)

(s)

If k / ACj , then it follows from PAj  ACj that k / PAj. Consequently, Xk is not

to directly influence Xj, and thus we simply set the corresponding p-value p(s)(j, k) = 1.

(s)
Our subsequent inference procedure is to focus on the case where k  ACj , and we set

M(js,k)

=

(s)
ACj - {k}.

We also remark that, the subsequent inference built on G(s)

does not

require

G (s)

to

be

consistent

to

G.

Instead,

we

only

require

P(PAj



(s)
ACj



DScj

- {j})



1.

14

3.3 Supervised learning

The second key component of our testing procedure is to learn a conditional mean function

gj(,sk)(x) = E

X |X j

Mj(s,k)

=

x

. This is essentially a regression problem, and there are many

methods available. In our implementation, we use the MLP again, by seeking

Ti

2

min j iIs t=1

Xi,t,j - MLP X ;  i,t,Mj(s,k) j

,

(8)

where the learner MLP(·) is as defined in (6). The optimization problem in (8) can be solved using a stochastic gradient descent algorithm, or the limited-memory Broyden-Fletcher-GoldfarbShanno algorithm (Byrd et al., 1995). Denote the estimated conditional mean function by gj(,sk)(x) = E Xj|XM-{k} = x .

3.4 Generative adversarial learning

The third key component of our testing procedure is to use GANs to produce a generator

G(s)(·, ·), such that the divergence between the conditional distribution of Xi,t,k given Xi,t,M(js,k)

and

that

of

(m)
Xi,t,k

given

Xi,t,Mj(s,k)

is

minimized.

To

that

end,

we

adopt

the

proposal

of

Genevay

et al. (2018) to learn the generator. Specifically, let µj,k and j,k denote the joint distribution of

X , X i,t,k i,t,Mj(s,k)

and

X , X (m) i,t,k

i,t,Mj(s,k)

, respectively. We estimate G(s) by optimizing

min max Dc,(µj,k, j,k).

(9)

Gc

Here Dc, is the Sinkhorn loss function between two probability measures µ, , with respect to a cost function c and a regularization parameter  > 0,

Dc,(µ, ) = 2Dc,(µ, ) - Dc,(µ, µ) - Dc,(, ),

Dc,(µ, ) = inf

c(x, y) - H(|µ  ) (dx, dy),

(µ,) x,y

where (µ, ) is a set containing all probability measures  whose marginal distributions cor-

respond to µ and , H is the Kullback-Leibler divergence, and µ   is the product measure

of µ and . When  = 0, Dc,0(µ, ) measures the optimal transport of µ into  with respect

15

to the cost function c(·, ·) (Cuturi, 2013; Genevay et al., 2016). When  = 0, an entropic reg-

ularization is added to this optimal transport. As such, the objective function Dc, in (9) is a

regularized optimal transport metric, and the regularization is to facilitate the computation, so

that Dc, can be efficiently evaluated.

Intuitively, the closer the two conditional distributions, the smaller the Sinkhorn loss. There-

fore, maximizing Dc, with respect to the cost function c learns a discriminator that can better

discriminate µj,k and j,k. On the other hand, minimizing the maximum cost with respect to the

generator

G

makes

the

conditional

distribution

of

(m)
Xi,t,k

given

Xi,t,Mj(s,k)

closer

to

that

of

Xi,t,k

given X . i,t,M(js,k) This yields the minimax formulation in (9). In our implementation, we approximate the cost function c and the generator based on

MLP (6). The distributions µj,k and j,k in (9) are approximated by the empirical distributions

of the data samples. The parameters involved in GANs are updated by the Adam algorithm

(Kingma and Ba, 2015). Denote the learnt generator by G(s). It takes Xi,t,Mj(s,k) and a set of multivariate Gaussian noise vectors {Zj(,mk )}M m=1 as the input, and returns the pseudo samples

(m)
Xi,t,k

=

G(s)(Xi,t,Mj(s,k) , Zj(,mk )),

m

=

1,

·

·

·

,

M,

as

the

output.

3.5 Test statistic and p-value

We next derive the test statistic and the corresponding p-value.

First, for each half of the data, s = 1, 2, we begin with a bounded function class H(s) = h(s) :   (s) , indexed by some parameter . In our implementation, we consider the class

of characteristic functions of Xk,

H(1) = H(2) = H = cos(Xk), sin(Xk) :   R .

(10)

Alternatively, one can set H(s) to the class of characteristic functions of (Xk, XMj(s,k)). By the Fourier Theorem (Siebert, 1986), such a choice of H(s) is able to approximate any square integrable function h in Theorem 1. Consequently, the resulting test is consistent against all alternatives. However, in our numerical experiments, we find that setting H(s) according to
(10) results in a better empirical performance in power. Although the test based on (10) is not

able to detect all alternatives, it is powerful for most practically interesting alternatives.

16

For simplicity, we choose an even number for the total number of transformation functions

B. We then randomly generate i.i.d. standard normal variables 1, . . . ,  B , and set 2

h(bs)

X , X k

Mj(s,k)

=

cos(bXk), sin(bXk),

for b = 1, . . . , B/2, for b = B/2 + 1, . . . , B.

Next, for each pair of (s, b), b = 1, . . . , B, s = 1, 2, we compute two estimators Ib(,sC)F

and Ib(,sN)CF for the measure I

j,

(s)
k|ACj ,

h(bs)

, one with cross-fitting, and the other without

cross-fitting. Specifically, we compute



-1 



Ib(,sC)F =  Ti
iIsc

 Ii(,st),b ,
iIsc

Ib(,sN)CF =

-1

Ti

Ii(,st),b ,

iIs

iIs

where

Ii(,st),b = Xi,t,j - gj(,sk) Xi,t,M(js,k)

h(bs)

X , X i,t,k i,t,M(js,k)

1 -
M

M

h(bs)

X , X (m) i,t,k

i,t,M(js,k)

,

m=1

and M is the total number of pseduo samples generated by G(s). We remark that, for Ib(,sN)CF,

we use the same subset of data to learn the graph, the generator, the condition mean function,

and to construct Ii(,st),b. By contrast, for Ib(,sC)F, the data used for the DAG learner, the conditional mean learner and the generator are independent from the data used to construct Ii(,st),b.
Next, we compute the corresponding standard errors b(,sC)F and b(,sN)CF for Ib(,sC)F and Ib(,sN)CF,

respectively. We note that, since our data observations are time-dependent, the usual sample

variance would not be a consistent estimator. To address this issue, we employ the batched

estimator that is commonly used in time series analysis (Carlstein, 1986). That is, we divide

the data associated with each subject into non-overlapping batches, with each batch containing

at most K observations. For simplicity, suppose Ti is divisible by K for all i = 1, . . . , N . We

then obtain the following standard error estimators,



b(,sC)F

=

 



K

Ti/K


T  iIsc i iIsc k=1

kK t=(k-1)K +1

Ii(,st),b - Ib(,sC)F



K

21/2
 , 




b(,sN) CF

=

 



K

Ti/K


iIs Ti iIs k=1 

kK t=(k-1)K +1

Ii(,st),b - Ib(,sN)CF



K

21/2
 . 


17

Putting Ib(,sC)F and Ib(,sN)CF together with their standard error estimators, we obtain two standardized measures,

Tb(,sC)F =

iIsc

Ti

Ib(,sC)F , b(,sC)F

and Tb(,sN)CF =

iIs

Ti

Ib(,sN)CF . b(,sN) CF

(11)

Finally, we select the index b(s) that maximizes the standardized measure without crossfitting, Tb(,sN)CF, in absolute value. That is,

b(s) = arg max Tb(,sN)CF . b{1,...,B}

We

take

the

measure

with

cross-fitting,

T (s) b(s)

,
,CF

under

the

selected

b(s)

,

as

our

final

test

statistic.

Note

that,

b(s)

is

selected

so

that

the

test

based

on

T (s) b(s),CF

achieves

the

largest

power

asymp-

totically. Meanwhile, since b(s) is determined by Tb(,sN)CF, it depends solely on the data in Is,

and is independent of the data in Isc. This allows us to derive the limiting distribution of

T (s) b(s),CF

and

compute

the

corresponding

p-value

easily.

Specifically, for each b

=

1, . . . , B,

Tb(,sC)F converges in distribution to standard normal under the null hypothesis H0(j, k); see The-

orem 2.

Since b(s)

is independent of the

data

in Isc,

T (s) b(s) ,CF

converges in

distribution

to stan-

dard normal under H0(j, k) as well. We thus compute the p-value for each half of the data

as p(s)(j, k) = 2

Z0 >

T (s) b(s) ,CF

, s = 1, 2, where Z0 denotes a standard normal random

variable. The final p-value of the test is then p(j, k) = 2 min p(1)(j, k), p(2)(j, k) .

4 Bidirectional theories

In this section, we first establish the asymptotic size and power of the proposed test. We then derive the oracle property of the DAG estimator produced by (7), which is needed to guarantee the validity of the test. To simplify the theoretical analysis, we assume T1 = . . . = Tn = T . All the asymptotic results are derived when either the number of subjects N , or the number of time points T , diverges to infinity. The results of this type provide useful theoretical guarantees for different types of applications, and are referred as bidirectional theories.

18

4.1 Asymptotic size and power

We begin with a set of regularity conditions needed for the asymptotic consistency of the test.

(C1)

With probability approaching one, PAj



(s)
ACj



DScj

-

{j}.

(C2) Suppose E gj(,sk) XM(js,k)

- g X (s)

j,k

Mj(s,k)

2
= O {(N T )-21} for some constant 1 > 0.

In addition, gj(,sk) is uniformly bounded almost surely.

(C3) Suppose E supBB P Xk  B|XM(js,k)

-P

G(s)

X , Z M(js,k)

(m) j,k

 B| XM(js,k)

2
=

O {(N T )-22} for some constant 2 > 0, where B denotes the Borel algebra on R.

(C4) The random process {Xi,t}t0 is -mixing if T diverges to infinity. The -mixing coefficients {(q)}q satisfy that q q3(q) < + for some constant 3 > 0. Here, (q) denotes the -mixing coefficient at lag q, which measures the time dependence between

the set of variables {Xi,j}jt and {Xi,j}jt+q. (C5) Suppose the number of observations K in the batched standard error estimators b(,sC)F and
b(,sN)CF satisfies that, K = T if T is bounded, and T (1+3)-1 K N T otherwise.

Assumptions (C1)-(C3) characterize the theoretical requirements on the three learners, respectively. In particular, Assumption (C1) concerns about the structural learner of DAG, and we show in Section 4.2 that (C1) holds when (7) is employed to estimate DAG. Assumption (C2) requires the squared prediction loss of the supervised learner of the conditional mean function to satisfy a certain convergence rate, whereas Assumption (C3) requires the squared total variation norm between the conditional distributions of the observed samples and the pseudo samples to satisfy a certain convergence rate. If some parametric models are imposed to learn the conditional mean function gj(,sk) and the generator G(s), we have 1 = 2 = 1/2 in general. In our setup, we do not impose any parametric models, and only require 1 + 2 > 1/2. When using the multilayer perceptron models and GANs for function approximation, the corresponding convergence rates have been established (see e.g., Schmidt-Hieber, 2017; Farrell et al., 2021; Liang, 2018; Bauer and Kohler, 2019; Chen et al., 2020). Consequently, both (C2) and (C3) are satisfied under some mild conditions. Assumption (C4) characterizes the dependence of the data observations over time, and is commonly imposed in the time series literature

19

(Bradley, 2005). We also note that, (C4) is not needed when T is bounded but N diverges to infinity. Assumption (C5) guarantees the consistency of the batched standard error estimators b(,sC)F and b(,sN)CF, and is easily satisfied, since K is a parameter that we specify. When T is bounded and is relatively small compared to a large sample size N , we can simply set K = T , i.e., treating the entire time series as one batch.
We next establish the asymptotic size of the propose testing procedure.

Theorem 2 (Size). Suppose (1), (C1)-(C5) hold. Suppose minb N T Var Ib(,sC)F| {Xi,t}iIs,1tT  4 for some constant 4 > 0. If the constants 1, 2, 3 satisfy that 1 + 2 > 1/2, 3 > max[{2 min(1, 2)}-1 - 1, 2], then, as either N or T  ,

(a)

The test statistic T (s) b(s),CF

d Normal(0, 1) under H0(j, k).

(b) The p-value satisfies that P{p(j, k)  }   + o(1), for any nominal level 0 <  < 1.

To establish the asymptotic size of the test, we require the convergence rates of the supervised

learner and the generator satisfy 1 + 2 > 1/2, which is slower than the usual parametric rate. We also require (q) to decay at a polynomial rate with respect to q. Such a condition

holds for many common time series models (see, e.g., McDonald et al., 2015). We also require

a minimum variance condition, which automatically holds when the conditional variance of

h(bs)

X , X k

Mj(s,k)

-E

h(bs)

X , X k

M(js,k)

|XM(js,k)

given XM(js,k) is bounded away from zero. Un-

der these conditions, we establish the asymptotic normality of the test statistic Tb((ss)),CF, which

further implies that the p-value p(s)(j, k) converges to a uniform distribution on [0, 1]. By Bon-

ferroni's inequality, p(j, k) is a valid p-value, and consequently, the proposed test achieves a

valid control of type-I error.

Next, we study the asymptotic power of the test. We introduce a quantity to character-

ize the degree to which the alternative hypothesis deviates from the null for a given func-

tion class H: (H) = minM suphH |I(j, k|M; h)|, where the minimum is taken over all subsets M that satisfy the conditions in Proposition 1. When H is taken over the class of

characteristic functions of (Xk, XM), we have (H) > 0. In addition, we introduce the

notion of the VC type class (Chernozhukov et al., 2014, Definition 2.1). Specifically, let

20

F denote a class of measurable functions, with a measurable envelope function F such that supfF |f |  F . For any probability measure Q, let eQ denote a semi-metric on F such that eQ(f1, f2) = f1 - f2 Q,2 = |f1 - f2|2dQ. An -net of the space (F , eQ) is a subset F of F, such that for every f  F, there exists some f  F satisfying eQ(f, f ) < . We say that F is a VC type class with envelope F , if there exist constants c0 > 0, c1  1, such that supQ N (F , eQ, F Q,2)  (c0/ )c1, for all 0 <  1, where the supremum is taken over all finitely discrete probability measures on the support of F , and N (F , eQ, F Q,2) is the infimum of the cardinality of F Q,2-nets of F . We refer to c1 as the VC index of F . To simplify the analysis, we also suppose Xj is bounded, and without loss of generality, its support is [0, 1].
Theorem 3 (Power). Suppose the conditions in Theorem 2 hold, and the -mixing coefficient (q) in (C4) satisfies that (q) = O(q5) for some constant 0 < 5 < 1 when T diverges. Suppose (H) (N T )-1/2 log(N T ) under H1(j, k). Suppose, with probability tending to one, gj(,sk) and G(s) belong to the class of VC type functions with bounded envelope functions and the bounded VC indices no greater than O{(N T )min(21,22,1/2)}, s = 1, 2. If the number of transformation functions B = 6(N T )7 for some constants 6 > 0, 7  1/2, then, as either N or T  , p(j, k) p 0 under H1(j, k).
To establish the asymptotic power of the test, we require the function gj(,sk) and the generator G(s) to both belong to the VC type class. This is to help establish the concentration inequalities for the measure Ib(,sN)CF without cross-fitting. This assumption automatically holds in our implementation where the MLP is used to model both (Farrell et al., 2021). We have also strengthened the requirement on (q), so that it decays exponentially with respect to q. This
 is to ensure the N T -consistency of the proposed test when T  . This condition holds when the process {Xi,t}t0 forms a recurrent Markov chain with a finite state space. It also holds for more general state space Markov chains (see, e.g., Bradley, 2005, Section 3). Under these conditions, this theorem shows that our proposed test is consistent against some local
 alternatives that are N T -consistent to the null up to some logarithmic term.
21

4.2 Oracle property of the DAG learner

As a by-product of theoretical analysis, we derive the oracle property of the DAG estimator
(s)
produced by (7). This result is to guarantee P j{1,··· ,d}{PAj  ACj }  1, which was not
available in Zheng et al. (2020). It implies that the ordering of the true DAG can be consistently

estimated, which in turn ensures the validity of (C1). See Theorem 4 for details.

We first define the oracle estimator. For an ordering  = (1, . . . , d) for a given DAG, consider the estimator (s)() = 1(s)(), . . . , d(s)() , where each j(s)() is obtained by

j =

arg min
A(j1),b(1),...,Aj(L),b(L) supp

A(j1)

{1,...,j-1} iIs

T

{Xi,t,j

-

MLP(Xi,t;

j )}2

+

N T 2

t=1

A(j1) 1,1,

where supp A(j1)  {1, . . . , j-1} means that, for any l that does not belong to this set, the lth column of A(j1) equals zero. In other words, the estimator j(s)() is computed as if the order  were known in advance.

Next, let  denote the set of all true orderings. This means, for any true ordering   ,

PAj  {1, . . . , j-1}, for any j = 1, . . . , d. In other words, the parents of each node should appear before the occurrence of this node under . It is also worth mentioning that, the true

ordering is not necessarily unique, even though the underlying DAG is unique. For instance,

consider Example 1 with a v-structure as shown in Figure 1(a). In this example, both (1, 2, 3)

and (1, 3, 2) are the true orderings, as there are no directional edges between nodes X2 and X3.

Next, we introduce some additional conditions. For any ordering , define a least squares

loss function, L() =

d-1
j=0 E

Xj+1 - E

Xj +1 |X{1 ,...,j }

2. Moreover, we focus on neural

networks with a ReLU activation function, (x) = max(0, x).

(C6) All minimizers of L() are contained in . (C7) The widths of all layers in the MLP share a common asymptotic order H. Besides,
the number of layers L and the asymptotic order H diverge with N T , in that HL = O{(N T )8}, for some constant 8 < 1/2. (C8) Suppose MLP ·; (s)() is bounded for any .

22

Assumption (C6) is reasonable and holds in numerous scenarios. One example is when all the random errors {j}dj=1 in model (1) are normally distributed with equal variance. In that case, the least squares loss L is proportional to the expected value of the log-likelihood of X. Since the underlying DAG is identifiable, any ordering that minimizes the expected log-likelihood belongs to . Assumption (C7) is also mild, as both H and L are the parameters that we specify. The part that HL = O{(N T )8} ensures that the stochastic error resulting from the parameter estimation in the MLP is negligible. Assumption (C8) ensures that the optimizer would not diverge in the  sense. Similar assumptions are common in the literature to derive the convergence rates of deep learning estimators (see e.g. Farrell et al., 2021).
Now we show that the estimator (s) obtained from (7) satisfies the oracle property, i.e., (s) = (s)(), for some   . In other words, (s) is computed as if one of the true ordering were known in advance. By the definition of , Assumption (C1) holds for our estimated DAG. Moreover, we note that the oracle property does not imply the selection consistency, i.e., PAj = PAj for any j = 1, . . . , d. Nor does it imply the sure screening property, in that PAj  PAj for any j = 1, . . . , d.
Theorem 4. Suppose (C6)-(C8) hold, the -mixing coefficient (q) in (C4) decays exponentially with q, and   0. Then, with probability approaching one, (s) = (s)(), for some   , as either N or T  .
5 Simulations
In this section, we examine the finite-sample performance of the proposed testing procedure. We begin with a discussion of some implementation details. Our test employs three neural
networks-based learners, which involve some tuning parameters. Many of these parameters are standard in neural networks learning, e.g., the number of hidden layers, the number of hidden nodes in each layer, the activation function, batch size, and epoch size. In our implementation, we set those parameters at their usual values as recommended by the literature. Specifically, for the DAG learning step, one tuning parameter is the sparsity parameter  in (7). Following
23

a similar strategy as in Zheng et al. (2020), we fix  = 0.025 in our implementation to speed up the computation. We have also experimented with a number of values of  in some interval and find the results are not overly sensitive. Moreover,  can be tuned via cross-validation. We set the rest of the parameters the same as in the implementation of Zheng et al. (2020). For the supervised learning step, we employ the multilayer perceptron regressor implementation of Pedregosa et al. (2011). For the GANs training step, we follow the implementation of Genevay et al. (2018). There are three additional parameters associated with our test, including the number of transformation functions B, the number of pseudo samples M produced by the GAN generator, and the number of observations K in the batched standard error estimators b(,sC)F and b(,sN)CF. We have found that the results are not sensitive to the choice of M and K, and we fix M = 100 and K = 20. For B, a larger value generally improves the power of the test, but also increases the computational cost. In our implementation, we set B = 2000, which achieve a reasonable balance between the test accuracy and the computational cost.
We compare the proposed test with two alternative solutions, the double regression-based test (DRT) as outlined in Section 2.2, and the constrained likelihood ratio test (LRT) proposed by Li et al. (2020) for linear DAGs. The implementation of DRT is similar to our proposed method. The main difference lies in that DRT uses the MLP regressor to first estimate the conditional mean function E(Xk|XM(jj,k) ) in Step 4, then plugs in this estimate to construct the test statistic in Step 5, with B = 1 and h(1s)(Xk, XMj(j,k) ) = Xk.
We consider two different models, a nonlinear DAG and a linear DAG,

Xt,j =

c f (1) j,k1,k2 j,k1,k2

(Xt,k1 )fj(,2k)1,k2

(Xt,k2

)

+

cj,k3 fj(,3k)3 (Xt,k3 ) + t,j ;

k1,k2PAj k1k2

k3PAj

Xt,j =

cj,kXt,k + t,j .

kPAj

(12) (13)

The data generation follows that of Zhu et al. (2020). Specifically, for the nonlinear model (12),

the

functions

f (1) j,k1,k2

,

fj(,2k)1,k2 ,

and

fj(,3k)3

are

randomly

set

to

be

sine

or

cosine

function

with

equal

possibility, whereas the coefficients cj,k1,k2 and cj,k3 are randomly generated from the uniform

distribution [0.5, 1.5] or [-1.5, -0.5] with equal possibility. For the linear model (13), cj,k is

24

Table 1: The percentage of times out of 500 data replications when the p-value is smaller than the nominal level . Three methods are compared: our proposed test (SUGAR), the double regression-based test (DRT), and the constrained likelihood ratio test (LRT). This table reports the results for the nonlinear model (12) with d = 50,  = 0.1.

Edge

j=35, k=5

j=35, k=31

j=40, k=16

Hypothesis

H0

H0

H0

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.050 0.108 1.000 0.012 0.068 0.316 0.016 0.016 1.000

 = 0.10 0.078 0.154 1.000 0.032 0.098 0.412 0.032 0.030 1.000

Edge

j=45, k=14

j=45, k=15

j=50, k=14

Hypothesis

H0

H0

H0

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.014 0.026 1.000 0.032 0.054 0.954 0.030 0.096 1.000

 = 0.10 0.030 0.050 1.000 0.058 0.092 0.964 0.046 0.126 1.000

Edge

j=35, k=4

j=35, k=30

j=40, k=15

Hypothesis

H1

H1

H1

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.534 0.082 1.000 0.992 0.728 0.204 0.550 0.204 0.102

 = 0.10 0.546 0.126 1.000 0.992 0.818 0.290 0.550 0.264 0.180

Edge

j=45, k=12

j=45, k=13

j=50, k=13

Hypothesis

H1

H1

H1

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.946 0.524 0.988 0.808 0.248 0.832 0.670 0.188 0.730

 = 0.10 0.948 0.616 0.996 0.816 0.318 0.870 0.672 0.252 0.824

the coefficient randomly generated from the uniform distribution [0.3, 0.5] or [-0.3, -0.5] with equal possibility. Then a portion of coefficients are randomly set to zero. For both linear and nonlinear cases, the error t,j is an AR(0.5) process with a standard normal white noise. The DAG structure is determined by a d×d lower triangular binary adjacency matrix, in which each entry is randomly sampled from a Bernoulli distribution with the success probability . For the nonlinear model (12), we consider three combinations, (d, ) = (50, 0.1), (d, ) = (100, 0.04), and (d, ) = (150, 0.02), and for the linear model (13), we consider (d, ) = (50, 0.1). In all cases, we set the number of subjects N = 20, and the number of time points T = 100.
Tables 1-4 report the empirical size and power, i.e., the percentage of times out of 500 data replications when the p-value is smaller than two nominal levels  = 0.05 and  = 0.1

25

Table 2: Results for model (12) with d = 100,  = 0.04. The rest is the same as Table 1.

Edge

j=80, k=37

j=85, k=29

j=85, k=68

Hypothesis

H0

H0

H0

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.002 0.002 0.116 0.004 0.022 1.000 0.004 0.004 0.306

 = 0.10 0.006 0.004 0.186 0.018 0.032 1.000 0.004 0.008 0.390

Edge

j=90, k=18

j=90, k=67

j=90, k=69

Hypothesis

H0

H0

H0

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.018 0.030 0.156 0.010 0.022 0.922 0.006 0.020 0.820

 = 0.10 0.032 0.038 0.252 0.032 0.048 0.942 0.016 0.034 0.876

Edge

j=80, k=36

j=85, k=28

j=85, k=69

Hypothesis

H1

H1

H1

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.726 0.186 0.740 0.276 0.120 0.826 0.524 0.254 1.000

 = 0.10 0.726 0.250 0.798 0.296 0.162 0.878 0.528 0.294 1.000

Edge

j=90, k=19

j=90, k=66

j=90, k=68

Hypothesis

H1

H1

H1

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.084 0.026 0.320 0.528 0.042 0.438 0.604 0.078 0.378

 = 0.10 0.112 0.042 0.426 0.536 0.074 0.502 0.606 0.124 0.464

respectively, for a set of pairs (j, k), j, k = 1, . . . , d, in the network. First of all, we have observed that our proposed test consistently outperforms the competing ones for all pairs of edges, in that the size is well controlled if H0 is true, and the power is equal or larger if H1 is true. We have chosen 12 pairs to report in the tables, not because our method performs the best on those pairs, but because the differences between the three methods are relatively distinctive for those pairs. For instance, if the methods achieve about the same power on an edge, we do not choose that edge in the tables. It is clearly seen from the tables that the proposed test achieves a competitive performance. In particular, the test of Li et al. (2020) has difficulty to control the type I error, while the double regression-based test suffers from a lower power for a number of edges in Tables 1 to 3, and some inflated type I error in Table 4. These findings also agree with our analytical analysis.
In terms of computing time, our testing procedure consists of two main parts: the DAG

26

Table 3: Results for model (12) with d = 150,  = 0.02. The rest is the same as Table 1.

Edge Hypothesis

j=132, k=123
H0

j=135,
k=69 H0

j=135, k=84 H0

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.006 0.018 0.768 0.068 0.084 0.472 0.008 0.010 0.222

 = 0.10 0.014 0.026 0.848 0.118 0.132 0.598 0.010 0.018 0.298

Edge

j=137, k=12

j=137, k=124

j=140, k=44

Hypothesis

H0

H0

H0

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.014 0.016 1.000 0.020 0.038 0.970 0.002 0.000 0.194

 = 0.10 0.020 0.024 1.000 0.044 0.068 0.986 0.002 0.002 0.270

Edge

j=132, k=125

j=135, k=72

j=135, k=81

Hypothesis

H1

H1

H1

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.678 0.254 0.936 0.832 0.742 0.994 0.842 0.740 0.876

 = 0.10 0.684 0.354 0.968 0.832 0.772 0.998 0.842 0.768 0.922

Edge

j=137, k=11

j=137, k=123

j=140, k=46

Hypothesis

H1

H1

H1

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.962 0.616 0.192 0.690 0.358 0.998 0.938 0.744 0.980

 = 0.10 0.962 0.710 0.262 0.690 0.412 0.998 0.938 0.812 0.992

estimation in Step 2 of Algorithm 1, and the rest of testing in Steps 3 to 6. The DAG estimation is the most time consuming step, but it only needs to be learnt once for all pairs of edges in the graph. We implemented the DAG estimation step on NVIDIA Tesla T4 GPU, and it took about 5 to 20 minutes when d ranges from 50 to 150 for one data replication. We implemented the rest of testing on N1 standard CPU, and it took about 2 minutes for one data replication.

6 Brain effective connectivity analysis

We next illustrate our method with a brain effective connectivity analysis based on task-evoked functional magnetic resonance imaging (fMRI) data. The brain is a highly interconnected dynamic system, and it is of great interest in neuroscience to understand the directional relations among the neural elements through fMRI, which measures synchronized blood oxygen level dependent signals at different brain locations. The dataset we analyze is part of the Human
27

Table 4: Results for model (13) with d = 50,  = 0.1. The rest is the same as Table 1.

Edge

j=40, k=16

j=40, k=29

j=45, k=14

Hypothesis

H0

H0

H0

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.034 0.034 0.120 0.014 0.026 0.148 0.056 0.114 0.196

 = 0.10 0.058 0.046 0.182 0.024 0.036 0.218 0.114 0.178 0.258

Edge

j=45, k=15

j=50, k=14

j=50, k=20

Hypothesis

H0

H0

H0

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.020 0.032 0.138 0.038 0.084 0.244 0.030 0.054 0.076

 = 0.10 0.032 0.048 0.192 0.054 0.124 0.296 0.054 0.082 0.12

Edge

j=40, k=15

j=40, k=28

j=45, k=12

Hypothesis

H1

H1

H1

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.812 0.944 0.998 0.500 0.520 1.000 0.986 1.000 1.000

 = 0.10 0.852 0.944 0.998 0.504 0.520 1.000 0.990 1.000 1.000

Edge

j=45, k=13

j=50, k=13

j=50, k=21

Hypothesis

H1

H1

H1

Method SUGAR DRT LRT SUGAR DRT LRT SUGAR DRT LRT

 = 0.05 0.994 1.000 1.000 0.998 1.000 1.000 0.992 1.000 1.000

 = 0.10 0.996 1.000 1.000 0.998 1.000 1.000 0.992 1.000 1.000

Connectome Project (HCP, Van Essen et al., 2013), whose overarching objective is to understand brain connectivity patterns of healthy adults. We study the fMRI scans of a group of individuals who undertook a story-math task. The task consists of blocks of auditory stories and addition-subtraction calculations, and requires the participant to answer a series of questions. An accuracy score is given at the end based on the participant's answers. We analyze two subsets of individuals with matching age and sex. One set consists of N = 28 individuals who scored below 65 out of 100, and the other set consists of N = 28 individuals who achieved the perfect score of 100. All fMRI scans have been preprocessed following the pipeline of Glasser et al. (2013), which summarizes each fMRI scan as a matrix of time series data. Each row is a time series with length T = 316, and there are 264 rows corresponding to 264 brain regions (Power et al., 2011). Those brain regions are further grouped into 14 functional modules (Smith et al., 2009). Each module possesses a relatively autonomous functionality, and complex brain

28

tasks are believed to perform through coordinated collaborations among the modules. In our analysis, we concentrate on d = 127 brain regions from four functional modules: auditory, visual, frontoparietal task control, and default mode, which are usually believed to be involved in language processing and problem solving task domain (Barch et al., 2013).
We apply the proposed test to the two datasets separately. We control the false discovery at 0.05 using the standard Benjamini-Hochberg procedure (Benjamini and Hochberg, 1995). Table 5 reports the number of identified significant within-module and between-module connections. We first note that, we have identified many more within-module connections than the between-module connections. The partition of the brain regions into the functional modules has been fully based on the biological knowledge, and our finding lends some numerical support to this partition. In addition, we have identified more within-module connections for the frontoparietal task control module for the high-performance subjects than the low-performance subjects, while we have identified fewer within-module connections for the default mode and visual modules for the high-performance subjects. These findings generally agree with the neuroscience literature. Particularly, the frontoparietal network is known to be involved in sustained attention, complex problem solving and working memory (Menon, 2011), and the highperformance group exhibits more active connections for this module. On the other hand, the default mode network is more active during passive rest and mind-wandering, which usually involves remembering the past or envisioning the future rather than the task being performed (Van Praag et al., 2017), and the high-performance group exhibits fewer active connections for this module.
7 Extensions
In this section, we discuss several extensions. In addition to a given edge, we can also test a directed pathway, or a union of directional relations. Furthermore, we can extend the test to the scenario when Xj is categorical and follows a generalized type model.
29

Table 5: The number of identified significant within-module and between-module connections of the four functional modules for the low-performance group ("low" with the score below 65) and the high-performance group ("high" with the perfect score of 100). The number in the parenthesis is the number of brain regions of each functional module.

Auditory (13)
Default mode (58) Visual (31)
Fronto-parietal (25)

Auditory (13)
low high

20 17

0

0

0

0

2

1

Default mode (58)
low high

0

0

68 46

3

2

11 23

Visual (31)
low high

0

1

3

2

56 46

0

1

Fronto-parietal (25)
low high

2

0

11 23

0

1

22 27

7.1 Testing a directed pathway
Suppose the goal is to test a given directed pathway, j1  j2  . . .  jK, where j1, j2, . . . , jK are a sequence of nodes in the DAG. The problem can be formulated as the pair of hypotheses:
H0 : H0(jk, jk+1) holds for some k, versus (14)
H1 : H0(jk, jk+1) does not hold for any k = 1, . . . , d.
Under this alternative, each individual null hypothesis H0(jk, jk+1) does not hold. Consequently, there exists such a directed pathway. The hypotheses in (14) can be tested using the union-intersection principle. Specifically, let p(jk, jk+1) denote the p-value for H0(jk, jk+1) from the proposed test. Then it is straightforward to show that maxk p(jk, jk+1) is a valid p-value for (14). Based on Theorems 2 and 3, we can also show that such a test is consistent.

7.2 Testing a union of directional relations
Suppose the goal is to test a union of the hypotheses lLH0(jl, kl). We first apply the proposed test to construct two standardized measures, Tb(,sC)F(jl, kl) and Tb(,sN)CF(jl, kl), with and without cross-validation, for each b = 1, . . . , B, s = 1, 2, and l  L. Then for each s, we select the indices b(s) and l(s) that yield the largest measure maxb,l |Tb(,sN)CF(jl, kl)| in the absolute value.
30

We

then

construct

the

Wald

type

test

statistic

T (s) b(s),CF

j , k l(s) l(s)

. Based on Theorems 2 and 3,

we can establish the consistency of this test.

7.3 Extension to generalized linear models
We can further extend the proposed test to the following class of models:

E(Xj|XPAj ) = j fj(XPAj ) , for any j = 1, . . . , d,
where the link function j is pre-specified while the function fj is unspecified. For instance, when Xj is binary, we may set j as the logistic function. Similar to Theorem 1, we can show that the null hypothesis in (4) is equivalent to I(j, k|M; h) = 0, for all square-integrable function h. Therefore, the proposed test can be applied to this class of models as well.

References
Barch, D. M., Burgess, G. C., et al. (2013). Function in the human connectome: Task-fmri and individual differences in behavior. NeuroImage, 80:169 ­ 189. Mapping the Connectome.
Bauer, B. and Kohler, M. (2019). On deep learning as a remedy for the curse of dimensionality in nonparametric regression. The Annals of Statistics, 47(4):2261­2285.
Benjamini, Y. and Hochberg, Y. (1995). Controlling the false discovery rate: A practical and powerful approach to multiple testing. Journal of the Royal Statistical Society, Series B., 57:289­300.
Bradley, R. C. (2005). Basic properties of strong mixing conditions. A survey and some open questions. Probability Survey, 2:107­144. Update of, and a supplement to, the 1986 original.
Bullmore, E. and Sporns, O. (2009). Complex brain networks: graph theoretical analysis of structural and functional systems. Nature reviews. Neuroscience, 10(3):186­198.
Byrd, R. H., Lu, P., Nocedal, J., and Zhu, C. (1995). A limited memory algorithm for bound constrained optimization. SIAM Journal on scientific computing, 16(5):1190­1208.
31

Carlstein, E. (1986). The use of subseries values for estimating the variance of a general statistic from a stationary sequence. The Annals of Statistics, 14(3):1171­1179.
Chen, M., Liao, W., Zha, H., and Zhao, T. (2020). Statistical guarantees of generative adversarial networks for distribution estimation. arXiv preprint arXiv:2002.03938.
Chernozhukov, V., Chetverikov, D., and Kato, K. (2014). Gaussian approximation of suprema of empirical processes. Ann. Statist., 42(4):1564­1597.
Chickering, D. M., Heckerman, D., and Meek, C. (2004). Large-sample learning of bayesian networks is np-hard. Journal of Machine Learning Research, 5:1287­1330.
Cuturi, M. (2013). Sinkhorn distances: Lightspeed computation of optimal transport. In Advances in neural information processing systems, pages 2292­2300.
Farrell, M. H., Liang, T., and Misra, S. (2021). Deep neural networks for estimation and inference. Econometrica, 89(1):181­213.
Friston, K. J. (2011). Functional and effective connectivity: A review. Brain Connectivity, 1(1):13­36.
Gao, Q. and Wang, X. (2021). Theoretical investigation of generalization bounds for adversarial learning for deep neural networks. Journal of Statistical Theory and Practice, 15:1­28.
Garg, R., Cecchi, G., and Rao, R. (2011). Full-brain auto-regressive modeling (farm) using fmri. NeuroImage, 58:416­41.
Genevay, A., Cuturi, M., Peyre´, G., and Bach, F. (2016). Stochastic optimization for large-scale optimal transport. In Advances in neural information processing systems, pages 3440­3448.
Genevay, A., Peyre´, G., and Cuturi, M. (2018). Learning generative models with sinkhorn divergences. In International Conference on Artificial Intelligence and Statistics, pages 1608­ 1617.
Glasser, M. F., Sotiropoulos, S. N., et al. (2013). The minimal preprocessing pipelines for the human connectome project. Neuroimage, 80:105­124.
32

Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems, pages 2672­2680.
Gui, J., Sun, Z., Wen, Y., Tao, D., and Ye, J. (2020). A review on generative adversarial networks: Algorithms, theory, and applications. arXiv preprint arXiv:2001.06937.
Jankova´, J. and van de Geer, S. (2019). Inference in high-dimensional graphical models. In Handbook of graphical models, Chapman & Hall/CRC Handb. Mod. Stat. Methods, pages 325­349. CRC Press, Boca Raton, FL.
Kang, J., Bowman, F. D., Mayberg, H., and Liu, H. (2016). A depression network of functionally connected regions discovered via multi-attribute canonical correlation graphs. NeuroImage, 141:431­441.
Kingma, D. P. and Ba, J. (2015). Adam: A method for stochastic optimization. In Bengio, Y. and LeCun, Y., editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.
Kingma, D. P. and Welling, M. (2013). Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114.
Li, C. and Fan, X. (2019). On nonparametric conditional independence tests for continuous variables. Wiley Interdisciplinary Reviews: Computational Statistics, page e1489.
Li, C., Shen, X., and Pan, W. (2020). Likelihood ratio tests for a large directed acyclic graph. Journal of the American Statistical Association, 115(531):1304­1319.
Liang, T. (2018). On how well generative adversarial networks learn densities: Nonparametric and parametric results. arXiv preprint arXiv:1811.03179.
McDonald, D. J., Shalizi, C. R., and Schervish, M. (2015). Estimating beta-mixing coefficients via histograms. Electronic Journal of Statistics, 9(2):2855­2883.
33

Menon, V. (2011). Large-scale brain networks and psychopathology: a unifying triple network model. Trends in Cognitive Sciences, 15(10):483­506.
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825­2830.
Peters, J., Mooij, J. M., Janzing, D., and Scho¨lkopf, B. (2014). Causal discovery with continuous additive noise models. J. Mach. Learn. Res., 15:2009­2053.
Power, J. D., Cohen, A. L., et al. (2011). Functional network organization of the human brain. Neuron, 72(4):665­678.
Qiu, H., Han, F., Liu, H., and Caffo, B. (2016). Joint estimation of multiple graphical models from high dimensional time series. Journal of the Royal Statistical Society Series B., 78(2):487­504.
Romano, J. and DiCiccio, C. (2019). Multiple data splitting for testing. Technical report, Technical report.
Sachs, K., Perez, O., Peter, D., Lauffenburger, D. A., and Nolan, G. P. (2005). Causal proteinsignaling networks derived from multiparameter single-cell data. Science, 308(5721):523­ 529.
Schmidt-Hieber, J. (2017). Nonparametric regression using deep neural networks with relu activation function. arXiv preprint arXiv:1708.06633.
Shah, R. D. and Peters, J. (2018). The hardness of conditional independence testing and the generalised covariance measure. arXiv preprint arXiv:1804.07203.
Siebert, W. M. (1986). Circuits, signals, and systems. MIT press.
Smith, S. D., Fox, P. T., Miller, K., Glahn, D., Fox, P., Mackay, C. E., Filippini, N., Watkins, K. E., Toro, R., Laird, A., and Beckmann, C. F. (2009). Correspondence of the brain;
34

functional architecture during activation and rest. Proceedings of the National Academy of Sciences of the United States of America, 106:13040­5.
Spirtes, P., Glymour, C., and Scheines, R. (2000). Causation, prediction, and search. Adaptive Computation and Machine Learning. MIT Press, Cambridge, MA, second edition. With additional material by David Heckerman, Christopher Meek, Gregory F. Cooper and Thomas Richardson, A Bradford Book.
van de Geer, S. and Bu¨hlmann, P. (2013). 0-penalized maximum likelihood for sparse directed acyclic graphs. The Annals of Statistics, 41(2):536­567.
Van Essen, D. C., Smith, S. M., Barch, D. M., Behrens, T. E., Yacoub, E., Ugurbil, K., Consortium, W.-M. H., et al. (2013). The wu-minn human connectome project: an overview. Neuroimage, 80:62­79.
Van Praag, C. D. G., Garfinkel, S. N., Sparasci, O., Mees, A., Philippides, A. O., Ware, M., Ottaviani, C., and Critchley, H. D. (2017). Mind-wandering and alterations to default mode network connectivity when listening to naturalistic versus artificial sounds. Scientific Reports, 7:45273.
Wang, Y., Kang, J., Kemmer, P. B., and Guo, Y. (2016). An efficient and reliable statistical method for estimating functional connectivity in large scale brain networks using partial correlation. Frontiers in Neuroscience, 10:1­17.
Yu, Y., Chen, J., Gao, T., and Yu, M. (2019). Dag-gnn: Dag structure learning with graph neural networks. In International Conference on Machine Learning, pages 7154­7163.
Yuan, Y., Shen, X., Pan, W., and Wang, Z. (2019). Constrained likelihood for reconstructing a directed acyclic Gaussian graph. Biometrika, 106(1):109­125.
Zhang, H., Zhou, S., and Guan, J. (2018). Measuring conditional independence by independent residuals: Theoretical results and application in causal discovery. In Thirty-Second AAAI Conference on Artificial Intelligence.
35

Zheng, X., Aragam, B., Ravikumar, P. K., and Xing, E. P. (2018). Dags with no tears: Continuous optimization for structure learning. In Advances in Neural Information Processing Systems, pages 9472­9483.
Zheng, X., Dan, C., Aragam, B., Ravikumar, P., and Xing, E. P. (2020). Learning sparse nonparametric DAGs. In International Conference on Artificial Intelligence and Statistics.
Zhu, S., Ng, I., and Chen, Z. (2020). Causal discovery with reinforcement learning. In International Conference on Learning Representations.
36

