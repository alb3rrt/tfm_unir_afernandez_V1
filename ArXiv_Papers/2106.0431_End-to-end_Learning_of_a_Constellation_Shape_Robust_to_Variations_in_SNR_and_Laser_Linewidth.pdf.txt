End-to-end Learning of a Constellation Shape Robust to Variations in SNR and Laser Linewidth
Ognjen Jovanovic, Metodi P. Yankov, Francesco Da Ros, Darko Zibar
Department of Photonics Engineering, Technical University of Denmark, ognjo@fotonik.dtu.dk

arXiv:2106.00431v1 [eess.SP] 1 Jun 2021

Abstract We propose an autoencoder-based geometric shaping that learns a constellation robust to SNR and laser linewidth estimation errors. This constellation maintains shaping gain in mutual information (up to 0.3 bits/symbol) with respect to QAM over various SNR and laser linewidth values.

Introduction
Geometric constellation shaping (GCS) is used to optimize high-order modulation formats to improve the spectral efficiency and maximize mutual information (MI). For coherent optical communication systems, such optimization should include residual phase noise (RPN) which results from an imperfect carrier phase estimation (CPE) and compensation. The parametrization of CPE algorithms, such as the ubiquitous blind phase search (BPS)[1], is sensitive to the channel conditions, such as signal-to-noise ratio (SNR) and laser linewidth (LW). In practical scenarios, measuring the laser LW is challenging and LW may drift over time, e.g. due to aging. Interoperatibility between vendors is becoming an increasingly important characteristic of optical networks[2], which means that the transmission needs to support a variety of hardware with different components, resulting in varying SNR and laser LW. It is therefore of the utmost importance to find a constellation that maintains good performance under imperfect knowledge of the channel conditions.
Performing GCS, which usually relies on gradient-based optimization, on a channel model that includes the PN and the CPE could be challenging because the CPE is usually complex and non-differentiable, e.g. the BPS algorithm. Therefore, previous works on GCS assume ideal knowledge of channel conditions and artificially modeled RPN[3]­[7]. However, this assumption does not reflect the true RPN after the CPE which is often mis-parametrized due to imperfect knowledge of the channel conditions.
In this paper, an autoencoder (AE) is used to geometrically optimize a constellation that is robust to variations in SNR and LW. The robust constellation was learned by varying the RPN severity and SNR in a simple differentiable RPN chan-
978-1-6654-3868-1/21/$31.00 ©2021 IEEE

nel in the training stage. The constellation is then tested on a realistic channel with BPS, where the RPN is due to the mismatch between the channel conditions and the BPS parameters. Up to 0.3 bits/symbol of shaping gain in MI with respect to QAM are achieved for a various degree of channel conditions mismatch in terms of LW and SNR.
Autoencoder and channel models
An AE, which consist of an encoder, a decoder, and an embedded differentiable channel model in between, is utilized to geometrically optimize a constellation[8], as shown on Fig. 1. Two different setups can be distinguished: the training and the testing setup. Both of the setups share the same encoder. In the training setup the channel model is a simple differentiable approximation of the test channel which is more suitable for training.
The encoder, which learns the geometrically optimized constellation, is represented by a linear feed-forward neural network (NN) N Ne(we) parameterized with trainable weights we. It performs a mapping of the one-hot encoded vector uk  U = {ei|i = 1, . . . , M } to a normalized complex constellation point xk, where k represents the k-th sample, ei is an all zero vector with a one at position i and M is the constellation size.
In the training setup, the channel consists of complex AWGN and RPN, both modelled as zeromean Gaussian distributions with variance n2 and R2 P N , respectively. A decoder NN N Nd(wd) with trainable weights wd and using a softmax output layer is used as a receiver during training. The decoder's goal is to reproduce the input sequence uk at the output sk with the highest fidelity. This is achieved by jointly optimizing the encoder and the decoder trainable weights. The optimization of these weights is performed by minimizing the cross-entropy cost function such that sk  uk. Once the training has converged, the encoder weights are fixed and the testing is performed.

Fig. 1: The training and testing setup of the autoencoder model used for geometrical constellation shaping.

Tab. 1: Autoencoder hyperparameters

Encoder NN Decoder NN

# of input nodes

M

2

# of hidden layers

0

1

# of hidden nodes

0

M/2

# of output nodes

2

M

Bias

No

Yes

Hidden layer

None Leaky Relu

activation function

Output layer

Linear

Softmax

activation function

In the testing setup, the channel consists of

phase noise modelled as a Weiner process with

variance 2, complex AWGN modelled as zeromean Gaussian distribution with variance n2 and
BPS as the blind CPE algorithm. The BPS al-

gorithm is parametrized by the number of test

phases Ns = 60 and window size W = 128 which were chosen so that the non-shaped QAM con-

stellation performs well on average across the

studied SNR and LW conditions. During test-

ing, the decoder is replaced by the common mis-

matched Gaussian receiver[7] to estimate the MI

between the channel input and output in order to

study the performance of the constellation.

In both setups, the channels operate at one

sample per symbol with a symbol rate Rs = 32 GBd. The AWGN variance is determined by

the SNR, n2

=

1 SN

R

.

The PN process variance

2 is determined by the laser LW  and symbol

period Ts = 1/Rs, 2 = 2Ts. The constella-

tion size is M = 64. The AE hyperparameters are

shown in Table 1.

Results and Discussion
We compare our learned robust constellation to
two cases: 1) a conventional square quadrature
amplitude modulation (QAM); 2) constellations trained on fixed SNR and RPN variance R2 P N , similar to what was done in[7]. The RPN vari-

Fig. 2: Performance in MI with respect to LW for the constellation trained by varying R2 P N at SNR = 17 dB.
Fig. 3: Constellation robust to (a) varying LW for a fixed SNR= 17 dB; (b) varying SNR and LW.
ance is taken from a coarsely chosen set R2 P N  {10-4, 5·10-4, 10-3, 5·10-3, 10-2, 2·10-2, 5·10-2}. Case 2) approaches the best performing constellation with regards to MI for a given SNR and LW pair and assumes they are known perfectly at both the transmitter and receiver. In both the training and the testing stage the studied SNR region includes values from the interval SNR  {15, 16, . . . , 20} dB. In the testing stage, the studied laser LWs are   {50, 100, . . . , 300} kHz.
The first goal was to achieve a constellation robust over various LWs for a target SNR (referred to as LW-robust constellation in the following). The training to learn such a constellation is exemplified by fixing the SNR to 17 dB and sampling the RPN variance from a log-uniform distri-

Fig. 4: Performance in MI with respect to SNR for LW values for the constellation trained by varying both R2 P N and SNR.

bution in the range of R2 P N  [0.005, 0.02]. Then, in order to achieve a single constellation that is

interval. The constellation is shown on Fig. 3(a). Fig. 4 shows MI performance of the enve-

robust over all target SNR and LW pairs (referred lope, QAM, and SNR&LW-robust constellation as

to as SNR&LW-robust constellation in the follow- a function of SNR for different LW values. In

ing.), the training was performed on uniformly this case, the SNR&LW-robust constellation was

distributed SNR  [15, 20] dB and log-uniformly distributed RPN variance R2 P N  [0.005, 0.05]. The SNR and RPN variance were drawn from

trained by varying both SNR and RPN variance during training. The constellation is given in Fig. 3(b) and is used for all tests shown in Fig. 4. The

these distributions for each training batch. In both SNR&LW-robust constellation has a similar trend

scenarios, the RPN variance range was chosen for all LW values. It achieves substantial gain at

based on the minimum and maximum fixed RPN a SNR region from 15 to 18 dB, which is com-

variance values that contribute to the envelope. parable to the constellation obtained with perfect

The envelope represents the MI of the constella- knowledge of the channel conditions. The gain is

tion at each SNR and LW pair obtained with the corresponding optimal R2 P N . The SNR range in the second scenario was chosen to cover the

then reduced at higher SNR, but the performance is still superior than regular QAM. The SNR&LWrobust constellation achieves up to 0.3 bits/sym-

whole target SNR region.

bols gain with respect to QAM for  = 100 kHz,

The training was done by applying the Adam optimizer[9] on a sample set of size N = 256 · M .

whereas the highest gain for the envelope is 0.33 bits/symbol for  = 300 kHz.

In each epoch, a new sample set is generated with uniformly distributed one-hot encoded vectors and divided into 8 batches of size B = 32 · M . The testing was done by running 100 simulations with 105 symbols per simulation in each case.
The simulation results obtained from testing the LW-robust constellation for a fixed SNR = 17 dB and varying LW are shown in Fig. 2. Only the constellations trained with a fixed RPN variance that contribute to the envelope are shown. The AE trained with a fixed RPN is only beneficial in a limited range of LW. For example, when the LW is fixed at  = 100 kHz, the RPN method from[7] can be used with R2 P N = 0.005 to achieve a potentially optimal constellation for this LW. However, for larger LWs this constellation becomes highly sub-optimal. Although the LW-robust constellation has a slight penalty compared to the envelope, it maintains MI gain compared to QAM, up to 0.15 bits/symbol over the whole observed LW

Conclusions Autoencoder-based optimization of geometric shapes robust to variations in SNR and laser linewidth was proposed. The robustness of the constellation was achieved by utilizing a simpler channel model that includes additive white Gaussian noise and residual phase noise, and varying their severity for each batch of the training stage. This constellation maintains the shaping gain in mutual information with respect to QAM over the studied SNR and laser linewidth intervals in the testing phase which includes a realistic model of residual phase noise due to the BPS algorithm.
Acknowledgements This work was financially supported by the European Research Council through the ERC-CoG FRECOM project (grant agreement no. 771878), the Villum Young Investigator OPTIC-AI project (grant no. 29334), and DNRF SPOC, DNRF123.

References
[1] T. Pfau, S. Hoffmann, and R. Noe´ , "Hardware-efficient coherent digital receiver concept with feedforward carrier recovery for M-QAM constellations", Journal of Lightwave Technology, vol. 27, no. 8, pp. 989­999, 2009.
[2] M. Filer, H. Chaouch, and X. Wu, "Toward Transport Ecosystem Interoperability Enabled by Vendor-Diverse Coherent Optical Sources Over an Open Line System", J. Opt. Commun. Netw., vol. 10, no. 2, A216­A224, Feb. 2018.
[3] Y. Li, S. Xu, and H. Yang, "Design of Signal Constellations in the Presence of Phase Noise", in 2008 IEEE 68th Vehicular Technology Conference, 2008, pp. 1­5.
[4] T. Pfau, X. Liu, and S. Chandrasekhar, "Optimization of 16-ary Quadrature Amplitude Modulation constellations for phase noise impaired channels", European Conference and Exhibition on Optical Communication, pp. 1­3, 2011.
[5] R. Krishnan, A. Graell i Amat, T. Eriksson, and G. Colavolpe, "Constellation Optimization in the Presence of Strong Phase Noise", IEEE Transactions on Communications, vol. 61, no. 12, pp. 5056­5066, 2013.
[6] F. Kayhan and G. Montorsi, "Constellation Design for Memoryless Phase Noise Channels", IEEE Transactions on Wireless Communications, vol. 13, no. 5, pp. 2874­ 2883, 2014.
[7] H. Dzieciol, G. Liga, E. Sillekens, P. Bayvel, and D. Lavery, "Geometric Shaping of 2-D Constellations in the Presence of Laser Phase Noise", Journal of Lightwave Technology, vol. 39, no. 2, pp. 481­490, 2021.
[8] R. T. Jones, T. A. Eriksson, M. P. Yankov, and D. Zibar, "Deep Learning of Geometric Constellation Shaping Including Fiber Nonlinearities", European Conference on Optical Communication (ECOC), 2018.
[9] D. P. Kingma and J. Ba, "Adam: A method for stochastic optimization", arXiv preprint arXiv:1412.6980, 2014.

