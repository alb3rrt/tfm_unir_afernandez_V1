arXiv:2106.00630v1 [stat.AP] 1 Jun 2021

Simulating flood event sets using extremal principal components
Christian Rohrbeck1 and Daniel Cooley2
1 Department of Mathematical Sciences, University of Bath, UK 2 Department of Statistics, Colorado State University, CO, USA
Abstract Hazard event sets, which correspond to a collection of synthetic flood events, are an important tool for practitioners to analyse and manage future flood risks. In this paper, we address the issue of generating hazard event sets for northern England and southern Scotland, a region which has been particularly affected by flooding over the past years. We start by analysing extreme river flow across 45 gauges in the region using recently introduced ideas from extreme value theory. This results in a set of extremal principal components, with the first components describing the large-scale structure of the observed flood events, and we find interesting connections to the region's topography and climate. We then introduce a framework to approximate the distribution of the extremal principal components which is dimension reducing in that it distinctly handles the large-scale and local extremal behavior. Synthetic flood events are subsequently generated efficiently by sampling from the fitted distribution. Our approach for generating hazard event sets can be easily implemented by practitioners and our results indicate good agreement between the observed and simulated extreme river flow dynamics.
Keywords­ Multivariate extreme value theory; Principal component analysis; Spatial flood risk analysis
1 Introduction
Severe flood events regularly cause widespread disruptions and huge losses around the world. The National Oceanic and Atmospheric Administration records about two billion-dollar flood events per year in the last decade for the US alone. In the UK, the flooding caused by Storm Desmond, Storm
1

Figure 1: Locations of the 45 river flow gauges in northern England and southern Scotland (left) and the effect of Storm Desmond on river flow levels (right); darker colours refer to more severe river flow, with the darkest colour indicating that the gauge recorded its maximum river flow between 1980 and 2018 in the week of Storm Desmond.
Eva and Storm Frank in 2015/2016 led to an estimated economic damage of between £1.3­1.9 billion (Environment Agency, 2018), and the cascading effects of Storm Ciara and Storm Dennis in February 2020 broke record levels for multiple rivers. These recent extreme events, together with a potential future increase in flood frequency and severity due to climate change, emphasize the need for flood risk analysis tools which can be applied by civil engineers when designing flood defences and by insurance companies to predict the financial capital required to cover potential payouts.
Catastrophe models are an important tool to estimate the impact of natural hazards (Grossi and Kunreuther, 2005). One component of these models is a simulated hazard event set, representing, for instance, a collection of floods over a long period, e.g., 1,000 or 10,000 years. In this paper, we are interested in generating hazard event sets of extreme river flow for northern England and southern Scotland. This region has experienced several severe flood events over the past years, which caused huge financial losses due to flood defences being breached. For instance, Storm Desmond and Storm Frank in 2015 led to collapsed bridges and thousands of flooded homes in Cumbria, northern Lancashire and Dumfries & Galloway, and tens of thousands of people lost power for days when a substation was flooded near Lancaster.
In order to study historical flooding across the region, we obtained daily river flow levels (in m3/s) for the period 01/01/1980­30/09/2018 for 45 gauges from the UK's National River Flow Archive (nrfa.ceh.a.uk). Figure 1 left panel shows that most of the gauges are located along the west coast, ranging from southern Scotland to the Welsh border, and in North-East England. The region has a varying topography (described later in Section 2.1) which we will find to be
2

represented by some of our results. To give an example of the spatial structure of extreme river flow, Figure 1 right panel indicates the gauges affected by Storm Desmond, most of them in Cumbria and northern Lancashire. In an exploratory data analysis, we find seasonality in both the scale and spatial structure of recorded extreme river flow levels, with the most severe and large-scale events occurring in winter. This seasonality is due to increases in river flow usually being caused by convectional rainfall (e.g. thunderstorms) in summer and frontal rainfall (e.g. extratropical cyclones) in winter. Since our main interest lies in the most severe flood events, we focus on generating hazard event sets for October­March in the remainder of this paper.
Our approach for generating hazard event sets is based on a joint analysis of extreme river flow across gauges. Extreme value theory provides asymptotically justified methods to analyse the tail behaviour of multivariate random variables (Beirlant et al., 2004) and stochastic processes (Davison et al., 2012), which have, for instance, been applied to analyse extreme river flow (Asadi et al., 2015, 2018; Rohrbeck and Tawn, 2021). Crucially for our analysis, these models allow to extrapolate the occurrence probability of events outside the range of recorded data. When analysing the tail behaviour of a K-dimensional random vector X, marginal distributions and extremal dependence structure often are modelled separately. While a block-maxima or peaks-over threshold approach is generally employed to model the marginals of X (Coles, 2001), most existing approaches for extremal dependence (Tawn, 1988; Hu¨sler and Reiss, 1989; Boldi and Davison, 2007; Cooley et al., 2010; Ballani and Schlather, 2011; de Carvalho and Davison, 2014) are limited to fairly moderate dimensions; see (Engelke and Ivanovs, 2020) for a review. This limitation is caused by extremal dependence being defined via a measure HX on the K-dimensional unit sphere, which usually has to be estimated based on a small number of extreme events. Some issues can be overcome by instead defining a graphical model on the dependence structure (Engelke and Hitz, 2020), but the assumptions on HX may still be too strong. The extremal dependence structure is likely to be very complex due to the K = 45 gauges in Figure 1 being spread across a river network with disparate catchments, and the varying topography and climate across the region.
Several approaches to analyse and visualise extremal dependence have been proposed in the literature: Chautru (2015) applies clustering techniques to identify groups of variables exhibiting dependence in the extremes; Goix et al. (2017) and Simpson et al. (2020) propose inference frameworks to identify the extremal dependence structure of a small to moderate number of variables; Cooley and Thibaud (2019) and Drees and Sabourin (2021) adapt ideas from principal component analysis (PCA). We focus on the PCA-based approaches to analyse the recorded extreme river flow, because they are best-equipped to handle high-dimensional settings. However, while these methods provide insight into the extremal dependence structure, they have not yet been applied to generate extreme events and hazard event sets.
This paper makes two substantial contributions to the area of statistical flood risk analysis in order to analyse flooding in northern England and southern Scotland and to generate hazard event sets for catastrophe modelling. Our first contribution is the analysis of the river flow data using
3

recently developed methodology in extreme value analysis, in particular, clustering and PCA. The second contribution is the development of a method to generate hazard event sets. Our framework utilises the methodology by Cooley and Thibaud (2019), which provides a transformation of X into a K-dimensional random variable V, termed the extremal principal components, with the extremes of V and X being linked. Critically, in our river flow application, the first components of V describe the large-scale spatial structure in the extreme river flow, while the remaining components capture local dynamics. This invites the application of dimension-reduction techniques ­ our proposed methods model the full extremal dependence structure of the first components of V, and provide a reasonable fit for the remaining components. The approach presented herein uses the kernel density estimate for spherical data by Hall et al. (1987) to model the extremal dependence; alternatives are discussed at the end of the paper. From the estimated model, large hazard event sets can be generated with very low computational cost. Compared to Keef et al. (2013), who sample hazard event sets from a conditional extremes approach (Heffernan and Tawn, 2004), our approach does not require a separate model for each individual gauge.
The remainder of this paper is organized as follows: Section 2 models the gauge-wise extreme values, summarizes the approach by Cooley and Thibaud (2019) and applies it to the river flow data; Section 3 introduces our methods and presents the generated sets of extreme river flow, and we conclude with a discussion in Section 4.
2 Analysis of extreme river flow
2.1 Introduction and data description
Interest lies in analysing the extreme values of weekly peak river flow for the K = 45 gauges in Figure 1. Gauges 1­12 are located at rivers flowing eastwards, towards the North Sea, while the remaining gauges record westward flows into the Irish Sea. The gauges further differ in topography: low mountain ranges dominate the northern half of the study area, while the southern half is mostly flatland. As described in Section 1, we focus on extreme river flow levels between November and March, the months when the most severe flood events tend to occur. Splitting this period into weeks, T = 848 weeks of recorded river flow between January 1980 and September 2018 are obtained for the analysis. Some gauges have a small proportion of missing values (2-3%), and complete records are available for 28 of the 45 gauges. The average weekly peak river flow ranges from 2.67 m3/s (gauge 30) up to 151.8 m3/s (gauge 40).
The spatial analysis of the extreme river flow levels is performed in two parts: (i) fitting the marginal distributions and (ii) studying the tail dependence. Section 2.2 describes our model for the marginal (gauge-wise) distribution of the extreme values of weekly peak river flow. The framework for the analysis of tail dependence by Cooley and Thibaud (2019) is summarized in Section 2.3, and results for the UK river flow data are presented and discussed in Section 2.4.
4

2.2 Marginal modelling of extreme river flow

Let Xt,k be the random variable representing the peak river flow for gauge k in week t, and define Xt = (Xt,1, . . . , Xt,K) (k = 1, . . . , K; t = 1, . . . , T ). We adopt a peaks-over threshold approach to model extremal behaviour of Xt,k (k = 1, . . . , K). For some suitably high threshold uk, exceedances by Xt,k of uk are modelled as generalized Pareto distributed, GPD(k, k), with

P(Xt,k > x + uk | Xt,k > uk) =

1 + kx k

-1/k +

(x > 0),

(1)

where (z)+ = max{z, 0}, and (k, k)  R+ × R are termed the scale and shape parameters respectively. The value of k = 0, interpreted as the limit of (1) as k  0, gives the exponential distribution, whilst k < 0 corresponds to a short-tailed distribution with finite upper end point, and k > 0 gives a power-law tail decay. Here, the threshold uk is selected using graphical diagnostic tools (Coles, 2001); see Wadsworth (2016) and Northrop et al. (2017) for a review of more recent selection techniques. We use return levels to characterise the estimated extremal behaviour of Xt,k. The  -year return level is the value which is exceeded on average once every  years. Formally, for parameters k and k, the  -year return level of Xt,k is

uk

+

k k

(uk  )k - 1

,

(2)

where uk is the expected number of times Xt,k exceeds uk per winter season. The diagnostic plots suggest setting uk to the empirical 94% quantile of Xt,k, providing about 50
exceedances to estimate k and k. When deriving the gauge-wise maximum likelihood estimates, the estimate for k takes values between ^17  -0.3 and ^37  0.58. However, such small and large shape parameter estimates seem unrealistic. Furthermore, the estimates have quite large standard errors, which result in very wide confidence intervals, for instance, for the 500-year return levels. This motivates the borrowing of statistical information across gauges for parameter estimation. One widely applied approach in regional flood risk analysis is to group gauges based on catchment attributes and to assume a common shape parameter for all gauges within a group; see, e.g. Institute of Hydrology (Great Britain) (1975). This approach was also applied by Asadi et al. (2015) who obtained shape parameter estimates between 0.0 and 0.3 for gauges across the upper Danube basin.
We propose to derive estimates via an alternative two-step process, which does not require grouping gauges before estimating the GPD parameters. In the first step, the gauge-wise shape parameters are estimated via the Bayesian clustering framework by Rohrbeck and Tawn (2021), which exploits potential spatial structures in the GPD parameters. In the second step, the scale parameter k is estimated using maximum likelihood estimation, with k being fixed to its posterior mean estimate derived in the first step. For our river flow data, the estimated shape parameters lie between ^13  0.10 and ^34  0.22, and the scale parameter is estimated based on the observations exceeding the empirical 96% quantile.

5

2.3 Analysing extremal dependence using principal components
Cooley and Thibaud (2019) study extremal dependence of a multivariate random variable X~ = (X~1, . . . , X~K) with marginal distribution P X~k  x = exp -x-2 (k = 1, . . . , K), i.e., X~k follows a Fr´echet distribution and only takes positive values. It is further assumed that X~ is regularlyvarying with index  = 2, that is, for any Borel set B  SK+ -1 = {w  RK+ : ||w||2 = 1},

lim P
r

||X~ ||2

>

rz,

X~ ||X~ ||2



B

||X~ ||2 > r

= z-2HX ({B}),

(3)

where HX is a measure on the unit sphere SK+ -1, termed the angular measure; in Section 2.4 we apply a marginal transformation to the river flow Xt (t = 1, . . . , T ) to meet these conditions.
Tail dependence of X~ is summarized via the K × K tail pairwise dependence matrix (TPDM)
, which is defined by the second-order properties of HX . Formally, the (i, j)-th element of  is

i,j =

wiwj dHX (w) (i, j = 1, . . . , K).

(4)

K-1

S+

Equation 4 corresponds to the extremal dependence measure of Larsson and Resnick (2012). The
restriction to  = 2 gives  properties analogous to a covariance matrix: in particular, it is positive
semidefinite and high values of i,j indicate strong extremal dependence, while values close to zero represent weak or no extremal dependence of the variables X~i and X~j.
To analyse extremal dependence of the components of X~ , we perform an eigendecomposition of . Formally, let  = UDUT, where D is a diagonal matrix with entries 1  . . .  K  0, and U is a K × K unitary matrix. Analogue to principal component analysis, extremal dependence
is explored by investigating the eigenvalue/eigenvector pairs (1, U·,1), . . . , (K, U·,K) sequentially. The extremal principal components of X~ are then defined as

V = UTt-1 X~ ,

(5)

where t-1(·) = log [exp(·) - 1] component-wise. Lemma A4 in Cooley and Thibaud (2019) implies that V is regularly varying with  = 2 and
we denote its angular measure by HV . Note that, unlike HX , the measure HV exists on the whole unit sphere SK-1 = {w  RK : ||w||2 = 1}. This result will form the basis for generating hazard event sets in Section 3. Furthermore, Proposal 6 in Cooley and Thibaud (2019) implies that the TPDM ~ for V satisfies ~ i,i = i and ~ i,j = 0 for i = j. This result suggests that the extremal principal components have analogous properties to the classical principal components; however, the components Vi and Vj are not asymptotically independent. Consequently, the generation of extremal principal components requires estimation of HV , which we will address.

6

2.4 Application to the UK river flow data
We first apply a transformation to Xt in order to obtain a variable X~ t = (X~t,1, . . . , X~t,K ) with Fr´echet marginal distributions, as required in Section 2.3. Specifically, define

X~t,k =

- log F^k(Xt,k)

-1/2
,

(k = 1, . . . , K; t = 1 . . . , T )

(6)

where F^k is an estimate for the distribution of the weekly peak river flow at gauge k. We derive F^k(·) as described by Coles and Tawn (1991), i.e., F^k(·) is set to the empirical cumulative distribution function for values below a suitably high threshold uk, while a GPD(k, k) is used to model F^k(·) above uk. For the analysis of the river flow data, uk is the empirical 96% quantile used to estimate the gauge-wise scale parameter k in Section 2.2. We further have to assume that the angular measure HX (·) in (3) is constant for all t = 1, . . . , T . Flood events between November and March are generally caused by frontal rainfall, in particular by storms coming in from the Atlantic Ocean. As such, this assumption appears reasonable.
The next step is to estimate the tail pairwise dependence matrix (TPDM), , defined in (4). Let {x~t = (x~t,1, . . . , x~t,K) : t = 1, . . . , T } be the set of marginal observations, obtained by applying the transformation (6) to the original river flow measurements. We then remove the weeks with incomplete data, i.e., week t  {1, . . . , T } is removed if x~t,k is missing for at least one k = 1, . . . , K. This leaves about 92% of weeks to analyse the tail dependence, and we define T   {1, . . . , T } as the set of weeks with complete records. Let rt = ||x~t||2 and wt,k = x~t,k / rt (t  T ; k = 1, . . . , K). The (i, j)-th element of  is then estimated as

^ i,j

=

K n

wt,i wt,j I(rt > r0),

tT 

(i, j = 1, . . . , K),

where I(·) denotes the indicator function, and r0 is set as the 94% quantile of {rt : t  T }, which corresponds to n = 47 weeks being used to estimate .
The estimated TPDM in Figure 2 left panel indicates positive correlation between spatial distance and tail dependence; for instance, the TPDM has generally low values when considering pairs of a northern gauge (gauges 1-9 and 40-45) and southern gauge (gauges 13-22). We perform the eigendecomposition of ^ to find U^ D^ U^ T = ^ . Figure 2 right panel shows that the eigenvalues are quite small after the first six or seven eigenvalues, with (1, . . . , 6) = (28.9, 4.7, 2.2, 1.7, 1.3, 1.2).
To analyse the extremal dependence across gauges, we investigate the calculated eigenvectors sequentially, and the six eigenvectors shown in Figure 3 reveal the large-scale spatial behaviour of extreme river flow events. The first eigenvector has only positive values and accounts for the overall magnitude of extreme river flow events, with the highest values in the centre of the study area. Next, the second eigenvector indicates a north-south divide, which correlates with geographical features: the northern gauges are located in mountainous regions (Lake District and Pennines), whereas the southern gauges are mostly located in flatland areas. The third eigenvector shows

7

3

1.6 40
1.4

2

Log( Eigenvalue )

Gauge

30

1.2

1.0

20

0.8

1

0

0.6
10 0.4

-1

0.2 10 20 30 40
Gauge

2

4

6

8

10

Index

Figure 2: Estimated TPDM  (left) and a scree plot of the eigenvalues of  on log scale (right) for the 45 river flow gauges in Figure 1.

Figure 3: Spatial illustration of the first six eigenvectors of the TPDM. The first row corresponds to the eigenvectors U^ ·,1, U^ ·,2 and U^ ·,3 (left­right). Colour scales for eigenvectors are balanced such that red colours indicate positive values, while blue colours correspond to negative values; however, each plot has its own scale.
8

200

100

40

150

20

50

V3

V2

100

V1

0

0

50

-20

-40

-50

0

0

200 400 600 800

Week

0

200 400 600 800

Week

0

200 400 600 800

Week

Figure 4: Time series plots for the first three extremal principal components: V1 (left), V2 (middle) and V3 (right). The red dots highlight the weeks for which rt exceeds the 98% quantile of {rt : t  T }. The blue dot highlights the extremal principal components related to Storm Desmond.

a linear trend from the west to east coast, with the exception of the most southern gauges. We conclude that U^ ·,3 explains a gauge's exposure to large-scale weather fronts from a westerly or south-westerly direction; the north-eastern gauges are protected by the Pennines, while the most southern gauges lie in the rain shadow of Snowdonia in northern Wales. The fourth eigenvector has a similar interpretation to U^ ·,3, but it divides the gauges exposed to westerly weather fronts into the ones in mountainous regions and those in flatland areas. Finally, the fifth and sixth eigenvector capture local differences between gauges, with the blue coloured northern gauges in the plot of U^ ·,6 mainly corresponding to the gauges located in the Pennines.
We conclude the analysis by studying the extremal principal components vt = U^ Tt-1(x~t) (t  T ) defined in (5). Figure 4 shows time series plots for the extremal principal components associated to the first three eigenvectors. For Storm Desmond in 2015 (highlighted in blue), the first component indicates that this event caused extreme river flow across the region, the second extremal principal component contains the information that the most severe river flow was observed across the northern half of the study area, and the moderately positive value of the third extremal principal component shows that river flows were slightly more severe in the west than in the east (after accounting for the effects already described by the first two components). This agrees with the findings shown in Figure 1 right panel. We find further agreements between high values for the first extremal principal components and recorded extreme river flow events. For instance, the highest value for the third extremal principal component relates to the highest observed levels for the southern gauges over the study period, which were caused by record levels of precipitation in the autumn of 2000.

9

3 Generating hazard event sets

3.1 General modelling framework

In the context of generating hazard event sets for flood risk analysis, we have to sample from the upper tail of X. Using the extreme value theory framework in Section 2, one may consider to sample from the tail distribution of X~ , and to then reverse the marginal transformation in (6), in order to generate extreme values of X. The drawback of this approach is that it requires the estimation of the K-dimensional angular measure HX (·) in (3). Since the number of observed extreme events is small, we would have to impose a very restrictive parametric model for HX (·), which is unlikely to capture the complex extremal dependence structure, or choose a more flexible model for HX (·), which is, however, likely to overfit, if it could even be fitted.
Instead of attempting to sample directly from the tail distribution of X~ , we propose to sample from the tail distribution of the extremal principal components V in (5). As shown in Section 2.4, the extreme values of V are linked to the extremes of X~ . Our approach for generating an extreme event of X can then be summarized as follows:

1. Sample v from the tail distribution of V 2. Reverse the transformation (5) to obtain x~ from the tail of X~

3. Reverse the marginal transformation (6) to obtain an observation from the tail of X

Recall from Section 2.3 that V is regularly-varying with index  = 2. We further have that ||V||2 is Fr´echet distributed with P (||V||2  r) = exp -(r/K)-2 (r > 0). To fully describe the tail distribution of V, we are thus left with estimating the distribution of

V

W= ||V||2

||V||2 > rV ,

(7)

where rV is a suitably high threshold; we set rV to the empirical 94% quantile of ||V||2 in our analysis, and denote the observations of W by {wi  SK-1 : i = 1, . . . , nexc}
At first glance, estimating the distribution of W, given by the angular measure HV , is just as difficult as the estimation of HX (·) for X~ , since both operate on the K-dimensional unit sphere. However, the key difference is that the components of V have varying contributions to the extremes of X~ . Specifically, similar to classical PCA, the first few components of V contain most of the information describing the structure of extreme events.
An analysis of the eigenvalues in Section 2.4 gives 1 + 2 + · · · + 6 = 39.75, compared to 7 + · · · + K = 5.25, indicating that the first six eigenvalue / eigenvector pairs capture the largescale structure of extreme flood events. This motivates our proposal to estimate the distribution of W as a combination of (i) a flexible model to capture the dependence structure of W1, . . . , W6 and (ii) a more restrictive / simplified approach for W7, . . . , WK. Consequently, the flexible model

10

Gauge 6 0 20 40 60 80
Gauge 31 0 20 40 60 80
Gauge 14 0 20 40 60 80

0 20 40 60 80 Gauge 5

0 20 40 60 80 Gauge 7

0 20 40 60 80 Gauge 8

Figure 5: Simulated (grey) and observed (black) extreme events of X~ for three pairs of gauges. The generated extreme events are based on one generated 500-year hazard event set.

part captures large-spatial structures in the extremes, while the second model part explains local differences in the observations, which can be considered as noise given the moderate number of extreme observations. Consequently, we have to choose a suitable model for (i) and to approximate the local dynamics (ii) such that the simulated extreme events appear realistic.
Details of our modelling framework for W are discussed in the following Section 3.2. Figure 5 shows a good agreement in the extremal dependence structure of sampled and observed values of X~ for three pairs of gauges (from left to right: strongly dependent, moderately dependent and weakly dependent) and a complete analysis of the generated hazard event sets of extreme river flow is presented in Section 3.3.

3.2 Modelling the distribution of W and sampling algorithm
We start by considering separate models for the random vectors (W1, . . . , W6) and (W7, . . . , WK). This then motivates our proposed joint modelling framework and the sampling algorithm for X~ .

Modelling the first components To estimate the joint distribution of W1, . . . , W6 we re-
quire a model that is sufficiently flexible to capture the potentially complex dependence structure. Consider W1:6 / ||W1:6||2, that is, W1, . . . , W6 projected onto to the six-dimensional unit sphere. Given observed values {w~ i = wi,1:6 / ||wi,1:6||2 : i = 1, . . . , nexc}, we model the distribution of W1:6 / ||W1:6||2 using a kernel density estimate appropriate for spherical data, in particular, we apply a mixture of Mises-Fisher distributions (Hall et al., 1987). Formally, the estimated density for W1:6 / ||W1:6||2 is given by

h^V (z; )

=

c0() nexc

nexc
exp
i=1

 zTw~ i

(z  S5),

(8)

11

where  is the bandwidth and c0() is the normalizing constant. The bandwidth is selected using the vmf.kde.tune function in the Directional R package, which estimates the value h via maximum likelihood inference. We verified the robustness of this approach for our analysis using bootstrapping, and we found only small variations in the estimated bandwidths.

Modelling the remaining components The simplest approach is to set the remaining
components W7, . . . , WK to their empirical average, and to only sample values for W1, . . . , W6. However, we found that the simulated values exhibit a higher extremal dependence than we observe in the recorded river flow. An alternative is to generate a sample of (W7, . . . , WK) from the empirical distribution function. While this approach improves upon the first approach, we still produce some unrealistic samples, e.g., sampled extremes for distant gauges are more dependent than in reality. This occurs because the approach samples independently from (W1, . . . , W6) and (W7, . . . , WK), while these random vectors are in reality dependent; recall from Section 2.3 that the components Vi and Vj (i, j = 1, . . . , K) are asymptotically dependent. Consequently, the separate modelling of large-scale structures and local dynamics in the extremes is unable to capture all properties of the underlying process, and we thus require a joint modelling framework.

Joint modelling framework We start by transforming W into a random variable Z on a
lower-dimensional unit sphere. For our analysis, we define Z on the seven-dimensional unit sphere S6 with Zj = Wj (j = 1, . . . , 6) and



Z7

 1- =
- 1 -

6 j=1

Wj2

6 j=1

Wj2

if W7  0 .
if W7 < 0

Generally speaking, the first six components of Z explain large-scale variations in the extreme values, and the last component summarizes local dynamics. The distribution of Z is modelled via a mixture of Mises-Fisher distributions as in (8).
To convert the model for Z into a model for W, we have to specify a mapping from S6 onto SK-1. Let {zi : i = 1, . . . , nexc} denote the observations for Z. For z  S6, define

q = arg max zTi z,

(9)

i

that is, we find the nearest neighbour of z amongst the observations of Z. The projected vector w  SK-1 of z is then defined as

w=

z1, . . . , z6,

z7 zq,7

wq,7:K

.

(10)

As such, the observation wq is used to decompose z7, the component representing local dynamics in the extremes, into values w7, . . . , w45. In other words, we use the observed data to learn about

12

V4 V9 V10

V1

V3

V7

Figure 6: Pairwise plots of simulated (grey) and observed (black) extremal principal components. The number of simulated extremal principal components is 11,000, while the number of observed extremal principal components is 47. In the left panel, both extremal principal components V1 and V4 are modelled via the flexible model part. In the middle panel, V3 is modelled via the flexible model part, while V9 is not. In the right panel, no component is modelled directly via the flexible model part.
the possible patterns of w7, . . . , w45. Note, the mapping implies that the projected vector of zi is wi.
Combining the estimated density for Z of the form (8) with the mapping defined by (9) and (10), yields our final model for W. The model gives full flexibility in terms of the possible values of W1, . . . , W6 representing the large-scale structure of extreme river flow events, while restricting the number of possible patterns describing local dynamics. Specifically, there are nexc possible patterns for the values of W7, . . . , WK.
Simulating values for X~ We generate approximate samples of X~ using the described modelling
framework as follows:
1. Sample z  S6 from the estimated mixture of Mises-Fisher distributions for Z.
2. Extract the index q in (9) and derive a sample w  SK-1 using (10).
3. Sample r = ||V||2 from a Fr´echet distribution with P (||V||2  r) = exp -(r/K)-2 .
4. The generated sample for V is then v = rw.
5. Apply the inverse of (5) to v and we obtain the sample for X~ .
We considered alternatives to the nearest neighbour approach in (9), such as picking randomly amongst the five nearest neighbours, but this did not result in a better performance. Figure 6 shows that the pairwise dependence of the sampled extremal principal components agrees with the observed pairwise dependence.

13

5.5

5.0

Simulated Value

Simulated Value 4.0 4.2 4.4 4.6 4.8 5.0 5.2

4.5

4.0

4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 Observed Value

4.2 4.4 4.6 4.8 5.0 5.2 5.4 Observed Value

Figure 7: Quantile-quantile plots for the fifty largest observations of log (||XG||2) for the the groups of gauges G1 = {13, 14, 19, 20, 22} (left) and G2 = {1, 2, 8, 32, 41} (right). The dashed lines correspond to the central 95% sampling intervals. A blue triangle indicates that the data point was used in the estimation of W, while the red crosses correspond to events that were not used in the estimation.

3.3 Analysis of generated hazard event sets
Prior to discussing the simulated hazard event set obtained for a 500-year period, we verify that our approach performs at capturing the distribution of the extreme values. Figure 5 indicates a similar dependence structure of simulated and observed extreme events for three pairs of gauges.
To perform a more comprehensive model assessment, we simulate 500 hazard event sets over the same time period as the original data; i.e. each hazard event set corresponds to a collection of generated extreme events over approximately 40 years. Instead of X~ , we consider X, the simulated river flow levels obtained by inverting (6). We first check the marginal model fit for each gauge by producing quantile-quantile plots for the observed and simulated tails, in particular, we compare the fifty largest order statistics. The results show that the historical extreme values lie within the 90% confidence interval and plots for two sites are provided in Appendix A.
The next step in the model assessment is to check whether our approach captures the extremal dependence structure for groups of more than two gauges. We thus selected two sets comprising five gauges, G1 = {13, 14, 19, 20, 22} and G2 = {1, 2, 8, 32, 41}. The gauges are chosen such that the magnitude of river flow is comparable across gauges within the same group. Further, the groups were picked such that they differ in their extremal dependence structure. The gauges in G1 are spatially close, while the locations of the gauges in G2 follow a semicircular path from the north-east to the west coast. As such, the extremal dependence amongst the gauges in G1 is higher than in

14

Figure 8: Illustration of four simulated extreme events. The colouring shows the severity of the event at each gauge, in terms of it exceeding the estimated return levels. For instance, the darkest colour corresponds to the 200-year level being exceeded.
G2. For each group, we derive the fifty highest values of ||XG||2, where XG are the components of X corresponding to group Gj (j = 1, 2). Figure 7 shows that the observations lie within the 95% central sampling interval for both groups. The plots indicate that the fit gets slightly worse for the lowest considered values (observations that were high but not extreme). This may be expected as the dependence structure for the extremes may well differ from the general dependence structure; extreme events may occur locally while high river flow levels are more widespread. In summary, our modelling framework and sampling algorithm generate hazard event sets that have the same properties as the original data, although we imposed a quite restrictive assumption in Section 3.2.
We now generate a 500-year hazard event set and investigate the simulated extreme events
15

using return levels. Figure 8 shows the spatial structure for four events with very high value ||X~ ||2; the top two plots correspond to the simulated events with the highest values for ||X~ ||2. In the top left figure, extremely high river flow levels which exceed the 200-year return level for multiple sites are recorded in Lancashire, while most of remaining gauges also observe very high river levels. The top right plot shows an extreme event which is more widespread but only exceeds the 200-year return level for one gauge in centre of the study region. The remaining two plots show events with extremely high river flow levels in the northwest (bottom left) and southern half (bottom right) of the study region. We also compared the gauge-wise extremes to the estimated 500-year return level. For the sampled hazard event set, the simulated gauge-wise maximum exceeds the 500-year return level for 32 of the 45 gauges. The generated hazard event set can now be used by practitioners to design flood defences or to set property insurance premiums.
4 Discussion
In this paper we started by analysing historical river flow levels across 45 gauges in northern England and southern Scotland for the period November till March in Section 2. A peaks-over threshold approach was adopted to model extreme river flow at the individual gauges, and information for parameter estimation was pooled spatially using the clustering method by Rohrbeck and Tawn (2021). To analyse extremal dependence across gauges, we estimated the TPDM introduced by Cooley and Thibaud (2019) and considered its eigendecomposition. We found a close link between the first eigenvectors of the TPDM, describing the large-scale strcture of the extreme events, and known geographical / climatological features. The analysis was concluded by studying the extremal principal components associated to historic flood events.
In Section 3, we then considered the generation of hazard event sets for the 45 gauges. The computationally efficient approach introduced herein exploited the property found in Section 2 that the first six eigenvectors of the TPDM summarize the large-scale structure in the extremes. Our methodology handles the dependence amongst the extremal principal components by first considering a lower-dimensional random variable, for which a kernel density estimate can be derived, and then generates a sample on the original space using a nearest neighbour approach. We found good agreement between historical and simulated extreme values for individual gauges and groups of gauges. These generated hazard event sets could now be readily applied by insurance companies and civil engineers in catastrophe models to quantify the risks and costs associated to future flood events.
While we focused on winter floods, our approach can also be applied to analyse summer floods in northern England and southern Scotland, such as those related to Storm Francis in 2020, or extreme river flows at any other set of gauges. Furthermore, the methods introduced herein may also be applied to generate hazard event sets of extreme temperature or rainfall. The number of sites that can be handled efficiently by our approach depends on the underlying dependence
16

structure. In our application, we found that the first six extremal principal components adequately described large-scale spatial variation in the extremes, but a larger number of components may be required in other settings. If a moderate to large number of principal components is required to describe large-scale variation, one may again use a mixture of Mises-Fisher distributions, but with the number of mixture components being informed, for instance, by climatology.
An alternative approach for generating hazard events could be the application of methods from spatial extremes, such as max-stable or Pareto processes. While extreme flood events are spatial by nature, the application herein is rather non-standard since we consider extremes across a river network with disparate catchments. As such, the dependence structure is highly complex and any spatial extremes model has to incorporate both geographical and hydrological distances, while our approach does not require any location information. In other settings though, such as extreme temperature or precipitation, it would be interesting to compare performance of spatial extremes and our approach.
Acknowledgement
Parts of this research were conducted while Christian Rohrbeck was beneficiary of an AXA Research Fund postdoctoral fellowship grant. Dan Cooley's work was partially supported by the US National Science Foundation grant DMS-1811657. The daily river flow data were obtained through the National River Flow Archive.
A Quantile-quantile plots for the marginals

70

60

50

Simulated value for Gauge 20

200

150

Simulated value for Gauge 2

100

40

30

50

50

100

150

200

Observed value for Gauge 2

30

40

50

60

Observed value for Gauge 20

Figure 9: Quantile-Quantile plot of the fifty largest observations for gauge 2 (left) and gauge 20 (right). The dashed lines correspond to the simulated central 90% confidence interval.

17

References
Asadi, P., Davison, A. C., and Engelke, S. (2015). Extremes on river networks. Annals of Applied Statistics, 9(4):2023­2050.
Asadi, P., Engelke, S., and Davison, A. C. (2018). Optimal regionalization of extreme value distributions for flood estimation. Journal of Hydrology, 556:182­193.
Ballani, F. and Schlather, M. (2011). A construction principle for multivariate extreme value distributions. Biometrika, 98(3):633­645.
Beirlant, J., Goegebeur, Y., Segers, J., and Teugels, J. L. (2004). Statistics of Extremes: Theory and Applications. John Wiley & Sons Chichester.
Boldi, M.-O. and Davison, A. (2007). A mixture model for multivariate extremes. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 69(2):217­229.
Chautru, E. (2015). Dimension reduction in multivariate extreme value analysis. Electronic Journal of Statistics, 9(1):383­418.
Coles, S. G. (2001). An Introduction to Statistical Modeling of Extreme Values. Springer-Verlag London.
Coles, S. G. and Tawn, J. A. (1991). Modelling extreme multivariate events. Journal of the Royal Statistical Society. Series B (Methodological), 53(2):377­392.
Cooley, D., Davis, R. A., and Naveau, P. (2010). The pairwise beta distribution: A flexible parametric multivariate model for extremes. Journal of Multivariate Analysis, 101(9):2103­2117.
Cooley, D. and Thibaud, E. (2019). Decompositions of dependence for high-dimensional extremes. Biometrika, 106(3):587­604.
Davison, A. C., Padoan, S. A., and Ribatet, M. (2012). Statistical modeling of spatial extremes. Statistical Science, 27(2):161­186.
de Carvalho, M. and Davison, A. C. (2014). Spectral density ratio models for multivariate extremes. Journal of the American Statistical Association, 109(506):764­776.
Drees, H. and Sabourin, A. (2021). Principal component analysis for multivariate extremes. Electronic Journal of Statistics, 15(1):908­943.
Engelke, S. and Hitz, A. S. (2020). Graphical models for extremes. Journal of the Royal Statistical Society: Series B (Statistical Methodology), To appear.
18

Engelke, S. and Ivanovs, J. (2020). https://arxiv.org/pdf/2004.12182.pdf.

Sparse structures for multivariate extremes.

Environment Agency (2018). Estimating the economic costs of the winter floods 2015 to 2016. Ref: LIT 10736, https://www.gov.uk/government/publications/ floods-of-winter-2015-to-2016-estimating-the-costs.

Goix, N., Sabourin, A., and Cl´emenc¸on, S. (2017). Sparse representation of multivariate extremes with applications to anomaly detection. Journal of Multivariate Analysis, 161:12 ­ 31.

Grossi, P. and Kunreuther, H. (2005). Catastrophe Modeling: A New Approach to Managing Risk, volume 25. Springer Science & Business Media New York.

Hall, P., Watson, G. S., and Cabrera, J. (1987). Kernel density estimation with spherical data. Biometrika, 74(4):751­762.

Heffernan, J. E. and Tawn, J. A. (2004). A conditional approach for multivariate extreme values (with discussion). Journal of the Royal Statistical Society: Series B (Statistical Methodology), 66(3):497­546.

Hu¨sler, J. and Reiss, R.-D. (1989). Maxima of normal random vectors: Between independence and complete dependence. Statistics & Probability Letters, 7(4):283 ­ 286.

Institute of Hydrology (Great Britain) (1975). Flood studies report. Natural Environment Research Council, London.

Keef, C., Tawn, J. A., and Lamb, R. (2013). Estimating the probability of widespread flood events. Environmetrics, 24(1):13­21.

Larsson, M. and Resnick, S. I. (2012). Extremal dependence measure and extremogram: the regularly varying case. Extremes, 15:231­256.

Northrop, P. J., Attalides, N., and Jonathan, P. (2017). Cross-validatory extreme value threshold selection and uncertainty with application to ocean storm severity. Journal of the Royal Statistical Society: Series C (Applied Statistics), 66(1):93­120.

Rohrbeck, C. and Tawn, J. A. (2021). Bayesian spatial clustering of extremal behavior for hydrological variables. Journal of Computational and Graphical Statistics, 30(1):91­105.

Simpson, E. S., Wadsworth, J. L., and Tawn, J. A. (2020). Determining the dependence structure of multivariate extremes. Biometrika, 107(3):513­532.

Tawn, J. A. (1988). Bivariate extreme value theory: Models and estimation. Biometrika, 75(3):397­ 415.

19

Wadsworth, J. L. (2016). Exploiting structure of maximum likelihood estimators for extreme value threshold selection. Technometrics, 58(1):116­126.
20

