arXiv:2106.00374v1 [cs.DS] 1 Jun 2021

Fault-Tolerant Labeling and Compact Routing Schemes

Michal Dory
ETH Zurich michal.dory@inf.ethz.ch *

Merav Parter
Weizmann Institute merav.parter@weizmann.ac.il 

Abstract
The paper presents fault-tolerant (FT) labeling schemes for general graphs, as well as, improved FT routing schemes. For a given n-vertex graph G and a bound f on the number of faults, an f -FT connectivity labeling scheme is a distributed data structure that assigns each of the graph edges and vertices a short label, such that given the labels of a vertex pair s and t, and the labels of at most f failing edges F, one can determine if s and t are connected in G \ F. The primary complexity measure is the length of the individual labels. Since their introduction by [Courcelle, Twigg, STACS '07], compact FT labeling schemes have been devised only for a limited collection of graph families. In this work, we fill in this gap by proposing two (independent) FT connectivity labeling schemes for general graphs, with a nearly optimal label length. This serves the basis for providing also FT approximate distance labeling schemes, and ultimately also routing schemes. Our main results for an n-vertex graph and a fault bound f are:
· There is a randomized FT connectivity labeling scheme with a label length of O( f + log n) bits, hence optimal for f = O(log n). This scheme is based on the notion of cycle space sampling [Pritchard, Thurimella, TALG '11].
· There is a randomized FT connectivity labeling scheme with a label length of O(log3 n) bits (independent of the number of faults f ). This scheme is based on the notion of linear sketches of [Ahn et al., SODA '12].
· For a given stretch parameter k  1, there is a randomized routing scheme that routes a message from s to t in the presence of a set F of faulty edges (unknown to s) over a path of length O(|F|2k) · distG\F(s, t). The routing labels have O( f ) bits, the messages have O( f 3) bits, and each routing table has only O( f 3n1/k) bits1. The results also holds for weighted graphs with positive polynomial weights.
This significantly improves over the state-of-the-art bounds by [Chechik, ICALP '11], providing the first scheme with sub-linear FT labeling and routing schemes for general graphs.

*Supported in part by the Swiss National Foundation (project grant 200021 184735). Supported by the European Research Council (ERC) No. 949083, and by the Israeli Science Foundation (ISF) No. 2084/18. 1Throughout the paper, we use the notation O to hide poly-logarithmic in n terms.
1

Contents

1 Introduction

3

1.1 Our Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4

1.2 Our Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6

1.3 Additional Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8

2 Preliminaries

10

3 Fault-Tolerant (FT) Connectivity Labels

10

3.1 Connectivity Labels Based on Cycle Space Sampling . . . . . . . . . . . . . . . . . . . 11

3.1.1 The Labeling Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

3.1.2 The Decoding Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

3.1.3 Faster Decoding Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

3.2 Connectivity Labels Based on Graph Sketches . . . . . . . . . . . . . . . . . . . . . . . 14

3.2.1 The Labeling Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15

3.2.2 The Decoding Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

4 Fault-Tolerant Approximate Distance Labels

21

5 Compact Routing Schemes

24

5.1 Forbidden Set Routing (Faulty Edges are Known) . . . . . . . . . . . . . . . . . . . . . 25

5.2 Fault-Tolerant Routing (Faulty Edges are Unknown) . . . . . . . . . . . . . . . . . . . 26

A Additional Definitions

34

B Overview of the Cycle Space Sampling Technique

35

C Missing Proofs

35

2

1 Introduction
Distributed graph representation is concerned with augmenting each vertex (and possibly also edges) with useful and low-space information in order to efficiently address various graph queries in a distributed manner. As the vertices and edges of the network may occasionally fail or malfunction, it is desirable to make these representations robust against failures. In this paper, we provide new constructions of succinct labeled-based distributed data structures that can handle connectivity, distance queries and routing in the presence of edge failures.
Connectivity labels are short names attached to each vertex in the n-vertex input graph G, such that given the labels of a pair of vertices s and t (and no any other information), it is possible to deduce if s and t are connected in G. The primary complexity measure of the labeling scheme is the label length (maximum length of a label). In general, labels can be viewed as the logical names of the vertices [KNR92, Pel05], as they are considerably more informative than the physical names that usually correspond to arbitrary O(log n)-bit identifiers. For example, in routing applications the label of the vertex is treated as its "address". It is quite immediate to provide connectivity labeling schemes of logarithmic length. Over the years, these labels have served the basis for devising also approximate distance labels, and compact routing schemes, which are arguably the grand finale of the distributed representation schemes.
Our goal in this paper is to provide fault-tolerant analogs for the above mentioned schemes, while paying a small overhead in terms of space and other complexity aspects. Several notions of fault-tolerant labeling and routing schemes have been addressed in the literature; starting with the earlier introduction of FT routing schemes by Dolev [DHSS84], to the more recent formulations of forbidden-set labeling and routing schemes by Courcelle et al. [CGKT07, CT07]. Despite much activity revolving these topics, FT labeling and routing schemes with sub-linear space are currently known only for a limited collection of graph families. We next elaborate more on the state-of-the-art affairs, and our main objectives.
Fault-Tolerant Connectivity and Distance Labeling. FT connectivity labeling schemes, also known in the literature as forbidden-set labeling [CT07], assign labels to the vertices and the edges of the graph such that given the labels of a vertex pair s, t, and the labels of the faulty edges F, one can determine if s and t are connected in G \ F.
Since their introduction, efficient FT labeling schemes have been devised only for a restricted collection of graph families such as graphs with bounded tree-width and planar graphs [CT07, ACGP16]. In the lack of any FT connectivity labeling schemes for general graphs with sub-linear label length (for any f  2 faults2), we ask:
Question 1.1. Is it possible to design FT connectivity labeling scheme resilient to at most f edge faults, for general graphs with label length of poly(log n) bits, or even poly(log n, f ) bits?
FT connectivity labels are also closely related to connectivity sensitivity oracles [PT07], which are low-space centralized data-structures that handle efficiently s, t, F connectivity queries using S(n) space. Our main goal is in providing a distributed variant of such constructions, e.g., where each vertex or edge in the graph "holds" only S(n)/n bits of information, such that an s, t, F query can be addressed using only the information stored by s, t and F.
An important step towards designing FT compact routing schemes involves the computation of FT approximate distance labels. In this setting, given the labels of s, t and the faulty edges F, it is required to report an approximation for the s-t shortest path distance in G \ F. FT approximate
2While there is no explicit construction of FT labeling for general graphs, for f = 1, the centralized distance sensitivity oracle of [KB10] might be modified to provide approximate distance labels against a single fault.
3

distance labels can be viewed as the distributed analog of f -FT distance sensitivity oracles [KB10, WY10]. These are global succinct data-structures that given an s, t, F query report fast an estimate for the approximate s-t distance in G \ F. Our goal is to provide FT approximate labeling schemes that match the state-of-the-art space vs. stretch tradeoff of the centralized data structures.
Fault-Tolerant Routing. A desirable requirement in most communication networks is to provide efficient routing protocols in the presence of faults. Specifically, an f -FT routing protocol is a distributed algorithm that, for any set of at most f faulty edges F, allows a vertex s to route a message to a destination vertex t along an approximate s-t shortest path in G \ F (without knowing F in advance). The routing scheme consists of two algorithms: (i) a preprocessing algorithm which computes (succinct) routing tables and labels for each vertex in the graph; and (ii) a routing algorithm that given the received message and the routing table of vertex v determines the next-hop (specified as a port number) on the v-t (approximate) shortest path in G \ F. The efficiency of the scheme is determined by the tradeoff between the stretch (i.e., the ratio between the weighted length of the s-t route in G \ F to the corresponding shortest path distance) and the space of the routing tables, labels and messages. While the stretch vs. space tradeoff of routing schemes is fully understood in the non-faulty setting, the corresponding bounds in the FT setting are still far from optimal. So far, in all the prior schemes, the space of the individual routing tables could be linear in the worst case, even when allowing a large stretch bound. This is in strike contrast to the standard (non-faulty) compact routing schemes, e.g., by Thorup and Zwick [TZ01], which provide each vertex a table of O(n1/k) bits, while guaranteeing a route stretch of 2k - 1. The current large gap in the quality of FT routing schemes compared to their non-faulty counterparts leads to the following question.
Question 1.2. Is it possible to design f -fault-tolerant compact routing scheme for general graphs with sublinear table size and with a sub-logarithmic stretch?
1.1 Our Results
We provide space-efficient labeling and routing schemes for any n-vertex graph. Our schemes are randomized and provide a high probability guarantee3 for any given triplet s, t, F . In other words, the schemes can faithfully support polynomially many queries4.
Our first key result presents two independent schemes for FT connectivity labels. These are the first FT connectivity labels for general graphs. These two constructions yield the following theorem, addressing Question 1.1:
Theorem 1.3. [FT Connectivity Labeling Schemes, Informal] For any n-vertex graph and a bound f on the number of edge faults, there is a randomized f -FT connectivity labeling scheme with label length of O(min{ f + log n, log3 n}) bits. The labels are computed in O(m) time, and the decoding algorithm takes poly( f , log n) time.
By the tightness of the label length of fault-free connectivity labels, our scheme is optimal for f = O(log n). Moreover, the label length is nearly-optimal for any f . Our actual scheme provides more information then merely a single bit (connected or not connected). Specifically, we augment the connectivity labels with additional information so that the decoding algorithm, given the labels of s, t and F, can also output a succinct description of an s-t path in G \ F (if such a path exists). This succinct path representation finds applications in the context of our FT routing schemes.
3As standard, we use the term high-probability to indicate success guarantee of 1 - 1/nc for any given constant c > 1. 4The same type of guarantee is provided in the centralized sensitivity oracles, e.g., of [DP17]. Providing a high probability guarantee over all possible triplets is possible upon increasing the space bound by a factor of f (largest number of faults supported).
4

We next consider the task of reporting also approximate s-t distances in G \ F using the labels of s, t and F. We employ the reduction of Chechik et al. [CLPR12] to convert the FT connectivity labels into FT approximate distance labels, providing nearly the same space vs. stretch tradeoff as in the centralized data-structures of [CLPR12]. Specifically, we show:
Theorem 1.4. [FT Approximate Distance Labeling Schemes] For any n-vertex (possibly weighted) graph, a bound f on the number of edge faults, and a stretch parameter k, there is a randomized f -FT approximate distance labeling scheme with label length of O(k · n1/k · log(nW) · log3 n). Given the labels of s, t and F the scheme returns a distance estimate
distG\F(s, t)  (s, t, F)  (8k - 2)(|F| + 1)distG\F(s, t) .
For the purpose of routing, we exploit the extra information provided by our connectivity labels, in order to output, in addition to the distance estimate (s, t, F), also a succinct description of the approximate s-t shortest path in G \ F. Our second key result provides FT compact routing schemes, with an almost optimal tradeoff between the space and stretch, for constant number of faults f . We answer Question 1.2 by showing:
Theorem 1.5. [FT Compact Routing] For every integers k, f , there exists an f -sensitive compact routing scheme that given a message M at the source vertex s and the routing label of the destination t, in the presence of at most f faulty edges F (unknown to s) routes M from s to t in a distributed manner over a path of length at most 32k(|F| + 1)2 · distG\F(s, t). The routing labels have O( f ) bits, the table size of each vertex is O( f 3 · n1/k log(nW)), the header size (also known as message size) is bounded by O( f 3) bits.
This improves over the state-of-the-art construction of Chechik [Che11] that obtained routing schemes with stretch of O( f 2( f + log2 n)k) and tables of size O(deg(v)n1/k log (nW)) for every vertex v. We note that the construction of Chechik [Che11] has a bounded global space of O(n1+1/k log (nW)), but the individual tables might have even super-linear space (e.g., when k = O(1) and deg(v) = O(n)). For the special case of f = 2, Chechik et al. [CLPR10, CLPR12] provide a stretch bound of O(k), and total space of O(n1+1/k log (nW)), where the space of each table is bounded by O(deg(v)n1/k), thus super-linear in the worst case. Our scheme provides an improved bound on the individual tables, nearly matching the fault-free constructions for f = O(1). We also show an improved scheme if one only aims to optimize for the global space, rather than optimizing for the largest table size for a vertex. For comparison of our results to prior work see Table 1.

Constructions of Fault-Tolerant Routing Schemes

Reference

Stretch

Table Size

|F|

Rajan [Raj12]

O(k2)

O(k deg(v) + n1/k) per vertex

1

Chechik et al. [CLPR12] O(k)

O(n1+1/k log(nW)) total size

2

Chechik [Che11]

O(|F|2(|F| + log2 n)k) O(n1+1/k log(nW)) total size

f

Chechik [Che11]

O(|F|2(|F| + log2 n)k) O(deg(v)n1/k log(nW)) per vertex f

Here

O(|F|2k)

O( f · n1+1/k log(nW)) total size

f

Here

O(|F|2k)

O( f 3 · n1/k log(nW)) per vertex

f

Table 1: Comparison between FT routing schemes with a set of failures F

Finally, we provide a lower bound result on the minimal stretch regardless for the space of the routing scheme, e.g., even if all vertices store all the graph edges.
Theorem 1.6 (Stretch Lower-Bound for FT Routing). Any FT routing randomized scheme resilient to f faults induces an expected stretch of ( f ) regardless of the size of the routing tables and labels. In particular, this holds even if each routing table contains a complete information on the graph.

5

Open Problems. Our work leaves several interesting open ends. One natural direction is to provide labeling and routing schemes resilient to vertex faults. The major challenge in handling vertex failure is that even a single faulty vertex might disconnect the graph into (n) disconnected components. Another interesting direction is to derandomize our constructions. Currently there are no deterministic constructions of FT labeling schemes for general graphs. Finally, it will be also important to provide FT distance approximate labeling schemes whose stretch bound is independent in the number of faults f . This problem is also open in the corresponding setting of approximate distance sensitive oracles.

1.2 Our Techniques
For our FT labeling schemes, we present two constructions based on different techniques. The first construction uses the cycle-space sampling technique of Pritchard and Thurimella [PT11] to determine if s and t are disconnected by a set of failures F. This technique has been applied in the past mainly in the context of computing small cuts in the distributed setting. The second construction uses the tool of linear sketches by Ahn et al. [AGM12] to try to find a path that connects s and t in G \ F. This scheme is also useful for routing. We next give an overview of the two approaches, and the applications for routing. Throughout, we assume that the graph G is originally connected, otherwise the scheme can be applied to each connected component of G, which can be indicated in the label of the vertex.

Connectivity Labels Based on Cycle Space Sampling. The cycle space sampling technique, intro-

duced by Pritchard and Thurimella [PT11], allows one to detect cuts in a graph by exploiting the

interesting connection between cuts and cycles in a graph. This technique was used in [PT11] to

design distributed algorithms for identifying small cuts in a graph. In more details, the technique

is based on the relation between induced edge cuts and binary circulations, defined as follows. For a

subset of vertices S, we denote by (S) the set of edges with exactly one endpoint in S. An induced

edge cut is a set of edges of the form (S) for some S. A binary circulation is a set of edges in which

every vertex has an even degree. For example, a cycle is a binary circulation. Note that if F is an

induced edge cut, and  is a cycle, the number of edges in the intersection |F  | is even, as the

cycle crosses the cut even number of times. This is also true for any binary circulation . The cycle

space technique extends this observation and shows that if  is a random binary circulation and

F  E, then

Pr[|F  | is even] =

1, i f F is an induced edge cut 1/2, otherwise

Hence, by choosing a random binary circulation, one can detect if a set of edges F is an induced edge cut with probability 1/2. To increase the success probability, we can choose b random binary circulations. Based on these ideas, [PT11] showed how to assign the edges of the graph b-bit labels with the following property. See Appendix B for an overview.

Lemma 1.7. There is an algorithm that assigns the edges of a graph G = (V, E), b-bit labels (e) such that given a subset of edges F  E, we have:

Pr[ (e) = 0] =
eF

1, i f F is an induced edge cut 2-b, otherwise

Where 0 is the all-zero vector. The time complexity for assigning the labels is O((m + n)b).

The connectivity labels. We next explain how to use this technique to build FT connectivity labels. Our goal is to assign labels to the vertices and edges of the graph, such that given the labels of two

6

vertices s, t and a set of failures F, we can check if s and t are disconnected by F. It is easy to show that s and t are disconnected by F iff there is an induced edge cut F  F that disconnects s and t. While we can use the cycle space labels to check if a subset of edges F  F is an induced edge cut, this is still not enough to solve FT connectivity. To do so, we should check if an induced edge cut F disconnects the vertices s and t. To check this, we bring to our construction ancestry labels in trees, and show that we can determine if s and t are in the same side of cut (induced by F ) based on the ancestry labels of s, t and F . The key observation is that a spanning tree T of the graph is disconnected to at most |F | + 1 connected components, upon removing F , where for any e  F both its endpoints reside on two different sides of the induced edge cut defined by F . We can use this to identify which components of T \ F are on the same side of the induced edge cut. Moreover, we show that the ancestry labels allow us to determine the connected components of s and t in T \ F . A brute-force implementation of this approach leads to a decoding time that is exponential in |F|. I.e., the algorithm should check for any subset F  F if F is an induced edge cut. To overcome it, we show an efficient way to find F  F that disconnects s and t if exists, by translating our problem to a system of linear equations. This results in a decoding time polynomial in |F| and log n. The size of the labels is O( f + log n), to guarantee that the cycle space labels are correct for any F  F w.h.p.
Connectivity Labels Based on Graph Sketches. We next provide some flavor of our labels based graph sketches. The length of the labels obtained in this technique is O(log3 n) bits, which is dominated by the sketching information. A graph sketch of a vertex v is a randomized string of O(1) bits that compresses v's edges. The linearity of these sketches allows one to infer, given the sketches of subset of vertices S, an outgoing cut edge (S, V \ S). Graph sketches have numerous applications in the context of connectivity computation under various computational settings, e.g., [KKM13, KW14, GKKT15, KKT15, MK18, GP16, DP17]. More concretely, our sketch-based labels are inspired by the centralized connectivity sensitivity oracles of Duan and Pettie [DP17]. A common approach for deducing the graph connectivity merely from the sketches of the individual vertices is based on the well-known Boruvka algorithm [NMN01]. This algorithm works in O(log n) phases, where in each phase, from each growable component an outgoing edge is selected. All these outgoing edges are added to the forest, while ignoring cycles. Each such phase reduces the number of growable components by a 2 factor, thus within O(log n) phases, a maximal forest is computed. Since this algorithm only requires the computation of outgoing edges it can simulated using O(log n) independent sketches for each of the vertices.
Our high level approach for determining the s-t connectivity in G \ F mimics this above mentioned procedure. For simplicity assume that G is connected and let T be some spanning tree in G. Using ancestry labels, one can infer the components of T \ F. Moreover, by augmenting the labels with graph sketching information, one can also deduce the sketch of each component in T \ F. Note however that these sketches are in G and therefore might encode outgoing edges that belong to F. To overcome this technicality, our sketching scheme allows us to cancel out the effect of the faulty edges F from the sketching information. Consequently, we obtain the sketches of each T \ F component in the surviving graph G \ F. We can then apply the Boruvka's algorithm on the components of T \ F, and infer the s-t connectivity in G \ F. The actual implementation of this labeling scheme is somewhat more delicate. We note that some of these technicalities are for the sake of our later extension of these labels into compact routing schemes.
Applications for Routing Schemes. The starting point to our routing scheme is given by our (sketch-based) labeling scheme. These labels allows one to deduce also a succinct description of an s - t path in G \ F if exists, by following the component merging procedure of the Boruvka
7

algorithm. This description is composed of O( f ) path segments, where each segment {u, v} either corresponds to an outgoing (non-tree) edge found in the algorithm using the sketch information, or to a tree path between two vertices u and v in the same connected component in T \ F. Given the connectivity labels of s, t and F, we can find this description, and use it for routing. Routing across an edge {u, v} just requires sending a message over the edge, while routing on a tree path between u and v can be done using a routing scheme for trees. While this approach allows to send a message from s to t, there is no bound on the length of the path traversed. Additionally, this approach assumes that the set of failures F is known in advance. We next explain how to overcome these issues. Bounding the stretch. To route messages on low-stretch paths we use the notion of tree covers, following the approach in [CLPR12]. This approach also allows us to translate our connectivity labels to approximate distance labels as we discuss in Section 4. Here, instead of applying our connectivity scheme on just one graph G, we apply it on many subgraphs Gi,j of G with the following properties.
1. Each vertex v is contained in O(n1/k) subgraphs.
2. For any 1  i  log(nW), and any vertex v, there is a subgraph Gi,i(v) that contains all the vertices in the 2i-neighborhood of v.
3. If v and u are connected in the graph Gi,i(v) \ F, then there is a path between them of length at most O(k|F|2i) in the graph Gi,i(v) \ F.
By applying our connectivity scheme on each one of the subgraphs Gi,j, we can route a message from s to t on a path of stretch O(k|F|). The size of the labels and routing tables of vertices is O(n1/k) as each vertex and edge participate in O(n1/k) subgraphs. Faulty edges are unknown. The scheme we described assumes that the routing algorithm knows the labels of s, t and F in advance, we next explain how to avoid this assumption. Our general approach is to work in phases, where in each phase we try to route a message from s to t according to the currently set of known faults. We either succeed, or learn about the label of a new faulty edge e  F and try again. The stretch of the scheme increases to O(k|F|2) because of the |F| + 1 phases. Direct application of this approach may require large routing tables, as each vertex may need to know the labels of all edges adjacent to it, to be able to learn the labels of faulty edges found in the algorithm. To overcome it we use the following ingredients.
First, recall that in our connectivity labeling scheme we use a spanning tree T. In the routing scheme, these are the trees of the tree cover. We show that it is enough for each vertex to store labels only of its adjacent tree edges. Consequently, the total size of all routing tables can be bounded by O( f n1+1/k).5 However, this alone is not enough to bound the size of individual routing tables of vertices, as the degree of a vertex in a tree may be linear. To overcome this, we show a clever way to load balance the labels' information between v and its children in the tree. This results in tables of size O( f 3n1/k) per vertex, while keeping the same stretch of the scheme. The increase in the total size of tables comes from the fact we now duplicate labels f + 1 times, to be able to recover them in the presence of f failures.
1.3 Additional Related Work
Fault-Tolerant Labeling Schemes. FT labels for connectivity were introduced by [CGKT07] under the term forbidden-set labeling. Forbidden set refers to a subset F of at most f edges, such that given the labels of s, t and F one should determine if s and t are connected in G \ F. The forbidden
5The f term in the size comes from the fact we apply the connectivity labels f + 1 times to support the |F| + 1 phases.
8

edge set can be treated in this context as faulty edges6. Previous works study FT connectivity labels only in restricted graph families. For example, Courcelle et al. [CT07] presented a labeling scheme with logarithmic label length for the families of n-vertex graphs with bounded clique-width, tree-width and planar graphs. For n-vertex graphs with doubling dimension at most , Abraham et al. [ACGP16] designed FT labeling schemes with label length O((1 + 1/ )2 log n) that output (1 + ) approximation of the shortest path distances under faults. Recently, [BCG+21] studied FT exact distance labels in planar graphs, and show that any directed weighted planar graph admits fault-tolerant distance labels of size O(n2/3).
Connectivity and Distance Sensitivity Oracles. Connectivity and distance sensitivity oracles are centralized data structures that support connectivity or distance queries in the presence of failures. The first construction of connectivity sensitivity oracles was given by Patrascu and Thorup [PT07] providing an S(n) = O( f n) space oracle that answers s, t, F connectivity queries in O( f ) time. The state-of-the-art bounds of these oracles are given by Duan and Pettie [DP17]. Chechik et al. [CLPR12] presented the first randomized construction of distance sensitivity oracle resilient to f edge faults. Specifically, for any n-vertex weighted graph, stretch parameter k, and a fault bound f , they provide a data-structure with O( f kn1+1/k log(nW)) space, query time of O(|F|), and O( f k) stretch, where W is the weight of the heaviest edge in the graph. Their solution is based on an elegant transformation that converts the FT connectivity oracle of [PT07] into an FT approximate distance oracle.
While the main focus of this paper is in approximate distances, sensitivity oracles that report (possibly near) exact distances under faults have been studied also thoroughly in e.g., [DT02, BK08, DP09, WY10, GW12, CCFK17, vdBS19]. Since reporting exact distances requires linear label length already in the fault-free setting [GPPR04], we focus on the approximate relaxation, where there is still hope to obtain labels of polylogarithmic length.
Fault-Tolerant Routing Schemes. The first formalization of FT routing schemes was given by the influential works of Dolev [DHSS84] and Peleg [PS87]. These earlier works presented the first non-trivial solutions for general graphs supporting at most  faulty edges, where  is the edgeconnectivity of the graph. Their routing labels had linear size, providing s-t routes of possibly linear length (even in cases where the surviving s-t path is of O(1) length). In competitive FT routing schemes, it is required to provide s-t routes of length that competes with the shortest s-t path in G \ F, even in cases where G \ F is not connected. Competitive FT routing schemes [Pel09] for general graphs were given by Chechik et al. [CLPR10, CLPR12] for the special case of f  2 faults. Specifically, for a given stretch parameter k, they gave a routing scheme with a total space bound of O(n1+1/k) bits, polylogarithmic-size labels and messages, and a routing stretch of O(k). This scheme was extended later on for any f by Chechik [Che11], at the cost of increasing the routing stretch to O( f 2( f + log2 n)k). For a single edge failure, [Raj12] showed a routing scheme with routing tables of size O(k deg(v) + n1/k) size per vertex, O(k2) stretch and O(k + log n) size header.
Forbidden Set Routing. A more relaxed setting of FT routing scheme which has been studied in the literature is given by the forbidden set routing schemes, introduced by Courcelle and Twigg [CT07]. In that setting, it is assumed that the routing protocol knows in advance the set of faulty edges F. In contrast, in the FT routing setting, the failing edges are a-priori unknown to the routing algorithm, and can only be detected upon arriving one of their endpoints. Forbidden set routing schemes have been devised to the same class of restricted graph families as obtained for the forbidden set labeling setting [CT07, ACGP16, ACG12].
6For routing, the forbidden-set scheme is slightly weaker than FT scheme as explained later.
9

2 Preliminaries
Given a graph G = (V, E), and vertex u  V, let deg(u, G) be the degree of u in G. Given a tree T and u, v  T, denote the u-v path in T by (u, v, T). When the tree T is clear from the context, we may omit it and write (u, v). For a (possibly weighted) subgraph G  G and a vertex pair s, t  V, let distG (s, t) denote the length of the s-t shortest path in G .
Fault-Tolerant Labeling Schemes. For a given graph G, let  : V × V × G  R0 be a function defined on pairs of vertices and a subgraph G  G, where G is the family of all subgraphs of G. For an integer parameter f  1, an f -fault-tolerant labeling scheme for a function  and a graph family F is a pair of functions (L, D). The function L is called the labeling function, and D is called the decoding function. For every graph G in the family F , the labeling function L associates with each vertex u  V(G) and every edge e  E(G), a label L(u, G) (resp., L(e, G)). It is then required that given the labels of any triplets s, t, F  V × V × E f , the decoding function D computes (s, t, G \ F). The primary complexity measure of a labeling scheme is the label length, measured by the length (in bits) of the largest label it assigns to some vertices (or edges) in G over all graphs G  F . An f -FT connectivity labeling scheme is required to output YES iff s and t are connected in G \ F. In f -FT approximate distance labeling scheme it is required to output an estimate for the s-t distance in the graph G \ F. Formally, an f -FT labeling scheme is q-approximate if the value (s, t, F) returned by the decoder algorithm satisfies that distG\F(s, t)  (s, t, F)  q · distG\F(s, t). Throughout the paper we provide randomized labeling schemes which provide a high probability guarantee of correctness for any fixed triplet s, t, F .
Fault-Tolerant Routing Schemes. In the setting of FT routing scheme, one is given a pair of source s and destination t as well as F edge faults, which are initially unknown to s. The routing scheme consists of preprocessing and routing algorithms. The preprocessing algorithm defines labels L(u) to each of the vertices u, and a header H(M) to the designated message M. In addition, it defines for every vertex u a routing table R(u). The labels and headers are usually required to be short, i.e., of poly-logarithmic bits. The routing procedure determines at each vertex u the port-number on which u should send the messages it receives. The computation of the next-hop is done by considering the header of the message H(M), the label of the source and destination L(s) and L(t) and the routing table R(u). The routing procedure at vertex u might also edit the header of the message H(M). The failing edges are not known in advance and can only be revealed by reaching (throughout the message routing) one of their endpoints. The space of the scheme is determined based on maximal length of message headers, labels and the individual routing tables. The stretch of the scheme is measured by the ratio between the length of the path traversed until the message arrived its destination and the length of the shortest s-t path in G \ F. In the more relaxed setting of forbidden-set routing schemes the failing edges are given as input to the routing algorithm.
3 Fault-Tolerant (FT) Connectivity Labels
We next discuss two labeling schemes for connectivity that are based on two different approaches. The first one uses the cycle space sampling technique to try to find cuts that disconnect s and t. The second one uses graph sketches to try to find a path that connects s and t. Since the second approach allows to find a path between s and t if exists, it is also useful later for routing. In terms of label size, the first approach gives labels of size O( f + log n), which is near-optimal if the number of failures is f = O(log n). On the other hand, the second scheme gives labels of size O(log3 n), which is better when the number of failures is large. We next discuss the labeling schemes. During this section,
10

we assume that the input graph G is connected. If not, we can add to the label of each vertex and edge the id of their connected component in G, and apply the labeling scheme to each one of the connected components separately.

3.1 Connectivity Labels Based on Cycle Space Sampling
3.1.1 The Labeling Algorithm Our labels are composed of two ingredients, that we review next.

Cycle Space Labels. The cycle space sampling technique, introduced in [PT11], allows to give the edges of a graph short labels that allow to detect cuts in the graph. For a set of vertices S, (S) is the set of edges with exactly one endpoint in S. A subset of edges F is called an induced edge cut if F = (S) for some S. The following is shown in [PT11] (see Corollary 2.9).
Lemma 1.7. There is an algorithm that assigns the edges of a graph G = (V, E), b-bit labels (e) such that given a subset of edges F  E, we have:

Pr[ (e) = 0] =
eF

1, i f F is an induced edge cut 2-b, otherwise

Where 0 is the all-zero vector. The time complexity for assigning the labels is O((m + n)b).

For an overview of the technique, see Appendix B. In our algorithm, given a subset of edges F

of size at most f , we want to be able to check for any subset F  F if F is an induced edge cut. To

support all these 2 f queries w.h.p we choose b = f + c log n for a constant c. This guarantees that

the probability of error is at most

2f 2 f +c log n

=

1 nc

.

This will guarantee that given a query

s, t, F , our

algorithm answers correctly w.h.p. We remark that if we increase the size of labels to O( f log n) we

can get an algorithm that is correct for all queries w.h.p. The reason is that we can then check for

any subset of edges F of size at most f if F is an induced edge cut. As the number of subsets of size

at most f is bounded by O(n f ), we get that the labels are correct for all such subsets w.h.p.

Ancestry Labels. Our second ingredient are ancestry labels for trees. To use them, we first fix a spanning tree T of the graph rooted at r. The goal is to assign vertices short labels, such that given the labels of u and v, we can infer if u is an ancestor of v in T. A simple labeling scheme based on a DFS scan solves the problem with labels of size 2 log n per vertex [KNR92], the time for assigning the labels is O(n) for the DFS scan of the tree. Labeling schemes with improved label size appear in [AAK+06, AR02, FK10a, FK10b].
Lemma 3.1. For every tree T, there is an algorithm that assigns the vertices u of the tree labels ANCT(u) of O(log n) bits, such that given the labels of u and v we can infer if u is an ancestor of v in T in O(1) time. The time for assigning the labels is O(n).

The Final Labels. Our final labels contain the following ingredients:
1. The label of the edge e = (u, v) is composed of ((e), ANCT(u), ANCT(v), j), where j is a bit indicating if e is a tree edge in T. In total, the label size is O( f + log n).
2. The label of a vertex v is its ancestry label ANCT(v) of size O(log n) bits.
As discussed, the time for assigning the labels is O((m + n)b) = O((m + n) f ), as b = f + c log n. We next explain how we use these labels to check FT connectivity.

11

3.1.2 The Decoding Algorithm
We next discuss several observations that allow us to check if s and t are disconnected by F.
Claim 3.2. The vertices s and t are disconnected by F if an only if there is an induced edge cut F  F that disconnects s and t.
Proof. First, if F  F disconnects s and t, then clearly F disconnects s and t. On the other hand, if s and t are disconnected by F, let F  F be a minimal set of edges whose removal disconnects s and t. We show that F is an induced edge cut. Let Vs be the vertices in the connected component of s in G \ F . We show that all edges in F are between Vs and V \ Vs, implying that F is an induced edge cut. Assume to the contrary that there is an edge e  F with both endpoints in one of the sides, say Vs, then F \ {e} is still a cut that disconnects s and t (as Vs is still disconnected from the rest of the graph if we add e), contradicting the minimality of F . A symmetric argument shows that e cannot have both its endpoints in V \ Vs.
We next show that given an induced edge cut F , there is a simple way to determine the two sides of the cut induced by F (see Figure 1 for illustration). For a vertex v and an induced edge cut F , we denote by nv(F ) the number of edges from F in the path from the root r to v in the spanning tree T. We show the following.
Claim 3.3. Let F be an induced edge cut. Let
V0 = {v  V| nv(F ) is even},
V1 = {v  V| nv(F ) is odd}.
Then (V0, V1) is the induced edge cut defined by F .
Proof. Since F is an induced edge cut, the endpoints of every edge in F are on different sides of the cut. Hence, if we scan the tree T from the root to the leaves, every time we reach an edge from F we change the side of the cut. It follows that one side of the cut contains all vertices v such that nv(F ) is even, and the other side has all vertices v such that nv(F ) is odd. Hence V0, V1 are the two sides of the cut.



\



1

1

2

2

3

4

3

4

Figure 1: Here F = {e1, e2, e3, e4} is an induced edge cut. On the right, you can see the partition into sides in the tree. Every time we reach an edge from F , we change the side of the cut.
From Claims 3.2 and 3.3, we get the following. Corollary 3.4. The vertices s and t are disconnected by F if an only if there is an induced edge cut F  F, such that one of the values ns(F ), nt(F ) is even and the other is odd.
12

This gives a simple approach to detect if s and t are disconnected by F. We go over all subsets F  F, for each one of them we first check if F is an induced edge cut using the cycle space labels. Second, if F is an induced edge cut, we compute the values ns(F ), nt(F ), if the number is even for one of them and odd for the second, we deduce that F disconnects s and t. Note that we can use the ancestry labels to compute the values ns(F ), nt(F ). For example, for computing ns(F ) we should check how many edges in F are in the tree path between r to s. For this, for each tree edge e = (u, v) in F , we check if it is above s in the tree, which happens if and only if both u and v are ancestors of s. This simple approach requires time exponential in |F| for going over all subsets of F, we next show a faster way to check the same condition.
3.1.3 Faster Decoding Algorithm
We next show that checking the condition from Corollary 3.4 boils down to solving a system of linear equations. First, note that from Lemma 1.7, w.h.p, a set of edges F  F is an induced edge cut iff eF (e) = 0. Hence, if we want to check if there is a non-empty subset F  F that is an induced edge cut it is equivalent to checking if there exists a binary vector x = (x1, ..., x f ) = 0 such that 1i f xi(ei) = 0, where {e1, ...e f } are the edges of F. Or equivalently checking if the vectors {(e)}eF are linearly dependant. To check the condition from Corollary 3.4, we generalize this idea.
Let b = O( f + log n) be the size of the cycle space labels. Given a triplet (s, t, F), we assign for each edge e  F, a binary vector  (e) of length b + 2, as follows.
1. If e is a tree edge which is in the tree path r - s but not in the path r - t, then  (e) = 10(e).
2. If e is a tree edge which is in the tree path r - t but not in the path r - s, then  (e) = 01(e).
3. In all other cases,  (e) = 00(e).
We denote by w1, w2 binary vectors of length b + 2 such that w1 = 100..0, w2 = 010...0 (all right entries are equal to 0). We show that the condition from Corollary 3.4 holds iff there is a binary vector x = (x1, ..., x f ) and j  {1, 2} such that
xi (ei) = wj.
1i f
This holds iff there is a solution to at least one of the linear systems Ax = w1, Ax = w2, where A is a (b + 2) × f matrix that has the vectors { (e)}eF as its column vectors, and x, w1, w2 are column vectors. All operations are modulo 2.
Lemma 3.5. With high probability, the vertices s and t are disconnected by F if an only if there is a binary vector x = (x1, ..., x f ) and j  {1, 2} such that 1i f xi (ei) = wj.
Proof. We assume for the proof that the cycle space labels are correct, i.e., a set of edges F  F is an induced edge cut iff eF (e) = 0. This happens w.h.p from Lemma 1.7 and the choice of b = O( f + log n).
First we show that if s and t are disconnected by F, the condition of the lemma holds. From Corollary 3.4, s and t are disconnected by F iff there is an induced edge cut F  F, such that one of the values ns(F ), nt(F ) is even and the other is odd. Denote by ns(F ) the number of edges from F in the r - s tree path that are not in the r - t path, and denote by nt(F ) the number of edges from F in the r - t tree path that are not in the r - s path. Note that if one of the values ns(F ), nt(F ) is even and the other is odd, then also one of ns(F ), nt(F ) is even and the other is odd, as if we denote by y the number of edges from F that are in both r - s and r - t, we get that
13

ns(F ) = ns(F ) - y, nt(F ) = nt(F ) - y. Assume first that ns(F ) is even and nt(F ) is odd. Let x be the characteristic vector of F . We show that 1i f xi (ei) = w2. First, as F is an induced edge cut, we have that eF (e) = 0. Hence, the b last bits of 1i f xi (ei) are equal to 0 as needed. F has even number of edges that are in the path r - s and not r - t, as the labels  (e) of all these edges start in 10, the XOR of the first 2 bits of these edges sums to 00. F has odd number of edges that are in the path r - t but not r - s. The labels of all these edges start in 01, as there is an odd number of them, the XOR of the first 2 bits of these edges sums to 01. All other edges have labels that start in 00, hence the XOR of their first 2 bits sums to 00. Overall we get that 1i f xi (ei) = eF  (e) = 010...0 = w2. The case that ns(F ) is odd and nt(F ) is even is symmetric and results in the equation 1i f xi (ei) = 100...0 = w1.
On the other hand, if we have that 1i f xi (ei) = wj for a binary vector x = (x1, ..., x f ) and j  {1, 2}, we can build from it F that satisfies the condition in Corollary 3.4, as follows. We define F to be all edges ei  F such that xi = 1. Since 1i f xi (ei) = eF  (e) = wj, we have that
eF (e) = 0, hence F is an induced edge cut. Additionally if wj = w2, it implies that the XOR of the first 2 bits of labels { (e)}eF are equal to 01. By the definition of the labels, this can only happen if ns(F ) is even and nt(F ) is odd. Similarly, if wj = w1, then ns(F ) is odd and nt(F ) is even. In both cases we get that one of the values ns(F ), nt(F ) is even and the other is odd, hence s and t are disconnected by F from Corollary 3.4.
To conclude, the question if s and t are disconnected by F boils down to checking if there is a solution to at least one of the linear systems Ax = w1, Ax = w2, where A is a (b + 2) × f matrix, and b = O( f + log n). Note that we can construct the labels  (e) and hence the matrix A given the labels of s, t, F. For this, we need the labels (e) of edges in F, and also to distinguish for each edge in F if it is in the r - s, r - t paths in the tree. The latter can be deduced from the ancestry labels of s, t, F and from the bits indicating which edges in F are tree edges. A tree edge e = (u, v)  F is in the r - s path iff both u and v are ancestors of s, this can be checked in O(1) time using the ancestry labels of u, v, s. Hence we can build the matrix A in O( f b) time. To check if the linear systems have a solution we can use Gaussian elimination, that takes O(MN2) time for M × N matrix, in our case this is O(( f + log n) f 2). Alternatively, we can use O(N) algorithms for N × N matrices, where  is the exponent of matrix multiplication. For this, we add zero columns to our matrix A to make it a (b + 2) × (b + 2) matrix A and increase the length of x to b + 2, the new system A x = wi has a solution iff the original system Ax = wi has a solution. The complexity here is O((b + 2)) = O(( f + log n)). This gives the following.
Theorem 3.6. There is a randomized f -FT connectivity labeling scheme that assigns the edges and vertices of the graph labels of size O(log n) bits per vertex and O( f + log n) bits per edge. The decoding time of the scheme is min{O(( f + log n) f 2), O(( f + log n))}. The time complexity for assigning the labels is O((m + n) f ).
3.2 Connectivity Labels Based on Graph Sketches
In this section, we show the following:
Theorem 3.7. For every undirected n-vertex graph G = (V, E), a positive integer f , there is a randomized f -FT connectivity labels ConnLabelG : V  E  {0, 1} of length = O(log3 n) bits. The decoding time of the scheme is O( f ), and the computation time for assigning the labels is O(m + n).
In Section 3.2.1, we present the labeling algorithm which assigns labels based on the notion of graph sketches. In Section 3.2.2 we present the decoding algorithm that given the label information determines if s and t are connected in G \ F. When the graph G is clear from the context, we may omit it and simply write ConnLabel.
14

3.2.1 The Labeling Algorithm
Given a connected graph G, let T be an arbitrary rooted spanning tree in G that is used throughout this section. In our future applications of this labeling scheme (e.g., routing), both the graph G and the tree T  G will be given as input to the labeling algorithm. In the latter case, we denote the output labels by ConnLabelG,T. Throughout, all vertices have unique ids ID(v) between {1, . . . , n}.

Extended Edge Identifiers. In our algorithm it is important to distinguish between an identifier of a single edge to the bitwise XOR of several edges. For this purpose, we define for each edge e an extended edge identifier EIDT(e) that allows distinguishing between these cases, and serves as the identifier of the edge. The extended edge identifier EIDT(e) consists of a (randomized) unique distinguishing identifier UID(e), as well as additional tree related information that facilitates the decoding procedure. The computation of UID(e) is based on the notion of -bias sets [NN93]. The construction is randomized and guarantees that, w.h.p., the XOR of the UID part of each given subset of edges S  E, for |S|  2, is not a legal UID identifier of any edge. Let XOR(S) be the bitwise XOR of the extended identifiers of edges in S, i.e., XOR(S) = eS EIDT(e). In addition, let XORU(S) = eS UID(e). Missing proofs are deferred to Appendix C.

Lemma 3.8 (Modification of Lemma 2.4 in [GP16]). There is an algorithm that creates a collection I = {UID(e1), . . . , UID(eM)} of M = (n2) random identifiers for all possible edges (u, v), each of O(log n)-bits using a seed SID of O(log2 n) bits. These identifiers are such that for each subset E  E, where |E | = 1, we have Pr[XORU(E )  I ]  1/n10. In addition, given the identifiers ID(u), ID(v) of the edge e = (u, v)
endpoints, and the seed SID, one can determine UID(e) in O(1) time.

For every vertex v  G, let ANCT(v) be the ancestor label of v computed for the given tree T using Lemma 3.1. The extended identifier EIDT(e) is given by

EIDT(e) = [UID(e), ID(u), ID(v), ANCT(u), ANCT(v)] .

(1)

The identifiers of ID(u), ID(v) are used in order to verify the validity of the unique identifier UID(e). When the tree T is clear from the context, we might omit it and simply write EID(e). As we will see, the labeling scheme will store the seed SID as part of the labels of the tree edges.

Fault-Tolerant Labels via Graph Sketches. Graph sketches are a tool to identify outgoing edges.

We start by providing an intuition for them. Say that S is a connected component, and that there

are 2j edges outgoing from S. If we sample all edges in the graph with probability 1/2j, there is

a constant probability that exactly one outgoing edge from S is sampled, and our goal is to find it

using local information stored at the vertices of S. This information is the sketch. The sketch of each

vertex stores the bitwise XOR of sampled edges adjacent to it. Now looking at the XOR of all the

sketches of vertices of S allows to detect an outgoing edge. This holds as any sampled edge that has

both endpoints in S gets cancelled out, and we are left with the XOR of sampled edges outgoing from

S. If there is exactly one outgoing edge, we find it. To increase the success probability we can repeat

the process O(log n) times. We define sets of vertices Ei,j, where for i  {1, . . . , c log n}, the set Ei,j is obtained by sampling each edge with probability 2-j. Since we repeat the process O(log n) times for

each j, then w.h.p we can use the sketches to identify outgoing edge from any component. To use

this approach in our context, it is crucial to be able to simulate the sampling process using a small

random seed. To do this, we follow [DP16, DP17] and use pairwise independent hash functions to

decide whether to include edges in sampled sets. We choose L = c log n pairwise independent hash functions h1, . . . , hL : {0, 1}(log n)  {0, . . . , 2log m - 1}, and for each i  {1, . . . , L} and j  [0, log m],

define the edge set

Ei,j = {e  E | hi(e)  [0, 2log m-j)} .

15

Each of these hash functions can be defined using a random seed of logarithmic length [Vad12]. Thus, a random seed Sh of length O(L log n) can be used to determine the collection of all these L functions. As observed in [DP16, GKKT15], pairwise independence is sufficient to guarantee that for any set E  E and any i, there exists an index j, such that with constant probability XOR(E  Ei,j) is the name (extended identifier) of one edge in E , for a proof see Lemma 5.2 in [GKKT15].

Lemma 3.9. For any edge set E and any i, with constant probability there exists a j satisfying that |E  Ei,j| = 1.
We also need to be able to tell that a bit string of XOR(E  Ei,j) is a legal edge ID or not. Here we exploit the extended ids. See Appendix C for a proof.

Lemma 3.10. Given the seed SID, one can determine in O(1) time if XOR(E  Ei,j) corresponds to a single edge ID in G or not, w.h.p.
For each vertex v and indices i, j, let Ei,j(v) be the edges incident to v in Ei,j. The ith basic sketch unit of each vertex v is then given by:

SketchG,i(v) = [XOR(Ei,0(v)), . . . , XOR(Ei,log m(v))].

(2)

The sketch of each vertex v is defined by a concatenation of L = (log n) basic sketch units:

SketchG(v) = [SketchG,1(v), SketchG,2(v), . . . SketchG,L(v)] .
For every subset of vertices S, let SketchG(S) = vSSketchG(v). When the graph G is clear from the context, we may omit it and write Sketchi(v) and Sketch(v).
We are now ready to define the fault-tolerant connectivity labels of vertices and edges. The label of each vertex u is given by:

ConnLabelG,T(u) = ANCT(u), ID(u) ,

(3)

where ANCT(u) is the ancestry label of u with respect to the tree T. For every u  V(T), let Tu be the subtree rooted at u. The label ConnLabelG,T(e) of each edge e = (u, v) is given by:

ConnLabelG,T(e) =

EIDT(e), Sketch(V(Tu)), Sketch(V(Tv)), Sketch(V), SID, Sh , for e  T

EIDT(e) ,

Otherwise.

We complete this subsection by bounding the label size and computation time of the labeling algorithm. For proofs see Appendix C.
Claim 3.11. The label length is O(log3 n) bits.

We show that assigning the labels takes O(m + n) time. Claim 3.12. The time complexity of the labeling algorithm is O(m + n).

Finally, the subsequent decoding algorithm will be based on the following useful property of the graph sketches, stored by our labels.
Lemma 3.13. For any subset S, given one basic sketch unit Sketchi(S) and the seed SID one can compute, with constant probability, an outgoing edge E(S, V \ S) if such exists. The complexity is O(1) time.

16

3.2.2 The Decoding Algorithm
We next describe the decoding algorithm where given a triplet s, t, F  V × V × E f along with their labels, it determines whether s and t are connected in G \ F, w.h.p. The decoding algorithm has four key steps: The first step identifies the at most f + 1 components C0 = {C1, . . . , C } of T \ F, as well as the components of s and t in C0. The second step uses the label information to compute the sketch value Sketch(Ci) of each component Ci  C0. The third step modifies this sketch information into SketchG\F(Ci), by subtracting the information related to the faulty edges. The forth and final step uses the sketch information in order to simulate L = O(log n) steps of the Boruvka algorithm. At the end of these steps, the decoding algorithm identifies the connected components of both s and t in G \ F. In the case where s and t are indeed connected in G \ F, the algorithm also outputs a succinct representation of an s-t path in G \ F. This extra information would be used later on by our compact routing scheme. We next describe these steps in details.
Step 1: Identification of the connected components C0 in T \ F. Let FT = F  T be the faulty tree edges and let FNT = F \ FT be the faulty non-tree edges. Let Q = {s, t}  V(FT). Each component Ci of T \ F will be identified by the maximum vertex ID in Ci  V(FT). Note that in the case where FT = , T \ F = T and thus s and t are connected iff s, t  V(T). From now on, we therefore assume that FT = .
We next show that although we do not have full information about the tree T and the vertices of each connected component, the ancestry labels of V(FT) give us enough information to identify the connected components of T \ F. Additionally, given an ancestry label of a vertex u, we can identify the connected component of u. To obtain this, it is helpful to look at the component tree that is obtained by contracting each connected component of T \ F to one vertex, as follows. Let
= |FT| + 1. The component tree TC = (C0, EC) is a tree of vertices representing the connected components in T \ F, and |FT| = - 1 edges corresponding to the edges of FT. There is an edge (Ci, Cj)  EC iff there is an edge (u, v)  FT where u  Ci, v  Cj. See Figure 2 for an illustration.


1 2
3 4


1 2
3 4

Figure 2: Illustration of the component tree where F = {e1, e2, e3, e4}. Each connected component of T \ F is contracted to one vertex on the right.
We can construct the tree TC using the ancestry labels of the edges FT. For this, for each edge e  FT we just need to identify the set of edges from FT above e in T. Moreover, for a given vertex v, its connected component is exactly determined by the set of edges in FT above it in T, which can again be identified using the ancestry labels of v  V(FT). In particular, we can identify the connected components of s and t. The component tree can be constructed in O( f 2) time by checking for any pair of edges e, e  FT, if e is above e in the tree. We next show a faster algorithm
17

taking only O( f ) time by exploiting properties of the ancestry labels. Moreover, we show that the component of each vertex can be identified in O(log f ) time.
Claim 3.14. The component tree can be constructed in O( f log f ) time. Additionally, given ANCT(v), we can identify the connected component of v in T \ F in O(log f ) time.
Proof. Our algorithm uses ancestry labels based on DFS from [KNR92]. In this scheme, the label of each vertex v is composed of two numbers (DFS1(v), DFS2(v)) that represent the first and last times a DFS scan of the tree visits v. A vertex u is an ancestor of a vertex v iff the interval (DFS1(u), DFS2(u)) contains the interval (DFS1(v), DFS2(v)). To build the component tree, we sort the labels of V(FT), as described next. First, for each component C  T \ F, we use the highest vertex in the component to represent the component. For the highest component, this is the root r. For any other component, we have that the highest vertex of the component, v, is in V(FT). This holds as the edge connecting v to its parent p(v) is necessarily in FT (otherwise, v is not the highest vertex in its component), see Figure 2 for illustration. Hence, for any edge (v, p(v))  FT, we have that the vertex v represents one component (we can identify which of the vertices is the parent using the ancestry labels). Hence, we have |FT| + 1 vertices vi representing the components Ci of the component tree, and we also know the ancestry labels (DFS1(vi), DFS2(vi)) of all vertices vi, except r. For r we can use the label (1, M) where M is a number greater than all values DFS2(vi) of other vertices. We next use these labels to determine the structure of the component tree. For this, we create for each vertex vi two tuples: (DFS1(vi), vi, 1), (DFS2(vi), vi, 2), and we sort the 2(|FT| + 1) tuples according to their first coordinate. This takes O( f log f ) time. We next scan the sorted list, and when we reach the tuple (DFS1(vi), vi, 1), we identify the parent of vi in the component tree, as follows. The first tuple is (1, r, 1) and r is set to be the root of the component tree. For a vertex vi = r, we identify its parent when we reach (DFS1(vi), vi, 1). Let (DFSb(u), u, b) be the last tuple before (DFS1(vi), vi, 1) in the sorted order. If b = 1, then u is the parent of vi in the component tree. If b = 2, let w be the parent of u in the component tree, then w is also the parent of v in the component tree. Additionally, w was already computed as (DFS1(u), u, 1) appears before (DFS1(vi), vi, 1). Hence, we can find the parent of v in O(1) time using the tuple before it. Scanning the list takes O( f ) time, and after it we know for each component its parent in the component tree, which gives the complete structure of the tree. We next prove the correctness of the algorithm.
We first discuss the case that b = 1. Here (DFS1(u), u, 1) is the last tuple before (DFS1(vi), vi, 1). This means that u is necessarily an ancestor of v, because the entry (DFS1(vi), vi, 1) is between the entries (DFS1(u), u, 1) and (DFS2(u), u, 2), and the DFS scan traverses exactly the subtree of u in the time interval (DFS1(u), DFS2(u)), implying that vi is a child of u. Moreover, this is the closest ancestor to vi among the vertices {v1, v2, ..., v } \ {vi}, as the DFS scan traverses the ancestors of vi from the highest to the lowest. It follows that u represents the closest component C above vi in the component tree, as needed.
We next discuss the case that b = 2. Here (DFS2(u), u, 2) is the last tuple before (DFS1(vi), vi, 1). Note that now u is not an ancestor of vi, as the DFS scan finished scanning the subtree of u before reaching vi, but we claim that u and vi have the same parent in the component tree. For this, we show they have exactly the same ancestors in the set {v1, v2, ..., v } \ {u, vi}. For any ancestor w = u of u, we have that DFS1(w) < DFS1(u) < DFS2(u) < DFS2(w). As (DFS1(vi), vi, 1) is the first tuple after (DFS2(u), u, 2), it must hold that DFS1(w) < DFS1(vi) < DFS2(w), implying that vi is a child of w as needed. Similarly, any ancestor w = vi of vi is also an ancestor of u, as we have DFS1(w) < DFS2(u) < DFS1(vi) < DFS2(vi) < DFS2(w). Hence, the parent of u in the component tree is also the parent of vi in the component tree, as needed.
Lastly, we show that using similar ideas we can also identify the component of a vertex v in T \ F. We create for v the tuple, (DFS1(v), v, 1), and use binary search to find the last tuple smaller or equal to it in the sorted list we computed before, denote it by (DFSb(u), u, b). If b = 1 then v is in
18

the component of u, and else it is in the component of the parent of u (that was computed before). The complexity of the binary search is O(log f ), we next prove correctness. One special case is that v is a root of one of the components in the component tree. In this case, the entry (DFSb(u), u, b) we find is equal to (DFS1(v), v, 1), and u = v is indeed the component of v. Otherwise, v is an internal vertex in its component, and the root of the component is the closest ancestor to v in {v1, ..., v }. If b = 1, then as shown before, u is the closest ancestor to v in the component tree, as needed. If b = 2, then as shown before, u is not an ancestor of v, but has exactly the same ancestors in the component tree. Hence, the root w of the component above u is the root of the component of v, as needed.
Step 2: Computing the sketch values of each component C0 in G. For each component Cj  C0 the algorithm computes SketchG(Cj) using the sketch information of the vertices in V(FT). The basic observation here is the following. Given S  S and Sketch(S), Sketch(S ), it holds that Sketch(S \ S ) = Sketch(S)  Sketch(S ). To compute the sketch values, first, we define for each component a temporary value SketchG(Cj) as follows. Let vj be the highest vertex (closest to the root in T) in the component Cj. For the component of the root r, this is r. For any other component Cj, let (Cj, p(Cj)) be the edge connecting Cj to its parent in the component tree. This edge corresponds to an edge (vj, p(vj))  FT, where v is the highest vertex in Cj. We define SketchG(Cj) = SketchG(V(Tvj )). Since (vj, p(vj))  FT, the sketch information SketchG(Cj) can be obtained from the label of the tree edge (vj, p(vj)). We also know the temporary sketch value of the component of r, as SketchG(Vr) = SketchG(V) is part of the labels of all tree edges (and we assume that FT = ). We next use the temporary sketch values to compute the sketch values of components using the following claim.
Claim 3.15. Let Cj be a component in T \ F. If Cj is a leaf in the component tree, we have SketchG(Cj) = SketchG(Cj). Otherwise, let D = {D1, ..., Dt} be the children of Cj in the component tree and let Sketch (D) = 1itSketchG(Di), then SketchG(Cj) = SketchG(Cj)  Sketch (D).
Proof. It holds that SketchG(Cj) = vCj SketchG(v). By definition, SketchG(Cj) = SketchG(V(Tvj )) = vV(Tvj )SketchG(v) is the XOR of sketches of all vertices in the subtree of vj. As vj is the highest vertex in Cj, if Cj is a leaf component in the component tree, then the vertices in Cj are exactly the vertices in Tvj, and the claim follows. Otherwise, the vertices in Cj are all vertices in Tvj that are not contained in any component below Cj. Hence, to compute the value SketchG(Cj), we should subtract from SketchG(V(Tvj )) the sketch values of vertices in components below Cj. Let D1, . . . , Dt be the children of Cj in the component tree, and let u1, . . . , ut be the highest vertices in the components D1, . . . , Dt, respectively. Any vertex that is in some component below Cj is in exactly one of the subtrees Tu1, . . . , Tut . Hence the sketch value of vertices in components below Cj equals 1itSketchG(V(Tui )) = 1itSketchG(Di) = Sketch (D). To conclude, we get SketchG(Cj) = SketchG(V(Tvj ))  Sketch (D) = SketchG(Cj)  SketchG(D), as needed.
To conclude, from the values SketchG(Cj), we can easily compute the values SketchG(Cj). The complexity is O( f ), as for each component, the sketch Sketch (Cj) participates in two computations, and we have at most O( f ) components and the sketches have poly-logarithmic size.
Step 3: Computing the sketch values of each component C0 in G \ F. For each faulty edge e  F (both tree and non-tree edges), our goal is to subtract the sketch information of e from the corresponding components of the endpoint of e. The step does not require the label information of the edges, and it would be sufficient to know only the seed Sh that determines the sampling of edges into the sketches, and the extended identifier of the failing edges. Since FT = , the algorithm holds the seed Sh (from the label of an edge e  FT), and it has the extended identifiers of all edges in F as part of their labels.
19

Using the extended identifier of the faulty edge e = (u, v), one can determine in O(log f ) time the components in C0 to which its endpoints belong, from Claim 3.14. Using the identifier EID(e) and the seed Sh, one can determine all the indices of the sketch to which the edge e was sampled in O(1) time using Fact A.2. Letting Cu, Cv be the components of u and v in T \ F, respectively. If Cu = Cv, then the values SketchG(Cu), SketchG(Cv) are updated by XORing them with the matrix that contains the extended identifier EID(e) in the relevant positions. The complexity is poly-logarithmic, as the matrix has poly-logarithmic size. In the case that Cu = Cv, as e is an internal edge in the component, it is not part of SketchG(Cu), and there is no need to update the value. Overall, doing the computation for all edges in F takes O( f ) time. From that point on, all sketches of the components C0 can be treated as sketches that have been computed in G \ F.
Step 4: Simulating the Boruvka algorithm. Finally, our goal is to determine the identifiers of the maximal connected components of s and t of G \ F. The input to this step is the identifiers of the components C0 = {C1, . . . , Ck} in T \ F, along with their sketch information in G \ F. While the algorithm does not have information on the vertices of each component, it knows the component identifier of each vertex in Q.
The algorithm consists of L = O(log n) phases of the Boruvka algorithm. Each phase i  {1, . . . , L} will be given as input a partitioning Ci = {Ci,1, . . . , Ci,ki } of (not necessarily maximal) connected components in G \ F. These components are identified by an O(log n) bit identifier, where for each vertex in Q, the algorithm receives its unique component identifier in Ci. In addition, the algorithm receives the sketch information of the components Ci in G \ F. The output of the phase is a partitioning Ci+1, along with their sketch information in G \ F and the identifiers of the components for each vertex in U. A component Ci,j  Ci is growable if it has at least one non-faulty outgoing edge to a vertex in V \ Ci,j. That is, the component is growable if it is strictly contained in some maximal connected component in G \ F. Letting Ni denote the number of growable components in Ci, the output partitioning Ci+1 of the ith step guarantees that Ni+1  Ni/2 w.h.p. To obtain outgoings edges from the growable components in Ci, the algorithm uses the ith basic-unit sketch Sketchi(Ci,j) of each Ci,j  Ci. By Lemma 3.13, from every growable component in Ci, we get one outgoing edge e = (x, y) with constant probability. Using the extended edge identifier of e the algorithm can also detect the component Ci,j to which the second endpoint, say y, of e belongs using Claim 3.14. That label allows us to compute the component of y in the initial partitioning T \ F, i.e., the component C0,q of y in C0. Thus y belongs to the unique component Ci,j  Ci that contains C0,q.
As noted in prior works [AGM12, KKM13, DP16], it is important to use fresh randomness (i.e., independent sketch information) in each of the Boruvka phases. The reason is that the cut query, namely, asking for a cut edge between S and V \ S, should not be correlated with the randomness of the sketches. Note that indeed the components of Ci are correlated with the randomness of the first (i - 1) basic sketch units of the vertices. Thus, in phase i the algorithm uses the ith basic sketch units of the vertices (which are independent of the other sketch units) to determine the outgoing edges of the components in Ci.
The algorithm then computes the updated sketches of the merged components. This is done by XORing over the sketches of the components in Ci that got merged into a single component in Ci+1. In expectation, the number of growable components is reduced by factor 2 in each phase. Thus after O(log n) phases, the expected number of growable components is at most 1/n5, and using Markov inequality, we conclude that w.h.p there are no growable components. The final partitioning CL corresponds w.h.p to the maximal connected components in G \ F. The pair s and t are connected in G \ F only if the components Cs, Ct of s, t respectively in T \ F are connected in the final component decomposition. We next show that the complexity of the algorithm is O( f ). This is also the decoding time of the whole algorithm, as all steps take O( f ) time, as discussed above.
20

Claim 3.16. The complexity of step 4 is O( f ).
Proof. The algorithm has O(log n) phases, where in each phase the following is computed. First, given the sketch values of the current components we identify outgoing edges from the components. This takes O(1) time per component from Lemma 3.13, and O( f ) time for all components, as we have at most f + 1 components. Next, for each outgoing edge we identify the components it connects using its ancestry labels, this takes O(1) time per edge using Claim 3.14. Then, we merge components accordingly and compute the sketch values of the new components by XORing the sketch values of merged components. Overall this takes O( f ) time, as we have at most O( f ) merges. In more detail, we can use a union-find data structure to implement the merges, where every time we merge components we compute the sketch value of the new component. We also maintain for each original component in T \ F its current component in phase i, this allows us to learn the current components connected by an outgoing edge e. This information can be maintained as follows. Let C be a component in T \ F, and assume we know the component Ci,j it belongs to at the beginning of phase i. After the merges of phase i, Ci,j joins some component Ci+1,j of phase i + 1. We can use the find operation to identify the id of the new component. Overall, we have O( f ) merges and O( f ) find operations to identify for each component C  T \ F, the corresponding component Ci+1,j it belongs to, hence the complexity is bounded by O( f ).
Finally, we show that the decoding algorithm can be slightly modified to output a compressed encoding of an s-t path in G \ F, using O( f log n) bits. This encoding is represented by an s-t path P that has two type of edges, appearing in an alternate manner on P: G-edges and edges e = (u, v) such that the u-v tree path is intact in T \ F. See Figure 3.
Lemma 3.17. Consider a triplet s, t, F such that s and t are connected in G \ F. The decoding algorithm can also output a set of at most f recovery edges R such (T \ F)  R is a spanning tree. In addition, it outputs a labeled s-t path P of length O( f ) that provides a succinct description of the s-t path. The edges of P are labeled by 0 and 1, where 0-labeled edges correspond to G-edges and 1-labeled edges e = (x, y) correspond to x-y paths in T \ F.
Proof. Let Cs, Ct be the components of s and t in the initial partitioning C0. In Step 4 of the decoding algorithm, the Boruvka algorithm is simulated up to the point that Cs and Ct are connected. Therefore, the algorithm has computed a path P that connects the components Cs and Ct. Each vertex on that path corresponds to a component in C0, and each edge corresponds to an outgoing edge (discovered using the sketch information). Since C0 has at most f + 1 components, |P|  f + 1. Each such edge e  P corresponds to an edge in G. Let e1 = (x1, y1), . . . , ek = (xk, yk) be the G-edges corresponding to the edges of P ordered from Cs to Ct. Letting y0 = s and xk+1 = t, we get that yi and xi+1 belong to the same component in C0, for every i  {0, . . . , k}. The labeled path is given by P = [s, x1, y1, x2, y2, . . . yk, t] where the edges (yi, xi+1) are labeled 1 and the edges (xi, yi) are labeled 0. Each 0-labeled edge is a real edge in G, and each 1-labeled edge (xi, yi) corresponds to a tree path (xi, yi) in T \ F.
4 Fault-Tolerant Approximate Distance Labels
Given integer parameters f , k  1, an ( f , k) FT approximate distance labeling scheme assigns labels DistLabel : V  E  {0, 1}q such that given the labels of s, t and a subset F  E, |F|  f , there exists a decoding algorithm that outputs a distance estimate G\F(s, t) satisfying:
distG\F(s, t)  G\F(s, t)  k · distG\F(s, t) .
21



1

2

3 3

4

2

5 4

 1



Figure 3: Shown is a tree T with faulty edges e1, . . . , e4. The s-t path in G \ F is represented by the path P = [s, v1]  (v1, v2)  [v2, v3]  (v3, r)  [r, v4]  (v4, v5)  [v5, t]. The recovery edges (v1, v2), (v3, r) and (v4, v5) are shown in dashed lines.

We next show that there is an efficient transformation from any FT connectivity labeling scheme into an FT approximate distance labeling scheme. This transformation increases the label size by a multiplicative factor of O(n1/k). This technique was first introduced by [CLPR12] in the context of distance sensitivity oracles, and it is based on the notion of tree covers.
Definition 4.1 (Tree Covers). Let G = (V, E) be an undirected graph with edge weights , and let , k be two integers. Define B(v) = {u  V | distG(u, v)  }. A tree cover TC(G, , , k) is a collection of rooted trees T = {T1, . . . , T } with root r(T) for every T  T such that:
1. For every vertex v there exists a tree T  T such that B(v)  T. 2. The radius of each tree T is at most (2k - 1) · . 3. Each vertex participates in (k · n1/k) trees.
Let |TC(G, , , k)| denote the number of trees in the tree cover TC(G, , , k).
Proposition 4.2. [Pel00] For any n-vertex graph G = (V, E, ), and any parameters , k, one can compute tree covers TC(G, , , k) in time O(|E(G)| · n1/k).
Lemma 4.3 (From Connectivity Labels to Approximate Distance Labels). Let G = (V, E, ) be a weighted undirected n-vertex graph where (e)  [1, W], and let ConnLabel : V  E  {0, 1}s be an f -FT connectivity labeling scheme for G with decoding time t. Then for every integer k  1, there is an ( f , (8k - 2)(|F| + 1)) FT approximate distance labeling scheme DistLabel : V  E  {0, 1}q for G, where q = O(s · k · n1/k · log(nW)), and with decoding time O(t log (nW)).

The labeling algorithm. For every vertex u, the label DistLabel(u) consists of K = log(nW) sub-
labels of FT connectivity labels in distinct subgraphs of G defined as follows. The ith sub-label
addresses all distances that are at most 2i in G. Let Hi be set of heavy edges in G of weight at least 2i, and define the ith tree-cover by

TCi = TC(G \ Hi, , 2i, k) .

(4)

For each tree Ti,j  TCi, the algorithm applies the FT connectivity scheme on the graph Gi,j = G[V(Ti,j)]. For every vertex u and i  {1, . . . , K}, let i(u) be an index of a tree in TCi that covers the 2i-ball of u. I.e., B2i (v)  Ti,i(u). The label of every u  V is then given by:

DistLabel(u) = { ConnLabelGi,j,Ti,j (u), i, j | i  [1, K], j  {1, . . . , |TCi|}, u  Gi,j} {i(u) | i  [1, K]} .

22

Similarly, the label of each edge e  G contains the FT connectivity label of e in each of the instances (Gi,j, Ti,j):
DistLabel(e) = { ConnLabelGi,j,Ti,j (e), i, j | i  [1, K], j  {1, . . . , |TCi|}, e  Gi,j}.
The time for assigning the labels is the time for constructing the tree cover and computing the indexes i(v), and the time for assigning the connectivity labels on each one of the trees. The first part requires polynomial time. The second depends on the connectivity labels. For example, using our scheme from Section 3.2 the time complexity of the second part is O(mn1/k), as it is linear in the total number of vertices and edges in the trees.
The decoding algorithm. Consider the query s, t, F . The algorithm has K phases, in each phase i  [1, K] the decoding algorithm of the FT connectivity labels is applied on the instance Gi,i(s), Ti,i(s) where Gi,i(s) contains the 2i ball of s in G. If t / Gi,i(s), the phase i ends and we continue to phase i + 1. Otherwise, the algorithm decides if s and t are connected in Gi,i(s) \ F in the following manner. Let Fi = F  Gi,i(s), this subset of edges can be obtained from the labels of the F edges. Since the labels of s, t and Fi contain the FT connectivity labels in the subgraph Gi,i(s) and the tree Ti,i(s), the algorithm can apply the decoding algorithm of the FT connectivity scheme. If s and t are indeed connected in Gi,i(s) \ Fi, the algorithm returns the estimate G\F(s, t) = (4k - 1) · (|F| + 1) · 2i. Otherwise, it proceeds to the next phase.
Overall, let i be the minimum index in {1, . . . , K} for which s and t are connected in the subgraph Gi,i(s) \ F. Then the decoding algorithm returns the distance estimate G\F(s, t) = (4k - 1) · (|F| + 1) · 2i. If no such i exists, the decoding algorithm returns G\F(s, t) = , which implies that s and t are not connected in G \ F.
The decoding time is O(t log (nW)), where t is the decoding time of the connectivity labels, as we use the decoding algorithm of the connectivity labels K times on the graphs Gi,i(s). To obtain this, we need to make sure that given the labels of s, t, F we can easily find their connectivity label in the graph Gi,i(s) if exist. This can be easily done if we store the connectivity labels in a sorted order.
Analysis. We now analyze the construction, and start by bounding the size of the labels. By the properties of the tree-cover in Def. 4.1, each vertex appears in O(K · k · n1/k) subgraphs. Thus, DistLabel(u)consists of O(K · kn1/k) FT connectivity labels and the label size is bounded by O(K · kn1/k · s) bits, as desired. Next, we show correctness. By the correctness of the FT connectivity labeling scheme, it is sufficient to show the following. Let Ps,t,F be an s-t shortest path in G \ F of length (2i-1, 2i]. By the properties of the tree cover, there is a tree Ti,i(s)  TCi that contains all the vertices of the path Ps,t,F. Therefore, we have that s and t are connected in Gi,i(s) \ F. Since the labels of s, t and Fi = F  Gi,i(s) contain the FT connectivity labels in Gi,i(s), we get that the distance estimate returned by the algorithm satisfies that
distG\F(s, t)  G\F(s, t)  (4k - 1)(|F| + 1) · 2i  (8k - 2)(|F| + 1) · distG\F(s, t) .
To see this, let j  i be the first index such that s and t are connected in Gj,j(s) \ F. The algorithm returns the estimate (4k - 1)(|F| + 1) · 2j  (4k - 1)(|F| + 1) · 2i = (8k - 2)(|F| + 1) · 2i-1  (8k - 2)(|F| + 1) · distG\F(s, t). To prove the left inequality, we show that if s and t are connected in Gj,j(s) \ F, there is indeed a path between them in G \ F of length at most G\F(s, t) = (4k - 1)(|F| + 1) · 2j. First, from the tree cover properties, the radius of Tj,j(s) is at most (2k - 1)2j, implying that any two vertices in Tj,j(s) are at distance at most (4k - 2) · 2j from each other. Now the graph Tj,j(s) \ F has at most |F| + 1 connected components. Since Gj,j(s) \ F is connected, it implies that there is a path
23

between s and t in Gj,j(s) \ F. This path traverses at most |F| + 1 different components in Tj,j(s) \ F, and at most |F| edges connecting them, each one of weight at most 2j. As the diameter of each component is bounded by (4k - 2) · 2j, the length of the path is at most (4k - 2) · 2j · (|F| + 1) + 2j · |F|  (4k - 1) · 2j · (|F| + 1), as needed.

5 Compact Routing Schemes

In this section, we explain how to use our FT distance labels to provide compact and low stretch routing schemes. This is the first scheme to provide an almost tight tradeoff between the space and the multiplicative stretch, for a constant number of faults f = O(1). Throughout this section, tree routing operations are performed by using the tree routing scheme of Thorup and Zwick [TZ01].
Fact 5.1. [Routing on Trees][TZ01] For every n-vertex tree T, there exists a routing scheme that assigns each vertex v  V(T) a label LT(v) of (1 + o(1)) log n bits. Given the label of a source vertex and the label of a destination, it is possible to compute, in constant time, the port number of the edge from the source that heads in the direction of the destination.

We slightly modify the connectivity label of the edges and vertices by augmenting them with routing information. First, we augment the extended identifier of an edge (see Eq. (1)) with port information and tree routing information, by having:

EIDT(e) = [UID(e), ID(u), ID(v), ANCT(u), ANCT(v), port(u, v), port(v, u), LT(u), LT(v)] , (5)

where port(u, v) is the port number of the edge (u, v) for u, and the labels LT(u), LT(v) are the tree routing labels taken from Fact 5.1. We then slightly modify the connectivity label of Eq. (3) to include also the tree label LT(u)from Fact 5.1, by defining

ConnLabelG,T(u) = ANCT(u), ID(u), LT(u) .

(6)

Throughout this section, when applying the connectivity labels from Section 3.2 on a graph G

with a spanning tree T, we use these modified extended identifiers and labels. This will also be

the basis for the application of the distance labels of Section 4. Similarly to the distance labels of

Section 4, we will apply the connectivity labels with respect to the different trees of the tree cover

as discussed in Section 4. Let Ti,j  TCi, recall that Gi,j = G[V(Ti,j)] and that T =

K i=1

TCi

for

K = O(log(nW)).

Lemma 5.2. Consider a triplet s, t, F such that s, t, F  Gi,j. Given the connectivity labels {ConnLabelGi,j,Ti,j (w)}wF{s,t}, we can determine w.h.p if s and t are connected
in Gi,j \ F. If they are connected, we can output a labeled s-t path P of length O( f ) that provides a succinct description of the s-t path in Gi,j \ F. The edges of P are labeled by 0 and 1, where 0-labeled edges correspond to Gi,j-edges and 1-labeled edges e = (x, y) correspond to x-y paths in Ti,j \ F. For each Gi,j-edge, the succinct path description has the port information of the edge, and for each x - y path, the description has the tree routing labels LTi,j (x), LTi,j (y). The length of the s-t path encoded by P is bounded by (4k - 1)(|F| + 1) · 2i.
Proof. The proof follows the proof of Lemma 3.17. Using {ConnLabelGi,j,Ti,j (w)}wF{s,t}, the decoding algorithm of Section 3.2 determines if s and t are connected in Gi,j \ F. If they are connected, then from Lemma 3.17, we get a succinct description of the s-t path in Gi,j \ F. We next show that the algorithm indeed has the relevant port and tree routing information. For this note that all the vertices in the path P obtained by Lemma 3.17 are either s and t or endpoints of the |F| recovery edges found in the algorithm. The labels of s and t contain the tree routing information LTi,j (s)

24

and LTi,j (t), and when the algorithm finds a recovery edge, it learns about its extended id EIDTi,j (e) that has the port information and tree routing information of its endpoints. Any Gi,j-edge in P is a recovery edge, hence the algorithm has its port information, and for any x-y path in Ti,j \ F, the algorithm has the tree routing labels LTi,j (x), LTi,j (y), as needed. The stretch analysis follows the stretch analysis in Section 4. It is based on the fact that P has as most |F| + 1 subpaths in Ti,j \ F, each of length at most (4k - 2)2i, and at most |F| recovery edges of weight at most 2i.
5.1 Forbidden Set Routing (Faulty Edges are Known)
We start by describing the routing scheme in the forbidden set setting, where the faulty edges F are known to the source vertex s. We show the following.
Theorem 5.3. [Forbidden-Set Routing] For every integers k, f , there exists an f -sensitive compact routing scheme that given a message M at the source vertex s, a label of the destination t, and labels of at most f forbidden edges F (known to s), routes M from s to t in a distributed manner over a path of length at most (8k - 2)(|F| + 1) · distG\F(s, t). The table size of each vertex is bounded by O(n1/k log (nW)). The header size of the messages is bounded by O( f ) bits. The labels of vertices and edges have size O(n1/k log(nW)).
Proof. The algorithm is based on the distance labels from Section 4 using the slightly modified connectivity labels (augmented with port and tree roting information). Recall that the distance labels are based on applying fault-tolerant connectivity labels on different graphs Gi,j, we use the slightly modified connectivity labels and the corresponding distance labels. The routing table of each vertex u consists of its distance label DistLabel(u). The label of an edge e is DistLabel(e). Each distance label has O(n1/k log(nW)) bits.
In the routing algorithm, the vertex s is given the label DistLabel(t), and the labels {DistLabel(e)}eF, and it needs to route a message to t in the graph G \ F. Recall that the algorithm from Section 4 works in K phases, where in phase i it checks if s and t are connected in the graph Gi,i(s) \ F that contains the 2i-ball around s. Let i be the first iteration where s and t are connected in Gi,i(s) \ F according to the algorithm, and denote Gi = Gi,i(s), Ti = Ti,i(s), and let Fi = F  Gi. The algorithm can also give a succinct description of an s-t path in Gi \ Fi following Lemma 5.2. For this, note that we indeed have all the required information. The distance labels of edges in F in particular contain the labels {ConnLabelGi,Ti (e)}eFi , and we can also tell which edges of F are in Gi from the labels. Also, the labels of s, t contain the information IDTi (s), IDTi (t) if they are both in Ti (otherwise, they are not connected in level i).
The path P as described in Lemma 5.2 is composed of O(|F|) parts, where segment (x, y) in the path corresponds either to an edge in Gi or to a tree path in Ti \ F, it also has the relevant port and tree routing information. Our goal is to route a message according to this path. For this we add to the header of the message the description of P, the indexes (i, i(s)) of the tree we explore and an index 1  q  2|F| + 1 that represents the segment of P we currently explore, initially q = 1. Overall, the header size is O( f ). To route a message according to the path, we work as follows. The header specifies the current segment in P. If the current segment corresponds to an edge (x, y)  G, then x uses the port information to route the message to y and increases the index q. Otherwise, the current segment represents a tree path (x, y)  Ti and a vertex u in this path uses its routing label in Ti and the routing label of y in Ti (that is part of the header) to route the message towards y. When the message reaches y, it increases the index q. This completes the description of the routing process. The length of the path described is at most (8k - 2)(|F| + 1) · distG\F(s, t), as shown in Section 4.
25

5.2 Fault-Tolerant Routing (Faulty Edges are Unknown)

We now consider the more involved setting where the set of failed edges F are unknown to s. In this

case, an edge (u, v)  F is detected only when the message arrives, during the routing procedure,

to one of the endpoints of e. Note that the routing scheme should, by definition, be prepared to

any set of faulty edges F. However, the space bound of our scheme is required to be bounded by O( f n1+1/k), which is possibly much smaller than the number of graph edges m. This in particular

implies that we cannot store the FT distance labels of all the graph edges. Nevertheless, we show

that it is sufficient to explicitly store the labeling information for the tree edges in T =

K i=1

TCi

.

The required information for the failed non-tree edges would be revealed throughout the process, by

applying the decoding algorithm of Lemma 5.2. Our routing scheme eventually routes the message

along the s-t path encoded by the FT distance labels of s, t and F. However, since the labels of F are

unknown in advance, the routing scheme will detect these edges in a trail and error fashion which

induces an extra factor of f in the final multiplicative stretch. This extra f factor is also shown to be

essential, in the end of the section. We proceed by describing the routing tables.

The routing labels and tables. For ease of presentation, we first describe a solution with a multi-

plicative stretch of O(k f 2), and global space of O( f K · n1+1/k), but the individual tables of some of

the vertices might be large. We later on improve the space of each table to O( f 3K · n1/k) bits.

Recall that T =

K i

TCi,

for

K

=

O(log(nW))

is

a

collection

of

tree

covers

in

all

K

=

log(nW )

distance scales, see Eq. (4). For every vertex v, let degT (v) = Ti,jT deg(u, Ti,j) be the sum of

degrees of u in the collection of trees T . Recall that Gi,j = G[V(Ti,j)]. For the routing we apply the

FT connectivity labels on the graphs Gi,j, similarly to Section 4.

Routing labels. The routing process uses at most f = f + 1 independent applications of ran-
domized FT connectivity labels from Section 3.2, applied on each one of the graphs Gi,j. In more details, when we apply the labeling scheme on the graph Gi,j with spanning tree Ti,j, we use f independent random seeds Sh to determine the randomness of the sketches. However, the seed SID used to determine the extended ids of edges in Gi,j is fixed in the f applications, hence the extended identifiers of the edges (see Eq. (1)) are fixed in all the f applications, and we only use fresh randomness to compute the sketch information using f independent seeds Sh1, . . . , Shf . This process is done independently on each one of the graphs Gi,j.
Denote the output connectivity labels obtained by the th application of the scheme (using Sh) on the graph Gi,j by ConnLabelGi,j,Ti,j (w) for every w  E(Gi,j)  V(Gi,j). For every edge e  Gi,j, define its Ti,j routing label by

Lroute,i,j(e) = (ConnLabel1Gi,j,Ti,j (e), . . . , ConnLabelGf i,j,Ti,j (e)), for e  Ti,j

(7)

EIDTi,j (e),

e  Gi,j \ E(Ti,j) .

Every Lroute,i,j(e) label has O( f log3 n) bits. In our routing algorithms, the Ti,j routing labels of the discovered faulty edges will be added to the header for the message in order to guide the routing
process. We now turn to define the routing labels of vertices. Recall that for a vertex v and index 1  i  K, we denote by i(v) an index such that the 2i-ball around v is contained in Gi,i(v). The routing label Lroute(v) of v For every vertex v, the routing label of v is given by

Lroute(v) = {(i(v), ConnLabel1Gi,i(v),Ti,i(v) (v)|i  [1, K]} .

(8)

Note that by definition, the connectivity labels of the vertices are the same in all f applications of the labeling algorithm, and therefore it is sufficient to include only one of these copies in the label.

26

The size of the label is O(K log n) = O(log n log nW).

Routing tables. The routing table Rroute(v) of a vertex v has the following information for every tree Ti,j such that v  Ti,j:

Rroute,i,j(v) = {Lroute,i,j(e), e  E(v, Ti,j)}  {ConnLabel1Gi,j,Ti,j (v)} ,

(9)

where E(v, Ti,j) is the set of edges incident to v in the tree Ti,j. The final routing table is given by Rroute(v) = {Rroute,i,j(v), (i, j) | Ti,j  T , v  Ti,j}.
Since the connectivity labels are of size O( f ), and as each v appears in degT (v) trees, the size of the table is O( f degT (v)). Since the total number of tree edges in T is bounded by O(K · n1+1/k), this provides a global space bound of O( f K · n1+1/k) bits.

The routing algorithm. In the routing algorithm, the source vertex s initially gets the routing label Lroute(t) (Eq. (8)) of the destination t and its own routing table, Rroute(s), and its goal is to find the smallest radius graph Gi,j such that s and t are connected in Gi,j \ F, and use it for routing. As the set F is not known in advance, the algorithm works in K = O(log nW) phases, where in phase i it tries to route a message in the graph Gi,i(t) (which contains the entire 2i-radius ball of t). If s and t are connected in Gi,i(t) \ F the algorithm succeeds, and otherwise we proceed to the next phase, corresponding to the distance scale of 2i+1. We next describe the algorithm for a single phase i, we denote Gi = Gi,i(t), Ti = Ti,i(t). Note that s can deduce the index i(t) from the routing label of t, and it can check if s  Ti using its routing table. If s  Ti, we proceed to the next phase.
If s  Ti, the routing procedure for phase i has at most |F| + 1 iterations. We maintain the following invariant in the beginning of each iteration  {1, . . . , |F| + 1}: (i) the iteration starts at vertex s, (ii) the algorithm has already detected a subset of - 1 faulty edges F  F, and (iii) the header contains the labels ConnLabelGi,Ti (e) of all the edges e  F . Each iteration  |F| + 1 terminates either at the destination vertex t, or at the source vertex s. In addition, w.h.p., if s and t are connected in Gi \ F, iteration |F| + 1 terminates at t. The invariant holds vacuously for iteration 1.
We now describe the th iteration (of the ith phase) of the routing procedure given the invariant. The source vertex s considers the th copy of the FT connectivity labels, ConnLabelGi,Ti (e) for every e  F . Using the routing labels of the edges, that are part of the header, the routing label Lroute(t) (of Eq. (8)) and the routing table Rroute(s), s can apply the decoding algorithm of Lemma 5.2 to determine if s and t are connected in Gi \ F . If the answer is no, the algorithm proceeds to the next phase i + 1. Otherwise, by applying the decoding algorithm of Lemma 5.2, it computes the succinct path P . The path P encodes an s-t path in Gi \ F , that includes the relevant port and tree routing information of its vertices. The header of the message H then contains
H = P , i, i(t), {Lroute,i,i(t)(e)}eF , q ,
where q = O( f ) is an index indicating the current segment of P we explore. Note that the header H contains the f copies of connectivity labels of the F edges, and not only the th copy. The size of the header is O( f 2), as the description of the path has size O( f ), and additionally we have at most f faulty edges with labels of size O( f ). Let P be the G-path encoded by the path P . The algorithm then routes the message along P in the same manner as in Sec. 5.1. In the case where P  F = , the iteration successfully terminates at the destination vertex t. From now on, we consider the case that P contains at least one faulty edge.
Let e = (u, v) be the first edge (closest to s) on the path P that belongs to F. Since P  F = , it holds that e  F \ F . Without loss of generality, assume that u is closer to s on P . Thus the

27

faulty edge e is detected upon arriving to the vertex u. In the case where e is a non-tree edge, then it must be a G-edge on P . Since this path has the extended ids EIDTi (e) of its G-edges, and since the connectivity label of a non-tree edge e is its extended identifier EIDTi (e) in all the f applications of the scheme on Gi7, u can add Lroute,i,i(t)(e) = EIDTi (e) to the header of the message. Assume now that e is a tree edge in Ti. The vertex u then adds the routing label Lroute,i,i(t)(e) to the header of the message, as e is a tree edge adjacent to u it has this information in its routing table. Finally, it
marks the header with the sign R, indicating that the message should now be routed in the reverse
direction, until arriving s again. This completes the description of iteration . It is easy to see that the invariant is maintained. If s and t are connected in Gi \ F, after at most f iterations all faulty edges are detected. In the last iteration, the path computed based on the labeling information is
free from faulty edges, and the routing is completed (in the same manner as in Sec. 5.1) at the
destination t. We next bound the multiplicative stretch of the routing.

Claim 5.4. Fix a set of faulty edges F, and let s, t be vertices that are connected in G \ F. Then, the message is routed from s to t within 32k(|F| + 1)2 · distG\F(s, t) steps, w.h.p.
Proof. First note that since each iteration and each graph Gi uses an independent set of FT connectivity labels, then in each phase and each iteration the decoding algorithm succeeds w.h.p. and outputs an s-t path P if exists.
Assume that distG\F(s, t)  (2i-1, 2i]. Then, s and t are connected in Gi \ F, as Ti = Ti,i(t) contains the 2i-ball around t. We show that the algorithm terminates at t in phase i or before it, and that in any phase j  i, the routing algorithm traverses a path of length at most 2(4k - 1)(|F| + 1)2 · 2j.
Let j  i. In the 'th iteration of phase j, the algorithm first checks if s and t are connected in Gj \ F , where F is the set of currently detected faults. If the answer is no, the algorithm proceeds
to the next phase. Otherwise, it tries to route a message from s to t on the path encoded by P . The length of the path is bounded by (4k - 1)(|F| + 1) · 2j from Lemma 5.2. The algorithm either succeeds, or finds a faulty edge on the way in which case it returns to s by traversing the same path on the reverse direction. Overall, the algorithm traverses a path of length at most 2(4k - 1)(|F| + 1) · 2j, in this iteration. In all |F| + 1 iterations of phase j, the length of the path explored is at most 2(4k - 1)(|F| + 1)2 · 2j. Summing over all iterations j  i, the stretch is bounded by

i

i

 2(4k - 1)(|F| + 1)2 · 2j = 2(4k - 1)(|F| + 1)2  2j  2i+2(4k - 1)(|F| + 1)2  32k(|F| + 1)2distG\F(s, t).

j=1

j=1

The last inequality uses the fact that 2i-1  distG\F(s, t). In the i'th phase, since s and t are connected in Gi \ F, then for any F  F, s and t are connected
in Gi \ F , hence the algorithm always finds a path P . Hence, it either succeeds in routing the message to t in one of the iterations (or one of the previous phases), or learns about all the failures
F. In the latter case, in iteration |F| + 1 it learns about a failure-free path P|F|+1, and the routing terminates at t. This completes the proof.

To conclude, we have the following.

Theorem 5.5. For every integers k, f , there exists an f -FT compact routing scheme that given a message M at the source vertex s and a label Lroute(t) of the destination t, in the presence of at most f faulty edges F (unknown to s) routes M from s to t in a distributed manner over a path of length at most 32k(|F| + 1)2 · distG\F(s, t). The global table size is O( f · n1+1/k log (nW)). The header size of the messages is bounded by O( f 2) bits, and the label size of vertices is O(log (nW) log n).
7This is because we use the same random seed SID in all these applications.

28

Improving the size of the routing tables. So far, we have described a routing scheme that consumes a total space of O( f · n1+1/k log(nW)) bits, and multiplicative stretch 32(|F| + 1)2k. We now explain the required modifications needed to providing routing tables with O( f 3 · n1/k) bits per vertex. The most space consuming information for a vertex u is the connectivity labeling information of the edges incident to u in each of the trees Ti,j  T . As the degree of u in some of the trees might be (n), it leads to tables of possible super-linear size. To reduce the space of the individual tables, we apply a load balancing idea which distributes the labeling information incident to high-degree vertices among their neighbors.
Instead of storing the labeling information of e = (u, v) at the routing tables of u and v, we define for every tree T  T and an edge e = (u, v)  T, a subset T(e) of vertices that store the connectivity labeling information of e in T. We will make sure that the information on some vertex in T(e) can be easily extracted in the routing procedure upon arriving one of its endpoints. In addition, we will make sure that each vertex stores the information only for a small number of edges in each of its trees. Consider an edge e = (u, v) in a tree T, and assume, without loss of generality, that u is the parent of v in the tree T. In the case where deg(u, T)  f + 1, we simply let T(e) = {u, v}. That is, the label of e is stored by both endpoints of e (as before). The interesting case is where deg(u, T)  f + 2, in which case, u might not be able to store the label of e, and will be assisted by its other children as follows. Let Child(u, T) = [v1, . . . , v ] be the lexicographically ordered list of the children of u in T. The algorithm partitions Child(u, T) into consecutive blocks of size f + 1 (the last block might have 2 f + 1 vertices). Letting [vq,1, . . . , vq, f +1]  Child(u, T) be the block containing v, define
T(e) = {vq,1, . . . , vq, f +1} .
Note that in particular, v  T(e). Thus, the label of e is stored by v and  [ f , 2 f - 1] additional children of u in T.
We then modify the tree labels from Fact 5.1 to contain the port information of T(e). In order to do that, we will be using the more relaxed variant of Fact 5.1, we have:
Claim 5.6. For every n-vertex tree T, there exists a (deterministic) routing scheme that assigns each vertex v  V(T) a label LT(v) of O( f log2 n) bits and table RT(v) of O( f log n) bits. Given the label LT(t) of the target t and the routing table RT(u), the vertex u can compute in O( f ) time: (i) the port number of the edge e = (u, v) on its tree path to t, and (ii) the port numbers of the neighbors of u in the set T(e = (u, v)).
Proof. The proof follows by slightly modifying the simpler scheme of Fact 5.1 by [TZ01]. Specifically, we will be using the routing scheme based on heavy-light tree decomposition. This scheme assigns each vertex v labels of O(log2 n) bits that contain the port information of the at most O(log n) light edges on the root to v path in T. The vertices are enumerated in DFS ordering, and the label of each vertex contains its DFS range, and the specification of all light edges on its path in T from the root, along with a port information of these edges. The routing table of v stores its DFS range, the port number of the (unique) heavy child of v and also the port to its parent. In our modification, we augment the label of each vertex u with the port information of T(e ) for every light edge e appearing on the root to u path in T. Since there are O(log n) such light edges, the total label information is encoded in O( f log2 n) bits. The routing table RT(u) is augmented with the port information for the set T(e ), where e is the (unique) heavy child of u. The routing scheme is then exactly as described at [TZ01], only that in addition to the port of the next-hop e = (u, v), we also obtain the port information of T(e). This increases the labels and tables in the scheme of [TZ01] by a factor of O( f ), the claim follows.
Since the modified claim of tree routing defines now both tree routing labels and tables, we employ the following modifications. The extended identifier EIDT(e) of an edge e = (u, v) from Eq.
29

(5) contains the modified tree labels and thus has O( f log2 n) bits. The routing labels of Eq. (7) are

defined in the same manner only using the modified extended edge identifiers. The routing label

of each edge has O( f 2) bits, and routing label of every vertex has O( f ) bits. We are now ready to

describe the more succinct routing tables of each vertex v. We modify the definition of Eq. (9) by

letting:

Rroute,i,j(v) = {Lroute,i,j(e), e  Ti,j (e)}  ConnLabel1Gi,j,Ti,j (v)  RTi,j (v) ,

thus the routing table Rroute,i,j(v) is augmented the tree routing tables RTi,j (v) of Claim 5.6. In addition, Rroute(v) = {Rroute,i,j(v), (i, j) | Ti,j  T , v  Ti,j} as before. We therefore have:

Claim 5.7. The size of each routing table Rroute(v) is bounded by O( f 3Kn1/k) bits.

Proof. For every tree Ti,j containing v, v stores the routing labels for the tree Ti,j of all edges in the set E (v, Ti,j) = {e  Ti,j | v  Ti,j (e)}. Since each connectivity label of an edge contains the modified
tree labels from Fact 5.6, it has O( f ) bits, and as the routing label for Ti,j contains O( f ) copies of this label, overall each routing label of an edge has O( f 2) bits. Observe that |E (v, Ti,j)| = O( f ) as each vertex stores the label of its parent in the tree, O( f ) child edges, and O( f ) child edges of its parent in the tree. Since each v participates in O(Kn1/k) trees, overall its routing table has O( f 3Kn1/k) bits,
as required.

It remains to explain the required modifications for the routing procedure over a tree Ti = Ti,i(t). Upon arriving to a vertex u incident to a faulty tree edge e = (u, v) the procedure is as follows. If e is a non-tree edge or if u stores the connectivity label ConnLabelGi,Ti (e)8, then u adds the routing label of the edge to the header, as before. In the remaining case it must hold that e is the edge incident
to u on its tree path to some vertex y. By using the tree routing scheme of Claim 5.6 we have that
given the tree routing labels LTi (u) and LTi (y), the vertex u can also obtain the port numbers of its  [ f , 2 f - 1] children in Ti (e) that store the label ConnLabelGi,Ti (e). Since there are at most f edge faults in the network, and Ti,j (e) contains information on at least f + 1 ports of u's neighbors that contain the label of e, the vertex u can access a non-faulty neighbor, say w, that has the label
information of e. That vertex can then add the labeling information of e to the header of the message,
and the routing algorithm proceeds as before. Since we use the modified tree labels of Claim 5.6, each connectivity label has O( f ) bits, and each routing label of an edge for a tree Ti,j has O( f 2) bits. Since the header stores the routing labels of O( f ) edges, it consists of O( f 3) bits.
The stretch is still bounded by 32k(|F| + 1)2 · distG\F(s, t), as we next explain. Recall that in the proof of Claim 5.4, we bounded the length of the path we explore in one iteration of the algorithm of phase j by 2(4k - 1)(|F| + 1)2j. In the new scheme, when we discover a faulty edge, the vertex
u may send messages to |F| + 1 neighbors until it finds the label of the edge. This adds at most 2(|F| + 1)2j to the stretch, as the weight of edges in the tree of phase j is at most 2j, and we may
send messages in both directions. This gives that the length of the path we explore in one iteration is now at most 2(4k - 1)(|F| + 1)2j + 2(|F| + 1)2j = 8k(|F| + 1)2j. The rest of the analysis proceeds as in the proof of Claim 5.4, and gives that the stretch is bounded by 32k(|F| + 1)2 · distG\F(s, t) (we get the same bound as in the original proof we bounded 2(4k - 1) with 8k during the analysis). We
therefore have:

Theorem 5.8. [Fault-Tolerant Routing] For every integers k, f , there exists an f -sensitive compact routing scheme that given a message M at the source vertex s and a label Lroute(t) of the destination t, in the presence of at most f faulty edges F (unknown to s) routes M from s to t in a distributed manner over a path of length at most 32k(|F| + 1)2 · distG\F(s, t). The routing labels have O( f ) bits, the table size of each vertex is O( f 3 · n1/k log(nW)). The header size of the messages is bounded by O( f 3) bits.
8This covers the cases where v is either a parent of u or else, it is one of the at most f + 1 children of u in Ti.

30

Lower Bound. Finally, we show that the price of not knowing the set of faulty edges F in advance might indeed incur a multiplicative stretch of ( f ).

Proof of Theorem 1.6. Consider a graph that consists of f + 1 vertex disjoint s-t paths, each of length L = (n/ f ). The last edge of each of the paths, except for one, is faulty. Assume that the non-faulty path is chosen uniformly at random. Since the routing scheme is oblivious to the faulty edges, it can discover a faulty edge only upon sending the message to one of the edge endpoints. The expected length of the routing is given by:

f

L +

1

+

2L

·

1-

f

1 +1

·

1 f

+

.

.

.

+

(

f

+

1)

L

·

f -1

i=0

1-

f

1 +1-

i

= ( f L) .

Since the s-t shortest path under these faults is L, the proof follows. See Fig. 4 for an illustration.


= 



Figure 4: Illustration for a stretch lower bound for any FT routing schemes. The s-t pair are connected by f + 1 vertex disjoint paths of length L. Since the faulty-edge is the last edge of the path, the routing requires (L) steps to discover a single faulty edge. As the non-faulty path is chosen uniformly at random, in expectation, the routing requires ( f L) steps.

References

[AAK+06] Serge Abiteboul, Stephen Alstrup, Haim Kaplan, Tova Milo, and Theis Rauhe. Compact labeling scheme for ancestor queries. SIAM Journal on Computing, 35(6):1295­1309, 2006.

[ACG12] Ittai Abraham, Shiri Chechik, and Cyril Gavoille. Fully dynamic approximate distance oracles for planar graphs via forbidden-set distance labels. In Proceedings of the forty-fourth annual ACM symposium on Theory of computing, pages 1199­1218, 2012.

[ACGP16] Ittai Abraham, Shiri Chechik, Cyril Gavoille, and David Peleg. Forbidden-set distance labels for graphs of bounded doubling dimension. ACM Trans. Algorithms, 12(2):22:1­ 22:17, 2016.
[AGM12] Kook Jin Ahn, Sudipto Guha, and Andrew McGregor. Analyzing graph structure via linear measurements. In Proceedings of the twenty-third annual ACM-SIAM symposium on Discrete Algorithms, pages 459­467. SIAM, 2012.

[AR02]

Stephen Alstrup and Theis Rauhe. Improved labeling scheme for ancestor queries. In Proceedings of the thirteenth annual ACM-SIAM symposium on Discrete algorithms (SODA), pages 947­953, 2002.

31

[BCG+21] Aviv Bar-Natan, Panagiotis Charalampopoulos, Pawel Gawrychowski, Shay Mozes, and Oren Weimann. Fault-tolerant distance labeling for planar graphs. SIROCCO 2021, 2021.

[BK08]

Aaron Bernstein and David Karger. Improved distance sensitivity oracles via random sampling. In Proceedings of the nineteenth annual ACM-SIAM symposium on Discrete algorithms, pages 34­43, 2008.

[CCFK17] Shiri Chechik, Sarel Cohen, Amos Fiat, and Haim Kaplan. (1+eps)-approximate fsensitive distance oracles. In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 1479­1496. SIAM, 2017.

[CGKT07] Bruno Courcelle, Cyril Gavoille, M Kante´, and Andrew Twigg. Forbidden-set labeling on graphs. In 2nd Workshop on Locality Preserving Distributed Computing Methods (LOCALITY)", Co-located with PODC, 2007.

[Che11] Shiri Chechik. Fault-tolerant compact routing schemes for general graphs. In International Colloquium on Automata, Languages, and Programming, pages 101­112. Springer, 2011.

[CKT93] Joseph Cheriyan, Ming-Yang Kao, and Ramakrishna Thurimella. Scan-first search and sparse certificates: an improved parallel algorithm for k-vertex connectivity. SIAM Journal on Computing, 22(1):157­174, 1993.

[CLPR10] Shiri Chechik, Michael Langberg, David Peleg, and Liam Roditty. f -sensitivity distance oracles and routing schemes. In Algorithms - ESA 2010, 18th Annual European Symposium, Liverpool, UK, September 6-8, 2010. Proceedings, Part I, pages 84­96, 2010.

[CLPR12] Shiri Chechik, Michael Langberg, David Peleg, and Liam Roditty. F-sensitivity distance oracles and routing schemes. Algorithmica, 63(4):861­882, 2012.

[CT07]

Bruno Courcelle and Andrew Twigg. Compact forbidden-set routing. In STACS 2007, 24th Annual Symposium on Theoretical Aspects of Computer Science, Aachen, Germany, February 22-24, 2007, Proceedings, pages 37­48, 2007.

[DHSS84] Danny Dolev, Joe Halpern, Barbara Simons, and Ray Strong. A new look at fault tolerant network routing. In Proceedings of the sixteenth annual ACM symposium on Theory of computing, pages 526­535, 1984.

[DP09]

Ran Duan and Seth Pettie. Dual-failure distance and connectivity oracles. In Proceedings of the twentieth annual ACM-SIAM symposium on Discrete algorithms, pages 506­515. SIAM, 2009.

[DP16]

Ran Duan and Seth Pettie. Connectivity oracles for graphs subject to vertex failures. CoRR, abs/1607.06865, 2016.

[DP17]

Ran Duan and Seth Pettie. Connectivity oracles for graphs subject to vertex failures. In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2017, Barcelona, Spain, Hotel Porta Fira, January 16-19, pages 490­509, 2017.

[DT02]

Camil Demetrescu and Mikkel Thorup. Oracles for distances avoiding a link-failure. In Proceedings of the thirteenth annual ACM-SIAM symposium on Discrete algorithms, pages 838­843, 2002.

[FK10a]

Pierre Fraigniaud and Amos Korman. Compact ancestry labeling schemes for xml trees. In Proceedings of the twenty-first annual ACM-SIAM symposium on Discrete Algorithms (SODA), pages 458­466. SIAM, 2010.

32

[FK10b]

Pierre Fraigniaud and Amos Korman. An optimal ancestry scheme and small universal posets. In Proceedings of the forty-second ACM symposium on Theory of computing (STOC), pages 611­620, 2010.

[GKKT15] David Gibb, Bruce M. Kapron, Valerie King, and Nolan Thorn. Dynamic graph connectivity with improved worst case update time and sublinear space. CoRR, abs/1509.06464, 2015.

[GP16]

Mohsen Ghaffari and Merav Parter. MST in log-star rounds of congested clique. In Proceedings of the 2016 ACM Symposium on Principles of Distributed Computing, PODC 2016, Chicago, IL, USA, July 25-28, 2016, pages 19­28, 2016.

[GPPR04] Cyril Gavoille, David Peleg, Ste´phane Pe´rennes, and Ran Raz. Distance labeling in graphs. Journal of Algorithms, 53(1):85­112, 2004.

[GW12]

Fabrizio Grandoni and Virginia Vassilevska Williams. Improved distance sensitivity oracles via fast single-source replacement paths. In 53rd Annual IEEE Symposium on Foundations of Computer Science, FOCS 2012, New Brunswick, NJ, USA, October 20-23, 2012, pages 748­757, 2012.

[KB10]

Neelesh Khanna and Surender Baswana. Approximate shortest paths avoiding a failed vertex: Optimal size data structures for unweighted graph. In 27th International Symposium on Theoretical Aspects of Computer Science-STACS 2010, pages 513­524, 2010.

[KKM13] Bruce M Kapron, Valerie King, and Ben Mountjoy. Dynamic graph connectivity in polylogarithmic worst case time. In Proceedings of the twenty-fourth annual ACM-SIAM symposium on Discrete algorithms, pages 1131­1142. SIAM, 2013.

[KKT15]

Valerie King, Shay Kutten, and Mikkel Thorup. Construction and impromptu repair of an MST in a distributed network with o(m) communication. In Proceedings of the 2015 ACM Symposium on Principles of Distributed Computing, PODC 2015, Donostia-San Sebastia´n, Spain, July 21 - 23, 2015, pages 71­80, 2015.

[KNR92] Sampath Kannan, Moni Naor, and Steven Rudich. Implicat representation of graphs. SIAM Journal on Discrete Mathematics, 5(4):596­603, 1992.

[KW14]

Michael Kapralov and David Woodruff. Spanners and sparsifiers in dynamic streams. In Proceedings of the 2014 ACM symposium on Principles of distributed computing, pages 272­281, 2014.

[MK18]

Ali Mashreghi and Valerie King. Broadcast and minimum spanning tree with o(m) messages in the asynchronous CONGEST model. In 32nd International Symposium on Distributed Computing, DISC 2018, New Orleans, LA, USA, October 15-19, 2018, pages 37:1­ 37:17, 2018.

[NMN01] Jaroslav Nesetril, Eva Milkova´, and Helena Nesetrilova´. Otakar boruvka on minimum spanning tree problem translation of both the 1926 papers, comments, history. Discrete Mathematics, 233(1):3­36, 2001.

[NN93] Joseph Naor and Moni Naor. Small-bias probability spaces: Efficient constructions and applications. SIAM journal on computing, 22(4):838­856, 1993.

[Pel00] David Peleg. Distributed Computing: A Locality-sensitive Approach. SIAM, 2000.

33

[Pel05]

David Peleg. Informative labeling schemes for graphs. Theoretical Computer Science, 340(3):577­593, 2005.

[Pel09]

David Peleg. As good as it gets: Competitive fault tolerance in network structures. In Symposium on Self-Stabilizing Systems, pages 35­46. Springer, 2009.

[PS87]

David Peleg and Barbara Simons. On fault tolerant routings in general networks. Information and Computation, 74(1):33­49, 1987.

[PT07]

Mihai Patrascu and Mikkel Thorup. Planning for fast connectivity updates. In 48th Annual IEEE Symposium on Foundations of Computer Science (FOCS'07), pages 263­271. IEEE, 2007.

[PT11]

David Pritchard and Ramakrishna Thurimella. Fast computation of small cuts via cycle space sampling. ACM Transactions on Algorithms (TALG), 7(4):46, 2011.

[Raj12]

Varun Rajan. Space efficient edge-fault tolerant routing. In IARCS Annual Conference on Foundations of Software Technology and Theoretical Computer Science (FSTTCS 2012). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2012.

[Thu97] Ramakrishna Thurimella. Sub-linear distributed algorithms for sparse certificates and biconnected components. Journal of Algorithms, 23(1):160­179, 1997.

[TZ01]

Mikkel Thorup and Uri Zwick. Compact routing schemes. In Proceedings of the thirteenth annual ACM symposium on Parallel algorithms and architectures, pages 1­10, 2001.

[Vad12] Salil P. Vadhan. Pseudorandomness. Foundations and Trends® in Theoretical Computer Science, 7(1­3):1­336, 2012.

[vdBS19] Jan van den Brand and Thatchaphol Saranurak. Sensitive distance and reachability oracles for large batch updates. In 2019 IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS), pages 424­435. IEEE, 2019.

[WY10]

Oren Weimann and Raphael Yuster. Replacement paths via fast matrix multiplication. In 51th Annual IEEE Symposium on Foundations of Computer Science, FOCS 2010, October 23-26, 2010, Las Vegas, Nevada, USA, pages 655­662, 2010.

A Additional Definitions
Definition A.1 (Pairwise Independence Hash Functions). Let H be a family of functions from {1, . . . , N} to {1, . . . , M}. The family H is pairwise independent if for every x, y  {1, . . . , N} such that x = y and for every a, b  {1, . . . , M} it holds that
Pr [h(x) = a  h(y) = b] = 1/M2 .
hH
That is, if h is chosen uniformly at random from H, then the random variable h(x) and h(y) are uniformly distributed and pairwise independent.
Fact A.2. [Vad12] There is an explicit family H of pairwise independent has functions from {0, 1}n  {0, 1}m constructed using O(max{m, n}) bits and computable in poly(n, m) time.

34

B Overview of the Cycle Space Sampling Technique

The cycle space sampling technique allows to detect cuts in a graph using a connection between cuts and cycles in a graph. This beautiful technique was introduced by Pritchard and Thurimella [PT11], that showed its applicability for distributed algorithms identifying small cuts in a graph. We next give a short overview of the technique, for full details see [PT11].
The cycle space of a graph is the family of all subsets of edges F that have even degree at each vertex, any such subset   E is called a binary circulation. The cut space is the family of all induced edge cuts. It is easy to see that if we take a cycle C in a graph and an induced edge cut, then the number of edges of the cycle that cross the cut is even. The cycle space technique extends this observation and shows that the cycle space and cut space are orthogonal vector spaces. Using this, they show the following (see Propositions 2.2 and 2.5 in [PT11]).
Claim B.1. Let  be a uniformly random binary circulation and F  E. Then

Pr[|F  | is even] =

1, i f F is an induced edge cut 1/2, otherwise

Hence, sampling a random binary circulation allows to detect if a subset of edges is an induced edge cut with probability 1/2. To reduce the failure probability to 1/2b we can choose b random binary circulations. To use this technique, the authors provide an efficient way to sample a random binary circulation, we describe next. Let T be a spanning tree of the graph. For any non-tree edge e, adding e to the graph creates a cycle. These cycles are the fundamental cycles, and it is shown that the fundamental cycles are a basis for the cycle space. Based on this, they show that sampling a random binary circulation can be done by choosing each fundamental cycle with probability 1/2, or equivalently choosing each non-tree edge with probability 1/2. The binary circulation  sampled has all the non-tree edges sampled, and each tree edge that appears in odd number of sampled cycles. Given the sampled non-tree edges in , the tree edges in  can be identified using a simple scan of the tree, as shown in [PT11]. Choosing b random binary circulations, is equivalent to choosing a b-bit random string (e) for each non-tree edge. For a tree edge t, we define (t) = eCt (e), where Ct are all non-tree edges e such that t is in the fundamental cycle of e. This again can be computed by a simple scan of the tree, and takes O((n + m)b) time if the labels have size b. This gives the following.
Lemma 1.7. There is an algorithm that assigns the edges of a graph G = (V, E), b-bit labels (e) such that given a subset of edges F  E, we have:

Pr[ (e) = 0] =
eF

1, i f F is an induced edge cut 2-b, otherwise

Where 0 is the all-zero vector. The time complexity for assigning the labels is O((m + n)b).

To see this, let 1, ..., b be the sampled binary circulations. If F is an induced edge cut, then
from Claim B.1, for every sampled circulation i, we have that |F  i| is even, and hence for all i,
the i'th bit of eF (e) is equal to 0 as needed. Otherwise, for all i, the i'th bit eF (e) equals 0 with probability 1/2, hence the probability that the whole vector equals 0 is 1/2b, as needed.

C Missing Proofs
Proof of Lemma 3.8. The lemma is proved in [GP16], the only part that is not discussed there is the time to determine UID(e) that follows from [NN93]. By Theorem 3.1 of [NN93], given the seed
35

SID and the edge identifier ej = (ID(u), ID(v)), determining the ith bit of UID(ej) can be done in O(log n) time. Thus, determining all O(log n) bits, takes O(log2 n) time. Proof of Lemma 3.10. Let X = XOR(E  Ei,j). Letting E = E  Ei,j, then X can be written as the concatenation of XOR1(E ) and XOR2(E ), where XOR1(E ) = XORU(E ) is the bit-wise XOR of the unique identifiers UID(e) for e  E and XOR2(E ) is the bit-wise XOR of the remaining information in the extended identifiers of E . We now show how using the seed and XOR2(E ), one can test the validity of XOR1(E ). The algorithm detects the case that |E |  2 as follows. First, in the case that E is a single edge, XOR2(E ) should contain legal ids ID(u), ID(v). If this is not the case, it follows that |E | = 1. If XOR2(E ) contains legal ids ID(u), ID(v), we use them and the seed SID to determine UID(e) for e = (u, v), and we check if XOR1(E ) = ID1(e). We have two options, either E = {e} is the single edge e, in which case XORU(E ) = UID(e)  I, and the verification succeeds. Otherwise |E |  2, in which case, from Lemma 3.8, Pr[XORU(E )  I ]  1/n10, hence w.h.p XORU(E ) = UID(e)  I and we identify that |E |  2. Proof of Claim 3.11. The label size is dominated by the sketching information Sketch(V(Tu)), which is made of a concatenation of the bitwise XOR of O(log n) basic sketch units Sketchi(u). By Eq. (2), each unit has O(log2 n) bits, and thus overall, the label has O(log3 n) bits. Proof of Lemma 3.13. The proof follows from Lemma 3.9. Note that by definition of the sketch values Sketchi(S) = vSSketchi(v) = [XOR(Ei,0(S)), . . . , XOR(Ei,log m(S))], where Ei,j(S) are the outgoing edges from S in Ei,j (edges that have both endpoints in S are cancelled out by the XOR operation). Let E be all the outgoing edges from S. From Lemma 3.9, with constant probability there exists a j such that |E  Ei,j| = 1. In this case, XOR(Ei,j(S)) corresponds to an extended id of a single outgoing edge from S. We can check if this happens in O(1) time using Lemma 3.10. Proof of Claim 3.12. To compute the labels of vertices we assign ids to vertices in O(n) time, and compute ancestry labels in O(n) time using Lemma 3.1. To compute the extended identifiers EIDT(e), we also choose the random seed SID and compute UID(e) using Lemma 3.8, this takes O(1) time per edge, and O(m) time for all edges. Lastly, we should compute the sketch values Sketch(V(Tu)). For this, first, we choose the random seed Sh, and compute the values SketchG(v). For this, we should identify for each vertex the adjacent edges in Ei,j. For each edge we can identify the sets it belongs to in O(1) time using Fact A.2. This allows us computing the sketch values of all vertices in O(m + n) time. We can then compute the values Sketch(V(Tu)) by scanning the tree in O(n) time.
36

