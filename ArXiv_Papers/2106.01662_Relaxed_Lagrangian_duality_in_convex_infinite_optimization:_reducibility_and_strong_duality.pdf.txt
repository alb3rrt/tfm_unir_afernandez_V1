Relaxed Lagrangian duality in convex infinite optimization: reducibility and strong duality
N. Dinh,, M. A. Goberna, M. A. Lo´pez§, M. Volle¶ June 4, 2021

arXiv:2106.01662v1 [math.OC] 3 Jun 2021

Abstract
We associate with each convex optimization problem, posed on some locally convex space, with infinitely many constraints indexed by the set T, and a given non-empty family H of finite subsets of T, a suitable Lagrangian-Haar dual problem. We obtain necessary and sufficient conditions for H-reducibility, that is, equivalence to some subproblem obtained by replacing the whole index set T by some element of H. Special attention is addressed to linear optimization, infinite and semi-infinite, and to convex problems with a countable family of constraints. Results on zero H-duality gap and on H-(stable) strong duality are provided. Examples are given along the paper to illustrate the meaning of the results.
Key words Convex infinite programming; Lagrangian Duality; Haar Duality; Reducibility
Mathematics Subject Classification Primary 90C25; Secondary 49N15 · 46N10

1 Introduction

The aim of this paper is to analyze relaxed forms of the Lagrangian-Haar dual problem relative to the convex infinite programming (CIP, in brief) problem

(P) inf f (x) s.t. ft(x)  0, t  T,

(1.1)

where X is a locally convex Hausdorff topological vector space, T is an arbitrary infinite index set, and {f ; ft, t  T } are convex proper functions on X. The key stone in this paper is the (relaxed ) H-Lagrangian-Haar dual of (P), where H is a given family of nonempty finite subsets of the index set T, defined as

(DH)

sup inf
HH, µRH+ xX

f (x) + µtft(x)
tH

,

International University, Vietnam National University - HCMC, (ndinh@hcmiu.edu.vn) Vietnam National University - HCM city, Linh Trung ward, Thu Duc district, Ho Chi Minh city, Vietnam Department of Mathematics, University of Alicante, Alicante, Spain (mgoberna@ua.es) §Department of Mathematics, University of Alicante, Alicante, Spain (marco.antonio@ua.es); and CIAO,
Federation University, Ballarat, Australia, corresponding author ¶Avignon University, LMA EA 2151, Avignon, France (michel.volle@univ-avignon.fr)

1

where µ = (µt)tH  RH+ , with the rule 0 × (+) = 0, which is applied along the whole paper, except in Remark 5.2. We say that zero H-duality (or just H-duality) holds if the optimal values of (P) and (DH) coincide, i.e., if inf(P) = sup(DH), while H-strong duality holds if, additionally, (DH) is solvable, i.e., if inf(P) = max(DH).
The usual Lagrangian-Haar dual (D) of (P) (see, e.g., [5], [8], [11], [12]) corresponds to the case where H is the family F(T ) of all non-empty finite subsets of T , that is,

(D)

sup inf
HF (T ), µRH+ xX

f (x) + µtft(x)
tH

.

(1.2)

Obviously sup(DH)  sup(D). Moreover, the so-called weak duality inequality establishes that sup(D)  inf(P).
Other examples of such type of families are H1 := {{t}, t  T } and, for T = N, HN := {{1, . . . , n}, n  N} , which are also meaningful in the framework of duality for the robust sum of functions [6]. So, we also pay attention to the dual problems

(DH1 )

sup inf {f (x) + µft(x)} ,
(t,µ)T ×R+ xX

and
n

(DHN )

sup inf
nN, µRn+ xX

f (x) + µkfk(x)
k=1

.

The problem (P) in (1.1) is said to be reducible if there exists a finite set H  T such that the optimal value of (P) coincides with that of the problem (PH ) which results of replacing T by H in (P). The reducible linear semi-infinite programming problems have been characterized in [10, Theorem 8.3], but we do not know antecedents on reducibility for other types of convex optimization problems. In the same vein, we can say that a dual problem (D) is reducible if there exists a finite set H  T such that the optimal value of (D) coincides with that of

(DH )

sup inf
µRH+ xX

f (x) + µtft(x)
tH

.

Accordingly, we say that (P) (respectively, (D)) is H-reducible if there exists a finite set H  H such that its optimal value coincides with that of (PH ) (respectively, (DH )). So, a given CIP problem (P) is H1-reducible if and only if it has the same optimal value as some subproblem with a unique constraint, and it is F(T )-reducible if and only if it is reducible (or HN-reducible whenever T is countable). Proposition 5.105 in [1] can be interpreted as providing a sufficient condition for a given convex semi-infinite programming problem (P), with compact index set T, and its dual (D), to be both reducible relatively to the family H of subsets of T whose cardinality is the dimension of X.

While this paper is focused on H-reducibility, zero H-duality, H-strong duality, and Hstable strong duality, in a forthcoming paper we consider reverse H-strong duality (where the solvable problem is (P)) and applications of this type of relaxed Lagrangian duality to derive Farkas-type lemmas and optimality conditions involving a fixed number of positive KKT multipliers (e.g., one, if we choose H = H1).
The classical Lagrange duality theory has been recently extended in another direction in [3], replacing the convex functions by the so-called H-convex functions, which are the supremum

2

of certain class of the space H of abstract affine functions (we use the same symbol H for a class of index sets, so that our duality theorems are independent of those of [3]).
The paper is organized as follows. Section 2 reviews the classical duality theorems for CIP problems and their finite subproblems. Section 3 characterizes the H-reducibility of (P) and (D) in Theorem 3.1 in terms of H-strong duality of this pair of problems. In Section 4 special attention is addressed to H-reducibility of linear infinite and semi-infinite programming problems (in short LIP and LSIP, respectively). Section 5 is devoted to the H-(stable) strong duality of the pair (P)-(DH), which is characterized by Theorem 5.1. The very particular case when H = H1 is analyzed in Theorem 5.3. Also, a special attention is addressed to HN-strong duality concerning countable convex infinite problems (Theorem 5.2, Corollary 5.4). Finally, Section 6 provides a characterization of zero H-duality gap between the problems (P) and (DH) (Theorem 6.1, Corollaries 6.1-6.2).

2 Preliminaries
Let X be a locally convex Hausdorff topological vector space, and suppose that its topological dual X, with null element 0X, is endowed with the weak*-topology. The w-closure of a set A  X is denoted by A. If A  X × R, then A denotes the closure of A w.r.t. the product topology. A subset A  X × R is said to be w-closed (respectively, w-closed convex) regarding another subset B  X × R if A¯  B = A  B (respectively, (coA)  B = A  B), see [2] (respectively, [7]).
We denote by co A the convex hull of A  X. For a set  = A  X, by the convex cone generated by A we mean cone(A) := R+(co A) = {µx : µ  R+, x  co A}.
A function h : X  R := R  {±} is proper if its epigraph epi h is non-empty and never takes the value -; it is convex if epi h is convex; it is lower semicontinuous (lsc, in brief) if epi h is closed; and it is upper semicontinuous (usc, in brief) if -h is lsc. For a proper function h, we denote by [h  0] := {x  X : h(x)  0} its lower level set of 0 (and, similarly, the strict lower level set [h < 0]), by dom h, epis h, h, and h its domain, its strict epigraph, its lsc envelope, and its Legendre-Fenchel conjugate, respectively. We also denote by  (X) the class of lsc proper convex functions on X. By A we denote the indicator function of A  X, and A   (X) if and only if A is closed, convex, and non-empty.
2.1 Classical convex infinite optimization duality
Now let T be an infinite index set and {f ; ft, t  T } be a collection of convex proper functions. Consider the problem
(P) inf f (x) s.t. ft(x)  0, t  T,
and its Lagrangian-Haar dual, that is (1.2) or, equivalently,

(D) sup inf f (x) +

tft (x) ,

R(+T ) xX

tT

where

(T )
R+

:= {

:

T

 R+

such

that

(t)



t

=

0

for

all

t

T

except

for

finitely

many}.

3

Given





(T
R+

),

let

us

consider

its

support,

supp  := {t  T :

t > 0}, and the associated

function tT tft : X  R  {+}, defined by

tft
tT





tft(x),

(x) = tsupp 

 0,

if supp  = ,

if

supp  =  (i.e.,

 = 0T



(T
R+

)).

The following function  : X  R is a key tool in our approach:

(x) := inf
R(+T )

f + tft
tT


(x).

Given the set in X × R



A :=

epi f + tft ,

R(+T )

tT

the following properties have been proved in [12, (2.1) and (2.2)] for {f ; ft, t  T }   (X), although they remain valid for arbitrary proper functions (even non-convex):

A is convex,  is convex, epis   A  epi , and epi  = A.

(2.1)

Let E := [ft  0]
tT
be the feasible set of (P). Then, the weak duality relations below always hold:
-   (f + E)(x)  (x)  f (x)  +, x  X.
In the case where x = 0X, one gets from (2.2)
-  infX f  sup(D)  inf(P)  +.

(2.2)

2.2 Subprogram duality
Given H  F(T ), consider the subproblem of (P)

and its Lagrangian dual

(PH ) inf f (x) s.t. ft(x)  0, t  H,

(DH )

sup inf
µRH+ xX

f (x) +

µtft
tH

(x) ,

where, for each µ  RH+ and each x  X,

4

µtft (x) = µtft(x).

tH

tH

Define

AH :=

epi

µRH+

and, for each x  X,

f + µtft
tH


 X × R,

(2.3)

H (x)

:=

inf
µRH+


f + µtft (x)  R.
tH

(2.4)

We have that AH is convex, H is convex, AH  A, H  , and epis H  AH  epi H . Moreover, sup(DH )  sup(D) and, if EH := tH [ft  0] is the feasible set of (PH ), the next weak duality relations hold:

-  (f + E) (x)  (f + EH )(x)  H (x)  f (x)  +, x  X.

For x = 0X these relations yield -   infX f  sup(DH )  inf(PH )  inf(P)  +.

(2.5)

3 H-reducibility

Let H be a non-empty family of non-empty finite subsets of T , i.e.,  = H  F(T ). Recall that (P) (respectively, (D)) is H-reducible if there exists H  H such that inf(P) = inf(PH ) (resp. sup(D) = sup(DH )).

3.1 Illustrative examples
We now illustrate this desirable property with two examples.

Example 3.1 Consider the problem

(P) inf f (x) = x, x
xR2
s.t. -tx1 + (t - 1)x2 + t - t2  0, t  [0, 1] ,

(3.1)

where x  R2+, and its corresponding family of singletons H1 = {{t}: t  [0, 1]} . The feasible set E of (P) is the Minkowski sum of the curve C = {(s, 1 + s - 2 s) : s  [0, 1]} with the positive cone R2+ (see Figure 1). In fact each constraint of (3.1) defines a supporting halfspace to C and viceversa. So, the boundary bd E of E is formed by those points of E with a unique
active constraint.

5

The feasible set of (P)

If x = (0, 0) , given H  H1, we have

min (P) = min (PH ) = 0 = max (DH )  sup (D)  min (P) ,

so that (P) and (D) are H1-reducible. Hence, we can assume that x = 02. Since any optimal solution x, when it exists, lies on bd E, at such a point only there will exist an active constraint, i.e., t  [0, 1] such that

- tx1 + (t - 1)x2 + t - t2 = 0.

(3.2)

On the other hand, since the set (-t, t - 1, t - t2), t  [0, 1] is compact and any interior

point of E is a Slater point, KKT optimality conditions (e.g. [10, Theorems 7.1 and 5.3])

apply to establish that x is optimal for problem (3.1) if and only if there exists   0 such

that

x = (t, 1 - t).

(3.3)

So, the optimal solutions of (P) are those x  bd E such that there exist t  [0, 1] and   0 satisfying (3.2) and (3.3), which implies x  R2+. If x / R2+, one has inf (P) = sup(D) = - and, recalling that the duality gap is zero in linear programming (LP in short) except in the case when the primal and the dual problems
are simultaneously inconsistent, inf (PH ) = sup(DH ) = - for all H  H1. So, (P) and (D) are H1-reducible. We finally explore the non-trivial case that x  R2+ {02} . Since

x=

x2 x1 + x2

2
,

x1

2

x1 + x2

 C,

with

t=

x1 x1 + x2

and

 = x1 + x2

> 0,

satisfies (3.2) and (3.3), x is an optimal solution of (P) (the unique one when x  R2++,

as

Figure

1

shows),

and

min (P)

=

. x1 x2
x1 +x2

It

is

easy

to

see

that,

taking

H

:=

t

 H1,

x is also optimal for (PH ) (but not the unique one, as (PH ) has infinitely many optimal

solutions) and min (P) = min (PH ) ; hence (P) is H1-reducible. It is also straightforward that

the

unique

feasible

solution

of

(DH )

is

µt

=

x1 + x2

>

0,

with

max (DH )

=

. x1 x2
x1 +x2

Since

max (DH )  sup (D)  min (P) = min (PH ) and max (DH ) = min (PH ), the problem (D) is

also H1-reducible.

From the previous discussion we conclude that both problems, (P) and (D), H1-reducible.

6

Example 3.2 Consider the LSIP problem

(P) inf f (x) = x, x

xR2

s.t.

-tx1

+ (t

- 1)x2

- t2

+t-

1 r



0,

(t, r)



[0, 1] ×

N,

where x  R2+ and the family of singletons is now H1 = {{(t, r)} : t  [0, 1] , r  N} . The primal feasible set is still the set E in Figure 1, but now no constraint is active at the boundary
of E. Hence, the optimal value of the subproblem with a unique constraint

inf f (x) = x, x

xR2

s.t.

-tx1

+

(t

-

1)x2

-

t2

+

t

-

1 r



0,

is less than min (P) for any x  R2+ and {(t, r)}  H1, so that (P) is not H1-reducible.

3.2 H-reducibility of general convex problems

The next two sets will play crucial roles along this paper. The first one,



AH := AH =

epi f + µtft ,

H H

HH µRH+

tH

involves all the data of (P) while the second one,

(3.4)

KH := cone

epi ft ,

H H

tH

only involves the constraints. In particular, K := KF(T ) is convex and satisfies [4, Theorem 3.1]
E =   (0X, -1) / K.

We also associate with H the function

H

:=

inf
H H

H

=

inf inf
HH µRH+


f + µtft
tH

(3.5)

and the set

EH :=

EH =

[ft  0].

H H

HH tH

Obviously AH  A, H  , epis H  AH  epi H and

(f

+ E) (x)  inf (f
H H

+ EH )(x)  H(x)  f (x),

x  X,

(3.6)

entailing

sup(DH)  sup(DF(T ))  sup(D)  inf(P).

(3.7)

Remark 3.1 Let H, J  F(T ). If for each H  H there exists J  J such that H  J,
then AH  AJ , J  H, and sup(DH)  sup(DJ ). This is, in particular, the case when H J.

7

Let us examine the relationship among H, AH and KH. Assume that {f ; ft, t  T }  (X) and E  (dom f ) = , entailing that all the functions f + tH µtft are proper. Then, following a similar reasoning to that in [12, Section 3], we can establish, that
epi H = epi f  + KH = AH.
In the particular case of f  0 we get AH = ({0X} × R+) + KH = KH. We now characterize the H-reducibility of a given bounded CIP problem (P) by combining
three main ingredients: the set AH, the strong duality between (P) and (DH), and the following property:

(RH) Each bounded subprogram (PH), H  H, satisfies inf(PH ) = max(DH ).

Property (RH) is, for instance, satisfied in the two well-known situations below:

1. (P) is a LSIP problem: due to the fundamental LP-duality theorem which establishes that if one of the problems (PH ) or (DH ) is bounded, then both problems are solvable and their optimal values coincide.
2. (P) is a general CIP problem such that (see [16, Theorem 2.9.3]):

H  H, aH  dom f such that ft (aH ) < 0, t  H. This is in particular satisfied under the (generalized) Slater condition; i.e.,

a  dom f such that ft (a) < 0 for all t  T.

Theorem 3.1 (CIP H-reducibility) Let (P ) be bounded (i.e.,  := inf(P )  R) and consider the following assertions involving a family  = H  F(T ) : (i) (0X, -)  AH. (ii) H-strong duality holds (i.e.,  = max(DH)). (iii) (D) is H-reducible and zero H-duality holds (entailing  = sup(D)). (iv) (P) is H-reducible. Then, one has (i)  (ii) = (iii) = (iv). Moreover, if assumption (RH) is satisfied, then (i), (ii), (iii), and (iv) are equivalent.

Proof f+

[(i) = (ii)] By definition of AH there exists H tH µtft  (0X)  - and, by (2.5), we have



H

and

µ  RH+

such

that

 = inf(P)  inf(PH )  sup(DH )  inf f +
X

µtft  ,

tH

and sup(D)  inf(P) = max(DH )  sup(D),

which shows that (ii) holds.

[(ii) = (i)] It is obvious from the definition of AH. [(ii) = (iii)] There exists H  H and µ  RH+ such that

sup(D)   = inf f +
X

µtft  sup(DH )  sup(D),

tH

8

and (iii) holds. [(iii) = (iv)] There exists H  H such that  = sup(D) = sup(DH )  inf(PH )  ,
and (iv) holds. [(iv) = (ii)] (under (RH)) There exists H  H such that, by (RH) ,  = inf(PH ) = max(DH )  sup(DH)  sup(D)  inf(P) = ,
and (ii) holds. We need some new notions in order to establish new sufficient conditions for H-reducibility.

Definition 3.1 (i) A family H  F (T ) is said to be covering if HH H = T . (ii) A family H  F(T ) is said to be directed if for each H, K  H there exists L  H such
that H  K  L.

The families F (T ) and HN are both covering and directed, whereas H1 is a covering family but it is not a directed one. Note that
H covering = [EH = E and sup(DH1)  sup(DH)] .
Proposition 3.1 The following statements are equivalent: (i) H is a directed covering family. (ii) For each K  F(T ), there exists H  H such that K  H.

Proof [(i) = (ii)] Let K  F(T ). Since H is covering one has K  Ht with t  Ht  H
tK
for each t  K. Since K is finite and H is directed there exists H  H such that tK Ht  H and K  H.
[(ii) = (i)] Let t  T . By (ii), with K = {t}, there exists H  H such that t  H, so that H is covering. We prove now that H is directed. Let I, J  H. By (ii) with K = I  J, there exists H  H such that I  J  H.

Proposition 3.2 For each directed covering family H  F(T ) one has

and, consequently,

AH = AF(T ) = A,

H = F(T ) = , and sup(DH) = sup(DF(T ))  sup (D). Moreover, KH = K.

Proof Since AH  AF(T )  A, it suffices to prove that A  AH. Let (x, r)  A. There

exists





(T )
R+

such

that

f+

tT tft  (x)  r. If supp  =  then (x, r)  epi f , with

epi f   AH for all H  H, and so, (x, r)  AH. Assume now that K := supp  = . By

Proposition 3.1 there exists H  H such that K  H and we have

(x, r)  AK  AH  AH.

The proof of the relation KH = K is similar.

9

Proposition 3.3 Assume that H is directed covering. Then (P) (resp. (D)) is reducible if and only if (P) (resp. (D)) is H-reducible.
Proof It suffices to prove that the necessity holds. So, assume that (P) (resp. (D)) is reducible. Then, there exists K  F(T ) such that inf (P) = inf(PK) (resp. sup (D) = sup(DK)). By Proposition 3.1 there exists H  H such that K  H. Consequently,
inf (P)  inf(PH )  inf(PK) = inf (P),
(resp. sup (D)  sup(DH )  sup(DK) = sup (D)), and finally, inf (P) = inf(PH ) (resp. sup (D) = sup(DH )).

4 H-reducibility of linear optimization problems

We now consider the case where

f (x) = x, x , ft(x) = at , x - bt, t  T, with {x; at , t  T }  X, and {bt, t  T }  R. Equivalently,
(P) inf x, x s.t. at , x  bt, t  T,

and

(D)

sup -

tbt

s.t.





(T
R+

),

tat = -x,

tT

tT

and, for each H  H  F(T ),

(PH ) inf x, x s.t. at , x  bt, t  H,

and

(DH ) sup - µtbt s.t. µ  RH+ ,

µtat = -x,

tH

tH

while

(DH)

sup - µtbt s.t. H  H, µ  RH+ ,

µtat = -x.

tH

tH

Let us make explicit AH . We have

f + tH µtft  = x + tH µt(at - bt)  =  x+ + tH µtat tH µtbt,

and where

epi f + tH µtft  = {(x, 0)} + tH µt(at , bt) + {0X } × R+,

AH =

epi f + tH µtft  = {(x, 0)} + KH ,

µRH+

KH := cone ({(at , bt), t  H} + {0X} × R+) .

(4.1) (4.2)

10

Taking into account that

KH =

KH ,

H H

which is a cone (not necessarily convex), we get

AH = {(x, 0)} + KH.

(4.3) (4.4)

Proposition 4.1 If H is a directed covering family, then KH = cone ({(at , bt), t  T } + {0X} × R+) .

Proof From Proposition 3.2 and (4.3),

KH = K =

cone ({(at , bt), t  H} + {0X} × R+)

HF (T )

=

t(at , bt) + {0X } × R+

HF (T ) R(+T ) tH

= cone ({(at , bt), t  T } + {0X} × R+) .

So, we are done.

Corollary 4.1 (LIP H-reducibility) Assume that (P) is bounded (that is,  := inf(P ) 

R), and

H  H, aH  X s.t. at , aH < bt, t  H.

(4.5)

Then the following statements are equivalent: (i) - (x, )  KH. (ii) H-strong duality holds (i.e.,  = max(DH)). (iii) (D) is H-reducible and zero H-duality holds (entailing  = sup(D)).
(iv) (P) is H-reducible.

Proof By (4.5), property (RH) is satisfied and we have just to apply Theorem 3.1 and use (4.4).
We now consider the LSIP problem (P) in (4.2) with X = Rn.
Corollary 4.2 (LSIP H-reducibility) Assume that X = Rn and (P) is bounded. Then, the statements from (i) to (iv) in Corollary 4.1 are still equivalent. Moreover, if H is a directed covering family, then the following statement is also equivalent to the four mentioned statements: (v)  = max(D) (usual strong duality).
Proof Since every LSIP problem satisfies (RH) , (i)  (ii)  (iii)  (iv) follows from Corollary 4.1. The equivalence between  = max(DH) and  = max(D) under the condition on H comes from Proposition 3.2.

11

Remark 4.1 Given a bounded LSIP problem (P) with x = 0n and optimal value , it has been proved in [10, Theorem 8.3] that (P) is reducible (i.e., F(T )-reducible) if and only if

- (x, )  K  ({0n} × R+) ,

(4.6)

with K  ({0n} × R+) being the so-called characteristic cone of the system { at , x  bt, t 

T } (e.g., [10, Chap. 4]). We now show that we can eliminate the half-line {0n} × R+ in

(4.6).

Let





(T )
R+

and

µ



0

be

such

that

Since x = 0n,  :=

- (x, ) = tT t(at , bt) + µ (0n, 1) . tT t > 0 and we can write

- (x, ) =

tT t (at , bt) +

µ 0n, 

 K.

The reducibility of (D) is not discussed in [10].

Example 4.1 We now revisit Examples 3.1 and 3.2 in the light of Corollary 4.2. For problem (P) in Example 3.1 one has

KH1 =

R+ ({(at , bt)} + {02} × R+)

tT

= R+ ({(at , bt) , t  T } + (02, R+))

= R+ -t, t - 1, t2 - t) , t  [0, 1] + (02, R+) ,

where -t, t - 1, t2 - t) , t  [0, 1] is an arch of parabola contained in the plane x1 + x2 =

-1 which connects the points (0, -1, 0) and (-1, 0, 0) . The equation of the cone generated by

the parabola

-t, t - 1, t2 - t) , t  R

is

x3

=

x1 x2 x1+x2

.

Defining



:

R2

-

R

such

that

 

x1 x2 x1+x2

,

 (x) = 0,

 +,

x  R2- x = 02, else,

{02} ,

as

2

(x)

=

(x1

2 + x2)3

-x22 x1x2 x1x2 -x21

,

is positive semidefinite on the interior of dom  = R2-,  is convex and also on dom  by

continuity. Since  is also lsc, the convex cone KH1 = epi  is closed. Since H1-strong duality

holds in the four cases discussed in Example 3.1, we conclude again, applying now Corollary

4.2(ii),

with



=

x1 x2 x1 +x2

if x  R2++ and  = 0 otherwise, that

(P) and (D) are H1-reducible

for all x  R2+.

Observe that the algebraic condition - (x, )  KH1 for H1-reducibility is easier to check than the H1-strong duality. In fact, if x  R2++, the unique solution of

-

x1,

x2,

x1x2 x1 + x2

= t -t, t - 1, t2 - t , t  0, t  [0, 1] ,

is (t, t) =

x1 x1 +x2

,

x1

+

x2

. Similarly, one has that - (x, 0)  KH holds when x lies on

the boundary of R2+.

12

Regarding Example 3.2, KH1 = {0n+1}  epis  is a convex but non-closed cone and, since (P) is not H1-reducible, the same happens with (D). Here the condition - (x, )  KH1 writes

-

x,

x1x2 x1 + x2

= t

-t, t - 1, t2 - t + 1 r

, t  0, t  [0, 1] , r  N,

which has no solution for any x  R2+.

5 H-stable strong duality

Let us go back to the general CIP problem (P) in (1.1). By (2.2) we have

(f + E)(x)  f + µtft (x), for all x  X, H  F (T ), and µ  RH+ .
tH

(5.1)

Definition 5.1 We say that the H-strong duality for (P) holds at a given x  X if

(f + E)(x) = min
HH, µRH+


f + µtft (x).
tH

(5.2)

For x = 0X, (5.2) amounts to the relation

inf(P) = max(DH).

(5.3)

Definition 5.2 If (5.2) is satisfied for all x  X, one says that H-stable strong duality for (P) holds, which amounts to say that
epi(f + E) = AH.

We first consider the H-strong duality in the general case. We first recall some general facts whose elementary proofs are similar to those in [12] and use (3.6).

Lemma 5.1 The following assertions always hold: (i) episH  AH  epiH  epi(f + E). (ii) co (epiH) = co (AH)  epi (f + E).
Another lemma will be useful.

Lemma 5.2 Let H  F(T ) be a covering family. Assume that the convex proper functions {f ; ft, t  T } are lsc (in other words {f ; ft, t  T }  (X)). Then, we have

(H) = f + E.

If, moreover, E  (dom f ) = , then epi(f + E) coincides with the w-closed convex hull of

AH, namely,









epi(f

+

E )

=

co

 



epi f +

µtft

. 

 HH
µRH+

tH



13

Proof We have 

(H)

= 

inf

H H

µRH+




f+

µtft

 

tH



= sup
H H µRH+

f + µtft
tH

= sup
H H µRH+

f + µtft
tH

= f + sup
H H µRH+

µtft
tH

= f + sup sup
HH µRH+

µtft
tH

= f + sup EH = f + EH = f + E.
H H
If, moreover, E  (dom f ) = , then dom(H) =  and by [9, Proposition 3.2],

epi(f + E) = epi(H) = co(epi H).

Lemma 5.1(ii) concludes the proof.

Theorem 5.1 (H-stable strong duality) Let H  F (T ) be a covering family, x  X,
and consider the following statements: (i) H-strong duality holds at x. (ii) AH is w-closed convex regarding {x} × R.
Then we have (i)  (ii). If, moreover, {f ; ft, t  T }  (X) and E  dom f = , then (i)  (ii). In particular, H-stable strong duality holds if and only if AH is w-closed convex.

Proof [(i)  (ii)] Let (x, r)  co(AH). By Lemma 5.1(ii) we have (f + E)(x)  r and, by assumption (i), there exist H  H, µ  RH+ such that (f + E) (x) = f + tH µtft  (x)  r, that means (x, r)  AH  AH. Therefore, AH is w-closed regarding {x} × R.

[(ii)  (i)] Since E  dom f = , we have (f + E)(x) = -. If (f + E)(x) = +, then for each H  H and each µ  RH+ , we get, from (5.1), f + tH µtft  (x) = + and



(f + E)(x) = + = min
HH, µRH+

f + µtft
tH

(x).

Assume now that r := (f + E)(x)  R. We have (x, r)  epi(f + E) = co(AH) (see Lemma 5.2). By assumption (ii) we obtain that (x, r)  AH, and there exist H~  H,
µ~  RH+~ , such that





f + µ~tft (x)  r = (f + E)(x)
tH~

 inf
H H µRH+


f + µtft
tH



(x)

 f + µ~tft (x),
tH~

14

and we are done.
Once again, regarding the problems in Examples 3.1 and 3.2, we conclude from Theorem 5.1 that (P) satisfies H1-stable strong duality in the first case because AH is w-closed convex, but not in the second because AH is just convex.
Lemma 5.3 For each family H  F(T ) we have
AH convex  H convex  H convex  AH convex  co(AH) = AH.
Proof Since epis H  AH  epi H we have H(x) = inf{r  R : (x, r)  AH} and then,
AH convex  H convex  H convex  epi H = AH convex  co(AH) = co(AH) = AH  AH convex.
As immediate consequence of Theorem 5.1 and Lemma 5.3 we establish the following consequences:
Corollary 5.1 Let H  F (T ) be a covering family with AH convex. Assume that {f ; ft, t  T }  (X) and E  (dom f ) = . Then H-strong duality holds at a given x  X if and only if AH is w-closed regarding {x} × R.
In particular, H-stable strong duality holds if and only if AH is w-closed.
Corollary 5.2 Assume that {f ; ft, t  T }  (X), E  (dom f ) = , and let H  F(T ) be a directed covering family. Then H-strong duality holds at a given x  X if and only if AH is w-closed regarding {x} × R. In particular, H-stable strong duality holds if and only if AH (alias A) is w-closed.
Proof Since AH = A (see Proposition 3.2) and A is convex (recall (2.1)), Corollary 5.1 concludes the proof.
We now give a corollary, addressing the LIP problem in (4.2), whose proof is a straightforward consequence of Theorem 5.1 and the relation AH = (x, 0) + KH.
Corollary 5.3 Consider the LIP problem (P) in (4.2), and let H be a covering family. Then, the following statements are equivalent: (i) inf(P) = max(DH). (ii) co(KH)  ({-x} × R) = KH  ({-x} × R). If H is additionally directed, (i) is equivalent to (iii) KH  ({-x} × R) = KH  ({-x} × R), and H-stable strong stability duality holds if and only if KH is w-closed.
Consider again problem (P) in Example 3.1, where we proved that KH1 is closed and convex. So, we conclude again, now from Corollary 5.3, that H1-strong duality holds.
We now give a new glimpse on HN-stable strong duality for convex infinite countable programs. Given the family {f ; fk, k  N}  (X), consider the countable convex optimization problem
(PN) inf f (x) s.t. fk(x)  0, k  N,
15

and, for each m  N, the finite subproblem (Pm) inf f (x) s.t. fk(x)  0, k  {1, · · · , m}.
The Lagrangian-Haar dual of (PN) reads

(DN)

sup inf
R(+N) xX

f (x) + kfk(x) .
kN

Let us consider the Lagrangian dual of the subproblem (Pm), that is

(Dm)

sup inf
µRm + xX

m
f (x) + µkfk(x) .
k=1

In terms of H-duality, the corresponding family is

HN = {{1, · · · , m}}mN ,

which is a directed covering family. Then, by Proposition 3.2, we have

A=

epi

R(+N)

f + kfk
kN



=

epi

mN,µRm +

m
f + µkfk
k=1


= AHN ,

which is a convex subset of X × R, and also

(5.4)

sup(DN)

=

sup
mN

sup(Dm)

=

lim
m

sup(Dm),

(5.5)

showing that the optimal value of (DN) can be arbitrarily approached by solving a sequence of finite subproblems.

Theorem 5.2 (HN-stable strong duality) Assume that E(dom f ) =  and let x  X.

The following statements are equivalent:

m



(i)

(f

+

E ) (x )

=

min
µRm +

f + µkfk
k=1

(x) for all m  N sufficiently large.

(ii) A is w-closed regarding {x} × R.

Proof [(i)  (ii)] There exist m  N and µ  Rm+ such that (f +E)(x) = (f +

m k=1

µk

fk

)

(x).

Consequently, HN-strong duality holds at x. By Corollary 5.2, A is w-closed regarding

{x} × R.

[(ii)  such that

(i)] By Corollary (f + E)(x) =

5.2 and the equality A

f+

N k=1

µ¯k

fk


(x).

= AHN, there For each m 

exist N  N and µ¯  N , let us now define

RN+

µ~k =

µ¯k, 0,

if 1  k  N, if N < k  m.

16

We have µ~  Rm+ and

m k=1

µk fk

=

N k=1

µ¯k

fk .

Finally,

if

m



N,

we

have

m



m



inf inf
mN µRp+

f + µkfk
k=1

(x) 

f + µ~kfk (x)
k=1

p



=

(f

+

E ) (x )



inf
pN, µRp+

f + µkfk
k=1

(x),

and (i) holds.

Corollary 5.4 Assume that inf(PN) = +. The following statements are equivalent: (i) inf(PN) = max(Dm) for all m sufficiently large. (ii) A is w-closed regarding {0X} × R.
Proof Apply Theorem 5.2 with x = 0X.

Remark 5.1 For each m  N it holds that

inf(PN) 

inf (Pm ) sup(DN)



sup(Dm).

Consequently, condition (ii) of Corollary 5.4 guarantees that, for m sufficient large,

inf(PN) = inf(Pm) = sup(Dm) = sup(DN),
and, in particular, that (PN) and (DN) are simultaneously HN-reducible. Note that for convex SIP problems such that {f ; ft, t  T }  (Rn) one can find in [13, Theorem 4.1 and Corollary 4.2] a recession condition ensuring that inf(Pm) = sup(Dm) for m sufficiently large, with inf(Pm)  inf(PN) as m  .

We finish this section providing easily checkable conditions guaranteeing the H1-(stable) strong duality for (P). Recall that the H1-dual of (P) reads

(DH1 )

sup inf {f (x) + µft(x)} .
(t,µ)T ×R+ xX

Theorem 5.3 (H1-stable strong duality) Assume: (a) dom f  dom ft.
tT
(b) T is a convex and compact subset of some locally convex space. (c) T t  ft(x) is concave and usc on T for each x  tT dom ft. (d) There exists x¯  dom f such that ft(x¯) < 0 for all t  T . Then H1-stable strong duality holds. In particular, we have
-   inf(P) = max(DH1) < +.

(5.6)

Proof We first prove (5.6). Let us consider the convex function h := suptT ft. Thanks to (d) we have
  inf(P) = inf{f (x) : x  [h  0]  dom f } < +.

17

The compactness of T, assumed in (b) , and the upper semicontinuity of the functions t  ft(x) on T, for each x  tT dom ft, assumed in (c), yield

dom h = dom ft  dom f and x¯  [h < 0]  dom f.
tT

Since h is convex and proper, by [16, Theorem 2.9.3] there exists µ¯  R+ such that

inf(P) = inf f (x) = inf {f (x) + µ¯h(x)} = inf max{f (x) + µ¯ft(x)}.

h(x)0

xdom f

xdom f tT

Now, by the general minimax theorem [16, Theorem 2.10.2], we have

inf(P) = max inf {f (x) + µ¯ft(x)}.
tT xdom f

Finally, there exists (t¯, µ¯)  T × R+ such that

inf (P)

=

inf {f (x)
xdom f

+

µ¯ft¯(x)}



sup(DH1 )

=

sup(D)



inf (P),

which shows that (5.6) holds.
Now, given an arbitrary x  X, we can apply (5.6), replacing f by f - x, since the corresponding assumptions (a), (b), (c), (d) are the same. So, H1-stable strong duality for (P) holds.

Consider the problems in Examples 3.1 and 3.2, with a fixed objective functional c instead of x. The problem in Example 3.1 enjoys H1-stable strong duality by Theorem 5.3, whose four assumptions trivially hold. However, we cannot apply Theorem 5.3 to the problem in Example 4.1 even though (a), (c), and (d) hold (in fact, we have seen in different ways that H1-stable strong duality fails).

Remark 5.2 [16, Theorem 2.9.3] is established under the rule 0 × (+) = + (see [16, p.39]) instead of the rule 0 × (+) = 0 we use in this paper. In fact, since dom f  dom h, the relations infh(x)0 f (x) = infxX {f (x) + µ¯h(x)} = infxdom f {f (x) + µ¯h(x)} we use in the proof of Theorem 5.3 are valid with both rules (recall that h := suptT ft).

Remark 5.3 In the proof of Theorem 5.3 we use two fundamental formulas. The first one, by [16, Theorem 2.9.3], says that

inf f (x) = max inf {f (x) + µh(x)},

h(x)0

µ0 xdom f

(5.7)

in which the linear space X  dom f is in fact a locally convex Hausdorff topological vector space. However, (5.7) holds in general linear spaces X provided Slater condition

x  dom f : h(x) < 0

(5.8)

is satisfied. This can be found for instance in [14, Lemma 1]. The second formula says that, for µ  0,

inf max{f (x) + µ¯ft(x)} = max inf {f (x) + µ¯ft(x)},

xdom f tT

tT xdom f

18

which is a direct consequence of [16, Theorem 2.10.2] with X being an arbitrary linear space and T a compact convex set. By (a) and (c) , (d) is equivalent to (5.8). Hence, Theorem 5.3 remains valid if X is only required to be a linear space. Observe also that the last part of the argument remains true replacing x  X by an arbitrary algebraic linear form on X since assumptions (a), (b), (c), (d) are the same for f and for f- .

Remark 5.4 Under the assumptions of Theorem 5.3 we know that H1-stable strong du-
ality holds (see Remark 5.3). By the first part of Theorem 5.1 we obtain that AH1 = (t,µ)T ×R+ epi(f + µft) is w-closed convex.

Remark 5.5 If one retains only the assumptions (a), (b), (c) of Theorem 5.3 (dropping the Slater condition (d)) we have that H1 is convex. Let us prove this fact that will be needed further on. Given x  X, we have

H1 (x)

=

inf
µR+

inf
tT

sup
xdom f

{

x, x

- f (x) - µft(x)} .

Applying again [16, Theorem 2.10.2] we have, for each µ  0,

inf sup { x, x - f (x) - µft(x)} = sup x, x - f (x) + min(-µft(x))

tT xdom f

xdom f

tT

= sup x, x - f (x) - µ max ft(x)

xdom f

tT

= (f + µh)(x).

Note that, for each x  dom f, the function R+ × X (µ, x)  x, x - f (x) - µh(x)
is affine. Consequently, the function R+ × X (µ, x)  (f + µh)(x)
is convex and, finally, H1(x) = infµ0(f + µh)(x) is convex too (e.g., [16, Theorem 2.1.3(v)]).

Corollary 5.5 Assume that {f ; ft, t  T }  (X), E  dom f = , and the conditions (a), (b), (c) in Theorem 5.3 are satisfied. Then, H1-stable strong duality holds if and only if
epi(f + µft) is w-closed.
(t,µ)T ×R+
Proof As mentioned in Remark 5.5, H1 is convex. Consequently, by Lemma 5.3, AH1 is convex and conclusion follows from Corollary 5.1.

19

6 Zero H-duality gap

In this section, we consider the general CIP problem in (1.1) with the feasible set E = tT [ft  0]. Given H  F (T ), and  = H  F (T ), recall the sets AH and AH defined in (2.3) and (3.4), respectively, and the function H in (3.5) as follows:



AH =

epi f + µtft , AH =

AH ,

µRH+

tH

H H



H

=

inf inf
HH µRH+

f + µtft
tH

=

inf
H H

H .

Definition 6.1 Given  = H  F (T ) and x  X, one says that H-duality for (P) holds at

x if

(f + E) (x) = H(x).

For x = 0X that leads us to

inf (P) = sup(DH) = sup inf
HH,µRH+ xX

f (x) + µtft(x)
tH

.

We now characterize the H-duality for (P).

Theorem 6.1 (Zero H-duality gap) Consider the following statements: (i) H-duality for (P) holds at x, (ii) (coAH)  ({x} × R) = AH  ({x} × R). Then (i)  (ii). If, moreover, {f ; ft, t  T }  (X), E  dom f = , and H is covering, then (i)  (ii).

Proof [(i)  (ii)] The inclusion [] in (ii) is obvious. Let us prove the opposite one. Let (x, r)  coAH. We have to check that (x, r)  AH  ({x} × R). By Lemma 5.1(ii), we have (f + E(x)  r, and by assumption (i), H(x)  r < r + 1/n for any n  1.
On the other hand, it follows from Lemma 5.1(i) that

(x, r + 1/n)  AH  ({x} × R) , n  1,

and

finally,

(x, r)

=

lim (x, r
n

+

1/n)



AH



({x}

×

R).

We now assume that {f ; ft, t  T }  (X), E  dom = , H is covering, and we prove (ii)  (i). Since  := (f + E)(x)  H(x) by (3.6), we have to prove that H(x)  .
This is obvious if  = +. Moreover, since E  dom f =  we have  = -. Suppose now

that   R. Suppose now that   R. We have (x, )  epi(f + E), and by Lemmas 5.2

and 5.1(ii),

(x, )  (coAH)  ({x} × R) .

Now, as (ii) holds, there exists a net (ri)iI such that

lim ri = , (x, ri)  AH, i  I.
iI
Again, it follows from Lemma 5.1(i), that H(x)  ri for all i  I. Passing to the limit we get H(x)  , as desired.

20

Remark 6.1 It is worth emphasizing that the implication (i)  (ii) of Theorem 6.1 holds for arbitrary proper functions f and ft, t  T .

By Proposition 3.2, we have

A :=

epi

(t)R(+T )

f + tft
tT


= AF(T ),

and the corresponding F(T )-dual problem of (P) reads:

(D)

sup inf
(t)R(+T ) xX

f (x) + µtft(x)
tT

.

Corollary 6.1 Assume that {f ; ft, t  T }  (X) and E  dom f = . The following statements are equivalent: (i) inf (P) = sup (D). (ii) A  ({0X} × R) = A  ({0X} × R).

Proof Applying Theorem 6.1 for H = F(T ), one has AH = A, which is convex. Consequently, coAH = A and, taking x = 0X, we are done.
We now come back to the general LIP problem in (4.2), with c instead of x,

and its H-dual,

(P) inf c, x s.t. at , x  bt, t  T,

(D)

sup - t bt,
H H,µRH+ tH tat =-c
tH

Recalling the sets KH and AH defined in (4.3) and (4.4), respectively,

KH =

KH =

cone ({(at , bt), t  H} + {0X} × R+) ,

H H

H H

AH = {(c, 0)} + KH,

we now can state

Corollary 6.2 Assume that the LIP problem (P) is feasible and H is covering. Then the following statements are equivalent: (i) inf (P) = sup (DH). (ii) (coKH)  ({-c} × R) = KH  ({-c} × R).
Proof Note that when f  0, ft = at - bt (t  T ), x = -c, we have - inf(D) = (f + E) (-c).
The second part of Theorem 6.1 now concludes the proof.

21

In Example 3.2 with x  R2+ {02} , by the characterization of KH1 in Example 4.1, one

has

coKH1  ({-x} × R)

= {-x} ×

-

x1 x2 x1 +x2

,

+

= {-x} ×

-

x1 x2 x1 +x2

,

+

= KH1  ({-x} × R),

so that condition (ii) in Corollary 6.2 holds. Thus, inf (P) = sup (DH1). The above argument

is valid for Example 3.1 just replacing the interval

-

x1 x2 x1 +x2

,

+

by its closure.

In the case where H is directed covering we have

KH = K = cone ({(at , bt), t  T } + {0X} × R+) .

The corresponding F(T )-dual problems of (P) reads:

(D)

sup - t bt,

(t)



(T )
R+

tat =-c

tT

tH

which is the familiar Haar-dual problem of the LIP problem (P).

Corollary 6.3 Assume that the LIP problem (P) is feasible. Then, the following statements are equivalent: (i) inf (P) = sup (D). (ii) K  ({-c} × R) = K  ({-c} × R).

Proof Apply Corollary 6.2 for H = F(T ). Then KH = K is convex, coK = K, and we are done.

Remark 6.2 Corollary 6.3 has been quoted in [10, Theorem 8.2] for the particular case when (P) is an LSIP problem and c belongs to the relative boundary of the cone{at , t  T }.
Funding This research was supported by the Vietnam National University HoChiMinh city (VNUHCM) under the grant number B2021-28-03, and by Ministerio de Ciencia, Innovaci´on y Universidades (MCIU), Agencia Estatal de Investigaci´on (AEI), and European Regional Development Fund (ERDF), Project PGC2018-097960-B-C22.

References
[1] Bonnans, J.F., Shapiro, A.: Perturbation Analysis of Optimization Problems. Springer, New York (2000)
[2] Bo¸t, R.I.: Conjugate Duality in Convex Optimization. Springer, Berlin/Heidelberg (2010)
[3] Bui, H.T., Burachik, R.S., Kruger, A.Y., Yost, D.T.: Zero duality gap conditions via abstract convexity. OPtimization, to appear. DOI: 10.1080/02331934.2021.1910694

22

[4] Dinh, N., Goberna, M.A., L´opez, M.A.: From linear to convex systems: consistency, Farkas' lemma and applications. J. Convex Anal. 13 (2006), 113-133
[5] Dinh, N., Goberna, M.A., L´opez, M.A., Son, T.Q.: New Farkas-type constraint qualifications in convex infinite programming, ESAIM: Control, Optim. & Calculus of Variations 13, 580-597 (2007)
[6] Dinh, N., Goberna, M.A., Volle, M.: Duality for the robust sum of functions, Set-Valued Var. Anal. 28, 41-60 (2020)
[7] Ernst, E., Volle, M.: Zero duality gap for convex programs: a generalization of the Clark-Duffin Theorem. J. Optim. Theory Appl. 158, 668-686 (2013)
[8] Fang, D.H., Li, C., Ng, K.F.: Constraint qualifications for extended Farkas's lemmas and Lagrangian dualities in convex infinite programming. SIAM J. Optim. 20, 13111332 (2009)
[9] Ekeland, I., Temam, R.: Analyse Convexe et Probl`emes Variationnels. Dunod, Paris (1974)
[10] Goberna, M.A., L´opez, M.A.: Linear semi-infinite optimization. J. Wiley, Chichester, U.K. (1998)
[11] Goberna, M.A., L´opez, M.A., Volle, M.: Primal attainment in convex infinite optimization duality. J. Convex Anal. 21, 1043-1064 (2014)
[12] Goberna, M.A., L´opez, M.A., Volle, M.: New glimpses on convex infinite optimization duality. RACSAM 109, 431-450 (2015)
[13] Karney, D.F.: A duality theorem for semi-infinite convex programs and their finite subprograms. Math. Programming 27, 75-82 (1983)
[14] Mart´inez-Legaz, J.-E., Volle, M.: Duality in D.C. programming: the case of several D.C. constraints. J. Math. Anal. Appl. 237, 657-671 (1999)
[15] Rockafellar, R.T.: Convex analysis. Princeton University Press, Princeton, N.J. (1970) [16] Zalinescu, C. : Convex Analysis in General Vector Spaces, World Scientific, N.J. (2002)
23

