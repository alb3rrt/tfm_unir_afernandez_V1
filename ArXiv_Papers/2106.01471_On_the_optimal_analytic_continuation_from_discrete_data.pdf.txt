arXiv:2106.01471v1 [math.CV] 2 Jun 2021

On the optimal analytic continuation from discrete data
Narek Hovsepyan
Abstract
We consider analytic functions from a reproducing kernel Hilbert space. Given that such a function is of order  on a set of discrete data points, relative to its global size, we ask how large can it be at a fixed point outside of the data set. We obtain optimal bounds on this error of analytic continuation and describe its asymptotic behavior in . We also describe the maximizer function attaining the optimal error in terms of the resolvent of a positive semidefinite, self-adjoint and finite rank operator.
1 Introduction
Analytic functions are of central importance in many applied problems. They appear in diverse areas, such as medical imaging [9], nuclear physics [3, 4] and optimal design problems [19, 20]. For example Fourier (or Laplace) transforms of real-valued functions vanishing on negative semi-axis are analytic in the upper half-plane. Such functions describe linear, time-invariant and causal systems. Some concrete examples are the complex magnetic permeability and complex dielectric permittivity functions [18, 10], complex impedance and admittance functions of electrical circuits [2]. Further examples include transfer functions of digital filters [14], the dependence of effective moduli of composites on the moduli of its constituents [1, 26] etc.
Typically these functions can be measured only on a subset  of their domain of analyticity (or its boundary). During the measurement process unavoidable error occurs, as a result an analytic function is known on  up to a certain precision of order  > 0. In order to predict the behavior of the system and to expand its application horizon, often times one is interested in extrapolating from the measured data to a given point z lying outside of the data set . On one hand, working in the class of analytic functions we expect rigidity (in the sense that values of an analytic function on  affect its values elsewhere). On the other hand, recent work [7, 30, 16, 17] shows, that surprisingly there is also flexibility, meaning that the measured data can be matched up to the given precision  by two analytic functions that are very different outside of the data set.
Let S = S() denote a class of physically admissible functions that are analytic in a domain  of the complex plane. Aside from analyticity, the set S may also contain further physical restrictions (cf. [15]), such as certain symmetry constraints, asymptotic constraints at infinity or inequality constraints e.g. nonnegative imaginary parts (which can be interpreted as presence of energy loss in the system). Let    denote the data set
1

where the measurements are done with relative error , with respect to some norm ·  on . To quantify the flexibility of the class S we ask the following question: given two functions from S that are -close on  (relative to their total size on ), how much can they differ at a point z  \? Assume that the total size of a function on  is measured in some norm · , then we arrive at the quantity

z() = sup

|(z) - (z)| max(  ,  )

:

, 



S

with

- max(  ,




)



.

(1.1)

Another related quantity interesting in its own right, is the relative error of analytic continuation. Loosely speaking 1, consider the difference f =  -  and rescale it (say S is a cone) by the total norm of  and  on , assume also that S - S can be approximated by functions from some normed space H = H() of analytic functions in . We arrive at an analogous question: given that f  H is of order  on  and is of order 1 on , how large
can it be at the point z? So to quantify the stability of analytic continuation in the normed space H we introduce

Az() = sup {|f (z)| : f  H with f H  1, f   } .

(1.2)

In the setting of Hilbert spaces and when    is a curve with ·  denoting the L2()norm (with respect to the arclength measure) we analyzed (1.2) in [16, 17], where we derived optimal bounds for it and showed that it behaves like a power law: Az()  (z), where the exponent (z)  (0, 1) decreases to 0, as we move further away from the source of data. How
fast (z) decays depends strongly on the geometry of the domain and the data source. The
most common setting, where (1.2) is analyzed in the literature is in the space of bounded
analytic functions. The power law estimates are then derived from a maximum modulus
principle, the Hadamard three-circles theorem is a classical example of such estimate. For
related works we refer the reader to [6, 5, 25, 29, 12, 31, 13, 7, 30].
This paper is dedicated to the analysis of (1.2) in the Hilbert space setting, when  = {zj}n1 represents a finite set of distinct points, where the function values are measured. In this case ·  is a seminorm, so we use the notation [·] instead, and treating all the points equally we consider the l2-seminorm: [f ]2 = j |f (zj)|2. The first difference of the discrete setting vs. the continuum one is that in the former case an analytic function is
not determined uniquely by its values on , as a result Az() does not converge to zero as   0. So then the questions are what is Az(0) and what is the next term in the asymptotic expansion of Az(). The answer to the last question reveals the second key distinction of the discrete setting, showing that there is no fractional power of  and the correction term is of
order . Namely, we will characterize Az(0) (in terms of the reproducing kernel of the space H, cf. Theorem 2.1) and show that

Az() = (1 + )Az(0) + O(2),

(1.3)

1For a rigorous comparison of quantities (1.1) and (1.2) in the context of the complex electromagnetic permittivity function we refer to [15] (in this case S is a cone of functions that is related to HerglotzNevanlinna functions)

2

where  = (z) > 0 will depend on the space H and the data set . Note that the set
of values Vz() = {f (z) : f H  1, [f ]  } is a convex, centrally symmetric (c  Vz iff -c  Vz) subset of the complex plane, and Az() is its "radius", i.e. half of the diameter. The formula (1.3) then shows the relation between the radii Az(0), Az() of the original and perturbed function value sets, respectively.
The quantity (1.2) is also related to the optimal estimation of the point evaluation func-
tional f  f (z) (see [23, 24] and references therein for the general theory of optimal estima-
tions and optimal recovery). Following [23] let us formulate the question of optimal recovery. Let fj = f (zj) + j represent the erroneous measurement of the function value at the point zj for j = 1, ..., n. Assume, that the error is of order , namely let  = (1, ..., n) be the error vector and let ||  , where | · | is the Euclidean length of a vector in Cn. The task is to approximate f (z) at a fixed point z /  = {zj}n1 . The error of a linear estimation algorithm (it is enough to restrict consideration only to linear algorithms [22]) is then defined as

n
Ez(, c) = sup |f (z) - cj(f (zj) + j)| : f H  1, ||   ,
j=1

(1.4)

where c = (c1, ..., cn)  Cn is a given vector defining the linear algorithm and the supremum goes over all f  H and   Cn satisfying the above-mentioned constraints. The intrinsic
error of the estimation problem is

Ez ()

=

inf c

Ez (,

c).

(1.5)

Any algorithm achieving this infimum yields an optimal procedure for estimating f (z). Theorem 1 of [22] implies that

Az() = Ez().

(1.6)

Let us actually prove this equality using an idea from [11] (Section 7.5). The constraints in (1.4) are invariant under multiplying f and  with a constant phase factor, so instead of maximizing the absolute value in (1.4) we can equivalently maximize the real part. Next, applying von Neumann's minimax theorem [27] we obtain

n

n

Ez(, c) = inf sup e f (z) - cj(f (zj) + j) = sup inf e f (z) - cj(f (zj) + j) .

c f,

j=1

f, c

j=1

It remains to note that the inner infimum will be - unless f (zj) + j = 0 for all j. This implies that the supremum can be restricted to considering those f  H with f H  1 for which the choice j = -f (zj) can be made, which means that f must also satisfy the second
constraint || = [f ]  . This concludes the proof of (1.6). In [21] the authors analyze a quantity related to Ez(), namely in order to obtain
constructive results in (1.4) they replace the target functional with the square root of |f (z) - j cjf (zj)|2 + | j cjj)|2. The square of the replaced quantity is comparable to Ez() and hence also to Az(). In this work we take an alternative approach and analyze

3

Az() directly using variational methods and derive the asymptotic expansion result (1.3) that is analogous to that of [21] (see Theorem 4 therein). Further, we do not assume linear independence of the point evaluation functionals f  f (zj) for j = 1, ..., n. Moreover, we describe the maximizer function attaining the supremum in (1.2) via the resolvent of a positive semidefinite, self-adjoint and finite rank operator, which (by taking limits as   0) also allows us to obtain a characterization for Az(0).

2 The Main Result

Let H = H() be a Hilbert space of analytic functions in a domain   C. Assume that the
point evaluation functional f  f (z) is continuous for any point z  , then by the Riesz
representation theorem, there exists an element pz  H such that f (z) = (f, pz)H. So inner products with the function p(, z) := pz() reproduce values of a function in H. In this case H is called a a reproducing kernel Hilbert space (RKHS) with kernel p (cf. [28]). Examples of such spaces include the Hardy spaces H2, the Bergman spaces A2 etc. From now on let
us drop the subscript H from the notation of the norm and the inner product of H. Let z, z1, ..., zn   be distinct points and set [f ]2 = j |f (zj)|2. Consider the problem

Az() = sup {|f (z)| : f  H with f  1, [f ]  } .

(2.1)

Introduce the restriction operator R : H  Cn given by Rf = f := (f (z1), ..., f (zn)) and let K = RR (cf. [6]), then it is easy to see that

n
Kf = f (zj)pzj
j=1

(2.2)

and (Kf, g) = (f , g)Cn, in particular the second constraint of (2.1) can be rewritten via the quadratic form of K:

(Kf, f ) = [f ]2.

(2.3)

Clearly K is a self-adjoint, positive semidefinite and compact (in fact, finite rank) operator

on H. Set U0 = ker K 2, let {1, ..., m} be all distinct nonzero eigenvalues of K and set

Uj = ker(K - jI), j = 1, ..., m. Hence, H =

m j=0

Uj

,

and

let

Pj

:

H



Uj

denote

the

orthogonal projection onto the closed subspace Uj for j = 0, ..., m.

Theorem 2.1. With the notation introduced above and assuming pz / K(H), we have

Az() = (1 + )Az(0) + O(2), where, in fact Az(0) = P0pz and

2 =

1

m

P0pz 2 j=1

Pj pz j

2
.

2when {pzj } are linearly independent U0 = {f  H : f (z1) = ... = f (zn) = 0}

(2.4) (2.5)

4

Moreover, the maximizer function for Az() is given via the resolvent operator

Az ()

=

u(z u

)

,

u = (K + ())-1pz,

where  = () > 0 is the unique solution of the equation

(2.6)

2

m j=1

(j

- 2) (j +

Pj pz )2

2

= 2

P0pz

2.

In particular, ()  / as   0.

The proof of this theorem is based on [16, 15] with a few technical differences, so for completeness we will present the full argument here. Let us make a few remarks before presenting the proof:

1. In the formula (2.6) for Az() we can take limits as   0 and obtain (see Section 3)

Az (0)

=

P0 pz (z ) P0pz

=

P0pz .

In particular, the maximizer function for Az(0) is P0pz/ P0pz (note that the assumption pz / K(H) implies P0pz = 0).

2. Let G  Cn×n be the Gram matrix with Gjk = (pzj , pzk) = pzj (zk), then Kf = f implies that GT f = f . So {j}m1 are also eigenvalues of G, and after finding the corresponsing eigenvectors {fj}, from (2.2) we see that the eigenfunctions of K are linear combinations of the functions {pzj } with coefficients given by the eigenvectors.
For example, in the trivial case when there is only one data point z1 we have 1 = pz1 2, P0 = Id - P1 and

P1f =

f (z1) pz1 2

pz1

.

3. If pz  K(H), then Ku = pz for some u  H. This relation means that the value of any function at z is determined by its values at {zj}, indeed f (z) = j cjf (zj) for any f  H where we set cj = u(zj). So in this case we have complete stability: order  smallness on {zj} implies order  smallness at z. Indeed, applying the Cauchy-Schwartz inequality to f (z) and using that [f ]   we obtain

Az()  |c|,

c = (c1, ..., cn).

Such situations arise if we consider spaces that contain "boundary conditions". For example, S = {f  H : f (z) = f (z1)} is a closed subspace of H and hence is a RKHS in its own right, to which the above discussion applies.

5

3 Proof of Theorem 2.1

First consider the case pz  ker K. Let us show that Az() = Az(0) for any , and so (2.4) is satisfied with  = 0. Indeed, using the Cauchy-Schwartz inequality

|(f, pz)|  f pz  pz ,
giving the trivial bound Az()  pz . But this yields an optimal bound in this case, since the function f = pz/ pz satisfies both of the constraints and |f(z)| = pz , attains the upper bound.
So let us concentrate on the non-trivial case pz / ker K (this assumption is used later in the proof, namely in (3.8)).
The two constraints of (2.1) are invariant under multiplying f with a constant phase factor: if f satisfies the constraints, then so does f for any   C with || = 1. So instead of maximizing |f (z)| we can equivalently maximize ef (z). Using the reproducing kernel property and (2.3) we rewrite (2.1) as a convex maximization problem with a linear target functional and two quadratic constraints:

e(f, pz)  max 
(f, f )  1 (Kf, f )  2

(3.1)

Introduce Lagrange multiplies: nonnegative numbers µ and  such that µ +  = 0. Multiply the first constraint of (3.1) by µ, the second one by  and add the two inequalities to obtain

((µ + K)f, f )  µ + 2.

(3.2)

Now, if M is a uniformly positive definite self-adjoint operator on H, expanding (M(M-1g - f ), (M-1g - f ))  0, we obtain that for any f, g  H

2e(f, g) - (M-1g, g)  (Mf, f ).
The uniform positivity of M ensures that M-1 is defined on all of H. This is an example of convex duality (cf. [8]) applied to the convex function f  (Mf, f )/2. Then we also have for µ > 0, taking M = µ + K and g = pz in the above inequality we get

so that

2(f, pz) - (µ + K)-1pz, pz  ((µ + K)f, f )  µ + 2,

(3.3)

(f, pz)



1 2

(µ + K)-1pz, pz

+

1 2

µ + 2

,

(3.4)

which is valid for every f , satisfying the constraints of (3.1) and all µ > 0,   0. In order

for the bound to be optimal we must have equality in (3.3), which holds iff pz = (µ + K)f giving the formula for optimal function f :

f = (µ + K)-1pz.

(3.5)

6

The goal is to choose the Lagrange multipliers µ and  so that the constraints in (3.1) are satisfied by f , given by (3.5).

1. if  = 0, then f =

pz pz

does not depend on the small parameter , which leads to

a contradiction, because pz / ker K implies that (Kf, f ) > 0 and hence the second

constraint (Kf, f )  2 is violated if  is small enough.

2.

if µ = 0, then

Kf

=

1 

pz

,

contradicting

to

our

assumption

pz

/ K(H).

Thus we are looking for µ > 0,  > 0, so that equalities hold at both of the constraints for the function (3.5) (these are the complementary slackness relations in Karush-Kuhn-Tucker conditions.), i.e.

(µ + K)-1pz = 1,

(µ + K)-1pz = .

(3.6)

Let



=

µ 

,

solving

the

first

equation

of

(3.6)

for



we

find



=

(K + )-1pz . Then the

square of the second equation of (3.6) reads

() :=

[(K (K

+ +

 )-1 pz ]2 )-1pz 2

=

2.

(3.7)

Let us now use the spectral decomposition of K. Recall that PjPk = 0 if j = k and

further we also have

m

m

Id = Pj, and K = jPj,

j=0

j=1

m
K +  = P0 + (j + )Pj,
j=1

(K

+

)-1

=

-1P0

+

m j=1

Pj j +

.

Then writing the numerator of  as the quadratic form of K using (2.3) we get

m j Pj pz 2

() = -2

j=1
P0pz

(j 2+

+ )2
m Pjpz 2 j=1 (j + )2

.

Next our goal is to show that the equation (3.7) has a unique solution  = () > 0. Clearly, (0+) = 0 and

(+) =

[pz ]2 pz 2

=

(Kpz, pz) pz 2

>

0,

(3.8)

because pz / ker K. Therefore, showing that  is strictly increasing will imply that (3.7) has a unique solution for  small enough, namely for any 2 < (+). So let us prove that

7

() > 0. Set aj = Pjpz 2 for j = 0, ..., m, then the numerator of () (up to a factor of 2) can be simplified to

a0 3

j

2j aj (j + )2

+

j,k

jbjk(j - k),

(3.9)

where bjk = ajak/(j + )3(k + )3. In particular bjk = bkj, so splitting the second sum of (3.9) into parts where j > k, j < k and swapping the indices j, k in the second part we find

jbjk(j - k) = jbjk(j - k) + kbkj(k - j) = bjk(j - k)2.

j,k

j>k

j>k

j>k

Recalling that all j are distinct and positive we conclude that (3.9) is strictly positive (the value 0 is excluded since otherwise aj = 0 for all j = 1, ..., m implying that pz  ker K) and hence () > 0.
Observe that, ()  22 as   0, where  is given by (2.5). Hence for the solution of
the equation (3.7) we have ()  / as   0. Setting u = (K + ())-1pz, from (3.4) we obtain

e(f, pz)



(u, pz) 2u

+

u 2

(2 + ()).

Definitions of u and () imply that (Ku, u)/ u 2 = 2, on the other hand

u(z) = (u, pz) = (u, Ku + ()u) = (Ku, u) + () u 2 = (2 + ()) u 2, which implies the optimal bound

Thus

|f (z)| = (f, pz) 

u(z) 2u

+

u(z) 2u

=

u(z) u

.

Az() =

u(z) u

= [2 + ()]

u

.

It remain to analyze the asymptotic behavior of Az(). To that end, using the spectral decomposition of K, note that

but then

u

2 = ()-2a0 +

m j=1

(j

aj + ())2

,

A2z() =

1

+

2 ()

2

a0

+

[2

+

()]2

m j=1

(j

aj + ())2

.

8

Letting   0 in the last formula gives A2z(0) = a0. Finally, using the asymptotics of () we conclude that

A2z() = (1 + 2)A2z(0) + O(2),

which,

upon

using

the

expansion

 1+

x

=

1

+

x 2

+

O(x2)

for

small

x,

implies

the

relation

(2.4) and concludes the proof.

References
[1] D. J. Bergman. The dielectric constant of a composite material -- A problem in classical physics. Phys. Rep., 43:377­407, 1978.
[2] O. Brune. Synthesis of a finite two-terminal network whose driving-point impedance is a prescribed function of frequency. Journal of Mathematics and Physics, 10(1-4):191­236, 1931.
[3] I. Caprini. On the best representation of scattering data by analytic functions in L2norm with positivity constraints. Nuovo Cimento A (11), 21:236­248, 1974.
[4] I. Caprini. Integral equations for the analytic extrapolation of scattering amplitudes with positivity constraints. Nuovo Cimento A (11), 49(3):307­325, 1979.
[5] S. Ciulli. A stable and convergent extrapolation procedure for the scattering amplitude.--i. Il Nuovo Cimento A (1965-1970), 61(4):787­816, Jun 1969.
[6] P. Davis. An application of doubly orthogonal functions to a problem of approximation in two regions. Transactions of the American Mathematical Society, 72(1):104­137, 1952.
[7] L. Demanet and A. Townsend. Stable extrapolation of analytic functions. Foundations of Computational Mathematics, 19(2):297­331, 2018.
[8] I. Ekeland and R. Temam. Convex analysis and variational problems. North-Holland Publishing Co., Amsterdam, 1976. Translated from the French, Studies in Mathematics and its Applications, Vol. 1.
[9] C. L. Epstein. Introduction to the mathematics of medical imaging, volume 102. Siam, 2008.
[10] R. P. Feynman, R. B. Leighton, and M. Sands. The Feynman lectures on physics. Vol. 2: Mainly electromagnetism and matter. Addison-Wesley Publishing Co., Inc., Reading, Mass.-London, 1964.
[11] S. Fisher. Function Theory on Planar Domains: A Second Course in Complex Analysis. A Wieley-Interscience publication. Wiley, 1983.

9

[12] J. Franklin. Analytic continuation by the fast fourier transform. SIAM journal on scientific and statistical computing, 11(1):112­122, 1990.
[13] C.-L. Fu, Z.-L. Deng, X.-L. Feng, and F.-F. Dou. A modified tikhonov regularization for stable analytic continuation. SIAM Journal on Numerical Analysis, 47(4):2982­3000, 2009.
[14] B. Girod, R. Rabenstein, and A. Stenger. Signals and systems. Wiley,, 2001.
[15] Y. Grabovsky and N. Hovsepyan. On feasibility of extrapolation of the complex electromagnetic permittivity function using Kramer-Kronig relations. submitted.
[16] Y. Grabovsky and N. Hovsepyan. Explicit power laws in analytic continuation problems via reproducing kernel hilbert spaces. Inverse Problems, 36(3):035001, feb 2020.
[17] Y. Grabovsky and N. Hovsepyan. Optimal error estimates for analytic continuation in the upper half-plane. Communications on Pure and Applied Mathematics, 74(1):140­ 171, 2021.
[18] L. D. Landau and E. M. Lifshitz. Electrodynamics of continuous media, volume 8. Pergamon, New York, 1960. Translated from the Russian by J. B. Sykes and J. S. Bell.
[19] R. Lipton. An isoperimetric inequality for gradients of solutions of elliptic equations in divergence form with applicatuion to the design of two-phase heat conductors. to appear in SIAM J. Math. Anal.
[20] R. Lipton. Optimal inequalities for gradients of solutions of elliptic equations occuring in two-phase heat conductors. preprint.
[21] L. Maergoiz and A. Fedotov. Optimal error of analytic continuation from a finite set with inaccurate data in hilbert spaces of holomorphic functions. Siberian Mathematical Journal, 42:926­935, 2001.
[22] A. Marchuk and K. Osipenko. Best approximation of functions specified with an error at a finite number of points. Mathematical Notes of the Academy of Sciences of the USSR, 17:207---212, 1975.
[23] C. A. Micchelli and T. J. Rivlin. A Survey of Optimal Recovery, pages 1­54. Springer US, Boston, MA, 1977.
[24] C. A. Micchelli and T. J. Rivlin. Lectures on optimal recovery. In P. R. Turner, editor, Numerical Analysis Lancaster 1984, pages 21­93, Berlin, Heidelberg, 1985. Springer Berlin Heidelberg.
[25] K. Miller. Least squares methods for ill-posed problems with a prescribed bound. SIAM Journal on Mathematical Analysis, 1(1):52­74, 1970.
[26] G. W. Milton. Bounds on complex dielectric constant of a composite material. Appl. Phys. Lett., 37(3):300­302, 1980.
10

[27] H. Nikaido. On von neumann's min--max theorems. Pacific Journal of Mathematics, 4:65­70, 1954.
[28] V. I. Paulsen and M. Raghupathi. An introduction to the theory of reproducing kernel Hilbert spaces, volume 152. Cambridge University Press, 2016.
[29] L. E. Payne. Improperly posed problems in partial differential equations, volume 22. Siam, 1975.
[30] L. N. Trefethen. Quantifying the ill-conditioning of analytic continuation. arXiv preprint arXiv:1908.11097, 2019.
[31] S. Vessella. A continuous dependence result in the analytic continuation problem. Forum Mathematicum, 11(6):695­703, 1999.
11

