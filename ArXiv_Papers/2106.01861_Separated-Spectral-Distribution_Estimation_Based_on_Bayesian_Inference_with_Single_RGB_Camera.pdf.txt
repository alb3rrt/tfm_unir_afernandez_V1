SEPARATED-SPECTRAL-DISTRIBUTION ESTIMATION BASED ON BAYESIAN INFERENCE WITH SINGLE RGB CAMERA
Yuma Kinoshita and Hitoshi Kiya
Tokyo Metropolitan University, Tokyo, Japan

arXiv:2106.01861v1 [eess.IV] 1 Jun 2021

ABSTRACT
In this paper, we propose a novel method for separately estimating spectral distributions from images captured by a typical RGB camera. The proposed method allows us to separately estimate a spectral distribution of illumination, reflectance, or camera sensitivity, while recent hyperspectral cameras are limited to capturing a joint spectral distribution from a scene. In addition, the use of Bayesian inference makes it possible to take into account prior information of both spectral distributions and image noise as probability distributions. As a result, the proposed method can estimate spectral distributions in a unified way, and it can enhance the robustness of the estimation against noise, which conventional spectral-distribution estimation methods cannot. The use of Bayesian inference also enables us to obtain the confidence of estimation results. In an experiment, the proposed method is shown not only to outperform conventional estimation methods in terms of RMSE but also to be robust against noise.
Index Terms-- Bayesian inference, camera sensitivity, illumination, reflectance, spectral distribution
1. INTRODUCTION
Spectral distributions of illumination, the reflectance of objects, and camera sensitivity play an important role in color image processing. They decide the color of pixel values in images captured by digital cameras. Spectral distribution is a function of wavelengths and describes what wavelengths of light are included in illumination, reflected by objects, or detected by imaging sensors. Knowledge on spectral distributions is essential for many computer vision tasks that use color information, such as hyperspectral imaging [1, 2], color constancy [3­8], color image enhancement [9­12], and intrinsic image decomposition [13­16].
Spectral distributions are often measured with specialized devices. Hyperspectral cameras are available for capturing a joint spectral distribution of a scene, but the captured distribution is usually not separated into illuminance, reflectance, and sensitivity. In addition, these cameras require line scans
This work was supported by JSPS KAKENHI Grant Number JP18J20326.

to capture images. For separately measuring reflectance or camera sensitivity, a monochromator that generates narrowband light and a spectrophotometer that measures the spectral power distribution of this light are generally required. The requirement of specialized devices, including hyperspectral cameras, has become a hurdle for estimating spectral distributions because these devices are not easy to carry around and are high-cost.
For this reason, methods of estimating spectral distributions with low-cost equipment such as color checkers and commonly used digital cameras have been proposed [17­19]. Although Han's and Fu's methods still require a specialized color checker or additional light sources, Jiang's method [19] can effectively estimate camera spectral sensitivity by using only a typical color checker and a camera. However, Jiang's method is not available for estimating reflectance because it uses an algorithm specifically designed for camera sensitivity estimation to incorporate prior information of spectral distributions [20]. The simple least-squares method can estimate illumination, reflectance, or sensitivity, but this method suffers from noise in images.
Therefore, in this paper, we propose a novel method for separately estimating a spectral distribution of illumination, reflectance, or camera sensitivity, from an image of a color checker captured by a commonly used digital camera. The use of Bayesian inference in the method makes it possible to take into account prior information of both spectral distributions and image noise as probability distributions. As a result, the proposed method enables us not only to estimate spectral distributions in a unified way but also to improve the robustness of the estimation against noise. In addition, we can obtain the confidence of the estimation results.
We performed a numerical simulation to evaluate the performance of the proposed method. The method was compared with a simple least-squares-based method and Jiang's camerasensitivity estimation method. The experimental results show that the proposed method outperformed the two conventional methods in terms of the root mean squared error (RMSE) between each estimation and the corresponding ground truth. The proposed method can also be used to estimate both illumination and sensitivity as well as the least-squares method can and is demonstrated to be more robust against noise than the least-squares method.

1.0

1.0

1.0

Sum Pixel value ,,

0 400 Wavelength 700
Illumination 

0 400 Wavelength 700
Reflectance 

0 400 Wavelength 700
Sensitivity 

Fig. 1. Imaging pipeline of digital camera

2. PRELIMINARY
In this section, we briefly summarize the imaging pipeline from spectral distributions to the pixel values of typical digital cameras. After that, we describe problems in estimating spectral distributions and clarify our aim.
2.1. Imaging pipeline
Under the assumption that objects have Lambertian reflectance, pixel values captured by a digital camera can be calculated by using spectral distributions of illumination, reflectance, and camera sensitivity (see Fig. 1). The mapping from spectral distributions into pixel values xi,j,k is written as:

xi,j,k = Ei()Rj ()Ck()d,

(1)

D

where  means a wavelength of light, D is a set of wavelengths of visible light, Ei() is the i  {1, · · · , I}-th illumination, Rj() is the j  {1, · · · , J}-th reflectance, and Ck() is the k  {1, · · · , K}-th sensitivity. When we capture an image of a color checker having 4 × 6 patches by using a single RGB camera under daylight, I, J, and K are 1, 24, and 3, respectively.
By sampling spectral distributions along the wavelength axis, eq. (1) can be approximated by the following discrete form.

xi,j,k = tr(diag(ei)diag(rj)diag(ck)),

(2)

where ei, rj, and ck are N -dimensional column vectors that denote sampled distributions of Ei, Rj, and Ck, respectively, and N indicates the number of discrete wavelengths.

2.2. Scenario

Our aim in this paper is to separately estimate a spectral

distribution of illumination, reflectance, or sensitivity [i.e., Ei(), Rj(), or Ck()] from pixel values xi,j,k under the condition that the other two spectral distributions are given. In contrast, a hyperspectral camera having a large number K

of channels aims to capture a multiplied spectral distribution Ei()Rj() when the camera sensitivity Ck() is given.

Let us consider a situation in which we want to estimate illumination ei from given reflectance rj, sensitivity ck, and the corresponding pixel values xi,j,k. In this situation, the simplest way is to use least squares as

e^i = arg min xi - Mr,ce 2,

(3)

e

where e^i is an estimation of ei. Vector xi is given as

xi = (xi,1,1, xi,1,2, · · · , xi,J,K ),

(4)

and matrix Mr,c is calculated by using the Hadamard product as

Mr,c = (r1 c1, r1 c2, · · · , rJ cK ) . (5)

Similarly to the case of illumination, the least-squares method can also estimate reflectance or sensitivity. In practice, however, the direct inversion in eq. (3) cannot reliably recover a spectral distribution because it is quite sensitive to noise and the spectral reflectance of real-world objects has low intrinsic dimensionality, as pointed out in [19].

To improve the estimation accuracy, research has been devoted to analyzing the characteristics of spectral distributions and to incorporating these characteristics as prior information in the estimation. Judd et al. analyzed the spectral distributions of daylight and found that they can be written as the sum of daylight's mean spectral distribution and two other bases [20]. Jiang et al. proposed a camera-spectral-sensitivity estimation method using prior information by which camera sensitivity can be approximated by using two bases obtained by principal component analysis on a set of spectral distributions of 28 camera sensitivities [19]. Jiang's method works better than the least-squares method. However, its dedicated algorithm for incorporating prior information makes the method specialized only for camera sensitivity estimation.

For this reason, we propose a novel spectral-distribution estimation method based on Bayesian inference.

3. PROPOSED METHOD

The proposed Bayesian-inference-based spectraldistribution estimation method separately estimates the spectral distribution of illumination, reflectance, or sensitivity from pixel values xi,j,k. The method enables us to:
· Estimate illumination, reflectance, or sensitivity separately in a unified way,
· Enhance the robustness of the estimation against noise by incorporating prior information of noise as probability distributions, and
· Obtain the confidence of estimation results as a precision matrix.

3.1. Estimating spectral distribution by Bayesian inference

Let us consider a situation in which illumination is estimated from given reflectance, sensitivity, and pixel values. The goal of the estimation is to calculate the posterior distribution of the p(ei|X, R, C) of ei, where X = {xi,j,k}, R = {rj}, and C = {ck}. To estimate p(ei|X, R, C), we assume a prior probability distribution p(ei) of ei and a probability

distribution p(xi,j,k|ei, rj, ck) of xi,j,k (i.e., likelihood) as

p(ei) = N (ei|µei , -ei1),

(6)

p(xi,j,k|ei, rj , ck)

= N (xi,j,k|tr(diag(ei)diag(rj)diag(ck)), -1), (7)

respectively, where the mean vector µei , the precision matrix ei , and the precision  are hyperparameters. Equation (7)
corresponds to an image noise model.

On the basis of the Bayesian theorem, p(ei|X, R, C) is given by

p(ei|X, R, C)  p(X|ei, R, C)p(ei).

(8)

Here,

p(X|ei, R, C) = p(xi,j,k|ei, rj, ck).

(9)

j,k

Taking the logarithm of p(ei|X, R, C), we obtain

ln p(ei|X, R, C)

= ln p(X|ei, R, C) + ln p(ei) + const.





1 = - 2 ei ei +  diag(sj)ckck diag(sj) ei
j,k





+ ei ei µei +  xi,j,kdiag(sj )ck
j,k

+ const.

(10)

From eq. (10), it is confirmed that the posterior dis-
tribution p(ei|X, R, C) follows a Gaussian distribution N (ei|µ^ ei , ^ ei ). The mean µ^ ei and precision ^ ei of the posterior distribution are given as

^ ei = ei -  diag(rj)ckck diag(rj),

(11)

j,k





µ^ ei = ^ ei ei µei +  xi,j,kdiag(rj )ck . (12)
j,k

Similarly to the case of illumination, we can estimate the posterior probability distribution p(rj|X, E, C) of reflectance from illumination, sensitivity, and pixel values as

^ rj = rj -  diag(ck)eiei diag(ck),

(13)

k,i





µ^ rj = ^ rj rj µrj +  xi,j,kdiag(ck)ei , (14)
k,i

or we can estimate the posterior probability distribution p(ck|X, E, R) of sensitivity from illumination, reflectance,

and pixel values as

^ ck = ck -  diag(ei)rjrj diag(ei),

(15)

i,j





µ^ ck = ^ ck ck µck +  xi,j,kdiag(ei)rj  . (16)
i,j

3.2. Incorporating prior information into estimation

Incorporating prior information of spectral distributions into the proposed estimation method is simply done by modifying the mean and the precision matrix for the prior distributions p(ei), p(rj), and p(ck). For example, we can use the mean spectral distribution e of daylight in [20] as

µei = e.

(17)

In addition, the mean spectral distribution ck of the 28 RGB

camera sensitivities in [20] can be utilized as

µck = ck.

(18)

Incorporating prior information of image noise into the

proposed estimation method is similarly done by modifying

the mean and the precision for p(xi,j,k|ei, rj, ck).

3.3. Proposed procedure

The procedure for estimating illumination ei by using the proposed method is as follows

1. Set hyperparameters for prior distributions in eqs. (6)

and (7), where prior information of illumination can be

incorporated such as in eq. (17). 2. Calculate the mean µ^ ei and the precision matrix ^ ei of
the posterior distribution p(ei|X, R, C) in accordance
with eqs. (11) and (12) by using X, R, and C.

3. Obtain an estimation by normalizing the mean µ^ ei as

e^i

=

µ^ ei , max ei,n

(19)

n

where ei,n indicates the n-th element of ei.

Note that the calculated posterior distribution p(ei|X, R, C) can be used as the prior distribution p(ei) for the next estimation. This enables the estimation to be updated each time

a new observation (i.e., captured image) is obtained. In addition, ^ ei can be considered as the confidence of the estimation. Reflectance rj and sensitivity ck can be estimated in the
same way as for illumination [see eqs. (11) to (16)].

4. SIMULATION

To confirm the effectiveness of the proposed method, we conducted a simulation.

4.1. Simulation conditions

In this simulation, we calculated pixel values from the spectral distributions shown in Fig. 2 in accordance with eq. (2), where the illumination was from the spectral distribution of the CIE Standard Illuminant D65, the reflectance was from a color checker manufactured by BabelColor [21], and the camera sensitivity was that of the Nikon 5100 in [22]. In addi-

Illumination Reflectance Sensitivity

1.0 0.9 0.8 0.7 0.6
400 450 500Wa5v5e0leng6th00 650 700

1.0 0.8 0.6 0.4 0.2
400 450 500Wa5v5e0leng6th00 650 700

1.0

R

G

0.8

B

0.6

0.4

0.2

0.0 400 450 500Wa5v5e0leng6th00 650 700

(a) Illumination

(b) Reflectance

(c) Sensitivity

Fig. 2. Ground truth for spectral distribution

1.0

1.0

0.9

0.9

0.8

0.8

0.7

0.7

0.6 400 450 500Wa5v5e0leng6th00 650 700

0.6 400 450 500Wa5v5e0leng6th00 650 700

(a) Least squares

(b) Proposed

Fig. 3. Estimated illumination

Illumination Illumination

tion, we added Gaussian noise with a mean of 0 and a standard deviation of 0.01 into the calculated pixel values xi,j,k. Assuming a situation in which the illumination is unknown, we estimated the illumination by using the reflectance, sensitivity, and pixel values. Similarly to the illumination, we also estimated the sensitivity from the illumination, reflectance, and pixel values. The estimation accuracy of the proposed method was evaluated by using the well-known root mean squared error (RMSE) between the estimation and the corresponding ground truth.
Although there are advanced spectral-distribution estimation methods such as [17, 18], they require a specialized color checker or light source. For this reason, we compared the proposed method with the least-squares method shown in eq. (3) and with Jiang's high-performance method that requires no special equipment [19]. Here, we used Jiang's method only for estimating sensitivity since Jiang's method is not designed for estimating illumination when sensitivity is given.
4.2. Results
Figure 3 shows spectral distributions of the illumination estimated by using the least-squares and proposed methods in the case where pixel values had no noise. Both methods estimated the illumination well.
Figure 4 shows spectral distributions of the sensitivity estimated by using the three methods for the case that pixel values had no noise. As shown in Fig. 4(a), least squares provided an estimation that was not smooth even under the noiseless case, but Jiang's method and the proposed method provided smooth distributions. This is because the number of available pixel values for estimating sensitivity was less than that for estimating illumination, i.e., I × J < J × K in this case.
RMSE scores for the three methods in the case of no noise and noise with the standard deviation of 0.01 are shown in Tables 1 and 2, respectively. From the tables, it is confirmed that

Sensitivity Sensitivity Sensitivity

1.0

R

G

0.8

B

0.6

0.4

0.2

0.0 400 450 500Wa5v5e0leng6th00 650 700

1.0

R

G

0.8

B

0.6

0.4

0.2

0.0 400 450 500Wa5v5e0leng6th00 650 700

1.0

R

G

0.8

B

0.6

0.4

0.2

0.0 400 450 500Wa5v5e0leng6th00 650 700

(a) Least squares

(b) Jiang [19]

(c) Proposed

Fig. 4. Estimated sensitivity

Table 1. RMSE scores (w/o noise)

Least squares Jiang [19] Proposed

Illumination

0.000

--

0.019

Sensitivity R

0.041

0.064

0.043

Sensitivity G

0.041

0.043

0.020

Sensitivity B

0.019

0.034

0.040

Table 2. RMSE scores (w/ additive Gaussian noise having

std. of 0.01)

Least squares Jiang [19] Proposed

Illumination Sensitivity R Sensitivity G Sensitivity B

0.580 0.149 0.256 0.168

-- 0.064 0.042 0.034

0.018 0.043 0.020 0.040

the proposed method and Jiang's method were robust against noise, but the least-squares method was not.
For these reasons, the effectiveness of the proposed method was confirmed in terms of RMSE. The proposed method was also demonstrated to be robust against noise and to achieve accuracy comparable to Jiang's recent effective method. Furthermore, the proposed method can estimate illumination, reflectance, or sensitivity in a unified way, while Jiang's method is specialized only for estimating sensitivity.
5. CONCLUSION
In this paper, we proposed a novel method for separately estimating a spectral distribution of illumination, reflectance, or sensitivity from images of a color checker captured by a single RGB camera. By using Bayesian inference in the method, prior information of both spectral distributions and image noise can be incorporated into the estimation. As a result, the method enables us not only to estimate spectral distributions in a unified way but also to improve the robustness of the estimation against noise. The method also has other advantages of Bayesian inference, i.e., obtaining the confidence of estimation. Experimental results showed that the proposed method can correctly estimate spectral distributions even under a noisy condition.
In future work, we will extend the proposed method to estimate both illumination and sensitivity at the same time from pixel values and reflectance. Moreover, we will apply a more realistic noise model to the proposed method.

6. REFERENCES
[1] J.-I. Park, M.-H. Lee, M. D. Grossberg, and S. K. Nayar, "Multispectral Imaging Using Multiplexed Illumination," in Proceedings of IEEE International Conference on Computer Vision, Oct. 2007, pp. 1­8.
[2] S. Tominaga, "Spectral imaging by a multichannel camera," Journal of Electronic Imaging, vol. 8, no. 4, p. 332, Oct. 1999.
[3] D. H. Brainard and W. T. Freeman, "Bayesian color constancy," Journal of the Optical Society of America A, vol. 14, no. 7, pp. 1393­1411, 1997.
[4] A. Gijsenij, T. Gevers, and J. van de Weijer, "Computational Color Constancy: Survey and Experiments," IEEE Transactions on Image Processing, vol. 20, no. 9, pp. 2475­2489, Sep. 2011.
[5] D. Cheng, B. Price, S. Cohen, and M. S. Brown, "Beyond White: Ground Truth Colors for Color Constancy Correction," in Proceedings of IEEE International Conference on Computer Vision, Dec. 2015, pp. 298­306.
[6] M. Afifi, B. Price, S. Cohen, and M. S. Brown, "When Color Constancy Goes Wrong: Correcting Improperly White-Balanced Images," in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, Jun. 2019, pp. 1535­1544.
[7] P. Das, A. S. Baslamisli, Y. Liu, S. Karaoglu, and T. Gevers, "Color Constancy by GANs: An Experimental Survey," Dec. 2018. [Online]. Available: http://arxiv.org/abs/1812.03085
[8] M. Afifi and M. S. Brown, "Deep White-Balance Editing," in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, Jun. 2020, pp. 1394­1403.
[9] Y. Ueda, H. Misawa, T. Koga, N. Suetake, and E. Uchino, "Hue-Preserving Color Contrast Enhancement Method Without Gamut Problem by Using Histogram Specification," in Proceedings of IEEE International Conference on Image Processing, Oct. 2018, pp. 1123­1127.
[10] Y. Kinoshita and H. Kiya, "Automatic exposure compensation using an image segmentation method for single-image-based multi-exposure fusion," APSIPA Transactions on Signal and Information Processing, vol. 7, no. e22, Dec. 2018.
[11] Y. Kinoshita and H. Kiya, "Scene Segmentation-Based Luminance Adjustment for Multi-Exposure Image Fusion," IEEE Transactions on Image Processing, vol. 28, no. 8, pp. 4101­4116, Aug. 2019.
[12] Y. Kinoshita and H. Kiya, "Hue-Correction Scheme Based on Constant-Hue Plane for Deep-Learning-Based Color-Image Enhancement," IEEE Access, vol. 8, pp. 9540­9550, Jan. 2020.

[13] B. Cai, X. Xu, K. Guo, K. Jia, B. Hu, and D. Tao, "A Joint Intrinsic-Extrinsic Prior Model for Retinex," in Proceedings of IEEE International Conference on Computer Vision, Oct. 2017, pp. 4020­4029.
[14] Z. Li and N. Snavely, "Learning Intrinsic Image Decomposition from Watching the World," in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, Jun. 2018, pp. 9039­9048.
[15] Y. Liu, Y. Li, S. You, and F. Lu, "Unsupervised Learning for Intrinsic Image Decomposition from a Single Image," in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, Jun. 2020, pp. 3245­3254.
[16] K. Seo, Y. Kinoshita, and H. Kiya, "Deep Retinex Network for Estimating Illumination Colors with SelfSupervised Learning," in Proceedings of IEEE Global Conference on Life Sciences and Technologies, Mar. 2021, pp. 1­5.
[17] Shuai Han, Y. Matsushita, I. Sato, T. Okabe, and Y. Sato, "Camera spectral sensitivity estimation from a single image under unknown illumination by using fluorescence," in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, Jun. 2012, pp. 805­812.
[18] Y. Fu, A. Lam, I. Sato, T. Okabe, and Y. Sato, "Reflectance and Fluorescence Spectral Recovery via Actively Lit RGB Images," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 38, no. 7, pp. 1313­1326, Jul. 2016.
[19] J. Jiang, D. Liu, J. Gu, and S. Susstrunk, "What is the space of spectral sensitivity functions for digital color cameras?" in Proceedings of IEEE Workshop on Applications of Computer Vision, Jan. 2013, pp. 168­179.
[20] D. B. Judd, D. L. MacAdam, G. Wyszecki, H. W. Budde, H. R. Condit, S. T. Henderson, and J. L. Simonds, "Spectral Distribution of Typical Daylight as a Function of Correlated Color Temperature," Journal of the Optical Society of America, vol. 54, no. 8, p. 1031, Aug. 1964.
[21] "BabelColor." [Online]. Available: https://www. babelcolor.com/colorchecker-2.htm
[22] T. Mansencal, M. Mauderer, M. Parsons, N. Shaw, K. Wheatley, S. Cooper, J. D. Vandenberg, L. Canavan, K. Crowson, O. Lev, K. Leinweber, S. Sharma, T. J. Sobotka, D. Moritz, M. Pppp, C. Rane, P. Eswaramoorthy, J. Mertic, B. Pearlstine, M. Leonhardt, O. Niemitalo, M. Szymanski, M. Schambach, S. Huang, M. Wei, N. Joywardhan, O. Wagih, P. Redman, J. Goldstone, and S. Hill, "Colour 0.3.16," [Online]. Available: https://doi.org/10.5281/zenodo. 3757045#.X zJFXCo-EY.mendeley

