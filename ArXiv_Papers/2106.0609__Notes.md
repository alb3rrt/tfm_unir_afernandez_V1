
# Robust Mutual Learning for Semi-supervised Semantic Segmentation

[arXiv](https://arxiv.org/abs/2106.0609), [PDF](https://arxiv.org/pdf/2106.0609.pdf)

## Authors

- Pan Zhang
- Bo Zhang
- Ting Zhang
- Dong Chen
- Fang Wen

## Abstract

Recent semi-supervised learning (SSL) methods are commonly based on pseudo labeling. Since the SSL performance is greatly influenced by the quality of pseudo labels, mutual learning has been proposed to effectively suppress the noises in the pseudo supervision. In this work, we propose robust mutual learning that improves the prior approach in two aspects. First, the vanilla mutual learners suffer from the coupling issue that models may converge to learn homogeneous knowledge. We resolve this issue by introducing mean teachers to generate mutual supervisions so that there is no direct interaction between the two students. We also show that strong data augmentations, model noises and heterogeneous network architectures are essential to alleviate the model coupling. Second, we notice that mutual learning fails to leverage the network's own ability for pseudo label refinement. Therefore, we introduce self-rectification that leverages the internal knowledge and explicitly rectifies the pseudo labels before the mutual teaching. Such self-rectification and mutual teaching collaboratively improve the pseudo label accuracy throughout the learning. The proposed robust mutual learning demonstrates state-of-the-art performance on semantic segmentation in low-data regime.

## Comments



## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{zhang2021robust,
      title={Robust Mutual Learning for Semi-supervised Semantic Segmentation}, 
      author={Pan Zhang and Bo Zhang and Ting Zhang and Dong Chen and Fang Wen},
      year={2021},
      eprint={2106.00609},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

## Notes

Type your reading notes here...

