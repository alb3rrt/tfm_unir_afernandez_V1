BAYESIAN AGENCY: LINEAR VERSUS TRACTABLE CONTRACTS

ARXIV PREPRINT

Matteo Castiglioni Politecnico di Milano matteo.castiglioni@polimi.it

Alberto Marchesi Politecnico di Milano alberto.marchesi@polimi.it

Nicola Gatti Politecnico di Milano nicola.gatti@polimi.it

arXiv:2106.00319v1 [cs.GT] 1 Jun 2021

June 2, 2021
ABSTRACT
We study principal-agent problems in which a principal commits to an outcome-dependent payment scheme (a.k.a. contract) so as to induce an agent to take a costly, unobservable action. We relax the assumption that the principal perfectly knows the agent by considering a Bayesian setting where the agent's type is unknown and randomly selected according to a given probability distribution, which is known to the principal. Each agent's type is characterized by her own action costs and action-outcome distributions. In the literature on non-Bayesian principal-agent problems, considerable attention has been devoted to linear contracts, which are simple, pure-commission payment schemes that still provide nice approximation guarantees with respect to principal-optimal (possibly non-linear) contracts. While in non-Bayesian settings an optimal contract can be computed efficiently, this is no longer the case for our Bayesian principal-agent problems. This further motivates our focus on linear contracts, which can be optimized efficiently given their single-parameter nature. Our goal is to analyze the properties of linear contracts in Bayesian settings, in terms of approximation guarantees with respect to optimal contracts and general tractable contracts (i.e., efficiently-computable ones).
First, we study the approximation guarantees of linear contracts with respect to optimal ones, showing that the former suffer from a multiplicative loss that grows linearly in the number of agent's types. Nevertheless, we prove that linear contracts can still provide a constant multiplicative approximation  of the optimal principal's expected utility, though at the expense of an exponentially-small additive loss 2-(). Then, we switch to tractable contracts, showing that, surprisingly, linear contracts perform well among them. In particular, we prove that it is NP-hard to design a contract providing a multiplicative loss sublinear in the number of agent's types, while the same holds for contracts that provide a constant multiplicative approximation  at the expense of an additive loss 2-(). We conclude by showing that, in Bayesian principal-agent problems, an optimal contract can be computed efficiently if we fix either the number of agent's types or the number of outcomes.
1 Introduction
Principal-agent problems are ubiquitous in real-world economies. These problems model interactions between two parties, a principal and an agent, where the latter chooses an action that determines some externalities on the former. We focus on hidden-action models, where the principal cannot observe the action taken by the agent, but only a stochastic outcome that is probabilistically determined as a result of the agent's action. Each action is associated with a corresponding cost for the agent, while the principal receives a reward for the resulting outcome. As a result, the principal's objective is to incentive an agent's action that leads to favorable outcomes. This is achieved by committing to an outcome-dependent payment scheme, usually called contract.
Principal-agent problems are pervasive in classical economic scenarios. A well-known textbook example of principalagent problem is that of a salesperson (agent) working for a company (principal). The former has to decide on the level of effort she wants to put in selling products for the company. Naturally, the company cannot observe the chosen level of effort (action), but it is only aware of the number of products sold. Assuming that this figure is correlated with the

ARXIV PREPRINT - JUNE 2, 2021
level of effort selected by the salesperson, the company can incentivize an high level of effort by paying a commission to the salesperson based on the actual number of sales.
Interactions involving a principal and an agent play a crucial role also in modern economies centered around digital means. In spite of this, principal-agent problems received far less attention from the economics and computation community than auctions and, more in general, mechanism design problems (more details on related computational works appear later in this section). Remarkably, principal-agent models may have potential applications in various real-world settings, such as, e.g., crowdsourcing platforms (Ho et al., 2016), blockchain-based smart contracts (Cong and He, 2019), and healthcare (Bastani et al., 2016).
In this paper, we study a generalization of the classical hidden-action principal-agent problem. In particular, we relax the assumption that the principal perfectly knows the agent by considering a Bayesian setting in which the agent's type is unknown and randomly selected according to a given probability distribution, which is known to the principal. Each agent's type is characterized by her own action costs and action-outcome distributions. In the salesperson example, types may correspond to different skill profiles for the salesperson, e.g., a clever worker can achieve better sales results than a non-clever one by putting the same level of effort in her work.
In the literature on principal-agent problems, considerable attention has been devoted to linear contracts (see, e.g., Carroll (2015, 2019); Dütting et al. (2019)), which are pure-commission payment schemes that pay the agent a given fraction of the principal's reward associated with the obtained outcome. These contracts enjoy some nice properties. In particular, they are simple to understand--given their single-parameter nature--and, in non-Bayesian settings, they still provide good approximation guarantees with respect to a principal-optimal (possibly non-linear) contract (Dütting et al., 2019). While in non-Bayesian principal-agent problems an optimal contract can be computed efficiently by using a linear program, this is no longer the case in our Bayesian setting. This further motivates our focus on linear contracts, which can be optimized efficiently given their single-parameter nature.

1.1 Original Contributions

The main goal of our work is to analyze the properties of linear contracts in Bayesian principal-agent settings, in order to understand their approximation guarantees with respect to optimal contracts and tractable ones, with the latter being defined as those that can be computed efficiently (i.e., in polynomial time). In particular, we look at approximations of the principal's expected utility. Notice that, while optimal contracts are a natural benchmark in any principal-agent problem, the comparison with tractable contracts becomes relevant and fundamental in our Bayesian model, where an optimal contract cannot be computed efficiently, and, thus, the most natural benchmark is the family of all contracts that can be computed in polynomial time.

After introducing all the required preliminary concepts in Section 2, we start our analysis by studying, in Section 3, the

approximation guarantees of linear contracts with respect to optimal ones in Bayesian principal-agent problems. We

show that, from a purely-multiplicative approximation perspective, linear contracts suffer from a loss with respect to

an optimal contract that grows linearly in the number of agent's types. This happens in degenerate instances in which

the principal's rewards are exponentially small in the number of agent's types, thus suggesting that there is hope linear

contracts could obtain a constant multiplicative approximation, at the expense of an exponentially-small additive loss.

This motivates the introduction of , g() -bi-approximate contracts, which are those providing the principal with

an

expected

utility

at

least

OP T 

- g(),

where

OP T

is the

principal's expected utility

in an

optimal

contract.

Our

main result is that linear contracts give a , 2-() -bi-approximation of an optimal contract, i.e., they guarantee a

constant multiplicative approximation  of the optimal principal's expected utility, at the expense of an exponentially-

small additive loss 2-(). We complement this result by showing that no linear contract can provide a , 2-() -

approximation of an optimal one, even in non-Bayesian settings. This implies that, using linear contracts, we can only

obtain bi-approximations whose additive losses decrease at most exponentially in the multiplicative factor . Notice

that our bi-approximation results also hold for the basic non-Bayesian case, complementing known approximation

results of linear contracts in such setting (Dütting et al., 2019) (see the related works for more details).

Then, in Section 4, we focus on the performances of linear contracts with respect to tractable ones in Bayesian settings, showing that, surprisingly, they perform well. In particular, we show that there is no tractable contract providing a constant multiplicative loss with respect to an optimal one. Formally, we prove that it is NP-hard to design a contract with a multiplicative loss sublinear in the number of agent's types. Then, we study the approximation guarantees of tractable contracts in terms of bi-approximations. We prove that it is NP-hard to design a contract that provides a , 2-() -bi-approximation of an optimal one, thus matching the lower bound of linear contracts.

2

ARXIV PREPRINT - JUNE 2, 2021
We conclude with Section 5, where we show that there are some special cases of our Bayesian principal-agent problem in which an optimal contract can be computed in polynomial time. In particular, this happens if we fix either the number of agent's types or the number of outcomes.
1.2 Related Works
Hidden-action principal-agent problems have received considerable attention in the economic literature, where they usually fall under the umbrella of a broader subject called contract theory, which is a fundamental pillar of microeconomic theory (Shavell, 1979; Grossman and Hart, 1983; Rogerson, 1985; Holmstrom and Milgrom, 1991) (see the books by Mas-Colell et al. (1995), Bolton et al. (2005), and Laffont and Martimort (2009) for a detailed treatment of the subject).
The first computational studies on principal-agent problems appeared only recently. Among them, it is worth discussing in detail that of Dütting et al. (2019), which is perhaps the most related to ours. Dütting et al. (2019) study non-Bayesian principal-agent problems (i.e., a special case of our setting having only one agent's type), with a focus on linear contracts. In particular, they show that linear contracts provide a constant multiplicative approximation of the principal's expected utility in an optimal contract, except in degenerate instances having the following three properties simultaneously: there are many agent's actions, there is a big spread of rewards, and there is a big spread of costs. Moreover, the results of Dütting et al. (2019) are tight. In our work, we extend this comparison between linear and optimal contracts to our Bayesian settings. However, apart from that, our work considerably departs from (Dütting et al., 2019), since our main focus is on understanding the performances of linear contracts with respect to tractable ones. Notice that this is not a concern for Dütting et al. (2019), since, differently from the Bayesian setting, an optimal contract can be computed efficiently in classical (non-Bayesian) principal-agent problems.
There is a number of other computational works that study extensions of classical hidden-action principal-agent problems exhibiting some sort of combinatorial structure. For instance, the work of Babaioff et al. (2006) studies a model with multiple agents (see also its extended version (Babaioff et al., 2012) and its follow-ups (Babaioff et al., 2009, 2010)). Its focus is on how complex combinations of agents' actions influence the resulting outcome in presence of inter-agent externalities, while in our model there is only one agent that can be of different types, and, thus, no externalities among agent's types are involved. Moreover, Babaioff et al. (2006) study settings in which each agent has only two actions, while in our model each agent's type can have an arbitrary number of actions. Recently, Dütting et al. (2020) study another principal-agent problem whose underlying structure is combinatorial, as a result of defining the outcome space implicitly through a suitably-defined succinct representation.
Other computational works on principal-agent problems worth citing are (Babaioff and Winter, 2014), which introduces a notion of contract complexity based on the number of different payments specified by the contract, and (Ho et al., 2016), which develops a dynamic model where, in each round, the principal determines a contract and an agent chooses an action, resulting in a reward for the principal. These works considerably depart form ours, as they study rather different models. The first one considers an n-player normal-form framework in which actions are not hidden. The second work uses multi-armed bandit techniques, and, thus, the goal is to minimize the principal's regret over time.
In conclusion, we also point out that considerable attention (especially in the economic literature) has been devoted to the study of some robustness properties of linear contracts in classical principal-agent problems (Carroll, 2015, 2019). This perspective has also been taken by Dütting et al. (2019) using a more computationally-oriented point of view.
Note on Concurrent Work by Guruganesh et al. (2020) The work by Guruganesh et al. (2020), which has been developed independently and concurrently with ours, studies the same Bayesian principal-agent problem that we address in this paper. Guruganesh et al. (2020) characterize worst-case multiplicative approximation guarantees of linear contracts, comparing them with some benchmarks (including optimal contracts). Among the results they provide, the closest to ours are discussed in the following. First, they show a tight approximation guarantee for linear contracts, which is linear in the number of agent's actions and logarithmic in the number of agent's types when all agent's types share the same costs, while, if they may have different costs, it is linear in the number of types and actions. This result is similar to our result in Section 3.1, where we only consider the dependency on the number of types. Second, they show the hardness of computing a single contract or a menu of contracts approximating the optimal principal's expected utility ip to within a given constant multiplicative factor. In Section 4, we show a stronger result. In particular, we prove the hardness of computing a single contract with a multiplicative loss sublinear in the number of types. Finally, they show that an optimal contract can be computed efficiently if we fix either the number of agent's types or the number of outcomes. This is equivalent to our results in Section 5. In conclusion, even though Guruganesh et al. (2020) study the same principal-agent problem, they focus on the approximation guarantees
3

ARXIV PREPRINT - JUNE 2, 2021
of linear contracts with respect to optimal ones and other possible benchmarks, while our main focus is their relation with efficiently computable contracts.
2 Preliminaries
In this section, we introduce all the elements we need in the rest of this work. Section 2.1 formally defines the problem we study, Section 2.2 describes its solutions (contracts), while Section 2.3 defines which kind of approximation guarantees we look for in contracts.
2.1 The Bayesian Principal-Agent Problem
An instance of the Bayesian principal-agent problem is characterized by a tuple (, A, ), where:  is a finite set of  := || agent's types; A is a finite set of n := |A| actions available to the agent; and  is a finite set of m := || possible outcomes. 1 The agent's type is drawn according to a fixed probability distribution known to the principal. We let µ   be such a distribution, with µ denoting the probability of type    being selected. 2 For each type   , we introduce F,a   to denote the probability distribution over outcomes  when an agent of type  selects action a  A, while c,a  [0, 1] is the agent's cost for that action. 3 We let F,a, be the probability that F,a assigns to   , so that  F,a, = 1. Each outcome    is characterized by a reward r  [0, 1] for the principal. As a result, when an agent of type    selects an action a  A, then the principal achieves an expected reward R,a, which is defined as R,a :=  F,a, r. As in classical (non-Bayesian) principal-agent problems, the principal's objective is to commit to a contract that maximizes her expected utility, as we formally describe in the following.
2.2 Contracts
A contract is specified by payments from the principal to the agent, which are contingent on the actual outcome achieved with the agent's action. We let p  0 be the payment associated to outcome   . The assumption that payments are non-negative (i.e., they can only be from the principal to the agent, and not the other way around) is common in contract theory, where it is known as limited liability (Carroll, 2015). When an agent of type    selects an action a  A, then the expected payment to the agent is P,a :=  F,a, p, while her utility is P,a - c,a. On the other hand, the principal's expected utility in that case is R,a - P,a. Given a contract, an agent of type    selects an action such that:
1. it is incentive compatible (IC), i.e., it maximizes her expected utility among actions in A; 2. it is individually rational (IR), i.e., it has non-negative expected utility (if there is no IR action, then the agent
of type  abstains from playing so as to maintain the status quo).
For the ease of presentation, we adopt the following w.l.o.g. common assumption (Dütting et al., 2019), which guarantees that IR is always enforced and, thus, it allows us to focus on IC only. Assumption 1. There exists an action a  A such that c,a = 0 for all   .
The assumption ensures that each agent's type has always an action providing her with a non-negative utility, thus ensuring IR of any IC action. We say that a contract implements an action a  A for an agent of type    if the agent chooses that action. 4 Finally, given a contract, by letting a()  A be the action implemented by such contract for an agent of type   , we can define the overall principal's expected utility as  µ R,a() - P,a() , which accounts for type probabilities. A special class of simple contracts that is commonly studied in the literature is that of linear contracts, which give payments equal to some fixed fraction of the outcome rewards (Dütting et al., 2019). Thus, these contracts are completely characterized by a single parameter   [0, 1], with their payments being defined as
1For the simplicity of exposition, we assume that all the agent's types share the same action set. All the results continue to hold even if each agent's type    has her own action set A.
2Given a finite set X, we denote with X the set of all the probability distributions defined over X. 3For the ease of presentation, we assume that rewards and costs are in [0, 1]. Notice that all the results in this work can be easily generalized to the case of an arbitrary range of positive numbers, by applying a suitable normalization. 4As it is common in the literature (Dütting et al., 2020), we assume that the agent breaks ties in favor of the principal, i.e., whenever there is more than one IC action, she selects the one maximizing the principal's expected utility.
4

ARXIV PREPRINT - JUNE 2, 2021

p =  r for every outcome   . We refer the reader to the work by Dütting et al. (2019) for more details on linear contracts in non-Bayesian principal-agent problems, including their geometric interpretation.

2.3 Approximation Guarantees of Contracts

The goal of the principal is to design an optimal contract, which is one maximizing her overall expected utility. In the following, we denote with OP T the principal's overall expected utility in an optimal contract. As we show later in this work, computing an optimal contract in our setting is computationally intractable (with the exception of some special cases). Thus, we look at suboptimal contracts providing some guaranteed approximation of the principal's optimal utility OP T .

Given a contract, we say that its multiplicative loss with respect to an optimal contract is   1 if it provides the princi-

pal

with

an

overall

expected

utility

of

OP T 

.

Equivalently,

we

sometimes

say

that

the

contract

provides

a

multiplicative

approximation  of an optimal one.

We also study approximation guarantees of contracts by considering both additive and multiplicative approxima-

tions at the same time. Formally, given a multiplicative approximation   1, we say that a contract provides a

(, g())-bi-approximation of an optimal one if it results in an overall principal's expected utility greater than or

equal to

OP T 

- g(), where g() denotes a (positive) additive loss depending on the parameter .

Intuitively, bi-

approximations allow us to analyze the performances of contracts by carefully managing the trade off between a

desired (constant) multiplicative approximation factor and an additional (small) additive loss. We are interested in

(, g())-bi-approximations such that the term g() quickly approaches zero as  increases. In particular, later in this

work, we focus on bi-approximations whose g() terms decrease exponentially in , so that the additive loss becomes

quickly negligible.

3 Linear versus Optimal Contracts: The Bayesian Setting
We start by analyzing the performances of linear contracts with respect to optimal (possibly non-linear) ones. Section 3.1 studies how linear contracts perform in terms of multiplicative loss, while Section 3.2 provides our main results on the bi-approximation guarantees of linear contracts.
3.1 Multiplicative Approximations
We prove that, in Bayesian principal-agent problems, linear contracts do not perform well when compared to optimal ones in terms of their multiplicative loss. Formally, in the following Theorem 1, we construct particular instances showing that, in the worst case, the multiplicative loss of any linear contract with respect to an optimal one increases at least linearly in the number of agent's types . We remark that, in the instances used to prove the theorem, the agent has only two actions available (notice that A = {a1, a2} in the proof). This strengthens already-known results. Indeed, Dütting et al. (2019) prove that, in the special case of non-Bayesian principal-agent problems, linear contracts are arbitrarily worse than optimal ones for a growing number of agent's actions, as their worst-case multiplicative loss is equal to n. Our result shows that, in Bayesian settings with many agent's types, the multiplicative loss of linear contracts can be arbitrarily bad even in the basic case in which the agent has only two actions.
Theorem 1. In Bayesian principal-agent problems, the worst-case multiplicative loss of any linear contract with respect to an optimal one is (), where  is the number of agent's types.

Proof. For any   N, let us consider a principal-agent setting (, A, ) with outcome set  = {j}j[m], where we

let m =  + 1. We define rj = 2-j for j   \ {m}, while rm = 0. The set of agent's types is  = {k}k[],

with

µ





being

defined so

that

µk

=

1 N

22(k-)

for

all

k



,

where

N

:=

k[] 22(k-) is a suitably defined

normalization constant. Each agent of type k   has two actions available, namely A = {a1, a2}, with probability

distributions defined so that Fk,a1,k = 1 and Fk,a2,m = 1. Intuitively, action a1 of type k deterministically

results in outcome k (with reward rk = 2-k), while action a2 leads to outcome rm no matter the agent's type (with reward rm = 0). Moreover, the action costs for type k   are ck,a1 = 2-k 1 - 2-k and ck,a2 =

0. The optimal (non-linear) contract sets the payments as follows: pj = 2-j 1 - 2-j for all j   \ {m},

while pm = 0. This contract implements action a1 for each agent's type k  , as her utility by playing a1 is

Pk,a1 - ck,a1 = pk - ck,a1 = 0 and rk > 0, while the utility of a2 is zero and rm = 0 (as previously stated, we

assume that ties are broken in favor of the principal). As a result, the contract provides the principal with an overall

5

ARXIV PREPRINT - JUNE 2, 2021

expected utility of:

µk

(Rk ,a1

- Pk,a1 )

=

1 N

22(k-) 2-k - 2-k 1 - 2-k

k 

k

=1

2-2 =  2-2 .

N

N

k 

Now, let us consider a linear contract with parameter   [0, 1]. For an agent of type k  , the contract implements action a1 only if Pk,a1 = pk =  rk =  2-k  2-k 1 - 2-k = ck,a1 . It is easy to check that an agent of type k is incentivized to play a1 if and only if k  - log2(1 - ). Let k := - log2(1 - ) be the highest index among agent's types that are incentivized to play action a1. Then, the overall principal's expected utility is:

µk (1 - ) Rk,a1

=

1 N

22(k-)(1 - ) 2-k 

k :kk

k :kk



1 N

22(k-) 2-k

2-k

=

1 N

2-2

2-k

2k 

k :kk

k :kk

 1 2-2 2-k 2k+1 = 2 2-2 ,

N

N

where the first inequality follows from 1 -   1 - 2-k  1 - 2-k (since the contract implements a1 for type k and it holds k  k). This concludes the proof.

We remark that the approximation result in Theorem 1 is tight in many cases. This is readily seen by leveraging the approximation results of Dütting et al. (2019). Let us recall that Dütting et al. (2019) show that, in non-Bayesian principal-agent problems, linear contracts provide a constant multiplicative approximation of optimal ones, except in settings where the following three conditions hold simultaneously: there are many agent's actions, there is a big spread of expected rewards, and there is a big spread of costs. Thus, whenever at least one of the conditions above does not hold in a Bayesian principal-agent setting, we have a simple polynomial-time algorithm that returns a linear contract with multiplicative loss O() (matching the lower bound in Theorem 1). This algorithm computes an approximate linear contract of Dütting et al. (2019) for each agent's type singularly and returns the one providing the highest overall principal's expected utility (after weighting them by the corresponding type probabilities). 5 Let us also notice that, even in pathological cases in which all the conditions above hold simultaneously, the result in Theorem 1 is still tight in the number of agent's types , though the multiplicative loss of linear contracts could be arbitrarily bad in one or more of the other parameters (number of agent's actions, spread of rewards, and spread of costs). For instance, Guruganesh et al. (2020) show that the worst-case loss is linear in the number of actions.

3.2 Bi-Approximation Guarantees
The instances exploited in the proof of Theorem 1 suggest that the negative result holds only when the rewards (and, thus, the principal's expected utilities) are very small. In particular, the rewards decrease exponentially in the approximation factor (the number of agent's types). This suggests that linear contracts could provide nice approximation guarantees when looking at bi-approximations.
Next, we prove that linear contracts achieve good bi-approximations of the optimal principal's expected utility: for any constant , they provide a multiplicative approximation  at the expense of an exponentially small additive loss 2-(). Let us remark that the additive loss decreases exponentially as  increases, becoming quickly negligible. For instance, given a constant multiplicative approximation factor  = 50, the resulting additive loss is 2-24, while Theorem 1 shows that linear contracts provide a (non-constant) approximation decreasing linearly in the number of agent's types  if we only consider multiplicative factors.
We start by proving the result in the easier non-Bayesian setting, in which  = 1. 6
First, we introduce the following observation that is useful to prove the following Theorem 2, as well as other results in the rest of this work.
Observation 1. Given a non-Bayesian principal-agent instance, it holds OP T  maxaA {Ra - ca}.
5For each agent's type   , the algorithm computes the linear contract of Theorem 5.1 in (Dütting et al., 2019) if the number of actions is small (that of Theorem 5.5, respectively Theorem 5.7, in (Dütting et al., 2019) if the spread of rewards, respectively costs, is small).
6When we refer to a non-Bayesian principal-agent instance, we adopt the same notational conventions, dropping any reference to the types.

6

ARXIV PREPRINT - JUNE 2, 2021

Proof. It is sufficient to notice that, by the IR property, the agent's expected payment covers the cost ca of the implemented action a  A, and, thus, the principal's expected utility is always upper-bounded by Ra - ca.
Theorem 2. Given a non-Bayesian principal-agent instance, linear contracts provide a , 2-() -bi-approximation of an optimal contract. Moreover, for any   2, there is a linear contract  that provides a , 2-d+e -biapproximation of an optimal contract for two constants d  R+ and e  R, where  = 1 - 2-i for some i = 1, . . . , /2. 7

Proof. For the ease of presentation, given   2, we let I := /2, while [I] is the set of integers from 1 to /2.

Moreover, for each i  [I], we define i := 1 - 2-i, while, letting A = {ai}i[n], we assume w.l.o.g. that the first

I actions of A are those implemented by the linear contracts with parameters i, so that ai  A denotes the agent's

action implemented by i. For i  [I] : i > 1, we also let i-1,i  [i-1, i] be the parameter identifying a linear

contract such that the agent is indifferent between actions ai-1 and ai. Whenever ai-1 and ai are the same action,

then we can set w.l.o.g. i-1,i := i. Instead, if ai-1 and ai are different actions, it is easy to check that it must be

i-1,i

:=

cai-1 -cai Rai-1 -Rai

(it cannot be the case that Rai-1

= Rai , otherwise one between ai-1 and ai would be weakly

dominated by the other, and, thus, never implemented by a contract that breaks ties deterministically in favor of the

principal). Finally, for convenience, we let 0,1 := 0. In the following, we show that at least one linear contract among

those with parameters i

for i



[I ]

provides the principal with expected utility at least

OP T 

-

2-

 2

+1.

In the rest of the proof, we need the following observation due to Dütting et al. (2019).

Observation 2 (Essentially Observation 6 in (Dütting et al., 2019)). Given i  [I] : i > 1, it holds:

(Rai - cai ) - Rai-1 - cai-1  (1 - i-1,i) Rai .

Observation 2 allows us to prove the following lemma. Lemma 1. For every i  [I], it holds that:

Rai - cai 

(1 - i-1,i) Rai .

i[I ]:ii

Proof. The proof every i  [I] : i

is by induction. For the base case i = 1, we have (1  2, let us assume by induction that Rai-1 - cai-1

- 0,1) Ra1 = Ra1  i[I]:ii-1 (1

 Ra1 - ca1 . - i-1,i) Rai .

Next, for Then, by

using Observation 2 and the inductive hypothesis, we get:

Rai - cai = Rai - cai -

R - c ai-1

ai -1

+

R - c ai-1

ai -1



 (1 - i-1,i ) Rai +

(1 - i-1,i) Rai =

i[I ]:ii -1

=

(1 - i-1,i) Rai .

i[I ]:ii

This concludes the proof of the lemma.

Now, we can prove the following:

max
i[I ]

(1

-

i)

Rai



1 2

max
i[I ]

(1

-

i-1,i

)

Rai



1 2I

(1 - i-1,i) Rai



RaI - caI 2I

,

i[I ]

where the first inequality holds since holds by definition of max, while the

1 - i last one

=

2-i

=

1 2

2-(i-1)

=

1 2

by Lemma 1. Finally, by

(1 - i-1 letting a

)



1 2

(1

-

i-1,i),

the

second one

 argmaxaA {Ra - ca}, we have:

RaI - caI  I RaI - caI  I Ra - ca  1 - 2-I Ra - ca  Ra - ca - 2-I  OP T - 2-I ,

7A bi-approximation as in Theorems 2 and 3 for the cases in which   [1, 2) can be easily obtained by using the linear contract



=

1 2

,

which

always

provides

an

additive

loss

of

1 2

.

7

ARXIV PREPRINT - JUNE 2, 2021

where the second inequality holds since the linear contract with parameter I implements action aI , the second-last inequality follows from Ra  [0, 1], while the last one holds by Observation 1. In conclusion,

max
i[I ]

(1

-

i)

Rai



RaI - caI 2I



OP T - 2-I 2I



OP T 

-

2-

 2

+1 .

This concludes the proof of the theorem.

We can exploit a reasoning similar to that used in the proof of Theorem 2 to prove our main result for the general Bayesian setting.
Theorem 3. Given a Bayesian principal-agent instance, linear contracts provide a , 2-() -bi-approximation of an optimal contract. Moreover, for any   2, there is a linear contract  that provides a , 2-d+e -bi-approximation of an optimal contract for two constants d  R+ and e  R, where  = 1 - 2-i for some i = 1, . . . , /2.

Proof. The proof follows the lines of that of Theorem 2, where we let I := /2 and i := 1 - 2-i for i  [I]. In this case, for every agent's type   , with a slight abuse of notation we define ai ()  A as the action implemented by the linear contract with parameter i for an agent of type . Moreover, for every i  [I], we introduce the parameters ai-1(),ai () (with a0(),a1() := 0), which are the analogous of the parameters i-1,i in the proof of Theorem 2, for actions ai-1() and ai (). Then, following steps similar to those in Theorem 2 (including an analogous of Lemma 1), we can prove the following:

max
i[I ]

µ

(1 - i) R,ai ()



1 2

max
i[I ]

µ 1 - ai-1(),ai () R,ai () 







1 2I

µ

1 - ai-1(),ai () R,ai () 

 i[I]



1 2I

µ

R,aI () - c,aI () 

 i[I]



1 2I

µ OP T - 2-I 





OP T

-

2-

 2

+1

,



where, in the second-last step, OP T denotes the principal expected utility in an optimal contract for the non-Bayesian setting in which only type    is present.

The following theorem shows that the bounds provided in Theorems 2 and 3 are tight.
Theorem 4. No linear contract provides a , 2-O() -approximation of an optimal contract, even in non-Bayesian principal-agent problems. Equivalently, for any   1, no linear contract provides a , 2-d+e -bi-approximation of an optimal one, for two constants d  N and e  Z.

Proof. Given any   1, we show that there exists a non-Bayesian setting (A, ) in which, using a linear contract, it is

impossible to obtain a , 2-4-2 -approximation of the optimal expected utility for the principal. In these instances,

an optimal (non-linear) contract provides the principal with an expected utility OP T > 42-4-2, while the best

linear

contract

achieves

at

most

2-4-1

utility.

Since

OP T 

-2-4-2

>

2-4-1 ,

this

concludes

the

proof.

Formally,

let us take  = {1, 2, 3} and A = {ai}i[]  {a¯}, where  := 4. Let r1 = 1 be the reward of outcome 1,

while

the

other

outcomes provide zero

reward, namely r2

=

r3

=

0.

The agent's actions are

such that

Fa1 ,1

=

1 2

and Fa1,2

=

1 2

,

while

Fai ,1

=

2-i

and Fai,3

=

1 - 2-i for every i



[]

:

i

>

1.

Each action ai



A has

cost cai = 2-i - ( - i + 2)2--2. Moreover, the last action a¯  A is such that Fa¯,3 = 1 and ca¯ = 0 (ensuring

IR). Simple arguments show that an optimal contract sets payments p1 = p3 = 0 and p2 = 1 - ( + 1)2--1,

implementing action a1 with a principal's expected utility ( + 1)2--2  42-4-2. Intuitively, the contract

is such that Pa1 = ca1, which ensures that the agent plays action a1 (it is IC and ties are broken in favor of the

principal), while minimizing the payment. Next, we show that any linear contract provides the principal with an

expected utility at most 2--1. First, let us notice that the principal's expected utility when implementing action

8

ARXIV PREPRINT - JUNE 2, 2021

a is at most Ra - ca = 2--1. Instead, suppose that a linear contract implements an action ai  A such that i  [] : 1 < i < . Then, it must be the case that ai provides the agent with an expected utility greater than or equal to that obtained by ai+1, i.e., it must be 2-ip1 + 1 - 2-i p3 - cai  2-i-1p1 + 1 - 2-i-1 p3 - cai+1 . Thus:
2-ip1 - 2-i - ( - i + 2)2--2  2-i-1p1 - 2-i-1 - ( - i + 1)2--2 ,
which implies that p1  1-2i+1--2. This prove that the expected utility for the principal is at most (1 - p1) 2-i  2--1 = 2-4-1, concluding the proof.

4 Linear versus Tractable Contracts
In this section, we show that linear contracts have the same worst-case performance as efficiently-computable ones. In Section 4.1, we prove that there is no tractable contract providing a multiplicative loss sublinear in the number of agent's types. This shows that, even if linear contracts provide a bad multiplicative loss in the number of agent's types (Theorem 1), this is also true for tractable contracts. Then, in Section 4.2 we show that the , 2-() -biapproximation result for linear contacts (Theorem 3) is the best one can possibly achieve in polynomial time. Technically, it is NP-hard to compute a contract providing a , 2-() -bi-approximation of an optimal one.
4.1 The Limits of Tractable Contracts
In the following Theorem 5, we prove that it is NP-hard to design a contract that approximates the overall principal's expected utility in an optimal contract up to within any multiplicative factor that is sublinear in the number of agent's types . The theorem is based on a reduction from GAP-INDEPENDENT-SET, which is the promise problem of deciding, in a given graph, whether there exists an independent set involving at least some (large) fraction of nodes or all the independent sets encompass at most some (small) fraction of nodes (Zuckerman, 2007).
Theorem 5. In Bayesian principal-agent problems, for any  > 0 it is NP-hard to design a contract providing a multiplicative loss O 1- of an optimal one, where  is the number of agent's types.

Proof. We reduce from GAP-INDEPENDENT-SET, which is a promise problem that formally reads as follows: given

 > 0 and a graph G = (V, E), with set of nodes V and set of edges E, determine whether G admits an independent

set of size at least |V |1- or all the independent sets of G have size smaller than |V |. The Bayesian principal-agent

instances in the reduction have a number of agent's types  = |V |. The main idea of the proof is to show that, provided

 is large enough, if G admits an independent set of size at least 1-, then in the corresponding principal-agent setting

there

exists

a

contract

in

which

the

overall

principal's

expected

utility

is

at

least

1 2

1- 2--1;

otherwise,

the

utility

is at most 2  2--1 for any contract. Since GAP-INDEPENDENT-SET is NP-hard for every  > 0 (Håstad, 1999;

Zuckerman, 2007), this is enough to prove the statement.

Construction Given a graph G = (V, E), we build a Bayesian principal-agent setting (, A, ) as follows. For

every node v  V in the graph G, there are two outcomes v, ¯v   such that rv = 1 and r¯v = 0. Moreover, there is an additional auxiliary outcome ¯   with r¯ = 0. The agent type is uniformly selected from a set  = {v}vV

of  = |V | different types, each corresponding to a node in the graph. Thus, the distribution µ   is such that

µv

=

1 

for

every v



.

The

agent

has

m

=

2

-+1

actions

available.

There is

an

action

a¯



A

that

induces

a distribution over outcomes Fv,a¯

with Fv,a¯,v

=

Fv ,a¯,¯ v

=

1 2

and has cost cv,a¯

=

1 2

- 2--1, no matter the

agent's type v  . Each of the remaining 2 -  actions, denoted as aui  A, corresponds to a node u  V and an

index i  [ - 1]. They are characterized by outcome distributions defined as follows. For every agent's type v  

and action aui  A (with v, u  V ), the distribution Fv,aui is such that:

· If (v, u)  E, then the reachable outcomes are v, ¯v, ¯u, and ¯, which are reached with probabilities,

respectively,

Fv ,aui ,v

=

2-i-1,

Fv ,aui,¯v

=

Fv ,aui,¯u

=

2 3

2-i-1,

and

Fv ,aui ,¯

=

1

-

7 3

2-i-1;

· If (v, u) / E, then the reachable outcomes are v and ¯, which are reached with probabilities Fv,aui,v = 2-i-1 and Fv,aui,¯ = 1 - 2-i-1, respectively.

Moreover, the cost of each action aui  A is cv,aui = 2-i-1 - ( - i)2--1, for any type v  .

9

ARXIV PREPRINT - JUNE 2, 2021

Overview In the instances of the reduction, the principal's expected utility contribution due to an agent's type playing
an action aui  A is small. Thus, the principal's objective is to incentivize as many agent's types as possible to play a¯, which is the action with the greatest difference between expected reward and cost. In order to incentivize an agent of
type v   to play a¯ rather than an action au1  A, while still achieving a satisfactory expected utility from that, the principal must set some (large) payment on outcome ¯v, some (small) payment on outcome v, and no payment on ¯. Indeed, rewarding the last two outcomes prevents from reaching the desired principal's expected utility. Moreover, the
principal must not set payments on outcomes ¯u such that vertex u is adjacent to v, otherwise an agent of type v   would be incentivized to play action au1 rather a¯. This implies that the principal can extract a satisfactory utility only from agent's types whose corresponding vertices constitute an independent set of the graph G.

Completeness Suppose that graph G admits an independent set of size at least |V |1-. Then, there exists a maximal

independent set V   V of size |V |  |V |1- such that, for every node v / V , there is a node u  V  with

(v, all

u)  E. v / V ,

Let us define a contract with p¯v = 1 while all the other payments are set to

- 0.

 2--1 for all First, we show

v



V

and pv

=

1 3

1

that, given this contract,

- 2--1 any agent

+ 2--1 for of type v  

with v  V  is incentivized to play action a¯. The expected utility of the agent by playing a¯ is:

Pv ,a¯

- cv,a¯

=

1 2

1 -  2--1

-

1 2

-

 2--1

=

 2

2--1.

As for the expected utility of playing an action there is no payment associated to v, being v

aui  A, two cases are possible. If (v, u) /  V ); thus, the resulting agent's expected

E, then Pv,aui = utility is negative.

0 (since Instead,

if (v, u)  E, then, by definition of independent set, it must be the case that u / V , which implies that the only

reachable outcome having non-zero payment is ¯v. Thus, in this case the agent's expected utility is:

Pv ,aui

- cv,aui =

2 3

2-i-1

1 - 2--1

-

2-i-1- ( - i)2--1) = 2--1



-

i

-

2 3

2-i-1

-

1 3

2-i+

.

Then,

for

i



 2

,

it

immediately

follows

that:

Pv,aui - cv,aui = 2--1



-

i

-

2 3

2-i-1

-

1 3

2-i+



 2

2--1

=

Pv ,a¯

- cv,a¯,

while,

for

i



 2

,

the

same

result

follows from

the

fact

that,

provided 

is

large enough,

it

holds:

2--1



-

i

-

2 3

2-i-1

-

1 3

2-i+

 2--1



-

1 3

2 2



 2

2--1,

where

the

last

inequality

holds

since

2

 2



 2

for

plays action a¯. Next, we prove that, whenever

a sufficiently large the agent's type v

. This shows   is such

that that

any v /

agent of type v with v  V  V , then the agent plays an

action au1 associated with a node u  V such that (v, u)  E and u  V . Notice that one such node always exists

since

V



is

a

maximal independent set.

Given

that

p¯v

=

0,

p¯u

=

1 - 2--1,

and

pv

=

1 3

1 - 2--1

+ 2--1,

the expected utility of the agent by playing action au1 is:

Pv ,au1

- cv,au1

=

2 3

2-2

1 - 2--1

+ 2-2

1 3

1 - 2--1

+ 2--1

- 2-2 - ( - 1)2--1

=

= ( - 1)2--1.

On the other hand, any action aui provides the agent with an expected utility:

Pv ,aui

- cv,aui

=

2 3

2-i-1

1 - 2--1

+

=

+ 2-i-1

1 3

1 - 2--1 + 2--1

- 2-i-1 - ( - i)2--1

=

= ( - i)2--1  ( - 1)2--1 = Pv,au1 - cv,au1 .

10

ARXIV PREPRINT - JUNE 2, 2021

Moreover, it is easy to check that action a¯ provides the agent with a negative utility, showing that any agent of type v with v / V  plays an action au1. Finally, we can conclude that the overall principal's expected utility is:

µv (Rv,a¯ - Pv,a¯) +

µv (Rv,au1 - Pv,au1 ) =

vV 

v/V 

=

1 1 - 1 1 - 2--1 +

2 2

vV 

=+

1 

2-2

-

2 3

2-2

1 - 2--1

-

1 3

2-2

1 - 2--1

- 2-22--1



v/V 



1 

1-

1 2

-

1 2

1 - 2--1

+

=

+

1 

 - 1-

2-2

-

2 3

2-2

1 - 2--1

-

1 3

2-2

1 - 2--1

- 2-22--1

=

=

1 

1-

 2

2--1

=

1 2

1-2--1

,

where we used the fact that |V |  |V |1- = 1- by assumption.

Soundness We start showing that, if the principal deploys a contract that implements an action aui  A, then she

achieves an expected utility Rv,aui - Pv,aui  2-, no matter the agent's type v  . First, notice that, by

implementing actions au -1  A, the principal can obtain an expected utility at most of Rv,au -1 - cv,au -1 =

2- - 2--1 = 2--1 (due to IR constraints). Next, suppose that the contract implements an action aui  A with

i  [ - 2] for an agent of type v  . Then, by IC constraints, action aui must provide the agent with an expected

utility

greater

than

or

equal

to

that

achieved by

playing au i+1,

i.e.,

it

must

be Pv ,aui - cv,aui



P - c . v ,au i+1

v,au i+1

Two cases are possible. In the first one, it holds (v, u)  E, which implies that:

pv 2-i-1

+

p¯v

2 3

2-i-1

+

p¯u

2 3

2-i-1

+

p¯

1

-

7 3

2-i-1

- 2-i-1 - ( - i) 2--1 



pv 2-i-2

+

p¯v

2 3

2-i-2

+

p¯u

2 3

2-i-2

+

p¯

1

-

7 3

2-i-2

- 2-i-2 - ( - i - 1) 2--1 .

Thus,

2-i-1

pv

+

2 3

p¯v

+

2 3

p¯u

-

7 3

p¯

 2-i-2 - 2--1.

As a result, the expected utility of the principal when an agent of type v plays an action aui is:

Rv,aui - Pv,aui = 2-i-1 -

pv 2-i-1

+

p¯v

2 3

2-i-1

+

p¯u

2 3

2-i-1

+

p¯

1

-

7 3

2-i-1



 2-i-1 -

pv

2-i-1

+

p¯v

2 3

2-i-1

+

p¯u

2 3

2-i-1

-

p¯

7 3

2-i-1



 2-i-1 - 2 2-i-2 - 2--1 = 2-.

A similar argument holds for the case in which (v, u) / E. Now, given a contract, let    be the set of agent's
types v such that: (i) the contract implements action a¯ for an agent of type v; and (ii) the principal achieves an expected utility strictly larger than 2- when an agent of type v plays a¯. We prove that, for any contract, any pair of types v, u   is such that (v, u) / E. By contradiction, suppose that there exist v, u   such that (u, v)  E. We distinguish two cases. The first one is when p¯v  p¯u. Since action a¯ must provide an agent of type v with an expected utility greater than or equal to that obtained for action au1 (by IC constraints), we have that:

1 2

pv

+

1 2

p¯v

-

1 2

-

2--1



2-2pv

+

2 3

2-2

(p¯v

+

p¯u )

+

1

-

7 3

2-2

p¯ - 2-2 - ( - 1) 2--1 .

By using the fact that p¯u  p¯v  0 and p¯  0, and re-arranging the terms, we obtain that 2-2 (pv + p¯v ) 

2-2 - 2--1,

which

implies that Pv,av¯

=

1 2

pv

+

1 2

p¯v



1 2

- 2-.

Since Rv,a¯

=

1 2

,

this

results

in

a principal's

expected utility at most of 2-, which is a contradiction. In the second case in which p¯v  p¯u, we reach a

11

ARXIV PREPRINT - JUNE 2, 2021

contradiction using an analogous argument for an agent of type u (rather than v). Thus, we can conclude that, for any contract, the set of nodes v  V such that v   constitutes an independent set of the graph G. Moreover, notice that the maximum expected utility that the principal can obtain when an agent of type v   plays action a¯ is Rv,a¯ - cv,a¯ = 2--1. Since, by assumption, the largest independent set of G has size at most |V | = , we can conclude that in any contract the overall expected utility of the principal is:

µv (Rv,a¯ - Pv,a¯) +

µv

v 

v \

Rv ,a(v) - Pv,a(v)

 1 2--1 + 1 ( - ) 2- 







2

1 

1+

2--1

=

= 2  2--1,

where the last inequality holds provided that  is sufficiently large.

4.2 The Limits of Bi-Approximations
We show that, for any   1, it is NP-hard to design a contract providing a , 2-() -bi-approximation of an optimal one. To this end, we employ a reduction from a promise problem associated with LABEL-COVER instances, whose definition follows. Definition 1 (LABEL-COVER instance). An instance of LABEL-COVER is a tuple (G, , ):
· G := (U, V, E) is a bipartite graph defined by two disjoint sets of nodes U and V , connected by the edges in E  U × V , which are such that all the nodes in U have the same degree;
·  is a finite set of labels; and
·  := {e :    | e  E} is a finite set of edge constraints.
Moreover, a labeling of the graph G is a mapping  : U  V   that assigns a label to each vertex of G such that all the edge constraints are satisfied. Formally, a labeling  satisfies the constraint for an edge e = (u, v)  E if it holds that (v) = e((u)).
The classical LABEL-COVER problem is the search problem of finding a valid labeling for a LABEL-COVER instance given as input. In the following, we consider a different version of the problem, which is the promise problem associated with LABEL-COVER instances. Definition 2 (GAP-LABEL-COVERc,s). For any pair of numbers 0 < s < c < 1, we define GAP-LABELCOVERc,s as the following promise problem.
· Input: An instance (G, , ) of LABEL-COVER such that either one of the following is true:
­ there exists a labeling  that satisfies at least a fraction c of the edge constraints in ; ­ any labeling  satisfies less than a fraction s of the edge constraints in .
· Output: Determine which of the above two cases hold.
In order to prove Theorem 7, we use the following result due to Raz (1998) and Arora et al. (1998). Theorem 6 (Raz (1998); Arora et al. (1998)). For any  > 0, there exists a constant k  N that depends on  such that the promise problem GAP-LABEL-COVER1, restricted to inputs (G, , ) with || = k is NP-hard.
Next, we show our main result. 8
8In order to prove Theorem 7, we need that the difference between the overall principal's expected utility in the completeness part and that in the soundness part is at least 2-O(), otherwise a contract providing a , 2-O() -bi-approximation cannot distinguish between the two cases. Thus, we cannot use the construction in Theorem 5, since it does not enjoy this property. Indeed, we would like that the principal's expected utility in the soundness case decreases at a rate of 2-O() as  increases, while in Theorem 5 the principal's expected utility decreases with the number of agent's types, i.e., its maximum value is 2-. Moreover, in Theorem 5 we reduce from GAP-INDEPENDENT-SET, which has not perfect completeness. Thus, the principal can extract a satisfactory utility from at most a fraction - of the agent's types, which implies that the expected utility decreases with the number of agent's types. In order to deal with these problems, we base our reduction on GAP-LABEL-COVERc,s. Using this problem, we have perfect completeness, though at the expense of the NP-hardness of approximating only to within any multiplicative constant factor. This is sufficient for proving Theorem 7, since it requires the NP-hardness of approximating up to within a multiplicative factor that is of the order of ().

12

ARXIV PREPRINT - JUNE 2, 2021

Theorem 7. Given a Bayesian principal-agent setting, it is NP-hard to design a contract providing a , 2-() bi-approximation of an optimal one. Equivalently, for any   1, it is NP-hard to design a contract providing a , 2-d+e -bi-approximation for two constants d  R+, e  R.

Proof.

Letting 

:=

10,

we

prove

the

result

by

means

of

a

reduction

from

GAP-LABEL-COVER1,

1 2

.

In

particular,

our construction is such that, if the LABEL-COVER instance admits a labeling that satisfies all the edge constraints

(recall that c = 1), then the corresponding Bayesian principal-agent setting admits a contract providing the principal

with an overall expected utility

at least

of (

+ 2)2-4.

Instead,

if

at most a

1 2

fraction of

the edge constraints are

satisfied by any labeling, then the principal expected utility is at most 2--1 in any contract. By Theorem 6, this

implies that designing a contract giving a , 2-8-4 -bi-approximation (for any   1) is NP-hard. Indeed, the

following relation shows that a , 2-8-4 -bi-approximation algorithm can determine whether the LABEL-COVER

instance

admits

a

labeling

that

satisfies

all

the

edge

constraints

or

at

most

a

1 2

fraction

of

the

edge

constraints

are

satisfied by any labeling:

1 

(

+

2) 2-4

-

2-8-4



1 

(

+

2)

2-4

-

2--3

>

10

·

2-4 - 2--3  2--1.

Next, we provide the formal definition of our reduction and prove its crucial properties.

Construction Given an instance of LABEL-COVER (G, , ) with a bipartite graph G = (U, V, E), we build a

Bayesian principal-agent setting (, A, ) as follows. For every node v  U  V of G and label   , there is an

outcome v   with reward rv = 0 to the principal. Moreover, there are two additional outcomes 0, 1  

such that formally,

r0 = 0 and r1 = 1.  = {e}eE. All the

The agent can types have the

be of same

 = |E| different types, probability of occurring,

each associated being µ  

with such

an edge that µe

of G;

=

1 

for e  E. For the ease of presentation and w.l.o.g., we let each agent's type e   having a different action set

Ae, so that, with an abuse of notation, A = {Ae}e. Notice that, in order to recover a principal-agent setting in

which each agent's type has the same set of actions, it is sufficient to add some dummy actions having zero cost for

the agent and deterministically leading to outcome 0 (with zero reward). Each agent's type e   with e = (u, v) has an action a  Ae for every pair of labels such that    and  = e(). The action induces a probability distribution over outcomes Fe,a such that:

·

Outcome 1 is reached half of the times, being Fe,a ,1

=

1 2

;

· In the other half of the cases, outcomes u and v are reached with equal probability, being Fe,a ,u =

Fe,a ,v

=

1 4

.

The cost of the action is ce,a

=

1 2

- ( + 2)2--3, no matter the agent's type e



.

Moreover, each agent's

type e    = e().

with e = (u, v) has an action ai  Ae for every index The action probability distribution Fe,ai is such that:

i



[]

and

pair

of

labels

, 





such

that

· Outcomes u and v are reached with the same (small) probability decreasing exponentially in the value of i, being Fe,ai ,u = Fe,ai ,v = 2-i-2;
· Outcome 1 is reached with a probability twice as large as that of the previous ones, as Fe,ai ,1 = 2-i-1; · In all the other cases outcome 0 is reached, since Fe,ai ,0 = 1 - 2-i.

Finally, the cost of the action is ce,ai = 2-i-1 - ( - i + 2)2--3

Overview The Bayesian principal-agent instances of the reduction have a structure similar to those in the proof of
Theorem 5. Here, the contribution to the overall principal's expected utility due to an agent's type playing an action
ai  A is small. Thus, the principal's objective is to incentivize as many agent's types as possible to play an action a . We recall that, for each agent's type e   with e = (u, v), there exists an action a only if the labels  and  satisfy the constraint for edge e, namely  = e(). Moreover, in order for the principal to incentivize an agent's type to play a and extract a satisfactory utility from that, the principal must commit to a contract that sets some payments on outcomes u and v . More precisely, an agent of type e   with e = (u, v) is incentivized to play a if the payments on outcomes u and v are equal and sufficiently large. At the same time, there must not be two labels u, v   with u =  and v =  such that a large payment is assigned to either u or v ,

13

ARXIV PREPRINT - JUNE 2, 2021

otherwise an agent of type e would be incentivized to play action a1uv rather than a . Then, for every vertex v  U  V of the graph G, there exists a single label    such that there is some payment on v and these labels define a labeling that satisfies all the constraints of edges corresponding to agent's types that play action a while
resulting in a satisfactory principal's expected utility.

Completeness Suppose the instance of LABEL-COVER (G, , ) admits a labeling  : U  V   that satisfies all the edge constraints in . Let us define a contract such that pv(v) = 1 - ( + 2)2--3 for every node v  U  V , while all the other payments are set to zero. First, we show that, given this contract, an agent of type e   with e = (u, v) is incentivized to play action a(u)(v). Recall that, in our construction, an agent of type e has action
a(u)(v) available if and only if (v) = e((u)), which is always true since the labeling  satisfies all the edge constraints by assumption. Given the definition of the contract, it holds that pu(v) = pv(v) = 1 - ( + 2)2--3,
while pu = 0 for every    \ {(u)} and pv = 0 for every    \ {(v)}. This implies that the expected utility of an agent of type e by playing action a(u)(v) is:

P - c = 41 e,a(u)(v)

e ,a(u)(v)

pu + pv

-

1 2

-

(

+

2)2--3

=

= -( + 2)2--4 + ( + 2)2--3 =

= ( + 2)2--4.

Moreover, for any pair of labels ,    such that  = e(), each action ai for i  [] provides an expected utility of:

Pe,ai - ce,ai = 2-i-2 1 - ( + 2)2--3 - 2-i-1 - ( - i + 2)2--3 = = 2--3 -2-i-2++3 - ( + 2)2-i-2 +  - i + 2 ,

which holds since it cannot be the case that both pu and pv are different from zero, otherwise it would be

(v)   \ {(u)}, contradicting the fact that the labeling  satisfies all the edge constraints. We distinguish two

cases.

In

the

first

one, it

holds

i



 2

+

1.

Then,

Pe,ai - ce,ai  2--3( - i + 2)  ( + 2)2--4 = Pe,a(u)(v) - c . e,a(u)(v)

In

the

second

case,

it

holds

i



 2

+

1,

which

implies

that:

Pe ,ai

- ce,ai



2--3(

+

2

-

2

 2

)



 2

2-

-3



Pe ,a(u)(v)

- c , e,a(u)(v)

where

the second-last inequality holds since

 2

+2



2 2

for





4.

Finally, it

is

easy to

see

that all

the

actions a

that are different from a(u)(v) provide an agent of type e with an expected utility smaller than that achieved by

playing a(u)(v). This shows that the contract incentivizes each agent's type e   with e = (u, v) to play action

a(u)(v). In conclusion, the overall expected utility of the principal is:

µe
e

Re,a(e) - Pe,a(e)

=

1 

R - P = e,a(u)(v)

e ,a(u)(v)

e=(u,v)E

=

1 2

-

1 2

1 - ( + 2)2--3

=

= ( + 2)2--4.

Soundness We show that, if the LABEL-COVER instance is such that every labeling  : U  V   satisfies

at

most

a

fraction

1 2

of

the

edge

constraints

in

,

then,

in

the

corresponding

principal-agent setting,

any

contract

provides the principal with an expected utility at most of 2--1. As a first step, we show that all the actions ai

provide the principal with an expected utility at most of 2--2. Assume that the agent has type e   with e =

(u, v) and that the contract deployed by the principal implements an action a for an agent of type e, for some

,    such that  = e(). Then, the principal's expected reward is Re,a = 2--1, while the agent's cost

is ce,a = 2--1 - 2--2, implying that the principal's expected utility is at most 2--2. Now, assume that

the contract implements an action ai with i  [] : i <  for an agent of type e, for some ,    such that

 = e(). Then, since the action ai must be IC, it must provide the agent with an expected utility greater than or

equal to that provided by action ai+1  .

Thus, it must be the case that Pe,ai -ce,ai

 P -c , e,ai+1 

e,ai+1 

which implies that:

2-i-1p1 + 2-i-2pu + 2-i-2pv + 1 - 2-i p0 - 2-i-1 - ( - i + 2)2--3   2-i-2p1 + 2-i-3pu + 2-i-3pv + 1 - 2-i-1 p0 - 2-i-2 - ( - i + 1)2--3 .

14

ARXIV PREPRINT - JUNE 2, 2021

Thus, by re-arranging the terms and using the fact that p0  0, we get 2p1 + pu + pv  2 - 2-+i, which implies that the principal's expected utility is:

Re,ai - Pe,ai = 2-i-1 - 2-i-1p1 - 2-i-2pu - 2-i-2pv - 1 - 2-i p0  2--2.

This proves that any agent's action ai provides the principal with an expected utility at most of 2--2. Next, we switch the attention to actions a . Given a contract, let  : U  V   be a labeling for the LABEL-COVER instance such that (v)  argmax pv for every v  U  V (with ties broken arbitrarily). We show that, for an agent of type e  , the contract implements an action providing the principal with an expected utility greater than 2--2 only if the labeling  satisfies the constraint e associated with edge e. By contradiction, suppose that e = (u, v) and the constraint e is not satisfied by  since (v) = e((u)). Then, there is an agent's action a1uv  Ae with u  argmax pu and v  argmax pv such that the agent's expected utility is:

Pe ,a1u v

- ce,a1uv

=

1 4

p1

+

1 8

puu + pvv

+

1 2

p0

-

1 4

-

(

+

1)2--3

.

Moreover, all the actions a  Ae for    and  = e() provide the agent with a utility:

Pe ,a

- ce,a

=

1 2

p1

+

1 4

pu + pv

-

1 - ( + 2)2--3 2

,

where, by definition, it holds pu  puu and pv  pvv . Thus, since an action a is IC only if it holds that Pe,a - ce,a  Pe,a1uv - ce,a1uv , we can conclude that 2p1 + pu + pv  2 - 2- . As a result, the expected utility of the principal is:

Re ,a

- Pe,a

=

1 2

-

1 2

p1

-

1 4

pu + pv

 2--2,

which is a contradiction. Finally, the maximum expected utility the principal can achieve for an agent of any type

e





is

maxaAe

{Re,a

-

ce,a}

=

(

+

2)2--3.

By

assumption,

any

labeling

satisfies

at

most

a

fraction

1 2

|E|

of

the

edge

constraints,

thus,

given

any

contract,

at

most

a

fraction

1 2



of

agent's

types

play

an

action

providing

the principal with an expected utility greater than 2--2 (and at most ( + 2)2--3). Then, the overall principal's

expected utility in any contract is:

µe

Re,a(e) - Pe,a(e)

<

1 

·

 2

(

+

2)2--3

+

1 

e



-

 2

2--2  2-+1,

which concludes the proof.

5 Tractable Cases
In this section, we investigate under which circumstances the problem of finding an optimal contract in Bayesian principal-agent settings is computationally tractable. In particular, we show that the problem is solvable in polynomial time when either the number of agent's types  or the number of outcomes m is small. Formally, we exhibit two algorithms that run in polynomial time when  and m, respectively, are kept constant.
Let us remark that, as a byproduct of Theorem 7, we also get that, even when the agent has a constant number of actions, it is NP-hard to approximate the contract-design problem up to within any given constant factor. Specifically, the theorem implies that, for any   1, there exists a constant k  N that depends on  such that the problem is NP-hard to approximate up to within a multiplicative loss  even when restricted to Bayesian principal-agent settings with |A|  k. However, the constant number of actions k required for the hardness increases as the multiplicative approximation loss  increases. We leave as an open problem determining whether there are or not algorithms providing reasonable approximation guarantees with a small number of agent's actions.
5.1 Constant Number of Types
The crucial observation grounding our result is that the hardness of the problem of designing an optimal contract in Bayesian principal-agent settings stems from the difficulty of finding, among the exponentially-many possibilities, the tuple of agent's actions (one per type) that need to be incentivized. Instead, given a tuple (a) defining an agent's
15

ARXIV PREPRINT - JUNE 2, 2021

action a  A for each type   , a contract that implements a for every type    and maximizes the overall principal's expected utility can be obtained by the following linear program:

min
pRm

µ

p F,a,

 

(1a)

s.t.

pF,a, - c,a 

pF,a, - c,a





p  0

  , a  A

(1b)

  ,

(1c)

where, for the ease of notation, we identify a contract with a vector p  Rm whose components are the payments p for    defining the contract. Notice that, given that the agent's actions are fixed, the objective function to be minimized is the expected payment from the principal to the agent (as the principal's reward is fixed). Constraints (1b) ensure that each action a is IC for an agent of type    (recall that IR is ensured by Assumption 1).
The following proposition shows that an optimal contract can be found by enumerating all the possible n tuples of actions (a), selecting the one that gives the highest optimal value for Problem (1) (and the corresponding contract). As an immediate consequence, we get that, when the number of agent's types  is kept constant, then the overall running time of the resulting algorithm is polynomial in the size of the problem instance. 9

Theorem 8. There exists an algorithm running in time polynomial in n and m that finds an optimal contract in any Bayesian principal-agent instance given as input.

5.2 Constant Number of Outcomes

The crucial insight underlying the polynomial-time algorithm is that, when the number of outcomes is kept constant,

it is sufficient to search for an optimal contract in a polynomially-sized set of possible candidates. For the ease of

notation, we let P := Rm + be the set of vectors identifying all the possible contracts, where, given p  Rm + , we denote with p the vector component defining the payment associated to outcome   . Moreover, for every agent's action a  A and agent's type   , we let P (a, )  P be the set identifying all the contracts that implement action a

for an agent of type . Formally, the set P (a, ) is characterized by the following set of inequalities representing IC

constraints:

pF,a, - c,a 

pF,a, - c,a a  A : a = a.

(2)





× Additionally, for every tuple of agent's actions a = (a)   A, we let P (a) :=  P (a, ) be
the set identifying all the contracts that implement action a for each agent's type   . Finally, we let P  := × a  A V(P (a)), where V(P (a)) denotes the set of vertices of polytope P (a).

The following theorem shows that, given any Bayesian principal-agent setting, there always exists an optimal contract belonging to the set P  and that P  has size bounded by a polynomial in nm and m. Thus, whenever the number of outcomes m is kept constant, an optimal contract can be computed in time polynomial in the size of the instance.

Theorem 9. There exists an algorithm running in time polynomial in nm and m that finds an optimal contract in any Bayesian principal-agent instance given as input.

6 Discussion
Despite principal-agent problems are ubiquitous in real-world economic scenarios, computational works on these problems appeared only recently and they are limited to specific settings (Babaioff et al., 2012; Dütting et al., 2019, 2020). In this paper, we introduce and study a new Bayesian principal-agent model in which the principal is uncertain about the agent's type. This makes a considerable step over classical (non-Bayesian) principal-agent settings, as there are many real-world problems in which it is unreasonable to assume that the principal has complete knowledge of the agent. Moreover, our Bayesian model begets new computational challenges that make it worth studying on its own, since, differently from the non-Bayesian case, in our setting a principal-optimal contract cannot be computed efficiently.
Linear contracts are the de facto standard usually employed in real-world principal-agent problems, given their relative implementation simplicity, due to them being based on a pure-commission principle. As a result, the research on principal-agent problems (mainly in economics, but also in computer science (Dütting et al., 2019)) strived to find
9The proofs of Theorem 8 and Theorem 9 are deferred to the Appendix.

16

ARXIV PREPRINT - JUNE 2, 2021
mathematical justifications of why linear contracts are so popular in practice. Recently-developed studies show that, in non-Bayesian principal-agent settings, linear contracts are approximately optimal except in some degenerate situations (Dütting et al., 2019) and that they enjoy some robustness properties (Carroll, 2015, 2019; Dütting et al., 2019). Our results further justify the use of linear contracts, showing that, in more realistic settings as those captured by our Bayesian model, they are the best among all the contracts that can be designed with bounded computationally resources.
Acknowledgments
This work has been partially supported by the Italian MIUR PRIN 2017 Project ALGADIMAR "Algorithms, Games, and Digital Market".
References
Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy. Proof verification and the hardness of approximation problems. Journal of the ACM (JACM), 45(3):501­555, 1998.
Moshe Babaioff and Eyal Winter. Contract complexity. EC, 14:911, 2014. Moshe Babaioff, Michal Feldman, and Noam Nisan. Combinatorial agency. In Proceedings of the 7th ACM Conference
on Electronic Commerce, pages 18­28, 2006. Moshe Babaioff, Michal Feldman, and Noam Nisan. Free-riding and free-labor in combinatorial agency. In Interna-
tional Symposium on Algorithmic Game Theory, pages 109­121. Springer, 2009. Moshe Babaioff, Michal Feldman, and Noam Nisan. Mixed strategies in combinatorial agency. Journal of Artificial
Intelligence Research, 38:339­369, 2010. Moshe Babaioff, Michal Feldman, Noam Nisan, and Eyal Winter. Combinatorial agency. Journal of Economic Theory,
147(3):999­1034, 2012. Hamsa Bastani, Mohsen Bayati, Mark Braverman, Ramki Gummadi, and Ramesh Johari. Analysis of medicare pay-
for-performance contracts. Available at SSRN 2839143, 2016. Patrick Bolton, Mathias Dewatripont, et al. Contract theory. MIT press, 2005. Gabriel Carroll. Robustness and linear contracts. American Economic Review, 105(2):536­63, 2015. Gabriel Carroll. Robustness in mechanism design and contracting. Annual Review of Economics, 11:139­166, 2019. Lin William Cong and Zhiguo He. Blockchain disruption and smart contracts. The Review of Financial Studies,
32(5):1754­1797, 2019. Paul Dütting, Tim Roughgarden, and Inbal Talgam-Cohen. Simple versus optimal contracts. In Proceedings of the
2019 ACM Conference on Economics and Computation, pages 369­387, 2019. Paul Dütting, Tim Roughgarden, and Inbal-Talgam Cohen. The complexity of contracts. In Proceedings of the
Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 2688­2707. SIAM, 2020. Sanford J Grossman and Oliver D Hart. An analysis of the principal-agent problem. Econometrica, 51(1):7­46, 1983. Guru Guruganesh, Jon Schneider, and Joshua Wang. Contracts under moral hazard and adverse selection, 2020. Johan Håstad. Clique is hard to approximate within n1-. Acta Mathematica, 182(1):105­142, 1999. Chien-Ju Ho, Aleksandrs Slivkins, and Jennifer Wortman Vaughan. Adaptive contract design for crowdsourcing mar-
kets: Bandit algorithms for repeated principal-agent problems. Journal of Artificial Intelligence Research, 55:317­ 359, 2016. Bengt Holmstrom and Paul Milgrom. Multitask principal-agent analyses: Incentive contracts, asset ownership, and job design. Journal of Law, Economics, & Organization, 7:24, 1991. Jean-Jacques Laffont and David Martimort. The theory of incentives: the principal-agent model. Princeton university press, 2009. Andreu Mas-Colell, Michael Dennis Whinston, Jerry R Green, et al. Microeconomic theory, volume 1. Oxford university press New York, 1995. Ran Raz. A parallel repetition theorem. SIAM Journal on Computing, 27(3):763­803, 1998. William P Rogerson. Repeated moral hazard. Econometrica: Journal of the Econometric Society, pages 69­76, 1985.
17

ARXIV PREPRINT - JUNE 2, 2021

Steven Shavell. Risk sharing and incentives in the principal and agent relationship. The Bell Journal of Economics, pages 55­73, 1979.
David Zuckerman. Linear degree extractors and the inapproximability of max clique and chromatic number. Theory of Computing, 3(6):103­128, 2007.

A Proofs Omitted from Section 5

Theorem 8. There exists an algorithm running in time polynomial in n and m that finds an optimal contract in any Bayesian principal-agent instance given as input.
× Proof. The algorithm works by solving Problem (1) for every possible tuple (a) in the set  A. Then, it picks
the tuple (and the corresponding contract obtained by solving Problem (1) for it) that results in the highest optimal value for Problem (1). We prove the correctness of the algorithm by showing that the returned contract, identified by a vector p  Rm, must provide the principal with an expected utility at least as large as that of any other contract. Let us take an arbitrary contract identified by vector p  Rm, and let (a) be a tuple such that, for every   , the contract implements action a for an agent of type . Then, by solving Problem (1) for (a), the algorithm finds a contract incentivizing the same tuple of agent actions and requiring the principal an expected payment smaller than or equal to that of p. Notice that, since the contract found by solving the LP in Problem (1) may lie on the boundary of its feasible region, there could be other tuples of agent actions that are incentivized by the contract. However, by using the assumption that the agent always breaks ties in favor of the principal, we can conclude that the tuple of agent actions that is actually played must provide the principal with an expected reward greater than or equal to that obtained for (a). Thus, we can conclude that p provides the principal with an expected revenue greater than or equal to that of p, while requiring a smaller or equal payment, showing the correctness of the algorithm. Finally, notice that the
× algorithm solves n different LPs, one for each tuple in  A. The LPs have m variables and  · n constraints, and,
thus, they can be solved in time polynomial in n, m, and .
Theorem 9. There exists an algorithm running in time polynomial in nm and m that finds an optimal contract in any Bayesian principal-agent instance given as input.

Proof. The proof involves two steps.

First Step We show that, for any contract defined by a vector p  P , there exists another contract identified by a vector p  P  providing the principal with an expected utility greater than or equal to that obtained for p. Let
× a = (a)   A be a tuple of agent actions such that the contract p implements action a for every type
  . Let us define p  P as the optimal solution of the LP in Problem (1) for the tuple (a). Noticing that the objective of Problem (1) is to minimize a linear function over the polytope P (a), we can assume w.l.o.g. that the vector p is a vertex of the polytope, i.e., that p  V(P (a)). Notice that, since p lies on a vertex of the feasible region of the LP, then there might be other tuples of agent actions that are incentivized by the contract identified by p.
However, given the assumption that the agent breaks ties in favor of the principal, these would provide the principal with an expected reward greater than or equal to that obtained for (a). Thus, we can conclude that p has expected reward greater than or equal to that of p, while requiring a smaller or equal payment, proving the first step.

Second Step We show that the size of P  can be bounded by a polynomial in nm and m. For any tuple of agent
× actions a = (a)   A, the set P (a) is an m-dimensional polytope, and, thus, each vertex in V(P (a)) is
determined by the intersection of exactly m hyperplanes among those defining it. Each polytopes P (a) is characterized

by a subset of the hyperplanes defining the sets P (a, ) for a  A and   . After removing duplicates, we can

conclude that, for each   , there are at most

n 2

hyperplanes resulting from Constraints 2, which are those defining

the boundaries between the sets P (a, ) and P (a, ), for any pair of actions a, a  A such that a = a. Moreover,

there are m hyperplanes resulting from non-negativity constraints, namely p  0 for every   . As a result, each polytope P (a) is defined by a subset of the same set of at most n2 + m hyperplanes. Hence, each vertex in P  is

obtained as the intersection of exactly m of these at most n2 + m hyperplanes and we can conclude that there are at

most all the

n2+m m
vertices

vertices in P . In conclusion, to find an optimal contract in P , which requires time polynomial in nm and m.

it

is

sufficient

that

the

algorithm

enumerates

18

