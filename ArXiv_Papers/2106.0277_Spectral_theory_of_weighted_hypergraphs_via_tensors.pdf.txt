Spectral theory of weighted hypergraphs via tensors
Francesco Galuppi1, Raffaella Mulas2,3, and Lorenzo Venturello 4
1University of Trieste, Trieste, Italy 2The Alan Turing Institute, London, UK 3University of Southampton, Southampton, UK 4KTH Royal Institute of Technology, Stockholm, Sweden

arXiv:2106.00277v1 [math.CO] 1 Jun 2021

Abstract
One way to study an hypergraph is to attach to it a tensor. Tensors are a generalization of matrices, and they are an efficient way to encode information in a compact form. In this paper we study how properties of weighted hypergraphs are reflected on eigenvalues and eigenvectors of their associated tensors. We also show how to efficiently compute eingenvalues with some techniques from numerical algebraic geometry.
Keywords: Spectral hypergraph theory, Tensors, Weighted hypergraphs, Eigenvalues

1 Introduction

Spectral hypergraph theory
Spectral graph theory is the study of the qualitative properties of a graph G = (V, E) that can be inferred from the spectrum, i.e. the multiset of the eigenvalues, of a square matrix associated to G. If the vertices of G are labelled as v1, . . . , vN , the considered square matrices are usually the N × N adjacency matrix A, whose entries are

Aij := 1 if (vi, vj)  E 0 otherwise,

the Kirchhoff Laplacian

K := D - A,

where D is the diagonal matrix of the degrees, and the normalized Laplacian

L := Id -D-1/2AD-1/2,

where Id is the N ×N identity matrix. There is a 1 : 1 correspondence between graphs and each of these operators. While there exist non-isomorphic graphs with the same spectra, nevertheless such spectra are known to detect many important geometric properties of the graph. Thus, if two graphs are isospectral with respect to a given operator, they have similar structures. Spectral graph theory has a long history, it has many connections with
Email address: fgaluppi@units.it Email address: r.mulas@soton.ac.uk Email address: lven@kth.se

1

the spectral theory in Riemannian geometry, and it is widely used in applications. In fact, because empirical networks can often be modeled as graphs, the computation of the spectra is a valid tool for studying and analyzing real data. Moreover, this theory also finds applications in the study of dynamical systems on graphs. The normalized Laplacian is isospectral to the random walk Laplacian
L := Id -D-1A,

whose off-diagonal entry

Lij

=

- Aij deg vi

is the probability that a random walker goes from vi to vj. Hence, the spectral theory of L and L has many connections with random walks on graphs. We refer the reader to [7, 8]

for classical monographs on the spectral theory of graphs.

Hypergraphs are defined as a generalization of graphs in which edges can link more than two vertices, that is, edges are sets of vertices of any cardinality. They allow the modeling of many more real networks than graphs, therefore they are often used in applications as well, see for instance [4, 5, 16, 17, 28, 34]. It is natural to ask what is the best way to generalize spectral graph theory to the case of hypergraphs, but the answer is not univocal. In fact, the spectral theory of hypergraphs can be studied either via matrices or via tensors, and the two approaches have different advantages. While there is a 1 : 1 correspondence between hypergraphs and their associated tensors, the same does not hold for the hypergraph adjacency and Laplacian matrices. Hence, the spectrum of a hypergraph tensor is expected to detect more precise structural properties of the hypergraph than the spectrum of a hypergraph matrix. However, the tensor eigenvalue problem is NP-hard [11], therefore it is more convenient to consider matrices for the analysis of big data that are modeled with hypergraphs.

In this work, we bring forward the spectral theory of hypergraphs via tensors and we generalize the operators in [1­3, 9, 23, 24] to the case of weighted hypergraphs, for which each edge has a positive weight. We show that most of the spectral properties that are known for unweighted hypergraphs can be generalized to the weighted case, and we prove several results which are also new for the unweighted case. We refer to [26] for a monograph on the spectral theory via tensors of uniform, unweighted hypergraphs. We refer to [15] for the related spectral theory of multilayer networks. For completeness, we also refer the reader to [13, 14, 21, 22, 29­31] for a vast -- but by no means complete -- literature on the spectral theory of hypergraphs via matrices.

Tensors
We start by recalling several definitions and properties of tensors that will be needed throughout the paper. We refer to [26] for a monograph on this topic. Given n  N, we denote by [n] the set {1, . . . , n}. We indicate a vector in Cn by x = (x1, . . . , xn). We write x  0 if xi  0 for every i  [n]. Let k, n  2. A k-th order n-dimensional tensor T consists of nk complex entries
Ti1,...,ik  C,
where i1, . . . , ik  [n]. The tensor T is symmetric if its entries are invariant under any permutation of their indices. One of the many differences between the spectral theory of

2

matrices and of tensors is that a the eigenvalues of a real symmetric tensor do not need
to be real. Given a vector x  Cn, define T xk-1  Cn by

n

(T xk-1)i =

Ti,i2,...,ik xi2 · · · xik .

i2 ,...,ik =1

Let x[k-1]  Cn be the vector with entries x[ik-1] := xki -1. If T xk-1 = x[k-1] for some   C and some non-zero vector x  Cn, then we say that (, x) is an eigenpair for T . The number  is an eigenvalue of T and x is an eigenvector. The spectral radius of T , denoted (T ), is the largest modulus of the eigenvalues of T . Let Id denote the k-th order n-th dimensional unit tensor, with entries

1 Idi1,...,ik := 0

if i1 = . . . = ik = 1 otherwise.

As shown in [25, Section 3], the eigenvalues of T are the roots of the characteristic polynomial
T () := det(T -  Id)
of T . The spectrum of T , denoted Spec(T ), is the multiset of its eigenvalues, counted with multiplicity as roots of the characteristic polynomial. An eigenpair (, x) is given by an H-eigenvalue and an H-eigenvector, respectively, if   R and x  Rn. We let Hspec(T ) denote the set of distinct H-eigenvalues of T . The tensor T is non-negative if all its entries are non-negative. The tensor T is weakly irreducible if, for any non-empty proper index subset J of [n], there is at least one entry

Ti1,...,ik = 0,
where i1  J and at least one index ij  [n] \ J, for j = 2, . . . , k. Similarly, T is reducible if there exists a non-empty proper set J of [n] such that

Ti1,...,ik = 0,

for each i1  J, i2, . . . , ik  [n] \ J. It is irreducible if it is not reducible. In [26, Theorem 3.11], the Perron-Frobenius theorem for non-negative matrices has been generalized to weakly irreducible non-negative tensors.

Theorem 1.1. If T is non-negative and weakly irreducible, then

(T

)

=

max
x0 x=0

min
xi>0

(T xk-1)i xik-1

is a positive H-eigenvalue, with a positive H-eigenvector x¯. Furthermore, (T ) is the unique H-eigenvalue of T with a positive H-eigenvector, and x¯ is the unique positive Heigenvector associated to (T ), up to a multiplicative constant.

Now, T is diagonally dominated if, for each i  [n],

Ti,...,i 

|Ti,i2,...,ik | .

(1)

i2 ,...,ik [n] not all equal to i

3

By [27, Theorem 2], if T is diagonally dominated and  is an eigenvalue for T , then there exists i  [n] such that

| - Ti,...,i| 

|Ti,i2,...,ik | .

(2)

i2 ,...,ik [n] not all equal to i

An immediate consequence is the following

Corollary 1.2. If T is a diagonally dominated tensor, then all its H-eigenvalues are non-negative.

Eigenvalue multiplicities
For a given tensor, the algebraic multiplicity of an eigenvalue , denoted am(), is its multiplicity as a root of the characteristic polynomial. The geometric multiplicity of , denoted gm(), is the dimension of its eigenvariety, i.e. the variety of its eigenvectors. While algebraic and geometric multiplicity coincide for symmetric matrices, this is not always the case for symmetric tensors. In [25, Section 3] it is conjectured that am()  gm() for any . In [12, Conjecture 1.1], it is conjectured that
am()  gm()(k - 1)gm()-1.
Given an eigenvalue , we also introduce its span multiplicity, denoted sm(), as the dimension of the vector space
span({x  Cn : x eigenvector for }).
Clearly, sm()  gm(). We conjecture that, for each eigenvalue ,
am()  sm().
If  is a real eigenvalue, we introduce its Hspan multiplicity, denoted Hsm(), as the dimension of the vector space
span({x  Rn : x eigenvector for }).
In the case of symmetric matrices, every eigenvalue  is an H-eigenvalue and
am() = sm() = Hsm() = gm().
In spectral graph theory and spectral hypergraph theory via matrices, the multiplicity of an eigenvalue is often studied by counting the maximum number of its linearly independent eigenvectors. This is what motivates us to introduce the span and the Hspan multiplicities.

Stirling numbers
Given a multiset i1, . . . , ik, let {i1, . . . , ik} be the set obtained from i1, . . . , ik by not accounting for multiplicity. Given a k-th order n-dimensional tensor T and an index set J  [n] of cardinality r, we say that an entry Ti1,...,ik of T corresponds to J if {i1, . . . , ik} = J. We let
N (r, k) := |entries of T corresponding to J|.

4

Given j  J, we define its j-th row as the (k - 1)-order n-dimensional tensor Tj obtained by setting the first index of T equal to j. We also set

N (r, k) N (r, k) := r = |entries of the row Tj corresponding to J|.

Observe that it does not depend on j. As shown in [23],

k!

N (r, k) =

,

k1,...,kr1, k1! · · · kr!

j kj =k

from which it follows that





1

k! 

N (r, k) = · 

.

r

 k1 ,...,kr 1,

k1!

·

·

·

kr !

 

j kj =k

However, we observe that we can write N (r, k) =

k r

r!, where

k

1 :=

r
(-1)j

r

(r - j)k

r r!

j

j=0

is the Stirling number of the second kind. This follows from the fact that

k r

counts the

number r-partitions of a set of cardinality k, while r! counts the number of permutations

of r objects. Hence,

k N (r, k) = (r - 1)!.
r

In particular, N (k, k) = (k - 1)!. The above characterization of N (r, k) will allow us to give a description of the hypergraph tensors which is simpler than the one in [1­3, 23, 24].

Weighted hypergraphs

Throughout the paper, we fix a weighted hypergraph G = (V, E, w) with vertex set V =

{v1, . . . , vN }, edge set E = {e1, . . . , eM } and weight function w : E  R>0. We assume that each edge contains at least two vertices.

Given v  V , its degree is

deg v :=

w(e).

eE: ve

Given e  E, we denote its cardinality by |e|. We let

 := min deg v,  := max deg v and  := max |e|.

vV

vV

eE

G is -regular if deg v =  for each v  V ; it is -uniform if |e| =  for each e  E. Given r  , we let
Er := {e  E : |e| = r}.

G is connected if, for every pair of vertices v, w  V , there exists a path that connects v and w, i.e. there exist v^1, . . . , v^k  V and e^1, . . . , e^k-1  E such that v^1 = v, v^k = w, and {v^i, v^i+1}  e^i for each i = 1, . . . , k - 1. The hypergraph G = (V, E, w) is unweighted if w(e) = 1 for each e  E. In this case, we use the notation G = (V, E). A simple graph is an unweighted 2-uniform hypergraph.

5

Structure of the paper
In Section 2 we introduce the tensors we are interested in. Our definitions generalize the known hypergraph tensors to the case of weighted hypergraphs. In Section 3 we prove some basic properties of the eigenvalues of such tensors. Section 4 is devoted to duplicate vertices, a combinatorial feature of an hyperghraph that has a clear impact on the spectra. This is particularly evident for hyperflowers, a remarkable family of hypergraphs that generalize star graphs and that we analyse in Section 5. Section 6 adds more words to our dictionary. We are able to translate properties of the hypergraphs, such as being bipartite or colorable, to spectral symmetries. Finally, in Section 7 we show how to effectively compute eigenvalues and their geometric multiplicities. We apply techniques from numerical algebraic geometry.

2 Hypergraph tensors

As we recalled in the introduction, there are several tensors attached to an hypergraph. In this section we generalize these tensors for weighted hypergraphs. Let G = (V, E, w) be a weighted hypergraph on N nodes, with largest edge cardinality . The adjacency tensor of G is the -th order N -dimensional tensor A = A(G) with entries

Ai1,...,i :=

0
w(e) N (r,)

if {vi1, . . . , vi} / E if {vi1, . . . , vi} = e  Er.

The Kirchhoff Laplacian tensor of G is the -th order N -dimensional tensor K = K(G)

with entries

Ki1,...,i :=

deg vi1 -Ai1,...,i

if i1 = . . . = i otherwise.

The normalized Laplacian tensor of G is the -th order N -dimensional tensor L = L(G) with entries


1 Li1,...,i := -Ai1,...,i ·

j{i1,...,i}

1
 deg vj

if i1 = . . . = i otherwise.

The random walk Laplacian tensor of G is the -th order N -dimensional tensor L = L(G)

with entries

Li1,...,i :=

1 - Ai1,...,i
deg vi1

if i1 = . . . = i otherwise.

For unweighted hypergraphs, A, K, L and L coincide with the tensors in [2, Section

3]. In the case of simple graphs, the adjacency, Kirchhoff Laplacian, normalized Laplacian

and random walk Laplacian tensors coincide with the adjacency, Kirchooff Laplacian,

normalized Laplacian and random walk Laplacian matrices, respectively.

Some of the tensors defined above have a signless version. The signless Kirchhoff Laplacian tensor of G is the -th order N -dimensional tensor K+ = K+(G) with entries

Ki+1,...,i :=

deg vi1 Ai1,...,i

if i1 = . . . = i otherwise.

6

The signless normalized Laplacian tensor of G is the -th order N -dimensional tensor L+ = L+(G) with entries

 1 L+i1,...,i := Ai1,...,i ·

j{i1,...,i}

1
 deg vj

if i1 = . . . = i otherwise.

The signless random walk Laplacian tensor of G is the -th order N -dimensional tensor L+ = L+(G) with entries

L+i1,...,i :=

1
Ai1 ,...,i deg vi1

if i1 = . . . = i otherwise.

For unweighted hypergraphs, K+ and L+ coincide with the tensors in [9]. In the case of simple graphs, the signless Kirchhoff Laplacian, signless normalized Laplacian and signless random walk Laplacian tensors coincide with the signless Kirchooff Laplacian, signless normalized Laplacian and signless random walk Laplacian matrices, respectively.

Remark 2.1. From the definition, it is apparent that the tensors A, K, K+, L and L+ are symmetric and that the tensors A, K+, L+ and L+ are non-negative.

Example 2.2. Let G = (V, E, w) be the weighted hypergraph with vertex set V = {v1, v2, v3}, edge set E = {{v1, v2}, {v1, v2, v3}} and weights w({v1, v2}) = 1 and w({v1, v2, v3}) = 2. In this case, N =  = 3. The non-zero entries of the adjacency tensor are

Figure 1: The hypergraph in Example 2.2.

A112

=

A121

=

A211

=

A122

=

A212

=

A221

=

w({v1, v2}) N (2, 3)

=

1 3

and

A123

=

A132

=

A213

=

A231

=

A312

=

A321

=

w({v1, v2, v3}) N (3, 3)

=

1.

Also, since deg v1 = deg v2 = 3 and deg v3 = 2, the non-zero entries of K are

1

K112

=

K121

=

K211

=

K122

=

K212

=

K221

=

-, 3

K123 = K132 = K213 = K231 = K312 = K321 = -1,

K111 = K222 = 3, K333 = 2.

Similarly, the non-zero entries of L are

1

L112

=

L121

=

L211

=

L122

=

L212

=

L221

=

-, 9

7

1

L123

=

L132

=

L213

=

L231

=

-, 3

1

L312

=

L321

=

- 2

L111 = L222 = L333 = 1.

3 First properties

In this section, we prove the first spectral properties of the hypergraph tensors that we introduced in the previous section. Some of our results generalize those in [26, Chapter 4] to weighted hypergraphs. We start by proving that the normalized Laplacian of a weighted hypergraph has the same spectrum as the random walk Laplacian tensor. The same holds for the signless versions.
Proposition 3.1. The tensors L and L have the same eigenvalues, counted with algebraic multiplicity. Moreover,

(, x) is an eigenpair for L  (, y) is an eigenpair for L,

where y  CN is the vector with entries

yj =

xj .  deg vj

Hence, the eigenvalues of L and L have also the same geometric and span multiplicities, and Hspec(L) = Hspec(L). The same holds for L+ and L+.

Proof. For the algebraic multiplicities, we only prove the claim for L and L. The other case is similar. As recalled for instance in [10, Page 2219], if d1, . . . , dN  R, then L has the same eigenvalues, counted with algebraic multiplicity, as the -th order N -dimensional tensor L (d1, . . . , dN ) with entries
1 L (d1, . . . , dN )i1,...,i = di1-1 · Li1,...,i · di2 · · · di .

By taking dj =  deg vj for each j  [N ], we have that L (d1, . . . , dN ) = L. This proves the claim. For the other multiplicities, we only prove that

(, x) eigenpair for L  (, y) eigenpair for L,

the other claims being similar. Observe that, if (, x) is an eigenpair for L, then
Li1,i2,...,i xi2 · · · xi =  · xi1-1, for each i1  [N ].
i2,...,i[N ]
Therefore, for each i1  [N ],

Li1,i2,...,i yi2 · · · yi

i2,...,i[N ]
=
i2,...,i[N ]


j{i1,...,i}  deg vj
deg vi1

Li1,i2,...,i yi2 · · · yi

8





=

 deg vi1 deg vi1



Li1,i2,...,ik

i2,...,i[N ]

 deg vi2 yi2 · · ·

 deg vi yi 





=

 deg vi1 deg vi1



Li1,i2,...,i xi2 · · · xi 

i2,...,i[N ]

=

 deg vi1 deg vi1

 · xi1-1 =  · yi1 -1,

implying that (, y) is an eigenpair for L.

Proposition 3.2. Each of the tensors A, K, K+, L, L+, L and L+ has ( - 1)N-1 · N eigenvalues, counted with algebraic multiplicity, whose sum is:
· 0, for A;

· ( - 1)N-1 ·

N i=1

deg

vi

, for K

and K+;

· ( - 1)N-1 · N , for L, L+, L and L+.
Proof. As shown in [25, Section 3], a symmetric tensor has ( - 1)N-1 · N eigenvalues, counted with algebraic multiplicity, whose sum is ( - 1)N-1 times the sum of its diagonal elements. Hence, the claim for A, K, K+, L and L+ follows. The claim for L and L+ follows by Proposition 3.1.

In Section 2 we defined quite a few tensors. However, Proposition 3.1 tells us that two of them are the same, from the spectrum viewpoint. The next two Remarks are a further step in this direction. They show that the spectra of all our tensors are closely related.
Remark 3.3. We have L+ = 2 · Id -L and L+ = 2 · Id -L. Therefore, it is easy to check that
(, x) is an eigenpair for L  (2 - , x) is an eigenpair for L+
and (, x) is an eigenpair for L  (2 - , x) is an eigenpair for L+. Moreover,

(0, x) is an eigenpair for K  (0, x) is an eigenpair for L

and similarly (0, x) is an eigenpair for K+  (0, x) is an eigenpair for L+. Finally, (0, x) is an eigenpair for A  (1, x) is an eigenpair for L and L+.

Remark 3.4. If G is -regular, then

K =  · Id -A,

1 L=L= ·K

and

K+ = 2 · Id -K.



Hence, in this case, it is easy to see that

 is an eigenvalue for K   -  is an eigenvalue for A
  is an eigenvalue for L = L
  2 -  is an eigenvalue for L+ = L+
  2 -  is an eigenvalue for K+,

with the same multiplicities. In particular, the spectral theories of the different tensors are equivalent to each other for regular weighted hypergraphs.

9

Such observations allow us to expand on the previous knowledge on their eigenvalues. For instance, we are in position to discuss existence of H-eigenvectors and H-eigenvalues.
Proposition 3.5. 1. The tensors A, K+, L+, and L+ have at least one H-eigenvalue. Their largest H-eigenvalue equals their spectral radius, and has a non-negative Heigenvector.

2. The tensors L, and L have at least one H-eigenvalue. Their smallest H-eigenvalue equals 2 - (L), and has a non-negative H-eigenvector.
Proof. The first claim follows from [26, Theorem 2.4], which applies to non-negative tensors. The second claim follows from the first one, together with Proposition 3.1 and Remark 3.3.

Now we want to prove that our hypergraph tensors are diagonally dominated. For this purpose we compute the sums of their rows, which is an interesting result in itself. This will also allow to bound their H-eigenvalues.

Theorem 3.6. Given i1  [N ],

Ai1,i2,...,i = deg vi1 ,
i2,...,i[N ]

Ki1,i2,...,i =

Li1,i2,...,i = 0,

i2,...,i[N ]

i2,...,i[N ]

Ki+1,i2,...,i = 2 · deg vi1 ,
i2,...,i[N ]

L+i1,i2,...,i = 2.
i2,...,i[N ]

Proof. Given i1  [N ],







w(e)

Ai1,i2,...,i =



|entries of the row Ai1 corresponding to e| · N (r, ) 

i2,...,i[N ]

r=2 eEr: i1e



=

w(e) = deg vi1.

r=2 eEr: i1e

This implies that

while Similarly,

Ki1,i2,...,i = deg vi1 -

Ai1,i2,...,i = 0,

i2,...,i[N ]

i2,...,i[N ]





1

Li1,i2,...,i
i2,...,i[N ]

=

deg vi1



K+i1,i2,...,i 

i2,...,i[N ]

=

0.

Ki+1,i2,...,i = deg vi1 +

Ai1,i2,...,i = 2 · deg vi1

i2,...,i[N ]

i2,...,i[N ]

and





L+i1,i2,...,i
i2,...,i[N ]

=

1 deg vi1



Ki+1,i2,...,i 

i2,...,i[N ]

=

1 deg vi1

(2 · deg vi1)

=

2.

10

Now we show that hypergraph tensors are diagonally dominated, and we prove some bounds for their eigenvalues.
Corollary 3.7. The tensors K, L, K+ and L+ are diagonally dominated. Moreover, if  is an eigenvalue for K or K+, then there exists i  [N ] such that

| - deg vi|  deg vi. If µ is an eigenvalue for L or L+, then

|µ - 1|  1.
In particular, all the H-eigenvalues of K and K+ are in [0, ], while all the H-eigenvalues of L and L+ (equivalently, L and L+) are in [0, 2].
Proof. By Theorem 3.6, for each i  [N ] we have

Ki,...,i = deg vi =

|Ki,i2,...,i | ;

i2,...,i[N ] not all equal to i

Ki+,...,i = deg vi =

Ki+,i2,...,i ;

i2,...,i[N ] not all equal to i

Li,...,i = 1 =

|Li,i2,...,i | ;

i2,...,i[N ] not all equal to i

L+i,...,i = 1 =

L+i,i2,...,i .

i2,...,i[N ] not all equal to i

Hence, K, L, K+ and L+ satisfy (1), implying that they are diagonally dominated. By Equation (2), which holds for diagonally dominated tensors, the second claim follows.

Now we move to irreducibility. Generalizing [26, Theorem 4.1], we give a necessary and sufficient condition for our tensors to be weakly irreducible, as defined in Section 1.
Theorem 3.8. A, K, K+, L, L+, L and L+ are weakly irreducible tensors if and only if G is connected.

Proof. Without loss of generality, we only prove the claim for A. By definition, the tensor A is weakly irreducible if and only if for any non-empty proper index subset J of [N ], there is at least one entry
Ai1,...,i = 0,
where i1  J and at least one index ij  [N ] \ J, for j = 2, . . . , . By definition of A, this happens if and only if, for each non-empty proper subset J of [N ], there exist i1  J and ij  [N ] \ J such that vi1 and vij share a common edge. Hence, A is weakly irreducible if and only if the hypergraph is connected.

Now that weakly irreducibility is settled, we address irreducibility. As it turns out, there is a combinatorial property of the hypergraph that will allow us to characterize irreducible hypergraph tensors.

11

Figure 2: A reducible hypergraph. This can be seen by taking V1 = {v1, v2, v3} and V2 = {v4, v5}.
Definition 3.9. A hypergraph G = (V, E, w) is reducible if one can decompose the vertex set as a disjoint union V = V1 V2 such that V1 and V2 are both non-empty and, for each edge e,
e  V1 =   |e  V1|  2. A hypergraph is irreducible if it is not reducible.
Let us consider some examples:
· Every disconnected hypergraph is reducible.
· If G has one vertex v that is not contained in any edge of cardinality 2, then, by setting V1 = V \ {v} and V2 = {v}, it is clear that G is reducible. This implies, in particular, that the majority of connected hypergraphs are reducible.
· If G = (V, E) and there exists E  E such that G = (V, E ) is a connected graph, then G is irreducible. In particular, every connected graph is irreducible.
Theorem 3.10. A, K, K+, L, L+, L and L+ are irreducible tensors if and only if G is an irreducible hypergraph.
Proof. If G is reducible, let V = V1 V2 be a decomposition of the vertex set as in Definition 3.9. Then, setting J = {i  [N ] : vi  V1} shows that the tensors associated to G are reducible. Vice versa, if J  [N ] shows that the tensors associated to G are reducible, then setting V1 = {vi  V : i  J} and V2 = V \ V1 shows that G is a reducible hypergraph.
Another important property that we want to understand better is the spectral radius. We are able to give tight bounds on (A) and (K+) and to compute (L+) and (L+) for a weighted hypergraph. Proposition 3.11. The spectral radii of A and K+ satisfy
  (A)   and 2  (K+)  2.
In particular, if G is -regular and -uniform, then (A) =  and (K+) = 2.
Moreover, if G = (V, E , w ) is another weighted hypergraph on N vertices and maximum edge cardinality , and it is obtained from G by removing edges or by decreasing some edge weights, then
(A(G ))  (A(G)) and (K(G ))  (K(G)).
12

Proof. If T is a non-negative tensor, then by [26, Lemma 3.20],

min
i1[N

]

i2,...,i

[N

]

Ti1,i2

,...,i



(T )



max
i1[N ]

i2

,...,i

[N

]

Ti1

,i2,...,i

.

By Theorem 3.6, this implies that   (A)   and 2  (K+)  2. Moreover,

if G = (V, E , w ) is another weighted hypergraph on N vertices and maximum edge

cardinality , and it is obtained from G by removing edges or by decreasing some edge

weights, then

A(G )i1,...,i  Ai1,...,i and K+(G )i1,...,i  Ki+1,...,i ,

for each ij  [N ] and j  []. By [19, Lemma 2.3], this implies that

(A(G ))  (A) and (K(G ))  (K).

Proposition 3.12. The spectral radius of L+ and L+ is (L+) = (L+) = 2.
Proof. Since L+ and L+ are isospectral, they have the same spectral radius. Now, since L is a non-negative tensor, by [26, Lemma 3.20],

min
i1[N

]

i2,...,i[N

]

L+i1,i2

,...,i



(L+)



max
i1[N ]

i2

,...,i[N

]

L+i1,i2

,...,i

.

By Theorem 3.6, the claim follows.

Thanks to Proposition 3.12, we can derive more information on the H-eigenvalues and H-eigenvectors.
Corollary 3.13. If G is connected, then 2 is an eigenvalue for L+ and L+, and (1, . . . , 1)  RN is the unique positive H-eigenvector of L+ associated to 2, up to a multiplicative constant.
Proof. The fact that 2 is always an eigenvalue for L+ and L+ follows by Proposition 3.5 and Proposition 3.12. Moreover, it is easy to check that a corresponding eigenvector for L+ is (1, . . . , 1)  RN . By Theorem 1.1, the claim follows.
Corollary 3.14. If G is connected, then 0 is an eigenvalue for K, L and L, and (1, . . . , 1)  RN is the unique positive H-eigenvector of L associated to 0, up to a multiplicative constant.

Proof. It follows from Remark 3.3 and Corollary 3.13.

The last two results concerned connected hyperghraphs. From our viewpoint, it is not very restrictive to assume that the hypergraph is indeed connected. If this is not the case, we can study the spectrum of an hypergraph from the spectra of its connected components. The following theorem generalizes [2, Theorem 3.15].

Theorem 3.15. Given two hypergraphs G1 = (V1, E1, w1) and G2 = (V2, E2, w2), let G := G1 G2 = (V1 V2, E1 E2, w), where w|Ei := wi for i = 1, 2. Let also T  {A, K, K+, L, L+, L, L+}. Then the eigenvalues of T (G) are precisely the eigenvalues of T (G1) together with the eigenvalues of T (G2). Moreover, an eigenvalue that has algebraic multiplicity m for T (G1) has algebraic multiplicity m( - 1)|V2| for T (G).
Proof. This is an immediate consequence of [33, Corollary 4.2].

13

4 Duplicate vertices

In this section we discuss duplicate vertices, i.e. vertices that do not share common edges but are structurally equivalent. It is known that, in the case of graphs, duplicate vertices leave a signature in the spectra of the operators. Also, such vertices are important in applied network theory because their presence is important for the study of the network redundancy and robustness, as discussed in [20].

Definition 4.1. Two vertices vi and vj are duplicate if they do not share common edges and the corresponding rows of the adjacency tensor are the same, that is,

Ai,i2,...,i = Aj,i2,...,i for every i2, . . . , i  [N ].
Note that the above definition of duplicate vertices does not coincide with [22, Definition 3.2], which is based on the hypergraph adjacency matrix. However, both these definitions coincide with the classical one in the case of simple graphs.
Theorem 4.2. If  is even and there are n vertices that are duplicate of each other, then
· 0 is an eigenvalue for A with Hspan multiplicity at least n - 1;
· 1 is an eigenvalue for L, L+, L and L+, with Hspan multiplicity at least n - 1.
Proof. We only prove the claim for A, as the other claims then follow from Remark 3.3. We assume, first, that there are two duplicate vertices, vi and vj. We claim that any vector x  RN satisfying

xi = -xj = 0 and xk = 0 for every k / {i, j} is an eigenvector for the eigenvalue 0. We need to prove that, for each k  [N ],

(T xk-1)k =

Ak,i2,...,i xi2 · · · xi = 0.

i2,...,i[N ]

Since xk = 0 if and only if k  {i, j}, and since vi and vj do not share common edges, this is equivalent to showing that

Ak,i,...,ixi -1 + Ak,j,...,j xj -1 = 0 for every k  [N ].

If k  {i, j}, the above equality holds since both terms on the left side vanish. If k / {i, j}, then Ak,i,...,i = Ak,j,...,j since the i-th row and the j-th row of A coincide, while
xi -1 = -xj -1,

by definition of x and since  is even. This proves the claim for n = 2. More generally, if
v1, . . . , vn are duplicate of each other, for some n  2, then the vectors xj  RN such that xjn = -xjj = 0 and xjk = 0 otherwise, for j = 1, . . . , n - 1, are n - 1 linearly independent eigenvectors for the eigenvalue 0.

Proposition 4.3. Let vi and vj be duplicate vertices. · If (, x) is an eigenpair for A and  = 0, then xi -1 = xj -1. · If (µ, y) is an eigenpair for L, L+, L or L+ and µ = 1, then yi-1 = yj-1.

14

Proof. We only prove the claim for A, the other cases being similar. Since (, x) is an

eigenpair for A,

Ai,i2,...,i xi2 · · · xi = xi -1

(3)

i2,...,i[N ]

and

Aj,i2,...,i xi2 · · · xi = xj -1.

(4)

i2,...,i[N ]

Since vi and vj are duplicate, the left-hand sides in (3) and (4) coincide. Thus,

xi -1 = xj -1.

Since  = 0, this implies that xi -1 = xj -1.

5 The hyperflower

The -hyperflower is the unweighted, -uniform hypergraph G = (V, E) on N nodes and M = N -  + 1 edges, such that

· V = {v1, . . . , vN }

· E = { , . . . , N}

· j = {v1, . . . , v-1, vj} for every j  {, . . . , N }.

We say that the vertices v1, . . . , v-1 are the central vertices of G, while v, . . . , vN are its peripheral vertices. If G is a -hyperflower, all its central vertices belong to all edges, hence they all have degree M . Moreover, the M peripheral vertices of G have degree 1. They are duplicate of each other and therefore, by Theorem 4.2, if  is even then 0 is an eigenvalue for A with Hspan multiplicity at least M - 1, while 1 is an eigenvalue for L, L+, L and L+, with Hspan multiplicity at least M - 1. In the following proposition we improve this result for the hyperflower.

Proposition 5.1. Let   3. If G is a -hyperflower on N nodes, then

· 0 is an eigenvalue for A, with Hspan multiplicity equal to N , and

· 1 is an eigenvalue for L, L+, L and L+, with Hspan multiplicity equal to N .

Proof. We only prove the claim for A. The other claims then follow from Remark 3.3. By [26, Section 4.1.3], since G is -uniform, x = 0 is an eigenvector with eigenvalue 0 for A if, for each k  [N ],
xi2 · · · xi = 0.
(k,i2,...,i)E
That is, x1 · · · x-1 = 0 and


N

 xj ·

xk = 0

j=

k[-1] k=i

for each i  [ - 1]. All vectors of the standard basis of RN satisfy the above conditions, implying that Hspan(0) = N .

15

Remark 5.2. Let G be a -hyperflower. Fix an eigenvalue  = 0 of A(G), and let x  CN be a corresponding eigenvector. By Proposition 4.3, xj -1 is constant for j  {, . . . , N }. Without loss of generality, up to a normalization of x, assume that

xj -1 = 1 for each j  {, . . . , N }.

(5)

Then each xj is a ( - 1)-th root of 1, and the xj's are not necessarily distinct.

By [26, Section 4.1.3], since G is -uniform, the fact that (, x) is an eigenpair for A

implies that

xi2 · · · xi = xk -1

(6)

(k,i2,...,i)E

for each k  [N ]. If vj is a peripheral vertex, (6) together with (5) implies that

x1 · · · x-1 = .

(7)

Hence, since  = 0, we have that xi = 0 for each i  [ - 1]. If vi is a central vertex, i.e. i  [ - 1], (6) implies that

N
xj
j=

·

x1 · · · x-1 xi

=

xi -1.

Thus, by (7),

N

xj = xi

(8)

j=

for each i  [ - 1]. In particular, xi is constant for all i  [ - 1], and

N

N

xi =

xj  |xj| = M,

(9)

j=

j=

 implying that |xi|   M . Also, by (7) and (9),

N

|| = xi =

xj  M.

j=

Theorem 5.3. If G is a -hyperflower with M edges and  is a -th root of 1, then







 M -1,   M -1, . . . , -1  M -1

are eigenvalues of A(G). If, furthermore, M = n( - 1) + 1 for some positive integer n, then 1, , . . . , -1 are also eigenvalues of A(G).

Proof. If  is a -th root of 1 and  is a ( - 1)-th root of , let
· xj :=  for each j  {, . . . , N }, and 
· xi :=   M for each i  [ - 1].

16

By Remark 5.2, x is an eigenvector for the eigenvalue 
xi -1 =   M -1.

Hence







 M -1,   M -1, . . . , -1  M -1

are eigenvalues of G. Now, assume that M = n( - 1) + 1 for some positive integer n. Let again  be a -th root of 1. Let  be a ( - 1)-th root of  and let z := , so that z is a ( - 1)-th root of 1. Assume that the M elements x, . . . , xN are given by
z (n + 1 times) , z2 (n times) , . . . , 1 (n times).

Then, since

-1 k=1

zk

=

0,

by

(8)

we

must

have

N
xj = z = xi ,
j=

if we want x to be an eigenvector. If, in particular, xi :=  for each i  [ - 1], then the above condition is satisfied and, by (7), x is an eigenvector with eigenvalue

xi -1 = -1 = . Hence 1, , . . . , -1 are eigenvalues of A(G).

Example 5.4. Let G = (V, E) be the 3-hyperflower with V = {v1, v2, v3, v4} and E = {{v1, v2, v3}, {v1, v2, v4}} (Figure 3).

Figure 3: The hyperflower in Example 5.4.

The characterstic polynomial of A is (3 - 4)323. Hence, the eigenvalues of A are

0 with multiplicity 23

 3 4 with multiplicity 3

 3 4 with multiplicity 3

 3 42 with multiplicity 3,

where  is a third root of 1. In particular, the distinct eigenvalues are exactly the ones in

Proposition 5.1 and Theorem 5.3.

The characteristic polynomial of K is (2 - 5 + 8)3( - 1)13( - 2)103. Its roots are



0 with multiplicity 3 

57 + i with multiplicity 3
22

57 - i with multiplicity 3
22

1 with multiplicity 13

2 with multiplicity 10.

The characteristic polynomial of L is (2 - 3 + 3)3( - 1)233. Thus, its eigenvalues are

0 with multiplicity 3 2 +  with multiplicity 3

1 with multiplicity 23 2 + 2 with multiplicity 3.

17

Example 5.5. Let G = (V, E) be the 3-hyperflower with V = {v1, v2, v3, v4, v5} and E = {{v1, v2, v3}, {v1, v2, v4}, {v1, v2, v5}} (Figure 4).

Figure 4: The hyperflower in Example 5.5

The characteristic polynomial of A is (3 - 9)3(2 +  + 1)9( - 1)944, therefore its eigenvalues are

0 with multiplicity 44  3 9 with multiplicity 3  3 92 with multiplicity 3 2 with multiplicity 9.

1 with multiplicity 9  3 9 with multiplicity 3
 with multiplicity 9

Also in this case, the distinct eigenvalues of A are exactly the ones in Proposition 5.1 and Theorem 5.3. Now, the characteristic polynomial of K is
(3 - 72 + 15 - 8)9(2 - 7 + 15)3( - 1)36( - 3)83.

The eigenvalues of K are

0 with multiplicity 3 0.7944305695994095 with multiplicity 9 1 with multiplicity 36 3 with multiplicity 8 3.1027847152002956 + 0.6654569511528129i with multiplicity 9 3.1027847152002956 - 0.6654569511528129i with multiplicity 9
 7 11
+ i, with multiplicity 3 2 2 7 11
- i with multiplicity 3. 22 The characteristic polynomial of L is
(93 - 272 + 27 - 8)9(2 - 3 + 3)3( - 1)443 .
387420489 Its eigenvalues are

0, with multiplicity 3 0.519250143230864, with multiplicity 9 1, with multiplicity 44

18

1.240374928384567 + 0.4163415888278001i, with multiplicity 9 1.240374928384567 - 0.4163415888278001i, with multiplicity 9 2 + , with multiplicity 3 2 + 2, with multiplicity 3.

6 Spectral symmetries

In this section we discuss some spectral symmetries. First, we recall [10, Theorem 3.12] and we apply it to the hypergraph tensors.

Definition 6.1 ([10]). Let T be a tensor and let be a positive integer. The tensor T is

spectral -symmetric if

2i
Spec(T ) = e Spec(T ).

Definition 6.2 ([10]). Let k  2 and  2 such that |k. A k-th order n-dimensional
tensor T is (k, )-colorable if there exists a map  : [N ]  [k] such that, if Ti1,...,ik = 0, then
k (i1) + . . . + (ik)  mod k.

Such  is an (k, )-coloring of T .

Definition 6.3 ([10]). The hypergraph G is (, )-colorable, for some  2 such that |, if there exists a map  : [N ]  [] such that, if {i1, . . . , i}  E, then
 (i1) + . . . + (i)  mod .

Remark 6.4. Clearly, the hypergraph G is (, )-colorable if and only if its associated tensors are (, )-colorable.
Theorem 6.5 ([10]). Let T be a symmetric weakly irreducible non-negative tensor of order k. Then T is spectral -symmetric if and only if T is (k, )-colorable.
As an immediate consequence of Theorem 6.5, we obtain the following
Corollary 6.6. A connected hypergraph G is (, )-colorable if and only if A, K+, L+ and L+ are spectral -symmetric.
Proof. The claim for A, K+ and L+ follows directly from Theorem 6.5, since these are all symmetric non-negative tensors and, by Theorem 3.8, they are also weakly irreducible, as we are assuming that G is connected. The claim for L+ then follows by Proposition 3.1.
We now discuss another kind of spectral symmetry for the hypergraph tensors. Recall that a graph G is bipartite if one can decompose the vertex set as a disjoint union V = V1 V2 such that each edge has one endpoint in V1 and one endpoint in V2. It is known that, for a simple graph G, the following are equivalent:
1. G is bipartite
2.   Spec(A)  -  Spec(A), with the same multiplicity
3. Spec(K) = Spec(K+)

19

4.   Spec(L)  2 -   Spec(L), with the same multiplicity.
There are various ways of generalizing the notion of bipartite graph to the case of hypergraphs, see for instance the balanced hypergraphs in [18, Section 3] or the bipartite hypergraphs in [13, Section 6.1.1]. We consider the odd-bipartite hypergraphs in [32], which are defined for uniform unweighted hypergraphs, and we generalize them for any hypergraph, as follows.
Definition 6.7. The hypergraph G is odd-bipartite if  is even and one can decompose the vertex set as a disjoint union V = V1 V2 such that, if i1, . . . , i  [N ], then
{i1, . . . , i}  E  There is an odd number of vertices of V1 among vi1, . . . , vi,
where the vertices vi1, . . . , vi are counted with repetitions. Clearly, if  = 2, G is a bipartite graph if and only if G is odd-bipartite. Theorem 2.1
in [32], which is formulated for A and K in the case of unweighted uniform hypergraphs, can be formulated also for L and for all hypergraphs, as follows.
Theorem 6.8. If G is a connected hypergraph, the following conditions are equivalent:
1.  is even and G is odd-bipartite.
2. There exists a diagonal matrix P of order N with all the diagonal entries ±1 and P = - Id such that A = -P -(-1)AP .
3. There exists a diagonal matrix P of order N with all the diagonal entries ±1 and P = - Id such that K = P -(-1)K+P .
4. here exists a diagonal matrix P of order N with all the diagonal entries ±1 and P = - Id such that L = P -(-1)L+P .
Theorem 6.8 can be proved as [32, Theorem 2.1]. It can be applied for proving the following theorem, which generalized Theorem 2.2 and Theorem 2.3 in [32], as well as the known results for graphs that we discussed above.
Theorem 6.9. If G is a connected hypergraph, the following conditions are equivalent:
1.  is even and G is odd-bipartite.
2. Spec(A) = - Spec(A) and Hspec(A) = - Hspec(A).
3. Hspec(A) = - Hspec(A). 4. Spec(K) = Spec(K+) and Hspec(K) = Hspec(K).
5. Hspec(K) = Hspec(K). 6. Spec(L) = Spec(L+) and Hspec(L) = Hspec(L).
7. Hspec(L) = Hspec(L).
Proof. As Theorem 2.2 and Theorem 2.3 in [32], using Theorem 6.8 instead of [32, Theorem 2.1].
20

Remark 6.10. The second condition in Theorem 6.9 means that
  Spec(A)  -  Spec(A), with the same multiplicity,
and   Hspec(A)  -  Hspec(A). Similarly, by Remark 3.3, the sixth condition in Theorem 6.9 means that
  Spec(L)  2 -   Spec(L), with the same multiplicity,
and   Hspec(L)  2 -   Hspec(L). Moreover, by Proposition 3.1, the claim for L and L+ also holds for L and L+.

7 Computing the eigenvalues

In this section we apply software implementing methods from numerical algebraic geometry to compute the set of eigenvalues of a tensor and their geometric multiplicity. In particular, this applies to all tensors associated to hypergraphs which were presented in the previous sections. We shall consider here a k-th order n-dimensional tensor T . To such tensors we associate the set of solutions of the system of polynomial equations

 (T 

xk-1)1

-

xk1-1

=0



...

(10)

 (T

xk-1)n

-

xkn-1

= 0.

Here we use the symbols x1, . . . , xn,  as variables of our polynomials, and we will use (x, )  Cn+1 for a specific solution. If   Spec(T ), then we define the eigenvariety of  as
V () = {x  Cn : (x, ) is an eigenpair for T }.

The eigenvarieties are solutions of polynomial systems, so they are by definition algebraic

varieties. If we want to consider all eigenvarieties together, then it is convenient to look

at their union in the bigger space Cn+1, where  is considered a variable as well. Hence

we define

V = {(0, . . . , 0, ) :   C} 

V () × {}.

(11)

 eigenvalue of T

The choice of considering  as a variable comes from our application-oriented approach. Indeed,  is a variable for the software. In general, eigenvarieties are not irreducible, i.e., they can be further decomposed into a union of varieties, of possibly different dimensions. We shall see an example of this behaviour. For a fixed , the equations (T xk-1)i - xki -1 = 0 are homogeneous of degree k - 1. In particular, if x  Cn is an eigenvector of T with eigenvalue , then cx is also an eigenvector with eigenvalue , for every c  C. In geometric terms, V ()  Cn is a cone. When we deal with matrices, all eigenvarieties are linear spaces. However, for k  3 eigenvarieties can have higher degrees. Our main goal is to compute the eigenvalues of T . When the entries of T can be represented on a field with exact arithmetic (for instance when they are rational numbers) we can compute the characteristic polynomial of T , which is the resultant of the system of equations (T xk-1)i = xki -1 using Gr¨obner basis techniques. For instance, the package "Resultants" of the computer algebra system Macaulay2 implements this idea. However, due to the notorious complexity of computing a Gr¨obner basis, computations do not terminate even for rather small hypergraphs.

21

This motivates us to consider numerical methods to solve the polynomial system. In the last decade a lot of research has been carried out in developing methods based on the so-called homotopy continuation. The idea is that in order to solve a system of polynomial equations S, one can first transform it into a similar, but simpler to solve, system S . After solving S , solutions of S can be tracked back via an homotopy between the two polynomial systems. There are several packages and sofware implementing this idea, such as Bertini and PHCpack. In the example below we use the package HomotopyContinuation.jl [6], developed in the language Julia, and we refer to the webpage juliahomotopycontinuation.org for documentation, examples and applications. In this way we are able to compute the geometric multiplicity of each eigenvalue, with high probability. However, it is not immediate to apply this technique to compute the span multiplicity nor the algebraic multiplicity. The software does not accept positive dimensional systems as input, and it suggests to add a generic affine linear equation to the system. We choose a generic affine linear polynomial  C[x1, . . . , xn]. Observe that does not involve the variable . In this way the affine hyperplane defined by does not intersect the line {(0, . . . , 0, ) :   C}. However, given the particular structure of our system, we can guarantee that there is a Zariski open subset of the space of affine linear polynomials of C[x1, . . . , xn] such that the hyperplane {(x, ) : (x, ) = 0}  Cn+1 intersects all irreducible components of all varieties V () × {}.
Lemma 7.1. The general affine hyperplane of Cn intersects every irreducible component of V () for every   Spec(T ).
Proof. Let W be an irreducible component of V (). As W is a cone, it contains at least a line L. An affine hyperplane H does not intersect L if and only if L is contained in the translate of H containing the origin. This is a Zariski closed condition.
Example 7.2. Let G = (V, E) be the unweighted hypergraph with V = {v1, . . . , v5} and E = {{v1, v2, v3, v4}, {v1, v5}, {v3, v5}}. This is the protein­protein interaction network depicted in [16, Figure 1 A].
Figure 5: The hypergraph in Example 7.2
As  = 4, A, K, L, L are all tensors in C5  C5  C5. We consider the adjacency tensor A, i.e., we compute the solutions of (10) with T = A. On a standard desktop computer the command resultant in Macaulay2 does not terminate the computation. This is perhaps not surprising, if we think that the characteristic polynomial has degree 5 · 34 = 405. We then use the software HomotopyContinuation.jl, which can be called via the command using HomotopyContinuation in Julia. We start generating a random affine linear polynomial p in C[x1, . . . , xn] and append it to the system (10).
p = sum(rand(ComplexFloat64, 5).  [x1, x2, x3, x4, x5]) + rand(ComplexFloat64)
22

The syntax to define our system in HomotopyContinuation.jl is the following:

@var x1 x2 x3 x4 x5 l;

f = System([-l  x13 + x2  x3  x4 + 3/7  x12  x5 + 3/7  x1  x52 + 1/7  x53,

-l  x23 + x1  x3  x4,

(12)

-l  x33 + x1  x2  x4 + 3/7  x32  x5 + 3/7  x3  x52 + 1/7  x53,

-l  x43 + x1  x2  x3,

-l  x53 + 1/7  x13 + 1/7  x33 + 3/7  x12  x5 + 3/7  x32  x5 + 3/7  x1  x52 + 3/7  x3  x52,

p]);

Here we use the symbol l in place of . We run the command result = solve(f); which stores the solution in a variable called "result". The computation terminates in few seconds and the program prints the following information.

Let us comment on the output. The program found 331 non-singular solutions (x, )  Cn+1 and 5 singular solutions. A solution is marked as singular using two classical parameters in complex analysis: the winding number and the condition number of the Jacobian of the system. In particular, singular solutions approximate solutions on a positive dimensional component of V , or solutions on a line which has multiplicity greater than 1 in V . None of the found solutions are marked as real. It does not mean that there is no solution (x, )  Rn+1, but simply that the eigenvectors corresponding to real eigenvalues found by the software have some complex coordinate. This is due to the choice of the polynomial p  C[x1, . . . , x5]. The reader concerned with real eigenpairs can apply the same procedure using generic polynomials in Q[x1, . . . , x5]. We remark that certain steps in the solution process involve randomness, hence calling the function "solve" twice on the same starting system might lead to a different number of solutions. However, as we are interested in computing the eigenvalues, it suffices to find at least one point in each eigenvariety. To retrieve the non-singular solutions we simply type solutions(result), which returns an array of 331 vectors in C6. We are interested in the value of the coordinate  of each vector. These numbers are not all distinct in general. We can easily write a loop to discard those eigenvalues which are close to another one. We obtain a list of 64 complex numbers which we plot in the complex plane (Figure 6). By further selecting only the real part of those with a sufficiently small imaginary part (< 10-15) we obtain the following 18 real eigenvalues.
23

-1.1503540417366391 -1.0589738102553747 -1.0 -0.9233845418913038 -0.5474615312663447 -0.1532944068758618 -0.1484156441177043 -0.14163743538075982 -0.25425744432182457

1.7219155529623352 · 10-41 0.9382912060665167 0.9858713918602654 1.0 1.071873232613355 1.0858832885825462 1.2267760851792766 1.4284010786135974 1.73405913985699

Figure 6: The 64 eigenvalues for the adjacency tensor of the hypergraph in Example 7.2,
found by numerically solving the system of equations with HomotopyContinuation.jl. The blue points have an imaginary part smaller than 10-15.

The singular solutions (x, ) in this example, which can be accessed typing singular(result), they all satisfy  = 0.

The numerical solution can be employed to obtain information on the geometric multiplicity of eigenvalues. The idea is the following: we generate new generic linear polynomials pi  C[x1, . . . , xn], append the polynomials p1, . . . , pk to (10) and solve the system numerically. Observe that unlike p, the polynomials pi are not affine linear, i.e., there is no degree 0.

Lemma 7.3. Lt p  C[x1, . . . , xn] be an affine linear polynomial, and for 1  i  k let pi  C[x1, . . . , xn] be linear polynomials. If (x, )  Cn+1 is a solution of the system

 

(T xk-1)1 - xk1-1 = 0

   

...

 

(T xk-1)n - xnk-1 = 0





 p(x, ) = p1(x, ) = · · · = pk(x, ) = 0,

then  is an eigenvalue with gm()  k+1. If after adding a new generic linear polynomial pk+1 to the system there is no solutuion with  = , then gm() = k + 1.

24

Therefore, we can continue adding generic linear polynomials until no solutions are found. All eigenvalues are found in this way, with the correct geometric multiplicity. We illustrate this fact in Example 7.4.
Example 7.4. As we pointed out in Example 7.2, the unique eigenvalue obtained from a singular solution of (12) is  = 0. Therefore this is the only eigenvalue which might have geometric multiplicity higher than 1. To verify that this the case, we append to the system (12) a random linear polynomial p1  C[x1, . . . , x5] and compute a solution numerically. We find solutions with  = 0, hence gm(0)  2. Moreover, the system obtained adding another random linear polynomial p2 does not admit any solution. We conclude that gm(0) = 2, and all the other eigenvalues have geometric multiplicity 1.
Funding
FG is supported by the fund FRA 2018 of University of Trieste ­ project DMG, and acknowledges the MIUR Excellence Department Project awarded to the Department of Mathematics and Geosciences, University of Trieste. RM is supported by The Alan Turing Institute under the EPSRC grant EP/N510129/1. LV is funded by the G¨oran Gustafsson foundation.
Acknowledgments
We thank Christian Kuehn (TUM) for the helpful comments and suggestions. We would like to thank Bernd Sturmfels (MPI MiS), who has always actively encouraged us to work together.
References
[1] A. Banerjee and A. Char. On the spectrum of directed uniform and non-uniform hypergraphs. arXiv:1710.06367.
[2] A. Banerjee, A. Char, and B. Mondal. Spectra of general hypergraphs. Linear Algebra and its Applications, 518:14­30, 2017.
[3] A. Banerjee and S. Parui. On synchronization in coupled dynamical systems on hypergraphs. arXiv:2008.00469, 2020.
[4] N. Bao, N. Cheng, S. Hern´andez-Cuenca, and V.P. Su. The quantum entropy cone of hypergraphs. arXiv:2002.05317, 2020.
[5] A´ . Bod´o, G.Y. Katona, and P.L. Simon. Sis epidemic propagation on hypergraphs. Bulletin of mathematical biology, 78(4):713­735, 2016.
[6] P. Breiding and S. Timme. HomotopyContinuation.jl: A Package for Homotopy Continuation in Julia. In Mathematical Software ­ ICMS 2018, pages 458­465, Cham, 2018. Springer International Publishing.
[7] A.E. Brouwer and W.H. Haemers. Spectra of graphs. Springer Science & Business Media, 2011.
[8] F. Chung. Spectral graph theory. American Mathematical Soc., 1997.
25

[9] C. Duan, L. Wang, and X. Li. Some Properties of the Signless Laplacian and Normalized Laplacian Tensors of General Hypergraphs. Taiwanese Journal of Mathematics, 24(2):265­281, 2020.
[10] Y.-Z. Fan, T. Huang, Y.-H. Bao, C.-L. Zhuan-Sun, and Y.-P. Li. The spectral symmetry of weakly irreducible nonnegative tensors and connected hypergraphs. Transactions of the American Mathematical Society, 372(3):2213­2233, 2019.
[11] C.J. Hillar and L.-H. Lim. Most Tensor Problems Are NP-Hard. J. ACM, 60(6), 2013.
[12] S. Hu and Y. Ke. Multiplicities of tensor eigenvalues. Communications in Mathematical Sciences, 14:1049­1071, 2016.
[13] J. Jost and R. Mulas. Hypergraph Laplace operators for chemical reaction networks. Advances in Mathematics, 351:870­896, 2019.
[14] J. Jost and R. Mulas. Normalized Laplace Operators for Hypergraphs with Real Coefficients. J. Complex Netw., 2021. To appear. DOI:10.1093/comnet/cnab009.
[15] M. Kivel¨a, A. Arenas, M. Barthelemy, J.P. Gleeson, Y. Moreno, and M.A. Porter. Multilayer networks. Journal of Complex Networks, 2(3):203­271, 07 2014.
[16] S. Klamt, U.-U. Haus, and F. Theis. Hypergraphs and cellular networks. PLoS Comput Biol, 5(5):e1000385, 2009.
[17] N. Lanchier and J. Neufer. Stochastic dynamics on hypergraphs and the spatial majority rule model. Journal of Statistical Physics, 151(1):21­45, 2013.
[18] L. Lov´asz. Normal hypergraphs and the perfect graph conjecture. Discrete Mathematics, 2(3):253­267, 1972.
[19] C. Ma, H. Liang, Q. Xie, and P. Wang. Some inequalities on the spectral radius of nonnegative tensors. Open Mathematics, 18(1):262­269, 2020.
[20] B.D. MacArthur, R.J. S´anchez-Garc´ia, and J.W. Anderson. Symmetry in complex networks. Discrete Applied Mathematics, 156(18):3525­3531, 2008.
[21] R. Mulas, C. Kuehn, and J. Jost. Coupled dynamics on hypergraphs: Master stability of steady states and synchronization. Phys. Rev. E, 101:062313, 2020.
[22] R. Mulas and D. Zhang. Spectral theory of Laplace operators on oriented hypergraphs. Discrete Mathematics, 344:112372, 2021.
[23] X. Ouvrard, J.-M. Le Goff, and S. Marchand-Maillet. Adjacency and Tensor Representation in General Hypergraphs Part 1: e-adjacency Tensor Uniformisation Using Homogeneous Polynomials. arXiv:1712.08189.
[24] X. Ouvrard, J.-M. Le Goff, and S. Marchand-Maillet. Adjacency and tensor representation in general hypergraphs. Part 2: Multisets, hb-graphs and related e-adjacency tensors. arXiv:1805.11952.
[25] L. Qi. Eigenvalues of a real supersymmetric tensor. Journal of Symbolic Computation, 40(6):1302­1324, 2005.
26

[26] L. Qi and Z. Luo. Tensor analysis. Society for Industrial and Applied Mathematics, Philadelphia, PA, 2017. Spectral theory and special tensors.
[27] L. Qi and Y. Song. An even order symmetric B tensor is positive definite. Linear Algebra and its Applications, 457:303­312, 2014.
[28] S. Ranshous, C.A. Joslyn, S. Kreyling, K. Nowak, N.F. Samatova, C.L. West, and S. Winters. Exchange pattern mining in the bitcoin transaction directed hypergraph. In International Conference on Financial Cryptography and Data Security, pages 248­263. Springer, 2017.
[29] N. Reff. Spectral properties of oriented hypergraphs. Electron. J. Linear Algebra, 27, 2014.
[30] N. Reff and L.J. Rusnak. An oriented hypergraphic approach to algebraic graph theory. Linear Algebra Appl., 437:2262­2270, 2012.
[31] L.J. Rusnak. Oriented hypergraphs: Introduction and balance. The Electronic Journal of Combinatorics, 20, 2013.
[32] J.-Y. Shao, H.-Y. Shan, and B.-F. Wu. Some spectral properties and characterizations of connected odd-bipartite uniform hypergraphs. Linear and Multilinear Algebra, 63(12):2359­2372, 2015.
[33] J.-Y. Shao, H.-Y. Shan, and L. Zhang. On some properties of the determinants of tensors. Linear Algebra and its Applications, 439(10):3057­3069, 2013.
[34] Z.-K. Zhang and C. Liu. A hypergraph model of social tagging networks. Journal of Statistical Mechanics: Theory and Experiment, 2010(10):P10005, 2010.
27

