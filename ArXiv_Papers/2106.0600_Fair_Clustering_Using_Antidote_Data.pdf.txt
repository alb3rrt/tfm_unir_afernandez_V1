arXiv:2106.00600v1 [cs.LG] 1 Jun 2021

Fair Clustering Using Antidote Data
Anshuman Chhabra*, Adish Singla, Prasant Mohapatra* * University of California, Davis, {chhabra, pmohapatra}@ucdavis.edu
 MPI-SWS, adishs@mpi-sws.org
Abstract
Clustering algorithms are widely utilized for many modern data science applications. This motivates the need to make outputs of clustering algorithms fair. Traditionally, new fair algorithmic variants to clustering algorithms are developed for specific notions of fairness. However, depending on the application context, different definitions of fairness might need to be employed. As a result, new algorithms and analysis need to be proposed for each combination of clustering algorithm and fairness definition. Additionally, each new algorithm would need to be reimplemented for deployment in a real-world system. Hence, we propose an alternate approach to fairness in clustering where we augment the original dataset with a small number of data points, called antidote data. When clustering is undertaken on this new dataset, the output is fair, for the chosen clustering algorithm and fairness definition. We formulate this as a general bi-level optimization problem which can accommodate any center-based clustering algorithms and fairness notions. We then categorize approaches for solving this bi-level optimization for different problem settings. Extensive experiments on different clustering algorithms and fairness notions show that our algorithms can achieve desired levels of fairness on many real-world datasets with a very small percentage of antidote data added. We also find that our algorithms achieve lower fairness costs and competitive clustering performance compared to other state-of-the-art fair clustering algorithms.
1 Introduction
With the increasing application of machine learning (ML) algorithms in modern society, the design of fair variants to traditional ML algorithms is an important concern. Vanilla ML algorithms do not account for the biases present in training data against certain minority protected groups, and hence, might reinforce them. Furthermore, clustering has been widely used to find meaningful structures, explanatory underlying processes, generative features, and groupings inherent in a set of examples. It plays a significant role in most modern data science applications, such as in medicine [1], vision [2], language modeling [3], financial decisions [4], and various societal resource allocation problems. Thus, ensuring fairness with respect to protected groups is an important issue for clustering algorithms.
Currently, many different notions for fairness in clustering exist, such as balance [5], proportionality [6], social fairness [7], among others. Traditionally, to make clustering outputs fair with respect to a specific notion of fairness, fair variants to clustering algorithms need to be proposed. Given that many different clustering algorithms exist, each fair variant proposed requires individual analysis, and possesses different theoretical guarantees. Moreover, if fairness notions or clustering algorithms are changed in a deployed real-world system, the corresponding fair algorithms would also have to be reimplemented. Therefore, instead of coming up with new fair algorithms for each fairness definition and each clustering algorithm, we propose an alternate approach to ensuring fairness for clustering. We aim to augment the dataset with antidote data points such that when we use vanilla clustering on this new combined dataset, fairness constraints are met. Thus, instead of changing the clustering algorithm to ensure fairness, we find an augmented dataset for which the specified fairness constraints
Preprint. Under review.

are met when vanilla clustering is undertaken on it. Our approach is therefore applicable in very general case scenarios where fairness on the original dataset can be achieved for any arbitrary choice of clustering algorithm and fairness definition. To summarize, we aim to make clustering fair in the pre-clustering stage as opposed to the in-clustering stage, unlike most research on fair clustering.
Data augmentation to improve fairness was first proposed by [8] for recommendation systems. The authors coined the term antidote data for the data points added to the original dataset. However, since recommendation systems and clustering algorithms differ widely, their problem formulation and techniques do not translate to clustering. The antidote data problem for clustering is then as follows: given a dataset U , can we compute (antidote) data V such that when we cluster on U  V we obtain a fair clustering output for a chosen fairness notion and clustering algorithm?
We answer this question in the affirmative by proposing a general bi-level formulation of the antidote data problem for clustering. In summary, we make the following contributions:
· We propose an alternative approach to fair clustering, where we augment the original dataset with data points (antidote data) such that when we use vanilla clustering on this new combined dataset, fairness is improved. This is the first work that utilizes data augmentation and antidote points for improving fairness in clustering. In contrast, existing works on fair clustering modify the clustering algorithm specific to a notion of fairness.
· We consider three problem settings for the proposed general bi-level formulation: 1) arbitrary fairness notions and the k-medoids/k-means clustering objectives, with side information about fair target centers , 2) convex fairness notions and convex center-based clustering objectives, and 3) general fairness notions and center-based clustering objectives.
· We provide algorithms and analysis for each of these settings, and conduct extensive experiments on real-world datasets for multiple clustering algorithms and fairness notions to demonstrate the efficacy and generality of our approaches.
· We also compare our algorithms to state-of-the-art fair clustering algorithms in terms of fairness, and clustering performance, and find that we achieve improved results on all metrics.

2 Problem Statement

2.1 Proposed Problem

The original dataset is denoted as U  Rn×d. This is the dataset we wish to augment with some antidote data points such that certain fairness constraints are met when we cluster on the augmented dataset. Furthermore for a matrix M , let Mi and M i denote the i-th row and i-th column respectively. To start, we first define the clustering problem on U . A center-based clustering objective, C, takes in a dataset as input (such as U ) and outputs a set of k centers µ  Rk×d, where k  n. That is, a clustering objective induces a k-partition set of the data, where each sample in the dataset is uniquely mapped to a center µi  µ where µ  Rd. For example, the k-means clustering objective on U can be defined as Ck-means(U ) := µ = argminµ Rk×d xU mini[k] ||x - µi||2.
We denote the fairness notion as F : (µ, U )  R. That is, the fairness notion takes as input the set of centers from a clustering algorithm and the original dataset, and outputs a fairness cost. The goal of improving fairness is to then minimize F. It is important to note that fairness will be evaluated only on the original real dataset U . Moreover, as we will see, all fairness notions can be defined this way.
The General Problem. We now state the antidote data problem for improving fairness. We aim to add a set of data points V to U , such that when we cluster on U  V and obtain centers µ, F(µ, U ) is less than some given value . The cost of adding points can be defined as the size of set V , and hence, we aim to add as few points as possible. The general bi-level optimization problem is as follows:

min |V |
V, µ

s.t. F(µ, U )  

(P1)

µ = C(U  V )

Relaxation P1.R. In the paper, we also at times consider a relaxed formulation of problem P1 (refer to Sections 3.2 and 3.3) . This relaxation allows us to propose algorithms that in turn also solve problem

2

P1 indirectly. The idea is to fix the size of the antidote dataset |V |  V s for a given V s  R, and optimize the fixed-set V so that we only minimize F in the upper-level problem. Since minimizing the fairness cost is now the upper-level objective, we can also omit writing it as a constraint using :

min F(µ, U )
V, µ
s.t. µ = C(U  V )

(P1.R)

|V |  V s

Relaxation P1.S. Another relaxed formulation we consider arises for the problem setting when we
have side information available in the form of fair centers (refer to Section 3.1). Here we have available target fair centers µ, such that F (µ, U )  . Using this side information, we can
reformulate problem P1 to optimize V so as to obtain centers as close as possible to the target center
set, thus meeting the fairness constraint. The goal is to add points to V such that the distance between
the centers obtained when we cluster on U  V and their corresponding target centers is minimized. Let µ be the centers obtained after clustering on U  V . We assume that µ and µ are ordered, where center µi  µ and its corresponding closest target center µi  µ can be accessed using i  [k]. The optimization problem thus becomes:

min |V | s.t. ||µ - µ|| 

(P1.S)

where > 0 is a small number denoting acceptable tolerance, and µ is obtained through C(U  V ). If is chosen to be a very small number, we are effectively finding a center set µ which satisfies F(µ, U )   while minimizing the size of the antidote dataset V . We have thus transformed the original problem P1 to problem P1.S when fair centers are available.

2.2 Definitions

We now define the fairness costs we use in the paper. Consider some g  Z+ number of protected groups that comprise U . Each protected group has an index j  [g] and contains a certain number of points of U . For simplicity of notation we also assume that a mapping function (U, j) exists which takes in as input U and an integer j, where 1  j  g, and gives us the set of points of U which belong to the protected group j. Now we can define the social fairness cost of Ghadiri et al [7]. This was originally proposed for k-means clustering, but it fits well with any center-based clustering objective where Euclidean distance is used as the clustering distance metric.
Definition 2.1. (Social Fairness [7]). Let (µ, U ) = xU minµiµ ||x - µi||2 where U is the original dataset and µ are cluster centers. Then the social fairness cost is defined as:

(µ, (U, j))

Fsocial(µ, U ) = max
j[g]

|(U, j)|

Next we define the balance metric [5, 9]. Traditionally, balance is a fairness metric that is not a cost, and is maximized. To fit with our framework, we frame it as a cost by multiplying it with -1, and name it the balance cost. Again, for simplicity of notation, we assume a mapping function (U, µ, i) exists which takes in as input U , µ, and a cluster label i  [k] and gives us the points in U which

belong to cluster i. Note that obtaining cluster labels is trivial as for each x  U the corresponding label can be obtained as i = argmini [k] ||x - µi ||.

Definition 2.2. (Balance Cost [9]). Let U be the original dataset and µ  Rk×d be the set of cluster

centers.

Define the following ratio R(i, j)

=

|(U,j)|/|U | |(U,j)(U,µ,i)|/|(U,µ,i)|

which signifies the ratio

between the proportion of points of group j in U and proportion of group j points in cluster i. The

balance cost Fbalance  [-1, 0] is then defined:

1

Fbalance(µ, U ) = - min
i[k],j[g]

min

R(i, j), R(i, j)

We also make use of the following, commonly used definition for well-separated clusters [10]:
Definition 2.3. (Well-separated Clusters). These are defined for a given k and dataset U as a set of cluster partitions {P1, P2, ..., Pk} on the dataset, s.t. points belonging to each Pi  U are closer to each other than any points belonging to Pj  U where i = j, i, j  [k].

3

3 Proposed Approaches

We consider problem P1 under 3 different settings and provide algorithms and analysis for each: (1) Side Information Available Regarding Fair Target Centers (µ), (2) Convex C and Convex F, and (3) General C and General F. With each subsequent setting, solving problem P1 becomes more
challenging. For the first setting, in which target fair centers are given, we can obtain theoretical results for our algorithm regarding convergence and the size of the antidote dataset V . For the second setting
with convex functions, we can reduce the bi-level problem to a single-level optimization, allowing us to utilize off-the-shelf solvers to obtain V . For the general setting, the antidote data problem is the hardest and we resort to using zeroth-order optimizers as part of our proposed solution to finding a feasible V .

3.1 Side Information Available Regarding Fair Target Centers µ

We consider the special case of side information available regarding fair target centers, denoted by µ  Rk×d. We consider general F where we have F (µ, U )  . We essentially aim to solve the problem P1.S, which is a relaxation to the original problem P1. There are many motivations
for this case. Fair centers could be known if fair algorithms have already been run prior on the
dataset, or if a domain specialist has estimates of where they should lie [11]. We also restrict our approach to the k-medoids (Ck-medoids) and k-means (Ck-means) clustering objectives. Since k-medoids can be defined with any distance metric, to maintain uniformity, we use the squared 2-norm. The
goal of both the k-means and k-medoids clustering approach is to compute a partition set of the dataset U such that the squared Euclidean distance between corresponding centers in µ and the
points in their partitions/clusters is minimized. The k-medoids clustering problem differs from
k-means only in that the set of chosen centers has to be a subset of the dataset, also known as exemplars. We define these for reference: Ck-means(U ) := argminµ Rk×d xU mini[k] ||x - µi||2 and Ck-medoids(U ) := argminµ Rk×d xU mini[k] ||x - µi||2 s.t. µ  U .
Our approach to solving problem P1.S is detailed as a simple algorithm (Algorithm 1). We start with V as an empty set (line 1) and run k-medoids/k-means clustering (C) on U to obtain the original clustering centers µ0 (line 2). Next, we initialize the set µ as µ0 (line 2). In line 3, we begin a while loop that iterates till the current center set is close to the target center set, ie, ||µ - µ||F  . We iterate over all clusters where the current centers are not the target centers (line 4), and build the set V by adding a   Z+ small number of points iteratively to each of these target centers µi for all i  [k] (line 5). We then run C on U  V to obtain the new cluster centers (line 6). The idea is that we have
to make each of the target centers a median/mean point of their respective cluster. By adding points
directly on these target centers, we do not lead to any increase in clustering cost (due to the very definition for Ck-medoids/Ck-means) for the target centers as a potential center set option. However, clustering costs for other points as candidate centers increase as a result. When the entire center set given by C is close to the set of target centers, the algorithm has converged and we have found V (line 9).

Convergence. Algorithm 1 converges to a feasible solution as is shown in Theorem 3.1. This

Algorithm 1: Target Centers µ Available

is intuitive to understand through the following Input: U, k, µ, , , C  {Ck-medoids, Ck-means}

argument: consider that an infinite number of points at each of the k target centers are added.

Output: V 1: initialize V   2: set µ0  C(U ) and µ  µ0

Now for each cluster of points, the means and 3: while ||µ - µ||F > do

medoid/median value are the target center since 4: there is infinite mass at these locations. In The- 5: orem 3.1 we also give an upper-bound on the 6: size of V  for well-separated clusters (refer to 7:

for each cluster i  [k] where ||µi - µi || > 0 do add  # of new points to V at location µi µ  C(U  V )
end for

Definition 2.3) and Ck-medoids as the clustering objective. Assuming the feasible antidote dataset

8: end while 9: return V

is denoted as V  and C runs in time TC, Algorithm 1 has a running time of O(|V |TC/k).

Theorem 3.1. For a well-separated clustering problem using k-medoids or k-means clustering and

i of

= minx Pi the antidote

xPi
dataset

||x V

- x ||2, Algorithm 1 finds a feasible for Ck-medoids is bounded as:

solution

to

problem

P1.S,

and

the

size

|V |  |Pi|
i[k]

( xPi ||x - µi ||2 - i) minyPi\µi ||y - µi ||2

4

Remark. Unlike the Ck-medoids case, for Ck-means, candidate centers are not finite. Even though for Ck-medoids Algorithm 1 can eventually ensure that ||µ - µ|| = 0, for Ck-means, ||µ - µ|| will converge to some small value . This is due to data points that belong to each cluster influencing the mean of the cluster. The only way to move the mean to the target center by adding points directly at that location is if we add an infinite number of points; otherwise there will be some shift in the mean caused by the other points of U belonging to that cluster. A better approach for k-means would be to leverage the other points in the dataset by only adding points to V such that the mean of the cluster gets to the desired targets. We thus devise an algorithm specifically for Ck-means where k = 2. Due to space considerations, we defer this specialized algorithm, and its feasibility analysis to the appendix (Section B.2).

3.2 Convex C and Convex F

For this setting, we assume that both C and F are convex functions. Assuming convexity allows us to effectively reduce the bi-level problem to a single-level form, which can then be provided to off-the-shelf convex/non-convex solvers for optimization. In particular, we exploit the convexity of the functions by replacing the lower-level problem with its Karush-Kuhn-Tucker (KKT) optimality conditions as constraints for the upper-level problem. Since the lower-level clustering problem is convex, the KKT conditions are necessary and sufficient to ensure optimality [12].

As optimizing bi-level problems is in general NP-Hard [13], and problem P1 contains an NP-Hard cardinality minimization problem [14] as the upper-level objective, we use the relaxed form P1.R to indirectly solve P1. This involves fixing |V | as an input hyperparameter and optimizing V so as to minimize F, without considering . We then use the convexity of the lower-level problem to obtain a single-level reduction from this bi-level problem by replacing the lower-level problem with its KKT constraints. When we minimize this reduced single-level problem, we effectively minimize P1.R.

We describe our approach as Algorithm 2. We aim to solve problem P1.R using our algorithm, and in
each iteration try to find a suitable V to optimize using the reduced single-level problem (obtained via
KKT conditions). In each iteration of the algorithm, we start by fixing the size of V to some Vs, and obtain F after optimizing V . If this fairness cost is less than , we can exit, otherwise we increase the size of V (denoted as Vs) by   Z+ for the next iteration and continue. Algorithm 2 can also exit if the constraint is not met, if a certain number of iterations are exceeded, or if |V | grows to an unacceptable
value. We omit these details from Algorithm 2 for simplicity, but they can be easily implemented.

Not many widely used convex formulations for clustering algorithms exist except for sum-of-norms

(SON) clustering [15, 16], which is strongly convex. SON clustering has been shown to be a convex

relaxation to both k-means clustering [15] and hierarchical agglomerative clustering [16]. Below,

we analyze SON clustering in the context of Algorithm 2. For the fairness notion, we utilize Fsocial

which is clearly convex and well-defined for SON clustering. We first define the SON clustering

objective. It is important to note that we modify the notation­ since the objective is convex, the

number of clusters are not discretely defined, but obtained via a regularization parameter . Centers are represented as a Rn×d matrix as there is no explicitly defined k, but note there will only be

some unique k  n centers decided by the parameterization of . The objective is as follows:

CSON(U )

:=

µ

=

argminµ

Rn×d

1 2

n j=1

||Uj

-

µj ||2

+



i<j ||µi - µj ||.

Let Vs(t) denote the size Vs of V in iteration t of Algorithm 2 (line 2). The number of centers we have will be µ  Rm×d where m = n + Vs(t) for U  V . To derive the KKT conditions we first reformulate the objective. Consider an ordering of all (µi, µj) pairs where all i < j. We can let each of the m centers µi be a node in a graph G. The created ordering essentially enumerates the list of edges E for the graph G. We denote this ordering as O where we will have |E| = |O| = m(m-1)/2. We also denote the node-arc-incidence matrix [17] for (G, E) as I  Rm×|O|. We can then rewrite the SON objective, define the dual problem to the reformulation, and derive the KKT conditions (details provided
in Section A.3 of appendix). Then the single-level reduction for P1.R can be written as follows:

min
V, µ, , , 
s.t.

Fsocial(µ, U )
 + µ - (U  V ) = 0  - max{0, 1 - (1/|| + ||)}( + ) = 0 µT I -  = 0 IT -  = 0

5

Here, µ  Rm×d,   Rd×|O| are the primal variables, and   Rm×d,   Rd×|O| are the dual variables. We also observe that replacing KKT conditions as constraints can introduce non-convexity. All the constraints and objectives are convex, except for one: -max{0, 1-(1/||+||)}(+) = 0. To approximate this, we can replace it with an affine constraint as  - ( + ) = 0 where 0    1. Then a convex solver such as CVX [18] can be used to solve the above problem. Finally, assuming it takes time TKKT to solve the single-level problem, and a feasible antidote dataset V  exists, Algorithm 2 has a running time of O(TKKT|V |/).
Remark. Since we are solving a convex problem above, the results for this setting are not too difficult to obtain. We thus defer results for Algorithm 2 to the appendix (Section C).

Algorithm 2: Convex C and F
Input: U, C, F, Vs,  Output: V
1: while true do 2: initialize V arbitrarily with |V | = Vs 3: reduce problem P1.R by replacing C(U  V )
with its KKT conditions as constraints 4: solve this single-level problem for optimal V 5: if F(µ, U )   return V else Vs  Vs +  6: end while

Algorithm 3: General C and F
Input: U, C, F, A, Vs, n ,  Output: V
1: while true do 2: define µ  C(U  V ) and f (V )  F(µ, U ) 3: initialize V arbitrarily with |V | = Vs 4: optimize V using SRE(n , f (V ), A) 5: obtain optimized V and F(µ, U ) from SRE & A 6: if F(µ, U )   return V else Vs  Vs +  7: end while

3.3 General C and General F
In this setting, we make no assumptions about the clustering objective C and the fairness cost F. In such a minimal assumption setting where fairness notions as well as center-based clustering objectives can vary widely, it is not trivial to propose algorithms with strong theoretical guarantees. Furthermore, some of the most popular and widely utilized clustering algorithms such as k-means, hierarchical clustering, DBSCAN, etc. possess highly non-convex objectives and are generally optimized via heuristic algorithms (such as Lloyd's algorithm for k-means). In terms of fairness notions for clustering, balance is generally the most widely used metric in proposing fair algorithms. As evident in Definition 2.2, it is both non-convex and non-differentiable.
Furthermore, general bi-level optimization is NP-Hard; even for the simpler case when the upper-level and lower-level problems are linear, a polynomial time algorithm that finds the global optima of the bi-level problem might not exist [13]. Since we are dealing with possibly many non-convex upper-level and lower-level problems in this setting, finding a global optima for P1 is not a trivial task. We then resort to finding a locally optimal solution (if at all) that satisfies our problem constraints. To do this, we relax the NP-Hard upper-level problem which seeks to minimize the size of the antidote dataset V . Similar to the convex setting, we are attempting to solve the relaxed formulation P1.R (indirectly solving P1), where we fix |V | to some given value, and optimize V to minimize F.
To solve P1.R, we can use zeroth-order optimization algorithms (such as RACOS [19], CMAES [20], IMGPO [21]). Let such an algorithm be denoted as A. Most zeroth-order optimization algorithms do not scale well with problem input, and hence, cannot usually be applied to data with number of samples n  1000 [22]. However, since our goal is to utilize antidote data on large-scale datasets, the algorithm A cannot be applied directly to solve P1.R in practice. To circumvent this problem, we propose using the Sequential Random Embedding (SRE) approach of [22], which can be used in conjunction with the zeroth-order blackbox optimizer A to solve P1.R. The SRE approach scales the problem input by projecting it to a low-dimensional setting where it invokes A to solve the optimization. SRE takes in as input the reduced dimension n n, the objective function f to optimize, and zeroth-order optimization algorithm A. We defer the reader to [22] for more details on SRE.
Using the SRE approach, we propose Algorithm 3 for solving P1.R. We begin by defining the nested function f to optimize (line 2) which takes in as input some V and outputs the fairness cost F(µ, U ) where µ is obtained via C(U  V ). The basic idea is to fix |V | to some pre-defined starting value Vs and optimize V using the SRE approach as the back-end (line 3-5). Then, if the constraint F(µ, U )   is not met, we increase |V | by some small number   Z+ and repeat (line 6). Similar to Algorithm 2, we can exit in the while loop after a certain number of iterations or if |V | |U |.
In our experiments for this setting, we use RACOS [19] as the algorithm A, which is a Samplingand-Learning (SAL) framework. Previous work on SAL approaches allows us to give some weak

6

theoretical results regarding Algorithm 3 on computing a locally optimal solution for Problem P1.R and the number of blackbox queries required to do so. We present Theorem 3.2, which we have adapted from [23] for our setting. Essentially the result states that the query complexity to compute a locally optimal solution given a fixed-size V to optimize, scales inversely with how effectively A samples feasible solutions and how many feasible solutions f admits. This does not provide much information from a practical perspective, however through experiments we obtain competitive results on real-world datasets for different combinations of F and C. Finally, if A runs for time TA, and assuming a feasible antidote dataset V  exists, Algorithm 3 has a running time of O(TA|V |/).

Theorem 3.2. [23]. Let V   RVs(t)×d be a minimizer for the function f (V ) in an iteration t of

Algorithm 3 and for > 0 define X = {V  RVs(t)×d | f (V ) - f (V )  }. Let PX denote the

average probability of successfully sampling from the uniform distribution over X by algorithm A,

and it takes nX samples to realize PX . Then, the number of queries to f that A makes to compute V~

s.t. f (V~ ) - f (V ) 

with

probability

at

least

1

-



is

bounded

as

O(max{

ln

( -1 ) PX

,

nX

}).

4 Results

We consider four real-world datasets commonly used to evaluate fair clustering algorithms: adult [24], bank [25], creditcard [26], and Labeled Faces in the Wild (LFW) [27]. The adult dataset has 10000 × 5 samples, and protected groups signify race (white, black, asian-pac-islander, amerindian-eskimo, other). The bank dataset has 45211 × 3 samples, and protected groups signify marital status (married, single, divorced). The creditcard dataset has 30000 × 23 samples, and the protected groups signify education (higher and lower education). LFW has 13232 × 80 samples, and the protected groups signify sex (male, female).
We next provide results obtained for Algorithm 1 and Algorithm 3 on the aforementioned datasets. We defer the results for Algorithm 2 (with CSON and Fsocial) to the appendix (Section C) as we are solving a convex problem for which the results can be obtained in a straightforward manner.

4.1 Results for Algorithm 1

For Algorithm 1 we present results for Ck-medoids and Fsocial (F can be arbitrary). We first obtain µ by running the Fair-Lloyd algorithm of [7] and then project centers to the set U as they have to be medoids. The original centers obtained by clustering on just U are denoted as µ0. Using Algorithm
1 we aim to compute V such that the centers obtained by clustering on U  V are the target center
set. That is, through Algorithm 1, we aim to reduce the initial distance between centers given by ||µ0 - µ||F . We vary k from 2 to 4, and run Algorithm 1 on all 4 datasets with = 0,  = 1. The results are shown in Table 1. As can be seen, by clustering on U  V , the obtained centers µ are now exactly the target center set µ, ie ||µ - µ||F = 0. As Fsocial(µ, U )  , we have Fsocial(µ, U )  . Thus, Algorithm 1 effectively achieves the goal of meeting the fairness constraint while adding a
minimal number of antidote data points. Results for k-means are present in the appendix (Section B.1).

Table 1: Results for Algorithm 1 with Ck-medoids and Fsocial. (Consider k = 2 and the LFW dataset as an example. The distance between the original centers µ0 and target fair centers µ is ||µ0 - µ|| = 28.418. The fairness

cost for µ0 is Fsocial(µ0, U ) = 1631.385 and for µ is Fsocial(µ, U ) = 1532.679. After Algorithm 1 is run, V is

obtained, with size |V | = 0.0757|U |, indicating minimal antidote data addition. Cluster centers µ obtained by

clustering on U  V are now µ as ||µ - µ|| = 0. The fairness constraint has been met. Refer to Section 4.1.)

#Clusters

Dataset

||µ0 - µ|| Fsocial(µ0, U ) Fsocial(µ, U ) |V |/|U | ||µ - µ||

adult

14.427

5.559

4.224

0.0075

0.0

k=2

bank creditcard

0.239 2.276

2.343 21.387

2.313 21.151

0.0112

0.0

0.0068

0.0

LFW

28.418

1631.385

1532.679

0.0757

0.0

adult

0.966

3.609

3.572

0.01

0.0

k=3

bank creditcard

0.294 4.047

1.802 18.771

1.781 18.727

0.0487

0.0

0.01

0.0

LFW

55.3336

1532.592

1476.691

0.144

0.0

adult

2.164

3.120

2.942

0.07

0.0

k=4

bank creditcard

0.241 12.357

1.322 19.486

1.295 17.077

0.0155

0.0

0.01

0.0

LFW

66.426

1466.232

1399.454

0.0832

0.0

7

4.2 Results for Algorithm 3

We compare Algorithm 3 against vanilla clustering and state-of-the-art fair clustering algorithms. Throughout we let k = 2 and due to space limitations, present results for k = 3 and k = 4 in the appendix (Section D.1). We also compare Algorithm 3 and other fair clustering approaches in terms of clustering performance, using clustering performance metrics such as the Silhouette coefficient [28], Calinski-Harabasz score [29], and the Davies-Bouldin index [30]. We use these metrics to unify comparisons across the different clustering algorithms considered in experiments. For all experiments, we choose  to be the fairness cost of the algorithms being compared against (vanilla clustering, fair algorithms) so as to improve on them. We let A be the RACOS [19] algorithm, Vs = 10, n = 100,  = 1.
Comparing Algorithm 3 With Vanilla Clustering and Fair Clustering Approaches. Since Algorithm 3 can accommodate general C and F, we experiment on 3 combinations: Combination #1 with Ck-means and Fsocial, Combination #2 with Ck-means and Fsocial, and Combination #3 where C is unnormalized spectral clustering, and F is Fbalance. The results when comparing against vanilla clustering are shown in Table 2. Vanilla cluster centers are denoted as µvanilla and centers obtained via Algorithm 3 are denoted by µ. As can be seen we add very few antidote data points (|V |/|U |) and improve on the fairness cost over vanilla clustering. For each of the combination settings considered, we also compare against an equivalent state-of-the-art fair clustering algorithm. For Combination #1 we consider the algorithm of Bera et al [9], for Combination #2 we consider the Fair-Lloyd algorithm of Ghadiri et al [7], and for Combination #3 we consider the algorithm of Kleindessner et al [31]. Since the approach of [31] cannot handle large datasets, we subsample each dataset to 1000 samples for Combination #3. The results are shown in Table 3, and centers obtained from fair clustering algorithms are denoted as µSOTA. We find that we outperform fair algorithms in terms of lower fairness costs.

Table 2: Comparing fairness costs of Algorithm 3 with vanilla clustering. (Consider Combination #1 and the bank dataset as an example. The fairness cost for the vanilla cluster centers µvanilla is F (µvanilla, U ) = -0.3054

and  is set to this value to improve on this fairness cost. After Algorithm 3 is run, V is obtained, with size |V | =

0.00011|U |. Cluster centers µ obtained by clustering on U  V result in fairness cost F(µ, U ) = -0.3077.

This is lower than F (µvanilla, U ), leading to improved fairness. Refer to Section 4.2 for more details.)

Clustering-Fairness Combination

Dataset



|V |/|U | F (µvanilla, U ) F (µ, U )

adult

-0.6119

0.001

-0.6119

-0.6196

Combination #1:

bank

-0.3054 0.00011

-0.3054

-0.3077

Ck-means, Fbalance

creditcard LFW

-0.8696 -0.8815

0.00017 0.00075

-0.8696 -0.8815

-0.8715 -0.8821

adult

5.3678

0.0005

5.3678

4.2104

Combination #2:

bank

2.3432

0.00022

2.3432

2.3416

Ck-means, Fsocial

creditcard

19.740

0.00034

19.740

19.729

LFW

1406.3411 0.00076

1406.3411 1406.1676

adult

-0.6458

0.001

-0.6458

-0.6911

Combination #3:

bank

-0.4811 0.00022

-0.4811

-0.5489

Cspectral, Fbalance

creditcard LFW

-0.8384 -0.9279

0.00034 0.00076

-0.8384 -0.9279

-0.8407 -0.9389

Table 3: Comparing fairness costs of Algorithm 3 with fair clustering algorithms. (Reads similarly to Table 2.)

Clustering-Fairness Combination

Dataset



|V |/|U | F (µSOTA, U ) F (µ, U )

adult

-0.6059

0.001

-0.6059

-0.6196

Combination #1:

bank

-0.3065 0.00011

-0.3065

-0.3077

Ck-means, Fbalance

creditcard LFW

-0.8696 -0.8816

0.00017 0.00075

-0.8696 -0.8816

-0.8715 -0.8821

adult

4.2636

0.0005

4.2636

4.2104

Combination #2:

bank

2.3135

0.1549

2.3135

2.3119

Ck-means, Fsocial

creditcard LFW

18.998 1344.5468

0.19 0.3999

18.998 1344.5468

18.998 1344.5461

adult

-0.5973

0.001

-0.5973

-0.6911

Combination #3:

bank

-0.6086

0.5

-0.6086

-0.6899

Cspectral, Fbalance

creditcard

-0.8407

0.38

LFW

-0.9926

0.4

-0.8407 -0.9926

-0.9990 -0.9997

Comparing Clustering Performance. For comparison, we use the widely utilized Silhouette score [28] which lies between [-1, 1], with higher scores indicating better clustering performance. We show the results in Figure 1 for each combination setting considered. The fair clusters of Algorithm 3 used here are the same from Table 3. We observe that despite outperforming fair algorithms in terms of fairness, we still exhibit competitive clustering performance. We defer the results for the other performance metrics to the appendix (Section D.2), since those are unbounded and harder to interpret.

8

(a) Combination #1

(b) Combination #2

(c) Combination #3

Figure 1: Comparing clustering performance of Algorithm 3 with fair clustering algorithms using Silhouette scores. (Higher scores indicate better clustering performance. As can be observed, fair clusters obtained via Algorithm 3 achieve similar clustering performance to SOTA algorithms, while providing improved fairness.)

5 Related Works
Fairness in Machine Learning. ML algorithms can be made fair in three stages of the learning pipeline [32, 33]­ before-training (pre-processing the dataset), during-training (changing the ML algorithm), or after-training (post-processing the learnt model). Most research on fair clustering focuses on the during-training phase [5, 7, 9, 31, 34­37] and proposes fair clustering algorithms. In their paper, [38] study the after-training phase for improving fairness post-clustering. The approaches proposed in our paper are novel since they improve fairness for clustering models in the before-training stage. Further, our approaches can accommodate general fairness notions and clustering algorithms.
Machine Teaching. Our approach in this paper is inspired by the techniques in machine teaching literature [39­45]. Machine teaching studies the interaction between a teacher and a learner where the teacher selects training examples for the learner to learn a specific task. A machine teaching problem can be cast in a bi-level form where the upper-level problem defines the teacher's cost and the lower-level problem defines the learner's method. Variations of this bi-level form can be used to formulate teacher's optimization problem in a variety of learning settings, including supervised learning [46­49], imitation learning [50­54], and reinforcement learning [55­59]. In the proposed antidote data problem for clustering, the upper-level problem (teacher's cost) is the cost of adding antidote data, and the lower-level problem (learner) is the clustering algorithm.
Bi-level Optimization. Bi-level problems involve a two-level hierarchical optimization. For these, a lower-level problem exists, which influences the solutions for an upper-level problem. Both bi-level optimization and verifying the optimality of an obtained solution are NP-Hard [60, 61]. This makes finding optimal solutions and evaluating them non-trivial tasks. In the paper, the main problem considered is a complex bi-level optimization, where both upper-level and lower-level problems can be non-convex optimization problems. Many techniques for bi-level programming exist, but most of these assume simple forms for the upper/lower problems, or use evolutionary methods for which theoretical results are hard to provide [13]. Despite these challenges, we provide algorithms that obtain feasible solutions to the bi-level problem and outperform state-of-the-art fair clustering approaches.
6 Concluding Discussions
We propose the antidote data problem for improving fairness in clustering. We provide a more general alternative to traditional approaches aimed at making clustering fair. Instead of proposing new fair variants to clustering algorithms, we augment the original dataset with new antidote data points. When regular clustering is undertaken on this new dataset, the clustering output is fair. This approach voids the need to come up with new fair algorithms or individual analysis, for different fairness notions or clustering algorithms. Our approach also does not require reimplementation for deployment in actual systems, if the fairness notion or clustering algorithm is changed. We find that our algorithms only need to add a small percentage of points to achieve the given fairness constraints on many real-world datasets without loss of clustering performance.
A major limitation of our work is running time. We present empirical results in the appendix (Section E). While not prohibitively slow, in comparison to fair clustering algorithms, Algorithm 3 is generally slower and requires careful parameterization for convergence. Similar limitations hold for the other algorithms. However, we believe that despite these shortcomings, our paper opens up an important alternative direction for future research in fair clustering, as our experiments also demonstrate. For future work, we aim to provide faster and more general algorithms for the bi-level problem.
9

References
[1] Bing Nan Li, Chee Kong Chui, Stephen Chang, and Sim Heng Ong. Integrating Spatial Fuzzy Clustering with Level Set Methods for Automated Medical Image Segmentation. Computers in biology and medicine, 41(1):1­10, 2011.
[2] Le Lu and René Vidal. Combined Central and Subspace Clustering for Computer Vision Applications. In ICML, volume 148, pages 593­600, 2006.
[3] Kevin Dela Rosa, Rushin Shah, Bo Lin, Anatole Gershman, and Robert Frederking. Topical Clustering of Tweets. Proceedings of the ACM SIGIR: SWSM, 63, 2011.
[4] Vijay Hanagandi, Amitava Dhar, and Kevin Buescher. Density-based Clustering and Radial Basis Function Modeling to Generate Credit Card Fraud Scores. In Proceedings of the IEEE/IAFE Conference on Computational Intelligence for Financial Engineering, pages 247­251, 1996.
[5] Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, and Sergei Vassilvitskii. Fair Clustering Through Fairlets. In NeurIPS, pages 5029­5037, 2017.
[6] Xingyu Chen, Brandon Fain, Liang Lyu, and Kamesh Munagala. Proportionally Fair Clustering. In ICML, volume 97, pages 1032­1041, 2019.
[7] Mehrdad Ghadiri, Samira Samadi, and Santosh S. Vempala. Socially Fair k-means Clustering. In FAccT '21: 2021 ACM Conference on Fairness, Accountability, and Transparency, pages 438­448, 2021.
[8] Bashir Rastegarpanah, Krishna P. Gummadi, and Mark Crovella. Fighting Fire with Fire: Using Antidote Data to Improve Polarization and Fairness of Recommender Systems. In WSDM, pages 231­239, 2019.
[9] Suman Kalyan Bera, Deeparnab Chakrabarty, Nicolas Flores, and Maryam Negahbani. Fair Algorithms for Clustering. In NeurIPS, pages 4955­4966, 2019.
[10] Pang-Ning Tan, Michael Steinbach, and Vipin Kumar. Introduction to Data Mining. Pearson Education India, 2016.
[11] Kiri Wagstaff, Claire Cardie, Seth Rogers, and Stefan Schrödl. Constrained K-means Clustering with Background Knowledge. In ICML, pages 577­584, 2001.
[12] Stephan Dempe. Foundations of Bilevel Programming. Springer Science & Business Media, 2002.
[13] Ankur Sinha, Pekka Malo, and Kalyanmoy Deb. A Review on Bilevel Optimization: From Classical to Evolutionary Approaches and Applications. IEEE Trans. Evol. Comput., 22(2):276­ 295, 2018.
[14] Mohammad Javad Abdi. Cardinality Optimization Problems. PhD thesis, University of Birmingham, 2013.
[15] Fredrik Lindsten, Henrik Ohlsson, and Lennart Ljung. Just Relax and Come Clustering!: A Convexification of k-means Clustering. Linköping University Electronic Press, 2011.
[16] Toby Hocking, Jean-Philippe Vert, Francis R. Bach, and Armand Joulin. Clusterpath: an Algorithm for Clustering using Convex Fusion Penalties. In ICML, pages 745­752, 2011.
[17] André A. Keller. Chapter 3 - elements of technical background. In Mathematical Optimization Terminology, pages 239­298. 2018.
[18] Steven Diamond and Stephen P. Boyd. CVXPY: A Python-Embedded Modeling Language for Convex Optimization. JMLR, 17:83:1­83:5, 2016.
[19] Yang Yu, Hong Qian, and Yi-Qi Hu. Derivative-Free Optimization via Classification. In AAAI, pages 2286­2292, 2016.
[20] Nikolaus Hansen, Sibylle D. Müller, and Petros Koumoutsakos. Reducing the Time Complexity of the Derandomized Evolution Strategy with Covariance Matrix Adaptation (CMA-ES). Evol. Comput., 11(1):1­18, 2003.
[21] Kenji Kawaguchi, Leslie Pack Kaelbling, and Tomás Lozano-Pérez. Bayesian Optimization with Exponential Convergence. In NeurIPS, pages 2809­2817, 2015.
[22] Hong Qian, Yi-Qi Hu, and Yang Yu. Derivative-Free Optimization of High-Dimensional Non-Convex Functions by Sequential Random Embeddings. In IJCAI, pages 1946­1952, 2016.
10

[23] Yang Yu and Hong Qian. The Sampling-and-learning Framework: A Statistical View of Evolutionary Algorithms. In Proceedings of the IEEE Congress on Evolutionary Computation, CEC, pages 149­158, 2014.
[24] Ron Kohavi. Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid. In KDD, pages 202­207, 1996.
[25] Sérgio Moro, Paulo Cortez, and Paulo Rita. A Data-driven Approach to Predict the Success of Bank Telemarketing. Decis. Support Syst., 62:22­31, 2014.
[26] I-Cheng Yeh and Che-hui Lien. The Comparisons of Data Mining Techniques for the Predictive Accuracy of Probability of Default of Credit Card Clients. Expert Syst. Appl., 36(2):2473­2480, 2009.
[27] Gary B Huang, Marwan Mattar, Tamara Berg, and Eric Learned-Miller. Labeled Faces in the Wild: A Database For Studying Face Recognition in Unconstrained Environments, 2008.
[28] Peter J. Rousseeuw. Silhouettes: A Graphical Aid to the Interpretation and Validation of Cluster Analysis. Journal of Computational and Applied Mathematics, 20:53­65, 1987.
[29] T. Calin´ski and J Harabasz. A Dendrite Method for Cluster Analysis. Communications in Statistics, 3(1):1­27, 1974.
[30] David L. Davies and Donald W. Bouldin. A Cluster Separation Measure. IEEE Trans. Pattern Anal. Mach. Intell., 1(2):224­227, 1979.
[31] Matthäus Kleindessner, Samira Samadi, Pranjal Awasthi, and Jamie Morgenstern. Guarantees for Spectral Clustering with Fairness Constraints. In ICML, volume 97, pages 3458­3467, 2019.
[32] Simon Caton and Christian Haas. Fairness in Machine Learning: A Survey. CoRR, abs/2010.04053, 2020.
[33] Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. A Survey on Bias and Fairness in Machine Learning. CoRR, abs/1908.09635, 2019.
[34] Ioana Oriana Bercea, Martin Groß, Samir Khuller, Aounon Kumar, Clemens Rösner, Daniel R. Schmidt, and Melanie Schmidt. On the Cost of Essentially Fair Clusterings. In APPROX/RANDOM, volume 145 of LIPIcs, pages 18:1­18:22. Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 2019.
[35] Arturs Backurs, Piotr Indyk, Krzysztof Onak, Baruch Schieber, Ali Vakilian, and Tal Wagner. Scalable Fair Clustering. In ICML, volume 97, pages 405­413, 2019.
[36] Melanie Schmidt, Chris Schwiegelshohn, and Christian Sohler. Fair Coresets and Streaming Algorithms for Fair k-means. In Approximation and Online Algorithms - 17th International Workshop, WAOA, volume 11926 of Lecture Notes in Computer Science, pages 232­251, 2019.
[37] Imtiaz Masud Ziko, Eric Granger, Jing Yuan, and Ismail Ben Ayed. Clustering with Fairness Constraints: A Flexible and Scalable Approach. CoRR, abs/1906.08207, 2019.
[38] Ian Davidson and S. S. Ravi. Making Existing Clusterings Fairer: Algorithms, Complexity Results and Insights. In AAAI, pages 3733­3740, 2020.
[39] Sally A. Goldman and Michael J. Kearns. On the Complexity of Teaching. Journal of Computer and System Sciences, 50(1):20­31, 1995.
[40] Thorsten Doliwa, Gaojian Fan, Hans Ulrich Simon, and Sandra Zilles. Recursive Teaching Dimension, VC-Dimension and Sample Compression. JMLR, 15(1):3107­3131, 2014.
[41] Adish Singla, Ilija Bogunovic, Gábor Bartók, Amin Karbasi, and Andreas Krause. NearOptimally Teaching the Crowd to Classify. In ICML, volume 32, pages 154­162, 2014.
[42] Xiaojin Zhu. Machine Teaching: An Inverse Problem to Machine Learning and an Approach Toward Optimal Education. In AAAI, pages 4083­4087, 2015.
[43] Xiaojin Zhu, Adish Singla, Sandra Zilles, and Anna N. Rafferty. An Overview of Machine Teaching. CoRR, abs/1801.05927, 2018.
[44] Yuxin Chen, Adish Singla, Oisin Mac Aodha, Pietro Perona, and Yisong Yue. Understanding the Role of Adaptivity in Machine Teaching: The Case of Version Space Learners. In NeurIPS, 2018.
[45] Tomi Peltola, Mustafa Mert Çelikok, Pedram Daee, and Samuel Kaski. Machine Teaching of Active Sequential Learners. In NeurIPS, 2019.
11

[46] Xiaojin Zhu. Machine Teaching for Bayesian Learners in the Exponential Family. In NeurIPS, pages 1905­1913, 2013.
[47] Ji Liu and Xiaojin Zhu. The Teaching Dimension of Linear Learners. JMLR, 17(162):1­25, 2016.
[48] Farnam Mansouri, Yuxin Chen, Ara Vartanian, Xiaojin Zhu, and Adish Singla. Preferencebased Batch and Sequential Teaching: Towards a Unified View of Models. In NeurIPS, pages 9195­9205, 2019.
[49] Rati Devidze, Farnam Mansouri, Luis Haug, Yuxin Chen, and Adish Singla. Understanding the Power and Limitations of Teaching with Imperfect Knowledge. In IJCAI, pages 2647­2654.
[50] Maya Cakmak and Manuel Lopes. Algorithmic and Human Teaching of Sequential Decision Tasks. In AAAI, volume 26, 2012.
[51] Luis Haug, Sebastian Tschiatschek, and Adish Singla. Teaching Inverse Reinforcement Learners via Features and Demonstrations. In NeurIPS, pages 8473­8482, 2018.
[52] Parameswaran Kamalaruban, Rati Devidze, Volkan Cevher, and Adish Singla. Interactive Teaching Algorithms for Inverse Reinforcement Learning. In IJCAI, pages 2692­2700, 2019.
[53] Daniel S Brown and Scott Niekum. Machine Teaching for Inverse Reinforcement Learning: Algorithms and Applications. In AAAI, 2019.
[54] Sebastian Tschiatschek, Ahana Ghosh, Luis Haug, Rati Devidze, and Adish Singla. Learneraware Teaching: Inverse Reinforcement Learning with Preferences and Constraints. In NeurIPS, 2019.
[55] Haoqi Zhang and David C. Parkes. Value-Based Policy Teaching with Active Indirect Elicitation. In AAAI, pages 208­214, 2008.
[56] Haoqi Zhang, David C. Parkes, and Yiling Chen. Policy Teaching through Reward Function Learning. In EC, pages 295­304, 2009.
[57] Amin Rakhsha, Goran Radanovic, Rati Devidze, Xiaojin Zhu, and Adish Singla. Policy Teaching via Environment Poisoning: Training-time Adversarial Attacks against Reinforcement Learning. In ICML, volume 119, pages 7974­7984, 2020.
[58] Yuzhe Ma, Xuezhou Zhang, Wen Sun, and Jerry Zhu. Policy Poisoning in Batch Reinforcement Learning and Control. In NeurIPS, pages 14543­14553, 2019.
[59] Amin Rakhsha, Goran Radanovic, Rati Devidze, Xiaojin Zhu, and Adish Singla. Policy Teaching in Reinforcement Learning via Environment Poisoning Attacks. CoRR, abs/2011.10824, 2020.
[60] Pierre Hansen, Brigitte Jaumard, and Gilles Savard. New Branch-and-Bound Rules for Linear Bilevel Programming. SIAM J. Sci. Comput., 13(5):1194­1217, 1992.
[61] L. Vicente, G. Savard, and J. Júdice. Descent Approaches for Quadratic Bilevel Programming. J. Optim. Theory Appl., 81(2):379­399, May 1994.
12

Checklist
1. For all authors...
(a) Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes] The claims made in the introduction (Section 1) and abstract accurately match the results obtained (Section 4).
(b) Did you describe the limitations of your work? [Yes] The limitations are discussed in the Concluding Discussions section (Section 6) and further detailed in the supplementary material (Section E of appendix).
(c) Did you discuss any potential negative societal impacts of your work? [No] There are no negative societal impacts of our work­ we instead aim to propose algorithms that make ML (clustering) fair.
(d) Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes]
2. If you are including theoretical results...
(a) Did you state the full set of assumptions of all theoretical results? [Yes] The assumptions are clearly listed in each theoretical statement. In particular, only Theorem 3.1 is our novel contribution which has all assumptions made clear in the theorem statement.
(b) Did you include complete proofs of all theoretical results? [Yes] All proofs are present in the supplementary material (Section A of appendix).
3. If you ran experiments...
(a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes] Yes, we provide parameter details in the Results section (Section 4). We also provide our code files (and instructions on reproduction) as part of the supplementary material.
(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes]
(c) Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? [No] The results obtained for our algorithms are deterministic, and error bars do not apply.
(d) Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes] These details regarding running time and time complexity analysis are present in the supplementary material (Section E of appendix).
4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
(a) If your work uses existing assets, did you cite the creators? [Yes] (b) Did you mention the license of the assets? [No] Not applicable. (c) Did you include any new assets either in the supplemental material or as a URL? [No]
We do not use any new assets; all our code is open-source and available. (d) Did you discuss whether and how consent was obtained from people whose data you're
using/curating? [No] Not applicable. (e) Did you discuss whether the data you are using/curating contains personally identifiable
information or offensive content? [No] Not applicable.
5. If you used crowdsourcing or conducted research with human subjects...
(a) Did you include the full text of instructions given to participants and screenshots, if applicable? [No] Not applicable.
(b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [No] Not applicable.
(c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [No] Not applicable.
13

