arXiv:2106.00492v1 [stat.ME] 1 Jun 2021

Logistic Regression Through the Veil of Imprecise Data
Nicholas Gray and Scott Ferson
Institute for Risk and Uncertainty, Univerity of Liverpool nickgray@liverpool.ac.uk
Abstract
Logistic regression is an important statistical tool for assessing the probability of an outcome based upon some predictive variables. Standard methods can only deal with precisely known data, however many datasets have uncertainties which traditional methods either reduce to a single point or completely disregarded. In this paper we show that it is possible to include these uncertainties by considering an imprecise logistic regression model using the set of possible models that can be obtained from values from within the intervals. This has the advantage of clearly expressing the epistemic uncertainty removed by traditional methods.
Keywords: Logistic Regression, Imprecise Data, Interval Analysis, Uncertainty Quantification, Epistemic Uncertainty, Missing Data
1 Introduction
Logistic regression is used to predict the probability of a binary outcome as a function of some predictive variable, where the time of the event is not important. In medicine for example, logistic regression can be used to predict the probability of an individual having a disease where the values of risk factors are known. While logistic regression is most commonly used for binary outcomes, it can be applied to any number of categorical outcomes (Menard, 2010, Chapter 1)). However, many decisions and events are binary in nature (yes/no, passed/failed, alive/dead, etc), and for the sake of simplicity, we will restrict our discussion and examples to binary outcome logistic regression. Additionally, logistic regression, unlike discriminant function analysis, does not require predictor variables to be normally distributed, linearly related or to have equal variance (Press and Wilson, 1978).
There are many practical applications for logistic regression across many different fields. For example, in the medical domain a risk factor in the form of continuous data ­ such as age ­ or categorical data ­ such as gender ­ may be fit a model to predict the probability of a patient surviving an operation (Bagley et al., 2001; Neary et al., 2003). In engineering systems, logistic regression can be used to determine whether a mineshaft is safe (Palei and Das, 2009); to predict the risk of lightning strikes (Lambert and Wheeler, 2005) or landslides (Ohlmacher and Davis, 2003). In the arts in can be used to explore how education impacts museum attendance or watching a performing arts performance (Kracman, 1996). Within professional sports, it is also possible to predict the probability of game outcomes using logistic regression (Li et al., 2021). Due to its wide range of applications, logistic regression is considered a key machine learning algorithm with many modern programming languages having packages for users to experiment with, such as Scikit-learn (Pedregosa et al., 2011) in Python which has been used for the analysis within this paper.
Traditionally it has been assumed that all of the values of the predictor variables and outcome states used in a logistic regression are precisely known. This assumption is valid when the sampling uncertainty or natural variability in the data is large compared to the epistemic uncertainty or if values are missing at random (Ferson et al., 2007). However, in practice there can be considerable imprecision in both the independent and dependent variables used in the regression analysis as well as in the application of the regression model. Analysis using data from combined studies with inconsistent measurement methods can even result in data sets with varying degrees of uncertainty. Likewise, the outcome data can be uncertain if there is ambiguity in the classification scheme (good/bad). However, even relatively clear classification (alive/dead) can yield uncertainty when a subject leaves a study and the outcome is now unknown. Measurement uncertainty in both the independent and dependent variables are sometimes best represented as forms of interval data, sometimes called "censored" data. In the case of continuous predictor variables, the interval reflects the
1

measurement uncertainty, while in the binary outcome, the interval is the vacuous [0, 1] because the true classification is unclear.
In the case that there is uncertainty in the outcome status used within logistic regression, traditionally, there is little that can be done but to discard these datapoints as they cannot be used as part of the analysis. There are multiple methods of dealing with interval data with the dependant variables for logistic regression, but they fall under two basic categories. The first approach is to use some approximation that allows the interval to be represented as a single value. This simplifies the process by allowing the use of standard logistic regression techniques. Another approach is to maintain the interval, propagate it through the regression analysis, and present a set of multiple logistic regressions models.
Under the first category of methods, one approach is to treat interval data as uniform distribution (Bertrand, 2000; Billard and Diday, 2000; Bock and Diday, 2001; De Souza et al., 2011) based on the "equidistribution hypothesis" (Bertrand, 2000) that each possible value can considered to be equally likely. This idea has its roots in the principle of insufficient reason first described by both Bernoulli and Laplace, and more recently known as the principle of indifference (Keynes, 1921). Alternatively, the interval is commonly represented by the interval's midpoint which represents the mean and median of a uniform distribution, or a random value from within the interval (Osler et al., 2010). While these approaches are computationally expedient, they underrepresent the imprecision by presenting a single middle-of-the-road logistic regression.
Similar methods include performing a conjoint logistic regression using the interval endpoints or averaging separate regressions performed on the endpoints of the intervals (De Souza et al., 2011, 2008). A more general approach is to construct a likelihood function for an interval datum as the difference in cumulative distribution functions of each endpoint (Escobar and Meeker Jr, 1992). While these various methods make different assumptions about the data within the interval ranges, ultimately, they still transform interval data such that the final results can be represented by a single binary logistic regression (De Souza et al., 2011).
The approach proposed within this paper for dealing with interval data in logistic regressions is based on imprecise probabilities and considers the set of models rather than a single one as has been proposed for linear regression (Walley, 1991; Manski, 2003; Ferson et al., 2007; Utkin and Coolen, 2011; Nguyen et al., 2012; Wiencierz, 2013). If separate logistic regressions are generated via maximum likelihood estimation from the interval data and displayed as cumulative distribution functions, the envelope of the extreme functions bound the true model. The primary benefit of such an approach is that it clearly represents the existing epistemic uncertainty that is removed by traditional methods. Additionally, this method can also handle the case of uncertainty in discrete risk factors or outcome status. The imprecise probabilities approach makes the fewest assumptions, but some statistics can be computationally challenging for large data sets (Ferson et al., 2007).

2 Certain Logistic Regression

A logistic regression model predicts the probability that a random variable with m explanatory features

x = (x1 x2 · · · xm)

(1)

has a binary outcome y equal to 0 or 1 given a dataset D that contains n datapoints which are pairs of y and x. The probability that y = 1, is given by:

1

(x) = Pr(y = 1|x) = 1 + exp (-0 -

m i=1

i

xi

)

.

(2)

The model needs to be trained to find the values of 0, 1, . . . , m such that the curve is best fitted to D. These values have to be estimated as they cannot be calculated directly from the data, maximum

likelihood estimation is often used to find these values (Menard, 2010; Myung, 2003). The use of least squares

regression has also been used with interval data (Gioia et al., 2005; Fagundes et al., 2013), but primarily for

linear regression models. Non linear least squares regression should be avoided because it does not support

hypothesis testing or generating confidence intervals (Myung, 2003).

For a new predictor x , a classification for the corresponding y can be made from the logistic regression

model by assuming that

1 if (x )  C

y=

(3)

0 if (x ) < C

where C is some threshold value. The simplest case is when C = 0.5, however this value could be different depending on the use of the model and the risk appetite of the analyst. For example in anaesthesiology, the

2

threshold value is 5% in order to produce a conservative classification. For the purpose of this paper where predictions are made, C = 0.5 unless otherwise stated.
2.1 Testing the Performance of the Logistic Regression

Figure 1: Logistic regression curve for the points shown.

Synthetic data with a sample size of fifty were generated and used to train the model that is shown in

Figure 1. After training it is useful to ask the question "how good is my model?" For logistic regression

there are several ways in which that can be done, see Hosmer Jr et al. (2013, pp. 157­169) or Kleinbaum

and Klein (2010, pp.318­326), but for the analysis in this paper there are two ways that will be used.

The first is using the Homser-Lemeshow (HL) test to assess the goodness of fit of the model (Hosmer Jr

and Lemeshow, 1980; Lemeshow and Hosmer, 1982). The second is to assess the model's discriminatory

performance by considering its receiver operating characteristics, the area under curve (AUC) statistic and

other visualisations (Royston and Altman, 2010).

HL uses the following approach to assess the goodness of fit of the model. Firstly  is calculated for

all n samples and then ordered and grouped into g groups such that the n/g samples that have the lowest

probabilities are in group G1 and so on until the n/g samples with the highest probabilities are in group Gg. For each group the expected number of cases, E1, (outcomes equal to 1) and the expected number of noncases, E0, can be calculate using

E1,i =

(xj )

(4)

xj Gi

and

E0,i =

1 - (xj)

(5)

xj Gi

respectively, i.e. the sum of all the probabilities within each of the groups. These values can be compared to the observed number of cases, O1, and observed number of noncases O0. The Hosmer-Lemeshow statistic, HL can then by calculated using

HL = g (O1,i - E1,i)2 + g (O0,i - E0,i)2 .

(6)

i=1

E1,i

i=1

E0,i

Clearly the lower the value the better the model so a perfect model would have HL = 0. As the HL statistic follows a 2 distribution with g - 2 degrees of freedom (Hosmer Jr and Lemeshow, 1980; Lemeshow and
Hosmer, 1982), a hypothesis test may be performed in order to determine the goodness of fit. Setting the

3

null hypothesis H0 to be that there is evidence to suggest that the model fits the data. By comparing HL to 2(g - 2), a p-value can be generated and if p  0.05 then we can reject the null hypothesis. For the above example we find that HL = 3.307, with a corresponding p-value of 0.914 which is not enough to reject the null hypothesis.
We can make and compare the predictions made from the logistic regression model using a larger data set that has been generated using the same method described above. Tabulating these results in a confusion matrix for the base predictions gives the following confusion matrix shown in Table 1. Two statistics are often used in order to express the performance of a classifier. These are the sensitivity s which is the fraction of positive individuals correctly identified as such and the specificity t which is the fraction of negative individuals correctly identified as such. Mathematically

T rue P ositive

s=

(7)

T otal N umber of P ositives

and

T rue N egative

t=

.

(8)

T otal N umber of N egatives

Predicted Positive Predicted Negative
Total

Positive 194 45 47

Negative 30 231 53

Total 224 276 100

Table 1: Confusion matrix for 500 datapoints generated using the same method as the training data.

From Table 1 we can see that s = 0.812 and t = 0.885, which represent a good classifier. As confusion matrices and statistics calculated from them depend on the cutoff value chosen (C from Equation 3), a more complete way of determining the classification performance of models is by considering the receiver operating characteristic (ROC) curve of the model (Kleinbaum and Klein, 2010; Hosmer Jr et al., 2013). This can be plotted by calculating how the sensitivity and specificity change for various threshold values and then plotting a graph of the false positive rate, f pr = 1 - t, against s for all C values. For the example such a plot is shown in Figure 2a. The more upper-left a curve is the better the classification. The worst performing model's ROC curve would match the black dotted line (s = f pr), which would be the ROC curve for a random classifier. If a model had a ROC curve down-right of this line then it implies that the performance would be improved by switching the outcome classes of the model, as if it predicted true then it is more likely to be false and vice versa. ROC curves can be compared both graphically and by considering the area under the curve (AUC), the better the model is the closer the AUC would be to 1. The worst possible AUC would be 0.5, as again anything lower than that would be improved by simply switching the classification. For the ROC curve shown in Figure 2a AUC = 0.923, which could be considered `outstanding discrimination' between the two classes (Hosmer Jr et al., 2013, p. 177).

(a) ROC curve for the simple example.

(b) Scatter plot of jittered outcome vs estimated probability for the simple example.

Figure 2: Two plots to show the discriminatory performance of the simple example.

4

Royston and Altman (2010) introduced visualisations to assess the discriminatory performance of the model by considering a scatter plot of the true outcome (jittered for clarity) vs the estimated probability. Such a plot is shown in Figure 2b. A perfectly discriminating model would have two singularities with all the points with outcome = 1 at (1,1) and all the points with outcome = 0 at (0,0). In general the better the classifier, the more clustered the points would be towards these values with the points on the upper band having larger probabilities and the points on the lower band having lower probabilities. From Figure 2b we can see that there is significant clustering towards the end points, showing that the model has excellent discriminatory performance as expected given its HL statistic.

3 Interval Uncertainty in Logistic Regression

When there is interval uncertainty in a logistic regression model, Equation 2 becomes

1

(x) = 1 + exp - 0, 0 -

m i=1

i, i

xi

(9)

where each of the  values is now an interval. As such (x) is itself also an interval (x), (x) . Unfortu-
nately, it likely to be the case that (x) is unnecessarily wide if it is calculated by simply using the upper and lower bounds for all the  values in Equation 9 using naive interval analysis (Moore et al., 2009). This is because dependence exists between all the  values. As a result it is useful to not just calculate the bounds for the  values but to instead consider the imprecise model as the set of possible logistic regression models
that could be created within the imprecision of the training data set. As such the (x), (x) can be cal-
culated by finding the minimum and maximum possible values for (x) from all possible logistic regression models that are consistent with the interval data.
When calculating the probability of a value being 1 under the imprecise model, for new data there is not just a single probability of being 1 but instead an interval probability as described above. When using the model to perform classifications, this interval means that Equation 3 becomes



1 if (x) > C



y = 0 if (x) < C

(10)

[0, 1] if (x) C

The final line of this equation returns the dunno interval, meaning there is uncertainty in determining whether the datum should be predicted true or false. It is left up to the analyst to decide what should be done with such a result. However, it may be the case that if a prediction cannot be made then it may be useful to simply not make a prediction using logistic regression. Under this framework the traditional confusion matrix has an additional row as shown in Table 2. From this confusion matrix there are some useful statistics that can be calculated to account for the uncertainty produced by these uncertain classifications. The first is to consider that the traditional definitions of sensitivity and specificity can be could be re-imagined by defining what the predictive sensitivity s as the sensitivity out of the points for which a prediction was made

a

s=

(11)

a+c

and similarly the predictive specificity t as the specificity for which a prediction was made

d

t=

.

(12)

b+d

Predicted Positive Predicted Negative
No Prediction Total

Positive a c e T+

Negative b d f T-

Total
P+ P- Px N

Table 2: Alternative confusions matrix where uncertain predictions are tabulated separately.

5

Two other statistics are useful to describe the data in Table 2. We can define the positive incertitude  to be the fraction of positive cases for which the model could not make a prediction

e

=

.

(13)

a+c+e

Similarly, the negative incertitude  can be defined as the total number of negative cases for which the model

could not make a prediction

f

=

.

(14)

b+d+f

As before, Hosmer-Lemeshow tests can be used to test for the goodness of fit of the models. For the imprecise model this requires careful consideration of the repeated variables and dependencies in order to ensure that the the statistics are unnecessarily wide, see Appendix A for details. The calculated HL statistic will itself be an interval and, ergo, the p­value will be an interval. This may lead to the situation in which it is not possible to determine if p > 0.05 and, as such, further analysis would be needed to conclude whether H0 should be rejected or not.

4 Uncertainty in Outcome Status
If there are n datapoints that can be used to train the model but q of them have an uncertain result then traditional analysis may just ignore these points. However they can be included within the analysis by considering the set of possible logistic regression models for all possible 0/1 results for all q uncertain values. All q's have outcome 0, all q's have outcome 1, and all intermediate combinations thereof. This leads to 2q possible logistic regression models. An imprecise logistic regression model can then be created by finding the envelope of the set. As the computational time for this algorithm increases as O(2q), then as q increases finding the bounds by calculating the envelope for all possible combinations can become computationally expensive. In such a scenario an efficient algorithm would be useful in order to estimate the bounds.

4.1 Example
Following on from the example in Section 2.1, Figure 3 shows what the imprecise logistic regression model looks like when 5 data points have been removed from the training data, although not at random. Points have been removed that are around the point at which the majority of the data goes from being positive to negative. From the figure it is clear that the datapoints add significant uncertainty to to the model and that simply removing the uncertain datapoints makes the regression curve significantly different from the `true' model that is trained with no uncertainty in the data (the model of Section 2.1). It can also be seen that the imprecise model bounds the true model.

6

Figure 3: Bounds for the imprecise logistic regression (blue) for all the 50 grey points with 5 points made uncertain (shown with vertical lines with the true values shown with black diamonds). Compared with the no-uncertainty curve from Figure 1 (black) and the logistic regression model trained on the dataset removing the uncertain points (red).

In this analysis we can calculate the HL statistic for all models in Figure 3. We find that the uncertain bounds have a interval HL-statistic, HL = [1.222, 7.500], with interval p-value = [0.484,0.996]. As might be expected from the graph, the discarded model has a significantly higher HL-statistic, HL = 10.203 and a correspondingly lower p-value = 0.251­although not low enough to reject the null hypothesis and conclude that there is no evidence of lack of fit.
When it comes to assessing classifications from the model, there are two possible ways of expressing the effect of uncertainty presented by the imprecise model. The method described above is to tabulate the dunno results separately within the confusion matrix as has been done in Table 3. From this we can clearly see that for observations for which the model produces a prediction it performs well, s = 0.815 and t = 0.909. This shows that, for the predictions that the model did make, there were fewer mistakes than when the analysis ignored the uncertain datapoints, although this has come at the cost of having a few datapoints for which no classification was made. For the incertitude we find  = 0.092 and  = 0.123.

Predicted Positive Predicted Negative
No Prediction Total

Positive 184 35 20 239

Negative 20 210 31 261

Total 204 245 51 500

Table 3: Confusion matrix for 500 datapoints from the imprecise logistic regression model shown in Figure 3, tabulating uncertain predictions separately.

Another method is to consider the prediction as the dunno interval [0, 1] within a traditional confusion matrix. Doing this we get the confusion matrix shown in Table 4, from which the sensitivity and specificity can be calculated as intervals s = [0.774, 0.824] and t = [0.843, 0.916].
As before it is useful to consider visualisations when discussing the discriminatory performance of the classifier (Figure 4). The simplest of these are the scatter plots shown in Figure 4a. Three analyses are shown here. The probability values from the analysis that ignores uncertainty are depicted in red. The analogous values from the analysis with the imprecise model are shown in blue. We can see that all the models have good discrimination. We can also construct ROC plots, and calculate their AUCs. The ROC plots are shown in Figure 4b. The original base analysis is shown as a black curve, the analysis that ignores uncertainty appears as a red curve, and the imprecise analysis where classifications are not made when there is dunno

7

Predicted Positive Predicted Negative
Total

Positive [184,204] [35,55]
239

Negative [20,51] [210,241]
261

Total [204,255] [245,296]
500

Table 4: Confusion matrix for 500 datapoints from the imprecise logistic regression model shown in Figure 3, keeping uncertain predictions as the interval [0, 1].

uncertainty is the blue line. There are a few notable things about these plots, firstly the red curve model is imperceptibly different to the black curve, with red AU C = 0.9235 compared to the black AU C = 0.9233. For the case where predictions are not made when there is uncertainty about the classification, s and f pr = 1 - t are plotted, overall this blue curve outperforms the others, with AU C = 0.9457.

8

(a) Scatter plots of probability vs outcome for the base model (black), the model where uncertain datapoints have been excluded (red) and the model including the uncertain datapoints (blue). The two outcomes have been separated into different plots for clarity.

(b) Receiver operating characteristic curve for the simple example with added uncertain classifications.

(c) 3 dimensional ROC curve for the simple example with positive/negative incertitude on z-axis. The blue line represents the 2-dimensional ROC curve shown in Figure 4b. The orange and green lines always lie above this blue line.
Figure 4: Three plots to show the discriminatory performance of the logistics regression models used within the simple example with uncertain classifications.
It is also worth considering how the incertitude changes as the threshold value changes. To do this we can plot a 3-dimensional version of the ROC plot, with the positive/negative incertitude on the z-axis. Such a plot is shown in Figure 4c. From this plot we can see that as the sensitivity improves the positive incertitude generally decreases and as the specificity increases the negative incertitude decreases.
In Figure 3 all the uncertain datapoints are around the centre of the range at the points at which the values switch from being false to true. However this need not be the case, consider the example shown in Figure 5. The dataset has 50 points, of which 5 have had their outcome status censored, the values that have been censored all have high x values. Simply ignoring these points gives a logistic regression model
9

with HL = 9.464, p = 0.305, suggesting that there is limited evidence that the model does not fit the data. Including these points within the model using the proposed method gives us an imprecise logistic regression model with HL = [13.07, 39.77] with p = [3.542 × 10-7, 0.109], from which we could not make a decision about whether or not H0 should be rejected, implying that there may be evidence to suggest that the model does not fit the data. Given that the lower bound of the p-value would represent such an extreme result, then it is probably the case that the null hypothesis should be rejected. It is not clear that the logistic model is appropriate given the uncertainty within the data.
Figure 5: Bounds for the imprecise logistic regression (blue) for all the 50 grey points with 5 points made uncertain shown with vertical lines. The logistic regression model trained on the dataset removing the uncertain points (red).
5 Interval Uncertainty in Predictor Variables
Let D be a m-dimensional dataset, containing n samples, some of which are intervals x(ij) = xi, xi (j) , i  n, j  m. Under this uncertainty the logistic regression model would be the envelope of all possible logistic regression curves calculated by taking all possible combinations of any x-values from within the intervals in the dataset. The number of configurations is infinitely large, but finite methods can be used in order to bound the curves. One approach is to use Monte Carlo in order to randomly sample from the intervals, however this is likely to be suboptimal as it is unlikely to find the extreme configurations of points within the dataset. An estimate for these bounds can be made using the following algorithm:
1. Find the logistic regression model that is trained on the dataset for which the intervals in all of the dimensions have been reduced to their upper bounds and the model that is trained on the dataset for which the intervals in all of the dimensions have been reduced to their lower bounds.
2. Find the logistic regression models that are trained on all combinations of the dataset where for some dimensions the intervals have been reduced to their upper bounds and for others they have been reduced to their lower bounds.
3. For each of these 2m logistic regression models find x such that (x) = 0.5 then train a model from the datasets constructed from the values from the intervals that correspond to the minimum and maximum variance around x. This produces the locally steepest and shallowest models.
4. The envelope set of these 3 × 2m logistic regression models can then be used as the imprecise logistic regression model
10

5.1 Example
The 2.1 data has been intervalised by the following transformation x  [m - , m + ] where m is a number drawn from a uniform distribution and = 0.25. Figure 6 shows the imprecise logistic regression curve. Also on this plot the red line is the case for which the dataset used to train the model is the midpoints of the interval dataset, and the base model in black is the same as in section 2.1. It is also evident that the interval datapoints have added considerable uncertainty to the regression. For this uncertain model HL = [1.878, 5.421] with p = [0.712, 0.985]. This can be compared to the base model with HL = 3.307, p = 0.914 and the midpoint model HL = 3.315, p = 0.913.

Figure 6: Imprecise logistic regression model (blue lines) for the interval data (grey) jittered slightly, compared with the base model (black line) from Figure 1 and the model trained using the midpoints of the intervals (red line).

As above, while making predictions from the imprecise model one is likely to obtain dunno ranges as shown in Equation 10. We can tabulate the dunno intervals in the confusion matrix, giving the result shown in Table 5, from which the sensitivity and specificity are calculated as s = [0.95, 0.98] and t = [0.85, 0.91]. Alternatively, we can tabulate the dunno predictions separately from the confusion matrix as has been done in Table 6. From this we can clearly see that, for observations for which the model produces a prediction, it performs well, with s = 0.88 and t = 0.98 both of which are higher than when ignoring the uncertainty as in Table 1. For the samples that were not given a prediction, analysts might devise alternative strategies to make a classification, potentially allowing improved outcomes.

Predicted Positive Predicted Negative
Total

Positive [185,197] [42, 54]
239

Negative [22,41] [220,239]
261

Total [207,238] [262,293]
500

Table 5: Confusion matrix for 500 samples from the imprecise logistic regression model shown in Figure 6, tabulating inconclusive results as dunno intervals.

11

Predicted Positive Predicted Negative
No Prediction Total

Positive 185 42 12 239

Negative 22 220 19 261

Total 207 262 31 500

Table 6: Confusion matrix for 500 samples from the imprecise logistic regression model shown in Figure 6, tabulating inconclusive results (dunno) separately.

The discriminatory performance of the model as a classifier can be assessed using visualisations, as shown in Figure 7. The simplest of these is the scatter plot shown in Figure 7a. We can see that all three models have good discrimination. We can also construct ROC plots, and calculate the AUC, for the ignored uncertainty model and the imprecise model. These plots are shown in Figure 7b. There are a few notable things about these plots, firstly the model where the uncertain training data has been reduced to the midpoints is similar to that of the base model with AU C = 0.9234. For the imprecise model, s and f pr are plotted, and overall this curve outperforms the others, with AU C = 0.936.

12

(a) Scatter plots of probability vs outcome for the base model (black), the model where uncertain datapoints have been excluded (red) and the imprecise model including the uncertain data (blue). The two outcomes have been separated into different plots for clarity.

(b) Receiver operating characteristic curve for the simple example with added uncertain classifications.

(c) 3 dimensional ROC curve for the simple example with positive/negative incertitude on z-axis. The blue line represents the 2-dimensional ROC curve shown in Figure 7b. The orange and green lines always lie above this blue line.
Figure 7: Three plots to show the discriminatory performance of the logistic regression models used within the simple example with uncertain classifications.
As with the uncertain classification example is it useful to consider the scenario in which the data has been given some systematic bias when the interval is generated. In Figure 8a the data has been biased by taking x  [x, x + 2 ], setting the true value as always the lower bound of the interval. In Figure 8b the reverse has been done x  [x - 2 , x], setting the true value as always the upper bound of the interval. Finally, in Figure 8c the data has been intervalised using
[x - 2 , x] , x < 5 x
[x, x + 2 ] , x  5
13

By looking at all these figures we can see that the true model is always bounded by the imprecise model, as would be expected. As a result any interval regression analysis that has been performed is guaranteed to bound the true answer, whereas there can be significant differences between the base model and the midpoint model.

(a)

(b)

(c)
Figure 8: Logistic regression plots for interval data where the data has been intervalised in some biased way. In all the plots the blue bounds represent the imprecise logistic regression trained on the interval data, the red line represents the logistic regression trained by taking the midpoints of the interval and the black line is the logistic regression model trained on the base data as in Figure 1
6 Interval Uncertainty in Predictor Variables and Outcome Status
In the case where there is uncertainty in both the independent variables and the outcome status within a dataset, the analysis uses a combination of the methods described in Sections 4 and 5. The analysis should first find the configurations of points that correspond to the leftmost, rightmost, steepest and shallowest functions for all m features that have interval values, as described in Sections 5. These configurations can then be used with the q uncertain classifications as described in Section 4 This combination of methods leads to 3 × 2m+q logistic regression models that may be needed to find the bounds of the set of possible models.
6.1 Burn Surviability Example
Osler et al. (2010) use a logistic regression model to predict the probability of death for a patient after a burn injury. The model that they use is based upon a subset of data from the American Burn Association's National Burn Database1. The dataset has a mix of discrete (gender, race, flame involved in injury, inhalation injury) and continuous variables (age, percentage burn surface area) that can be used to model the probability
1http://ameriburn.org/research/burn-dataset/
14

that a person dies (outcome 1) after suffering a burn injury. Osler et al. exclude some patients from the dataset before training their model. They remove patients if their age or `presence of inhalation injury' wasn't recorded. Additionally, as patients older than 89 years were assigned to a single age category in the original dataset, they gave these patients a random age between 90 and 100 years.
Osler et al. did not need to exclude these patients merely because of epistemic uncertainty about the values. The proposed approach can be used with the original data. For instance, patients for which the outcome was unknown could have been included within their analysis as described in Section 4. Similarly, patients for which inhalation injury or age was unknown could have been included with the method described in Section 5. Patients with unknown inhalation injury could have been included as the dunno [0, 1]. For patients whose age was completely unknown then it could have been replaced by an interval between the minimum and maximum age, whereas if there was uncertainty because they were over 90 years old then they could be intervalised as [90, 100].
There are also other interval uncertainties that may be present within the dataset. It is unlikely to be the case that all the people used within the study fit neatly into the discrete variables as given. For instance the variable race is valued at 0 for "non-whites" and 1 for "whites". However, it goes without saying that the great diversity of humanity does not simply fall into such overly simplified categories, there are likely to be many people who could not be given a value of 0 or 1 and should instead have a [0, 1] value. The same is true for gender, not everyone can simply be defined as male or female. Also there is almost certainly some measurement uncertainty associated in calculating the surface area of the burn that may also be best expressed as intervals. For simplicity these uncertainties have not been addressed below.
For use in this analysis, the subsample of the dataset used by Osler et al. that was made available by Hosmer Jr et al. (2013, p. 27) has been used. This version of the dataset includes 1000 patients from the 40,000 within in the full study and has a much higher prevalence of death than the original dataset. Because access to the original data is prohibitively expensive, the values in this dataset have been reintervalised in order to replicate some of the removed uncertainty to create a hypothetical dataset for the purpose of this exposition. As there are no individuals older than 90 within the dataset, that particular intervalisation has not been possible, so all patients who were older than 80 have had their ages intervalised as [80,90]. Similarly, for 20 patients the censored inhalation injury has been restored to dunno interval. Ten patients, who had been dropped because their outcome status was unknown, have been restored with status represented as [0,1].
There are two possible routes in which an analyst could proceed when faced with such a dataset. They could follow the original methodology of Osler et al. and randomly assign patients with interval ages a precise value and then discard all other patients for which there is some uncertainty. Doing this gives us a logistic regression model with HL = 7.959, p = 0.437 demonstrating that such a model does have good fit. Alternatively, the analyst could include the uncertainty within the model by creating an imprecise logistic regression model as described above. Doing so gives a model with HL = [2.476, 16.580], p = [0.035, 0.963]. Such a p-value raises questions about whether or not the Hosmer-Lemeshow null hypothesis should be rejected because the interval straddles the 0.05 decision threshold. This implies that within the bounds there are models that do not fit the data. However, the upper bound of HL implies that there exist models that fit the data excellently.
When it comes to the discriminatory performance of the two analyses we can again turn to visualisations, as shown in Figure 9. From these plots there are a few notable things. Firstly, looking at Figure 9a we can see that the vast majority of patients who were given a low probability of death () did indeed survive and patients who were given a high probability of death did sadly die.
Before considering the ROC of the model is is pertinent to consider how a model is likely to be used and how uncertainty about the predicted probability of death impacts the classification. One method of dealing with this uncertainty that arises in Sections 4.1 and 5.1 is simply not making a prediction when the interval for  straddles C. This method may not be appropriate in this example. What should happen with a dunno prediction should depend on what the result of deciding a patient has a high risk of death means clinically. If the model was being used to triage patients that need to go to a major trauma centre because the probability of death is considered high, then­out of an abundance of caution­one might prefer that, if any part of the interval probability was greater than some threshold, the patient should be considered high risk. This is equivalent of taking the probabilities from the upper bound of the range,

1, if   C

high risk =

(15)

0, otherwise.

However, if patients who are considered high risk then undergo some life-altering treatment that is perhaps

15

only preferable to death, then under the foundational medical aphorism of "first do no harm", it may be preferable to consider a patient high risk only if the whole interval is greater than the decision threshold, this is equivalent of taking the probabilities from the lower bound of the range,

1, if   C

high risk =

(16)

0, otherwise.

(a) Scatter plots of probability vs outcome for the model where uncertain values have been excluded (red) and the model including the uncertain values (blue). The two outcomes have been separated into different plots for clarity.

(b) Receiver operating characteristic curves for the burn example.

Figure 9: Plots to show the discriminatory performance of the various logistic regression models for the burn survivability example

We can plot ROC curves for the ignored-uncertainty model and the models that take the uncertainty into account for both examples above as well as the case where predictions are not made when there is uncertainty as shown in Figure 9b. It is clearly the case that all these curves represent models with excellent discriminatory performance. Something which can be seen when looking at the AUC for each of the plots: for the ignored-uncertainty model we get AU C = 0.966, for the lower bound we get AU C = 0.965, for the upper bound we get AU C = 0.967 and for the generic imprecise model we get AU C = 0.975.

7 Discussion
Many uncertainties are naturally expressed as intervals and it is better to compute with what we know than to make assumptions than may need to be revised later. In the case of logistic regression, when faced with interval uncertainties it is often the case that samples are dropped from analyses­making the assumption that they are missing at random­or they are reduced down to a single value. In this paper we have shown that this need not be the case. Interval uncertainties can be included within a logistic regression model by considering the set of possible regression models as an imprecise structure. This even includes situations where there is uncertainty about the outcome status, it is not reasonable to throw away data when the status is unknown if the reason the data has gone missing is dependent on the value or status of the missing samples.
It is unlikely to be the case that all the predictor values used within the studies are often associated with non-negligible interval uncertainties. This uncertainty should not simply be thrown away as there is For instance the variable race is valued at 0 for "non-whites" and 1 for "whites". However, it goes without saying that the great diversity of humanity does not simply fall into such overly simplified categories, there are likely to be many people who could not be given a value of 0 or 1 and should instead have a [0, 1] value. The same is true for gender, not everyone can simply be defined as male or female.
When using an imprecise model, each new sample gets an interval probability of belonging to one of the binary classifications. When it comes to making classifications from the model there is likely to be samples

16

for which a definitive prediction cannot be made. If one is happy to accept a don't know result, then the deterministic performance can be improved for the samples for which a prediction could be made. It may seem counterproductive or unhelpful for a model to return a don't know result, however this can be desirable behaviour. Saying "I don't know" is a perfectly valid thing to do in situations where the uncertainty is large enough that a different decision could have been reached. Uncertainty in the output can allow for decisions made by algorithms to be more humane by requiring further interrogation in order to make a classification. Alternatively, depending on the use case other ways of making decisions based on uncertain predictions could be made.
To conclude, we have shown that it is possible to include uncertainty in both outcome status and predictor variables within logistic regression analysis by considering the set of possible models as an imprecise structure. Such a method has the advantage of clearly expressing the epistemic uncertainties within the dataset that are removed by traditional methods.
This paper used a crude algorithm to compute the imprecise logistic regression. As this approach is NP-hard, future work in this area should be invested to find improved algorithms to make them practical for datasets at scale.
Acknowledgements
This work has been funded through EPSRC programme grant "Digital twins for improved dynamic design", EP/R006768/1.
Code Availibility
The code that has been used within this analysis is availible at https://github.com/ngg1995/LR-python/.
References
Bagley, S. C., White, H. and Golomb, B. A. (2001) Logistic regression in the medical literature : Standards for use and reporting , with particular attention to one medical domain. Journal of Clinical Epidemiology, 54, 979­985.
Bertrand, P. (2000) Descriptive Statistics for Symbolic Data. In Analysis of Symbolic Data: Exploratory Methods for Extracting Statistical Information from Complex Data (eds. H.-H. Bock and E. Diday), 106­ 124. Springer Berlin Heidelberg.
Billard, L. and Diday, E. (2000) Regression Analysis for Interval-Valued Data. In Data Analysis, Classification, and Related Methods (eds. H. A. L. Kiers, J.-P. Rasson, P. J. F. Groenen and M. Schader), 369­374. Springer Berlin Heidelberg.
Bock, H. and Diday, E. (2001) Book Review: Analysis of Symbolic Data: Exploratory Methods for Extracting Statistical Information from Complex Data, edited by H.-H. Bock and E. Diday. Journal of Classification, 18, 291­294.
De Souza, R. M. C. R., Jos, F., Cysneiros, A., Queiroz, D. C. F. and Fagundes, R. A. D. A. (2008) A Multi-Class Logistic Regression Model for Interval Data. In IEEE International Conference on Systems, Man and Cybernetics, 1253­1258. Singapore,Singapore.
De Souza, R. M. C. R., Queiroz, D. C. F. and Jose, F. (2011) Logistic regression-based pattern classifiers for symbolic interval data. Pattern Analysis and Applications, 14, 273­282.
Escobar, L. A. and Meeker Jr, W. Q. (1992) Assessing Influence in Regression Analysis with Censored Data. Biometrics, 48, 507­528.
Fagundes, R. A. A., Souza, R. M. C. R. D. and Jose, F. (2013) Robust regression with application to symbolic interval data. Engineering Applications of Artificial Intelligence, 26, 564­573.
Ferson, S., Kreinovich, V., Hajagos, J., Oberkampf, W. and Ginzburg, L. (2007) Experimental Uncertainty Estimation and Statistics for Data Having Interval Uncertainty. Tech. rep., Sandia National Laboratories, Albuquerque, NM, USA.
17

Gioia, F., Lauro, C. N. and Federico, N. (2005) Basic statistical methods for interval data. Statistica Applicata, 17, 1­29.
Hosmer Jr, D. W., Lameshow, S. and Sturdivant, R. X. (2013) Applied Logistic Regression. Hoboken, NJ, USA: John Wiley & Sons, Ltd, 3rd edn.
Hosmer Jr, D. W. and Lemeshow, S. (1980) Goodness of fit tests for the multiple logistic regression model. Communications in Statistics - Theory and Methods, 9, 37­41.
Keynes, J. (1921) A Treatise on Probability. London, UK: Macmillian and Co.
Kleinbaum, D. G. and Klein, M. (2010) Logistic Regression: A Self-Learning Text. New York, NY USA: Springer, 3rd edn.
Kracman, K. (1996) The effect of school-based arts instruction on attendance at museums and the performing arts. Poetics, 24, 203­218.
Lambert, W. and Wheeler, M. (2005) Objective Lightning Probability Forecasting for Kennedy Space Center and Cape Canaveral Air Force Station. Tech. rep., National Air and Space Administration, Hannover, MD, USA.
Lemeshow, S. and Hosmer, David W., J. (1982) A review of goodness of fit statistics for use in the development of logistic regression models 1. American Journal of Epidemiology, 115.
Li, Y., Wang, L. and Li, F. (2021) A data-driven prediction approach for sports team performance and its application to National Basketball Association R. Omega, 98, 102123­102123.
Manski, C. (2003) Partial Identification of Probability Distributions. New York, NY USA: Springer.
Menard, S. (2010) Logistic Regression: From Introductory to Advanced Concepts and Applications. Thousand Oaks, California: SAGE Publications, Inc.
Moore, R. E., Kearfott, R. B. and Cloud, M. J. (2009) Introduction to Interval Analysis, vol. 110. Philadelphia, USA: Society for Industrial and Applied Mathematics.
Myung, I. J. (2003) Tutorial on maximum likelihood estimation. Journal of Mathematical Psychology, 47, 90­100.
Neary, W. D., Heather, B. P. and Earnshaw, J. J. (2003) The Physiological and Operative Severity Score for the enUmeration of Mortality and morbidity (POSSUM). British Journal of Surgery, 30, 157­165.
Nguyen, H. T., Kreinovich, V., Wu, B. and Xiang, G. (2012) Computing Statistics under Interval and Fuzzy Uncertainty. Heidelberg, Germany: Springer.
Ohlmacher, G. C. and Davis, J. C. (2003) Using multiple logistic regression and GIS technology to predict landslide hazard in northeast Kansas, USA. Engineering Geology, 69, 331­343.
Osler, T., Glance, L. G. and Hosmer, D. W. (2010) Simplified Estimates of the Probability of Death After Burn Injuries : Extending and Updating the Baux Score. Journal of Trauma Injury, Infection and Critical Care, 68.
Palei, S. K. and Das, S. K. (2009) Logistic regression model for prediction of roof fall risks in bord and pillar workings in coal mines : An approach. Safety Science, 47, 88­96.
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M. and Duchesnay, E. (2011) Scikit-learn: Machine Learning in {P}ython. Journal of Machine Learning Research, 12, 2825­2830.
Press, S. J. and Wilson, S. (1978) Choosing Between Logistic Regression and Discriminant Analysis. Journal of the American Statistical Association, 73, 699­705.
Royston, P. and Altman, D. G. (2010) Visualizing and assessing discrimination in the logistic regression model. Statistics in Medicine, 29.
18

Utkin, L. V. and Coolen, F. P. A. (2011) Interval-valued regression and classification models in the framework of machine learning. 11.
Walley, P. (1991) Statistical Reasoning with Imprecise Probabilities. London, UK: Chapman and Hall. Wiencierz, A. (2013) Regression analysis with imprecise data. Ph.D. thesis, Ludwig-Maximilians-
Universit\ at M\ unchen.
19

Appendix A Hosmer-Lemeshow Tests with Bounded Logistic Regression

Due to the problems of repeated variables and dependencies between different intervals there are numerous nuances that need to be taken into account when calculating the Homsmer-Lemeshow statistic for an imprecise logistic regression model. These occur because we will get an interval number of expected cases and
expected noncases, E1,i = E1,i, E1,i and E0,i = E0,i, E0,i . The textbook equation for the calculation is

HL = g (O1,i - E1,i)2 + g (O0,i - E0,i)2

i=1

E1,i

i=1

E0,i

(A.2)

If we consider the term

(O1,i - E1,i)2 E1,i

(A.3)

then it is important to realised that naively computing this statistic may lead to overinflation of the resulting interval. Under standard interval arithmetic

where

(O1,i - E1,i)2 = [min(a, b, c, d), max(a, b, c, d)] E1,i

(A.4)

2
O1,i - E1,i a=
E1,i
b = O1,i - E1,i 2 E1,i
2
O1,i - E1,i c=
E1,i
d = O1,i - E1,i 2 E1,i

(A.5a) (A.5b) (A.5c) (A.5d)

However b and c are not valid calculations as if E1,i is in the denominator then E1,i cannot be in the numerator and vice versa. Hence



2



(O1,i - E1,i)2 =  O1,i - E1,i

,

O1,i - E1,i 2 

E1,i



E1,i

E1,i



(A.6)

This will only hold however if 0  (O1,i - E1,i), as in this case

2
O1,i - E1,i = 0, max

O1,i - E1,i

2
,

O1,i - E1,i

2

(A.7)

Hence



(O1,i - E1,i)2

   
=

0, max

( ) (O1,i-E1,i)2 , E1,i

O1,i-E1,i 2 E1,i

, if O1,i - E1,i

0

E1,i

 ( ) ( ) O1,i-E1,i 2  , E1,i

O1,i-E1,i 2 E1,i

otherwise

(A.8)

and similarly for the noncase side of A.2. However, as E1,i is oppositely dependant to E0,i, meaning that if E1,i = E1,i then E0,i = E0,i hence the full calculation needed to calculate the Homsmer-Lemeshow statistic

20

is



g

  

0, max



( ) ( ) ( ) ( ) O1,i-E1,i 2 - , - E1,i

O0,i-E0,i 2 E0,i

O1,i-E1,i 2 E1,i

O0,i-E0,i 2 E0,i

HL =

 ( ) - ( ) , ( ) - ( ) i=1

O1,i-E1,i 2 E1,i

O0,i-E0,i 2 E0,i

O1,i-E1,i 2 E1,i

O0,i-E0,i 2 E0,i

, if (O1,i - E1,i) 0 otherwise

(A.9)

This resulting HL statistic interval may still be too wide as there is still dependence between E1,1,E1,2,E1,3, etc as E1,1 + E1,2 + · · · + E1,g = N where N is the total number of samples. Reducing this dependence cannot be done analytically.

21

