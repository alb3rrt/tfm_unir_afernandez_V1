
# MINIMALIST: Mutual INformatIon Maximization for Amortized Likelihood Inference from Sampled Trajectories

[arXiv](https://arxiv.org/abs/2106.01808), [PDF](https://arxiv.org/pdf/2106.01808.pdf)

## Authors

- Giulio Isacchini
- Natanael Spisak
- Armita Nourmohammad
- Thierry Mora
- Aleksandra M. Walczak

## Abstract

Simulation-based inference enables learning the parameters of a model even when its likelihood cannot be computed in practice. One class of methods uses data simulated with different parameters to infer an amortized estimator for the likelihood-to-evidence ratio, or equivalently the posterior function. We show that this approach can be formulated in terms of mutual information maximization between model parameters and simulated data. We use this equivalence to reinterpret existing approaches for amortized inference, and propose two new methods that rely on lower bounds of the mutual information. We apply our framework to the inference of parameters of stochastic processes and chaotic dynamical systems from sampled trajectories, using artificial neural networks for posterior prediction. Our approach provides a unified framework that leverages the power of mutual information estimators for inference.

## Comments



## Source Code

Official Code

- [https://github.com/statbiophys/MINIMALIST](https://github.com/statbiophys/MINIMALIST)

Community Code

- [https://paperswithcode.com/paper/minimalist-mutual-information-maximization](https://paperswithcode.com/paper/minimalist-mutual-information-maximization)

## Bibtex

```tex
@misc{isacchini2021minimalist,
      title={MINIMALIST: Mutual INformatIon Maximization for Amortized Likelihood Inference from Sampled Trajectories}, 
      author={Giulio Isacchini and Natanael Spisak and Armita Nourmohammad and Thierry Mora and Aleksandra M. Walczak},
      year={2021},
      eprint={2106.01808},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```

## Notes

Type your reading notes here...

