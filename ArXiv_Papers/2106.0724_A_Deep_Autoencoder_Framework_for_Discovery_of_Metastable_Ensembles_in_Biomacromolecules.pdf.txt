arXiv:2106.00724v1 [physics.chem-ph] 1 Jun 2021

A Deep Autoencoder Framework for Discovery of Metastable Ensembles in
Biomacromolecules
Satyabrata Bandyopadhyay1 and Jagannath Mondal1, a) Tata Institute of Fundamental Research, Center for Interdisciplinary sciences, Hyderabad 500046, India
(Dated: 3 June 2021)
Mini-proteins and peptides manifest dynamic conformational fluctuation and involve mutual interconversion among metastable states. A robust mapping of the conformational landscape underlying mini-proteins and peptides often requires low-dimensional projection of the conformational ensemble along optimized collective variables. However, the traditional choice for the collective variable (CV) is often limited by user-intuition and prior knowledge about the system, which lacks a rigorous assessment of their optimality over other candidate CVs. To address this issue, we propose a generic approach in which we first choose the possible combinations of inter-residue C-distances within a given macromolecule as a set of input CVs. Subsequently we derive a non-linear combination of latent-space embedded collective variables via auto-encoding the unbiased MD simulation trajectories within the framework of feed-forward neural network. We demonstrate the ability of the derived latent space variables in elucidating the conformational landscape in three hierarchically complex systems. When the conformational dynamics is resolved along the latent space CVs, it identifies key metastable states of a bead-in-a-spring polymer. The combination of the adopted dimensionally reduction technique with a Markov state model, built on the derived latent space, efficiently projects the free energy landscape of GB1 -hairpin, revealing multiple spatially well-resolved and kinetically well-separated metastable conformations. A quantitative comparison based on variational approach to Markov Process of the auto encoder-derived latent-space CVs with the ones obtained from independent component analysis (PCA or TICA) confirms the optimality of the former. Finally, as a practical application, we demonstrate that the auto-encoder derived CVs successfully predict the reinforced folding of Trp-cage mini-protein in an aqueous osmolyte solution.

I. INTRODUCTION
Bio-macromolecules are intrinsically complex and are often associated with rugged thermodynamic and kinetic conformational landscapes1,2. This is more prominent in case of small proteins and peptides due to their large conformational fluctuations, which give rise to dynamically interconverting metastable ensemble of conformations. However, the large number of degrees of freedom associated with the biomolecules eludes spatial and temporal dissection of underlying conformational landscape. A popular approach to circumvent this issue is to reduce the dimensionality of the system. This approach has motivated derivation of appropriate collective variables (CV) or feature-space for the system of interest. Generally these CVs are often used to project the conformational ensembles of biomacromolecules along these subs-spaces. The quality of chosen CVs is crucial for suitable projection and identification of key macrostates. Hence a rigorous assessment and optimization of CVs would play very important roles in elucidating the complicated biomolecular dynamics.
The process of hunting the right CVs for distinguishing the ensembles of biomacromolecular conformations is a non-trivial task. Traditionally, the choice has been mostly driven as well as limited by the user's input and personal experience on the system of interest. This process often forces one either to choose certain pre-decided

CVs (mostly single or a pair of CVs) or requires arbitrary attempts via trial or error. The projection of conformational motions along those user-defined CVs does not guarantee exhaustive identification of all metastable conformations. Moreover, this approach most often runs into the risk of missing out on important conformational basin in those projected basins. Significantly, the process lacks a rigorous assessment of the chosen CVs for their optimality. This is particularly relevant for enhanced sampling techniques namely umbrella sampling3 or, metadynamics4,5 simulation which accelerate the exploration of phase space via biasing certain CVs, in which inappropriate choice of CVs can result in misleading free energetics.

(A) 32 Bead Polymer

(B) GB1 (PDB: 1GB1)

(C) TrpCage (PDB: 1L2Y)

FIG. 1: Systems used in the current work.

a)Electronic mail: jmondal@tifrh.res.in, +914020203091

A continued thrust over last decade has been focussed

2

on the invention of new approaches for assessment and optimization of the candidate CVs for a biomolecular process. This has resulted in emergent directions involving maximum caliber based approach like Spectral gap optimization of order parameter6. Independent component analysis (ICA) based approaches have also received prominence for their ability to efficiently combine multiple CVs in a linear fashion. In particular, principal component analysis (PCA)7 has become a regular approach for projecting the conformational space along the direction of maximum variance. Lately, time-structured independent component analysis (TICA)8,9 is gaining traction for its efficiency in projecting the conformational landscape along kinetically slow directions. The implementation of TICA has seen successful application in identifying metastable states and quantitatively assessing the contribution of constituent CVs in the resultant CVs. TICA has now been well-integrated as a key method of choice as a dimension-reduction technique for building Markov state Models for kinetics.
However, the inherently linear nature of ICA-based CVs poses a key restriction in CV optimization process. The realization of limitation in linearly combined CVs has paved the way for more general machine learning based approaches which are inherently nonlinear in nature. Machine learning provides a systematic way-out to discover data-driven features of CVs in Molecular Dynamics (MD) simulations. Conceptually, these approaches posit that the MD in the largedimensional (3N-dimensional) space of the Cartesian coordinates of macromolecule(s) are effectively encoded in a low-dimensional `intrinsic manifold' containing the slow dynamics to which the remaining fast degrees of freedom are filtered out. The validity of this assumption has been demonstrated in multiple investigations and in all cases, the approach has aimed at obtaining a small number of collective modes from a large set of coupled degrees of freedoms. In this regard, developments including diffusion maps10 and sketch maps11 have demonstrated great success in parameterising nonlinear intrinsic manifolds of complex macromolecules by discovering nonlinear CVs for capturing conformational changes.
In the current work, we harness the efficiency of a popular deep-learning algorithm, namely auto associative encoder, for an efficient derivation of optimized CVs for a set of conformationally dynamic macromolecules. The recent times have seen successful implementation of auto encoders and its variants for CV discovery and predicting the conformational free energetics and dynamics. The purpose of dimensional reduction followed by feature extraction has become an active area of research12. The reduced dimensions obtained by artificial neural network holds promises of becoming powerful collective variables hence would fulfil the purpose of collective variable discovery13­19. Wang and Ferguson20 has applied machine learning to generate the folding funnel using delay embeddings on time series data and manifold learning. Tiwary et al.21 have applied the machine learning tech-

niques to analyze and enhance the molecular dynamics simulations.
On a similar spirit, this article adopts a feed-forward neural network based framework. A key advantage of this technique is that one can choose extensively large set of CVs as input and can reduce this into a complex lowdimensional embedding in the `latent space', provided that the input is autoencoded in the output. Due to its ability to handle large set of data as an input, the choice of input CVs does not have any restriction in its number. Accordingly, in the current work, we go beyond the conventional and user-intuitive choice of CVs (Rg, RMSD, number of contacts etc) for biomolecules. In stead, we use a large set of inter-residue distances as the input CVs and auto-encode the choice within the framework of feedforward neural networks. The approach gives rise to a minimal number of latent-space CVs in which the original input CVs are compressed. We first show that the latent space CVs, resulting from this approach, can efficiently identify the key intermediates in a collapse dynamics of bead-in-a-spring polymer in solvent. Second, the projection of MD simulation trajectories of GB1 -haripin along the latent space leads to identification of distinct metastable states. A quantitative comparison, based on variational approach to Markov processes (VAMP), confirms the superiority of derived latent space CVs over PCA and TICA derived CVs. A Markov state model developed on the latent space provides robust spatial and temporal resolution of conformational landscape of GB1 -hairpin. Finally, the technique is successfully assessed for its ability to capture the osmolyte-induced folding of Trp-cage mini-protein.
II. MATERIAL AND METHODS
Description of Systems: Three systems of increasing hierarchical complexity are used in the work: 1) A model bead-ina-spring polymer, 2) 16-residue GB1 -hairpin Ace41GEWTYDDATKTFTVTE56-NMe, a polypeptide corresponding to C-terminal domain of GB1 protein. 3) Trp-cage, a 20-residue mini-protein (see Figure 1). A large set of all-atom Molecular Dynamics simulation trajectories for each of the systems act as the input source. The simulation trajectories were previously generated by our group in multiple past works22­24. For 32-bead-ina-spring charge-neutral polymer (with alternatively patterned positive and negative charges on the beads), 200 MD simulation trajectories, each 30 ns long, modelled in aqueous media were used as inputs. The model and simulation details of the polymer system have been reported in a previous investigation from our research group22 . Likewise, For GB1 -hairpin, 200 previously performed MD trajectories23 , each 100 ns long, served as the input. Finally 200 MD trajectories of conformational fluctuation of Trpcage miniprotein, each 100 ns long in neat water as well as in 4 M Trimethyl amine N-oxide (TMAO) act

3

as the resource for CV discovery in this system. The method and model details used for generating all MD trajectories of Trp-cage have been reported in a recent article by Mukherjee and Mondal24.
Methods: The current work focuses on implementing the framework of autoencoder based artificial neural network in reducing the large number of dimensions of a set of biomacromolecules (see Figure 1) into a low number of optimal CVs. In stead of limiting ourselves to traditionally preconceived CVs for protein folding (such as Rg,RMSD,Number of contacts etc), here we opted for more generic features as input CVs for our neuralnetwork auto-encoders. More specifically, the large combinatorial set of inter-residue distances for each systems of interest served as the input CVs of the autoencoder applied in the current article (See Figure 2A for illustration of the input CVs). Autoencoder is a self-supervised machine learning technique where the neural network would strive to generate the final output which is same as the supplied input. Figure 2B schematically depicts the architecture of the autoencoder employed in the current investigation. By construction, these autoencoders would have an input layer, an output layer and one or multiple hidden layers in between the input and output layers with a bottleneck in the middle. The layer structure is usually symmetric, with the first half including the bottleneck referred as the encoder, while the second half is called a decoder. The input layer and output layer have same number of nodes while the intermediate hidden layers in encoder and decoder part often have fewer number of nodes, thereby forcing the network to reduce the dimensions and consequently to learn a lower-dimensional, compressed representation in the latent space from the present data-set with a minimal regression error. For each pair of nodes there is an associated weight (wij). The linear combination of the inputs with appropriate weights after a bias addition and followed by some activation function operation will result in the value of the output on next node. This activation function can be defined by:
xli+1 = f (Nj=1wiljxlj + bli+1) (1)
,where xli+1 is i-th node at (l +1)-th layer, xlj is j-th node at l-th layer, N is the number of nodes in l-th layer, wilj is the weight corresponding to the (i, j)-th pairs of nodes at l-th layer, bli+1 is the bias at the i-th node at (l + 1)-th layer.
The C-C inter-residue distances have been used as input and output data in this work for the feedforward densely connected neural network. The specific number of dimensions used in each layer has been mentioned in respective example of biomacromolecules in Results section. 0.1 fraction of the data has been taken as validation data set while the rest was kept as training data set. We have used symmetrical dense neural

network for our work. Activation functions are crucial in order to introduce the non-linearity in the network, hence facilitating the feature of non-linear fitting into the model on the data-set. In the current work, the activation functions were used as tanh and linear alternatively from input to output layers. Here the weights and biases as described above are the parameters which have to be optimised in order to minimise a loss function. In our work the loss function or regression error is used as mean squared error(MSE) and it is defined as: M SE = ni=1(yitrue - yipredicted)2/n ,where n being the total number of samples. For 32-bead polymer, gb-1 and Trp-cage systems 6000200 ; 2000200 and 2000200 samples were used respectively. Our model has been implemented using tensorflow25 backend with Keras26 Python Library for Neural Networks. The optimizer used here is Adam27 with learning rate  = 0.001 and other parameters used were 1 = 0.9,2 = 0.999, = 1e - 07 with batch size as 100 to train our model. The weights were initialized using glorot uniform method28 and biases were initialised as zeros. The latent space is considered our desired CVs, as obtained from auto-encoder. The structure and the number of the layers in encoder and decoder parts of the neural networks have been described in Results section in context to each of the systems investigated in the work.
In the current work, we have compared the autoencoder based dimensional reduction approaches with two popular linear dimension reduction approaches, namely PCA and TICA. In both cases, the same set of combinatorial inter-residue distances served as input feature space. Below, for the sake of completeness, we provide a brief discussion of PCA and TICA.
PCA: Principal Component Analysis(PCA) is a widely used7 feature extraction tool leading to dimensional reduction technique. Here the goal is to derive those dimensions which will maximize the variance along it by linearly combining the input feature vectors. This procedure of maximizing the variance is equivalent to obtain the eigen components of the covariance matrix from the input data set. Eigen vectors obtained after diagonalization of the covariance matrix leads to the coefficients of that linear combination. The corresponding eigen values will depict the explained variance along that projected mode. Mathematically, PCA would maximize the variance from a given input data-set:
V ar(x) = Ni=1(xi - x¯)2 N
,where Var(x) is the variance along x-dimension, xi is the i-th value of a time-series data. Index i describes the time-series index and varies from 1 to N as there are N time points present here for example and x¯ is the average value of the x-dimension data, x¯ = Ni=1xi/N . PCA then maximizes V ar(x). If there are m such input dimensions, PCA would determine m linearly combined

(A)

d11

d12

d13

d21

d22

d31 d23

d32

d14 d15

(C)
(1) 32 Bead Polymer

4

(B)

d1

d2

d3

d1

d2

h1

h1

d3

h2

h2

H1

(2) Gb1 beta-hairpin

dn-2 dn-1

H2

hm-1 hm

hm-1 hm

dn-2 dn-1

dn

dn

IInnpputuLtayer Hidden

Bottleneck Hidden Output

Hidden Layer

Output Layer

(3) TrpCage

FIG. 2: (A)Input CVs: A set of inter-residue C-distances (B) Schematics of auto-encoder scheme employed in the work. The set of inter-residue C-distances described in figure A is used here as the input and the dimensions are iteratively reduced with a focus on minimising the loss function. (C) The profile of loss function as obtained on course to an optimized auto-encoding of input CVs for three systems investigated here.

projected variables. The total sum of variances would be distributed among them in a way such that the first principal component(PC1) will have maximum variance. The retained variance again would be distributed in this way, making the second principal component (PC2) to have next maximum variance from the rest of the total variance and so on.
TICA: The Time-lagged Independent Component Analysis (TICA) is another linear dimension reduction technique which has been applied successfully for bio-molecular simulation8,9. Originally used in signal processing29,TICA is mostly similar to the previously explained PCA technique. The main difference is that instead of maximizing the variance, TICA will maximize a time-lagged autocorrelation function. TICA transforms and projects the input data along those dimensions for which the autocorrelation function is the maximum. Mathematically speaking , TICA will maximize the time-lagged autocorrelation function as depicted below:

C orr(x)

=

[iN=-1 (xi

-

x¯)(xi+ x2

- x¯)]/(N

- )

,where Corr(x) is the time-lagged kinetic variance along

x-dimension, xi is the i-th value and xi+ is the (i +  )-th

value of a time-series data,  is the lag interval. Index

i varies from 1 to N -  as there are N -  time-series

data points after considering a lag-interval of  . x¯ is the

average value of the x-dimension data, x¯ = Ni=1xi/N . Again x is the standard deviation along x defined by:

x =

. N i=1 (xi -x¯)2
N

Here TICA would maximise this time-lagged correlation

function Corr(x). If the data-set consists of r such input

dimensions, then TICA will find out r linear combina-

tions among them. The total sum of kinetic-variances

will be distributed in such a way that the TIC-1 com-

ponent will get maximum kinetic-variance and conse-

quently will become kinetically most sluggish. The re-

tained kinetic-variance again will be distributed in this

way so the TIC-2 will become next slowest component

and so on.

5

Finally, we use the variational approach for Markov processes (VAMP-2) score30,31 to compare the optimality of the auto-encoder-derived latent space CVs relative to PCA and TICA.

III. RESULTS AND DISCUSSION A. 32-Bead Polymer:

VAMP-2 score: VAMP is based on Canonical Correlation Analysis(CCA)32 method for time-series data and also known as Time-lagged Canonical Correlation Analysis(TCCA). Here we will look for the cross correlation function between a pair of of variables, say for example (x,y). CCA will maximize the cross-corelation function for this pair. Analytically,

C 1.6
1.4

Time Fluctuation of Rg and chi-dimension for 32-Bead Polymer Rg

Order Parameters

1.2

1.0

D

E

0.8 0.6

A

0.4
B 0.2

0.0

0

5

(A)

(B)

10 tim1e5(ns) 20

25

30

(C)

(D)

Bead 1-13: Blue Bead 14-21: Green Bead 22-32: Red
(E)

Corr(x, y) = [Ni=1(xi - x¯)(yi - y¯)]/N xy
,where Corr(x, y) is the cross correlation function between (x,y). xi is the i-th value for x-variable and yi is the i-th value of the y-variable. x¯ and y¯ are the average values of the x and y respectively. Again x and y are the standard deviations along x and y respectively. Here CCA will maximize this cross-correlation function Corr(x, y). Now, for time-lagged CCA, we will typically divide our data-set into two halves. For first half, we will have our data as x and index i goes from 1 to (N -  ). For the last half, we will have our data as y and here index i goes from ( + 1) to N . So, eventually it would involve a time-lag interval of  , hence the name as time-lagged CCA(TCCA). The VAMP-2 score will be the sum of the diagonal elements of that time-lagged cross-correlation matrix(after diagonalization) raised on a power of 2(squared). The higher the value of this score implies the better it is conserving the slowest modes and hence giving rise to optimality of the collective variable.
Apart from the regular projection of the trajectories along the chosen CVs, in some cases, the MD simulation trajectories were discretised and clustered along the derived feature spaces and a Markov state model (MSM)33,34 is built to analyze the free energetics and kinetics of metastable conformational ensembles. We have described the MSM protocols in the Results section.

FIG. 3: The proposed Autoencoder Scheme captures time-fluctuation of the different conformations for 32-bead polymer system . A,B,C,D,E are the diffterent conformations of the polymer.
We first assess the ability of the proposed input CVs and the autoencoder-derived latent-space dimension in capturing the essential conformational dynamics of a prototypical model polymer ( see Figure 1A). This 32bead-in-a-string polymer and its variants have remained an attractive system of interest in multiple precedent applications.22,35 Despite its apparent simplicity, this polymer is known for displaying interesting dynamical conformational transitions. The polymer of interest in this work has 16 alternatively positive and negative charged beads, rendering the complete system chargeneutral. The presence of charges allow for increased conformational fluctuation of this polymer in aqueous media. The aggregated 6 microsecond of MD simulation trajectories (200 independent trajectories, each 30 ns long) serve as the source. In any case, even this system with 32C2 = 496 number of pair-wise distance brings out a large dimensionality, which is well beyond what is trivially graspable and is still fairly simple model. To apply our method for broader scope of application and in order to use this method in a more tractable way, we started with 28 number of pair-wise distances as input features or CVs, instead of starting with all the 496 pair-wise distances for the autoencoder. In particular, we have chosen the beads starting from the first bead in an arithmetic progression with an interval of 4, hence total number of effective beads we have obtained to be 7 among the 32 beads. So, we have got 7C2 = 56/2 = 28 dimensional pair-wise distances. We find that an autoencoder of 5 layers having nodes 28,12,4 for the encoder part, with a latent space combination of 4 CVs gradually reduces the loss-function to a plateau (see Figure 2 C). The decoder used in our work had same architectures of layers as in encoder, except in reverse fashion.
In Figure 3, a representative MD trajectory of the 32-

6

bead polymer is projected on latent space CV of the model polymer, as derived by the autoencoder upon minimisation of loss function or the regression error. The time profile of the derived latent space CV of the model polymer (Figure 3) indicates multiple dynamical transitions. In particular, an overlay of the time-profile of complex latent space dimension with that of a traditional CV, namely, radius of gyration (Rg), suggests that the derived CV recapitulates the salient trend of conformational dynamics quite well. The time profile of latent space projection captures a series of conformational ensemble of the polymers, namely collapsed, extended, hairpin and partial extended states. The faithful reproduction of conformational landscape of this polymer by the autoencoder derived CVs and its similarity with a popular knowledgebased CV like Rg for polymer, indicates that the derived latent-space CV shows early promises of discovering new conformation in relatively complex biomacromolecules.

B. GB1 -hairpin:
The demonstrated ability of the frame-work in spatial separation of conformational landscape of model polymer prompted us to apply the protocol to explore the dynamical interplay of a small but complex polypeptide, namely 16-residue GB1 -hairpin. This particular polypeptide has been the subject of numerous experimental36,37 and computational38­41 investigations due to the diversity of metastable conformations it demonstrates. Our past investigation has also suggested that a single CV is not sufficient for capturing the underlying conformational complexity of this system. Rather an optimized combination of a set of curated CVs is a necessity.23,42

Free Energy/kBT

12
1

10

2

8

3 4

6

4

2

0

4

3

2 Hidden Di1mension 0

1

2

FIG. 4: One Dimensional Free Energy Distributions for Hidden data for GB1.

In this context, we wanted to investigate if an auto encoder frame-work with a large set of inter-residue distances as input features, can spatially and temporally resolve the metastable ensembles of GB1 -hairpin. Towards this end, we employed all pair-wise distances between C- atoms as input dimensions in the autoencoder, giving rise to 16C2 = 120 input dimensions for a 16-residue poly-peptide. We have invoked these

large number of input dimensions in the auto encoder and slowly quenched these to a very less number of hidden dimensions. For this purpose, 72, 36,12 number of nodes were used in the first, second and third hidden layers respectively. Finally 4 nodes were used in the fourth and most compressed hidden layer, constituting the latent space bottleneck in the encoder part. The data analysed was on the projected data along this few number of latent dimensions, hence satisfying the goal of extracting features from big-data sets via dimensional reduction. The autoencoder is symmetric around the bottleneck, the decoder part also adds same number of hidden layer as the encoder part in reverse order ( i.e. 12,36,72 number of hidden nodes), followed by 120 dimensional nodes as output.
The comparison of one-dimensional projection of free energy profiles along each of the four latent-space CVs ( Figure 4) suggested that combination of two CVs (1 and 2) will be sufficient for effective projection of MD trajectories. Accordingly, we project the free energy surface of GB1 along 1 and 2. Figure 5 A) depicts the twodimensional free energy surface (FES) along these two auto-encoded latent spaces. We find that the projection of FES along the chosen latent-space dimension spatially resolved multiple basins. Visual inspection of the conformational ensembles, extracted from each annotated basin in the FES, mutually separates out the diverse conformational ensembles of GB1 -hairpin. Specifically, the free energy decomposition recovered metastable conformations ranging from -sheets, partially folded helices to unfolded coils. A secondary structure analysis , based on DSSP algorithm43 of conformational ensembles (Figure 5 C) further ascertained that these are distinct conformations having little overlap in the features of their secondary structures. The secondary structures of each of the conformations remain unmixed in the free energy surface projected along the latent space.
The ability of these neural-network derived CVs in spatially resolving the FES encouraged us to optimally tessellate the metastable states of GB1 -hairpin along the projected dimension. Towards this end, we discretised all simulation trajectories of GB1 -hairpin using the two latent space CVs into 500 micro states via kmeans clustering44 and built a MSM. The implied time scale (ITS) underlying the MSM built in the reduced conformational sub-space was found to readily converge to a plateau within a short lag-time, representing a clear time-scale separation among six metastable macrostates (Figure 6A) . Additionally, as shown in Figure 6B) the six macrostate model also passed Chapman-Kolmogorov (CK) test seamlessly. These analysis indicated that the model based on the autoencoder-derived CVs is robust as far as attaining the Markovianity is concerned. Our Markov model has been built with 5 nano-second of lag-time. A PCCA45 based coarse-graining of 500 microstates into six macrostates tile them on distinct location of the FES.
These macro-states are mutually distinct on sec-

7

(A)
3
(C) 0

2 4
0 51

1

2

(B)
3

PCCA State Decomposition for GB-1

4

5

Population Table for Macro-states State-0 2.64 % State-1 16.54% State-2 18.53% State-3 10.81% State-4 29.06% State-5 22.40%

Secondary structure

16

15

14

13

12

11

10

9

8

7

6

5

4

3

2

1

Coil

01234567 18 19 111101121314252627282920212232435363738393031323345464748494041424344556575859505152535465667686960616263647576778797071727374858687889808182838495969798990919 129 139 14151617 018 019 01010101 0101 201 301 4151617181910111 2131421 521 621 721 821 921 02121 21 321 431 531 631 731 831 931 03131 231 31 41 541 641 741 841 941 04141 241 341 451 51 651 751 851 951 05151 251 351 461 561 61 761 861 961 06161 261 361 471 571 671 71 871 971 07171 271 371 481 581 681 781 81 981 08181 281 381 491 591 691 791 892 92 091929394050678901 Time (ps)

B-Bridge

Bend

Turn

3-Helix

Secondary structure

16

15

14

13

12

11

10

9

8

7

6

5

4

3

2

1

Coil

01234567 18 19 111101121314252627282920212232435363738393031323345464748494041424344556575859505152535465667686960616263647576778797071727374858687889808182838495969798990919 129 139 14151617 018 019 01010101 0101 201 301 4151617181910111 2131421 521 621 721 821 921 02121 21 321 431 531 631 731 831 931 03131 231 31 41 541 641 741 841 941 04141 241 341 451 51 651 751 851 951 05151 251 351 461 561 61 761 861 961 06161 261 361 471 571 671 71 871 971 07171 271 371 481 581 681 781 81 981 08181 281 381 491 591 691 791 892 90919293940567890 Time (ps)

B-Sheet

B-Bridge

Bend

Turn

Secondary structure

16

15

14

13

12

11

10

9

8

7

6

5

4

3

2

1

Coil

0123456718191111011213142526272829202122324353637383930313233454647484940414243445565758595051525354656676869606162636475767787970717273748586878898081828384959697989909191291391415161701801901010101 0101 201 301 4151617181910111 2131421 521 621 721 821 921 02121 21 321 431 531 631 731 831 931 03131 231 31 41 541 641 741 841 941 04141 241 341 451 51 651 751 851 951 05151 251 351 461 561 61 761 861 961 06161 261 361 471 571 671 71 871 971 07171 271 371 481 581 681 781 81 981 08181 281 381 491 591 691 791 892 90919293940567890 Time (ps)

Bend

Turn

A-Helix

3-Helix

Secondary structure

16

15

14

13

12

11

10

9

8

7

6

5

4

3

2

1

Coil

0123456718191111011213142526272829202122324353637383930313233454647484940414243445565758595051525354656676869606162636475767787970717273748586878898081828384959697989909191291391415161701801901010101 0101 201 301 4151617181910111 2131421 521 621 721 821 921 02121 21 321 431 531 631 731 831 931 03131 231 31 41 541 641 741 841 941 04141 241 341 451 51 651 751 851 951 05151 251 351 461 561 61 761 861 961 06161 261 361 471 571 671 71 871 971 07171 271 371 481 581 681 781 81 981 08181 281 381 491 591 691 791 892 90919293940567890 Time (ps)

Bend

Turn

A-Helix

3-Helix

Secondary structure

16

15

14

13

12

11

10

9

8

7

6

5

4

3

2

1

Coil

0123456718191111011213142526272829202122324353637383930313233454647484940414243445565758595051525354656676869606162636475767787970717273748586878898081828384959697989909191291391415161701801901010101 0101 201 301 4151617181910111 2131421 521 621 721 821 921 02121 21 321 431 531 631 731 831 931 03131 231 31 41 541 641 741 841 941 04141 241 341 451 51 651 751 851 951 05151 251 351 461 561 61 761 861 961 06161 261 361 471 571 671 71 871 971 07171 271 371 481 581 681 781 81 981 08181 281 381 491 591 691 791 892 90919293940567890 Time (ps)

Bend

Turn

A-Helix

3-Helix

Secondary structure

16

15

14

13

12

11

10

9

8

7

6

5

4

3

2

1

Coil

0123456718191111011213142526272829202122324353637383930313233454647484940414243445565758595051525354656676869606162636475767787970717273748586878898081828384959697989909191291391415161701801901010101 0101 201 301 4151617181910111 2131421 521 621 721 821 921 02121 21 321 431 531 631 731 831 931 03131 231 31 41 541 641 741 841 941 04141 241 341 451 51 651 751 851 951 05151 251 351 461 561 61 761 861 961 06161 261 361 471 571 671 71 871 971 07171 271 371 481 581 681 781 81 981 08181 281 381 491 591 691 791 892 90919293940567890 Time (ps)

B-Sheet

B-Bridge

Bend

Turn

3-Helix

FIG. 5: (A) Free energy surface of conformational landscape of GB1 -hairpin along two of the four latent CVs (B) The PCCA State Decomposition Diagram along with Population Table (C) The representative conformations corresponding to the free energy basins. For each basin, the secondary structure of all conformations are also characterised via DSSP scores.

time-scale(ns) Residue Residue Residue Residue
probability probability probability probability probability probability Residue Residue

(A)

Implied Time-Scales for GB-1

(B)

estimate

predict

1.00

103

0.75 0.50

0.25 01..0000

1 -> 1

1 -> 2

1 -> 3

1 -> 4

1 -> 5

1 -> 6

102

0.75 0.50

0.25 01..0000

2 -> 1

2 -> 2

2 -> 3

2 -> 4

2 -> 5

2 -> 6

0.75

101

0.50

0.25 01..0000

3 -> 1

3 -> 2

3 -> 3

3 -> 4

3 -> 5

3 -> 6

0.75

100

0.50

0.25 01..0000

4 -> 1

4 -> 2

4 -> 3

4 -> 4

4 -> 5

4 -> 6

0.75

10 1

0.50

0.25 01..0000

5 -> 1

5 -> 2

5 -> 3

5 -> 4

5 -> 5

5 -> 6

0.75

10 2
0 1 2 3 4 lag-tim5 e(ns) 6 7 8 9 10

0.50

0.25 0.00

0

6

-> 5

1 10

15

20

6 -> 2 0 5 10

15

20

6 -> 3 0 5 10

15

20

6 -> 4 0 5 10

15

20

6 -> 5 0 5 10

15

20

6 -> 6 0 5 10

15

20

lag time (ns) lag time (ns) lag time (ns) lag time (ns) lag time (ns) lag time (ns)

FIG. 6: Using Encoded Data: (A) Implied Time-scale plot (B) Chapman-Kolmogorov (CK) test.

8

Transition Network

3 8.765

0.235

2

4 0.932
1.576

0.628

0.98 0.472

0.272

3.60

3.815

0.781 0.302 1.038
5 1.341 1.332

0 0.72
0.56 3.438
1

FIG. 7: Transition Network for GB-1 with the MFPT values written in µs. Refer to Figure 5 for index of macro states.

ondary structural basis. We confirm this by rendering the representative snapshots of each of the macro states and via quantifying the secondary structure of each of the macrostates via DSSP algorithm. Our analysis and the visual inspection indicate that although the crystal structure of GB1 is suggestive of -hairpin, the conformational ensemble of GB1 peptide segment is highly heterogeneous. However interestingly, the adopted latent space CVs are able to distinctly identify each individual macrostates. The resolved FES and its PCCA decomposition show that along with perfect -sheet conformation (Macrostate 5), a large array of conformations, namely, distorted -sheet (Macrostate 1), N-terminal -helix (Macrostate 3), partial -helix (Macrostate 4), C-terminal helix(Macrostate 2) and random coil(Macrostate 0) (See Figure 5 A-C) also coexist. Folded GB-1 exists in perfect -sheet conformation(22.40%). Additionally, the statespace decomposition suggests GB1 can adopt another -hairpin like conformation, distorted -sheet(16.54%) in the ensemble. The full population of -hairpin like conformations is combined to be 38.94%. These are in good agreement with the experimentally measured population of -hairpin conformations36,37. Previously, computer simulations based on structure based clustering39 and the sketch-map analysis11 of simulated data had suggested that this polypeptide could have more than four different types of metastable conformations i.e, unfolded, collapsed, helical, and -sheet structures. But none of the previously proposed CVs, on its own, has been able to dissect all of these conformationally distinct states. In this regard, the current framework, via combining auto encoder based deep learning approaches with Markov state model, is found to identify and distinguish the native and native-like conformations of a dynamically fluctuating polypeptide like GB1 -hairpin. In addition the projection can potentially capture the subtle nonnative conformational fluctuations for this small peptide,

thereby manifesting the efficacy of the identified collective variables. The spatial resolution of the FES, derived in the current investigation, is found to be significantly higher than that obtained via sketch map for the same system11.
After coarse-graining of the micro-states to 6 different macro-states we have calculated the mean first passage time(mfpt) of transitions between different macrostates. Random coil has been taken as unfolded state and perfect -sheet as native folded conformation. The folding time (unfolded to folded) has turned out to be 4.40 µ-second and the unfolding time (folded to unfolded) has turned out to be 1.48 µ-second. Both these values are in good agreement with the experimentally measured rates or transition times46 for GB1 -hairpin. Then we have performed transition path thoery(TPT)47 analysis on this -peptide system to resolve the kinetic pathways for this folding-transtions from unfolded to folded state. We have found that there are 4-major pathways for this folding to occur (see Figure 7). Firstly, the transition can happen through Random Coil, C-terminal -helix, partial -helix, perfect -sheet [0  2  4  5] with a percentage of pathways as 31.5%. Secondly, 22.7% of pathways are following a pathway with a sequence of Random Coil, distorted -sheet, partial -helix, perfect -sheet meaning [0  1  4  5]. Thirdly, 20.0 % of total pathways are following Random Coil, distorted sheet, perfect -sheet [0  1  5]. Finally, 19.3 % of total pathways are following through Random Coil, partial -helix, perfect -sheet meaning [0  4  5]. These 4 pathways are contributing altogether 93.5 % of total folding pathways.
How do the latent space CVs derived using the neuralnetwork approach rank in comparison with the popular independent component analysis techniques? Towards this end, we individually perform PCA7 and TICA8 on the original input CVs (set of pair-wise inter-residue distances) of GB1 -hairpin. Contrary to neural-network based approaches PCA and TICA are linear dimensional reduction techniques. However, PCA focusses on maximising the variance while TICA strives to maximize the time-correlation of the projected dimension. For a robust comparison among PCA, TICA and auto-encoder derived optimised CVs on an equal footing, we employ variational approach for Markov processes (VAMP-2) score, as introduced by Noe and coworkers30,31. VAMP-2 score enables one to cross-validate multiple candidate CVs for their optimal representation and have been instrumental in making approbate choice of CVs in describing biomolecular conformation48. For a quantitative measure of relative optimality of the CVs, we analyze the VAMP-2 score on the CVs derived from each of the three dimension-reduction techniques (PCA,TICA and autoencoder). As shown in Figure 8 A, the VAMP-2 score is clearly the highest for the latent space CVs derived from neural-network based auto-encoder, compared to TICA and PCA. Together this suggests that the quality of autoencoder derived latent space CVs would be superior over

9

(A)

GB-1

2.0

VAMP-2 Score

1.5

1.0

0.5

0.0

PCA

time-scale(ns)

(B) (1)
103 102 101 100 10 1 10 2
0.0 0.5 1.0 1.5 lag-ti2m.0e(ns) 2.5 3.0 3.5 4.0

Different CoTllIeCctAive Variables AUTOENCODING

time-scale(ns)

(2)
105 103 101 10 1
0.0 0.5 1.0 1.5 lag-ti2m.0e(ns) 2.5 3.0 3.5 4.0

time-scale(ns)

(3)
103 102 101 100 10 1 10 2
0.0 0.5 1.0 1.5 2.0 lag-ti2m.5e(ns) 3.0 3.5 4.0 4.5 5.0

FIG. 8: Comparison of auto-encoder-derived CVs with PCA and TICA (A) via VAMP analysis (B) Using ITS Plots (1) ITS for PCA projected data (2) ITS for TICA projected data (3) ITS for Encoded data

TICA or PCA-derived CVs (applied on same input features) for efficient exploration of conformational landscape of GB1 -hairpin. Again the comparison of ITS plots has been shown in Figure 8 B for the PCA, TICA and Autoencoder-projected data to show the greater ease of having clear implied time scale separation attaining plateau for the Encoded-data.
C. TrpCage Mini-protein:
Finally, as an application of auto-encoder derived CVs, we investigate if these CVs can assist in elucidating the role of osmolyte in tuning the conformational landscape of the proteins. Here-in, we apply the auto encoderbased optimized CVs to assess the effect of popular osmolyte Trimethyl amine N-oxide (TMAO) on the conformational landscape of mini protein Trp-cage. The previously performed24 swarm of MD simulation trajectories of Trp-cage miniprotein in 0 M (i.e. neat water) and 4 M aqueous TMAO formed the basis of our current investigation. Consistent with protocols deployed in the other two systems, we use pair-wise inter-residue distances of Trpcage mini protein as the input CVs in our auto-encoder frame-work and employed a similar auto encoder schemes as in GB1 -hairpin for deriving the latent space variables.

Figure 9 (1) represents the two-dimensional projection of conformational space of Trp-cage in neat water along the latent space 1 and 2. Three free energy basins corresponding to the native fold, partially folded and unfolded states of the Trp-cage is evident in the FES in neat water. Interestingly, as shown in Figure 9 (2), the projection of MD trajectories of Trp-cage in 4 M aqueous TMAO solution along the same latent space 1 and 2 (which was obtained using the trajectories in neat water) clearly indicates that the presence of TMAO free energetically destabilises the basin corresponding to the partially folded and unfolded state, thereby tilting the free energy more favourably towards the native folded state of the Trp-Cage. Together, this analysis dictates that the CVs discovered via the autoencoder based neural network is able to distinguish the conformational landscape in different media and pinpoint the key factors.
The present scheme recovers the fully folded -helix, unfolded random coils and partially folded -helix conformations as three major macro-states following the principle of Implied Time Scale plots. For the folded states these structures have good resemblance with the previously identified structures for the same system13, albeit using enhanced sampling methods. However, the extent of diversity in the metastable states discovered , especially the coexistence of unfolded random coils and partially folded -helix observed in the current work is sig-

10

(1)

TrpCage in 0M TMAO

(2)

TrpCage in 4M TMAO

A
(3)
(A)

C

C

A

B

B

(B)

(C)

FIG. 9: (1) Projection of conformational landscape along latent CVs of Trp-Cage in neat water. (2) The projection along same latent CVs in 4 M TMAO. (3) The Representative Snap-shots for TrpCage.

nificantly more than that in previous work.13 The extent of spatial separation of the conformations, derived in the current setup is also significantly superior than previously adopted encoder map18.
IV. CONCLUSIONS
In summary, the current work employs a generic input CVs, namely an exhaustive sets of inter-residue distance of a biomacromolecule to derive an optimal low-dimensional embedded CVs within the frame-work of auto associative deep learning neural network. By striving to encode N-dimensional input features as a ddimensional representation (d << N), the protocol passes the information through the bottleneck and reconstructs the original signal again in the decoder. The resultant latent space CVs are shown to resolve the crucial conformations of three hierarchically complex systems of biomacromolecules. In combination with MSM, the latent space CVs are able to distinctly identify the key macro-states and avoid any mixing. The approach is able to sense the effect of solvent and cosolute in tuning the conformational landscape of the protein. Finally, the superiority of the auto-encoded latent space over linear combination based techniques (namely PCA and TICA) is rigorously demonstrated.
While extensions of linear dimensional reduction tech-

niques ,such as Kernel PCA and kernel TICA49, present a means to alleviate this problem by applying a known nonlinear transformation of the atomic coordinates prior to dimensionality reduction, the specification of appropriate kernels can be almost as tedious job as guessing the CVs themselves. In this regard, the frame-work presented in the current article provides a practical and efficient avenue for CV discovery and identification of kinetically relevant metastable conformations. The frame-work of auto encoding based approach, similar to what has been described here has recently been found to be quite effective for CV discovery and for generating synthetic trajectories via simulating the latent space50. A related approach in this direction has enabled on-the-fly CV discovery and accelerated energy landscape exploration via combining umbrella sampling with autoencoder-based dimensional reduction51. On the contrary, in this work, we have avoided the introduction of enhanced simulation approaches, which may run the risk of introducing biases on CV discovery. We demonstrate that the usage of unbiased MD simulation trajectories for identifying appropriate CVs within the frame-work of auto encoder and its effective combination with MSM leads to clearer separation of the conformational landscape. The higher spatial and temporal separation of the conformations is particularly evident for GB1 -hairpin when compared to that obtained from sketch map11 . Apart from the elucidation of static conformational landscapes via discovery of optimal CVs, emerging directions have seen extension and

11

proposals of suitable framework for capturing the underlying dynamics. Development of relevant deep-learning based techniques such as time-lagged autoencoders14,19, Variational dynamical encoders16, RAVE15 have paved the way for prediction of future dynamics and reconstruction of dynamical trajectories for macromolecules. Future directions will aim to extend along this line.
ACKNOWLEDGMENTS
This work was supported by computing resources obtained from shared facility of TIFR Centre for Interdisciplinary Sciences, India. We acknowledge support of the Department of Atomic Energy, Government of India, under Project Identification No. RTI 4007. JM acknowledges Ramanujan Fellowship and Core Research grants provided by the Department of Science and Technology (DST) of India (CRG/2019/001219). SB thanks to TIFR for providing all support. SB also thanks Dr. Navjeet Ahalawat for useful discussions on related topics.
REFERENCES
1J. D. Bryngelson, J. N. Onuchic, N. D. Socci, and P. G. Wolynes, Proteins: Structure, Function, and Genetics 21, 167 (1995).
2K. A. Dill and H. S. Chan, Nature Structural & Molecular Biology 4, 10 (1997).
3G. Torrie and J. Valleau, Journal of Computational Physics 23, 187 (1977).
4A. Laio and M. Parrinello, Proceedings of the National Academy of Sciences 99, 12562 (2002).
5O. Valsson, P. Tiwary, and M. Parrinello, Annual Review of Physical Chemistry 67, 159 (2016).
6P. Tiwary and B. J. Berne, Proc Natl Acad Sci USA 113, 2839 (2016).
7A. Altis, P. H. Nguyen, R. Hegger, and G. Stock, The Journal of Chemical Physics 126, 244111 (2007).
8G. P´erez-Herna´ndez, F. Paul, T. Giorgino, G. D. Fabritiis, and F. No´e, The Journal of Chemical Physics 139, 015102 (2013).
9C. R. Schwantes and V. S. Pande, J. Chem. Theory Comput. 9, 2000 (2013).
10A. L. Ferguson, A. Z. Panagiotopoulos, I. G. Kevrekidis, and P. G. Debenedetti, Chemical Physics Letters 509, 1 (2011).
11A. Ardevol, G. A. Tribello, M. Ceriotti, and M. Parrinello, J. Chem. Theory Comput. 11, 1086 (2015).
12G. E. Hinton, Science 313, 504 (2006). 13W. Chen, A. R. Tan, and A. L. Ferguson, The Journal of Chem-
ical Physics 149, 072312 (2018). 14C. Wehmeyer and F. No´e, The Journal of Chemical Physics 148,
241703 (2018). 15J. M. L. Ribeiro, P. Bravo, Y. Wang, and P. Tiwary, The Journal
of Chemical Physics 149, 072301 (2018). 16C. X. Hern´andez, H. K. Wayment-Steele, M. M. Sultan, B. E.
Husic, and V. S. Pande, Phys. Rev. E 97 (2018), 10.1103/physreve.97.062412. 17M. M. Sultan, H. K. Wayment-Steele, and V. S. Pande, J. Chem. Theory Comput. 14, 1887 (2018).

18T. Lemke and C. Peter, J. Chem. Theory Comput. 15, 1209
(2019). 19W. Chen, H. Sidky, and A. L. Ferguson, J. Chem. Phys. 151,
064123 (2019). 20J. Wang and A. L. Ferguson, J. Phys. Chem. B 122, 11931 (2018).
21Y. Wang, J. M. L. Ribeiro, and P. Tiwary, Current Opinion in
Structural Biology 61, 139 (2020). 22M. Mukherjee and J. Mondal, J. Phys. Chem. B 123, 4636 (2019). 23N. Ahalawat and J. Mondal, J. Chem. Phys. 149, 094101 (2018). 24M. Mukherjee and J. Mondal, J. Phys. Chem. B 124, 6565 (2020). 25https://www.tensorflow.org,. 26https://github.com/keras team/keras,. 27J. Kingma, D. P.; Ba, arXiv:1412.6980 2014. 28X. Glorot and Y. Bengio. 29L. Molgedey and H. G. Schuster, Phys. Rev. Lett. 72, 3634
(1994). 30F. Paul, H. Wu, M. Vossel, B. L. de Groot, and F. No´e, J. Chem.
Phys. 150, 164120 (2019). 31M. K. Scherer, B. E. Husic, M. Hoffmann, F. Paul, H. Wu, and
F. No´e, J. Chem. Phys. 150, 194108 (2019). 32T. R. Knapp, Psychological Bulletin 85, 410 (1978). 33J.-H. Prinz, H. Wu, M. Sarich, B. Keller, M. Senne, M. Held,
J. D. Chodera, C. Schu¨tte, and F. No´e, The Journal of Chemical
Physics 134, 174105 (2011). 34G. R. Bowman, K. A. Beauchamp, G. Boxer, and V. S. Pande,
The Journal of Chemical Physics 131, 124101 (2009). 35J. Mondal, G. Stirnemann, and B. J. Berne, J. Phys. Chem. B
117, 8723 (2013). 36F. J. Blanco, G. Rivas, and L. Serrano, Nat Struct Mol Biol 1,
584 (1994). 37A. Soranno, F. Cabassi, M. E. Orselli, T. Cellmer, A. Gori,
R. Longhi, and M. Buscaglia, J. Phys. Chem. B 122, 11468
(2018). 38J. Juraszek and P. G. Bolhuis, Journal of Physical Chemistry B
113, 16184 (2009). 39R. B. Best and J. Mittal, Proteins: Structure, Function and
Bioinformatics 79, 1318 (2011). 40M. Andrec, A. K. Felts, E. Gallicchio, and R. M. Levy, Proceed-
ings of the National Academy of Sciences of the United States of
America 102, 6801 (2005). 41Daniel S. Weinstock, Chitra Narayanan, Anthony K. Felts,
Michael Andrec, . Ronald M. Levy, , Kuen-Phon Wu, and
J. Baum*, (2007), 10.1021/JA0677517. 42D. D. Prakashchand, N. Ahalawat, S. Bandyopadhyay, S. Sen-
gupta, and J. Mondal, J. Chem. Theory Comput. 16, 2508
(2020). 43W. Kabsch and C. Sander, Biopolymers 22, 2577 (1983). 44S. Lloyd, IEEE Trans. Inf. Theor. 28, 129 (2006). 45P. Deuflhard and M. Weber, Linear Algebra and its Applications
398, 161 (2005), special Issue on Matrices and Mathematical
Biology. 46V. Mun~oz, P. A. Thompson, J. Hofrichter, and W. A. Eaton,
Nature 390, 196 (1997). 47F. No´e, C. Schu¨tte, E. Vanden-Eijnden, L. Reich, and T. R.
Weikl, PNAS 106, 19011 (2009). 48B. R. Dandekar, N. Ahalawat, and J. Mondal, Biophysical Jour-
nal 120, 1732 (2021). 49C. R. Schwantes and V. S. Pande, J. Chem. Theory Comput. 11,
600 (2015). 50H. Sidky, W. Chen, and A. L. Ferguson, Chem. Sci. 11, 9459
(2020). 51W. Chen and A. L. Ferguson, J Comput Chem 39, 2079 (2018).

