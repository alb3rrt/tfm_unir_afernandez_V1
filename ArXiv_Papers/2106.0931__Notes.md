
# Understanding the Design Space of Mouth Microgestures

[arXiv](https://arxiv.org/abs/2106.0931), [PDF](https://arxiv.org/pdf/2106.0931.pdf)

## Authors

- Victor Chen
- Xuhai Xu
- Richard Li
- Yuanchun Shi
- Shwetak Patel
- Yuntao Wang

## Abstract

As wearable devices move toward the face (i.e. smart earbuds, glasses), there is an increasing need to facilitate intuitive interactions with these devices. Current sensing techniques can already detect many mouth-based gestures; however, users' preferences of these gestures are not fully understood. In this paper, we investigate the design space and usability of mouth-based microgestures. We first conducted brainstorming sessions (N=16) and compiled an extensive set of 86 user-defined gestures. Then, with an online survey (N=50), we assessed the physical and mental demand of our gesture set and identified a subset of 14 gestures that can be performed easily and naturally. Finally, we conducted a remote Wizard-of-Oz usability study (N=11) mapping gestures to various daily smartphone operations under a sitting and walking context. From these studies, we develop a taxonomy for mouth gestures, finalize a practical gesture set for common applications, and provide design guidelines for future mouth-based gesture interactions.

## Comments

14 page, 5 figures; Accepted to DIS 2021

## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{chen2021understanding,
      title={Understanding the Design Space of Mouth Microgestures}, 
      author={Victor Chen and Xuhai Xu and Richard Li and Yuanchun Shi and Shwetak Patel and Yuntao Wang},
      year={2021},
      eprint={2106.00931},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}
```

## Notes

Type your reading notes here...

