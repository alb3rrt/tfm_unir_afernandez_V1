Concurrent Learning Based Tracking Control of Nonlinear Systems using Gaussian Process
Vedant Bhandari and Erkan Kayacan

arXiv:2106.00910v1 [eess.SY] 2 Jun 2021

Abstract-- This paper demonstrates the applicability of the combination of concurrent learning as a tool for parameter estimation and non-parametric Gaussian Process for online disturbance learning. A control law is developed by using both techniques sequentially in the context of feedback linearization. The concurrent learning algorithm estimates the system parameters of structured uncertainty without requiring persistent excitation, which are used in the design of the feedback linearization law. Then, a non-parametric Gaussian Process learns unstructured uncertainty. The closed-loop system stability for the nth-order system is proven using the Lyapunov stability theorem. The simulation results show that the tracking error is minimized (i) when true values of model parameters have not been provided, (ii) in the presence of disturbances introduced once the parameters have converged to their true values and (iii) when system parameters have not converged to their true values in the presence of disturbances.
I. INTRODUCTION
The performance of feedback linearization depends on the accuracy of the system model, and its parameter estimates in the linearization process and all generalized external forces that change in different environments [1]­[3]. It is often difficult to exactly know the model parameters for any practical system, with uncertainty in measurement always present [4], [5]. Uncertainty in model parameters leads to a decreasing reference tracking performance [6]. Furthermore, changing operation environments introduces varying disturbances, which cannot always be accounted for in the controller design [7].
These challenges mentioned above require feedback linearization to be combined with more robust design techniques to account for model uncertainties and adapt to various environments with varying disturbances. The proposed law by [8] combines feedback linearization (FBL) control with Gaussian Process (GP) to account for model uncertainty. Using online learning GP, the controller learns the model mismatch between the actual model and the estimated model used for the feedback linearization, reducing the model uncertainty and leading to better reference tracking. However, no attempt is made to estimate the system model's true parameters and the effect of any external disturbances is directly captured by the GP as a model mismatch. This is not ideal as the model mismatch and disturbance cannot be distinguished. A similar proposal by [9], [10] also uses GP-based tracking control, where the Gaussian
*This work was supported by UQ Early Career Researcher grant (UQECR2057325).
The authors are with the School of Mechanical and Mining Engineering, The University of Queensland, 4072 Brisbane, Australia. {v.bhandari, e.kayacan }@uq.edu.au

Fig. 1. Schematic diagram for the developed control algorithm. Along with the use of the traditional feedback linearization technique (FBL and statefeedback controller blocks), a concurrent learning algorithm is used to estimate the model parameters to be used in the feedback linearization process, and an online non-parametric Gaussian Process and Robustness term are used to account for unknown disturbances.
process is used offline to learn the model mismatch and any modelled dynamics together. This presents the same issues as mentioned previously.
Concurrent learning approach was used and demonstrated significantly with model reference adaptive control methods as initially proposed in [11]. Recently, it has also been used as an online parameter estimator [12]. It can be used in any other nonlinear control methods. This paper will demonstrate its applicability in the scheme of the FBL method ­ this is unique and has not been shown in the literature.
The developed control law in this paper provides a twostage controller design, as shown in Fig.1. In the first stage, the system model parameters are estimated to provide optimal tracking control with feedback linearization using concurrent learning in a known and controlled environment. The learned model parameters are then used with a GP-based online learning approach to operate in environments with unknown disturbances in the second stage. This approach's key benefits are that the system model parameters can be accurately estimated, which is critical in a model-based controller design process. The unstructured uncertainties can then be captured by a non-parametric GP; thus, the control system can also work in unstructured environments.
The main contributions of this study are as follow:
· An approach that uses concurrent learning to estimate system model parameters in the framework of FBL in a known environment accurately.
· A control system that learns the disturbances and model mismatch in the second stage, where a non-parametric GP is used to compensate for the disturbances in unknown,

unstructured environments. · The stability of the nth-order closed-loop system is proven
using the Lyapunov stability theorem. · Tracking error convergences to zero with and without
exact parameter estimation convergence by using GP.
This paper is organized as follows: The problem statement is described in Section II. Concurrent learning and Gaussian process are given in Section III. In Section IV, the details of the developed control algorithm is explained, the system stability for an n-th order system is proven. Simulations results have verified the developed control approach leading to minimized tracking error in Section V. Finally, the study is concluded in Section VI.

II. PROBLEM STATEMENT

Single-input single-output (SISO) nonlinear system dynamics that can be linearly parameterized are given by:

x = Ax + b u + wT  (x) + d

(1)

where A  Rn×n exploits the integrator chain structure, b = [0, 0, ..., 1]T  Rn, u  R is the control input, x  Rn is the state vector, the system dynamics are given by wT  (x), and
d is an unknown disturbance. The system model regressor vectors  (x)  Rm are known and w  Rm is the unknown
ideal weight vector. Expanding the system equations (1), the
state-derivative is given by the last equation:

xn = wT  (x) + u + d

(2)

where xn is the state-derivative and n is the order of the system. In addition to being linearly parameterizable, the system
considered in this paper must have no internal dynamics, and the state-derivative in the system model must be measurable or estimated. Moreover, it is assumed there exists a training environment where the dynamics of the system can be accurately modelled in the regressor vector  (x) before the system is operated in an environment where disturbance d may exist. This does not necessarily include the weightings of the system dynamics, w, but only the dynamics representing the system.
Feedback linearization algebraically transforms a non-linear system (fully or partially) into a linear one, allowing the use of linear control techniques [13], [14]. This is achieved by exact state transformations and feedback control law. Feedback linearization requires a mathematical model of the system and considers a fixed model estimate traditionally [15]. The larger the error in the model estimate, the greater the tracking error. Let the estimated weight vector be given by vector w. To linearize a nonlinear system using feedback linearization, the control input is given by:

u = -wT  (x) + v

(3)

where w is the estimate of the model weights and v is a selected linear controller. This results in the following system:

xn = -w~  (x) + d + v

(4)

where w~ = w - w is the modelling error. Note that if w  w,

then w~ = 0 and also if d = 0, then a linear system is obtained

as

xn = v

(5)

Considering the closed-loop dynamics presented by (5), the linear controller v is chosen such that the closed-loop system is stable. Let the tracking error be defined as :

e = xref - x

(6)

where e is the vector of the error states and xref is the vector of the state references where

e = e1 e2 · · · en T , ei = xiref - xi

(7)

The linear controller, i.e., v, is designed such that:

v = xnref + k1e1 + k2e2 + · · · + knen

(8)

Substituting the linear controller v (8) in (5) gives:

0 = en + knen + · · · + k2e2 + k1e1

(9)

The values of the polynomial coefficients k1, k2, · · · , kn  0 are such that the system poles are on the left half of the plane, leading to exponentially stable dynamics [6]. This demonstrates that the control input given by (3) results in stable closed-loop dynamics when the system is perfectly modelled and in the absence of any disturbances [16].
However, in the common case that w = w, and in the presence of a disturbance, (9) becomes:

w~  (x) - d = en + knen + · · · + k2e2 + k1e1

(10)

Eq. (10) shows that the tracking error cannot converge to zero due to the presence of modelling error and disturbance under the traditional feedback linearization control law proposed in (3). As the control law is deemed insufficient in this case, it needs to be redesigned to account for system modelling errors and disturbances.
The goal of the developed control law in this paper is to design the control input u such that the tracking error is minimized and converges to zero in finite-time in the presence of modelling error and disturbance. This goal is to be achieved using concurrent learning to accurately estimate the system parameters to minimize the modelling error and Gaussian Process to learn the disturbance and cancel its effects by compensating in the control input.

III. CONCURRENT LEARNING AND GAUSSIAN PROCESS
A. Concurrent Learning
Traditionally, an inaccurate model parameter estimate in the feedback linearization control method leads to an error in the linearization process, and it is not easy to obtain the model parameter estimate accurately. It would be ideal to update the model parameter weights using state feedback until the model parameters converge to their true values. Concurrent learning allows for model parameter estimation without requiring persistent excitation instead of providing a user-selected

model parameter estimate. It uses the current error and a set of recorded data to converge parameter estimates to their true values, as visible in the second half of (11).
The concurrent learning method is initially introduced in the context of model reference adaptive control. The same concept is integrated with the feedback linearization framework in this paper. The following weight update law is used:

p

w = -W  (x)eT Pb -  W  (x) j

(11)

j=1

with the conditions and parameters detailed in [11]. The algorithm to store data points is given in [12]. The Lyapunov equation is written as follows:

(A - bk)T P + P(A - bk) + Q = 0

(12)

where (A - bk) is introduced in Section IV-C, Q  Rn×n is any positive definite matrix and P  Rn×n is the positive definite solution to the Lyapunov equation [17]. It was shown the weight update law to be exponentially stable within the model reference adaptive control context [11]. The error dynamics of the proposed closed-loop system in the context of feedback linearization is formulated in Section IV-C and is shown to be in the form as in [11], meaning the stability results apply directly to the proposed closed-loop system as well. The stability results for the parameter convergence are not repeated here and can be found in [11], [18].

B. Gaussian Process
Gaussian Processes are used in the control law to compensate for disturbances when systems exposed to an unknown environment [10], [19]. The following part of this subsection outlines the key concepts used in the controller design in this paper.
Gaussian Process (GP) Regression allows for a nonlinear mapping from a set of input values X ={x1, x2, · · · , xn} to output values Y ={y1, · · · , yn} [20]. The GP is provided with a set of training data D ={X,Y }, from which a nonlinear map is generated, so an unseen input X returns a predicted output Y [21]. This makes GP a powerful prediction tool and useful addition to the control law discussed in Section IV-B when dealing with disturbances. The idea of Bayesian inference is used to perform regression on a set of training data, in which the current hypothesis is updated based on new information. If the greater number of training data is provided around a point to be estimated, the better GP prediction is obtained.
Two priors are required to define the Gaussian distribution along with the training data: a mean function µ, which describes the expected value of the distribution, generally set to zero, and a covariance matrix or kernel, , which provides a measure of similarity between two points and their values, describing the shape of the distribution. These two priors can significantly impact the nonlinear mapping generated by the GP and must be selected carefully. Each kernel has various hyperparameters that are also user-selected and significantly

Fig. 2. Gaussian Process. Offline vs Online Gaussian Process learning.

impact the overall input-output mapping. However, these parameters can be optimized by solving the maximum loglikelihood problem [21].
Mathematically, consider the joint Gaussian distribution of the training outputs, Y corresponding to inputs X, and the test outputs, Y corresponding to test inputs X [21]:

Y Y

N

0,

K(X, X) K(X, X)

K(X, X) K(X, X)

(13)

In the controller, the test inputs, X, are the time-dependent system states. For n training points and n test points, K(X, X) represents the n×n matrix of covariances evaluated at all pairs of training and test points. The same applies to the other entries of the covariance function. The squared exponential covariance function is used in this paper and is given by [22]:

kSE

(X

,

X)

=



2 f

exp

-

(X

- X 2l2

)2

(14)

Conditioning the joint prior distribution on the training data, D, the mean and variance at query points X is given by [21]:

µ(X) = K(X, X)K(X, X)-1Y

(15)

 2(X) = K(X, X) - K(X, X)K(X, X)-1K(X, X) (16)

In the context of this paper, a GP is trained with n data pairs, with the system states, x as inputs, and the control input mismatch (u - u^), as the output, representing the torque compensation for the disturbance. This can be performed using two methods; online or offline learning displayed in Fig. 2.
In offline learning, the GP is trained across a set of generic inputs, and the pre-recorded GP is used to predict the compensation for the disturbance in simulation. This differs from online learning in the sense that the GP is not updated during the simulation. In online learning, the GP model is continuously updated throughout tracking the reference signal. This allows the GP to be trained to meet the experimental conditions and update according to any model mismatch during the simulation. Using an online GP requires greater processing power as the prediction hypothesis is updated throughout the simulation compared to only obtaining a prediction from the GP.

IV. METHODOLOGY

A. Reference Model

In matrix form, the reference system can be represented as:

xref = Axref + bu

(17)

where A  Rn×n exploits the integrator chain structure, xref = [x1ref , x2ref , · · · , xn-1ref ] is the reference output, b  Rn, b = [0, 0, ..., 1]T as before and u is the reference input equal to the

reference output, u = xnref . The reference signal is assumed to be continuously differentiable.

B. Control Law

Let the control law be defined as:

u = uFBL + uSFB + ure f - uGP - urob

(18)

where uFBL is the feedback linearization law to linearize the system, uSFB is the chosen linear controller, ure f is the reference signal required to cancel the input from the reference model, uGP is the Gaussian process-based estimate of the disturbance, and urob is robustness term with its formulation detailed in Section IV-D to ensure closed-loop system stability. They are formulated as follows:

uFBL = -wT  (x)

(19)

uSFB = ke, k = [k1, k2, · · · , kn]

(20)

ure f = xnref

(21)

uGP = µ(x) = u(x) - u^(x)

(22)

bT Pe

urob = -m bT Pe

(23)

uGP is determined at a query state x. The estimate is given by learning the difference in the actual control input, i.e., u, and the control input estimated from the known system model, i.e., u^. If the model parameters converge to their true value during the learning stage, only the disturbance is learnt by the Gaussian Process. The plant model is given by:

u = xn - wT  (x) - d

(24)

The estimated model is given by:

u^ = xn - wT  (x)

(25)

Using the same state feedback, x, u - u^ = -d if w  w. If the parameters do not converge, the GP learns the disturbance and the model convergence error.

C. Tracking Error

The error dynamics are given by:

e = xref - x

(26)

Substituting the reference and system model in (26), the error dynamics can be written considering (17) as:

e = Axref + bxnref - Ax + b u + wT  (x)

(27)

Substituting in for the control law (18) and letting w~ = w - w be the model parameter estimation error, the error dynamics can be simplified to:

e = (A - bk)e + b w~  (x) - d + µ(x) + urob (28)

D. System Stability

The closed-loop system is shown to be stable using the Lyapunov stability theorem in the possibility of concurrent learning not learning the system parameters correctly as well. An approach similar to [8] is used below to show the closedloop system is stable. The common quadratic Lyapunov function is proposed below:

V = eT Pe

(29)

where e is the tracking error vector and P is the positive definite matrix that solves the algebraic Ricatti equation:

(A - bk)T P + P(A - bk) + S~ = 0

(30)

where S~ = Q + kTRk > 0 with Q, R > 0. The derivative of the Lyapunov function is given by:

V = eT Pe

(31)

The time-derivative of Lyapunov function is equivalently using the algebraic Ricatti equation and by inserting (28) into the equation above:
V = -eT S~ e + 2(bT Pe)T w~  (x) - d + µ(x) + urob (32)
The robustness term urob is now designed such that the system can be shown to be stable. Using urob defined in (23) and substituting into (32):

V =-eT S~ e + 2(bT Pe)T

w~  (x) - d + µ(x) - m

bT Pe bT Pe

(33)

Using the Lyapunov theorem, V needs to be shown to be
strictly negative for the system to be closed-loop stable. The first term -eTS~ e < 0 is strictly negative. The second term also
needs to be shown to be strictly negative to show system stability. Let the second term be represented by V2. Using the Cauchy-Schwarz inequality, V2 can be rewritten as:

V2  2 bT Pe - m + |w~  (x) - d + µ(x)|

(34)

V2 is negative if and only if:

m > |w~  (x) - d + µ(x)|

(35)

Therefore, as V1 is strictly negative, and V2 is negative in the presence of a disturbance or no disturbance, V = V1 +V2 < 0 and the closed-loop system is stable.
Remark 1: The term above |w~  (x) - d + µ(x)| is equal to |xnmeasured - xn|.
V. SIMULATION
The simulation results for the proposed control law applied to the system presented in [11] are presented in this section. The following cases are simulated for the system and referred to below:
Case a) FBL without any learning, with model mismatch w~ = 0 in the absence of disturbance, d = 0.

Case b) FBL with only concurrent learning for parameter estimation without model mismatch w~ = 0 in the absence of disturbance, d = 0.
Case c) FBL with only concurrent learning for parameter estimation without model mismatch w~ = 0 in the presence of disturbance, d = 0.
Case d) FBL with concurrent learning for parameter estimation with model mismatch w~ = 0 and Gaussian process-based online learning for disturbance in the presence of disturbance, d = 0.
Case e) FBL with concurrent learning for parameter estimation without model mismatch w~ = 0 and Gaussian process-based online learning for disturbance in the presence of disturbance, d = 0.
All simulations use gains k1 = k2 = 20,  = 0.01 and a reference tracking of xre f = A sin t with A = 0.5 and  = 1 rad/s. All initial conditions are zero, i.e., x(0) = 0. A learning rate of W = 3 is used for the concurrent parameter estimation. For the GP, the squared exponential kernel is used as each new training point reduces the posterior variance [23]. The hyperparameters are optimized using the maximum log likelihood function and all GP processing is handled by using the fitrgp function in MATLAB.
The online GP implementation has a ten-second learning period where the model is initially learnt, and then the model is updated with every previous 100 data points throughout the simulation. Since the disturbance is unknown to a control system in practice, it is not feasible to use offline GP learning unless the same simulation was run under the same circumstances, the model was trained and then deployed again. Using an online GP allows the learning and training to happen simultaneously and is used below for all simulations.

A. Systems

The system used for simulations is the same as that presented in [11], and is given by:

¨ = u + sin  - | | + 0.5 exp (  )

(36)

Rewriting in the form of (2):

¨ = wT  ( ) + u + d

(37)

where the ideal weights, w = [1, -1, 0.5]T , the regressor vector values are  ( ) = [sin  , | | , exp (  )]T , and u is the

control input. For Case a), the weight estimate is given by w = [0.5, -1.3, 0.75]T . The added external disturbance is given

by:

0

0 < t < 10

d = cos  +  10  t  30

(38)

The simulation has three stages. In the first ten seconds, there is no disturbance and concurrent learning is used to estimate the model parameters. From 10 to 20 seconds, the disturbance is introduced and data is collected to train the GP. After 20 seconds, the GP begins compensating for the disturbance and the GP is continuously updated.

B. Simulation Results
The average tracking error for the cases outlined at the beginning of Section V is shown in Figure 3(a). The proposed control law leads to the reduced tracking error in both scenarios, Case d) and Case e), even in the presence of large continuous disturbances. With the Gaussian Process learning and predicting the system disturbance, the average tracking errors for Case b) and Case e) are approximately equal. Both cases would have the same tracking error given that the GP exactly learns the disturbance. The effect of using a fixed model estimate versus a concurrent learning model is visible in Case a) and Case b), respectively, in which using concurrent learning drastically reduces the error. If a case was to exist where the model parameters were not estimated accurately using concurrent learning, the GP would learn the model error as part of the disturbance and provide appropriate compensation, as is shown by Case d).
The three stages for Case e) and Case (d) are shown in Figure 3(b) and 3(c), respectively. In the first stage, the model parameters are being learnt in a controlled environment for the first ten seconds only ­ this provides sufficient time for the parameters to converge to their parameter estimates. In the second stage, a disturbance is introduced, the GP also begins learning the disturbance as a torque mismatch for the 10 to 20 second period. During this time, the GP provides no compensation and only learns. After 20 seconds, the GP begins compensating for the effects of the disturbance and the tracking error is significantly reduced. The ability of the GP to compensate for large disturbances is apparent by comparing Case c) and Case e). In Case e), the Gaussian process captures the disturbance only as the model parameters are exactly estimated, whereas in Case d), the Gaussian process accounts for the disturbance and the system model error, as shown in Fig. 3(e). The exact parameter convergence of concurrent learning in Case b) and Case e) is shown in Fig. 3(d). The robustness value for Case d) and Case e) is also shown in Fig. 3(f). As the GP compensates for the control input mismatch, the robustness term has minimal input.
VI. CONCLUSION
This paper has developed the use of concurrent learning for exact model parameterization in the context of feedback linearization, combined with the use of Gaussian Processes for learning the disturbance for uncertain nonlinear systems. A robustness term was developed and added to the control law to ensure closed-loop system stability, which has been proven by using the Lyapunov stability theorem. Simulation results have verified the effectiveness of the control law in achieving minimized tracking error in the presence of model mismatch and disturbances, and ensured more accurate tracking performance.
REFERENCES
[1] T. Westenbroek, D. Fridovich-Keil, E. Mazumdar, S. Arora, V. Prabhu, S. S. Sastry, and C. J. Tomlin, "Feedback linearization for unknown systems via reinforcement learning," 2020.

Angle (rad)

Angle (rad)

Average Tracking Error (%)

10 8.88
8
6

Reference Angle

Reference Angle

Actual Angle

Actual Angle

Tracking Error

Tracking Error

0.5

0.5

4 2.62

2

0.38

0.44 0.44

0

a

b

c

d

e

Case

(a) Average tracking error (%).

0

-0.5 0

10

20

30

Time (s)

(b) Reference tracking Case e).

0

-0.5 0

10

20

30

Time (s)

(c) Reference tracking Case d).

Disturbance Gaussian Esitmate

Weight, W

1

0.5 Weight Estimate 1

0

Weight Estimate 2 Weight Estimate 3

Ideal Weight 1

-0.5

Ideal Weight 2

Ideal Weight 3

-1

0 5 10 15 20 25 Time (s)

(d) Parameter estimation: Weights.

8

uGP Exact Model Estimate

6

uGP Incorrect Model Estimate

Actual Disturbance

4

2

0 20 22 24 26 28 30
Time (s)
(e) Gaussian estimate of the disturbance.

Robustness Value

8

urob Exact Model Estimate

6

urob Incorrect Model Estimate

4

2

0

-2

-4 20 22 24 26 28 30 Time (s)
(f) Output of the robustness term.

Fig. 3. Simulation results: (a) The average tracking error for each case outlined at the beginning of Section V. Case d) and Case e) show the minimized tracking error when using the proposed control law. (b) Reference tracking when concurrent learning converges to the exact model parameters (w~ = 0) ( Case e) ). (c) Reference tracking when concurrent learning does not converge to the true model parameters (w~ = 0) ( Case d) ). (d) Exact parameter convergence using concurrent learning in Case b) and Case e). (e) Gaussian estimate of the disturbance when the model is exactly parameterized and when a model error is present ( Case d) and Case e) ). (f) The robustness value when the model is exactly parameterized and when a model error is present ( Case d) and Case e) ).

[2] E. Kayacan, "Closed-loop error learning control for uncertain nonlinear systems with experimental validation on a mobile robot," IEEE/ASME Trans. Mechatronics, vol. 24, no. 5, pp. 2397­2405, 2019.
[3] J. Umlauft and S. Hirche, "Feedback linearization based on gaussian processes with event-triggered online learning," IEEE Trans. Autom. Control, vol. 65, no. 10, pp. 4154­4169, 2020.
[4] L. Oliveira, A. Bento, V. J. Leite, and F. Gomide, "Evolving granular feedback linearization: Design, analysis, and applications," Applied Soft Computing, vol. 86, p. 105927, 2020.
[5] E. Kayacan, "Sliding mode learning control of uncertain nonlinear systems with lyapunov stability analysis," Transactions of the Institute of Measurement and Control, vol. 41, no. 6, pp. 1750­1760, 2019.
[6] J.-J. E. Slotine and W. Li, Applied nonlinear control. Prentice-Hall, 1991.
[7] J. Chai, E. Medagoda, and E. Kayacan, "Adaptive and efficient model predictive control for booster reentry," Journal of Guidance, Control, and Dynamics, vol. 43, no. 12, pp. 2372­2382, 2020.
[8] M. Greeff and A. P. Schoellig, "Exploiting differential flatness for robust learning-based tracking control using gaussian processes," IEEE Control Systems Letters, vol. 5, no. 4, pp. 1121­1126, 2021.
[9] T. Beckers, J. Umlauft, D. Kulic, and S. Hirche, "Stable gaussian process based tracking control of lagrangian systems," in 2017 IEEE 56th Annual Conference on Decision and Control (CDC), 2017, pp. 5180­5185.
[10] T. Beckers, D. Kulic´, and S. Hirche, "Stable gaussian process based tracking control of euler­lagrange systems," Automatica, vol. 103, pp. 390­397, 2019.
[11] G. Chowdhary and E. Johnson, "Concurrent learning for convergence in adaptive control without persistency of excitation," in 49th IEEE Conference on Decision and Control (CDC), 2010, pp. 3674­3679.
[12] E. Kayacan, S. Park, C. Ratti, and D. Rus, "Online system identification algorithm without persistent excitation for robotic systems: Application to reconfigurable autonomous vessels," in IEEE/RSJ Int. Conf. Intell Robots Syst., 2019, pp. 1840­1847.
[13] L. Martins, C. Cardeira, and P. Oliveira, "Feedback linearization with

zero dynamics stabilization for quadrotor control," Journal of Intelligent & Robotic Systems, vol. 101, no. 1, p. 7, 2020. [14] J. Moreno­Valenzuela, J. Montoya­Cha´irez, and V. Santiba´n~ez, "Robust trajectory tracking control of an underactuated control moment gyroscope via neural network­based feedback linearization," Neurocomputing, vol. 403, pp. 314­324, 2020. [15] G. Li, A. Luo, Z. He, F. j. Ma, Y. Chen, W. Wu, Z. Zhu, and J. M. Guerrero, "A dc hybrid active power filter and its nonlinear unified controller using feedback linearization," IEEE Trans. Ind. Electron., pp. 1­1, 2020. [16] M. Mehndiratta, E. Kayacan, M. Reyhanoglu, and E. Kayacan, "Robust tracking control of aerial robots via a simple learning strategy-based feedback linearization," IEEE Access, vol. 8, pp. 1653­1669, 2020. [17] D. Boley and B. Datta, "Numerical methods for linear control systems," 1994. [18] R. Kamalapurkar, B. Reish, G. Chowdhary, and W. E. Dixon, "Concurrent learning for parameter estimation using dynamic state-derivative estimators," IEEE Trans. Autom. Control, vol. 62, no. 7, pp. 3594­3601, 2017. [19] E. Bradford, L. Imsland, D. Zhang, and E. A. del Rio Chanona, "Stochastic data-driven model predictive control using gaussian processes," Computers & Chemical Engineering, vol. 139, p. 106844, 2020. [20] Y. Cao, J. Huang, H. Ru, W. Chen, and C. H. Xiong, "A visual servobased predictive control with echo state gaussian process for soft bending actuator," IEEE/ASME Trans. Mechatronics, vol. 26, no. 1, pp. 574­585, 2021. [21] C. E. Rasmussen and C. K. I. Williams, Gaussian processes for machine learning, ser. Adaptive computation and machine learning. MIT Press, 2006. [22] D. Duvenaud, "Automatic model construction with gaussian processes," Ph.D. dissertation, 2014. [23] I. Steinwart and A. Christmann, Support vector machines, 1st ed., ser. Information science and statistics. Springer, 2008.

