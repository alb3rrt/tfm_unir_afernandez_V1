Timing configurations affect the macro-properties of multi-scale feedback systems

Patricia Mellodge Electrical & Computer Engineering
University of Hartford mellodge@hartford.edu

Ada Diaconescu Computer Science & Networks
Telecom Paris, LTCI diacones@telecom-paris.fr

Louisa Jane Di Felice Institute of Environmental Science & Technology
Autonomous University of Barcelona louisajane.difelice@uab.cat

arXiv:2106.01651v1 [eess.SY] 3 Jun 2021

Abstract--Multi-scale feedback systems, where information cycles through micro- and macro-scales leading to adaptation, are ubiquitous across domains, from animal societies and human organisations to electric grids and neural networks. Studies on the effects of timing on system properties are often domain specific. The Multi-Scale Abstraction Feedbacks (MSAF) design pattern aims to generalise the description and understanding of multiscale systems where feedback occurs across scales. We expand on MSAF to include timing considerations. We then apply these considerations to two models: a hierarchical oscillator (HO) and a hierarchical cellular automata (HCA). Results show how (i) different timing configurations significantly affect system macroproperties and (ii) different regions of time configurations can lead to the same macro-properties. These results contribute to theory, while also providing useful insights for designing and controlling such systems.
Index Terms--Multi-scale feedback systems, time scales, oscillator, hierarchical cellular automata, micro-macro behaviour
I. INTRODUCTION
Multi-scale systems are those systems where different scales of time, space, or information granularity interrelate via information flows. If information cycles through the system leading to the adaptation of system entities, they become multi-scale feedback systems [42]. For example, workers in an organisation send information about their state to their managers, who then send back commands leading to changes in their behaviours. Similarly, foraging ants lay pheromones, forming a trail that affects their behaviour. In autonomic systems, managed resources are monitored and control commands issued for self-adaptation [28]. In these examples, information from the micro-scale (workers, ants, resources) is abstracted onto a macro-scale, and some adaptation at the micro-scale occurs based on information flowing back down. Such feedback cycles can be repeated at recursively higher scales, with increasing abstraction tied to ever larger system parts, e.g., multi-level management organisations, autonomic systems [32],[47], or plants `controlling' foraging ants to disperse their seeds, by attaching food packages to their grains [40]. In this paper, we use both level and scale to express the idea of multiple amounts of time, space, or information granularity in a system.
While multi-scale feedback systems can be found across all domains, their generic properties remain under-explored. In previous work, we introduced the Multi-Scale Abstraction

Feedbacks (MSAF) design pattern, as a means to generalise feedback cycles of information flows operating at multiple abstraction levels, in systems with different types of entities, structures, and functions [10][9]. In this pattern, scales are identified in relation to information abstraction and are orthogonal to how such abstractions are implemented. A macroproperty at a higher scale can be tied to an exogenous macroentity (e.g., a manager in an organisation, different from the workers) but can also be micro-distributed among microentities at a lower scale (e.g., knowledge of power relations distributed across members of an animal society [21]), or composed from the collective structure of micro-entities (e.g., forest patch shapes affecting tree growth [18]). Such multiscale design allows coordinating increasingly large-scale systems, via a divide-and-conquer approach. Each scale may process similar amounts of information by making a different trade-off between information accuracy and control scope.
Another important trade-off is between a system's reaction time and the control scope considered, at different scales. Such timing aspects depend on inherent communication and processing delays, process execution frequencies, and adaptation lags (i.e., how long before adaptation takes effect). The question of how such timing configurations affect the behaviour of multi-scale systems, in particular, has been approached primarily in domain-specific ways. General insights that would facilitate cross-domain transfer remain vague and untested. E.g., it is often said that higher levels must operate slower than lower ones, to ensure system stability [48], [32], [47]. Yet, excessive communication delays between macro- and microscales can cause dysfunction depending on system goals [20].
This paper aims to reduce the gap between highly generic remarks and application-specific practices in matters of time concerns. First, we expand the MSAF pattern with domainindependent time-related aspects (sec. III). We then illustrate the impact of chosen timing aspects on system macroproperties via two generic case studies with multiple potential applications (secs. IV and V). The studies expand previous multi-scale oscillator models: a biochemical model of hierarchical oscillators (HO) [29] and a hierarchical cellular automata (HCA) [11]. We focus on these examples as many real-world systems are characterised by oscillating patterns, from collective behaviour in animal groups [15] [37] and circadian cycles in the brain [27] to opinion dynamics in social

networks [38], clock synchronisation in distributed computing systems, and the coupled motion of pendulum clocks [13].
The contribution of our results is two-fold. First, we show how different timing configurations can significantly affect system macro-properties. This allows using time delays as configuration parameters for changing system behaviours. Second, we show how different regions of time configurations lead to the same macro-property. This can be used to improve system robustness to time disturbances. These general principles are relevant to domain practitioners, as key factors to be considered when modelling, designing, configuring, or managing multi-scale feedback systems within each specific domain.
II. BACKGROUND & RELATED WORK
A. Timing in Multi-Scale Systems
The role of timing in multi-scale systems has been explored mostly in either domain-specific ways (e.g., hierarchical smart grids [43], houses [3] and vehicles [1]) or in generic terms (e.g., multi-level design patterns in self-adaptive systems [47], autonomic systems [32], organic computing (OC) [41], selfaware systems [12], and multi-agent systems [34]). In both cases, results are difficult to reuse and transfer across domains. It is generally considered that lower levels should execute faster than higher ones. While this applies to most systems, the underlying constraints and variants are rarely discussed. Exceptions may also exist depending on desired behaviour (e.g., stock markets may not aim to reach steady state).
Similar examples can be found in natural system studies. In the field of ecology, multi-scale systems are usually nested. As macro-properties at higher levels arise from the composition of levels below, it is often taken for granted that higher levels operate slower than lower ones, and that this is necessary for system stability [2]. Similarly, research in biology and paleontology that has focused on nested hierarchies assumes that different timescales (with higher levels operating slower than lower ones) are inherent to such systems [44]. Institutional and policy studies, on the other hand, tend to focus on multiscale systems with exogenous macro-entities (e.g., higher-level bureaucracies send commands to lower ones). Here, delays are often described as dysfunctional, as they can lead to policy ineffectiveness (as upper levels send out-dated commands to controlled resources) [6] [33] [46]. Building on the examples of coral reef formation and power dynamics in Macaque societies, [20] argue that slow variables (at the macro-scale) lead to the adaptation of micro-entities by reducing environmental uncertainty, but that if these variables are too slow, they cannot be detected by micro-entities, leading to a slow variable lock-in. The fact that the slowness of macro-entities allows for them to be perceived as constant by micro-entities is also highlighted by [17] in the context of adaptive neural code, showing how in the vision system of flies adaptation occurs at different timescales, with longer ones providing a separate information transmission channel. [5] links organism motor functions to primitive language, indicating that macroproperties (or `symbols') allow to delay immediate reactions

to external changes, so as to take into account previous experiences and generate more complex behaviours.
The control systems community has studied timing in multiscale systems using different terminology, e.g., hierarchical, singularly perturbed, multiloop, nested, and cascade control systems. Hierarchical control systems are addressed in [19], where hierarchies are defined by functions or time horizons of the multilayer configuration. The highest layer necessarily has the longest time horizon to achieve optimal control for the system. Applications of singular perturbation theory to control systems were reviewed in [31], where systems are decomposed into parts with fast and slow dynamics. Multiloop [8], nested [4], and cascade [22] systems generally refer to systems in which multiple feedback loops control variables of importance at different scales. For example, in aerospace applications the different loops address (from micro- to macro-scale): attitude, attitude rate, and guidance. In these applications it is generally assumed that higher levels (corresponding to outer loops in the nested system) operate at a slower rate, or that it can be shown in specific situations what the relative rates should be for stability and optimal performance.
B. Coupled Oscillators
Our two case studies build on existing models of coupled oscillators. Kim et al.'s model [29] explores the synchronisation of coupled biochemical oscillations in cellular systems. Synchronisation is affected by the coupling strength, with two thresholds defining three different behaviours: oscillation without synchronisation, oscillation with synchronisation, and no oscillation. We expand on this model by connecting oscillators in multi-scale configurations, and adding micro-macro communication delays that affect synchronisation (sec. IV).
For the HCA case, we expand on the model in [11], where Cellular Automata (CAs) were organised in a multiscale configuration, generating macro-structures from uniform micro-scale conditions. We expand on this model to explore how different combinations of execution frequencies at various scales affect micro and macro oscillating behaviours (sec. V).
As highlighted in [35], natural oscillatory processes tend to follow a multi-scale organisation, with macro-scale frequencies affecting micro-scale behaviour. In most oscillators, communication and adaptation are not instantaneous [39] [16]. E.g., biological systems require a minimum interval to transmit information [7]. The same applies to most artificial systems. Hence, time-related questions are relevant both in the context of oscillator behaviour, within a wide range of applications, and for multi-scale feedback systems, more generally. Several studies discussed the impact of time delays on the behaviour of coupled oscillators (e.g., [7] [26] [30]). These studies suggest that time delays can significantly affect system dynamics [14].
III. MSAF DESIGN PATTERN & TIME EXTENSIONS
A. Overview of the MSAF Design Pattern
The MSAF design pattern [10] [9] models feedback loops in multi-scale systems in terms of information flows that merge, split, and cycle through different abstraction levels

macro micro

Abstract state to Lk+1

macro micro

State info abstraction

Info processing
Adaptation

Lk+1 Control from
Lk+1
Lk Control info reification
Lk-1

Fig. 1. MSAF Feedback Loops: all arrows are information flows; each level
Lk is a macro level relative to the one below Lk-1 (except for bottom level, L0) and a micro level for the one above Lk+1 (except for top level, LM-1)

(Fig. 1). Information flows are streams of changes (attached to a material substrate) which can be observed, interpreted, and used for adaptation in line with semantic definitions of information [25].
Such information flows merge and aggregate information at increasingly higher abstraction levels (bottom-up), then split and reify information again at more detailed levels (top-down), forming multi-scale feedback cycles.
A single feedback loop consists of the following steps: 1) collection and abstraction of state information; 2) information processing (e.g., decision); 3) information reification (control command); and 4) adaptation. These steps match existing feedback designs in autonomic (MAPE-K) [28] and organic computing [41], or feedback control systems [23].
Extending this design to multiple scales implies adding further feedback loops on top of each other. This involves two extra steps for connecting feedback loops between levels (in green): a) sending state abstraction of Lk to upper level Lk+1; and b) receiving control information from Lk+1, to be used as control input, or goal, in Lk's processing step (2). From Lk's perspective, all upper-level feedbacks can be modelled as a single one (dotted green arrow), at Lk+1; and all lower levels as one adaptation process (dotted blue arrow), at Lk-1.
Hence, a managed resource (at L0) receives feedback controls that merge information from several scales, covering increasingly larger system scopes. Such multi-scale feedback design helps to control large-scale systems by limiting the amount of processed information at each level and by mixing quick local reactions with slower coordinated responses.
B. Time Considerations in Multi-Scale Feedback Loops
Generalising from feedback systems [23] and control theory [36], we distill several key timing considerations impacting system behaviour: communication delay; processing time; adaptation lag; sample time (for digital systems). To simplify, we merge these into two main timing aspects, applicable to all MSAF steps: i) execution delay ( ), the step execution duration (including communication and processing); and ii) execution interval (t), how often the step executes. We group MSAF steps (1-3) (abstraction, processing, and control) into a single `management flow' (including inter-level abstraction

(a) and control (b) for higher levels), featuring an execution delay mng and interval tmng. The adaptation step (4) also features an execution delay adpt and interval tadpt.
All timing considerations from `classic' feedback control systems apply here. We highlight some of these below without aiming for a comprehensive review. Delay in the management flow mng implies the risk of providing a control command (output) based on an outdated monitored state (input). It may lead to oscillations, longer settling times, or instability [23]; and decrease reactivity to state disturbances. Yet, if mng << adpt there is a risk of overreaction from the management flow, i.e., repeating or exacerbating a control command as it fails to perceive the effects of a previous command. This risk is removed when controls are not `cumulative' (e.g., goaloriented commands can be repeated with the same effect).
With respect to execution intervals, the smaller the tmng (i.e., the management flow executes more often), the more reactive it can be to state changes, while again, risking to overreact if it executes before previous controls take effect. Overreaction is avoided if adpt < mng (also considering delays); or when controls are merely repeated (without increased amplitudes) and the adaptation flow only executes the last one (if adpt > mng). Ideally, the management flow would be fast to execute (mng  0) but only execute at intervals large enough to allow for the effects of its commands to take effect in the adaptation flow (mng  adpt). Other combinations of execution delays and intervals are also viable (domain and application-specific).
The above considerations become more complex when feedback cycles extend across multiple scales, incurring further cross-scale delays and combinations of their relative values. When management flows at different scales execute in parallel (common case), each flow at Lk gets abstract state information from Lk-1 and control information from Lk+1, to issue commands back to Lk-1. For Lk, information from Lk-1 is more recent than from Lk+1, as the latter would have crossed at least an extra scale. Yet, information from Lk+1 includes abstractions about broader system scopes (under control levels from Lk+1 to LM-1). This allows Lk managers to coordinate their local actions based on wider system views. Hence, control information for L0 entities merges information flows from all system scales, with lower-scales information being narrower but more recent (or accurate) and higher-scales information being broader but more outdated.
Hence, higher-level management flows would have larger delays than lower ones, as it takes more time for their input and output flows to travel to and from L0. This situation is due to system implementation constraints (i.e., inherent communication and processing delays, at each level), rather than being a desirable system design property. Still, in case of rapid management relative to adaptation delay (mng<<adpt) it makes sense to execute higher managers less often than lower ones (mng,k>mng,k-1), to avoid overreactions or instability. However, increasing mng,k may decrease the system's coordinated responses. Typical solutions combine fast, accurate, localised reactions from lower-scales, for avoiding

Fig. 2. Coupled oscillators with PP coupling (a) and NN coupling (b).

disaster (e.g., reflexes in organisms, obstacle avoidance in autonomous cars) with slower, more context-aware responses, for coordinated behaviour (e.g., strategic planing in organisms, rerouting autonomous cars). Various combinations of crosslevel execution delays and intervals lead to different system behaviours (macro-properties). We focus on a few examples illustrated via our two applications (HO and HCA).

IV. BIOCHEMICAL OSCILLATOR MODEL
A. HO Overview
We use the coupled biochemical oscillator model from [29] which is extended to: i) a flat network of more than two coupled oscillators; and ii) a hierarchy of oscillators (HO). In coupled biochemical oscillators, each oscillator consists of two interacting components X and Y , with coupling between the X components as shown in Fig. 2.
To accommodate multiple oscillators, we generalise this model to include more oscillators arranged in a "flat" configuration (i.e., where all the oscillators are peers and there is no hierarchy present in the network). Fig. 3(a) shows this system with four oscillators, which can have either P or N type coupling. Each Xi promotes or inhibits Xi+1 depending respectively on P or N type coupling.
The HO uses a repetitive design, with oscillators being the entities repeating at different levels. When integrated within a multi-scale structure, these entities differ from their standalone forms by taking into account (detailed) state information from the lower levels and (abstract) control information from the upper levels. The macro-entities are oscillators whose models are modified from [29]. Fig. 3(b) shows the structure of the hierarchy of oscillators for three levels with two children per oscillator. The coupling occurs between the X components of the oscillators between levels. There is no direct communication between oscillators at a given level.

B. Flat and HO Models

The flat network of oscillators is modeled by the following differential equations; for i = 1..N , where N is the number of oscillators and i - 1 is within the range 1..N (so if i = 1, then i - 1 = N ). It is assumed that all oscillators are coupled with the same strength F , type P or N, and time delay  .

dXi =

1 + P P (F Xi-1(t -  ))3

dt

1 + (F Xi-1(t -  ))3 +

Yi (t-2) 0.5

3 ...

(1)

. . . - 0.5Xi(t) + 0.1

Fig. 3. (a) A flat network with N = 4 oscillators and (b) a hierarchy of oscillators with M = 3 levels and C = 2 children per oscillator. Each oscillator consists of X and Y components. The small circles indicate either P or N type coupling between the X components of each oscillator.

Xi(t-2) 3

dYi = dt 1 +

0.5
Xi(t-2) 3 - 0.5Yi(t) + 0.1
0.5

(2)

For the HO model, the differential equations for X depend on their level. At the highest level, oscillators only act as aggregators of information from the lower level. At the lowest level, they only receive feedback from their corresponding macro-entity. Oscillators at middle levels receive information from above and below. While the equation modelling the Y component of all oscillators is analogous to (2), those for the X components of the bottom, top, and middle levels respectively are:

dX0,i = dt 1 +

1 + P P F0X1,p0,i (t - 0) 3

F0X1,p0,i (t - 0) 3 +

Y0,i (t-2) 0.5

3 ...

. . . - 0.5X0,i(t) + 0.1

(3)

dXK,0 = dt 1 +

1 + P P FK X¯K,0(t - K ) 3

FK X¯K,0(t - K ) 3 +

YK,0 (t-2) 0.5

3 ...

. . . - 0.5XK,0(t) + 0.1

(4)

dXm,i =

1 + P P (Fmm,i(t - m))3

dt

1 + (Fmm,i(t - m))3 +

Ym,i (t-2) 0.5

3 ...

. . . - 0.5Xm,i(t) + 0.1

(5)

where

m,i(·) =W Xm+1,pm,i (·) + (1 - W )X¯m,i(·)

(6)

and X¯m,i(·) denotes the mean X concentration taken over the children of Xm,i; m = 0..M - 1, where M is the number of levels; i = 0..Nm - 1, where Nm is the number of oscillators in level m; pm,i is the position of the parent of Xm,i; K = M - 1; Fm is the coupling strength; m is the time delay; and W  [0, 1]. Parameters Fm and m are constant across a level and W is constant across the system.

In the HO model, the abstracted information is the average

concentration of a substance X in micro-entities given by X¯m,i(·). The feedback information that is sent down from
macro to micro is the concentration of X in the macro-

oscillator, which impacts the concentration of X in the micro-

oscillators through (3) and (5). Function m,i(t - m) in (6) communicates both the abstracted information from the lower level and feedback information from the higher level, with W controlling the relative importance of the feedback signal.

C. Simulation Time and Sequence
The oscillators are continuous time systems described by differential equations, digitized using a numerical solver. The coupled oscillator systems were simulated in MATLAB using the dde23 function to numerically solve the delay differential equations [29]. Each differential equation was solved simultaneously for specified interval of time [0, Tend], resulting in a discrete time series of X and Y concentration values.
With respect to timing aspects described in Section III-B, there is a micro-to-macro abstraction delay and macro-tomicro feedback delay, both characterised by m, which reflects the time it takes for the concentration of X to be transmitted (i.e., transmission delay, in literature). This means that the abstracted state and feedback is based on old micro-state information. These semantics simulate communication delays mng for abstracted states, with negligible adaptation delay (adpt = 0) and continuously executing feedback cycles (mng and adpt). Delays at higher levels are always higher than at lower levels due to delay accumulation.
D. Experimental Settings
A number of system configurations were simulated. Flat networks had from 4 to 11 oscillators. HOs had 64 bottomlevel oscillators arranged in two ways: M = 2 levels, C = 64 children; and M = 4 levels, C = 4 children. For each configuration a range of parameter values was used: coupling strength F = 0..8, time delay  = 1..15, and coupling (PP, NN). Each configuration was simulated for 10 runs, with the initial X values of an oscillator randomly chosen from the interval (0,1) and the initial Y values set to 1. Values of oscillation frequency, amplitude, and synchronisation time were averaged over the 10 runs.
E. Overall Behaviour
The coupled oscillator systems exhibit three basic types of emergent behaviour: unsynchronised oscillation, no oscillation, and synchronised oscillation with all levels in phase. In the case of the HO, there is an additional type: synchronised oscillation with levels out of phase. These behaviours are shown in Fig. 4 (for M = 3 levels and C = 2 children). The three stacked time series plots show the oscillator X concentrations at each level plotted together, with the top level having one oscillator, the middle level having two oscillators, and the bottom level having four oscillators.
F. Experimental Results
In flat networks, it was found that synchronisation occurred consistently in PP coupled systems having no more than 5 oscillators and for NN coupled systems having no more than 10 oscillators in the network. Furthermore, the region of the parameter space that achieved synchronisation was a relatively

Fig. 4. Different types of emergent behaviour for an HO with M = 3 levels and C = 2 children. Upper left: unsynchronised oscillation. Upper right: no oscillation. Lower left: synchronised oscillation with adjacent levels out of phase. Lower right: synchronised oscillation with all levels in phase.
small subset. To achieve consistent synchronisation in systems with more than 10 oscillators and for a larger range of F and  values, it is necessary to have a hierarchical structure.
For HO systems, we present two kinds of results relevant to our contribution (with analogs in the HCA model): the effect of system parameters on (1) generated macro patterns and (2) oscillation periods. Other results on oscillation amplitudes and synchronisation settling time are also briefly discussed.
1) Impact of time on generated macro patterns: In HO systems, Fig. 5 shows the emergent behaviour of the system for all configurations tested. In all cases, the bottom level synchronised for the middle range values of F (yellow region). For low F values, there was oscillation, but no synchronisation (light blue region). For high F values, there were no oscillations (dark blue region). The smaller hierarchy (M = 2) achieved synchronisation in a larger part of the parameter space. There are two distinct transition regions: from unsynchronised to synchronised oscillations and from synchronised oscillations to no oscillations. The transition from synchronised to no oscillations was deterministic. For both PP systems, oscillations only occurred for 0  F  3.5. This transition was unaffected by time delay. In contrast, for both NN systems, the transition from oscillations to no oscillations occurred for F between 3 and 6, depending on the value of time delay. The transition from unsynchronised to synchronised oscillations was stochastic, as indicated by the color transition from light blue to yellow: yellow, synchronisation happened in each run; light blue, it did not happen in any run; in-between colors, synchronisation occurred only in some runs, according to the color scale to the right of the plot.
2) Impact of time on oscillation periods: Fig. 6 shows how the period of oscillation varies with the coupling strength and time delay. Time delay has a larger impact on the period for PP coupled systems while the effect is negligible for NN coupled systems. The number of levels had no effect on the period.

Fig. 5. Each plot shows the emergent behaviour for F = 0..8 and  = 1..15. Colors indicate regions in the parameter space where different behaviours occur: Dark blue, no oscillations; yellow, synchronised oscillations (with levels in or out of phase); light blue, unsynchronised oscillation; color gradients from yellow to light blue, synchronisation only in some runs.
Fig. 6. Each plot shows the oscillation period for F = 0..8 and  = 1..15. Upper left: M = 2 levels, C = 64 children, PP coupling. Upper right: M = 4 levels, C = 4 children, PP coupling. Lower left: M = 2 levels, C = 64 children, NN coupling. Lower right: M = 4 levels, C = 4 children, NN coupling. Zero values means there is no oscillation in that region.
Oscillation amplitude varies with time delay within the synchronised region, with a larger impact occurring in NN systems (in contrast to the effect on period). The number of levels (M = 2 and M = 4) had a negligible impact on amplitude; but fewer levels lead to faster synchronisation, for both PP and NN coupling. The effect of time delay on synchronisation time is more pronounced for NN coupling. Full results are omitted due to space constraints (Cf. https://gitlab.telecomparis.fr/ada.diaconescu/msaf (acsos21 directory)). G. Discussion
These results show the effect of time delay on the system's macro patterns and their properties. For NN coupling  affects the type of synchronisation, but not the amplitude. Conversely for PP coupling,  affects the oscillation period, but not the synchronization type. For both types, the number of levels M affects unsynchronised to synchronised transition, due to the

increased time delay caused by larger M . Further these results indicate that HO systems are advantageous compared to flat networks: (1) HO systems are able to synchronise more oscillators: 64 oscillators for HO, compared to a maximum of 5 and 10 for flat network (with PP and NN, respectively). (2) The desired synchronisation behaviour occurs in a larger region of the parameter space as noted by the large yellow regions in Fig. 4. In contrast, at their maximum size, flat networks achieved synchronisation for a single combination of coupling strength and time delay. (3) Due to their large synchronised region, HO systems are more robust to parameter variations. Moreover for NN coupling, a change in one parameter (time delay) can also be compensated by changing another parameter (coupling strength) to achieve synchronisation without affecting the amplitude.
V. HIERARCHICAL CELLULAR AUTOMATA CASE STUDY
A. HCA Overview
Cellular Automata (CA) are discrete models where the state of each entity (cell) at t depends on the cell's previous state and on its neighbours' states, at t-1. Cells are usually arranged in a grid and their inter-dependency modelled via a rule set. CA, including coupled CA, have been employed to model a wide range of complex systems, including multiscales [24]. To analyse timing effects on such multi-scale systems, we reuse the Hierarchical Cellular Automata (HCA) simulator in [11]. It organises multiple CA into several scales (levels). Cross-level CA interactions follow the MSAF pattern: a) abstract state-information (bottom-up); and b) control commands, or goals (top-down). Each CA (except the top) has two rule sets: Expansive rules (RE) increase the CA's number of live cells; Regressive rules (RR) decrease them. The control goal from above dictates the CA's active rules (to execute). CAs at different levels have different RE-RR rule-pairs.
Each CA at a lower level Lk is mapped bidirectionally to a single cell of a CA at a higher level Lk+1. In the bottom-up mapping (a), the entire state of a lower CA is abstracted (based on the percentage of its live cells relative to a threshold T hk) and sets the binary state of its mapped cell in a higher CA. In the top-down mapping (b), the state of each cell in a higher CA controls the rule activation of its mapped lower CA (i.e., sets RE or RR). These bidirectional interactions form inter-level feedbacks, replicated at successive levels, up to the top (which only executes static rules). Simulations are deterministic.
B. HCA Notation & Inter-level Mapping
Table I summarises the main HCA concepts and notations (details in [11]). HCA consists of several levels (Lk), each with one or several CA (CAk,i) (Fig. 7). Each CAk,i at a micro-level is mapped bidirectionally to one cell Ck+1,j,s of a CAk+1,j at the macro-level: (a) the state abstraction (ASk,i) of CAk,i (micro) is set as the state (CSk+1,j,s) of its mapped cell Ck+1,j,s (macro) (Eq. 7 and Eq. 8); and (b) the control goal (Gk,i) from the cell state CSk+1,j,s (macro) sets the active rule of its mapped CAk,i (micro) (Eq. 9 and Eq. 10).
CSk+1,i  ASk,i , i = 1..Nk , map(Ck+1,i; CAk,i) (7)

Notation Lk C Ak,i
CAk,i  < state > C Sk,i,s
ASk,i T hk Gk,i Rk,i map(Ck,i,s ; CAk-1,j ) F qk
F q = ...

Description Level k, with k = 0..M -1, M the N of HCA levels
Cellular Automata i at level Lk, i = 0..Nk-1, Nk the N of CA at Lk CAk,i converges to steady state < state >: either OP (oscillate with period P ) or SX (stuck with X live cells) State of Cell Ck,i,s of CAk,i (Sk,i cells), s=1..Sk,i CSk,i,s  {0, 1}, 0  false/dead, 1  true/live Abstract State of CAk,i, ASk,i  {0, 1} Threshold for calculating Abstract States of CAk,i at Lk Goal of CAk,i; Gk,i  {0, 1} Active Rules (executing) of automaton CAk,i Mapping between cell Ck,i,s and automaton CAk-1,j ; implies transfer of abstract state (up) & cntrl. goal (down)
Activation frequency of level Lk­ the number of activations of Lk after which CAk,i actually execute Rk,i. Activation frequency pattern across HCA levels;
E.g., F q= 1-2-3 means that F q0=1, F q1=2, F q2=3 TABLE I
MAIN HCA CONCEPTS AND NOTATIONS

Fig. 7. 3-level HCA, with 3 differentiated states at L0: 4x Corners CACr (purple), 16x Borders CABo (green), 12x Core CACo (cyan)
Fig. 8. Diamond Rules: a) RE for L0 &L1; b) RR for L0; (c) RR for L1

ASk,i =

1, 0,

if

Sk,i s=1

C Sk,i,s

>=

T hk

otherwise

(8)

Gk,i  CSk+1,i, map(Ck+1,i; CAk,i)

(9)

Rk,i =

Rk,E (Expansive rules), Rk,R (Regressive rules),

if Gk,i == 1 if Gk,i == 0

(10)

C. Simulation Time & Sequence
A HCA simulation proceeds in discrete cycles, each one executing all levels successively, from bottom L0 to top LM-1. A cycle consists of M discrete steps tk (k=0..M-1), each one executing all CAs at a corresponding level Lk. Each CAk,i in an active level Lk: i) exchanges information with its macroCA; (sends ASk,i, Eq. 8; gets Gk,i, Eq. 9); ii) sets its active rules (Rk,i) depending on its goal (Gk,i, Eq. 10); and, iii) steps (executes its active rules). As exceptions, CA0,i (bottom) do not get abstracted states from below, using their previous state instead; and CAM-1 (top) do not get goals from above, using a static rule. During a step tk, all CAs at Lk execute in parallel; the step ends when all CAk,i have finished executing.
With respect to timing aspects in subsec. III-B, HCA considers state abstraction delays as negligible; and controls incurring delays of one cycle between each two levels (i.e., mng,k=1 cycle). Hence, abstract state is always up to date (i.e., travels across all levels in one cycle) yet controls take M steps to arrive from top to bottom. Adaptation delay is also negligible (adpt=0). Each level has an activation frequency (F qk) (i.e., execution interval mng,k): F qk=d means that Lk only activates at every d cycles. Finally, control commands Gk are cumulative (repeating them exacerbates the effect), yet do not increase their values if inactive micro-CAs ignore them.

analysis, we only experiment here with inversible rule-pairs: from any CA state, executing RE and RR (or RR and RE) leads to the same state. Non-inversible rules were exemplified in [11]; results presented here do not apply to these.
All experiments start with CAk,0 in the same initial state, executing R0,E; and CA1 and CA2 in dead state (sending G=1 control goals until first changing to live states). Experiments vary in configurations for: the two thresholds (T h0 and T h1) for calculating abstract states for L1 and L2 (Eq. 8); and the three activation frequencies (F q0, F q1 and F q2), setting the delay between subsequent level activations (for L0, L1 & L2).
To show the rule-independence of our results, we tested two inversible rule-pairs at L0: 1) Diamond (Fig. 8: (a) RE & (b) RR; non-toroidal), with CA0,i initialised with one central live cell, generating an expanding and regressing diamond shape (Fig. 9-top); and 2) Line (RE: cell `dead'  `live' if at least one live neighbour, and RR: cell `live'  `dead' when less than 4 live neighbours; toroidal), with CA0,i initialised with a central horizontal line of live cells, generating a verticallyexpanding and -retracting rectangle (Fig. 9-bottom).
For CA1 we always use a non-inversible rule-pair (Fig. 8: (a) RE & (c) RR), which generates four possible states (Fig. 10): Null (0 live cells); Core (12 live cells); Cross (28 live cells); Full (32 live cells). L2 has a single rule-set, inversing the current state (i.e., live  dead; dead  live).
We define three experimental sets, with T h0=0.1 (i.e., 10% live cells) and T h1  {0.3, 0.7, 0.9}. These three values fall

D. Experimental Settings
We set-up a three-level HCA: L0 (bottom), L1 (middle) and L2 (top), Fig. 7. L0 has 32 CAs (4x8 matrix), of 441 (21x21) cells each. This maps to a 32 (4x8) cells CA at L1; which maps to a one-cell CA at L2. To simplify HCA behaviour and

Fig. 9. 21x21 CA States: expand left-to-right, RE ; regress right-to-left, RR Diamond (top): generates 20 states, with N of live cells: 1, 5, 13, 25, 41, 61, 85, 113, 145, 181, 221, 261, 297, 329, 357, 381, 401, 417, 429, 437, 441; Line (bottom): 11states: 21, 63, 105, 147, 189, 231, 273, 315, 357, 399, 441

Fig. 10. L1 States: expand left-to-right (RE ): Null  Core  Cross  Full; regress right-to-left (RR): Null  Core  Full (skip Cross, non-inversible)

in-between the four CA1 states; all other values are redundant (i.e., same results). Within each set, we run tests with varying activation frequencies: F q0=1..2, F q1=1..5, F q2=1..5. A test with e.g., F q=1-3-5 means that F q0=1, F q1=3, F q3=5. This means about 300 tests (2 rules x 3 T h1 vals. x 50 F q vals.).
E. Overall Behaviour
A finite CA can only converge () to three behaviours: i) dead (S0), all cells set to 0; ii) live-stuck (SX ), blocked in a state with X live cells (set to 1); iii) oscillating (OP ), cycling through a set of states, with the state sequence repeating every P steps. At L0, a CA0,i's behaviour depends on the goal pattern received from L1 (i.e., 1 & 0 sequence activating RE & RR). If a goal pattern has more 0s than 1s, activating RR more than RE, then CA0,iS0. If RE activates more than RR, then CA0,iS441. For `balanced' RE &RR patterns, CA0,iOP .
Superposing goal patterns from CA1's four states differentiates CA0,i into a maximum of three groups (Fig. 7): 1) Core CA0,Co, the 12 CA0,i at the core of L0's 4x8 matrix; mapped to the 12 live cells in CA1's Core state; 2) Corner CA0-Cr, the 4 CA0,i at the corners of L0's matrix; mapped to the 4 dead cells in CA1's Border state; and 3) Border CA0-Bo, 16 remaining CA0,i on the borders of L0's matrix (no corners).
In brief, CA0,i have an expanding or regressing tendency (i.e., growing or shrinking N of live cells) depending on the active rule set, RE or RR, respectively. When crossing T h0, this tendency is propagated (and accentuated) upwards through CA1. When crossing T h1, it reaches CA2, which inverses it. The inverse tendency is propagated downwards, back to CA0,i, which crosses T h0 the other way. The propagation process is repeated upwards with the opposite tendency, then inverses again at CA2. This creates an expansion-regression oscillation across levels. Because CA1 executes its own rule-pair (R1,ER1,R), CA0,i differentiate, following different behaviours and converging to different states (e.g., 3 CA0,i states in Fig. 7).
F. Experimental Results
We present two main kinds of results, relevant to our contribution. Firstly, we show how different activation frequencies constrain the possible oscillation periods P that may occur at HCA levels. We also note that many frequency combinations generate the same oscillation period P (macro-property), though not necessarily through the same state set. Secondly, we show how different activation frequencies lead to different macro-patterns amongst CA0,i, i.e., whether CA0,Co, CA0,Bo, CA0,Cr converge to OP , S0 or SX . The full results set is available from https://gitlab.telecomparis.fr/ada.diaconescu/msaf (acsos21 directory).

Fig. 11. Diamond oscillations: T h0=0.1, T h1=0.7, F q0=1, F q1&F q2=1..5

1) Impact of time on oscillation periods: Fig. 11 summarises results for Diamond rules, with T h0 = 0.1, T h1 = 0.7, F q0 = 1; and F q1 & F q2 varying between 1 and 5. At L0, some CA0,i oscillate (same OP ) and some end in a static state (S0 or S441). To simplify, we only show here the OP value for CA0,is that do oscillate; and discuss differentiated CA0,is (i.e., macro-patterns) in the next subsection. Equivalent results were obtained for F q0=2, in terms of obtained OP types.
Results show clear correlations between activation frequencies (F q pattern) and ensuing OP s. We generalise these via unifying formulae (Eq. 11 & 12), deduced from empirical
analysis. We note that in `common' cases (green in Fig. 11), P is the double of the maximum frequency among levels (Eq. 11-upper for P0 & P1 and Eq. 12-upper for P2). E.g., for F q {1-3-1, 1-3-2, 1-3-3}, we get oscillations with P = 6 (O6) at all levels. In `exceptional' cases (red in Fig. 11), P is a multiple of the lowest common multiplier (LCM) of all frequencies (Eq. 11-lower for P0 & P1 and Eq. 12-lower for P2). In such cases, we have parameters a = 2 and b = 2 in Eq. 11 & 12. E.g., F q=1-3-4 gives P0=P1=24 (LCM=12, b=2) and P2=8; F q=1-4-3 gives P0=P1=8 and P2=24. Intuitively, it makes sense for Pk to be some multiple of F qk, where this multiple may depend on the other F ql (l = k).

P0 = P1 =

a  F q1, if F q1 F q2 b  LCM (F q0, F q1, F q2), if F q1 < F q2
a, b  N>0 \ {1} (11)

P2 =

a  F q2, if F q2 F q1 b  LCM (F q0, F q1, F q2), if F q2 < F q1

(12)

a, b  N>0 \ {1}

Similar results were obtained when increasing T h1 to 0.9. The main difference was that for F q=1-3-4, we obtained O12 at all levels, hence a=b=1; rather than O24-O24-O8 as when T h1=0.7. Results for T h1=0.3 were also similar, the only difference occurring for F q  {1-4-5, 1-2-3}, where the HCA  S0. Using Line rules produced equivalent Ok,P types, when testing the same configuration ranges. A difference here is that the toroidal configuration means that a CA0,i that grows (RE) to all live cells can no longer regress (RR), hence

staying in S441. E.g., for F q0=1, F q1=5, F q2=1..5, we have CA0,iS441, for all threshold combinations tested.
2) Impact of time on generated macro patterns: At L0, macro-patterns occur as different behaviours (e.g., S0, SX , OP ) in the three CA0,i groups: CA0,Cr (corners), CA0,Bo (borders), and CA0,Co (core). Different F q patterns generate different macro-patterns (CA0,Cr-Bo-Co). E.g., for Diamond rules with T h0=0.1, T h1=0.9, we test all frequency combinations having at least one F qk=3 (i.e., 19 cases) to obtain O6 (or multiples) at L0. This distinguishes three configuration sets, producing three macro-patterns: i) for F q  {1-1-3, 2-1-3, 31-2, 3-1-3} (4 cases), we get CA0,Cr-Bo-Co  S0-O6-S441 (i.e., CA0,Cr  S0, CA0,Bo  O6, CA0,Co  S441); ii) for Fq  {3-2-1, 3-2-2} (2 cases), CA0,Cr-Bo-Co  O12-O12-S441; iii) for the other combinations (13 cases), CA0,Cr-Bo-Co  O6-O6-S441.
Similarly, for Line rules with e.g., T h0=0.1, T h1=0.3 and F q patterns with at least one F qk=3 (19 cases), we obtain four configuration sets producing four macro-patterns: i) for F q  {1-1-3, 3-1-1, 3-3-1, 3-3-2, 3-3-3} (5 cases), we get CA0,Cr-Bo-Co S0-S0-O6; ii) for F q=2-1-3 (1 case), CA0,Cr-Bo-Co  S0-S0-S0; iii) for F q  {3-1-2, 3-1-3, 32-1, 3-2-2, 3-2-3}, CA0,Cr-Bo-Co  S0-O6-S441; and iv) for the rest (8 cases), CA0,Cr-Bo-Co  S0-S0-S441.
G. Discussion
Results on the impact of activation frequencies on the resulting behaviour show how oscillation periods P can be controlled via timing adjustments. Interestingly, Pk only depends on cross-level activation frequencies (Eqs. 11 & 12), while the actual (inversible) rule-pairs and threshold configurations only impact the state set that such oscillations cycle through; and the CA0,i macro-pattern. Also notably, a wide range of frequency combinations lead to similar oscillation behaviour, e.g., all combinations with a maximum frequency of 2 lead to O4 forms; maximum F q of 3 lead to O6 forms (and sometimes multiples, e.g., O12); maximum of F q=4 to O8 (and multiples, e.g., O12, O24); and maximum of F q=5 to O10 (and multiples, e.g., O20, O30). These are important properties for obtaining generic oscillations (OP ), while being robust to certain disturbances (e.g., in thresholds or frequencies).
Results on CA0,i macro-pattern formation show how varying frequencies can lead to equivalent oscillation periods at L0 (as above) yet occurring via different CA0,i groups. Hence, activation frequencies become configuration parameters for shifting overall system behaviour (i.e., macro-pattern productions). As above, different frequency configurations can lead to the same macro-pattern, which can enhance robustness.
VI. DISCUSSION, CONCLUSIONS & PERSPECTIVES
This paper aimed to narrow the gap between highly general statements and domain-specific theory about timing in multiscale feedback systems. It highlighted cross-domain timing aspects, e.g., time delays and execution intervals, and their (combined) impacts on resulting system behaviour (macroproperties). Some of these phenomena were illustrated via

two multi-scale oscillator simulators (hierarchical biochemical oscillators (HO) and cellular automata (HCA)) which are both generic and applicable to various domains.
Experimental results from both examples show how timing confers a configuration parameter just as powerful as any other variable. Changing delays or execution intervals, in various cross-scale combinations, generates different outcomes, e.g., synchronisation type in HO; oscillation period and differentiation pattern in HCA. Several time configuration regions produce equivalent macro-behaviours, possibly improving system robustness to time disturbances. This may benefit applications that require rapid behavioural plasticity, without re-learning or reconfiguring other parameters (e.g., neuro-modulated artificial neural networks [45]). This contribution sets a basis for developing a comprehensive theory of timing in multi-scale feedback systems, helping practitioners to transfer and apply key insights across specific domains.
REFERENCES
[1] J. Albus et al. 4DRCS: a reference model architecture for unmanned vehicle systems version 2.0. Tech. rep. National Institute of Standards and Technology, 2002.
[2] T.F.H. Allen and T.B. Starr. Hierarchy: perspectives for ecological complexity. Univ. of Chicago Press, 2017.
[3] F. Allerding, B. Becker, and H. Schmeck. Decentralised Energy Management for Smart Homes. Ed. by C. Mu¨ller-Schloer et al. Springer, 2011.
[4] D.J. Allwright and W.M. Wonham. "Time Scales Hierarchical in Stably Control Nested Systems". In: IFAC Proc. Vol. 13.6 (1980), pp. 85­91. ISSN: 1474-6670.
[5] K.L. Bellman and L.J. Goldberg. "Common origin of linguistic and movement abilities". In: American Journal of Physiology 246.6 (1984), R915­R921.
[6] R.L. Brinkman and J.E. Brinkman. "Cultural lag: a relevant framework for social justice". In: International Journal of Social Economics (2005).
[7] M.Y. Choi et al. "Synchronization in a system of globally coupled oscillators with time delay". In: Physical Review E 61.1 (2000), p. 371.
[8] T.C. Coffey and I.J. Williams. "Stability analysis of multiloop, multirate sampled systems." In: AIAA Journal 4.12 (1966), pp. 2178­2190.
[9] A. Diaconescu, L.J. Di Felice, and P. Mellodge. "Exogenous coordination in multi-scale systems: How information flows and timing affect system properties". In: Future Gen. Compu. Sys. 114 (2021), pp. 403­426.
[10] A. Diaconescu, L.J. Di Felice, and P. Mellodge. "Multi-scale feedbacks for large-scale coordination in self-systems". In: Intl. Cnf. Self-Adaptive and SelfOrganizing Systems (SASO). IEEE. 2019, pp. 137­142.
[11] A. Diaconescu, S. Tomforde, and C. Mu¨ller-Schloer. "Holonic cellular automata: modelling multi-level selforganisation of structure and behaviour". In: Intl. Cnf. Artificial Life. MIT Press. 2018, pp. 186­193.

[12] A. Diaconescu et al. Generic architectures for collective self-aware computing systems. Ed. by S. Kounev et al. Springer, 2017, pp. 191­235.
[13] R. Dila~o. "Antiphase and in-phase synchronization of nonlinear oscillators: The Huygens's clocks system". In: Chaos: An Interdisciplinary Journal of Nonlinear Science 19.2 (2009), p. 023118.
[14] M.G. Earl and S.H. Strogatz. "Synchronization in oscillator networks with delayed coupling: A stability criterion". In: Physical Review E 67.3 (2003), p. 036204.
[15] B. Ermentrout. "An adaptive model for synchrony in the firefly Pteroptyx malaccae". In: Journal of Mathematical Biology 29.6 (1991), pp. 571­585.
[16] B. Ermentrout and T.W. Ko. "Delays and weakly coupled neuronal oscillators". In: Philosophical Transactions of the Royal Society A 367.1891 (2009), pp. 1097­ 1115.
[17] A.L. Fairhall et al. "Efficiency and ambiguity in an adaptive neural code". In: Nature 412.6849 (2001), pp. 787­792.
[18] E. Filotas et al. "Viewing forests through the lens of complex systems science". In: Ecosphere 5.1 (2014), pp. 1­23.
[19] W. Findeisen. Hierarchical Control Systems: An Introduction. Tech. rep. IIASA, Laxenburg, Austria: Intl. Insti. for Applied Systems Analysis, Apr. 1978.
[20] J. Flack et al. "Timescales, symmetry, and uncertainty reduction in the origins of hierarchy in biological systems". In: Evolution cooperation and complexity (2013), pp. 45­74.
[21] J.C. Flack. "Coarse-graining as a downward causation mechanism". In: Philosophical Transactions of the Royal Society A 375.2109 (2017), p. 20160338.
[22] R.G. Franks and C.W. Worley. "Quantitative Analysis of Cascade Control". In: Ind. Eng. Chem. Res. 48.6 (1956), pp. 1074­1079.
[23] J.L. Hellerstein et al. Feedback Control of Computer Systems. J. Whiley, 2004.
[24] A.G. Hoekstra et al. "Complex Automata: Multi-scale Modeling with Coupled Cellular Automata". In: Simulating Complex Sys. by CA. Springer, 2010, pp. 29­57.
[25] E. Jablonka. "Information: Its interpretation, its inheritance, and its sharing". In: Philosophy of science 69.4 (2002), pp. 578­605.
[26] S.O. Jeong, T.W. Ko, and H.T. Moon. "Time-delayed spatial patterns in a two-dimensional array of coupled oscillators". In: Physical review letters 89.15 (2002), p. 154104.
[27] T.H. Kang et al. "Circadian oscillation of nucleotide excision repair in mammalian brain". In: Proc. of National Academy of Sciences 106.8 (2009), pp. 2864­2867.
[28] J.O. Kephart and D.M. Chess. "The vision of autonomic computing". In: Computer 36.1 (2003), pp. 41­50.
[29] J.R. Kim et al. "A design principle underlying the synchronization of oscillations in cellular systems". In: Journal of Cell Science 123.4 (2010), pp. 537­543.

[30] T.W. Ko, S.O. Jeong, and H.T. Moon. "Wave formation by time delays in randomly coupled oscillators". In: Physical Review E 69.5 (2004), p. 056106.
[31] P.V. Kokotovic. "Applications of Singular Perturbation Techniques to Control Problems". In: SIAM Rev. 26.4 (1984), pp. 501­550.
[32] J. Kramer and J. Magee. "Self-Managed Systems: an Architectural Challenge". In: Future of Software Engineering (FOSE '07). 2007, pp. 259­268.
[33] T. Mangin et al. "The cost of management delay: The case for reforming Mexican fisheries sooner rather than later". In: Marine Policy 88 (2018), pp. 1­10.
[34] M. Minsky. Society of Mind. Simon&Schuster, 1988. [35] D. Monsivais-Velazquez et al. "Dynamics of hierar-
chical weighted networks of van der Pol oscillators". In: Chaos: An Interdisciplinary Journal of Nonlinear Science 30.12 (2020), p. 123146. [36] N.S. Nise. Control Systems Engineering. 8th. USA: John Wiley & Sons, Inc., 2019. [37] D.A. Paley et al. "Oscillator models& collective motion". In: Control Systems Mag. 27.4 (2007), pp. 89­ 105. [38] A. Pluchino et al. "Opinion dynamics and synchronization in a network of scientific collaborations". In: Physica A: Statistical Mechanics and its Applications 372.2 (2006), pp. 316­325. [39] J.P. Ram´irez et al. "Effects of time delay in the synchronized motion of oscillators with Huygens' coupling". In: IFAC Proceedings Volumes 45.12 (2012), pp. 159­164. [40] R. Rico-Grey and P.S. Oliveira. The Ecology and Evolution of Ant-Plant Interactions. U. Chicago Press, 2007. [41] H. Schmeck et al. Adaptivity and Self-organisation in Organic Computing Systems. Ed. by C Mu¨ller-Schloer et al. Springer, 2011, pp. 1­32. [42] H.A. Simon. "The architecture of complexity". In: Facets of systems science. Springer, 1991, pp. 457­476. [43] J-P. Stegho¨fer et al. "HiSPADA: Self-Organising Hierarchies for Large-Scale Multi-Agent Systems". In: Autonomic and Autonomous Systems. 2013, pp. 259­268. [44] J.W. Valentine and C.L. May. "Hierarchies in biology and paleontology". In: Paleobiology (1996), pp. 23­33. [45] N. Vecoven et al. "Introducing neuromodulation in deep neural networks to learn adaptive behaviours". In: PLOS ONE 15 (Jan. 2020), pp. 1­13. [46] W.A. Warren. "Hierarchy theory in sociology, ecology, and resource management". In: Society and Natural Resources 18.5 (2005), pp. 447­466. [47] D. Weyns et al. On Patterns for Decentralised Control in SAS. Ed. by R.deLemos et al. LNCS, 2013, pp. 76­ 107. [48] J. Wu. "Hierarchy theory". In: Linking ecology and ethics for a changing world (2013), pp. 281­301.

