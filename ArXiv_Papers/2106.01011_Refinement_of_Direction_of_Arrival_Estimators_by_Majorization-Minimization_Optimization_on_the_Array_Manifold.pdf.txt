© 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.

arXiv:2106.01011v1 [eess.SP] 2 Jun 2021

REFINEMENT OF DIRECTION OF ARRIVAL ESTIMATORS BY MAJORIZATION-MINIMIZATION OPTIMIZATION ON THE ARRAY MANIFOLD
Robin Scheibler and Masahito Togami
LINE Corporation, Tokyo, Japan

ABSTRACT
We propose a generalized formulation of direction of arrival estimation that includes many existing methods such as steered response power, subspace, coherent and incoherent, as well as speech sparsity-based methods. Unlike most conventional methods that rely exclusively on grid search, we introduce a continuous optimization algorithm to refine DOA estimates beyond the resolution of the initial grid. The algorithm is derived from the majorizationminimization (MM) technique. We derive two surrogate functions, one quadratic and one linear. Both lead to efficient iterative algorithms that do not require hyperparameters, such as step size, and ensure that the DOA estimates never leave the array manifold, without the need for a projection step. In numerical experiments, we show that the accuracy after a few iterations of the MM algorithm nearly removes dependency on the resolution of the initial grid used. We find that the quadratic surrogate function leads to very fast convergence, but the simplicity of the linear algorithm is very attractive, and the performance gap small.
Index Terms-- direction of arrival, optimization, majorization minimization, array signal processing
1. INTRODUCTION
Direction of arrival (DOA) estimation is a technique to spatially localize sources using an array of sensors [1]. The focus of this paper is on acoustic sound source localization, where sensors are microphones [2]. However, we note that DOA estimation is also widely applied in radar [3] and sonar [4] technologies.
There has been a tremendous amount of work on DOA over the years. Steered response power (SRP) methods create beams in multiple directions to find those with largest power [5, 6, 7]. Subspace methods, such as the famous MUSIC algorithm, identify source directions due to their orthogonality to the noise subspace [8]. An important development is that of sparsity-based methods, starting with [9]. All the methods so far operate on a grid and their accuracy is limited by its coarseness. Grid-search is costly in terms of processing power and memory to store all the steering vectors. These problems become acute for full three dimensional localization where accuracy within a degrees requires over 30000 grid points. The requirements are then multiplied by the number of frequency sub-bands and sensors used. As a mitigation, so-called off-the-grid methods combine sparse optimization with a continuous re-gridding step [10, 11]. For some special array geometries, e.g. linear, the MUSIC criterion can be solved by polynomial rooting [12, 13]. Extensions to arbitrary arrays and the wideband setting exists via array interpolation [14] and finite rate of innovation [15, 16]. Recently, several deep learning based systems have been proposed [17, 18].
Code available at https://github.com/fakufaku/doamm.

While more complex methods lead to improved accuracy and performance, classic methods such as SRP and MUSIC are reliable, easy to implement, and widely deployed in the industry. In this work, we introduce a simple algorithm to refine coarse grid estimates produced by these methods using continuous domain optimization based on the majorization-minimization (MM) technique [19, 20]. Recently, the algorithm SPIRE-MM [21] has been proposed for robust speech DOA estimation. It introduced MM optimization refinement of time-frequency bin-wise DOA estimators with a surrogate function based on a cosine inequality [22]. We propose a generalization of this MM algorithm applicable to most of the SRP and subspace based methods. We formulate the problem as the minimization of the power mean [23] of the cost at the different frequency bands. We produce two surrogate functions, one quadratic, similar to [21], and one linear. The former can be minimized efficiently by the generalized trust region sub-problem method [24], as in [21], and the latter has a closed-form solution. Both lead to iterative algorithms that are guaranteed to decrease the value of the objective. They estimate DOA vectors directly on the sphere, without any projection, and do not require hyperparameters. One iteration has the same computational cost as the evaluation of one grid point.
We study the performance of the refinement method for SRPPHAT [6] and MUSIC [8] on both simulated and recorded datasets. We find that the median accuracy with initial estimates computed on a 100-points grid is better than that of a 10000-points grid. Furthermore, the number of iteration required is around 10 for the quadratic surrogate, and 30 for the linear one.

2. BACKGROUND

We consider an array of M sensors with known locations dm  R3, m = 1, . . . , M . We work in the time-frequency domain by applying a short-time Fourier transform [25] to the input time domain signals. The signal model of the vector containing the sensor measurements at frequency band k = 1, . . . , K and frame n = 1, . . . , N , is

L

xkn =

ak(q )y kn + bkn,

(1)

=1

with xkn  CM , the th source signal y kn  C, and the noise bkn  CM . The vector q  R3 is a unit-length vector pointing towards source . In terms of colatitude  and azimuth , we have
q = cos  sin  sin  sin  cos  . The steering vectors are

ak(q) = M -1/2 ejkd1 q · · · ejkdM q .

(2)

with k

=

2

fk c

where fk

is the center frequency of the kth band

and c the speed of sound.

In the rest of this manuscript, we denote vectors and matrices

by bold lower and upper case letters, respectively. Furthermore, A

and AH denote the transpose and conjugate transpose, respectively
of matrix A. The Euclidean norm of vector x is written x = (xHx)1/2. Unless specified otherwise, indices m, k, n, and take
the ranges defined here. We use R+ to denote the set of non-negative real numbers. The (d - 1)-sphere is Sd-1 = {u | u  Rd, u = 1}. The DOA vectors belong to the 2-sphere, i.e. q  S2. Finally,
we define the unnormalized sinc function as sinc(x) = sin(x)/x.

2.1. Covariance-based DOA Estimators

Many of the conventional DOA estimators can be described as finding the local maxima, one per source, of the function,

J (q) =

K (ak(q)HCkak(q))s,

q



2
S

,

(3)

k=1

where Ck  CM×M is a Hermitian positive semi-definite matrix related to the covariance of the input channels and s is a real exponent. If we consider K = 1, this is a narrowband estimator. When working with the sum of the objectives of narrow-bands, i.e. K > 1, these methods are known as incoherent. See [1, 7] for more details.
The Steered Response Power family of algorithms is obtained with Ck = Sk, a weighted sample covariance matrix of (1),

Sk = N -1

N n=1

x~ kn x~ Hkn ,

(4)

and s = 1. The vector x~kn is a weighted version of xkn, i.e. x~mkn = wmknxmkn. Choosing wmkn = 1 or wmkn = |xmkn|-1 yield the conventional SRP or SRP-PHAT estimators [6], respec-
tively. Other weighting schemes used for the generalized cross-
correlation (GCC) [26], such as SCOT, are also possible. MUSIC [8, 12, 14] considers the covariance matrix of (1), i.e.,

Rk = E xknxHkn =

E |y kn|2 ak(q )ak(q )H + Bk,

where Bk is the covariance matrix of the noise. Now, let the

eigenvalue decomposition of Sk  Rk (with wkn = 1) be

Sk = U kkU Hk , where U k contains the eigenvectors of Sk

and k is the diagonal matrix containing the eigenvalues. MUSIC

decomposes U k into signal and noise subspaces, U k = [Gk Ek].

These

subspaces

are

assumed

orthogonal,

i.e.

E

H k

ak

(q

)

=

0,

for

all , and the estimator uses Ck = EkEHk and s = -1.

The MVDR estimator, also known as Capon, is obtained by

taking

Ck

=

S

-1 k

(with

wkn

=

1)

and

s

=

-1.

Wideband Coherent Subspace Methods, e.g., [27, 28], con-

struct an estimate of the covariance matrix at one frequency fk using the data from all K frequencies. From this estimate, they obtain

a basis Ek for the noise subspace at fk and the DOA is obtained

from

(3)

with

Ck

=

Ek

E

H k

and s = -1.

Robust Speech DOA Methods, e.g., [29, 30, 21], are ro-

bust DOA estimators exploiting the sparseness of speech signals.

Namely, they assume so-called W-disjoint orthogonality whereas

each time-frequency bin is occupied by at most one source. They

share the following general structure. First, for all k, n, compute the local DOA estimate qkn with (3) with s = 1 and Ck = x~knx~Hkn, where x~ = xkn/|xkn|. Then, compute the histogram of qkn on a
finer grid. Pick the peaks of the histogram as source locations.

2.2. MM Algorithm for unit-min-sum-cos
Definition 1 (unit-min-sum-cos). The unit-min-sum-cos problem is the minimization of a sum of cosine subject to a unit norm constraint,

min

up cos(p - bp q),

(5)

qSd-1 pP

where up  R+, p  R, bp  Rd, and P some index set.

Because Ck is positive semi-definite and ak(q) are complex exponentials, the terms ak(q)HCkak(a) from (3) are of the form (5) (up to a constant). No closed form solution to minimize or maximize
(5) exists, but MM optimization is applicable [21]. A quadratic sur-
rogate for (5) can be obtained from the following proposition [22].

Proposition 1 (Cosine Surrogate [22]). Let , 0  R, z0 = arg min |0 + 2z|, and 0 = 0 + 2z0. Then, the following
zZ
inequality holds, with equality when  = 0,
- cos   1/2 sinc(0)( + 2z0)2 - cos 0 - 1/2 0 sin 0. (6)

The MM method leads to the following iterative updates for q

qt  arg min

u^p(qt-1)(^p(qt-1) - bp q)2,

(7)

qS2 pP

where the previous iterate qt-1 is used to compute the quantities,

^p(q^)  p +  + 2 arg min p +  - bp q^ + 2z , (8)
zZ

u^p(q^)  up sinc(^p(t) - bp q^).

(9)

The update (7) involves a quadratically constrained quadratic minimization. This is known as a generalized trust region sub-problem, and, albeit non-convex, its global minimum can be computed efficiently as follows [24]. Rewrite (7) as a quadratic form,

qt  arg min q Dq - 2v q,

D



d×d
R

,

v



d
R

.

(10)

qSd

By the method of Lagrange multipliers, the solution is qt = q^(µ0) = (D+µ0I)-1v, where µ0 is the unique zero of q^(µ) 2-1 larger than -min, with min the smallest eigenvalue of D. The zero can be efficiently found by Newton-Raphson or bisection, and working in the eigenspace of D (see [24, 21] for details).

3. MM ALGORITHMS TO REFINE DOA ESTIMATORS
We start by stating a general formulation covering all the algorithms of Section 2.1. Then, we introduce two surrogate functions for the generalized objective function, one quadratic, and one linear.

3.1. Generalized Cost Function

Instead of the maxima of (3), we propose to find the local minima of

1 G(q) =
K

aHk (q)V kak(q)

s

1/s
,

q



2
S

,

(11)

k

with s  (-, 1)\{0}. The function Ms(y) =

1 K

k yks 1/s

with yk  0, k, is a generalized power-mean [23]. This choice is

motivated in part because it allows to formulate all the methods of

Section 2.1 by the same objective, and in part to explore new ways of

combining multiple frequency bands. For example, when s  -,

only the frequency sub-band with largest power is considered. We

can show that with a careful choice of V k and s, we can recover all

the methods of Section 2.1.

Those algorithms from Section 2.1 that aim at maximizing aHk (q)Ckak(q) can be turned to minimization problems by con-
sidering V k = Pk - Ck, with Pk a positive constant. By the

Gershgorin circle theorem, choosing Pk as the largest row-sum

of Ck ensures that V k is positive semi-definite. Methods from Section 2.1 that minimize aHk (q)Ckak(q), e.g. MUSIC-like, are readily covered with V k = Ck.
Starting from a local estimate obtained from a coarse grid
search, we perform local optimization by MM with a surrogate
function Qv(q, q^). This leads to the following iterative algorithm,

qt  arg min Qv(q, q^t-1), v = 1, 2,

(12)

qS2

for t = 1, . . . , T . By virtue of the MM algorithm, these updates are guaranteed to monotonically decrease the value of the objective of (11) [19]. The procedure is summarized in Algorithm 1.

3.2. Quadratic Surrogate

A quadratic surrogate function is obtained by successive application of the tangent inequality and Proposition 1.
Theorem 1. Let P = {(m, r) | 1  m  M, m < r  M } be the set of distinct pairs, and for p = (m, r), p = dm - dr, vector of coordinate differences of sensor m and r, and

ukp = |(V k)mr| , kp = arg ((V k)mr) .

(13)

Then, the following is a surrogate function of the objective of (11),

Q2(q, q^) = q D(q^)q - 2v(q^) q + const.,

(14)

where D(q^)  R3×3 and v(q^)  R3 are defined as

D(q^) = p(q^)pp , v(q^) = p(q^)p, (15)

pP

pP

with weights

p(q^) =

k2 k (q^ )u^kp (q^ ),

(16)

k

p(q^) =

k k (q^ )u^kp (q^ )^kp (q^ ),

(17)

k

where ^kp(q^) and u^kp(q^) are given by (8) and (9) (with bp replaced by kp), respectively, and

k(q^) = 1 K

1 K

(aHk (q^)V

k ak (q^ ))s-1

.

k (aHk (q^)V k ak (q^))s 1-1/s

(18)

Proof. For s  (-, 1), one can show that Ms(y) is concave [23] and thus, the tangent inequality may be applied, giving,

Ms(y)  Ms(y^) y + const.

(19)

Replacing y^ by the terms of (11) evaluated at q^ gives k(q^) of (18). Due to the hermitian symmetry of V k, the imaginary part of
the symmetric terms in the quadratic form cancels and it can be expressed as a sum of cosine. This sum of cosine is majorized as in Section 2.2,

aHk (q)V

k ak (q )

=

tr(V k) M

+

2 M

ukp cos(kp - kp q)

pP

 u^kp(q^)(^kp(q^) - kp q)2 + const.,
pP

where ^kp and u^kp are given by (8) and (9), respectively. Finally, notice that the terms in q only have a scalar dependency
on k. Expanding the quadratic terms, inverting the order of the sums, and completing the squares yields the final weights.

Our first algorithm is obtained by solving (12) with Q2(q, q^). The minimizer of Q2(q, q^) is computed exactly as that of (10).

Input : V k, k = 1, . . . , K Output: q , = 1, . . . , L Evaluate the cost function (11) on a rough grid Pick L local minimizers q for = 1, . . . , L for  1 to L do
for loop  1 to Max Iterations do Update q according to (10) or (23)
Algorithm 1: Proposed DOA with MM refinement algorithm.

3.3. Linear Surrogate
Because a quadratic function with a norm constraint can be majorized with a linear function [20], we can derive an even simpler algorithm.
Theorem 2. Let q be such that q = 1, and

C(q^) = (maxm p(q^)) max

p pp

(20)

where max( . ) is the largest eigenvalue operator. Then,

Q1(q, q^) = 2((D(q^) - C(q^)I)q^ - v(q^)) q + const., (21)

is a surrogate function of (11).

Proof. Dropping the dependency on q^ to simplify notation, we first show that CI D. For any x such that x = 1, because p  0,

x

ppp x  (maxp p) max

pp .

p

p

Then, we have the following majorization, with equality for q = q^,

q Dq  Cq q - 2q^ (CI - D)q + q^ (CI - D)q^. (22)

Due to the norm constraint q q = 1, the quadratic term becomes constant and we obtain (21).

Now, the corresponding MM update is given by solving (12) for v = 1. The method of Lagrange multipliers yields,

qt 

v(qt-1) - D(qt-1)qt-1 + C(qt-1)qt-1 , v(qt-1) - D(qt-1)qt-1 + C(qt-1)qt-1

(23)

which is indeed very simple. This surrogate function has several advantages. It does not require to solve any linear system. In addition, the eigenvalue in (20) only depends on the array architecture and can be computed offline. The price to pay is the slower convergence speed due to the extra majorization, as shown in Section 4.

3.4. Computational Complexity
The evaluation of u^kp, ^kp, k, p, p all require K × |P| = O(M 2 × K) operations. Thus, the overall complexity for both algorithms is O(T M 2K), T being the number of MM iterations.
The linear surrogate provides some minor computational savings,
but, as we will see, is slower to converge. For comparison, the computation of the covariance matrices is O(M 2KN ), subspace decomposition in MUSIC-like methods is O(M 3K), and the initial search on a grid of size G is O(GM 2K). Thus, the refinement
algorithm represents a small fraction of the total computations.

Error [deg.] Error [deg.] 2 Sources 1 Source

SRP-PHAT/Quadratic

10 8

Grid 100

6

4

2

Grid 10000

0

Grid 10000 + 30 MM iter.

10 8

Grid 100

6

4

2

Grid 10000

0

Grid 10000 + 30 MM iter.

SRP-PHAT/Linear
Grid 100
Grid 10000 Grid 10000 + 30 MM iter.
Grid 100
Grid 10000 Grid 10000 + 30 MM iter.

MUSIC/Quadratic
Grid 100
Grid 10000 Grid 10000 + 30 MM iter.
Grid 100
Grid 10000 Grid 10000 + 30 MM iter.

10 5 0 5 10 10 5 0 5 10 10 5 0 5 10 10

SNR [dB]

SNR [dB]

SNR [dB]

MUSIC/Linear
Grid 100
Grid 10000 Grid 10000 + 30 MM iter.
Grid 100
Grid 10000 Grid 10000 + 30 MM iter.
5 0 5 10 SNR [dB]

MM Iter.
1 2 3 4 5 10 20 30

Fig. 1: Median error in degrees as a function of the SNR. The thin black lines are for different grid sizes. The colored lines are for different number of iterations of the MM refinement algorithm starting from the 100-points grid estimate. The black thick dashed line is for 30 iterations of refinement started from the 10000-points grid estimate.

Table 1: Median error in degrees for different values of s.

Srcs

s = -10.0 -3.0 -1.0 -0.5 0.2 0.5 0.8 1.0

1 MUSIC

0.40 0.40 0.40 0.40 0.40 0.40 0.40 0.40

SRP-PHAT 0.50 0.43 0.41 0.40 0.40 0.40 0.40 0.40

2 MUSIC

0.79 0.70 0.62 0.60 0.57 0.58 0.60 0.59

SRP-PHAT 0.79 0.69 0.73 0.74 0.86 0.92 0.96 1.07

3 MUSIC

1.68 1.31 1.11 1.06 0.99 0.98 0.98 0.98

SRP-PHAT 1.43 1.23 1.37 1.38 1.42 1.48 1.66 1.79

Table 2: Median runtimes in second with the quadratic surrogate.

SRP-PHAT (Grid 10000) SRP-PHAT (Grid 100 + 30 iter.)
MUSIC (Grid 10000) MUSIC (Grid 100 + 30 iter.)
0

123 Error [deg.]

Fig. 2: Error distribution on recorded data from the Pyramic dataset

Description
proposed method fine grid-search

Grid
100 10000

MM Iter.
30 0

SRP-PHAT 1 src 2 src
0.35 0.42 4.55 4.58

MUSIC 1 src 2 src
0.27 0.37 4.57 4.48

4. EXPERIMENTS
4.1. Experiment on Simulated Reverberant Speech
We use the pyroomacoustics toolbox [31] to simulate a cubic room of 10 m side. The reverberation time is set to 500 ms. We use an array with twelve microphones whose locations are sub-sampled from the Pyramic array geometry [32] and placed at the center of the room. The simulation is repeated for 100 random locations of the sources at 3 m from the center of the array. Uncorrelated additive white Gaussian noise added to the microphone inputs. The DOAs are estimated using SRP-PHAT and MUSIC with different grid sizes and number of iterations of the refinement procedure. The evaluation is done with respect to the permutation producing the smallest average error in terms of great circle distance.
Fig. 1 shows the median error as a function of the signal-to-noise ratio for the grid size of 100 and 10000, and the for successive refinement iterations starting from the former estimate. We observe that 10 to 20 iterations is sufficient for the refinement procedure to produce better estimates regardless of the SNR or number of sources. For higher SNR, the convergence is faster. The linear surrogate requires slightly more iterations. We also see that starting from the finer grid does not significantly improve the final estimate. In Table 1, we compare the median error for different values of s. For MUSIC, values of s  -1 seem appropriate in all conditions. For SRP-PHAT, s = -3 produces the best results for two and three sources. Table 2

shows between 11 to 17 times speed-up of the median runtime.
4.2. Experiment on the Pyramic Dataset
We validate the proposed method on the Pyramic dataset of anechoic recordings with a 48-channel three-dimensional microphone array [32]. We use one speech sample recorded with azimuth of 0° to 358° in 2° increments and colatitudes of 77°, 89°, and 106°. Compare a using a 10000-points grid only, and a 100-points grid followed by 30 iterations of the refinement with the quadratic surrogate. Box-plots of The DOA estimation error are shown in Fig. 2. As in simulation, the rough grid followed by refinement consistently outperforms the fine grid. Since one iteration of refinement has the same cost as a grid point evaluation, the proposed method, in this case, requires theoretically around 76× less computations, ignoring the initial cost of computing V k's, which is the same in both cases.
5. CONCLUSION
We presented a refinement algorithm for classical DOA estimators such as SRP or MUSIC. The algorithm relies on the MM technique to perform local improvements to the cost function starting from an initial estimate produced with a rough grid. We proposed two different algorithms based on a quadratic and linear surrogate of the cost function, respectively. The linear surrogate is especially attractive due to the simplicity of its implementation. We find that the final median accuracy does not depend on the resolution of the initial grid. This means that we can dramatically reduce the computational complexity by replacing fine grid-search by local optimization. We demonstrated lower median error and 11­17 times practical runtime improvement for one to three sources on reverberant simulated data and an anechoic dataset of recordings.

6. REFERENCES
[1] H. Krim and M. Viberg, "Two decades of array signal processing research: the parametric approach," IEEE Signal Process. Mag., vol. 13, no. 4, pp. 67­94, 1996.
[2] M. Brandstein and D. Ward, Eds., Microphone Arrays, ser. Signal Processing Techniques and Applications. Springer, Dec. 2010.
[3] C. Vasanelli, F. Roos, A. Duerr, J. Schlichenmaier, P. Huegler, B. Meinecke, M. Steiner, and C. Waldschmidt, "Calibration and direction-of-arrival estimation of millimeter-wave radars: A practical introduction," IEEE Antennas Propag. Mag., May 2020, early access.
[4] P. Grall, I. Kochanska, and J. Marszal, "Direction-of-arrival estimation methods in interferometric echo sounding," Sensors, vol. 20, no. 12, pp. 3556­16, Jun. 2020.
[5] J. Capon, "High-resolution frequency-wavenumber spectrum analysis," Proc. IEEE, vol. 57, no. 8, pp. 1408­1418, 1969.
[6] J. H. DiBiase, "A high-accuracy, low-latency technique for talker localization in reverberant environments using microphone arrays," Ph.D. dissertation, Brown Univ., Providence, RI, 2000.
[7] I. J. Tashev, Sound Capture and Processing, ser. Practical Approaches. John Wiley & Sons, Jul. 2009.
[8] R. Schmidt, "Multiple emitter location and signal parameter estimation," IEEE Trans. Antenna Propag., vol. 34, no. 3, pp. 276­280, Mar. 1986.
[9] D. Malioutov, M. Cetin, and A. S. Willsky, "A sparse signal reconstruction perspective for source localization with sensor arrays," IEEE Trans. Signal Process., vol. 53, no. 8, pp. 3010­ 3022, Jul. 2005.
[10] A. Gretsistas and M. D. Plumbley, "An alternating descent algorithm for the off-grid DOA estimation problem with sparsity constraints," in Proc. IEEE EUSIPCO, Bucharest, RO, Aug. 2012, pp. 874­878.
[11] X. Zhang, T. Jiang, Y. Li, and X. Liu, "An off-grid doa estimation method using proximal splitting and successive nonconvex sparsity approximation," IEEE Access, vol. 7, pp. 66 764­ 66 773, Jan. 2019.
[12] A. Barabell, "Improving the resolution performance of eigenstructure-based direction-finding algorithms," in Proc. IEEE ICASSP, Boston, MA, USA, 1983, pp. 336­339.
[13] Y. Bresler and A. Macovski, "Exact maximum likelihood parameter estimation of superimposed exponential signals in noise," IEEE Trans. Acoust., Speech, Signal Process., vol. 34, no. 5, pp. 1081­1089, Oct. 1986.
[14] B. Friedlander, "The root-MUSIC algorithm for direction finding with interpolated arrays," Signal Processing, vol. 30, no. 1, pp. 15­29, 1993.
[15] H. Pan, R. Scheibler, E. Bezzam, I. Dokmanic, and M. Vetterli, "FRIDA: FRI-based DOA estimation for arbitrary array layouts," in Proc. IEEE ICASSP, New Orleans, LA, USA, Mar. 2017, pp. 3186­3190.
[16] Y. Pan, G. Q. Luo, Z. Liao, B. Cai, and M. Yao, "Wideband direction-of-arrival estimation with arbitrary array via coherent annihilating," IEEE Access, vol. 7, pp. 51 058­51 068, Apr. 2019.

[17] S. Adavanne, A. Politis, J. Nikunen, and T. Virtanen, "Sound event localization and detection of overlapping sources using convolutional recurrent neural networks," IEEE J. Sel. Topics Signal Process., vol. 13, no. 1, pp. 34­48, Apr. 2019.
[18] S. Chakrabarty and E. A. P. Habets, "Multi-speaker doa estimation using deep convolutional networks trained with noise signals," IEEE J. Sel. Topics Signal Process., vol. 13, no. 1, pp. 8­21, Apr. 2019.
[19] K. Lange, MM optimization algorithms. SIAM, 2016.
[20] Y. Sun, P. Babu, and D. P. Palomar, "Majorizationminimization algorithms in signal processing, communications, and machine learning," IEEE Trans. Signal Process., vol. 65, no. 3, pp. 794­816, Feb. 2017.
[21] M. Togami and R. Scheibler, "Sparseness-aware DOA estimation with majorization minimization," in Proc. INTERSPEECH, Shanghai, CN, Oct. 2020.
[22] K. Yamaoka, R. Scheibler, N. Ono, and Y. Wakabayashi, "Subsample time delay estimation via auxiliary-function-based iterative updates," in Proc. IEEE WASPAA, New Paltz, NY, USA, Oct. 2019, pp. 130­134.
[23] J. Xu and K. Lange, "Power k-means clustering," in Proc. ICML, Long Beach, CA, USA, 2019, pp. 567­581.
[24] J. J. More´, "Generalizations of the trust region problem," Optimization Methods and Software, vol. 2, no. 3-4, pp. 189­209, Jan. 1993.
[25] J. Allen, "Short term spectral analysis, synthesis, and modification by discrete Fourier transform," IEEE Trans. Acoust., Speech, Signal Process., vol. 25, no. 3, pp. 235­238, Jun. 1977.
[26] C. Knapp and G. C. Carter, "The generalized correlation method for estimation of time delay," IEEE Trans. Acoust., Speech, Signal Process., vol. 24, no. 4, pp. 320­327, 1976.
[27] H. Wang and M. Kaveh, "Coherent signal-subspace processing for the detection and estimation of angles of arrival of multiple wide-band sources," IEEE Trans. Acoust., Speech, Signal Process., vol. 33, no. 4, pp. 823­831, Aug. 1985.
[28] E. D. di Claudio and R. Parisi, "WAVES: weighted average of signal subspaces for robust wideband direction finding," IEEE Trans. Signal Process., vol. 49, no. 10, pp. 2179­2191, Oct. 2001.
[29] M. Togami, A. Amano, and Y. Obuchi, "Automatic speech recognition of human-symbiotic robot EMIEW," in HumanRobot Interaction, N. Sarkar, Ed. Vienna, Au: InTech, Sep. 2007, pp. 395­404.
[30] M. Togami, T. Sumiyoshi, and A. Amano, "Stepwise phase difference restoration method for sound source localization using multiple microphone pairs," in Proc. IEEE ICASSP, Honolulu, HI, USA, Sep. 2007, pp. I­117­I­120.
[31] R. Scheibler, E. Bezzam, and I. Dokmanic´, "Pyroomacoustics: A Python package for audio room simulations and array processing algorithms," in Proc. IEEE ICASSP, Calgary, CA, Apr. 2018, pp. 351­355.
[32] R. Scheibler, J. Azcarreta, R. Beuchat, and C. Ferry, "Pyramic: Full stack open microphone array architecture and dataset," in Proc. IWAENC, Sep. 2018, pp. 226­230.

