Decision-making Oriented Clustering: Application to Pricing and Power Consumption Scheduling
Chao Zhanga,°, Samson Lasaulceb, Martin Hennebelc, Lucas Saludjiand, Patrick Panciaticid, H. Vincent Poore
aL2S(CentraleSupelec and Univ. Paris Saclay), 91190 Gif-sur-Yvette, France bCRAN (CNRS and University of Lorraine), 54000 Nancy, France
cGeePs (CentraleSupelec and Univ. Paris Saclay), 91190 Gif-sur-Yvette, France dRTE France, 92800 Puteaux, France
ePrinceton University, 08544 Princeton, United States

arXiv:2106.01021v1 [cs.LG] 2 Jun 2021

Abstract
Data clustering is an instrumental tool in the area of energy resource management. One problem with conventional clustering is that it does not take the final use of the clustered data into account, which may lead to a very suboptimal use of energy or computational resources. When clustered data are used by a decision-making entity, it turns out that significant gains can be obtained by tailoring the clustering scheme to the final task performed by the decision-making entity. The key to having good final performance is to automatically extract the important attributes of the data space that are inherently relevant to the subsequent decision-making entity, and partition the data space based on these attributes instead of partitioning the data space based on predefined conventional metrics. For this purpose, we formulate the framework of decision-making oriented clustering and propose an algorithm providing a decision-based partition of the data space and good representative decisions. By applying this novel framework and algorithm to a typical problem of real-time pricing and that of power consumption scheduling, we obtain several insightful analytical results such as the expression of the best representative price profiles for real-time pricing and a very significant reduction in terms of required clusters to perform power consumption scheduling as shown by our simulations.
Keywords: Clustering, Decision-making, Pricing, Power consumption scheduling, EV charging.

1. Introduction
It is now well-known that future gains in terms of energy-efficiency will largely rely on the intensive use of data and algorithms. This will be true at a small scale e.g., at the consumer's scale. For instance, charging an electric vehicle (EV) efficiently at home will depend on a forecast of the consumption of the other home appliances. Smart home heating systems will also rely on the exploitation of the data recorded by a smart meter. At a larger scale, transmission operators already have to monitor various energy sources, energy needs of a country and its neighbors, use recorded data to try to predict some key parameters. For all these examples, the number of measurements and even the dimension of the data is typically large and data clustering appears to be an instrumental tool to be able to perform various optimization and decision-making tasks. Clustering is a method that consists in creating clusters, groups, or partitions of data and possibly finding a representative for each cluster. For example, an electricity operator or utility may want to determine e.g., a given number of consumption behaviors and associate a given
°Corresponding author Email address: zhangchaohust@gmail.com (Chao Zhang)

tariff with each behavior, and for this, properly clustering recorded consumption data is required.
Above examples are among many others in the area of energy conversion, management, and processing that show the importance of data clustering. Because of its importance, data clustering has become an active research area. Despite of the existence of a quite rich literature, the authors have identified a lack in this area that may make very suboptimal and even non-suitable existing clustering techniques for some key energy management problems such as the power consumption scheduling problem.
The current conventional data clustering paradigm consists in creating clusters of data based on some similarity indices of various forms. It turns out that the used indices are chosen to be exogenous to the decision-making process that effectively exploits the clustered data, formed clusters, or formed cluster representatives. As a consequence, this may make the decision-making task too complex (e.g., for a human decision-maker), computationally demanding or not admissible, too slow, and very suboptimal. From the physical and technical point of views, adopting the conventional clustering approach may lead to overestimating the amount of required resources e.g., in terms of needed energy, required storage space, transmission bandwidth, or computation capabilities. For instance, an electricity

Preprint submitted to Elsevier

June 3, 2021

provider or a distribution system operator (DSO) may have no interest in having a very accurate representation of the data recorded by a monitoring device (such as a smart meter). The reason for this may be for designing an implementable pricing policy, for limiting the complexity involved by the optimization tasks at stake (see [3] for a very convincing discussion concerning the interest in using clustering to manage complexity issues in such a scenario), for limiting the amount of private information revealed to the system exploiting the data [4], or for improving robustness towards diverse forms of noise (see e.g.,[5] for the problem of forecasting noise). Ultimately, what matters is the quality of the final decision the provider will take (typically from a large number of smart meters).
To bridge the aforementioned gap between conventional clustering and decision-making operations that need to be performed in the area of resource management, we develop a novel framework namely, decision-oriented making clustering (DMOC). To show how the developed framework can be exploited in practice the authors have chosen two important case-studies namely, the power consumption scheduling problem (PCS) and the pricing problem. The PCS problem is a very relevant problem since it appears at different scales of an energy network: at the consumer's scale when an EV or a heating system has to schedule the consumed power so that a need in terms of energy (over a given time window) is filled; at a factory level; at a country level; at a market level when a buyer has to schedule its consumption based on market prices. To be more specific about the limitations of the conventional clustering paradigm, consider the following simplified PCS example. Assume that, after performing some analysis and simplifications due to clustering in particular, the consumer (e.g., an individual or a factory) has the possibility to consume at full power P or not consume at all, and has two periods of time to do this. The power consumption profile can thus only be the sequence pP, 0q and p0, P q. Measured in terms of similarity (say in terms of Euclidean distance, which would be the case when using the famous k-means clustering technique), these profiles would be declared to be completely different. However, if one assumes that the goal of the decision-maker (the scheduler) wants to minimize the peak-power, these sequences are equivalent. This shows that using a similarity index exogenous to the decision-making process can lead to markedly different outcomes or conclusions. From now on, the authors provide a more detailed view of the existing works and the technical contributions of this article.
In the present paper, the authors' intent is to revisit the aforementioned dominant data processing paradigm by assessing the potential benefits from integrating (when available) the knowledge of the final use of the data in the way the data are processed e.g., in the decision-making (DM) process exploiting the data. Because of its importance, the focus of this work is on the problem of data clustering but mathematically, the developed approach is perfectly applicable to signal digitalization and quantization in par-

ticular. The most conventional approach of clustering in the area of energy networks is to form groups of data so that the "approximated" data are sufficiently close to the original ones. A typical approach is to make use of similarity or clustering indices such as the Davies-Bouldin index or the Silhouette index (see e.g., [6] for a review of more than 30 popular indices) to characterize the performance of clustering. However, all of these indices are exogenous to the decision-making process, which effectively exploits the clustered data. One of the goals we pursue in this paper is to revisit the conventional clustering approach by designing the clustering scheme so that the cluster or representative information provides sufficient information to perform well in the sense of the performance metric of the decision-maker using the clustered data. An example of such a decision is to choose in advance a power consumption (PC) profile based on a given clustered day-ahead forecast of the non-controllable part of the PC (NCPC); here, clustering may be applied offline to a database of previous measurements of the NCPC profiles. The problem of electric vehicle charging (at home) would be a typical instance of such scenario: the charging power is controllable whereas, the consumption power associated with the other appliances is assumed to be exogenous to the power control and monitored e.g., through a smart meter.
Below, we review several related works on clustering but it will be seen that none of them adopts the approach of decision-making oriented clustering (DMOC), at least not from the formal point of view developed in this paper. The most famous clustering technique is probably the k´means clustering (KMC) technique, which amounts to minimizing a certain Euclidean distance that is clearly independent of how the data are used. KMC has been used e.g., in [7] for time-series aggregation, in [8][9] to perform load estimation, in [10] for electricity generation expansion planning, or in [11][12] where 365 days are clustered into few representative days. More elaborate techniques have been proposed such as Fuzzy C-Means (FCM) clustering to generate the optimal fuzzy rule for decentralized load frequency control [13], and hierarchical clustering (HC) to aggregate periods with similar load and renewable electricity generation levels [14][15][16]. To exploit the data features more efficiently, the authors of [17] proposed to use dynamic time warping instead of the Euclidean distance to partition the residential electricity profiles into different clusters, the authors of [18] proposed to use cross correlation as a measure to cluster data from wind turbine power generator, and the authors of [19] used the delay coordinate embedding technique to reduce the dimensionality of load time series. To find appropriate timeseries aggregation schemes in energy systems, the authors of [20] compared the k-means clustering, k-medoids clustering, and hierarchical clustering in presence of an optimization entity. The underlying problem of high time resolution has also been addressed in [21] and [3]. In [21], the focus is on wind and photovoltaic time-series and a planning problem. In [3] the authors consider general

2

complex energy systems in which time-varying operations are performed; they conduct a detailed numerical comparison between conventional clustering (k-means clustering, k-medoids clustering, and hierarchical clustering) and shape-based clustering (dynamic time warping barycenter averaging and k-shape). Notice here, as all aforementioned works, the evaluation is performed ex post, meaning that each given clustering scheme is evaluated in terms of a given objective but not adapted to the objective. There are also many works on clustering in the computer science literature (even not yet widely applied to energy system problems), but again the existing contributions are dataoriented and not decision-oriented (see e.g., [22][23][24] [25] [26]). The selected references are good representatives of the dominant clustering paradigm, which is either to cluster the data by considering the approximation quality as a primary objective or to cluster to meet imposed constraints (e.g., in terms of complexity). At last, note that the authors have produced a preliminary work dedicated to a specific quantization problem appearing in wireless communications [27] which is partially related to DMOC.
In contrast with the conventional clustering paradigm, the data attributes are not predefined; the data attributes that are relevant to the decision to be made are automatically extracted by DMOC. To demonstrate the efficiency of the novel approach, the developed framework is applied to two important problems: the problem of real-time pricing (RTP) and the problem of PCS.
The main contributions of this paper can be listed as: (1) we develop a novel data clustering framework in which the partition and representatives are determined under the consideration of the subsequent decision-making operations; (2) we propose the first algorithm to be able to exploit this framework in practice ;(3) we apply this new approach to two important problems in the area of energy networks and provide both analytical and numerical results for these two case-studies; (4) we investigate about the potential improvement the proposed approach can provide when compared to existing state-of-the-art clustering techniques.
The paper proceeds as follows. In Section 2, we introduce the novel framework of DMOC. An alternating optimization algorithm is provided in Section 3 to show how to exploit this framework in practice. In Section 4, the developed framework is applied to two concrete and important problems in the area of energy. Section 5 allows one to assess the potential of DMOC for the two aforementioned problems under a typical simulation setting, and we conclude the article in Section 6.
Notation. Throughout the paper underlined quantities v, bold quantities M, calligraphic quantities X, and p.qT will respectively stand for vectors, matrices, sets, and the transpose operation.

2. Problem formulation

One considers a database of size N . The data set is

denoted by GN " tg1, . . . , gN u where gn P G  Rd represents Data sample n P N, N " t1, . . . , N u, and d is

the dimension of the data space G. For instance, for the

problem of PCS, gn represents the NCPC profile or vector and d " T is the number of time-slots of the profile (e.g.,

T " 48). Data are clustered in the following sense. The

data space is partitioned into cells or clusters denoted by

Cm, m P t1, ..., M u, M being the number of clusters of the

partition. By construction: C1 Y C2 Y ¨ ¨ ¨ Y CM " G and
Cm X Cm1 " H for any m  m1. If Data sample gn falls in Cm then it is represented by the representative rm P R, R being the space of representatives. For conventional clus-

tering, we typically have that there is a one-to-one map-

ping between R and G. A key difference between DMOC

and conventional clustering is that R will correspond to

the decision space. A clustering technique or strategy is

thus given by a pair under the form tpCmqm, prmqmu or equivalently by the clustering operator  with pgq " rm when g P Cm, g being a generic data sample.

The (most) conventional approach consists in choos-

ing (offline)  that minimizes the sum of the Euclidean

distances between Data sample gn and its representative

pgnq:

N
ÿ>

>2

conv

P

arg

min


n"1

>>pgnq

´

gn>>

.

(1)

A way of solving the above minimization problem is to use a (genrally) suboptimal but (generally) implementable technique such as KMC (see e.g., [8]). One of the main advantages of such an approach is that it may be possible to obtain explicitly the corresponding partition clusters and the representatives. But this way of clustering data is obviously independent of the final use of the data. For example, if the ultimate goal is to answer a question such as knowing about the absence or presence of a given feature or pattern in the data sample, partitioning the data space in two clusters only may be sufficient and, the way to split the space has to be made according to the considered final feature detection performance metric. More generally, if the task performed by the DM entity is known, it seems to be possible to improve the clustering technique (e.g., by decreasing the number of clusters or by improving its approximation quality). This is precisely the approach adopted in this paper.
Formally, the proposed approach (see Fig. 1) consists in assuming that the (online) task to be performed by the DM entity (e.g., a power consumption scheduler) can be represented by a standard OP, that is, a given function has to be maximized under some constraints. Therefore, the goal is to maximize a certain function or performance metric f px; gq (e.g., some profit or revenue function) with respect to the decision variable x P X, X  RD, D  1, given some measurement of the parameters g under some constraints under the form dipxq  0, i P I, I " t1, ..., Iu,

3

and ejpxq " 0, j P J, J " t1, ..., Ju. This mathematically writes as the following standard form online OP:

minimize ´ f `x; g
x

s.t. dipxq  0, i P I .

(2)

ejpxq " 0, j P J

By denoting x<pgq an optimal solution of the above OP, the problem of finding a DMOC scheme therefore amounts to solving the following offline problem:

Performance metric f (x; g)

Database GN DMOC (Oine)

Partition

of

GN

=

[
m

Cm

Representative decisions xm 2 X

Given data g Decisionmaking (Online)

Decision x 2 X

N

new

P

arg

max


ÿ f px<ppgnqq;
n"1

gnq.

(3)

At this point, the difference between the conventional clustering paradigm and the DMOC paradigm appears very clearly:

· The conventional clustering paradigm: 1. exploits, in an offline manner, the data set GN to compute the partition of the data space G and the representative data points (e.g., with KMC); 2. uses, in an online manner, clustering to find the representative pg of the current data sample g; 3. solves, based on the knowledge of pg, the OP which determines the best decision x (namely, maximizing f under some constraints).

· The DMOC paradigm: 1. exploits, in an offline manner, the data set GN to compute (via solving OP (7)) the partition of the decision space X and the representative decision points; 2. uses, in an online manner, DMOC to directly find the representative (final) decision xp associated with the current data sample g.

It can be checked that the conventional clustering approach given by (1) can be obtained from (3) by making the following specific choices: R " G; f px; gq " ´}x ´ g}2, dipxq " ´8, and ejpxq " 0 for all pi, jq P I ^ J. In its full generality, solving the problem associated with (3) is difficult. Indeed, finding the best clusters and the best representatives jointly may be hard both from the analytical and computational point of view. This is one of our motivations for proposing an alternating optimization algorithm in the next section.
Remark 1. In this paper, we have selected as case studies the problem of RTP and PCS. For RTP, the decisionmaker is the provider, its decision consists in choosing electricity price profiles or tariffs, and the measured data consists of the various satisfaction parameters of the consumers. For PCS, the decision-maker is a consumer (e.g., a factory or an electric vehicle), its decision consists in choosing a power consumption profile, and the measured data consists of the non-controllable power consumption profiles. Many other problems of the modern power grid are concerned by the newly developed framework and would need to be studied from the proposed perspective. For example, electricity market price profiles may be clustered

Figure 1: The DMOC approach. As key points notice that: 1. An arbitrary DM performance metric can be considered (f ); 2. The representatives of the clusters are in the decision space X; 3. What matters for a DM entity aiming at maximizing f px; gq w.r.t. the decision x given pg (clustered/imperfect/noisy version of g is not the similarity between g and g but the average of the final optimality
p loss measured by |f px<pgq; gq ´ f px<ppgq; gq|.
for a given purpose and the (distribution/transmission) network states may be clustered to be able to characterize its behavior (e.g., the absence/presence of a global anomaly).
3. Proposed algorithm
As mentioned in the previous section, solving the OP associated with (3) is not an easy task in general. In fact, even for a specific performance metric f px; gq " ´}x ´ g}2 which is used for k´mean like algorithms, it is known that some degree of suboptimality has to be accepted. In the present section, we propose an algorithm which applies to any performance metric f and relies on two key ingredients. First, by providing an appropriate equivalence argument, the problem of finding the representatives of the data is converted into a problem of finding the representative decision points. Second, since the joint determination of the optimal clusters and representative decision points is difficult in general, we resort to an iterative (and suboptimal) algorithm which operates in two steps.
When inspecting (3), it is seen that the optimal DM function x<pgq is needed. Although there are well-known examples for which such a function can be found (e.g., the valley-filling solution [28]), this knowledge is not always available. This is one of the reasons why we reformulate the problem of finding the data representatives r1, ..., rM into that of finding representative decision points x1, ..., xM . The equivalence between these two problems is the purpose of the proposition below. Before stating this proposition, a few notations are in order. The set of data indices is assumed to be partitioned as follows: N " N1 Y N2 Y ¨ ¨ ¨ Y NM . For m P t1, ..., M u, the set Nm represents the set of indices of the data samples which belongs to Cluster Cm, i.e., gn P Cm implies n P Nm and vice versa. Therefore, the set Nm completely characterizes the cluster Cm and conversely. For g P Cm, the representative

4

decision point is denoted by xm. Using these notations, such as KMC, convergence to a global minimum is not

the following result can be stated.

guaranteed in general. Maximizing jointly a function w.r.t.

Proposition 3.1. The offline OP associated with (3) is equivalent to the following offline OP:

the set of clusters and the set of representatives is known to be an NP-hard problem (See [29][30]). This is the reason why we resort to an alternating optimization algo-

minimize pN1,...,NM ,x1,...,xM q
s.t.

M

ÿÿ

´

f pxm; gnq

m"1 nPNm

dipxmq  0, i P I

ejpxmq " 0, j P J

rithm. In general, the proposed DMOC algorithm guarantees convergence to a local maximum. In the scalar case (4) (namely, g P R as it is the case for the RTP case) sufficient conditions under which convergence to a global maximum may be exhibited. For instance, this is the case when f px; gq " ´px ´ gq2 and the probability distribution func-

tion pgq is log-concave [31]. In particular, if g is normally

Proof. See Appendix.

distributed, global convergence is available. Another in-

Prop. III. 1 allows one to characterize the optimal DMOC strategies. But, for classical complexity arguments, we resort to an alternating optimization algorithm to find pN1, ..., NM q and px1, ..., xM q in an iterative manner. For this, it is first assumed that a set of representative decision points is given. It can then be checked that the best clusters (given a set of representative decision points) are given by:

teresting case is when the function verifies the following property f px; gq " f px ´ g; gq. Then, reference [32] allows one to claim that the maximum point is unique, which guarantees global convergence. In the vector case (as in the PCS case), the problem becomes more complicated. In particular, finding a general way to determine the optimal tesselation structure of the clusters is known to be an open problem [33]. Notice that the proposed iterative algorithm can always be initialized with the best state-of-the-art so-

! C°m " gn P G : f pxm; gnq  f pxm1 ; gnq

@m1,

) lution. This guarantees a positive performance gain over 1  m1  M . any state-of-art solution. This value of this positive gain

(5) will be assessed thanks to the detailed numerical perfor-

or equivalently,

mance analysis conducted in Sec. 5. To conclude on the

!

) proposed algorithm, note that to run the algorithm, only

Nm° " n P N : f pxm; gnq  f pxm1 ; gnq @m1, 1  m1  M . the data set GN and a given initial choice of the represen-

(6) tative decision points are required. The maximum number

For the sake of clarity, we will mainly use the notation of iterations Q is fixed.

Cm to refer to Cluster m. The above formula characterizes the optimal clusters for given representative decision points. To know more about the "geometry" of the clusters, a specific choice for f has to be made. For instance,

Inputs: Data set GN ; initial representative decisions txp10q, ..., xpM0qu; number of clusters M ; number of iterations Q

for f px; gq " ´}x ´ g}2 and N large, the best clusters correspond to the famous Vorono¨i regions. Now, as a second

Outputs: tx°1 , ..., x°M u, tC°1 , ..., C°M u Initialization: Set iteration index q " 0.

step, we now assume that some choice for the clusters is made and want to characterize the representative decision points which maximize the considered performance metric. It can be checked that for m P t1, ..., M u, the best representative decision (given a set of clusters) is obtained by solving the following OP:

Initialize the representatives by txp10q, ..., xpM0qu. Set performance evaluation quantity A0 " 0 and
A´1 " ´100. Set the tolerance as Td. while q  Q and Aq ´ Aq´1  Td do
Update the iteration index: q Ð q ` 1. For all m P t1, ..., M u, update Cpmqq from xpmq´1q

x°m P s.t.

ÿ

´

arg min
xPX

nPNm

f

pxm;

gnq

dipxmq  0, i P I

(7)

ejpxmq " 0, j P J.

Equations (5) and (7) precisely constitute the two steps

using (5).

For all m P t1, .., M u, update xm pq`1q for each

cluster Cpmqq by solving OP (7).

NM

Compute

Aq

"

1 ÿ ÿ f pxpmqq; gnq
n"1 m"1

. g n

PCpmqq

end

of Algorithm 1, which is the iterative algorithm proposed to determine the clusters and representative decision points to solve the original OP given by (3). These two steps are

@m P t1, ..., M u, x°m " xpmqq, C°m " Cpmqq Algorithm 1: Algorithm to obtain a DMOC strategy

performed at each iteration of the algorithm until convergence is reached. At each iteration, the function to be maximized in (7) can only increase or stay constant. Since functions of practical interest are generally bounded, convergence is guaranteed. Similarly to iterative algorithms

In the next section, we show how to exploit this general algorithm for specific performance metrics.
Remark 2. We will not conduct here the complexity analysis of Algorithm 1, the main objectives of this paper

5

Figure 2: Flowchart of the proposed algorithm
being to introduce the DMOC approach, to provide one possible algorithm to implement it, and to assess the performance gains (measured in terms of a given utility function) for the two applications of interest. Nonetheless, we would like to make some useful comments on this issue. As illustrated through Fig. 1, offline operations have to be distinguished from online operations. Algorithm 1 only relies on offline operations namely, computing the partition tC°muM m"1 and the representative decisions tx°muM m"1. This means that these operations can be made once and for all by powerful computers. In fact, even for the most computationally demanding scenario studied in Sec. V, the total computation time has never exceeded 10 min with a standard personal computer. As for the online operation, given g, it consists in selecting the element in the set tx°muM m"1 that maximizes f px°m; gq. The complexity of this operation is in OpM q.
4. Applying DMOC to Real-time Pricing and Power Consumption Scheduling
In this section, we make specific choices for the performance metric f px; gq. We have selected the two considered corresponding metrics because they concern quite a large number of works in the literature of smart grids and also because they allow us to clearly illustrate the new point of view developed in this paper. The first metric corresponds to a largely used performance criterion which is derived from [34]. It consists in mixing the social welfare of a group of consumers and the total production cost; other relevant pricing problems (e.g., [35]) might be considered as extensions of this work. The decision for the provider corresponds to a price profile, pricing strategy, or tariff policy and the function parameters to the satisfaction parameters for the consumers. The second performance metric corresponds to the Lp norm, which in particular allows one to include as a special case the peak power minimization problem. Here, the decision is a power consumption profile and the parameters correspond to the non-flexible part of the power consumption.

4.1. Pricing problems
The first step taken in this section is to study pricing problems with clustering. Since operating at high time resolution over a long period of time generally leads to intractable optimization problems [3, 20, 21], we resort to clustering. Clustering is applied here to obtain a small number of representative time profiles (e.g., cluster the 365 days into 5 representative time profiles) and to design a corresponding tariff for each representative. We derive the performance metric given by (10) from the largely used RTP setting proposed in [34]. For this model, we are able to calculate the optimal tariff x from consumers' loads/demands time-series g. We consider a provider and a set of consumers K " t1, . . . , Ku. Our goal is to cluster the corresponding time-series and associate with each cluster a representative tariff, the association being performed by using the DMOC algorithm of Sec. III. The considered performance metric for the provider implements a tradeoff between the sum of the consumer's utility functions and the total energy procurement cost (10). The action of the provider at time t is denoted by xptq  0 and consists in choosing the price of electricity at time t P T, T " t1, ..., T u, T being the number of time-slots of the time period under consideration (For instance, a time period can consiste of a day and a time-slot can consist of an hour if T " 24). Time-varying prices are natural when the consumers correspond to large entities such as states or big companies but are also well motivated for future grids when they correspond to individuals (see e.g., [34][36]).. To take his decision, the provider has some knowledge about the satisfaction parameters of the consumers (see [34] for more details) at the current time-slot. The satisfaction parameter for Consumer k P K at time t P T is denoted by gkptq  0. It is defined through the generic benefit or utility function u for the consumers:

 

g

´

 2

2

if

0



g 



up

; gq

"

 

g2

 

2

if



g 

(8)



where  0 represents the load or consumption level, g the satisfaction parameter, and   0 is a constant. This means that the benefit of the consumer increases quadratically with the load level but reaches a saturation point determined by the parameters g and . To make this generic utility consumer-specific and time-dependent, one just has to replace g with gkptq and with kptq. As in [34], it is assumed that Consumer k has a cost for consuming under the form xptq kptq where xptq represents the price of electricity at a given time t. The generic combined utility for the consumer thus writes as the difference up kptq; gkptqq ´ xptq kptq. For a given price of electricity chosen by the provider at time t, the combined utility is assumed to determine the best response in terms of con-

6

sumption, which is to consume at a load level given by:

 

0

if xptq  gkptq



< k

pxptqq

"

 

gk ptq´xptq

 



if xptq  gkptq .

(9)



Of course, when the price is higher than the satisfaction

parameter,

< k

is

not

an

interior

solution

and

reaches

the

minimal consumption level allowed and therefore has to

be replaced with the corresponding value. For the sake of

clarity, we assume no over-pricing for the case study un-

der consideration, i.e.,

< k

pxptqq

"

gk

ptq´xptq 

.

To

design

its

DMOC strategy, the provider is assumed to pursue (pos-

sibly by using a learning algorithm which only exploits

partial or indirect information e.g., about gkptq) the max-

imization of the average welfare of all its customers over

time minus the cost of energy procurement (quadratic cost

model) as follows :

T «K

ff

ÿ f1px; gq "

ÿ

up

< k

pxptqq;

gk

ptqq

´

apL<ptqq2

´

bL<ptq

´

c

t"1 k"1

(10)

where x " pxp1q, . . . , xpT qq (i.e., d " T ) is the sequence

of prices chosen by the provider;

g " pg1p1q, . . . , gK p1q, . . . , g1pT q, . . . , gK pT qq (11)

is a vector which comprises all the consumer satisfaction

parameters

in

one

time

period;

L<ptq

"

K
k"1

< k

ptq

is

the

total load induced by the K consumers for time-slot t and

pa, b, cq is a triplet of constants to model the (quadratic)

procurement cost for the provider. The constraint on RTP

is the positivity of price, namely,

xpdq  0, @d P t1, . . . , Du.

(12)

Our target is to cluster the set G " tg1, . . . , gN u consisting of N time period vectors with

gn " pg1pnqp1q, . . . , gKpnqp1q, . . . , g1pnqpT q, . . . , gKpnqpT qq (13)

into M representative time periods, and find the corre-

sponding tariff for each representative time period. For

the performance metric f1, it turns out that the clusters

and representatives respectively obtained by the general

equations (5) and (7) express in an elegant manner. Be-

fore providing the corresponding proposition, let us in-

troduce some auxiliary quantities. Notice that the pa-

rameters K, , a, b, and c have all been defined in the

current subsection. We introduce three scalar quantities:

ra

"

K2 2

`a

`

 2K

;



"

aK 2 a

;



"

bK 2a

.

From this and

by denoting 1K the columnr vector of rK ones, we define

the two following quantities:  " 1T ; A " IT b 1TK ,

the operator b standing for the Kronecker tensor product

[37].

Proposition 4.1 (DMOC for RTP). For a given sequence of representative price profiles xm the best way of cluster-

ing (in the sense of f1) the consumer's satisfaction parameter space is given by the following clusters:

C°m " g P G : }Ag `  ´ xm}22  }Ag `  ´ xm1 }22, @m1  mu.
(14)
Now, for a given partition of the satisfaction parameter
space into a set of clusters Cm, the best representative price profiles are given by:

x°mptq

"

agmptq

`

b 2K

a

`

 2K

(15)

where gmptq "

1 N n"1

K
k"1

gkpnqptq

g
n

PCm

1 K

N
n"1

g
n

PCm

represents the av-

erage satisfaction parameter of Cluster m at time-slot t

and 1 being the indicator function.

Proof. See Appendix.

The above proposition is particularly interesting since

it allows clear interpretations to be made. Indeed, for a

fixed sequence of prices, it is seen that the best clusters

form the famous "Vorono¨i cells" in a space which results

from an affine transformation of the initial parameter or

data space. Through the Kronecker product operation,

one can also see that a quantity which matters for obtain-

ing the best clusters is given by the sum of satisfaction pa-

rameters, which contrasts with KMC. On the other hand,

if the clusters are fixed, the best decisions, which are given

by the best representative price profiles have very appeal-

ing expressions. The best price is seen to be related to

the average satisfaction parameter in an affine manner.

When a is small, the procurement cost becomes almost

linear and the best price becomes time-independent and

equal

to

lim
aÑ0

x°mptq

"

b.

Additionally, when K Ñ 8, the

optimal price profile is given by x°mptq ,, g¯mptq, which cor-

responds, at any time, to the spatial average (i.e., over the

consumers) of the satisfaction parameters. Therefore, if

the provider has access to the spatial average of the sat-

isfaction parameters, it immediately obtains a good ap-

proximation of the optimal pricing strategy in the sense of

(9).

4.2. Power consumption scheduling
In this section, the decision-maker is a scheduler. The task of the scheduler is to choose in advance a sequence of consumption power levels, x " pxp1q, ..., xpT qq given some knowledge (e.g., a day-ahead forecast) about the non-controllable part of the consumption pgp1q, ..., gpT qq. The problem of electric vehicle battery charging [5] given a forecast of the consumption profile associated with the other electric home appliances and the problem of PCS under price uncertainty [38] typically fall in the setting under consideration. Even in scenarios where the (possibly central) decision entity which computes the consumption profiles, it may be beneficial to cluster the non-controllable

7

profiles tg1, . . . , gN u into M groups and find the representative consumption profile for each cluster. This might

be typically motivated by complexity issues or for having

more robustness regarding the measurement or forecasting

noise present in the available non-controllable profiles. A

simple but very relevant choice for the performance metric

for the scheduler consists in choosing the following func-

tion:

f2px; gq " ´}Wpx ` gq}p

(16)

where W is a diagonal matrix with non-negative entries and the Lp-norm of a generic vector v of size T is given by }v}p " p|v1|p ` ¨ ¨ ¨ ` |vT |pq1{p. The matrix is a weighting matrix which may model situations where the price is timevarying. When p " 1 and W " IT the problem amounts to minimizing the total energy consumption. When p " 2, the problem is simple since the electricity price depends on the power consumption in a linear manner. For p Ñ 8, minimizing the Lp-norm amounts to minimizing the peak power. Here, we also assume some (classical) constraints on the consumption power:

0  xptq  xmax

T
ÿ xptq  E

(17)

t"1

where E  0 is the energy need. With the notations of

Sec. III, this means that the inequality constraint func-

tions write as: @t P t1, ..., T u, d2t´1pxq " ´xptq, d2tpxq "

xptq ´ xmax,

and

d2T `1pxq

"

E

´

T
t"1

xptq.

Note

that

for

p " 1, the problem is trivial for positive prices and pow-

ers. The best decision is obtained by choosing xptq " E

for the time index associated with the lowest coefficient

of the diagonal of W. For p  2, the clustering strategy

matters and designing a DMOC strategy will be seen to be

very beneficial for the performance. The next proposition

characterizes the best clusters and representative profiles.

Proposition 4.2 (DMOC for PCS). Let G  RT be the
data set. For a given sequence of representative PC profiles xm the best way of clustering (in the sense of f2) the NCPC profile space is given by the following clusters:

Proof. See Appendix.
It is seen that the best clusters (for fixed representatives) have a relatively simple "geometry" since they are generalized Vorono¨i cells that is, the Euclidean norm is replaced with the general distance given by the Lp-norm (they coincide for p " 2). As for the best representatives, here we don't provide an explicit formula. But the OP to be solved (19) to find them numerically is convex, which strongly facilitates the task of determining them. If complexity to solve this OP or to determine the clusters given by (18) occurred to be an issue, one may resort to approximating the DMOC procedure. Indeed, whatever the actual values for p, it is always possible to force p to be equal to 2 in (18). As a consequence, clusters become Vorono¨i regions. By doing so, one obtains an approximated version of DMOC. The virtue of this approximate version is that it allows one to reduce the complexity as the tesselation/geometry of Vorono¨i regions is known. The induced performance loss is assessed in the numerical part in a typical scenario (see Fig. 2).
Remark: Both RTP and PCS problems are convex. Due to the quadratic structure of the utility functions in RTP, we can provide the expression of the solutions (according to Proposition 4.1.) However, in the PCS problem with Lp norm optimization problem, it is very difficult to express the solution and thus we resort to numerically efficient algorithms (Interior point algorithms) to compute the solution of the optimization problem. In terms of computational complexity, solving the PCS problem is more demanding.
5. Numerical performance analysis
In the preceding section, several interpretable analytical results have been derived, especially for RTP. To get more insights on the problem of PCS for which less analytical results are available, we dedicate here more space to this case. All the provided numerical results have been performed by using the Matlab software. In particular, the k´means clustering (KMC) technique is executed by using the Matlab routine "kmeans".

C°m "

gPG

:

}Wpxm ` gq}p  }Wpxm1 ` gq}p,

@m1  m( . (18) 5.1.

Influence of the clustering scheme on the performance

Now, for a given partition of the NCPC profile space into

of PCS

a set of clusters Cm, the best representative PC profiles are

For all the numerical results concerning the problem of

given by solving the following convex OP:

PCS, we consider the peak power minimization problem

minimize
xm
s.t.

ÿ }Wpxm ` gnq}p

nPNm

´xmptq  0

@t

xmptq ´ xmax  0 @t
T
E ´ ÿ xmptq  0

t"1

that is, p " 8 in (16). For simplicity reasons, the weight-

ing matrix is chosen as W " IT . The database under

consideration is the Pecan Street database [39]. The used

(19)

database corresponds to Year 2013 and comprises N " 365 (non-flexible) household power consumption vectors of size

T " 24 (with the specific approval by PecanStreet, these

consumption profiles are shared in [40]). This database

is used to feed Algorithm 1. Algorithm 1 is initialized

where Nm, as defined in Sec. III, represent the set of in- with randomly chosen representative decision points. The

dices of the data which belongs to the cluster Cm.

maximum number of iterations is set as Q " 10. The

8

tolerance is set to Td " 10´3. The considered DMOC is

given by the set of clusters and representative decisions at

convergence. For each household, the DM operation con-

sists in finding a controllable consumption vector x min-

imizing the peak power given a (perfect) day-ahead fore-

cast of the NCPC vector g (the case of imperfect forecast

can be treated by extending our results). Precisely, what

is known for taking the decision is to which cluster the

NCPC vector belongs. The numerical determination of the

PC vector is performed by using the dense quasi-Newton

Hessian approximation-based interior point technique (im-

plemented by the Matlab fmincon function). The perfor-

mance of the conventional k´means clustering technique

and the proposed DMOC technique are measured in terms

of the function f2 (see (16)); more precisely, unless stated

otherwise, the latter is averaged over several randomly se-

lected household profiles namely, Households 4998, 6910,

9499, and 9609. The energy need in terms of PC for a

household is set to E " 30 kWh.

First, we want to assess the loss induced by clustering

(namely, by using a fixed number of possible decisions x in-

stead of using the optimal solution x°pgq for every g). For

this, we define the relative optimality loss of the generic

clustering scheme C with respect to the ideal case as fol-

lows

2,Cp%q

"

F2perfect ´F2C F2perfect

^ 100

where

F2

is

obtained

by

averaging f2 over several realizations of the NCPC vector

and the performance of the ideal case is attained by as-

suming that the optimal PC vector x° is available (this

amounts to having an infinite number of clusters). The

natural relevance of the notion of relative optimality loss

stems from the fact the decision-making entity process is

represented by the maximization of the function f2. There-

fore, what matters is that the decision taken is as close as

possible to the ideal situation which is obtained by maxi-

mizing f2px; gq with an absolutely perfect knowledge of the

parameters g. Here, F2 intervenes instead of f2 because

the performance is averaged. Fig. 3 represents 2,Cp%q as

a function of the number of clusters for 4 different cluster-

ing schemes when F2 is obtained by averaging over the 365

daily NCPC profiles of Household 9499. Indeed, DMOC

is compared to four popular clustering schemes namely,

KMC, hierarchical clustering (HC), fuzzy C-means clus-

tering (FCMC), and symbolic aggregate approximation

(SAX) based clustering [41][42]. For HC, the squared Eu-

clidean distance and weighted pair group method with

arithmetic mean are used. For FCMC, the fuzzifier ex-

ponent parameter is set to 2. For SAX based clustering,

the window size is set to 4 and the alphabet size is fixed

to 8. Regarding the performance, for 15 ´ 20 clusters,

the optimality loss for KMC, HC, FCMC and SAX based

clustering are seen to be around 20%. With the proposed

approach (DMOC), it is seen that the optimality loss is

as low as 2 ´ 3% for the same number of clusters, which

represents a very significant improvement. Additionally,

by approximating the clusters by Vorono¨i regions, the ap-

proximated DMOC allows one to reduce complexity while

only inducing a reasonable performance loss w.r.t. the original DMOC. To better illustrate the other potential benefits from using DMOC, we mainly show the comparison between DMOC and KMC in the following figures. In Fig. 4, the desired maximum peak power level is fixed to a given value in the range r3.8, 4.4s kW. Then, one computes the number of clusters which allows one to guarantee that the total power will not exceed this value. Fig. 4 shows, in particular, that the required number of clusters can be very high when the constraint on the maximum power level is strong (e.g., when it equals 3.8 kW). On the other hand, using DMOC allows one to adapt in an ideal manner the shape of the clusters and the representative decisions, which explains why the number of required clusters can be made very small. To better understand how DMOC operates in terms of shaping the clusters and selecting the representative decisions, we consider in the next subsection special cases allowing to make interpretations.

Optimality loss (%)

30

25

20

Hierarchical clustering

15

Fuzzy C-means clustering

k-means clustering

SAX clustering

10

Approximated DMOC

DMOC

5

0

0

5

10

15

20

Number of clusters

Figure 3: Relative optimality loss induced by the finiteness of the number of clusters.

5.2. About the shape of DMOC clusters and DMOC rep-
resentative decisions (PCS)
To be able to represent the clusters geometrically, we fix the dimension of the data space to T " 2. This means that the consumption profile g comprises 2 phases with constant power; here, it corresponds to the average power from 6 am to 6 pm and that from 6 pm to 6 am, always for the Pecan street database. As a consequence, the number of clusters is also small. It is set as M " 4. For this setting, Fig. 5 shows the clusters obtained when using DMOC (left subfigure) and KMC (right subfigure). With KMC, the obtained clusters correspond to Vorono¨i cells. With DMOC, the obtained clusters are markedly different. The latter are tailored to the L8´norm. These clusters are much more suited to manage the peak power

9

120 100

X: 3.805 Y: 120

k-means clustering (KMC) The proposed approach (DMOC)

power occurrence (the densest part in the left figures).

DMOC shaping

KMC shaping

Required number of clusters Non-controllable night consumption (kW) Non-controllable night consumption (kW)

80

X: 3.917

Y: 69

60 X: 4.021 Y: 45
40

20 0 3.7

X: 3.793 Y: 4

X: 3.913 Y: 3

X: 4.019 Y: 2

X: 4.354 Y: 3

3.8 3.9

4

4.1

4.2

4.3 X: 4.337
Y: 1

Expected daily peak power (kW)

Non-controllable daytime consumption (kW)

Non-controllable daytime consumption (kW)

Figure 5: Geometry of the cluster shape.

5.3. Influence of the data on the performance gains (PCS)

Figure 4: Required number of clusters to reach a given target in terms of maximum peak power.
reduction problem. Roughly, data samples are grouped into regions in which the difference in terms of power between the two consumption phases (namely, the quantity (|gnp1q ´ gnp2q|) is small. Now, let us turn our attention to the shape of representative PC profiles. In this case, any value for the data space dimension can be assumed. Therefore, we assume the typical value T " 24 and that the data are clustered in three groups that is, M " 3. The rationale behind this choice is to make apparent the main features of interest that are automatically extracted by the DMOC technique. As far as the decision to be taken aims at minimizing the peak power, the main feature is found to be the time information associated with the occurrence of the most likely dominant peak power. Fig. 6 depicts the three PC profiles (in red dash line) of KMC and DMOC, respectively. As a side information, for each of the clustering approaches (KMC/DMOC), the empirical mean of the NCPC profiles (in solid blue line) over the cluster under consideration is given for each cluster. Notice that, since the clusters provided by the two approaches differ, the means also differ. It can be seen that DMOC classifies the NCPC g according to the peak power occurrence time. The peak of the first NCPC profile (called Type I) occurs in the afternoon while the peaks of the second and the third type occurs in the early evening and late evening, respectively. The representative PC profiles naturally comprise higher values over off-peak periods of its corresponding NCPC profiles. By contrast, KMC provides less suited PC profiles by considering the L2´norm of the NCPC profiles instead of adapting to the decision performance metric, here an Lp´norm. Fig. 7 allows one to be able to compare the representative profile of a cluster with the rest of the cluster members. Interestingly, the timeslot of the representative peak (right figures) corresponds to the time-slot which has the highest probability of peak

In the previous subsections, results were averaged over

four randomly selected households. Here, we look at the

performance for each household, in particular, our goal

being to see to what extent the nature of the data influ-

ences the outcome in terms of gains brought by DMOC

over KMC. Fig. 8 represents the relative optimality loss

2,C for given realizations of the NCPC profile with different households. The four curves correspond to the ran-

domly selected households. It is seen that the loss induced

by clustering (here only DMOC is considered) clearly de-

pends on the household but is always as low as 5% when

the number of clusters exceeds 10. Interestingly, we have

seen that the entropy of a non-flexible consumption pro-

file can be used as a measure to know whether DMOC will

bring a significant performance gain. Indeed, by denoting

ppptq the empirical probability that the non-flexible peak

power

occurs

at

time-slot

t

by

ppptq

"

1 N

N

1 ÿ

gn

ptq"max

g
n

,

n"1

the entropy of an NCPC profile merely expresses as

T

ÿ

Hpppq " ´ ppptq log2 ppptq.

(20)

t"1

For Households 6910, 4998, 9609, and 9499, the value of the entropy is respectively given by 3.45, 3.82, 3.91, and 4.19. This shows here that entropy may reflect well the optimality loss obtained when using DMOC.

5.4. Potential benefits from using DMOC for RTP
Here, we consider the problem of RTP. The simulation setting we choose is very close to [34]. We consider a system with a unique provider and K " 5 or K " 10 consumers. For each day, the consumer satisfaction parameter gkptq is assumed to be constant for a period of 6 hours, which means that gk " pgkp1q, ..., gkpT qq with T " 4. Additionally, the satisfaction parameters gkptq are assumed to be realizations that are i.i.d. over the consumers and time. Each gk is uniformly distributed

10

Load (kW)

Load (kW)

KMC Type I (52% load profiles belonging to it) 2

1.5

1

Non-controllable consumption g

Controllable consumption x

0.5

0

0

5

10

15

20

25

Time (h)

KMC Type II

(16% load profiles belonging to it)

4

Non-controllable consumption g

Controllable consumption x

3

2

1

0

0

5

10

15

20

25

Time (h)

KMC Type III

(32% load profiles belonging to it) 3

Non-controllable consumption g

2.5

Controllable consumption x

2

1.5

1

0.5

0

0

5

10

15

20

25

Time (h)

Load (kW)

Load (kW)

Load (kW)

DMOC Type I

(30% load profiles belonging to it)

2.5

Non-controllable consumption g

Controllable consumption x

5

2

1.5

0

0

1

5

0.5

Load (kW)

0

0

0

5

10

15

20

25

Time (h)

0

5

DMOC Type II

(38% load profiles belonging to it)

2.5

Non-controllable consumption g

Controllable consumption x

0

2

0

1.5

5

10 15 20

2

1

0

20

5

1

5

10 15 20

0

5

1.2

1

0.8

0.6

0.4

5 10 15 20 25 0

5

Time (h)

10

15

20

25

10

15

20

25

10

15

20

25

1
Figure 7: Comparison between cluster representative and cluster

0.5

members

0

0

5

10

15

20

25

Time (h)

DMOC Type III (32% load profiles belonging to it) 2
1.5
1

25

Entropy=4.19

Household 9499 Household 9609

20

Entropy=3.91

Household 4998 Household 6910

0.5

Non-controllable consumption g

0

Controllable consumption x

0

5

10

15

20

25

Time (h)

15

Entropy=3.82

Relative optimality loss (%)

Load (kW)

10 Figure 6: DMOC vs KMC. Three PC profiles and their corresponding average NCPC profiles are represented.
5

Entropy=3.45

over the interval r2, 3s and we choose  " 0.5, a " 0.1,

b " 0, and c " 10 for the parameters of the function f1

(see (10)). Fig. 9 represents the relative optimality loss

1,Cp%q

"

F1perfect ´F1C F2perfect

^ 100,

C P tKMC, DMOCu as a

function of the number of clusters for KMC and DMOC

where F1 corresponds to an average of f1 over N " 365

draws for the vector of satisfaction parameters. The gain

brought by DMOC over KMC is globally less significant

than for the peak power minimization problem; this can

be explained by the quadratic structure of the problem,

which implies that the DMOC representatives are also ob-

tained by using the Euclidean distance just as KMC does.

However, as it can be seen from (15), exploiting an affine

transformation of the initial parameters, DMOC considers

the sum of all the consumers' demand levels as a single

parameter. By classifying the dataset according to this

automatically extracted feature, the optimality loss can

be made significantly lower compared to the conventional

approach such as KMC. If one wants to guarantee small

optimality losses (say  10%) it is even seen that it may be

impossible for KMC to reach the corresponding accuracy

level, making the use of DMOC necessary.

6. Conclusion
In this paper, we have provided a new approach to clustering that allows one to extract ex ante and in an automatic manner, for any performance metric, the fea-

0

2

4

6

8

10

Number of clusters

Figure 8: Relative optimality loss against the number of clusters.

tures relevant to the decision maker using the data. By doing so, one can minimize the impact of the finiteness of the number of clusters on the final performance. For instance, for the peak power problem, we have seen that the number of required clusters to perform the corresponding power scheduling task can be divided by a factor as high as 30 compared to conventional clustering. The analytical results provided for the problem of real-time pricing and power consumption scheduling illustrate very well the effects of the adopted point of view compared to the conventional point of view. The numerical analysis clearly illustrates the benefits of decision-making oriented clustering e.g., in terms of required number of clusters or optimality loss for the decision making process. The proposed approach might be refined. For instance, an interesting and deepened discussion of the complexity issue might be conducted. For a given complexity level for the clustering plus decision operation, the conventional approach might be compared to the proposed approach. For this, approximation-based low-complexity decision-making oriented clustering schemes may be considered. Also, the im-

11

14

k-means with 5 consumers

where

ctpgq

"

K
k"1

" p´2aqgk2 ptq
22

´

bgkptq i


is

independent

Proposed approach with 5 consumers k-means with 10 consumers Proposed approach with 10 consumers

of x and thus irrelevant for the choice of Cm. By combining (22) and (5), for given representatives, the optimum

12

regions can be written as (14).

For given clusters (C1,. . . ,CM ), the best representative

10

is obtained by solving the following OP:

Optimality loss (%)

8

x°m P

ÿ

´arg min
xPX

nPNm

f

pxm;

gnq.

(23)

6

In the RTP case, the sum-utility expresses as:

4

2

1

2

3

4

5

6

7

8

9

10

Number of clusters

Figure 9: Relative optimality loss against the number of clusters for the problem of RTP.

ÿ

f1

pxm

;

g
n

q

nPNm

T
ÿÿ "
t"1 nPNm

« ´a~pxm ptq

´

1 2a~2 pbK

`

2aK

K
ÿ gkpnqptqqq2
k"1

`

ff

ct

pg
n

q

1 T N
ÿÿ "
t"1 n"1

gn PCm

« ´a~pxm ptq

´

1 2a~2

pbK

`

2aK

K
ÿ gkpnqptqqq2
k"1

`

ff

ct

pg
n

q

1 T «

N

ÿ "

´a~p ÿ

t"1

n"1

~ gnPCm q pxmptq ´

ag m ptq

`

b 2K

a

`

 2K

q2

¸ff

`

c1t

pg
n

q

.

(24)

pact of the choice of the performance metric on the performance gain of decision-making oriented clustering should be investigated more; we provide the answer for two famous performance metrics but a deeper problem would be to mathematically characterize functions for which the gain is large, intermediate, or small. The extension to the case where the data used by the decision-maker are noisy would be very relevant; possible paths would be to generalize the proposed algorithm the way the Lloyd-Max quantization algorithm has been generalized to noisy inputs or to exploit reinforcement learning algorithms with noisy measurements.

Therefore,

maximizing


nPNm

f1pxm;

gnq

is

equivalent

to

minimizing

pxmptq

´

agm

ptq`

b 2K

a`

 2K

q2,

the

solution

can

be

ob-

tained and written as (15).

7.3. Proof of Prop. 4.2
Proof. The result follows from replacing f with the Lp´norm function f2 and by noticing that the problem is convex since }x}p is convex w.r.t. x.

7. Appendix*
7.1. Proof of Prop. 3.1 Proof. The OP associated with (3) can be rewritten as:

Acknowledgement
This work is partially supported by the RTE-CentraleSupelec Chair.

M

minimize ´ pN1,...,NM ,r1,...,rM q

ÿ ÿ f px<prmq; gnq

m"1 nPNm

.

s.t. dipx<prmqq  0

ejpx<prmqq " 0

(21)

By replacing x<prmq with xm, the equivalence is proved.

7.2. Proof of Prop. 4.1

Proof. By plugging

< k

pxptqq

"

gk ptq´xptq 

into (10),

the

function f1px; gq can be rewritten as:

f1px; gq

T
ÿ "
t"1

« ´a~pxptq

´

1 2a~2

pbK

`

2aK

K
ÿ
k"1

gk ptqqq2

`

ff ctpgq

T
" ´ a~}Ag `  ´ x}22 ` ÿ ctpgq
t"1

(22)

References
References
[1] Krishnamurti T, Schwartz D, Davis A, Fischhoff B, de Bruin WB, Lave L, et al. Preparing for smart grid technologies: A behavioral decision research approach to understanding consumer expectations about smart meters. Energy Policy. 2012 Feb;41:790-7.
[2] Peng J, Sun Y, Wang HF. Optimal PMU placement for full network observability using Tabu search algorithm. Int J Elect Power Energy Syst. 2006 May;28(4):223-31.
[3] Teichgraeber H, Brandt AR. Clustering methods to find representative periods for the optimization of energy systems: An initial framework and comparison. Appl Energy. 2019 Apr;239:1283-93.
[4] Sankar L, Rajagopalan S R, Mohajer S, Poor HV. Smart meter privacy: A theoretical framework. IEEE Trans Smart Grid 2012; 4(2):837-846.
[5] Beaude O, Lasaulce S, Hennebel M, Mohand-Kaci I. Reducing the impact of EV charging operations on the distribution network. IEEE Trans Smart Grid 2016; 7(6):2666-79.

12

[6] Desgraupes B. Clustering indices, University of Paris OuestLab, Modal'X Tech Rep 2013; 1-34.
[7] Bahl B, Ku¨mpel A, Seele H, Lampe M, Bardow A. Time-series aggregation for synthesis problems by bounding error in the objective function. Energy 2017;135:900-12.
[8] Al-Wakeel A, Wu J, Jenkins N. K-means based load estimation of domestic smart meter measurements. Appl energy. 2017 May;194:333-42.
[9] Li W, Gong G, Fan H, Peng P, Chun L, Fang X. A clusteringbased approach for cross-scale load prediction on building level in HVAC systems. Applied Energy. 2021 Jan 15;282:116223.
[10] Tanoto Y, Haghdadi N, Bruce A, MacGill I. Clustering based assessment of cost, security and environmental tradeoffs with possible future electricity generation portfolios. Applied Energy. 2020 Jul 15;270:115219.
[11] Brodrick PG, Brandt AR, Durlofsky LJ. Operational optimization of an integrated solar combined cycle under practical timedependent constraints. Energy 2017;141:1569-84.
[12] Gabrielli P, Gazzani M, Martelli E, Mazzotti M. Optimal design of multi-energy systems with seasonal storage. Appl Energy 2018;219:408-24.
[13] Sudha KR, Raju YB, Sekhar AC. Fuzzy C-Means clustering for robust decentralized load frequency control of interconnected power system with Generation Rate Constraint. Int J Elect Power Energy Syst. 2012 May;37(1):58-66.
[14] Nahmmacher P, Schmid E, Hirth L, Knopf B. Carpe diem: A novel approach to select representative days for long-term power system modeling. Energy. 2016 Oct;112:430-42.
[15] Merrick JH. On representation of temporal variability in electricity capacity planning models. Energy Econ. 2016 Sep;59:26174.
[16] Tso WW, Demirhan CD, Heuberger CF, Powell JB, Pistikopoulos EN. A hierarchical clustering decomposition algorithm for optimizing renewable power systems with storage. Applied Energy. 2020 Jul 15;270:115190.
[17] Teeraratkul T, O'Neill D, Lall S. Shape-based approach to household electric load curve clustering and prediction. IEEE Trans Smart Grid 2017;9(5):5196-5206.
[18] Blanco I, Morales JM. An efficient robust solution to the twostage stochastic unit commitment problem. IEEE Trans Power Syst. 2017 Mar;32(6):4477-88.
[19] Motlagh O, Berry A, O'Neil L. Clustering of residential electricity customers using load time series. Applied energy. 2019 Mar 1;237:11-24.
[20] Kotzur L, Markewitz P, Robinius M, Stolten D. Impact of different time series aggregation methods on optimal energy system design. Renew Energy 2018;117:474-87.
[21] Pfenninger S. Dealing with multiple decades of hourly wind and PV time series in energy models: A comparison of methods to reduce time resolution and the planning implications of interannual variability. Appl Energy 2017; 197:1-13.
[22] Zhang L, Zhou WD, Jiao LC. Kernel clustering algorithm. Chinese J Comput. 2002 Jun;25(6):587-90.
[23] Elhamifar E, Vidal R. Sparse manifold clustering and embedding. In Advances in neural information processing systems 2011 (pp. 55-63).
[24] Jain AK. Data clustering: 50 years beyond K-means. Pattern Recognit Lett. 2010 Jun 1;31(8):651-66.
[25] Kriegel HP, Kro¨ger P, Sander J, Zimek A. Density-based clustering. Wiley Interdiscip Rev: Data Min Knowl Discov. 2011 May;1(3):231-40.
[26] Von Luxburg U. A tutorial on spectral clustering. Stat Comput. 2007 Dec;17(4):395-416.
[27] Zou H, Zhang C, Lasaulce S, Saludjian L, Panciatici P. Decisionoriented communications: Application to energy-efficient resource allocation. In Proceedings of the Sixth International Conference on Wireless Networks and Mobile Communications (WINCOM) 2018 Oct 16 (pp. 1-6).
[28] Gan L, Topcu U, Low SH. Stochastic distributed protocol for electric vehicle charging with discrete charging rate. In Proceedings of IEEE Power and Energy Society General Meeting 2012

Jul 22 (pp. 1-8). [29] Garey MR, Johnson D, Witsenhausen H. The complexity of
the generalized Lloyd-max problem (corresp.). IEEE Trans Inf Theory. 1982 Mar;28(2):255-6. [30] Hanna OA, Ezzeldin YH, Sadjadpour T, Fragouli C, Diggavi S. On Distributed Quantization for Classification. IEEE J Sel Areas Commun. 2020 Apr 8. [31] Fleischer P. Sufficient conditions for achieving minimum distortion in a quantizer. IEEE Innt Conv Rec. 1964: 104-111. [32] Trushkin A. Sufficient conditions for uniqueness of a locally optimal quantizer for a class of convex error weighting functions. IEEE Trans Inf Theory. 1982 Mar;28(2):187-98. [33] Gray RM, Neuhoff DL. Quantization. IEEE Trans Inf Theory. 1998 Oct;44(6):2325-83. [34] Samadi P, Mohsenian-Rad AH, Schober R, Wong VW, Jatskevich J. Optimal real-time pricing algorithm based on utility maximization for smart grid. In Proceedings of First IEEE International Conference on Smart Grid Communications 2010 Oct 4 (pp. 415-420). [35] Yang J, Zhao J, Wen F, Dong Z. A model of customizing electricity retail prices based on load profile clustering analysis. IEEE Trans Smart Grid. 2018 Apr 10;10(3):3374-86. [36] Roozbehani M, Dahleh MA, Mitter SK. Volatility of power grids under real-time pricing. IEEE Trans Power Syst. 2012 May;27(4):1926-40. [37] Petersen KB, Pedersen MS. The Matrix Cookbook. Kgs. Lyngby, Denmark: Tech. Univ. Denmark, 2006. [38] Kim TT, Poor HV. Scheduling power consumption with price uncertainty. IEEE Trans Smart Grid. 2011 Jul;2(3):519-27. [39] Pecan street inc. dataport. [Online]. Available: https://dataport.pecanstreet.org/data. [40] https://sites.google.com/site/l2szhangchao/data-sharing. [41] Lin J, Keogh E, Lonardi S, Chiu B. A symbolic representation of time series, with implications for streaming algorithms. In Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery 2003 Jun 13 (pp. 2-11). [42] Fonseca JA, Miller C, Schlueter A. Unsupervised load shape clustering for urban building performance assessment. Energy Procedia. 2017 Sep 1;122:229-234.

13

