arXiv:2106.01098v1 [cs.LG] 2 Jun 2021

Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and Practical Solutions
Leslie O'Bray1, 2,  Max Horn1, 2,  Bastian Rieck1, 2, ,  Karsten Borgwardt1, 2, 
1Department of Biosystems Science and Engineering, ETH Zurich, 4058 Basel, Switzerland 2SIB Swiss Institute of Bioinformatics, Switzerland These authors contributed equally. These authors jointly supervised this work.
Graph generative models are a highly active branch of machine learning. Given the steady development of new models of ever-increasing complexity, it is necessary to provide a principled way to evaluate and compare them. In this paper, we enumerate the desirable criteria for comparison metrics, discuss the development of such metrics, and provide a comparison of their respective expressive power. We perform a systematic evaluation of the main metrics in use today, highlighting some of the challenges and pitfalls researchers inadvertently can run into. We then describe a collection of suitable metrics, give recommendations as to their practical suitability, and analyse their behaviour on synthetically generated perturbed graphs as well as on recently proposed graph generative models.
1. Introduction
Graph generative models have become an active research branch, making it possible to generalise structural patterns inherent to graphs from certain domains--such as chemoinformatics--and actively synthesise new graphs [24]. Next to the development of improved models, their evaluation is crucial. This is a well-studied issue in other domains, leading to metrics such as the `Fréchet Inception Distance' [18] for comparing image-based generative models. Graphs, however, pose their own challenges, foremost among them being that an evaluation based on visualisations, i.e. on perceived differences, is often not possible. In addition, virtually all relevant structural properties of graphs exhibit spatial invariances-- connected components and cycles, for example, are invariant with respect to rotations--that have to be taken into account by a comparison metric.
While several such comparison metrics have already been established in previous work, neither their expressive power nor their other properties have been systemically compared. The goal of this paper is to provide such a comparison, starting from first principles by describing the desired properties of such comparison metrics. We will then compare different graph generative models using a variety of metrics, ranging from simple comparisons of the degree distribution of graphs to a more complicated analysis of its topological properties. Next to providing an overview of existing and novel metrics for this purpose, we also also analyse their respective expressive power, their computational efficiency, as well as their stability with respect to common graph perturbations. We additionally highlight the caveats and shortcomings of existing approaches when used to rank models, aiming to give actionable recommendations to practitioners. This paper purposefully refrains from developing its own graph generative model to avoid any bias in the comparison.
1

Use as filtration for direct input

Clustering coefficient

Rd

Degree distribution

Heat kernel trace

Laplacian spectrum

Topological data analysis
Optimal transport

Graphs Descriptor functions

Representations

MMD
Evaluator functions

Figure 1.: An overview of the workflow used to evaluate graph generative models: given a distribution of graphs, a set of descriptor functions is employed to map each graph to a high-dimensional representation in Rd. These representations are then compared (with a reference distribution or with each other) using evaluator functions based on optimal transport or the maximum mean discrepancy (MMD), resulting in a ranking of models. Note that the evaluator function based on topological data analysis does not require the use of auxiliary representations in Rd. In principle, MMD also does not require the vectorial representation, but in this context, it is typically the case. All bold parts in the figure highlight new additions to the comparison workflow that we will subsequently describe.

2. Comparing graph distributions
In the following, we will deal with undirected graphs. We denote such a graph as G = (V, E) with vertices V and edges E. We treat graph generative models as black-box models, each of which results in a set1 of graphs G. The original distribution of graphs is denoted as G. Given models {M1, M2, . . . }, with generated sets of graphs {G1, G2, . . . }, the goal of generative model evaluation is to assess which model is a better fit, i.e. which distribution is closer to G. This requires the use of a (pseudo-)metric d(·, ·) to assess the dissimilarity between G and generated graphs. We argue that the desiderata of any such comparison metric are as follows:
1. Expressivity: if G and G do not arise from the same distribution, a suitable metric should be able to detect this. Specifically, d(G, G ) should be monotonically increasing the further apart G and G are from one another.
2. Robustness: if a distribution G is subject to a perturbation, a suitable metric should be robust to small perturbations. Changes in the metric should be ideally upper-bounded by a function of the amplitude of the perturbation. Robust metrics are preferable because of the inherent stochasticity of training generative models.
3. Efficiency: model comparison metrics should be reasonably fast to calculate; even though model evaluation is a post hoc analysis, a metric should scale well with an increasing number of graphs and an increasing size of said graphs.
While there are many ways to compare two distributions, ranging from statistical divergence measures to proper metrics in the mathematical sense, the comparison of distributions of graphs is exacerbated by the fact that individual graphs typically differ in their cardinalities and are only described up to permutation. With distances such as the graph edit distance being NP-hard in general [41], which precludes using them as an efficient metric, a potential alternative is provided by using descriptor functions (see Section 6
1Formally, the output can also be a multiset, because graphs are allowed to be duplicated.

2

for alternatives). A descriptor function f maps a graph G to an auxiliary representation in some space Z. The problem of comparing a generated distribution G = {G1, . . . , Gn} to the original distribution G = {G1, . . . , Gm} thus boils down to comparing the images f (G) := { f (G1), . . . , f (Gn)}  Z and f (G)  Z by any preferred statistical distance in Z. Figure 1 depicts an overview of this approach and how it relates to the remainder of this paper, highlighting the additions to the overall comparison workflow that we propose.

3. Current state and associated challenges

Of particular interest in previous literature is the case of Z = Rd and using the maximum mean
discrepancy dMMD(·, ·) as a metric. MMD is one of the most versatile and expressive options available for comparing distributions of structured objects such as graphs [3, 13], providing also a principled way to
perform two-sample tests [4, 14, 25]. It enables the comparison of two statistical distributions by means
of kernels, i.e. similarity measures for structured objects. Letting X refer to a non-empty set, a function
k : X × X  R is a kernel if k(xi, xj) = k(xj, xi) for xi, xj  X and i,j cicj k(xi, xj)  0 for xi, xj  X and ci, cj  R. MMD uses such a kernel function to assess the distance between two distributions. Given n samples X = {x1, . . . , xn}  X and m samples Y = {y1, . . . , ym}  X , the empirical estimate of the MMD between X and Y is obtained as

MMD(X, Y)

:=

1 n2

n
 k(xi, xj) +
i,j=1

1 m2

m
 k(yi, yj) -
i,j=1

2 nm

nm
  k(xi, yj).
i=1 j=1

(1)

Since MMD is known to be a metric on the space of probability distributions under certain conditions,
Eq. 1 is often treated as a metric as well, even though it would be more correct to only use it for hypothesis/two-sample testing.2 Nevertheless, MMD has been adopted by the community and requires (i) choosing a descriptor function f as described above, and (ii) choosing a kernel on Rd such as an RBF kernel. One then evaluates dMMD(G, G) := MMD( f (G), f (G)) for a distribution G. Given multiple distributions {G1, G2, . . . }, the values dMMD(Gi, G) can be used to rank models: smaller values are assumed to indicate a larger agreement with the original distribution G. We will now describe this
procedure in more detail and highlight some of its pitfalls.

3.1. Descriptor functions and kernels
Before one can calculate the MMD distance between two distributions, it is necessary to define both the kernel function k and the descriptor function f that will convert a graph G to a representation in Z = Rd, for use in the MMD calculation in Eq. 1. A common choice among authors for the kernel function is the radial basis function kernel kRBF(x, y) := exp(- x-y 2/22) with a smoothing parameter   R, also known as the Gaussian kernel, or a Laplacian kernel kTV(x, y) := exp(- x - y ), with a smoothing parameter   R, and x - y referring to the Euclidean distance in Rd. While we have not observed its use in practice, we additionally consider the linear kernel, i.e. the canonical inner product on Rd, since it is parameter-free. In our experiments, we will use previously-described [24, 40] graph-level descriptor functions, namely (i) the degree distribution histogram, (ii) the clustering coefficient, and (iii) the Laplacian spectrum histogram. We also propose including a descriptor function based on the heat kernel trace of the graph Laplacian [34], i.e. an exponentially-weighted function of the sum of its eigenvalues. In contrast to the full Laplacian spectrum, the heat kernel trace can be efficiently approximated [34, 35] and does not require an eigendecomposition. For the degree distribution and clustering coefficient, we considered the option of normalising the resultant vector as a parameter. Additionally, for the clustering coefficient, we treat the number of bins nb  {100, 200, 300} as a parameter as well. Please refer to Section A.2 for a detailed explanation of all descriptor functions.
2We will follow this convention in this paper and refer to Eq. 1 as a distance.

3

3.2. Issues with this approach
Even though the calculation of MMD based on kernels on the range of descriptor functions provides a suitable way to asses the dissimilarity between probability distributions, there are certain issues with this approach, namely (i) the selected kernel might be computationally inefficient to compute, as is the case for the previously-used Earth Mover's Distance (EMD) kernel function, (ii) the use of positive definite kernel functions is a limitation, with previous work inadvertently employing functions that are not valid kernels, and (iii) finally, many kernels require selecting hyperparameters, and there is no clear way of choosing them. We will now discuss these issues before addressing common practices.
Issue (i) might prevent an evaluation metric to be used in practice, thus stymieing graph generative model development. Issue (ii) is more subtle and potentially more problematic. MMD requires that the kernel function is positive definite, but previous work [10] demonstrated that this is not true for a large class of functions, specifically those arising from a distance metric. Previous work [24] used a kernel based on the total variation distance between histograms, which has since been used in subsequent publications as one of the ways to evaluate different models. As we discuss in Appendix A.1, this approach leads to an indefinite kernel, whose behaviour in the context of MMD is not well-defined. Thus, care has to be taken when it comes to interpreting the respective results. Last, issue (iii) is the most notable, and we will therefore consider it in more depth. While the choice of which kernel to use in the MMD calculation is itself an a priori design choice without clear justification, it is further exacerbated by the fact that many kernels require choosing parameters (such as 2 and  for the Gaussian and Laplacian kernels, respectively), without any clear process by which to choose them. To the best of our knowledge, the selection of such parameters is glossed over in publications at present, even though literature outside the graph generative modelling domain describes such choices, for example in the context of two-sample tests [15] or general model criticism [32].
Common practice. Common practice among graph generative model papers is to fix a parameter, and then assess the newly-proposed model and existing competitor models using said parameter. There are two objections we have to this approach. First, since there is no inherent scale or meaning to the MMD metric presented, it is difficult to assess whether the smaller MMD distance of one model is substantially improved when compared to the MMD distance of another model. For instance, suppose that the MMD distance of one model is 5.2 × 10-8. Is that a meaningfully better model than one whose MMD distance is 4.6 × 10-7? Second, the choice of the parameter in the kernel calculation has a non-trivial effect on the MMD calculation: depending on the parameter choice, the ranking of different models can change.
To clearly illustrate these points, we provide a brief example with three real-world models, GraphRNN [40], GRAN [24], and Graph Score Matching [26]. We ran the models using the author-provided implementations to generate new graphs, and then calculated the MMD distance between the generated graphs and the test graphs, using (i) different kernels (Gaussian kernels, Laplacian kernels, and linear kernels), (ii) descriptor functions (degree histogram, clustering coefficient histogram, Laplacian spectrum, and heat kernel trace), and (iii) parameter ranges (,   {10-5, . . . , 102}. For simplicity we will refer to the parameter in either kernel as . We purposefully refrained from using model names, preferring instead `A, B, C' in order to focus on the issues imposed by such an evaluation, rather than providing a commentary on the performance of specific models. Figure 2 shows the results for the `Community Graphs' dataset, but the findings are consistent across the different datasets we tested. These figures are available for the other datasets in Appendix A.6.
Instability of rankings. Figure 2a provides a summary of the overall ranking of the three models, where each curve represents a single configuration of kernel, descriptor function, and parameter. We note that we would not necessarily expect for a single model to maintain its top rank when evaluated over different graph descriptor functions, such as the degree distribution and clustering coefficient distribution, since they are assessing different properties in the generated graphs. However,
4

Rank Rank MMD Distance to Original Graphs

Model A

Model B

Model C

3

3

1.0

Linear

RBF

TV

0.8

0.6

2

2

0.4

1
Model A

Model B
(a)

Model C

1 10 5 10 4 10 3 10 2 10 1 100 101 102
log( )
(b)

0.2

0.0

0.2

0.4

0.6

0.8

1.0

% Perturbation

(c)

Figure 2.: An investigation of the behaviour of MMD, described in detail in Section 3.2. Figure 2a shows how three recent graph generative models (whose names we intentionally omitted) rank against one another when using MMD as a metric, using different kernels, descriptor functions, and parameter ranges. Each line represents one such combination. Figure 2b depicts a more detailed ranking analysis, showing whether a specific combination of kernel and descriptor function (represented by a unique line) yields the same ranking of all models (distinguished by colours) across different parameter choices. Figure 2c shows how MMD performs as two graph distributions become increasingly dissimilar via perturbations. Each line is a different parameter­kernel combination.

it empirically is often the case that new models report the top rank across multiple descriptors. This summary view is therefore notable, because based on the current standard, models are in large part reporting to consistently outperform the competitor models, which would result in a stable ranking across descriptor functions. If this held true, and MMD were stable in its ranking, all lines would be stacked on top of each another. Instead, we notice that there are several different rankings of the models, which are nearly equally distributed, showing that the ranking is highly unstable and depends strongly on the particular setup (e.g. descriptor function and choice of parameter) for the comparison.
Instability with respect to parameter choices. Figure 2b provides a more detailed view of the ranking. Here, we similarly analyse the ranking of the models, but specifically investigate whether the ranking of the same combination of kernel and descriptor functions changes by varying kernel parameters. Each line therefore represents a unique kernel­descriptor combination, with colours specifying individual models. Ideally, each curve should maintain its rank across the entire parameter range (or a large part thereof). Instead, we see that despite keeping the kernel and descriptor function fixed, the ranking of a given model changes simply by changing the value of , and even flips. Furthermore, under some combinations, we observed the ranking to switch multiple times. The consequence of this is alarming: inadvertently, one can select kernel parameters that show a specific model to be the best, even though for a different selection said model could perform worse than the other models.
MMD does not always capture differences in graph distributions. Finally, Figure 2c analyses the behaviour of MMD as two graph distributions become increasingly dissimilar. We focus on a single descriptor function, the clustering coefficient, where each line once again represents a unique kernel and parameter choice. We increasingly perturbed the original test graphs and then measured the MMD to the original distribution. We ideally would like a graph comparison metric that increases monotonically as the degree of perturbation increases. Unfortunately, we see that the behaviour of the MMD as the graph distributions become dissimilar is highly sensitive to the respective configuration, exhibiting unexpected behaviour. In many cases, the distance remains nearly constant, despite the

5

increased level of perturbation, until it reaches extraordinary levels. In some cases, the distance even decreases as the degree of perturbation increases. Furthermore, the MMD values as a function of the degree of perturbation are highly sensitive with respect to the parameter selection, as evidenced by the wide range of curve shapes observed in Figure 2c.
4. Novel evaluator functions
We propose addressing the aforementioned issues with two alternative ways of performing an evaluation. First, we propose making use of recent advances in optimal transport in order to compare the high-dimensional distributions arising for each choice of high-dimensional graph descriptor function f : G  Rd. Second, we propose employing topology-based descriptors that are capable of capturing more connectivity information and are amenable to efficient distance calculations.
4.1. Comparing graph distributions using optimal transport
Optimal transport (OT) provides a principled way of comparing probability distributions, specifically those arising from probability spaces that also satisfy the properties of a metric space, e.g. for Z = Rd. The relationship of OT to MMD is well-studied [14] and recent work discusses efficient algorithms for calculating OT-based metrics [27]. We therefore suggest using an OT metric as a drop-in replacement to MMD. Let X  Rn×d and Y  Rm×d denote two matrices that collect two sets of distributions of high-dimensional vectors. Moreover, let M denote an n × m matrix of pairwise distances between rows of X and Y, evaluated using the (squared) Euclidean distance. Our optimal transport metric is then defined as W1(X, Y) := minP(X,Y) P, M F, with (X, Y) referring to all valid transportation plans and ·, · F denoting the Frobenius inner product; please refer to Section A.3 for more details on OT. The advantage of this procedure is that W1(X, Y) directly results in a distance metric; it therefore permits the ranking of models without requiring the choice of an additional kernel function with additional parameters.
4.2. Comparing graph distributions using topological data analysis
The field of topological data analysis (TDA) deals with understanding complex structured datasets by means of their topological features. Originally arising from algebraic topology, TDA methods are seeing increasing use in machine learning, in particular in the context of graph classification or graph representation learning [19, 20, 28, 42, 43]. For unlabelled graphs, simple types of topological features are the number connected components 0 as well as the number of cycles 1. It is possible to increase the expressivity of these counts, leading to a set of multi-scale Betti numbers. This requires the existence of a filtration function f : V  R that is defined on the vertices of a graph G = (V, E). The image of f , i.e. im f := {w1, w2, . . . , wn}, only attains a finite number of values because |V| is finite. Without loss of generality, let w1  · · ·  wn and let Gi refer to the subgraph induced by filtering G according to wi, such that Gi := (Vi, Ei), with Vi := {v  V | f (v)  wi}, and Ei := {(u, v)  E | max( f (u), f (v))  wi}. We have G1  G2  · · ·  Gn, making it possible to track the creation and destruction of topological features over im f . For instance, if a connected component is created in Gi but destroyed in Gj because it merges with another connected component, we assign it the tuple (wi, wj). The collection of all such tuples forms the persistence diagram DG, f of the pair (G, f ).3 Being subsets of R2 whose cardinality depends on the input graph, persistence diagrams are somewhat cumbersome to work with, which is why we represent them as a curve instead, i.e. as a function g : R  R, the Betti curve. The Betti
3Here, we focus only on 0-dimensional topological features, i.e. connected components. Higher-dimensional features can also be considered, resulting in a set of persistence diagrams.
6

curve g of a diagram DG, f is defined as g( ) := {(wi, wj)  DG, f |  [wi, wj]} . These curves admit an efficient distance calculation based on the L1 distance between functions [7, 29, 37].
To use Betti curves in practice, we require a descriptor function that can be turned into a filtration function f : V  R. Among the previously-described descriptor functions, every descriptor except for the Laplacian spectrum admits such a representation. For each descriptor f and a set of l graphs, we obtain a set of persistence diagrams {DG1, f , . . . , DGf , f }. We calculate their mean Betti curve g¯ and calculate its distance to the mean Betti curve g¯ of the original distribution, leading to another way to efficiently rank models without requiring pairwise comparisons of graphs. Since persistent homology can be calculated in the same time it takes to sort the edges of a graph, i.e. O(nE log nE) for a graph with nE edges, this procedure is highly efficient. The Betti curve calculation (as well as its distance) can be performed in linear time in the size of the graph, thus the runtime is dominated by calculating persistence diagrams. In practice, we find that this type of evaluation performs almost as fast as the heavily-optimised OT evaluation.
5. Experiments
To further assess the performance of MMD and our proposed evaluators, we systematically evaluate them under controlled settings to elucidate some of their properties. Throughout this analysis, we consider the different evaluation metrics under the aspects outlined in Section 2.
5.1. Experimental setup
We can analyse the desiderata outlined above using an experimental setting. In the following, we will assess expressivity, robustness, and efficiency for a set of common perturbations, i.e. (i) random edge insertions, (ii) random edge deletions, (iii) random rewiring operations, i.e. `swapping' edges, and (iv) random node additions. For each perturbation type, we will investigate how the metric changes for an ever-increasing degree of perturbation, where each perturbation is parametrized by at least one parameter. When removing edges, for instance, this is the probability of removing an edge in the graph. Thus for a graph with 100 edges and premove = 0.1 we would expect on average 90 edges to remain in the graph. Similar parametrizations apply for the other perturbations, for an more detailed description we refer to Appendix A.4. All these operations are inherently small-scale (though not necessarily localised to specific regions within a graph), but turn into large-scale perturbations of a graph depending on the strength of the perturbation performed. We performed these perturbations using our own Python-based framework for graph generative model comparison and evaluation. Our framework permits the simple integration of additional descriptor functions and evaluators; please refer to Appendix A.5 for more details.
The perturbation experiments are appealing because they do not require access to other models but rather only an initial distribution G. This procedure therefore does not leak any type of information from models and is unbiased. Moreover, researchers have more control over the ground truth in this scenario, as they can adjust the desired degree of dissimilarity.
5.2. Experimental results
Subsequently, we focus on Operation (i); please refer to Section A.6 for details on other scenarios.
5.2.1. Expressivity and robustness
Our principal goal was to assess how the aforementioned graph comparison methods fare when handling perturbations. We ideally want our metric to effectively reflect the degree of perturbations.
7

MMD Distance to Original Graphs MMD Distance to Original Graphs MMD Distance to Original Graphs

1.0

Linear

RBF

TV

0.8

0.6

0.4

0.2

0.0

0.2

0.4

0.6

0.8

1.0

% Perturbation

(a) MMD

1.0

0.8

0.6

0.4

0.2

0.2

0.4

0.6

0.8

1.0

% Perturbation

(b) TDA

1.0

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.2

0.4

0.6

0.8

1.0

% Perturbation

(c) OT

Figure 3.: An example of how the three evaluators react to the perturbation of progressively adding edges to the graph on the Community Graphs dataset. We use the degree distribution for MMD and OT, and the analogous degree filtration for the TDA evaluator. Since MMD requires the selection of a kernel and parameters, each line represents a unique combination. In OT, we considered both the normalised and unnormalised degree distribution, as in the linear kernel of MMD, but the results were so similar the lines are indistinguishable. An ideal metric for comparing graph distributions should reflect the degree of the perturbation.

Hence, with an increasing degree of perturbation--the insertion of more edges at random--of graphs, the distance to the original distribution G of unperturbed graphs should increase. We can therefore assess both the expressivity of the metric, i.e. its ability to distinguish two distributions when they are different, and its robustness (or stability) based on how rapidly such a metric changes when subject to small perturbations. Succinctly, we would like to see that the evaluator has a clear correlation with the degree of perturbation.
Comparison procedure. For each of the aforementioned perturbation types, we compared the graph distribution of the perturbed graphs with the original graphs using the MMD, TDA and OT evaluators. We repeated this for different scenarios, comprising different kernels, different descriptor functions, and where applicable, parameters. Since these experiments resulted in hundreds of combinations for MMD alone, due to the choice of kernel, descriptor function, and parameter choices, we relegated most of the visualisations to the Appendix (see Section A.6, which also provides more detailed plots) and focus only on edge perturbations. We provide a snapshot of these curves for a single data set (Community Graphs) and a single descriptor function (degree distribution) in Figure 3. In order to compare the different comparison functions effectively, we needed a way to condense the multitude of results into a more interpretable and comparable visualisation. We therefore calculated Pearson's correlation coefficient between the degree of perturbation and the resulting distance, calculated using one of the comparison functions from Figure 1. While this neatly summarised all the TDA evaluators, since all but one of them are parameter-free, we still had to choose between a large number of MMD parameters, and several OT parameters. We thus created two heatmaps, the first one showing the best parameter choice, the second one showing the worst parameter choice, both measured in terms of Pearson's correlation coefficient. In the absence of a meaningful, agreed-upon procedure to choose such parameters, the heatmaps effectively depict the extremes of what will happen if one is particularly `lucky' or `unlucky' in the choice of parameters. A robust combination of descriptor function and comparison function is characterised by both heatmaps exhibiting high correlation with the degree of perturbation.

8

BA

BA

BA

1.0

Community

Community

Community

ER

ER

ER

0.8

Proteins

Proteins

Proteins

WS

WS

WS

0.6

BA

BA

BA

Community

Community

Community

0.4

ER

ER

ER

Proteins WS

Proteins WS

Proteins WS

0.2

CC Degree HKTLaplacian

CC Degree HKS

CC Degree HKTLaplacian

0.0

(a) MMD

(b) TDA

(c) OT

Figure 4.: The correlation of the respective distance (MMD, TDA, and OT) with the degree of perturbation (here: adding edges) in the graph, assessed for different descriptor functions/filtrations. For an ideal metric, the distance would increase as the degree of perturbation increases; resulting in a correlation close to 1. The upper row shows the best results in terms of the correlation (for MMD, which has different kernels and parameters, we report only the single best configuration). As we can see, all evaluators report good results in this scenario. The lower row shows the worst correlation; here, all metrics except TDA are drastically different.

Correlation analysis. Figure 4 shows the results for the random edge insertion perturbation,4 which is somewhat analogous to the salt-and-pepper perturbation of images. For the best-case scenario in Figure 4 (top), all three evaluators perform in large part similarly across the different evaluator functions and datasets. However, we see the strongest consistency across evaluation functions and datasets in the TDA-based evaluator. This is to be expected; MMD can be an effective measure of differences in distributions, and our principal caution against it in the graph generative scenario is the fact that there currently is no agreed-upon way to choose the parameters or kernel of interest. However, Figure 4 (bottom), depicting the lowest correlation among all perturbations, shows a different story. The TDA evaluator when combined with the clustering coefficient filtration or the degree filtration does not change, since there are no parameters. The heat kernel signature filtration shows slightly lower values, but overall still high correlation. The behaviour of the MMD and OT evaluators is different. The MMD distance in many cases no longer shows any correlation with the degree of perturbation, and in the case of the clustering coefficient (CC), is even negatively correlated with the degree of perturbation. Such behaviour is undesired, and showcases a potential pitfall for authors if they inadvertently do not manage to pick a `good' parameter or kernel combination.
Ranking models. The perturbation analysis also yields an effective strategy for ranking models: for each descriptor function, we use the resulting curves (see Figure 3) to pick the parameters with the highest correlation, potentially pooling parameter sets across different perturbation experiments (or selecting the parameter set that has the highest average correlation). We may then use the combination of evaluator function, descriptor function, and corresponding parameters to obtain a ranking. This strategy underscores the idea of using descriptor functions and evaluators with small (or non-existent) parameter sets, as this results in perturbation experiments that are faster to run and evaluate.

4Please refer to Section A.6 for heatmaps depicting the other perturbation types.

9

5.2.2. Efficiency
Finally, our third property assesses whether the proposed metric is efficient to compute, and therefore scalable. MMD has an approximation that is linear in the number of graphs, permitting a fast calculation [14]. Similarly, the improvements proposed for OT result in a near-linear runtime in the input size. Furthermore, the TDA evaluator offers a runtime that is linear in the number of samples. Thus, all three options evaluators satisfy the criteria of being efficient to compute.
6. Discussion and practical recommendations
We provided a thorough analysis of how graph generative models are being currently assessed by means of MMD. While MMD itself is powerful and expressive, it was originally designed for a different problem [3, 13], and therefore can present challenges when comparing two distributions of graphs. We highlighted some of the pitfalls researchers may fall into if they are unaware of the behaviour of MMD in this context, namely that the choice of parameters can result in different rankings of different models, and may not monotonically increase as two graph distributions become increasingly dissimilar. We want to stress that this does not mean that MMD is unsuitable in this context. However, in the absence of an agreed-upon strategy in the field for comparing two graph distributions, there is no procedure on how to select suitable (i.e. stable) parameters for MMD. If the practitioner would nevertheless like to still use MMD, we suggest running a perturbation experiment as described in this paper, and choosing parameters that are highly correlated with the degree of perturbation. This way, the choice of parameters does not depend on the candidate models but only on the initial distribution.
Choosing descriptor functions and evaluator functions. In the interest of covering different properties of graph distributions, we suggest using the clustering coefficient and degree distribution, as well as either a heat kernel trace or a heat kernel signature, both of which are able to capture multi-scale properties of a graph (as opposed to using a Laplacian spectrum histogram). The downside of the perturbation selection experiment is that it requires a non-trivial amount of computational resources when one needs to repeat the analysis over a large grid of kernel and parameter combinations. As an alternative, we would recommend that practitioners use a different comparison function that satisfies our desiderata. We introduced two evaluators, one based on optimal transport (OT), and one based on topological data analysis (TDA), that performed favourably in all experiments. The advantage of the OT-based evaluator is that it satisfies the properties of a metric, regardless of the choice of descriptor function. By choosing ground distances accordingly, more complicated descriptor functions can be accommodated--we leave a domain-driven choice of ground distance for future work. The downside of any OT-based approach is that regularisation parameters for the approximation algorithm might impede convergence during optimisation. Another viable alternative is the TDA-based evaluator, which showed particular expressivity and robustness, and remained very efficient to compute. With recent research analysing the relation between statistics and TDA [6, 23], we would recommend considering this comparison function in future model evaluations.
Limitations and future work. Although we consider the OT-based and TDA-based evaluators as a promising alternative solution to the question of how to compare graph distributions, we acknowledge that our results are preliminary and the evaluators will benefit from further testing. This work was intended to provide a overview of the current situation, hint at possible solutions, and serve as a starting point for the community to embark on further investigations of the properties of these and other evaluators. One interesting avenue of future research could be the use of efficient graph kernels, as described in a recent review [2]. This would reduce the comparison pipeline in that graph kernels can be directly used with MMD, thus making graph descriptor functions unnecessary.
10

Conclusion. As this paper illustrates, the evaluation of graph generative models has certain idiosyncratic issues that need to be avoided in order to obtain fair and reproducible comparisons. We suggest that practitioners steer clear of the outlined pitfalls by choosing a suitable comparison function and reporting the robustness of their rankings; as our examples demonstrate, the respective hyperparameters of descriptor functions and/or kernels play a crucial role in determining the overall ranking, which often turns out to be unstable. Transparency about the choices of descriptors as well as the robustness of the ranking will make it easier to determine the performance of a specific model. Moreover, knowledge about the empirical properties of a generative model--specifically, the graphs it does well on and the graphs it does not--will also encourage further method development. All of this is contingent on having comparison metrics that are expressive, robust, and efficient to compute.
References
[1] J. Altschuler, J. Niles-Weed, and P. Rigollet. Near-linear time approximation algorithms for optimal transport via Sinkhorn iteration. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017.
[2] K. Borgwardt, E. Ghisu, F. Llinares-López, L. O'Bray, and B. Rieck. Graph kernels: State-of-the-art and future challenges. Foundations and Trends® in Machine Learning, 13(5­6):531­712, 2020.
[3] K. M. Borgwardt, A. Gretton, M. J. Rasch, H.-P. Kriegel, B. Schölkopf, and A. J. Smola. Integrating structured biological data by kernel maximum mean discrepancy. Bioinformatics, 22(14):e49­e57, 2006.
[4] W. Bounliphone, E. Belilovsky, M. B. Blaschko, I. Antonoglou, and A. Gretton. A test of relative similarity for model selection in generative models. In International Conference on Learning Representations, 2016.
[5] M. R. Bridson and A. Haefliger. The model spaces Mn. In Metric Spaces of Non-Positive Curvature, pages 15­31. Springer, Berlin, Heidelberg, 1999. ISBN 978-3-662-12494-9. doi: 10.1007/978-3-662-12494-9_2.
[6] P. Bubenik. Statistical topological data analysis using persistence landscapes. Journal of Machine Learning Research, 16(3):77­102, 2015.
[7] I. Chevyrev, V. Nanda, and H. Oberhauser. Persistence paths and signature features in topological data analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence, 42(1):192­202, 2020. doi: 10.1109/TPAMI.2018.2885516.
[8] F. R. K. Chung. Spectral Graph Theory, volume 92 of CBMS Regional Conference Series in Mathematics. American Mathematical Society, 1997.
[9] M. Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems, volume 26. Curran Associates, Inc., 2013.
[10] A. Feragen, F. Lauze, and S. Hauberg. Geodesic exponential kernels: When curvature and linearity conflict. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3032­3042, 2015.
[11] A. Genevay, M. Cuturi, G. Peyré, and F. Bach. Stochastic optimization for large-scale optimal transport. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 29. Curran Associates, Inc., 2016.
11

[12] S. Gerber and M. Maggioni. Multiscale strategies for computing optimal transport. Journal of Machine Learning Research, 18(72):1­32, 2017.
[13] A. Gretton, K. Borgwardt, M. Rasch, B. Schölkopf, and A. J. Smola. A kernel method for the two-sample-problem. In B. Schölkopf, J. C. Platt, and T. Hoffman, editors, Advances in Neural Information Processing Systems 19, pages 513­520. MIT Press, 2007.
[14] A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Schölkopf, and A. Smola. A kernel two-sample test. Journal of Machine Learning Research, 13(25):723­773, 2012.
[15] A. Gretton, D. Sejdinovic, H. Strathmann, S. Balakrishnan, M. Pontil, K. Fukumizu, and B. K. Sriperumbudur. Optimal kernel choice for large-scale two-sample tests. In F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems, volume 25. Curran Associates, Inc., 2012.
[16] A. Grigor'yan. Heat Kernel and Analysis on Manifolds. American Mathematical Society, 2009.
[17] M. Gromov. Hyperbolic groups. In S. M. Gersten, editor, Essays in Group Theory, pages 75­263. Springer, Heidelberg, Germany, 1987.
[18] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter. GANs trained by a two time-scale update rule converge to a local Nash equilibrium. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30, pages 6626­6637. Curran Associates, Inc., 2017.
[19] C. D. Hofer, F. Graf, B. Rieck, M. Niethammer, and R. Kwitt. Graph filtration learning. In Proceedings of the 37th International Conference on Machine Learning (ICML), volume 119 of Proceedings of Machine Learning Research, pages 4314­­4323. PMLR, 2020.
[20] M. Horn, E. De Brouwer, M. Moor, Y. Moreau, B. Rieck, and K. Borgwardt. Topological graph neural networks. arXiv preprint arXiv:2102.07835, 2021.
[21] N. Hu, R. M. Rustamov, and L. Guibas. Stable and informative spectral signatures for graph matching. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2313­2320, 2014.
[22] N. M. Kriege, P.-L. Giscard, and R. Wilson. On valid optimal assignment kernels and applications to graph classification. In Advances in Neural Information Processing Systems 29, pages 1623­1631. Curran Associates, Inc., 2016.
[23] R. Kwitt, S. Huber, M. Niethammer, W. Lin, and U. Bauer. Statistical topological data analysis A kernel perspective. In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 28. Curran Associates, Inc., 2015.
[24] R. Liao, Y. Li, Y. Song, S. Wang, W. Hamilton, D. K. Duvenaud, R. Urtasun, and R. Zemel. Efficient graph generation with graph recurrent attention networks. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.
[25] J. R. Lloyd and Z. Ghahramani. Statistical model criticism using kernel two sample tests. In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 28. Curran Associates, Inc., 2015.
[26] C. Niu, Y. Song, J. Song, S. Zhao, A. Grover, and S. Ermon. Permutation invariant graph generation via score-based generative modeling. In S. Chiappa and R. Calandra, editors, Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics, volume 108 of Proceedings of Machine Learning Research, pages 4474­4484. PMLR, 26­28 Aug 2020. URL http://proceedings. mlr.press/v108/niu20a.html.
12

[27] G. Peyré and M. Cuturi. Computational optimal transport: With applications to data science. Foundations and Trends® in Machine Learning, 11(5-6):355­607, 2019. doi: 10.1561/2200000073.
[28] B. Rieck, C. Bock, and K. Borgwardt. A persistent Weisfeiler­Lehman procedure for graph classification. In Proceedings of the 36th International Conference on Machine Learning, volume 97, pages 5448­5458. PMLR, June 2019.
[29] B. Rieck, F. Sadlo, and H. Leitte. Topological machine learning with persistence indicator functions. In H. Carr, I. Fujishiro, F. Sadlo, and S. Takahashi, editors, Topological Methods in Data Analysis and Visualization V, pages 87­101. Springer, Cham, Switzerland, 2020. ISBN 978-3-030-43036-8. doi: 10.1007/978-3-030-43036-8_6.
[30] A. J. Schwenk. Almost all trees are cospectral. In F. Harary, editor, New Directions in the Theory of Graphs, pages 275­307. Academic Press, 1973.
[31] J. Sun, M. Ovsjanikov, and L. Guibas. A concise and provably informative multi-scale signature based on heat diffusion. Computer Graphics Forum, 28(5):1383­1392, 2009.
[32] D. J. Sutherland, H.-Y. Tung, H. Strathmann, S. De, A. Ramdas, A. Smola, , and A. Gretton. Generative models and model criticism via optimized maximum mean discrepancy. In International Conference on Learning Representations, 2017.
[33] M. Togninalli, E. Ghisu, F. Llinares-López, B. Rieck, and K. Borgwardt. Wasserstein Weisfeiler­ Lehman graph kernels. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems (NeurIPS), volume 32, pages 6436­6446. Curran Associates, Inc., 2019.
[34] A. Tsitsulin, D. Mottin, P. Karras, A. Bronstein, and E. Müller. NetLSD: Hearing the shape of a graph. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 2347­2356, 2018.
[35] A. Tsitsulin, M. Munkhoeva, D. Mottin, P. Karras, A. Bronstein, I. Oseledets, and E. Müller. The shape of data: Intrinsic distance for data distributions. In International Conference on Learning Representations, 2020.
[36] S. Ubaru, J. Chen, and Y. Saad. Fast estimation of tr( f (a)) via Stochastic Lanczos Quadrature. SIAM Journal on Matrix Analysis and Applications, 38(4):1075­1099, 2017.
[37] Y. Umeda. Time series classification via topological data analysis. Transactions of the Japanese Society for Artificial Intelligence, 32(3):D­G72_1­12, 2017.
[38] E. R. van Dam and W. H. Haemers. Which graphs are determined by their spectrum? Linear Algebra and its Applications, 373:241­272, 2003.
[39] D. J. Watts and S. H. Strogatz. Collective dynamics of `small-world' networks. Nature, 393(6684): 440­442, 1998.
[40] J. You, R. Ying, X. Ren, W. Hamilton, and J. Leskovec. GraphRNN: Generating realistic graphs with deep auto-regressive models. In J. Dy and A. Krause, editors, Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 5708­5717. PMLR, 2018.
[41] Z. Zeng, A. K. H. Tung, J. Wang, J. Feng, and L. Zhou. Comparing stars: On approximating graph edit distance. Proceedings of the VLDB Endowment, 2(1):25­36, Aug. 2009. doi: 10.14778/1687627. 1687631.
13

[42] Q. Zhao and Y. Wang. Learning metrics for persistence-based summaries and applications for graph classification. In Advances in Neural Information Processing Systems 32 (NeurIPS), pages 9855­9866. Curran Associates, Inc., 2019.
[43] Q. Zhao, Z. Ye, C. Chen, and Y. Wang. Persistence enhanced graph neural network. In Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS), volume 108 of Proceedings of Machine Learning Research, pages 2896­2906. PMLR, 26­28 Aug 2020.
14

A. Appendix
The following sections provide additional details about the issues with existing methods. We also show additional plots of our ranking and perturbation experiments.

A.1. Kernels based on total variation distance

Previous work used kernels based on the total variation distance in order to compare evaluation functions via MMD. The choice of this distance, however, requires subtle changes in the selection of kernels for MMD--it turns out that the usual RBF kernel must not be used here!
We briefly recapitulate the definition of the total variation distance before explaining its use in the kernel context: given two finite-dimensional real-valued histograms X := {x1, . . . , xn} and Y := {y1, . . . , yn}, their total variation distance is defined as

dTV(X, Y)

:=

1 2

n

i=1

|xi

-

yi| .

(2)

This distance induces a metric space that is not flat. In other words, the metric space induced by Eq. 2 has non-zero curvature (a fact that precludes certain kernels from being used together with Eq. 2). We can formalise this by showing that the induced metric space cannot have a bound on its curvature.

Theorem 1. The metric space XTV induced by the total variation distance between two histograms is not in CAT(k) for k > 0, where CAT(k) refers to the category of metric spaces with curvature bounded from above
by k [17].

Proof. Let x1 = (1, 0, . . . , 0) and x2 = (0, 1, 0, . . . , 0). There are at least two geodesics--shortest paths--of the same length, one that first decreases the first coordinate and subsequently increases the second one, whereas for the second geodesic this order is switched. More precisely, the first geodesic proceeds from x1 to x1 - ( , 0, . . . , 0) for an infinitesimal > 0, until x0 = (0, . . . , 0) has been reached. Following this, the geodesic continues from x0 to x0 + (0, , 0, . . . , 0) in infinitesimal steps until x2 has been reached. The order of these two operations can be switched, such that the geodesic goes from x1 to (1, 1, 0, . . . , 0), from which it finally continues to x2. Both of these geodesics have a length of 1. Since geodesics in a CAT(k) space for k > 0 are unique [5, Proposition 2.11, p. 23], XTV is not in CAT(k) for k > 0.
Since every CAT(k) space is also a CAT(l) space for all l > k, this theorem has the consequence that XTV cannot be a CAT(0) space. Moreover, as every flat metric space is in particular a CAT(0) space, XTV is not flat. According to Theorem 1 of Feragen et al. [10], the associated geodesic Gaussian kernel, i.e. the kernel that we obtain by writing

k(x, y) := exp

-

dTV(X, 22

Y)2

,

(3)

is not positive definite and should therefore not be used with MMD. One potential fix for this specific distance involves using the Laplacian kernel, i.e.

k(x, y) := exp(- dTV(X, Y)).

(4)

The subtle difference between these kernel functions--only an exponent is being changed--demonstrate that care must be taken when selecting kernels for use with MMD.

A.2. Details on evaluation functions
We provide more details on the evaluation functions used in our experiments, highlighting their respective strengths and weaknesses.

15

A.2.1. Descriptors based on summary statistics
Degree distribution histogram. Given a graph G = (V, E), we obtain a histogram by evaluating deg(v) for v  V, where position i of the resulting histogram is the number of vertices with degree i. Assuming a maximum degree d and extending the histogram with zeroes whenever necessary, we obtain a mapping f : G  Rd. This representation has the advantage of being easy to calculate and easy to compare; by normalising it (so that it sums to 1), we obtain a size-invariant descriptor).

Clustering coefficient. The (local) clustering coefficient of a vertex v is defined as the fraction of edges within its neighbourhood, divided by the number of all possible edges between neighbours, i.e.

2 C(v) :=

(vi, vj)  E | vi = v or vj = v deg(v)(deg(v) - 1)

.

(5)

The value of C(v)  [0, 1] measures to what extent a vertex v forms a clique [39]. The collection of all clustering coefficients of a graph can be binned and converted into a histogram in order to obtain a graph-level descriptor. This function is also easy to calculate but is inherently local; a graph consisting of disconnected cliques or a fully-connected graph cannot be distinguished, for example.

A.2.2. Descriptors based on spectral graph theory

The basic idea of spectral methods involves assigning a matrix to a graph G, whose spectrum, i.e.

its eigenvalues and eigenvectors, is subsequently used as a characterisation of G. Let A refer to the

adjacency matrix of G, with Aij = 1 if and only if vertices vi and vj are connected by an edge in G (since G

is

undirected,

A

is

symmetric).

The

normalised

graph

Laplacian

is

defined

as

L

:=

I

-

D-

1 2

AD-

1 2

,

where

I

denotes the identity matrix and D refers to the degree matrix, i.e. Dii = deg(vi) for a vertex vi and Dij = 0 for i = j. The matrix L is real-valued and symmetric, so it is diagonalisable with a full set of eigenvalues

and eigenvectors. Letting 1  2  . . . refer to the eigenvalues of L, we have 0  i  2 [8, Chapter 1, Lemma 1.7].

Laplacian spectrum histogram. The aforementioned property lends itself naturally to a histogram representation (regardless of the size of G), making it possible to bin the eigenvalues and use the resulting histogram as a simplified descriptor of a graph. This endeavour is only partially justified by the theory--in fact, the question of whether graphs are fully determined by their spectrum is still open [38] and has only been partially answered in the negative for certain classes of graphs [30].

Heat kernel signature and trace. The graph Laplacian is attractive precisely because it carries a large amount of structural information about the graph. The shape matching literature, for example, defines the heat kernel signature [31] or generalisations thereof [21]. It is motivated by heat diffusion on graphs and can be shown to be linked to the Laplace­Beltrami operator on manifolds [16]. The heat kernel signature is defined on the level of individual vertices of a graph, making it cumbersome to derive a graph-level representation5. We thus propose using the heat kernel trace (HKT), defined as

n

HKT(t) :=  exp(-it),

(6)

i=1

where t  R+ denotes the diffusion time: small values emphasise local properties (small neighbourhoods), while large values emphasise global properties of G. By evaluating Eq. 6 for different values of t, we obtain a vector of fixed dimensionality that summarises a graph. Making use of recent advances

5Since the signature is primarily used for shape matching, it needs to be defined on the vertex level. Extensions to the graph level involve assumptions such as equal cardinality of vertex sets.

16

in approximation algorithms [36], it is possible to approximate the heat kernel trace reliably without performing a full eigendecomposition of the Laplacian. This operation can be performed in time logarithmic in the number of vertices of the graph [35].

A.3. Details on optimal transport
We provide some additional details on optimal transport and recapitulate some content and equations from the main paper. Adopting a discrete viewpoint for the sake of notational simplicity, we assume that we are given two sets of distributions of high-dimensional vectors, collected in two matrices X  Rn×d and Y  Rm×d, respectively, with the usual convention that rows of X, Y correspond to individual samples. Letting M refer to the n × m matrix of distances between pairs of rows of X and Y, evaluated using the (squared) Euclidean distance, for instance, our optimal transport metric is defined as

W1(X,

Y)

:=

min
P(X,Y)

P, M

F,

(7)

with (X, Y) referring to all valid transportation plans6 and ·, · F denoting the Frobenius inner product. Eq. 7 depicts the first Wasserstein distance between X and Y, which has shown exceptional promise in graph classification tasks [22, 33]. Other scaled variants exist as well, but we refrained from adding them to the experimental section because most efficient approximation algorithms pertain to Eq. 7 or variants thereof.
In fact, OT-based distances were considered impractical for large-scale applications until recent advances demonstrated that they can be well-approximated with efficient algorithms [1, 9, 11, 12, 27]. Moreover, their well-studied relationship to maximum mean discrepancy [14] makes them an ideal replacement for MMD. Instead of solving Eq. 7 exactly, we solve its variant with entropic regularisation, resulting in near linear-time computational complexity in the input size, i.e.  O(nm) for distributions of size n, m. In contrast to MMD as shown in Eq. 1, OT leads directly to a distance measure--thus permitting the ranking of models--and does not require the choice of an additional kernel function with additional parameters. It is possible to change the distance function used to calculate P, but this choice should be driven by the choice of Z. With Z = Rd for all evaluators, the standard Euclidean distance is the canonical choice. Practically, Eq. 7 turns out to be faster to calculate than Eq. 1 as only a single matrix optimisation has to be solved, whereas Eq. 1 requires the calculation of three matrices.

A.4. Details on graph perturbations
We describe all graph perturbations used in this work on the example of a single graph G := (V, E) where V refers to the vertices of the graph and E to the edges.

Add Edges For each vi, vj  V with vi = vj a sample from a Bernoulli distribution xij  Ber(padd) is drawn. Samples for which xij = 1, are added to the list of edges such that E = E  {(vi, vj) | xij = 1}.
Remove Edges For each ei  E a sample from a Bernoulli distribution xi  Ber(premove) is draw, samples with xi = 1 are removed from the edge list, such that E = E  {ei | xi = 1}.
Rewire Edges For each ei  E a sample from a Bernoulli distribution xi  Ber(prewire) is drawn, samples with xi = 1 are rewired. For rewiring a further random variable yi  Ber(0.5) is drawn which determines which node ei[yi] of the edge ei is kept. The node to which the edge is connected is chosen uniformly from the set of vertices vi  V, where vi / ei, i.e. avoiding self-loops and reconnecting the
6A transportation plan is an n × m matrix whose rows and columns sum to 1/n and 1/m, respectively, because the total transported probability mass must sum to 1. In essence, this means that we must map all probability mass from X to Y and vice versa.

17

original edge. Finally the original edge is removed and the new edge ei = (ei[yi], vi) is added to the graph E = E  {ei | xi = 1}  {ei | xi = 1}.
Add Connected Node We define a set of vertices to be added V = {vi | |V| < i  |V| + n}, where n represents the number of nodes to add. For each vi  V and vj  V we draw a sample from a Bernoulli distribution xij  Ber(pconnect_node) and an edge between vi and vj to the graph if xij = 1. Thus E = E  {(vi, vj) | vi  V, vj  V, xij = 1}.
A.5. Implementation details
We used the official implementations of GraphRNN, GRAN and Graph Score Matching in our experiments. GraphRNN and GRAN both have an MIT License, and Graph Score Matching is licensed under GNU General Public License v3.0. We will make our code available under a BSD 3-Clause license upon publication of this paper.
Compute resources. All the jobs were run on our internal cluster, comprising 64 physical cores (Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz) with 8 GeForce GTX 1080 GPUs. We stress that the main component of this paper, i.e. the evaluation functions themselves, do not necessarily require a cluster environment. The cluster was chosen because individual generative models had to be trained in order to obtain generated graphs, which we can subsequently analyse and rank.
Evaluation framework. Our evaluation framework is extensible and can easily accommodate additional descriptors for comparing graphs. We distinguish between evaluators (for performing the ranking) and descriptors. All of these combinations are managed in a large list:
evaluators += [ OTEvaluation(heat_kernel_trace), MMDEvaluation(degree_distribution, linear_kernel), ...
]
Each combination is then called with its corresponding parameters:
iterations, scores, times = eval_iterations( X, Y[index], n_iter, n_samples_iter, evaluator, **params
)
Writing new evaluators. The framework can be easily extended. A skeleton of the evaluator for optimal transport metrics could look as follows:
class OTEvaluation: """Optimal transport evaluation class."""
def __init__(self, descriptor_fn, metric='sqeuclidean'): """Create new instance of evaluator. Parameters ---------descriptor_fn : callable Function for turning an input graph into a vectorial representation. Needs to support being called for an individual graph. metric : str or callable, optional Describes metric to use for the cost matrix calculation. If a string is provided, needs to be compatible with ot.dist interface. Else, a callable can be provided. """ self.descriptor_fn = descriptor_fn self.metric = metric
def __call__(self, X, Y, **kwargs): """Evaluate optimal transport distance between samples. Parameters ----------
18

X : iterable of graphs First distribution of graphs. Needs to be compatible with descriptor function.
Y : iterable of graphs Second distribution of graphs. Needs to be compatible with descriptor function.
**kwargs: Further keyword arguments. Will be shown to the descriptor function and can influence its calculation.
Returns ------Optimal transport distance between X and Y , measured according to the provided descriptor function. """ fn_values_X = [self.descriptor_fn(x, **kwargs) for x in X] fn_values_Y = [self.descriptor_fn(y, **kwargs) for y in Y] fn_values_X, fn_values_Y = ensure_padded(fn_values_X, fn_values_Y) # Following terminology for other evaluators. m = len(X) n = len(Y) a = np.asarray(m * [1.0 / m]) b = np.asarray(n * [1.0 / n]) M = dist(fn_values_X, fn_values_Y, self.metric) M = M.astype(float, copy=False) # Regularisation can of course also be made configurable. loss = sinkhorn2(a, b, M, 100) return loss[0] @property def __name__(self): """Return dictionary of parameters for evaluator.""" return {
'evaluator': 'OTEvaluator', 'descriptor_fn': self.descriptor_fn.__name__, 'metric': self.metric if isinstance(self.metric, str) else self.metric.__name__ }
Writing new descriptor functions. Descriptor functions can be easily added as well. They merely need to support generating an output on the graph level and may feature an arbitrary number of parameters. Here is an example of the degree distribution function, for instance:
def degree_distribution(G, density=False, **kwargs): """Calculate degree distribution of a graph.""" hist = nx.degree_histogram(G) if density: hist = np.divide(hist, np.sum(hist)) return np.asarray(hist)
In this case, we do not have to take care of different dimensions of the resulting histograms, as they can by default be zero-extended. Global information can nevertheless be supplied to such a function using the usual **kwargs mechanism.
A.6. Experimental results
19

3

3

3

3

Rank

Rank

Rank

Rank

2

2

2

2

1
Model A

Model B
(a) BA

Model C

1
Model A

Model B

Model C

(b) Community

1
Model A

Model B
ER

Model C

1
Model A

Model B
WS

Model C

Figure A.1.: The full ranking results presented in Figure 2a across all datasets. It shows how MMD ranks three different graph generative models (intentionally unspecified) when using different kernels, descriptor functions and parameter ranges. Each line represents a kernel, descriptor function, and parameter choice. Although we do not expect a single model to always outperform other models when assessed using different descriptor functions, we have empirically observed that this is often reported. If MMD were a stable metric, this would mean that all lines are stacked on top of one another. Instead, we observe that MMD returns several different ranking of the models, and the rankings are approximately equally distributed.

Rank

Model A

Model B

Model C

3

Model A

Model B

Model C

3

Model A

Model B

Model C

3

Model A

Model B

Model C

3

Rank

Rank

Rank

2

2

2

2

1 10 5 10 4 10 3 10 2 10 1 100 101 102
log( )
(a) BA

1 10 5 10 4 10 3 10 2 10 1 100 101 102
log( )
(b) Community

1 10 5 10 4 10 3 10 2 10 1 100 101 102
log( )
ER

1 10 5 10 4 10 3 10 2 10 1 100 101 102
log( )
WS

Figure A.2.: The ranking of the three models across datasets, as is presented in Figure 2b. It provides a more detailed investigation into the ranking of different models when only the parameters, generally called , are changed. Each line represents a kernel and descriptor function combination, and the ranking is shown across a range of values of the respective parameters, here deemed . Ideally, the choice of  should not change the ranking of the models; however, this is not the case.

20

Distance to Original Graphs

Descriptor Function = Degree

Distance to Original Graphs

Descriptor Function = CC

dataset = BarabasiAlbertGraphs

dataset = CommunityGraphs

dataset = ErdosRenyiGraphs

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.0

0.0

0.0

0.0

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.0

0.0

0.0

0.0

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.0

0.0

0.0

0.0

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8 0.6 0.4 0.2
0.2

0.4 0.6 0.8 % Pertubation

0.8

0.6

0.4

0.2

0.0

1.0

0.2

0.4 0.6 0.8 % Pertubation

0.8

0.6

0.4

0.2

1.0

0.2

0.4 0.6 0.8 % Pertubation

0.8

0.6

0.4

0.2

0.0

1.0

0.2

dataset = Proteins
0.4 0.6 0.8 % Pertubation

Distance to Original Graphs

Distance to Original Graphs

dataset = WattsStrogatzGraphs 1.0 0.8 0.6 0.4 0.2 0.0 1.0 0.8 0.6 0.4 0.2 0.0 1.0 0.8 0.6 0.4 0.2 0.0 1.0

Distance to Original Graphs

Distance to Original Graphs

0.8

0.6

0.4

0.2

1.0

0.2 0.4 0.6 0.8 1.0

% Pertubation

Distance to Original Graphs

Descriptor Function = Laplacian

Distance to Original Graphs

Descriptor Function = HKT

Figure A.3.: Evaluator function: MMD; perturbation: adding edges. This figure shows the full results across datasets, descriptor functions and parameters when the perturbation is adding edges to the graphs. At each level of perturbation, the distance of the perturbed graphs is calculated to the original graph distribution using the specified evaluator function. Each line represents a different parameter combination. An ideal evaluator function would monotonically increase as the degree of perturbation increases.

21

Distance to Original Graphs

Filtration Function = Degree

Distance to Original Graphs

Filtration Function = CC

dataset = BarabasiAlbertGraphs

dataset = CommunityGraphs

dataset = ErdosRenyiGraphs

dataset = Proteins

1.00

1.0

1.0

1.0

dataset = WattsStrogatzGraphs 1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.95

0.8

0.9

0.8

0.8

0.90

0.6

0.8

0.6

0.6

0.85

0.4

0.7

0.4

0.4

0.80

0.2

0.2

0.6

0.2

1.0

1.00

1.000

1.000

1.000

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.9

0.999

0.995

0.8

0.99

0.995

0.998

0.990

0.7

0.98

0.990

0.997 0.996

0.985 0.980

0.6

0.995

0.985

0.975

0.97 0.5

0.994 0.970

0.980

0.993

1.000

1.00

1.00

1.00

1.000

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.995 0.990

0.95

0.99

0.98

0.96

0.995

0.985

0.90

0.98

0.94 0.990

0.980

0.97

0.92

0.975

0.85

0.90

0.985

0.96

0.970 0.965

0.80

0.95

0.88

0.86

0.980

0.2 0.4 0.6 0.8 1.0

0.2 0.4 0.6 0.8 1.0

0.2 0.4 0.6 0.8 1.0

0.2 0.4 0.6 0.8 1.0

0.2 0.4 0.6 0.8 1.0

% Pertubation

% Pertubation

% Pertubation

% Pertubation

% Pertubation

Distance to Original Graphs

Filtration Function = HKS

Figure A.4.: Evaluator function: TDA; perturbation: adding edges. This figure shows the full results across datasets, descriptor functions and parameters when the perturbation is adding edges to the graphs. At each level of perturbation, the distance of the perturbed graphs is calculated to the original graph distribution using the specified evaluator function. Each line represents a different parameter combination. An ideal evaluator function would monotonically increase as the degree of perturbation increases.

22

Distance to Original Graphs

Descriptor Function = Degree

Distance to Original Graphs

Descriptor Function = CC

dataset = BarabasiAlbertGraphs

dataset = CommunityGraphs

dataset = ErdosRenyiGraphs

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.0

1.0

1.0

1.0

1.0

dataset = Proteins

Distance to Original Graphs

dataset = WattsStrogatzGraphs 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3
1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.2

0.0

0.0

0.0

0.0

0.0

1.0

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.2

0.0

0.0

0.0

0.0

0.0

1.00

1.00

1.00

1.00

1.00

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.95

0.98

0.99

0.95

0.90

0.95

0.96

0.98 0.97

0.90

0.85

0.90

0.94

0.96

0.85

0.80

0.85

0.92 0.90

0.95 0.94

0.80

0.75

0.88

0.93

0.2 0.4 0.6 0.8 1.0 % Pertubation

0.2 0.4 0.6 0.8 1.0 % Pertubation

0.2 0.4 0.6 0.8 1.0 % Pertubation

0.2 0.4 0.6 0.8 1.0 % Pertubation

0.2 0.4 0.6 0.8 1.0 % Pertubation

Distance to Original Graphs

Descriptor Function = Laplacian

Distance to Original Graphs

Descriptor Function = HKT

Figure A.5.: Evaluator function: OT; perturbation: adding edges. This figure shows the full results across datasets, descriptor functions and parameters when the perturbation is adding edges to the graphs. At each level of perturbation, the distance of the perturbed graphs is calculated to the original graph distribution using the specified evaluator function. Each line represents a different parameter combination. An ideal evaluator function would monotonically increase as the degree of perturbation increases.

23

Distance to Original Graphs

Descriptor Function = Degree

Distance to Original Graphs

Descriptor Function = CC

dataset = BarabasiAlbertGraphs

dataset = CommunityGraphs

dataset = ErdosRenyiGraphs

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.0

0.0

0.0

0.0

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.0

0.0

0.0

0.0

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.0

0.0

0.0

0.0

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8 0.6 0.4 0.2 0.0
0.2

0.4 0.6 0.8 % Pertubation

0.8

0.6

0.4

0.2

0.0

1.0

0.2

0.4 0.6 0.8 % Pertubation

0.8

0.6

0.4

0.2

0.0

1.0

0.2

0.4 0.6 0.8 % Pertubation

0.8

0.6

0.4

0.2

0.0

1.0

0.2

dataset = Proteins
0.4 0.6 0.8 % Pertubation

dataset = WattsStrogatzGraphs 1.0

Distance to Original Graphs

0.8

0.6

0.4

0.2

0.0 1.0

Distance to Original Graphs

0.8

0.6

0.4

0.2

0.0 1.0

Distance to Original Graphs

0.8

0.6

0.4

0.2

0.0 1.0

Distance to Original Graphs

0.8

0.6

0.4

0.2

0.0

1.0

0.2 0.4 0.6 0.8 1.0

% Pertubation

Distance to Original Graphs

Descriptor Function = Laplacian

Distance to Original Graphs

Descriptor Function = HKT

Figure A.6.: Evaluator function: MMD; perturbation: removing edges. This figure shows the full results across datasets, descriptor functions and parameters when the perturbation is removing edges from the graphs. At each level of perturbation, the distance of the perturbed graphs is calculated to the original graph distribution using the specified evaluator function. Each line represents a different parameter combination. An ideal evaluator function would monotonically increase as the degree of perturbation increases.

24

Distance to Original Graphs

Filtration Function = Degree

Distance to Original Graphs

Filtration Function = CC

dataset = BarabasiAlbertGraphs

dataset = CommunityGraphs

dataset = ErdosRenyiGraphs

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

dataset = Proteins

Distance to Original Graphs

dataset = WattsStrogatzGraphs 1.0 0.8 0.6 0.4 0.2

1.0

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.2

0.0

0.0

0.0

0.0

0.0

1.0

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.2

0.0

0.0

0.0

0.0

0.0

0.2 0.4 0.6 0.8 1.0 % Pertubation

0.2 0.4 0.6 0.8 1.0 % Pertubation

0.2 0.4 0.6 0.8 1.0 % Pertubation

0.2 0.4 0.6 0.8 1.0 % Pertubation

0.2 0.4 0.6 0.8 1.0 % Pertubation

Distance to Original Graphs

Filtration Function = HKS

Figure A.7.: Evaluator function: TDA; perturbation: removing edges. This figure shows the full results across datasets, descriptor functions and parameters when the perturbation is removing edges from the graphs. At each level of perturbation, the distance of the perturbed graphs is calculated to the original graph distribution using the specified evaluator function. Each line represents a different parameter combination. An ideal evaluator function would monotonically increase as the degree of perturbation increases.

25

Distance to Original Graphs

Descriptor Function = Degree

Distance to Original Graphs

Descriptor Function = CC

dataset = BarabasiAlbertGraphs

dataset = CommunityGraphs

dataset = ErdosRenyiGraphs

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.0

0.0

0.0

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.0

0.0

0.0

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.0

0.0

0.0

0.0

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0.0 0.2

0.4 0.6 0.8 % Pertubation

0.0

1.0

0.2

0.4 0.6 0.8 % Pertubation

0.0

1.0

0.2

0.4 0.6 0.8 % Pertubation

0.0

1.0

0.2

dataset = Proteins
0.4 0.6 0.8 % Pertubation

Distance to Original Graphs

dataset = WattsStrogatzGraphs 1.0 0.8 0.6 0.4 0.2

1.0

Distance to Original Graphs

0.8

0.6

0.4

0.2

0.0 1.0

Distance to Original Graphs

0.8

0.6

0.4

0.2

0.0 1.0

Distance to Original Graphs

0.8

0.6

0.4

0.2

0.0

1.0

0.2 0.4 0.6 0.8 1.0

% Pertubation

Distance to Original Graphs

Descriptor Function = Laplacian

Distance to Original Graphs

Descriptor Function = HKT

Figure A.8.: Evaluator function: OT; perturbation: removing edges. This figure shows the full results across datasets, descriptor functions and parameters when the perturbation is removing edges from the graphs. At each level of perturbation, the distance of the perturbed graphs is calculated to the original graph distribution using the specified evaluator function. Each line represents a different parameter combination. An ideal evaluator function would monotonically increase as the degree of perturbation increases.

26

Distance to Original Graphs

Descriptor Function = Degree

Distance to Original Graphs

Descriptor Function = CC

dataset = BarabasiAlbertGraphs 1.0

dataset = CommunityGraphs 1.0

dataset = ErdosRenyiGraphs

0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0

0.0

10

0.8

20

0.6

0.4 30
0.2 40
0.0

1e13

1.0

1.0

0.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.5

0.8

0.6

0.6

1.0

0.6

0.4

0.4

0.4

1.5

0.2

0.2

0.2

0.0

0.0

2.0

1e34

1e13

0

0

0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

10

2

1

0.8

20

4

2 0.6

30

6

3 0.4

40

4

8

dataset = Proteins

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

dataset = WattsStrogatzGraphs 1.0 0.8 0.6 0.4 0.2 0.0
1.0 0.8 0.6 0.4 0.2 0.0
1.0 0.8 0.6 0.4 0.2 0.0

1.0

1.00

5.0

1.0

2.5

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.75 0.50

0.8

2.5 0.0

0.8

2.0

0.25

0.6

2.5

0.6

1.5

5.0

1.0

0.00

0.4

7.5

0.4

0.5

0.25

10.0

0.0

0.2 0.4 0.6 0.8 1.0 % Pertubation

0.2 0.4 0.6 0.8 1.0 % Pertubation

0.2 0.4 0.6 0.8 1.0 % Pertubation

0.2 0.4 0.6 0.8 1.0 % Pertubation

0.2 0.4 0.6 0.8 1.0 % Pertubation

Distance to Original Graphs

Descriptor Function = Laplacian

Distance to Original Graphs

Descriptor Function = HKT

Figure A.9.: Evaluator function: MMD; perturbation: rewiring edges. This figure shows the full results across datasets, descriptor functions and parameters when the perturbation is rewiring edges in the graphs. At each level of perturbation, the distance of the perturbed graphs is calculated to the original graph distribution using the specified evaluator function. Each line represents a different parameter combination. An ideal evaluator function would monotonically increase as the degree of perturbation increases.

27

Distance to Original Graphs

Filtration Function = Degree

Distance to Original Graphs

Filtration Function = CC

dataset = BarabasiAlbertGraphs

dataset = CommunityGraphs

dataset = ErdosRenyiGraphs

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.9

0.8

0.8

0.8

0.8

0.7

0.6

0.6

0.6

0.6

0.4

0.4

0.5

0.4

0.4

0.2

0.2

0.2

0.3

0.0

0.0

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.2

0.2

0.4

0.2

0.0

0.0

0.2

0.0

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.2

0.2

0.4

0.2

0.0

0.0

0.2 0.4 0.6 0.8 1.0

0.2 0.4 0.6 0.8 1.0

% Pertubation

% Pertubation

0.0

0.2 0.4 0.6 0.8 1.0

0.2

% Pertubation

dataset = Proteins
0.4 0.6 0.8 % Pertubation

dataset = WattsStrogatzGraphs 1.0

Distance to Original Graphs

0.8

0.6

0.4

0.2

1.0

Distance to Original Graphs

0.8

0.6

0.4

0.2

0.0 1.0

Distance to Original Graphs

0.8

0.6

0.4

0.2

0.0

1.0

0.2 0.4 0.6 0.8 1.0

% Pertubation

Distance to Original Graphs

Filtration Function = HKS

Figure A.10.: Evaluator function: TDA; perturbation: rewiring edges. This figure shows the full results across datasets, descriptor functions and parameters when the perturbation is rewiring edges in the graphs. At each level of perturbation, the distance of the perturbed graphs is calculated to the original graph distribution using the specified evaluator function. Each line represents a different parameter combination. An ideal evaluator function would monotonically increase as the degree of perturbation increases.

28

Distance to Original Graphs

Descriptor Function = Degree

Distance to Original Graphs

Descriptor Function = CC

dataset = BarabasiAlbertGraphs

dataset = CommunityGraphs

dataset = ErdosRenyiGraphs

1.0

1.0

1.00

1.0

dataset = Proteins

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.9

0.9

0.98

0.9

0.8

0.8

0.96

0.8

0.7

0.7

0.94

0.7

0.6

0.6

0.5

0.6

0.92

0.5

0.5

0.90

0.4

0.4

0.3

1.0

1.0

1.00

1.0

Distance to Original Graphs

dataset = WattsStrogatzGraphs 1.0 0.8 0.6 0.4 0.2 1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.9

0.95

0.8

0.8

0.90 0.8

0.6

0.6

0.6

0.85

0.4

0.7

0.4

0.4

0.80

0.2

0.6

0.2

0.75

0.0

1.00

1.00

1.000

1.00

1.00

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.98

0.95

0.995

0.95

0.95

0.96

0.90 0.990

0.90

0.90

0.85 0.94

0.85

0.85

0.92

0.80

0.985

0.80

0.80

0.75

0.980

0.75

1.0

1.0

1.0

1.0

1.0

0.9 0.8 0.7 0.6 0.5 0.4
0.2 0.4 0.6 0.8 1.0 % Pertubation

Distance to Original Graphs

0.9 0.8 0.7 0.6 0.5 0.4
0.2 0.4 0.6 0.8 1.0 % Pertubation

Distance to Original Graphs

0.9
0.8
0.7
0.6 0.2 0.4 0.6 0.8 1.0 % Pertubation

Distance to Original Graphs

0.9 0.8 0.7 0.6 0.5 0.4
0.2 0.4 0.6 0.8 1.0 % Pertubation

Distance to Original Graphs

0.9 0.8 0.7 0.6 0.5 0.4
0.2 0.4 0.6 0.8 1.0 % Pertubation

Distance to Original Graphs

Descriptor Function = Laplacian

Distance to Original Graphs

Descriptor Function = HKT

Figure A.11.: Evaluator function: OT; perturbation: rewiring edges. This figure shows the full results across datasets, descriptor functions and parameters when the perturbation is rewiring edges in the graphs. At each level of perturbation, the distance of the perturbed graphs is calculated to the original graph distribution using the specified evaluator function. Each line represents a different parameter combination. An ideal evaluator function would monotonically increase as the degree of perturbation increases.

29

Distance to Original Graphs

Descriptor Function = Degree

Distance to Original Graphs

Descriptor Function = CC

dataset = BarabasiAlbertGraphs

dataset = CommunityGraphs

dataset = ErdosRenyiGraphs

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.9

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.7

0.4

0.4

0.4

0.6

0.5

0.2

0.2

0.2

0.4

0.0

0.0

0.0

0.3

1e25

1e7

1.0

0.0

0.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.5

0.5

0.8

0.6

1.0

1.5

1.0

0.6

0.4

2.0

1.5

0.2

0.4

2.5

0.0

2.0

1.0 0.8 0.6 0.4 0.2 0.0
1.0 0.8 0.6 0.4 0.2
6

Distance to Original Graphs

0 1000 2000 3000 4000 5000

1.0

Distance to Original Graphs

0.8

0.6

0.4

0.2

8 10 12 14

6

# Nodes Added

Distance to Original Graphs

1.0 0.8 0.6 0.4 0.2 0.0

1.0

Distance to Original Graphs

0.8

0.6

0.4

0.2

8 10 12 14

6

# Nodes Added

Distance to Original Graphs

1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3

1.0

Distance to Original Graphs

0.8

0.6

0.4

0.2

8 10 12 14

6

# Nodes Added

dataset = Proteins

Distance to Original Graphs

dataset = WattsStrogatzGraphs 1.0 0.9 0.8 0.7 0.6 0.5 0.4

Distance to Original Graphs

1.0 0.9 0.8 0.7 0.6 0.5 0.4

Distance to Original Graphs

1.0 0.8 0.6 0.4 0.2 0.0
1.0 0.8 0.6 0.4 0.2

Distance to Original Graphs

8 10 12 14 # Nodes Added

6 8 10 12 14 # Nodes Added

Distance to Original Graphs

Descriptor Function = Laplacian

Distance to Original Graphs

Descriptor Function = HKT

Figure A.12.: Evaluator function: MMD; perturbation: adding connected nodes. This figure shows the full results across datasets, descriptor functions and parameters when the perturbation is adding connected nodes to the graphs (for each node that is added, there is a 15% chance the node will be connected to any other node in the graph). At each level of perturbation, the distance of the perturbed graphs is calculated to the original graph distribution using the specified evaluator function. Each line represents a different parameter combination. An ideal evaluator function would monotonically increase as the degree of perturbation increases.

30

Distance to Original Graphs

Filtration Function = Degree

Distance to Original Graphs

Filtration Function = CC

dataset = BarabasiAlbertGraphs

dataset = CommunityGraphs

dataset = ErdosRenyiGraphs

1.0

1.0

1.00

1.00

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.9

0.95

0.95

0.90

0.8

0.90

0.6

0.85

0.7

0.85

0.80

0.4

0.6

0.80

0.75

0.2

0.70

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.9

0.9

0.9

0.9

0.8

0.8

0.8

0.8

0.7

0.7

0.7

0.7

0.6

0.6

0.6

0.6

0.5

0.5

0.5

0.5

0.4

0.4

0.4

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.9 0.8 0.7 0.6 0.5
6

8 10 12 # Nodes Added

0.8

0.6

0.4

0.2

14

6

8 10 12 # Nodes Added

0.9

0.8

0.7

0.6

0.5

14

6

0.8

0.6

0.4

8 10 12 # Nodes Added

0.2

14

6

dataset = Proteins

Distance to Original Graphs

dataset = WattsStrogatzGraphs 1.00 0.95 0.90 0.85 0.80 0.75 0.70

8 10 12 # Nodes Added

Distance to Original Graphs

1.0 0.9 0.8 0.7 0.6 0.5 0.4 1.00

Distance to Original Graphs

0.95

0.90

0.85

0.80

0.75

14

6

8 10 12 14 # Nodes Added

Distance to Original Graphs

Filtration Function = HKS

Figure A.13.: Evaluator function: TDA; perturbation: adding connected nodes. This figure shows the full results across datasets, descriptor functions and parameters when the perturbation is adding connected nodes to the graphs (for each node that is added, there is a 15% chance the node will be connected to any other node in the graph). At each level of perturbation, the distance of the perturbed graphs is calculated to the original graph distribution using the specified evaluator function. Each line represents a different parameter combination. An ideal evaluator function would monotonically increase as the degree of perturbation increases.

31

Distance to Original Graphs

Descriptor Function = Degree

Distance to Original Graphs

Descriptor Function = CC

dataset = BarabasiAlbertGraphs 1.0

dataset = CommunityGraphs 1.0

Distance to Original Graphs

0.9 0.9
0.8 0.8
0.7

0.6

0.7

0.5

0.6

1.0

1.00

Distance to Original Graphs

0.9

0.95

0.90 0.8
0.85

0.7

0.80

0.6

0.75

0.5

0.70

1.00

1.00

Distance to Original Graphs

0.95

0.98

0.90

0.96

0.85

0.94

0.92 0.80
0.90 0.75

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

dataset = ErdosRenyiGraphs

1.0

1.0

Distance to Original Graphs

0.9

0.9

0.8

0.8

0.7

0.7

0.6

0.6

0.5

0.5

0.4

1.0

1.0

Distance to Original Graphs

0.9

0.9

0.8

0.8

0.7

0.7

0.6

0.6

0.5 0.5

0.4 0.4

1.00

1.000

Distance to Original Graphs

0.975 0.95
0.950

0.90

0.925

0.85

0.900

0.875 0.80
0.850

1.0

1.0

1.0

1.0

Distance to Original Graphs

Distance to Original Graphs

Distance to Original Graphs

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2 6

8 10 12 # Nodes Added

0.2

14

6

8 10 12 # Nodes Added

0.2

14

6

8 10 12 # Nodes Added

0.0

14

6

dataset = Proteins

Distance to Original Graphs

Distance to Original Graphs

dataset = WattsStrogatzGraphs 1.0 0.9 0.8 0.7 0.6 0.5 0.4 1.0 0.9 0.8 0.7 0.6 0.5

8 10 12 # Nodes Added

Distance to Original Graphs

1.00 0.95 0.90 0.85 0.80 0.75 0.70

1.0

Distance to Original Graphs

0.9

0.8

0.7

0.6

0.5

0.4

0.3

14

6

8 10 12 14 # Nodes Added

Distance to Original Graphs

Descriptor Function = Laplacian

Distance to Original Graphs

Descriptor Function = HKT

Figure A.14.: Evaluator function: OT; perturbation: adding connected nodes. This figure shows the full results across datasets, descriptor functions and parameters when the perturbation is adding connected nodes to the graphs (for each node that is added, there is a 15% chance the node will be connected to any other node in the graph). At each level of perturbation, the distance of the perturbed graphs is calculated to the original graph distribution using the specified evaluator function. Each line represents a different parameter combination. An ideal evaluator function would monotonically increase as the degree of perturbation increases.

32

BA

BA

BA

1.0

Community

Community

Community

ER

ER

ER

0.8

Proteins

Proteins

Proteins

WS

WS

WS

0.6

BA

BA

BA

Community

Community

Community

0.4

ER

ER

ER

Proteins WS

Proteins WS

Proteins WS

0.2

CC Degree HKTLaplacian

CC Degree HKS

CC Degree HKTLaplacian

0.0

(a) MMD

(b) TDA

(c) OT

Figure A.15.: Perturbation: adding edges. The correlation of the respective distance (MMD, TDA, and OT) with the degree of perturbation (here: adding edges) in the graph, assessed for different descriptor functions/filtrations. For an ideal metric, the distance would increase as the degree of perturbation increases; resulting in a correlation close to 1. The upper row shows the best results in terms of the correlation (for MMD, which has different kernels and parameters, we report only the single best configuration). As we can see, all evaluators report good results in this scenario. The lower row shows the worst correlation; here.

BA

BA

BA

1.0

Community

Community

Community

ER

ER

ER

0.8

Proteins

Proteins

Proteins

WS

WS

WS

0.6

BA

BA

BA

Community

Community

Community

0.4

ER

ER

ER

Proteins WS

Proteins WS

Proteins WS

0.2

CC Degree HKTLaplacian

CC Degree HKS

CC Degree HKTLaplacian

0.0

(a) MMD

(b) TDA

(c) OT

Figure A.16.: Perturbation: removing edges. The correlation of the respective distance (MMD, TDA, and OT) with the degree of perturbation (here: removing edges) in the graph, assessed for different descriptor functions/filtrations. For an ideal metric, the distance would increase as the degree of perturbation increases; resulting in a correlation close to 1. The upper row shows the best results in terms of the correlation (for MMD, which has different kernels and parameters, we report only the single best configuration). As we can see, all evaluators report good results in this scenario. The lower row shows the worst correlation.

33

BA

BA

BA

1.0

Community

Community

Community

ER

ER

ER

0.8

Proteins

Proteins

Proteins

WS

WS

WS

0.6

BA

BA

BA

Community

Community

Community

0.4

ER

ER

ER

Proteins WS

Proteins WS

Proteins WS

0.2

CC Degree HKTLaplacian

CC Degree HKS

CC Degree HKTLaplacian

0.0

(a) MMD

(b) TDA

(c) OT

Figure A.17.: Perturbation: rewiring edges. The correlation of the respective distance (MMD, TDA, and OT) with the degree of perturbation (here: rewiring edges) in the graph, assessed for different descriptor functions/filtrations. For an ideal metric, the distance would increase as the degree of perturbation increases; resulting in a correlation close to 1. The upper row shows the best results in terms of the correlation (for MMD, which has different kernels and parameters, we report only the single best configuration). As we can see, all evaluators report good results in this scenario. The lower row shows the worst correlation.

BA Community
ER Proteins
WS
BA Community
ER Proteins
WS CC Degree HKTLaplacian

BA Community
ER Proteins
WS
BA Community
ER Proteins
WS
CCDegreHe KS

BA

1.0

Community

ER

0.8

Proteins

WS
0.6

BA

Community

0.4

ER

Proteins

WS

0.2

CC Degree HKTLaplacian

0.0

(a) MMD

(b) TDA

(c) OT

Figure A.18.: Perturbation: adding connected nodes. The correlation of the respective distance (MMD, TDA, and OT) with the degree of perturbation (here: adding connected nodes, where each node added has the probability of having an edge to any other node fixed at 15%) in the graph, assessed for different descriptor functions/filtrations. For an ideal metric, the distance would increase as the degree of perturbation increases; resulting in a correlation close to 1. The upper row shows the best results in terms of the correlation (for MMD, which has different kernels and parameters, we report only the single best configuration). As we can see, all evaluators report good results in this scenario. The lower row shows the worst correlation.

34

