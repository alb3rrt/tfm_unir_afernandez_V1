Online Detection of Vibration Anomalies Using
Balanced Spiking Neural Networks
Nik Dennler§, Germain Haessig, Matteo Cartiglia, and Giacomo Indiveri Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland Department of Computer Science, KTH Royal Institute of Technology Stockholm, Sweden
Department of Computer Science, University of Hertfordshire, United Kingdom §International Center for Neuromorphic Systems, Western Sydney University, Australia
Corresponding author: nik.dennler@posteo.net

arXiv:2106.00687v1 [cs.NE] 1 Jun 2021

Abstract--Vibration patterns yield valuable information about the health state of a running machine, which is commonly exploited in predictive maintenance tasks for large industrial systems. However, the overhead, in terms of size, complexity and power budget, required by classical methods to exploit this information is often prohibitive for smaller-scale applications such as autonomous cars, drones or robotics. Here we propose a neuromorphic approach to perform vibration analysis using spiking neural networks that can be applied to a wide range of scenarios. We present a spike-based end-to-end pipeline able to detect system anomalies from vibration data, using building blocks that are compatible with analog-digital neuromorphic circuits. This pipeline operates in an online unsupervised fashion, and relies on a cochlea model, on feedback adaptation and on a balanced spiking neural network. We show that the proposed method achieves state-of-the-art performance or better against two publicly available data sets. Further, we demonstrate a working proof-of-concept implemented on an asynchronous neuromorphic processor device. This work represents a significant step towards the design and implementation of autonomous lowpower edge-computing devices for online vibration monitoring.
Index Terms--predictive maintenance, spiking neural networks, cochlea, E-I balance, neuromorphic processor
I. INTRODUCTION
The analysis of vibration patterns is an essential part of industrial Predictive Maintenance (PM), which is the schematic health monitoring of a degrading system. Leading to reparations and replacements that come just-in-time, PM promises to be an energy- and cost-saving alternative over routine or time-based preventive maintenance. Today, PM is mainly used in cases where maintenance requires an expensive shutdown of the system, as in railway technology, windmills and large manufacturing plants [1]. But also smaller-scale systems like mobile robots, drones and autonomous cars constitute a favourable platform for PM. In these systems, space, power, and latency are often critical factors, which motivates our neuromorphic approach to PM.
The use of mixed-signal analog/digital neuromorphic technology to implement on-chip spiking neural networks (SNNs), allows for highly efficient signal processing, minimizing latency, bandwidth, memory usage, and power consumption. These SNN chips provide an asynchronous event-driven information processing modality, where computation happens only when data in present. As such, they represent a promising

alternative to traditional deep learning approaches for edge applications that require ultra-low power computing capabilities. Recently, SNNs have been used to solve a wide range of engineering problems, such as image classification speech recognition [2], sensor fusion [3], motor control [4], biomedical signal processing [5] and vibration-based soundlocalization [6].
In this work we propose a pipeline to detect arising system anomalies from vibrational data, using proven building blocks compatible with analog/digital neuromorphic circuits. This approach operates in an unsupervised online fashion, relying on feedback adaptation. The pipeline is tested against two publicly available data sets, where state-of-the-art results are reached. Furthermore, we implemented parts of this work on the Dynamic Neuromorphic Asynchronous Processor (DYNAP-SE) [7].
The pipeline can be summarized in three steps: (1) decomposing raw accelerometer data into frequency components, (2) transforming the continuous signal into spike trains, (3) analyzing the spike trains with a SNN. Specifically, the decomposition into frequency components is done using a cochlea model. The conversion into spike trains is achieved by using an asynchronous sigma-delta modulator, where for an initial time window, an adaptive spiking-threshold pins the spiking frequencies of all channels to a fixed target rate. Finally, a balanced neural network performs anomaly detection by detecting frequency deviations across the channels. The full pipeline is illustrated in Figure 1.
II. ANOMALY DETECTION PIPELINE
A. Frequency Decomposition
Cochlea models are ideal candidates to perform frequency decomposition of acoustic waves. Specifically, they implement a Gammatone filterbank [9], which is a tonotopically organized set of linear filters, each tuned to a specific center frequency fc. Several analog Very-Large-Scale-Integration (VLSI) circuits have been proposed to implement such filterbanks [10]. They provide an essential building block for low-power auditory processing, as they use analog and digital event-based circuits to capture many details of the biological cochlear functionality.

a

b

c

Atarget

P

Vthr

Vthr

d
Brian2 DYNAP-SE

Accelerometer Vibration Recordings

Gammatone Filterbank

Asynchr. Delta Modulator w. Threshold Adaptation

Balanced Spiking Neural Network

Anomaly Alert

Fig. 1. Anomaly detection pipeline. a: Raw accelerometer vibration recordings from bearings that degrade over time. b: Gammatone filterbank (cochlea model), decomposing the signal into frequency channels. c: Spike generation through an Asynchronous Delta Modulator. Additionally, for an initial calibration time, a low-pass filter and a proportional control feedback mechanism pin the spiking activity to a fixed target value Atarget by adapting the threshold Vthr for each channel. d: Balanced Spiking Neural Network, triggering an anomaly alert if one or multiple channels deflect from target rate. Excitatory connections
are illustrated in blue, inhibitory connections in red. The network is simulated in Brian2 [8] and implemented on the the DYNAP-SE chip [7].

The impulse response of each Gammatone filter is given by a gamma distribution function multiplied by a sinusoidal:

g(t) = atn-1e-2bt cos(2fct + ),

(1)

where a, n, b and  describe the amplitude, filter order, bandwidth and phase respectively. Here we use a cochlea model with logarithmically spaced frequency channels to decompose the raw vibration recordings into their spectral representation. We use a cascade of four second-order filters applied to the signal in the Laplace domain.

B. Spike Conversion

To benefit of the power advantages offered by spike-based signal processing, the filtered signal needs to be encoded into asynchronous spike trains. For this, we use the Asynchronous Delta Modulator (ADM) [11], [12]: whenever the signal crosses a predefined upper (lower) threshold, an up (down) spike is generated, and simultaneously, the crossed threshold subtracted from the signal. In this matter, the spiketrain represents the changes in amplitude rather than the amplitude itself. A refractory period tr prevents the generation of multiple spikes within a given time window.
As the amplitudes across frequency channels can vary greatly, we propose an online calibration method inspired by homeostatic plasticity [13], [14]. We assume that, initially, the system is in a healthy state and its noise is constant. For a given initial time window tadapt of the systems healthy state, an exponentially weighted running average tracks the spiking neuron activity Aup (Adn). The thresholds Vthr are then modified in a proportional control scheme to drive the activity towards a fixed target activity Atarget:

Aup = Aup + (sup - Aup)/

(2)

Vthr,up = Vthr,up +  · (Aup - Atarget)

(3)

Analogous equations hold for Adown and Vthr,down. Here, sup (sdn) is a binary value, indicating if there has been at least one up (down) spike in the current time step.  and  denote

the exponential running average time constant and the learning rate, or gain. The method is illustrated in Figure 1c.

C. Neuron and Synapse Model

We chose to use a simple model of a Leaky-Integrate-and-

Fire (LIF) neuron [15]. The neurons membrane is modelled by

an electrical circuit composed of a resistor R and a capacitor C

in parallel, where the membrane potential Vmem is described

by

dVmem = (Vrest - Vmem) + RI .

(4)

dt

RC

Here, Vrest is the resting potential and I the inflowing current. If Vmem of a pre-synaptic neuron exceeds the threshold voltage Vthr, Vmem of the post-synaptic neuron increases or decreases by w, depending on if the connection is of excitatory or

inhibitory nature. For further processing, only up-spikes were

used.

D. Anomaly Detection Network Structure
Our spike representation encodes information in the channel-wise spike rate, where after tadapt, all input channels fire with approximately the same rate. Once the system starts to deflect from its healthy state, one or multiple of the channels will deflect from their target rate. We propose a three layer SNN, which is designed to detect such channel-wise rate deflections. Next to the N -dimensional input layer and one output neuron, the network consists of a N -dimensional hidden layer, in which a tight balance of excitatory and inhibitory connections is implemented: Each hidden neuron hj combines an excitatory projection of one input neuron nj with an inhibitory projection of all other input neurons nk,k=j. The weight between neuron nj and hj is set to be  · (N - 1) times larger than the weight between any other input neuron nk,k=j and hj :

wnj,hj =  · (N - 1) · wnk,hj,k=j .

(5)

Here,  = 1.25 is a scaling parameter. The hidden neurons project with symmetric excitatory connections to the output

a

d

Healthy No.3

Healthy No.1

Channels

Channels

Activty (normalized)

b

0
0.05

0.04

0.03

0.02

20

40
target Ch0 Ch1 Ch2 Ch3 Ch4 Ch5 Ch6 Ch7

60
Ch8 Ch9 Ch10 Ch11 Ch12 Ch13 Ch14 Ch15

0.01

0.00

c

0

0.10

20

40

60

Firing Threshold

0.08

0.06

0.04

0.02

0.00
0

20

40

60

Time (s)
Threshold

Adaptation

Vmem (mV)

Vmem (mV)

Vmem (mV)

0
­40 ­70
e

Healthy No.3

Defective No.4

Channels

0
­40 ­70
0
f

2 tadapt 4

6

8

Time (s)

10

12

Channels

0

­40

­70

0 tadapt 200

400

600

800

1000

f

Time (s)
Spiking Neural Network Analysis

(Simulation)

Channel Rates (Hz)
11 12 13 14 15 16 21 22 23 24 25 26 31 32 33 34 35 36 11 12 13 14 15 16 21 22 23 24 25 26 31 32 33 34 35 36 11 12 13 14 15 16 21 22 23 24 25 26 31 32 33 34 35 36

g
1400 1200 1000
800 600 400 200
0
h
1000

Input Layer
Run ID
Input Layer

800

IHnipdudteLnaLyaeyrer

IOnuptuptuLtaLyaeyrer

20

25

15

20

15 10

10 5
5 0

Run ID

Run ID

IHnipdudteLnaLyaeyrer

IOnuptuptuLtaLyaeyrer

7

17.5

6

15.0

5

12.5

healthy defective

Channel Rates (Hz)

600

4

10.0

3

7.5

400

2

5.0

200

1

2.5

0

0.0

0

250 500 750 1000

Time (s)

0

250 500 750 1000

Time (s)

0

250 500 750 1000

Time (s)

DYNAP-SE Measurements

(Hardware)

Fig. 2. a-c: Threshold adaptive spike generation. a shows channel activity of initial tadapt = 60s in input layer of Run-To-Failure Bearing Data Set, bearing 4 (R2F, b4), resulting from the fixed-rate threshold adaptation mechanism shown in b & c. d - f: Simulation results. Channel activity of input layer and combined membrane potential (black) and neuron activity (red) of output neuron. From top to bottom: Induced Bearing Fault Data Set (IBF) , 3-1 (healthy-healthy), IBF, 3-4 (healthy-defective) and R2F, b4. g & h: DYNAP-SE results. g shows measured rates for all experiments in IBF, where h shows measured rates for R2F, b4. Dots and error bars correspond to averages and standard deviations of multiple trials. Black dotted line illustrates separation in healthy and defective.

neuron. This Balanced Spiking Neural Network architecture (BSNN) is inspired by Efficient Balance Networks [16] and promises sparse spike trains in the healthy state and rapid reaction times for arising anomalies. The network is simulated using Brian2 [8] and illustrated in Figure 1d.
III. DATASETS
The model is tested against two publicly available datasets, where the first one is used to evaluate the models reliability, and the second to benchmark time-to-fault-detection.
A. Induced Bearing Fault Data Set (IBF)
IBF [17] comprises of measurements from a bearing test rig. We choose six experimental trials that were conducted under the same circumstances: on three healthy bearings and three bearings with outer race faults, a radial load of 122.5 kg and shaft speed of 25 Hz were applied. The measurements consist of accelerometer recordings of t = 6 s, sampled at 97.656 kHz. We concatenated all pairs of trials that begin with healthy bearings. Thus, we obtained a dataset of 18 experimental runs, composed of healthy-healthy and healthy-defective trials. The aim is to detect the transition from healthy to defective as accurately and fast as possible.
B. Run-To-Failure Bearing Fault Data Set (R2F)
R2F [18] contains multi-day measurements of four bearings, with applied radial load of 2721 kg and shaft speed of 33.3 Hz.

Accelerometers at each bearing take 20480 samples at 20 kHz every 10 min. The initially healthy bearings degrade over time until the system fails completely. The aim is to detect the arising failure as early as possible. We test our system on one run-to-failure experiments, consisting of 984 recordings. Here, an outer race failure occurred in bearing number 1. For each sensor, the recordings are concatenated to one large time series, omitting the intervals between the recordings. Stateof-the-art detection-times have been reported using One Class Least Squares Support Vector Machines (LSSVM) [19] and Autoencoder Correlation-Based Rate methods (AEC) [20].
IV. ANALYSIS AND RESULTS
For analyzing both IBF and R2F, the recordings are decomposed into 16 frequency channels and subsequently converted to spike trains. There, during the first tadapt, which is 3 s and 60 s respectively, the thresholds adapt according to Eq. 3 to reach a firing rate ftarget of 500 Hz and 100 Hz. The spikes are then fed into the BSNN. While the networks input weights wi,h are fixed, the output weights wh,o as well as the global neuron time constant c = RC have to be tuned. Here we use an initial time window of 3 s of one of the 18 IBF runs, and of 300 s of one of the four R2F runs, during which wh,o and c are optimized to yield the highest output neuron membrane potential without the neuron producing spikes. After this, all parameters remain fixed for all runs. The output neuron is

monitored for each run. If a spike is measured, an anomaly detection is registered.
For IBF, we obtain a perfect confusion matrix resulting from our model: all healthy-faulty transitions are detected, while no spikes are present for any healthy-healthy transition. The time between experiment transition (healthy-defective) to first spike across the 18 runs is tdetect = (0.17 ± 0.08)s. For R2F, we show in Table I the resulting times-to-first-spike for all four bearings (b1-b4), compared to the current stateof-the-art [19], [20]. For b3 & b4, our method enables an earlier anomaly detection than the other methods. Figures 2ac show the evolving thresholds and neuron activities during calibration, while Figures 2d-f display the BSNN activity.

TABLE I DETECTION TIMES (DATAPOINT) FOR RUN-TO-FAILURE DATASET

b1 b2 b3 b4

LSSVM 533 823 893 700

AEC

547 - -

-

This work 543 890 873 683

V. DYNAP-SE IMPLEMENTATION
As a proof-of-concept, we implemented the BSNN on the Dynamic Neuromorphic Asynchronous Processor (DYNAPSE) [7]. The DYNAP-SE neurons were connected according to the BSNN architecture described previously. The input layer was fed with the spikes generated by the ADM, and the activity of all neurons measured. To overcome memory issues posed by the large number of spike-times, we assumed an interval-wise Poisson process, which was used to generate the spike-trains on-chip. We measured the time constants of all neurons on the chip and selected pairs of neurons, for which the incoming charge from excitatory and inhibitory connections are balanced. Further, to gain robustness, we used a low output spike rate for the healthy state and a high rate for the anomalous state. Figures 2g&h show the measured firing rate of each silicon neuron, for all experiments in IBF an for R2F, b4. Figure 2g displays that the output neuron provides a linearly separable representation of healthy and anomalous data. In Figure 2h, a steep increase in output firing rate successfully reveals the arising anomaly.
VI. DISCUSSIONS AND CONCLUSION
In this work, we presented a neuromorphic pipeline that detects machine anomalies from vibration pattern recordings. We showed that, based on the evaluation on two industrial bearing fault data sets, anomalies are registered in a robust and accurate manner, and we achieve state-of-the art faultdetection times. The spiking neural network was both implemented in simulation and validated on the asynchronous neuromorphic processor DYNAP-SE.
On the grounds of this work, we aim to design, assemble and manufacture an ultra-low power end-to-end hardware solution. This will make predictive maintenance accessible for edge-devices and finally will have an impact towards a more ecological and sustainable Industry 4.0.

ACKNOWLEDGEMENT
The authors thank D. Zendrikov for the technical support
in using the DYNAP-SE, T. Koch for providing the CAD
drawings, as well as K. Burelo, A. Renner, F. Baracat and
C. Nauer for fruitful discussions. This work was partially
supported by the Swiss National Science Foundation Sinergia
project #CRSII5-18O316 and the ERC Grant "NeuroAgents"
(724295).
REFERENCES
[1] R. K. Mobley, An introduction to predictive maintenance. Elsevier, 2002. [2] J. Wu, E. Yilmaz, M. Zhang, H. Li, and K. C. Tan, "Deep spiking neural
networks for large vocabulary automatic speech recognition," Frontiers in Neuroscience, vol. 14, p. 199, 2020. [3] P. O'Connor, D. Neil, S. C. Liu, T. Delbruck, and M. Pfeiffer, "Realtime classification and sensor fusion with a spiking deep belief network," Frontiers in neuroscience, vol. 7, p. 178, 2013. [4] J. Zhao, N. Risi, M. Monforte, C. Bartolozzi, G. Indiveri, and E. Donati, "Closed-loop spiking control on a neuromorphic processor implemented on the iCub," IEEE Journal on Emerging and Selected Topics in Circuits and Systems, vol. 10, no. 4, pp. 546­556, 2020. [5] D. Farina et al., "The extraction of neural information from the surface emg for the control of upper-limb prostheses: emerging avenues and challenges," IEEE Transactions on Neural Systems and Rehabilitation Engineering, vol. 22, no. 4, pp. 797­809, 2014. [6] G. Haessig, M. B. Milde, P. V. Aceituno, O. Oubari, J. C. Knight, A. van Schaik, R. B. Benosman, and G. Indiveri, "Event-based computation for touch localization based on precise spike timing," Frontiers in Neuroscience, vol. 14, pp. 1­19, 2020. [7] S. Moradi, N. Qiao, F. Stefanini, and G. Indiveri, "A scalable multicore architecture with heterogeneous memory structures for dynamic neuromorphic asynchronous processors (DYNAPs)," IEEE Transactions on Biomedical Circuits and Systems, vol. 12, no. 1, pp. 106­122, 2017. [8] M. Stimberg, R. Brette, and D. F. M. Goodman, "Brian 2, an intuitive and efficient neural simulator," eLife, vol. 8, pp. 1­41, 2019. [9] R. D. Patterson, I. Nimmo-Smith, J. Holdsworth, and P. Rice, "An efficient auditory filterbank based on the gammatone function," In a meeting of the IOC Speech Group on Auditory Modelling at RSRE, vol. 2, 1987. [10] M. Yang, C.-H. Chien, T. Delbruck, and S.-C. Liu, "A 0.5 v 55 µw 64×2 channel binaural silicon cochlea for event-driven stereo-audio sensing," IEEE Journal of Solid-State Circuits, vol. 51, no. 11, pp. 2554­2569, 2016. [11] F. Corradi and G. Indiveri, "A neuromorphic event-based neural recording system for smart brain-machine-interfaces," IEEE Transactions on Biomedical Circuits and Systems, vol. 9, no. 5, pp. 699­709, 2015. [12] M. Sharifhazileh, K. Burelo, J. Sarnthein, and G. Indiveri, "An electronic neuromorphic system for real-time detection of high frequency oscillations (HFOs) in intracranial eeg." 2020. [13] G. G. Turrigiano, "Homeostatic plasticity in neural networks: the more things change, the more they stay the same," Trends in Neuroscience, vol. 22, no. 5, pp. 221­227, 1999. [14] N. Qiao, C. Bartolozzi, and G. Indiveri, An ultralow leakage synaptic scaling homeostatic plasticity circuit with configurable time scales up to 100 ks. IEEE Transactions on Biomedical Circuits and Systems, 2017. [15] W. Gerstner, W. M. Kistler, R. Naud, and L. Paninski, Neuronal Dynamics: From Single Neurons to Networks and Models of Cognition. USA: Cambridge University Press, 2014. [16] R. Bourdoukan, D. G. T. Barrett, C. K. MacHens, and S. Dene`ve, "Learning optimal spike-based representations," Advances in Neural Information Processing Systems, vol. 3, pp. 2285­2293, 2012. [17] E. Bechhoefer, "Condition based maintenance fault database for testing of diagnostic and prognostics algorithms." Accessed: 2020-11-1, 2013. [18] H. Qiu, J. Lee, J. Lin, and G. Yu., "Wavelet filter-based weak signature detection method and its application on rolling element bearing prognostics," Journal of Sound and Vibration, vol. 289, no. 4-5, pp. 1066­1090, 2006. [19] A. Prosvirin, M. M. Islam, C. Kim, and J. M. Kim, "Fault prediction of rolling element bearings using one class least squares svm," The Engineering and Arts Society in Korea, 2017.

[20] R. M. Hasani, G. Wang, and R. Grosu, An Automated Auto-encoder Correlation-based Health-Monitoring and Prognostic Method for Machine Bearings. arXiv, 2017.

