Using artificial neural networks to improve photometric modeling in airless bodies
J. L. Rizosa,b, A. Asensio Ramosa,b, R. Golishc, D. N. DellaGiustinac, J. Licandroa,b, J. de Leóna,b, H. Campinsd, E. Tatsumia,b, and M. Popescue
a Instituto de Astrofísica de Canarias, C/Vía Láctea s/n, E-38205 La Laguna, Tenerife, Spain b Departamento de Astrofísica, Universidad de La Laguna, E-38206 La Laguna, Tenerife, Spain c Lunar and Planetary Laboratory, University of Arizona, 1415 N. Sixth Ave., Tucson, AZ 85705-0500, USA d Department of Physics, University of Central Florida, P.O. Box 162385, Orlando, FL 32816-2385, USA e Astronomical Institute of the Romanian Academy, 5 Cuitul de Argint, 040557 Bucharest, Romania
ICARUS: Received 31-05-2021
Abstract
Relevant information about physical properties of the surface of airless bodies such as porosity, particle size, or roughness can be inferred knowing the dependence of the brightness with illumination and observing geometry. Additionally, this knowledge is necessary to standardize or photometrically correct data acquired under different illumination conditions. In this work we develop a robust, automatic, and efficient photometric modeling methodology which is tested and validated using Bennu images acquired by the camera MapCam from the OSIRIS-REx spacecraft. It consists of a supervised machine learning algorithm through an artificial neural network. Our system provides a more precise modeling for all color filters than the previous procedures which are already published, offering an improvement over this classic approach of up to 14.30%, as well as a considerable reduction in computing time. Keywords: Photometric modeling; Machine Learning; (101955) Bennu; OSIRIS-REx
1

1. Introduction
Studying the dependence of the brightness with illumination and observing geometry in airless bodies is useful for multiple reasons. First, it allows us to retrieve relevant information about physical properties of the surface. There are many characteristics that will condition the reflected light on the surface such as porosity, particle size, or roughness, which can be inferred by analyzing the reflected light. One needs to standardize observing geometries to compare data acquired under different illumination conditions. This standardization procedure, commonly called photometric correction, consists of finding a mathematical model that describes how light is reflected as a function of the geometric phase (), emission (e), and incidence (i) angles. For an arbitrary point on a surface P, illuminated from a point S and observed from another point C (Figure 1), the phase angle is defined as the intersection angle between the two lines PS and PC, the emission angle as that formed by the segment PC and the normal to that point n, and the angle of incidence as the angle between PS and n. Then, by means of a model, it is possible to translate the measured brightness under any geometric values (, , ) to a reference ones (0, 0, 0) (Eq. 1). The most common reference angles used in photometric corrections are (0, 0, 0) = (0°, 0°, 0°), which correspond to the normal reflectance, or (0, 0, 0) = (30°, 0°, 30°), which is a common laboratory setting (also known as standard reflectance). Hereinafter we refer to them as normal or laboratory reference, respectively.

Figure 1. Diagram of the positions of the camera C, the Sun S and a point P on a surface. The reflectance value will depend on the relative positions of these three elements.

(0,

0,

0)

=

(,

,

)

(0, 0, 0) (, , )

(1)

There are several mathematical models (also called photometric models), that describe reflectance as a function of the phase, incidence, and emission angles and other physical parameters. These include Hapke (Hapke 1963, 1981, 1986, 1993, 2012) or Shkuratov (Shkuratov et al. 1999) models --which are physically motivated and based on the radiative transfer theory-- and purely empirical models such as Lambert or Minnaert, that have been developed ad hoc (Li et al. 2015). The theoretical origin of Hapke model allows for a physical interpretation of its terms is possible and thus it is a popular approach. However, there are several cases where
2

correlations between supposedly independent Hapke parameters have been found (Gunderson et al. 2006; Shepard & Helfenstein 2007; Shkuratov et al. 2012). Likewise, empirical models are based on a priori dependence relationships between the geometric angles, which can bias photometric analysis because they might just be approximating more complex relationships. Empirical approaches assume that the photometric model can be decomposed as the product of two functions. A phase function, dependent only on the phase, and a disk function, which will depend on the emission and incidence values, and for some models also on the phase. Limitations to the existing physically motivated and empirical techniques for have prompted us to seek new approaches. Our objective in this work is to identify new way that could either replace or complement the classic approach to photometric modelling.
Currently, planetary science community is witnessing unprecedent growth in robotic exploration, a field where photometric modeling is an indispensable tool. Recent missions to airless bodies such as OSIRIS-REx or Hayabusa2, or those planned in the short term such as Martian Moons eXploration (MMX), would benefit considerably from having rapid tools for establishing photometric models in real time. The exponential growth of technology, and the possibility of acquiring large-scale data sets, makes manual processing carried out by humans exceedingly challenging.
In this work we develop a robust, automatic, and efficient photometric modeling methodology, making use of a supervised machine learning algorithm. Specifically, we develop an artificial neural network given their powerful application to analogue problems within astronomy (Cambioni et al. 2019; Asensio-Ramos et al. 2021; Moseley et al. 2020). At the same time, we will reproduce classical modeling to compare results. We use OSIRIS-REx data of near-Earth asteroid (101955) Bennu, one of the more recent missions to an airless body of our Solar System. The spacecraft was launched in September 2016 and surface-resolved images have been acquired since October 2018. OSIRIS-REx images are public and available at the Planetary Data System1. For this work, we focus on multispectral data collected by the MapCam medium-fieldof-view imager. MapCam has a 125-mm focal length and a focal ratio of f/3.3, which provided a ~ 4° field of view (Rizk et al., 2018). It has four narrow band filters based on the Eight-Color Asteroid Survey (ECAS, Tedesco et al., 1982): b, v, w, and x, with effective wavelengths at 473, 550, 698, and 847 nm, respectively. This instrument has taken thousands of images from multiple viewing geometries of asteroid Bennu for each color filter. In Section 2 we present both the classical approach and the new method using machine-learning, as well as our criterion to select and train data and evaluate results. In Section 3 we present and discuss the results of the modelling efficiency. In Section 4 we summarize our conclusions and the planned future work.
1 https://pds.nasa.gov/
3

2. Methods

2.1 Classical approach

The classical approach followed so far for photometric modeling consisted of fitting empirical data to a photometric model with several adjustable parameters. This process determines the value of these parameters that minimizes the error. As a reference for this first part, we base our procedure in the conclusions of the work carried out by Golish et al. (2021a), in which, after testing several photometric models, they concluded that the ROLO phase function, A(), -- which includes an explicit term to model the opposition surge-- with the Lommel-Seeliger disk function, d(e, i), is the best option to describe how light is reflected from the surface of Bennu (Eqs. (2) ­ (4)).

 = () · (, )

(2)

() = 0-1 + 0 + 1 + 22 + 33 + 44

(3)

cos () (, ) = cos() + cos ()

(4)

To do this, as in the cited work, we use the color filter images of the Approach, Preliminary survey, and Equatorial stations phases, from October 29th, 2018 to June 6th, 2019. It accounts for 951, 878, 873, and 868 images for the b, v, w, and x filters, respectively. These images were calibrated in terms of radiance factor (RADF) in line with the Golish et al. (2020) methodology. Their calibration method also removes known sources of noise such as dark current, charge smear, and pixel non-uniformity.
Following the steps of Golish et al. (2021a), we compute the photometric angles by means of Integrated Software for Imagers and Spectrometers 3 (ISIS3; Keszthelyi et al., 2013) and SPICE kernels (Acton et al., 2018) and a shape model provided by the mission. Specifically, we use the same shape model of Bennu, version v28 with a mean ground sample distance (GSD) of 80 cm (Barnouin et al., 2019, 2020). In images where the resolution exceeds that of the shape model GSD, we reduce it to the same value. Otherwise, we could be getting in the same area different reflectance values for the same phase, emission and incidence value, something without any physical meaning. Later, we select pixels following the same criteria followed in Golish et al. 2021a: incidence, or emission angles below 82°, and RADF above 0.001. In addition, we exclude pixels with a phase above 90° due to low signal-to-noise-ratio (SNR). After this last filtering, the number of useful images is reduced to 408, 338, 338 and 338 for the b, v, w, and x bands, respectively.
After data selection, we compute the equigonal albedo dividing the RADF by the disk function. Finally, we average for each image the phase value and the equigonal albedo, and we fit the ROLO phase function to these points with a Levenberg-Marquardt algorithm (black curve in Figure 2). In Table 1, we present the values obtained for the parameters.

4

Figure 2. ROLO phase function (black line) for the v-filter. Red points are the average equigonal albedo of each image. The phase angle ranges from 0° to 90°.

Table 1. Values of the photometric parameters for the ROLO phase function used together with the Lommel-Seeliger disk function.

b'

C0

0.0112

C1

7.169 ·10-1

A0

7.633·10-2

A1

-1.961·10-3

A2

2.576·10-5

A3

-1.784·10-7

A4

4.598·10-10

v
0.0107 7.336·10-1 7.709·10-2 -2.062·10-3 2.926·10-5 -2.269·10-7 7.044·10-10

w
0.0091 7.618·10-1 7.505·10-2 -1.951·10-3 2.593·10-5 -1.828·10-7 4.989·10-10

x
0.0088 7.204·10-1 7.275·10-2 -1.794·10-3 2.097·10-5 -1.141·10-7 1.609·10-10

2.2 Artificial Neural Networks

An artificial neural network (ANN) is a mathematical model inspired in the fundamental structure of the brain (Schmidhuber, 2015). ANNs are composed of neurons arranged in layers with arbitrary deep --linked by composite functions-- that can learn from data. The most basic ANN consists of one input layer, one hidden layer and an output layer. In an ANN the input data is fed in the forward direction through the network. Each hidden layer accepts the input data, processes it, and passes to the successive layer. In each neuron, the inputs (x1, x2, ... xm) are converted into an output by means of weights (w1, w2, ..., wm), a bias (b), and a non-linear function called activation function (f) as follows:



 = (  + )

(5)

=0

Usually weights are initialized (randomly created) using a normal distribution with fixed standard deviation. However, deep ANN models can have difficulty converging if not properly initialized. For this reason and to avoid this problem, we use the Kaiming method (Kaiming et al. 2015) that

5

gives particularly good results in practice. Activation functions gives neural networks their power to model complex non-linear relationships. In this work we use elu --to connect each layer-- and sigmoid --just in the last layer-- as the activation functions, which are defined in Eq 6 and 7:

()

=

((

, -

1)

 

 

> 

00)

(6)

1

() = 1 + -

(7)

Once the input is propagated through the output layer, the predicted value is compared to the real one (extracted from the dataset, hence the name of supervised learning) by a loss function. In this work we use the mean square error (MSE) (Eq. 8), which is widely used for its performance in analogue problems:



=

1 


(

-

)2

(8)

=1

The loss is optimized by modifying the weights and biases using Adam stochastic gradient algorithm (Diederik et al. 2015). The gradient is computed by using backpropagation. A sequential iteration of this cycle (epoch) is repeated until a convergence of MSE is reached.

For shorten computing time, we set maximum number of 1100 pixels of each image, which are randomly selected from our data set --it was checked that this data reduction does not affect to our final results. To avoid overfitting, the dataset is separated into training and validation data. Validation data are not used for training but are tested for convergence in each epoch. For that, we randomly separate our data into two groups with a 9:1 ratio, i. e., 90% data for training and 10% for validation (Table 2). Figure 3 shows the phase, emission and incidence ranges used in this work.

Table 2. Number of pixels used in this work for both training and validation. For each pixel we extract the phase, emission, incidence and RADF values, so the total number is four times the values shown in this table.

b' filter v filter w filter x filter

Training
417025 352044 346944 345952

Validation 46480 39255 38694 38584

To evaluate the modeling efficiency, we calculate the MSE value for both the classical and ANN predictions. The percent improvement is given by Eq (9):



(%)

=

 -  

·

100

(9)

6

a)

b)

Figure 3. Visualization of the data range used in this work. For this inspection we choose randomly 10% of all v-filter pixels and represent phase against emission (a), and phase against incidence (b).
The input layer of our ANN contains 3 units: phase, emission, and incidence angle values, while the output layer is the measured RADF for these three angles (Figure 4). To implement the ANN, we use the open-source machine learning library PyTorch, which provides accelerated computation using graphical processing units (GPUs), which can do the same calculation ~50 fast than a CPU.

Figure 4. The most basic neural network composed only for one hidden layer.
7

3. Results
The hyperparameters of the ANN (number of hidden layers, neurons in each layer, and the learning rate used for the optimization step for backpropagation) need to be tuned to get optimal performance. To select the best configuration, we made a series of trial-and-error tests where we compute the MSE for a sample of data using a fixed number of 200 epochs. The best set-up will be this one that offers the lowest MSE value but also presents a smooth and constant decrease (Figure 5). For this evaluation we combine a large number of possible configurations, starting from 1 hidden layer and increasing this number, and in parallel modifying the number of neurons --3, 5, 7, 9, 12, 15, 18 or 21-- and the Adam learning rate --1, 1E-1, 1E-2, 1E-3, 1E4, or 1E-5. For more than 5 hidden layers, the computational times increased remarkably while the MSE did not decrease, so it is the maximum number tested here. In Table 3 the best results (lowest MSE values) are shown for each number of hidden layers.

Figure 5. MSE vs epoch using 3 hidden layers and 15 neurons in each one. For a learning rate larger than 1E-2, the MSE variation is irregular. The lower MSE is reached for a learning rate of 1E-3.

From this experience we concluded that the best set-up is 3 hidden layers, with 15 neurons in each layer, and a learning rate equal or less than 1E-3.
Table 3. Test to identify the best ANN configuration running 200 epochs. In this table we show the best case for an increasing number of layers, from 1 up to 5. We also include the computation time (in seconds) but after fixing the learning rate at 1E-4 and the number of neurons at 9 for an appropriate comparison.

Hidden Layers
1 2 3 4 5

N. of neurons
7 9 15 5 7

Learning Rate
1E-2 1E-3 1E-3 1E-3 1E-3

MSE
2.77 · 10-3 2.76· 10-3 2.73· 10-3 2.78· 10-3 2.74· 10-3

Time (s)
14.28 20.62 26.36 32.34 37.78

After identifying the best ANN, we train our data for each color filter. We stop the training process at 6000 epochs because at this point the MSE remains practically constant, reaching an
8

asymptotic regime. To accelerate the process and reduce computation times taking advantage of the parallel computing GPU platform provided by PyTorch, we separated the total set of training data into batches of 1000 pixels, so in each epoch we calculate, optimize and update weights for each one of them. Finally, we use our trained network to test the modeling efficiency. For that, we use the validation (non-trained) data, and we simulate the RADF using phase, emission, and incidence angles by means of both ROLO model and our trained ANN. We compute the improvement (Eq. 9) through MSE. Our method reaches a more precise modeling for all color filters than ROLO, with an improvement over the classic approach of up to 14.30% (Table 4). Note that a number amount of training data are available for the b' filter, so the efficiency is not correlated with the amount of data used.
Table 4. MSE value and modeling improvement (in percentage) for each MapCam color filter. These numbers are obtained using validation (non-trained) data.

b' filter v filter w filter x filter

MSEROLO 0.00435 0.00453 0.00441 0.00423

MSEANN 0.00373 0.00397 0.00392 0.00362

Improvement (%) 14.15 12.54 11.13 14.30

If we represent the predicted RADF as a function of the phase value (fixing emission and incidence angles at 30°), we see how both ROLO and our trained ANN show a similar phase function (Figure 6). However, it follows from our results that more complex relationships than those represented by the ROLO photometric model are presented and they are being captured by our ANN. Also, we can see that the real measurements (overlapped black points in Figure 6) present a high RADF variation for the same photometric angles. Apart from the natural scatter due to noise, it also could be that the heterogeneity of the surface (DellaGiustina et al., 2020), thus suggesting that several photometric models could be needed to describe the scattering properties of different materials over the surface. This is planned as an improvement in our next approach.

Figure 6. Simulated RADF values from ROLO model (blue curve) and our trained ANN (red curve) for the phase range 0° - 90°. Overlapping back points are direct measurements used to train the ANN.
9

4. Conclusions and future work
Photometric modeling is essential when applying corrections before analyzing spectral data from resolved surfaces to remove the effects of varying observation and illumination conditions. In this work we decided to develop a machine learning methodology via an artificial neural network (ANN) to improve the efficiency of photometric modeling. To do this, first we replicated the classical approach, consisting of the search for parameters of previously defined photometric models (Golish et al. 2021a). In parallel, we trained an ANN with the same data used for the classic modeling. Later, to compare both systems, we predicted RADF from phase, emission and incidence angles using non-trained or validation data and compute the MSE in each case. We found that our trained ANN obtains a higher precision model, up to 14.30% for the x-filter. When we represent both ROLO and ANN predicted phase function curves (Figure 6) along direct measurements, we see that real measurements present a high degree of scatter. This means that we are detecting albedo variations for the same phase, emission, and incidence angles. There are certain natural uncertainties due to errors in shape model, image to shape model misregistration, inaccurate pointing, artifacts or MapCam instrumental noise. However, heterogeneity observed in the surface also suggests the presence of boulders with varying composition, including potentially exogenous material, having originated in other bodies such as (4) Vesta (DellaGiustina et al. 2021). It is likely that these varying materials will have distinct light scattering properties. Thus, a next step will be to consider latitude and longitude values along with phase, emission, and incidence as inputs in our neural network. We expect that regional photometry modelling will further improve our precision. Moreover, photometric corrections are just application of photometric modelling. As discussed in Section 1, there are many characteristics such as porosity, particle size, or roughness, that can be inferred by studying how light is reflected from a planetary surface. It can be done using Hapke model, which presents a set of parameters with physical meaning. An ML approach could be an ideal approach to improve precision, as well as overcoming some of the difficulties of physically motivated models, such as convergence issues or correlations between supposedly independent parameters. Finally, through PDS, we have access to a very wide set of images and shape models of other Solar System bodies acquired by space missions such as Dawn, that visited the asteroid (4) Vesta or the dwarf planet (1) Ceres, or NEAR-Shoemaker, which visited (433) Eros. Therefore, we plan to apply this new methodology to other planetary surfaces to assess the light-scattering behavior of those airless bodies.
10

5. Acknowledgements
We thank the entire OSIRIS-REx Team for making this mission possible. A. Asensio Ramos acknowledges financial support from MICIU through project PGC2018-102108-B-I00 and FEDER funds. J. L. Rizos, J. Licandro, J. de León and M. Popescu acknowledge support from the AYA2015-67772-R (MINECO, Spain). J. de León acknowledges financial support from the Severo Ochoa Program SEV-2015-0548 (MINECO) and the project ProID2017010112 under the Operational Programmes of the European Regional Development Fund and the European Social Fund of the Canary Islands (OP-ERDF-ESF), as well as the Canarian Agency for Research, Innovation and Information Society (ACIISI).
6. Data Availability
This research has made use of the USGS Integrated Software for Imagers and Spectrometers (ISIS) (https://isis.astrogeology.usgs.gov/). OCAMS/MapCam images used in this work are available via the Planetary Data System (Rizk et al., 2019). Shape models of Bennu are available via the Small Body Mapping Tool (http://sbmt.jhuapl.edu/). D.N. DellaGiustina and D.R. Golish were supported by NASA under contract NNM10AA11C issued through the New Frontiers Program.
11

7. References

Acton, C. et al., 2018. A look towards the future in the handling of space science mission geometry. Planet. Space Sci. 150, 9­12. https:// doi.org/10.1016/j.pss.2017.02.0133
Asensio-Ramos, A. et al., 2021. Planet cartography with neural learned regularization. Astronomy & Astrophysics, 646 - A4. https://doi.org/10.1051/0004-6361/202040066
Barnouin, O.S. et al., 2019. Shape of (101955) Bennu indicative of a rubble pile with internal stiffness. Nat. Geosci. 12, 247­252. https://doi.org/10.1038/s41561-019- 0330-x
Barnouin, O.S. et al., 2020. Digital terrain mapping by the OSIRIS-REx mission. Planet. Space Sci. 180, 104764. https://doi.org/10.1016/j.pss.2019.104764
Cambioni et al., 2019. Constraining the thermal properties of planetary surfaces using machine learning: Application to airless bodies. Icarus, 325, 16-30. https://doi.org/10.1016/j.icarus.2019.01.017

DellaGiustina, D.N., et al., 2020. Variations in color and reflectance on the surface of asteroid (101955) Bennu. Science 370, eabc3660. https://doi.org/10.1126/science.abc3660

DellaGiustina, D.N., et al., 2021. Exogenic basalt on asteroid (101955) Bennu. Nat. Astron. 5, 31­ 38. https://doi.org/10.1038/s41550-020-1195-z

Diederik et al. 2015. Adam: Method for Stochastic Optimization. Published as a conference paper at ICLR 2015.

Golish, D. R. et al., 2020. Ground and In-Flight Calibration of the OSIRIS-REx Camera Suite. Space Sci. Rev. 216, 12. DOI: 10.1007/s11214-019-0626-6

Golish, D.R. et al., 2021a. Disk-resolved photometric modeling and properties of asteroid (101955) Bennu. Icarus 113724. DOI: 10.1016/j.icarus.2020.113724.

Golish, D.R. et al., 2021b. Regional Photometric Modeling of Asteroid (101955) Bennu. Planetary Science Journal. Accepted.

Gunderson, K. et al., 2006. First measurements with the Physikalisches Institut Radiometric

Experiment

(PHIRE).

Planet

Space

Sci.,

54,

1046-1056.

https://doi.org/10.1016/j.pss.2005.12.020

Hapke, B., 1963. A theoretical photometric function for the lunar surface. J. Geophys. Res., 68, 4571­4586. https://doi.org/10.1029/JZ068i015p04571

Hapke, B., 1981. Bidirectional reflectance spectroscopy: 1. Theory. J. Geophys. Res. Solid Earth 86, 3039­3054. https://doi.org/10.1029/JB086iB04p03039

Hapke, B. 1986. Bidirectional reflectance spectroscopy 4. The extinction coefficient and the opposition effect. Icarus 67, 264­280. https://doi.org/10.1016/0019-1035(86)90108-9

Hapke, B. 2012. Theory of Reflectance and Emittance Spectroscopy, 2nd ed. Cambridge University Press, Cambridge. https://doi.org/10.1017/CBO9781139025683

12

Hapke, B., et al., 1993. The opposition effect of the Moon: the contribution of coherent backscatter. Science. https://doi.org/10.1126/science.260.5107.509 Kaiming, H., et al. 2015. Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification. 2015 IEEE International Conference on Computer Vision (ICCV). https://doi.org/10.1109/ICCV.2015.123 Keszthelyi, L., et al. 2013. Support and future vision for the Integrated Software for Imagers and Spectrometers (ISIS). 44th Lunar Planet. Sci. Conf, 44, p. 2546. Li et al. 2015. Asteroid photometry. Asteroids IV (P. Michel et al., eds.), pp. 129­150. Univ. of Arizona, Tucson. https://doi.org/10.2458/azu_uapress_9780816532131-ch007 Moseley, B. et al. 2020. Unsupervised Learning for Thermophysical Analysis on the Lunar Surface. The Planetary Science Journal, 1:32 (16pp). https://doi.org/10.3847/PSJ/ab9a52 Rizk, B. et al., 2018. OCAMS: The OSIRIS-REx Camera Suite. Space Sci. Rev. 214, 26. https://doi.org/10.1007/s11214-017-0460-7 Rizk, B., et al. 2019. Origins, Spectral Interpretation, Resource Identification, Security, Regolith Explorer (OSIRIS-REx): OSIRIS-REx Camera Suite (OCAMS) Bundle, NASA Planetary Data System, urn:nasa:pds:orex.ocams. Schmidhuber, J., 2015. Deep learning in neural networks: an overview. Neural Networks, 61, 85­ 117. https://doi.org/10.1016/j.neunet.2014.09.003 Shepard, M. K., et al., 2007. J. Geophys. Res. Planets, 112, E03001. https://doi.org/10.1029/2005JE002625 Shkuratov, Y., et al. 1999. Opposition effect from Clementine data and mechanisms of backscatter. Icarus, 141, 132­155. https://doi.org/10.1006/icar.1999.6154 Shkuratov, Y., et al., 2012. A critical assessment of the Hapke photometric model. J. Quant. Spectr. Rad. Transf., 113, 2431-2456. https://doi.org/10.1016/j.jqsrt.2012.04.010 Tedesco, E.F., et al., 1982. The eight-color asteroid survey ­ Standard stars. Astron. J. 1585­1592.
13

