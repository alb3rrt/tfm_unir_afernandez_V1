
# A Differentiable Point Process with Its Application to Spiking Neural Networks

[arXiv](https://arxiv.org/abs/2106.0901), [PDF](https://arxiv.org/pdf/2106.0901.pdf)

## Authors

- Hiroshi Kajino

## Abstract

This paper is concerned about a learning algorithm for a probabilistic model of spiking neural networks (SNNs). Jimenez Rezende & Gerstner (2014) proposed a stochastic variational inference algorithm to train SNNs with hidden neurons. The algorithm updates the variational distribution using the score function gradient estimator, whose high variance often impedes the whole learning algorithm. This paper presents an alternative gradient estimator for SNNs based on the path-wise gradient estimator. The main technical difficulty is a lack of a general method to differentiate a realization of an arbitrary point process, which is necessary to derive the path-wise gradient estimator. We develop a differentiable point process, which is the technical highlight of this paper, and apply it to derive the path-wise gradient estimator for SNNs. We investigate the effectiveness of our gradient estimator through numerical simulation.

## Comments

Accepted to ICML 2021

## Source Code

Official Code



Community Code



## Bibtex

```tex
@misc{kajino2021differentiable,
      title={A Differentiable Point Process with Its Application to Spiking Neural Networks}, 
      author={Hiroshi Kajino},
      year={2021},
      eprint={2106.00901},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}
```

## Notes

Type your reading notes here...

