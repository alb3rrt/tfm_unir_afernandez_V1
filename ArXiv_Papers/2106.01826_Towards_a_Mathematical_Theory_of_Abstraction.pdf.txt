arXiv:2106.01826v1 [cs.AI] 3 Jun 2021

TOWARDS A MATHEMATICAL THEORY OF ABSTRACTION
Beren Millidge MRC Brain Networks Dynamics Unit
University of Oxford beren@millidge.name
4th June, 2021
ABSTRACT
While the utility of well-chosen abstractions for understanding and predicting the behaviour of complex systems is well appreciated, precisely what an abstraction is has so far has largely eluded mathematical formalization. In this paper, we aim to set out a mathematical theory of abstraction. We provide a precise characterisation of what an abstraction is and, perhaps more importantly, suggest how abstractions can be learnt directly from data both for static datasets and for dynamical systems. We define an abstraction to be a small set of `summaries' of a system which can be used to answer a set of queries about the system or its behaviour. The difference between the ground truth behaviour of the system on the queries and the behaviour of the system predicted only by the abstraction provides a measure of the `leakiness' of the abstraction which can be used as a loss function to directly learn abstractions from data. Our approach can be considered a generalization of classical statistics where we are not interested in reconstructing `the data' in full, but are instead only concerned with answering a set of arbitrary queries about the data. While highly theoretical, our results have deep implications for statistical inference and machine learning and could be used to develop explicit methods for learning precise kinds of abstractions directly from data.
1 Introduction
We enunciate a rather basic principle, which might be dismissed as an obvious triviality were it not for the fact that it is not recognized in any of the literature known to this writer: If any macrophenomenon is found to be reproducible, then it follows that all microscopic details that were not reproduced, must be irrelevant for understanding and predicting it. In particular, all circumstances that were not under the experimenter's control are very likely not to be reproduced, and therefore are very likely not to be relevant.
Macroscopic Prediction (1985) by E.T Jaynes
In this paper, we present the beginnings of a mathematical theory of abstraction. While the intuitive concept of an abstraction has long been recognized, as has the centrality of well-chosen abstractions for understanding the world, the concept itself has largely eluded mathematical formalization. In this paper, by combining insights from maximum entropy theories of statistical mechanics (Jaynes, 2003), methods of statistical and Bayesian inference (Casella & Berger, 2021; Knill & Richards, 1996; Wainwright & Jordan, 2008), and recent advances in machine learning (Bishop, 2006; Goodfellow, Bengio, Courville, & Bengio, 2016), we aim to provide a mathematically precise definition of abstraction,

A PREPRINT - 4TH JUNE, 2021
understand how our definitions relate to classical methods in statistics and machine learning, and offer suggestions for how these definitions and insights can aid the development of powerful algorithms for learning abstractions from data.
Before we dive into the formalism, however, we wish to provide an intuitive and accessible description of our ideas. To begin with, we consider the `folk notion' of an abstraction. Several aspects of this slippery idea are immediately apparent. An abstraction involves some kind of summary of a more complex reality. It involves ignoring or throwing away certain kinds of information, and somehow preserving only those aspects which are most relevant to the problem at hand. Physics furnishes many examples of extremely clear and precisely specified abstractions, so in this paper we often turn to these as exemplar cases
For instance, let us consider the classical physical abstraction of a uniform mass rolling along a frictionless plane. What is the fundamental nature of such an abstraction? The first, and most obvious, property is that the objects described in the abstraction are `ideal' in some sense. The mass is completely uniform, the plane is completely frictionless and also implicitly entirely flat and smooth. These properties are not true of any masses and planes in the `real world' ­ but we take these mundane real world details to be irrelevant. The second property is that due to their idealness and simplicity, the objects in the abstraction possess are vastly simpler to represent mathematically. We can usually define the mass using only several scalar variables ­ its mass, and its position, velocity, and acceleration. The frictionless plane is even simpler to represent ­ typically just its angle. By contrast, a `real' mass and a `real' plane would consist of many trillions of atoms, each with their own mass and position and velocity. The combined interactions of all these vast numbers of variables would produce the actual behaviour of the system. From this, we can get to our first fundamental property of an abstraction ­ an abstraction represents a compression, often a dramatic one. In the case of the abstract mass and plane we have gone from a practically infinite amount of variables, to a finite and very small number.
The second key property is that abstractions ignore irrelevant information. Encoded into the abstraction of the frictionless plane is the idea that the positions and velocities of the atoms comprising the plane somehow do not matter to the things we are trying to represent or use the abstraction for. This idea, while seemingly obvious, contains the two insights required to make our definition. The first insight is that abstractions are fundamentally predictive and that they are for a purpose. An abstraction only focuses on, or is specific to, certain facets of the system, certain properties that we care about or certain questions that we wish to ask. In the case of the mass and plane, these questions are probably things about motion of the mass ­ the speed of motion, the acceleration, perhaps the vector direction, and so forth. Specifically, we do not care about aspects of the real situation like the velocity of a random particle in the plane, the nature of the atmosphere surrounding the mass (if any), the precise shape of the mass, the temperature of the mass, the precise time of day this experiment is occurring, whether the experiment is occurring in the north or the south hemisphere of the earth, or in outer space. By choosing only to care about questions which do not heavily depend on this `irrelevant' information, we can create an abstraction which does not represent it. Conversely, the quality and utility of an abstraction is entirely dependent on the questions we wish to use it to reason about. The goodness of any abstraction is relative to the queries one makes of it. It is important to note that an abstraction is not necessarily just a coarse-graining of a system 1. For instance, consider again the idea of a frictionless plane. This is not simply a coarse-grained version of a plane with friction, but rather a model which ignores some aspects of the behaviour of the real system ­ i.e. friction. While incorrect as a model of the real system, this nevertheless can be a good abstraction if the queries we are interested in are not significantly affected by the presence or absence of friction.
As a consequence, abstractions are almost never perfect. By their very nature, they throw away information. That information almost always has effects, even if sometimes they are minuscule. In computer science, this fact is known by the aphorism that `all abstractions leak' ­ that some detail of the underlying structure which is abstracted away always makes it through to result in actual behaviour subtly different to that predicted solely based on the abstraction. We will use this idea to formalize the `goodness' of an abstraction. Namely, that an abstraction is good to the degree to which it does not `leak' for the kinds of queries or questions that we are interested in. We operationalize the leakiness of an
1Although the converse holds: a coarse graining is, of course, an abstraction
2

A PREPRINT - 4TH JUNE, 2021
abstraction as the difference between the behaviour of the system (as evaluated by our queries) expected given only the abstraction, and the real behaviour.
This, then, leads us straight to the final obstacle that must be surpassed before we can make our definition. What is: `The behaviour of the system given only the abstraction'? Here we turn to the principle of maximum entropy (Jaynes, 1957, 1988, 2003) for a solution. The principle of maximum entropy is a variational principle which, originally introduces by Gibbs (Gibbs, 1879) and developed and formalized by Jaynes (Jaynes, 1957, 1988, 1989) underpins much of the field of statistical mechanics, and is applicable much more broadly. The key insight of this principle is that, given a system with unknown state, and some knowledge about it, you should infer the state to be the one that maximizes your ignorance (entropy), constrained by your knowledge. For instance, given a box of gas, what should you infer the distribution of gas molecules inside the box to be? The principle of maximum entropy states that you should infer the distribution to be uniform, since it represents the maximum level of uncertainty you could have about the distribution. If you then know the average energy of the gas, you can consider this knowledge as a constraint on the ultimate distribution and instead find the maximum entropy distribution which satisfies this constraint which, in this case, is the well-known Maxwell-Boltzmann distribution.
Here, we argue that the principle of maximum entropy provides precisely the right description of what it means to throw away information irrelevant to the abstraction ­ namely that such a system is the maximum entropy system where the constraints are the abstraction state. Such a system would represent our best guess at the true system state given our knowledge only of the abstraction state. If we could compare the behaviour of this maximum entropy system and the real system on a set of queries, then this would provide a direct way of measuring the leakiness of the abstraction on the questions we care about. If we have a way to measure the leakiness of an abstraction, we can turn this around and parametrize the abstraction function and then learn those parameters to find the best abstractions possible, given data or samples from the system. This intuition is what we aim to formalize and discuss for the rest of the paper.
Finally, we turn to the quote by Jaynes at the beginning (Jaynes, 1985) which gets to the heart of why this definition of abstraction might work, and why it may capture the important aspects of our intuitive understanding of abstraction. Here, Jaynes focuses understanding the relationship between microscopic phenomena and the reproducible macrovariables which reliably emerge from their interactions. The clear message is encapsulated in the quote at the top of this section ­ that if a macroscopic phenomena can exist reproducibly, then the vast majority of microscopic interactions cannot meaningfully affect the macroscopic phenomena, since the microphenomena cannot all be controlled by the experimenter, and are therefore almost certainly not reproduced, while the macrophenomena is reproduced. From the perspective of the macrophenomena, all these microscopic interactions, and the information they contain, is irrelevant, and contains no predictive power over and above knowledge of the macrophenomena itself.
The intuition behind our definition of abstraction is precisely the reverse of this insight. If the vast majority of the microscopic interactions are irrelevant, and contain no useful information about the evolution of the system not given by the macrophenomena, then we can say that the macrophenomena provides a good abstraction of the microscopic details involved in the overall functioning of the system. Notably, this intuition covers exactly the same intuitive bases for our normal use of the word abstraction ­ the macrophenomena discards irrelevant microscopic information while retaining just enough information to maintain itself as a reproducible phenomenon.
Additionally, we then take a more speculative turn and consider the question of why we should expect there to be useful abstractions of systems at all. We argue, albeit on an intuitive basis, that in general for many systems there should exist useful or `natural' abstractions which are useful for many different queries (i.e. generalize across queries) and which represent important `objective' abstract facts about the system in question. These `natural facts' or macrophenomena arise due to the nature of many stochastic interacting processes which tend to preserve certain kinds of information while losing others. This leads to the convergence of distributions over such systems to a few well known limiting aggregate distributions which are well studied in statistics and can be described faithfully with just a few parameters. These parameters can then be interpreted as abstractions, or macrophenomena, of the system.
3

A PREPRINT - 4TH JUNE, 2021

1.1 The Maximum Entropy Principle

The maximum entropy principle originated in statistical physics, where it was first invented and applied by Boltzmann and Gibbs, and then further developed and exposited by Jaynes in a number of works (Jaynes, 1957, 2003) where he aims to formulate and understand the basic principles of statistical mechanics purely in terms of this maximum entropy approach, as well as apply its precepts more widely. The maximum entropy principle states, essentially, that given a system where there are many unknown microscopic degrees of freedom, but yet we know several macroscopic variables which constrain these degrees of freedom, we can predict the distribution of the system, or our measurements of the system in terms of the distribution which matches our knowledge while otherwise maintaining the highest possible entropy. In mathematical terms, the maximum entropy principle states that the distribution of the system will be that which maximises its own entropy while simultaneously satisfying any constraints imposed by our knowledge of the system, which usually take the form of macrophenomonal averages over system states. From a thermodynamic perspective, the maximum entropy principle provides a heuristic but stronger version of the second law of thermodynamics, stating not just that entropy will increase, but that it will tend to increase to the maximum possible allowed by the intrinsic constraints of the system.

Intuitively, the maximum entropy principle can be justified by the fact that it presupposes the least knowledge about the system ­ we explicitly encode the fact that we are maximally ignorant about everything other than what we explicitly know. The maximum entropy principle thus generalizes Laplace's principle of indifference as a special case where we in fact know nothing at all about the distribution except its support and so derive a uniform distribution. Mathematically, the maximum entropy principle prescribes a straightforwardly applicable apparatus for computing maximum entropy distributions given a certain set of constraints using the simple principle of constrained optimization with Lagrange multipliers. For instance, consider the original thermodynamical problem where we wish to describe the distribution of states of the system p(xi) where xi is the i'th state, given an average energy E¯ = i p(xi)Ei. The maximum entropy principle states that we can solve this by solving the following constrained optimization problem,

p(x) = argmaxL
p(x)

L = - dx p(x) ln p(x) - 0 dxp(x) - 1) - 0( dx p(x)E(x) - E¯)

(1)

Where the entropy H[p(x)] = - dx p(x) ln p(x) is maximized while the first constraint with multiplier 0 encodes
the normalization constraint that the probability distribution over the states must sum to 1, and the second constraint encodes the fact that the average energy of the system i p(x)E(x) must equal the known average energy E¯. To solve, we take the derivatives and set them equal to 0,

L p(x) = 1 + ln p(x) - 0 - 1E(x) = 0

= p(x) = e-(0-1)e-1E(x)

(2)

Then, plugging this into the normalization constraint, we can derive,

dx e-(0-1)e-1E(x) = 1

e-(0-1) dx e-1E(x) = 1

e0-1 = dx e-1E(x)

0 - 1 = ln dx e-1E(x) = ln Z

(3)

where Z =

dx e-1E(x) is the partition function or normalizing constant. With this definition, we can thus write,

p(x) = 1 e-1E(x)

(4)

Z

4

A PREPRINT - 4TH JUNE, 2021

If we do some more algebra, and apply some thermodynamic knowledge (see Jaynes (1957) for details), we can derive

that 1



1 T

where

T

is the temperature, thus deriving the Boltzmann distribution.

In Appendix

A, to showcase

the

power of the framework, we also derive the Gaussian (or normal) distribution from the maximum entropy framework

under the constraint that we only know the variance of the distribution dx p(x)(x - µ)2 = 2.

In general, all maximum entropy problems share the same mathematical apparatus and take a common form, differing only in the details of the constraints. Specifically, for a general set of constraints .C = i i f (x) - ci , we can express the maximum entropy objective as,

L = - dxp(xi) ln p(xi) - 0 dxp(x) - 1 - i f (x) - ci

(5)

i

with the solution,

L = 0 = p(x) = e-(0-1)e- i if(x)

(6)

p(x)

where 0 - 1 = ln Z = ln dx e- i if(x) relates to the log partition function or, in probabilistic terms, the

normalizing constant for the density since it arises from the normalization constraint. The other lagrange multipliers

{1 . . . N } can often be solved for via algebraic manipulations over the expressions for the constraints, which will

ultimately give an analytical expression for the maximum entropy distribution. Furthermore, we always know that the

maximum entropy objective is a minimum by taking the second derivative, by which we find that

2L p(x)2

=

1 p(x)

which

is always positive.

2 Formulation
While previously we have given an intuitive description of the key ideas behind our definition, here we provide the mathematical formalism to make these ideas precise. To recap concisely, an abstraction is a small set of 'summary statistics' which provide sufficient information to answer queries about a system such that, for the queries we wish to ask, the answers to the queries of the particular system are the same as the answers given by the maximum entropy system corresponding to the constraint that the abstract variables are set to the values they hold.
Mathematically, let us define a system as possessing variables x  RX where X is the dimensionality of the state vector, which we assume to be very large in general. If we are uncertain about the system, we can define a probability distribution p(x) over the variables of the system. Secondly, we define an abstraction a  RA to be a vector of abstraction variables where A << X is the dimensionality of the abstraction vector, and is usually assumed to be much smaller than the dimensionality of the system. Intuitively, one can think of a as a kind of `summary statistic' for the system in a way we shall make precise shortly. For now, we assume that we have a given a, and we will discuss learning a from data later. We define the maximum entropy function m such that m(a) = p~(x|a) is a function that maps a given abstraction variable to the maximum entropy distribution over the system's variables, given the constraints of the abstraction variables following a particular distribution, where we write p~ to denote the fact that this is a maximum entropy distribution. Formally, this can be written as,

m(a) = p~(x|a) = argmax H[p(x|a)] - 0 p(x|a)dx - 1

(7)

p(x|a)

Where 0 is the lagrange multiplier which ensures that the probabilities of each state sum to one. We also possess a set of query functions Q = {Q1, Q2 . . . QN }; Q : X  Q, where Q is the output space of the query function, which may be different from the state space, and different between different query functions. For generality, we assume that the query functions can themselves be probabilistic and and therefore map from a distribution over X to a distribution over Q: p(q|x) = Q(p(x)) given a distribution over system states p(x). From these definitions, we define the `goodness', or `loss' LQ(a, x) of a given abstraction, for a given query and a given system, to be the divergence between the query

5

A PREPRINT - 4TH JUNE, 2021

distribution given the true system, and the query distribution taken from the maximum entropy system inferred from the constraints. We write this as,

LQ(x, a) = D Q(p(x))||Q(m(a))

(8)

In general, we take the divergence function D to be the KL divergence DKL[p(x)||q(x)] =

dxp(x)

log

p(x) q(x)

,

although

other divergences are possible. If we have a set of query functions, we can define the overall goodness of the abstraction

to be simply the average loss over all queries,

L(x, a) =

p(Qi)LQi (a, x)

(9)

Qi Q

This equation provides a quantitative measure of the goodness of fit of a particular set of abstractions given the set of queries one might want to make of that abstraction. In computer science terminology, Equation 8 measures the `leakiness' of an abstraction. If L = 0 then knowing the abstraction allows us perfectly to predict all queries without needing to know any more information about the original system than is contained within the abstraction. If L > 0, then there is some information about the system, which is relevant to our queries, which is not captured by the abstraction ­ the abstraction `leaks'.

We define a perfect abstraction for given queryset and system to be the abstraction a for which L(a, x) = 0. If our queryset is the set of all possible queries, then we can define a universally perfect abstraction, for which the abstraction loss is 0 for all possible queries. A universally perfect abstraction can only exist when p(x) = p~(x|a) ­ i.e. that the real system distribution is already a maximum entropy distribution which can be specified with abstraction constraints a which would simply be the parameters of the maximum entropy distribution. In statistics, universally perfect abstractions of a distribution are called sufficient statistics, since they contain all the necessary information to precisely recreate the distribution, and thus answer any query about it. By this argument, it is clear that sufficient statistics can only exist for maximum entropy distributions, thus providing an intuitive grounding for the Pitman-Koopman-Darmois theorem (Koopman, 1936; Pitman, 1936) which states that finite-size sufficient statistics only exist for exponential distributions ­ i.e. maximum entropy distributions. Conversely, there are some (trivial) query sets, for which all abstractions are perfect. This can occur with any query function which simply ignores its input, and returns the same output for every input. All abstractions under this (trivial) query are perfect.

Given a perfect abstraction for a given query, we can directly show that this means that it contains all the information about the system important in answering the query. In information-theoretic terms, this means we can show that the mutual information between the final query distribution and the abstract summary is the same as the mutual information between the query distribution and the actual state, thus implying that all the information relevant to the query is captured by the abstraction

LQ(a, x) = 0 = DKL Q(p(x))||Q(m(a)) = 0 = Q(p(x)) = Q(m(a))

I[q; x] = DKL p(q, x)||p(q)p(x)

= DKL Q(p(x))||p(q)

= DKL Q(m(a))||p(q)

= DKL p(q|a)||p(q)

= I[q; a]

(10)

If we then generalize slightly from being given a specific abstraction vector, to instead being given a distribution p(a) over the abstraction vector, we find that the information contained within the abstraction with the queries is greater than

6

A PREPRINT - 4TH JUNE, 2021

q

Q(x)

x



q

Q(x~)

x~

a m(a)

Figure 1: The logical flow of the abstraction objective. We compare the query function evaluated on the real system q = Q(x) with that of the query set evaluated on the maximum entropy distribution q^ = Q(x~) which is generated from the abstraction x~ = m(a). The idea is that the difference between the `true' queryset evaluated on the system and that generated through the maximum entropy process based only on the abstraction is a good measure of the `leakiness' of the abstraction, since if this difference is minor, then this abstraction provides a good representation of the aspects of the system which we care about (as measured by the queries).

that just within the system, with the difference coming from the entropy of the abstraction distribution.

LQ(x, p(a)) = 0 = Ep(a)DKL Q(x)||Q(m(a))p(a) = 0

= Q(x) = Q(m(a))p(a)

I[q; x] = Ep(a)DKL p(q, x)||p(q)p(x) = Ep(a)DKL[Q(m(a))p(a)||p(q)]

= I[q; a] - H[p(a)]

(11)

If the abstraction distribution becomes a delta distribution p(a) = (a - a¯) then H[p(a)] = 0 and so we regain the original equality. Figure 1 shows a graph of the pattern of logic required. A good abstraction is one which minimizes the divergence over the query-set between the real system, and the maximum entropy system given the constraints imposed by the abstraction.
7

A PREPRINT - 4TH JUNE, 2021

2.1 Learning abstractions

While thus far, we have only provided a definition of an abstraction, and a means to judge the goodness of one, an important question we still wish to answer is whether we can learn abstractions from data. Given that we possess a computable objective function which measures goodness of an abstraction, this is straightforward in principle. We suppose we are given a dataset of i.i.d instances of the system D = {x1 . . . xN }  p(x) drawn from the distribution over system states from which we can learn the abstraction vector which minimizes our abstraction objective.

First, for conceptual clarity, we must distinguish between two different possible types of abstraction variables. Firstly, we have fixed, or static abstraction variables which do not depend directly on specific data items but only on the dataset as a whole. These are invariants of the dataset, and correspond to the classical notion of parameters in statistical models. We denote these as a and we often optimize a distribution over them p(a; D) = p(a) where we use the ; D when it is necessary to make explicit that these depend on the dataset as a whole, but are not a direct function of a specific dataset. The second kind of abstraction variables that are possible are those that depend directly on specific datapoints. In machine learning models these correspond to the latent variables which are output by an encoder network but which change depending on the specific datapoint considered and are used to model that specific datapoint. We denote these abstractions as a¯ and their distribution as p(a¯|x; ), which is the output of an abstraction function a¯(x; ) = p(a¯|x) with a set of parameters  which are learnt over the whole dataset and then applied to each datapoint. For instance p(a¯|x; ) could represent an encoder network in a variational autoencoder (Kingma & Welling, 2013) where the parameters  are the weights of the neural network (and, since they are not direct functions of the datapoint, are in a). For now, we will generally only consider the classical statistical parameters a as abstractions, and will return to this notion of latent variables encoding datapoints when we discuss the relationship to machine learning.

Combining these two sets of abstraction variables, we can write the joint objective to be optimized, for a given datapoint x as,

LQ(x, p(a), ) = Ep(a)DKL Q(x)||Q(m([a, a¯]))p(a)p(a¯|x; )

(12)

Then, we can simply learn the necessary abstraction parameters p(a),  as an optimization process over the full dataset ­ for instance using gradient descent,

 = -Ep(D)

LQ(x, p(a), ) 

(13)

And similarly for p(a). If we wish, we could optimize both a and a¯ simultaneously by interchanging iterations of

optimizations of one variable while holding the other fixed. In the language of Bayesian inference, this corresponds

to a factorization assumption between a and a¯ where inference is performed through the Expectation-Maximization

(EM) algorithm (Dempster, Laird, & Rubin, 1977). This objective is computable as long as the queries are computable

and the solution of the maximum entropy variational problem to infer p~(x|a) is tractable. As such, the gradients of

the objectives required for Equation 13 can be computed by automatic differentiation software (Griewank et al., 1989;

Paszke et al., 2017). An important note is that if we wish to use the abstractions for multiple queries in a query set,

we should update the learning rule to update with the average abstraction loss over the query set. We will discuss the

implications of this for machine learning architectures later.

 = -

p(Qi)Ep(D)

LQ(x, p(a¯), ) 

(14)

Qi Q

While this approach will be able to infer the best abstraction vector given the state, it can only infer abstraction vectors of a given dimensionality. However, for many systems, the correct dimensionality of the abstractions is not known a-priori. Thus, more general methods which can infer both the optimal a and the optimal dimensionality of A would ultimately be ideal. This problem is very close to that of model selection encountered in the statistics literature, and may be solved in a very similar manner. For instance, if we consider the dimensionality of A as a model, then we could fit separate functions p(a¯|x; ) for each dimensionality, then compare the ultimate abstraction loss obtained, and

8

A PREPRINT - 4TH JUNE, 2021
ultimately compare the models through classical model selection techniques such as Bayes Factors (Chipman et al., 2001; Sakamoto, Ishiguro, & Kitagawa, 1986; Stephan, Penny, Daunizeau, Moran, & Friston, 2009).
One key computational difficulty with this scheme is the necessity to infer the maximum entropy distribution before applying the query distribution, since the query distribution takes in the system distribution p(x) as input. While in many cases inferring the maximum entropy distribution of the state is easy since, for well-known constraints, it follows a natural and mathematically tractable maximum entropy distribution, such as the Boltzmann, or Gaussian distributions, in many other cases, with more complex constraints, the solution to the variational equation in Eq 7 is a challenging computational problem without a neat solution. In these cases, there may be difficulty directly computing, and hence optimizing this loss function to be able to learn good abstractions.
The ideal scenario would be if we were able to define or learn a composite query function which directly maps from the abstract state to the query distribution ­ Q~ : A  Q. By inspecting Figure 1, we can see that this composite query function is simply the composition of the maximum entropy function m, which maps the abstraction to its maximum entropy distribution and the original query function. Thus we have that Q~ = Q  m. If this composite function Q~ could be learnt, approximated, or computed straightforwardly, it would greatly improve the computational efficiency of this scheme by circumventing the necessity to solve the maximum entropy variational problem on each step. Additionally, it has the benefit of conceptual clarity. In many cases, the whole point of abstraction is to not need to refer to the original system anymore, and instead run your queries directly on the abstract representation. This is precisely what Q~ enables. Discovering whether this scheme can be reorganized, so that Q~ becomes the central computational unit is a very important area for future work, since it would bring this scheme much closer to the intuitive use of abstractions, where the queries are often defined only in terms of the abstract variables themselves and not upon the entire system state.
If we allow for a distinction between phases of `learning' and phases of `inference', then it is quite straightforward to imagine an approximate Q~(a; ), with parameters  being learned during a learning phase where the abstractions a are also learnt by optimizing Eq 8. The loss function for Q~ would be extremely simple ­ just the difference or divergence between the prediction given by Q~(a; ) and the actual query output by going through the maximum entropy system ­ LQ~ = D Q~(a; )||Q(m(a))) . Then, once Q~ has been learned, it could be used during an inference phase to directly infer query outputs purely from the abstractions without any reference to the underlying system.
2.2 Dynamical Abstractions and Maximum Calibre
It is fairly straightforward to extend this principle to the inferring abstractions of dynamical systems, which is more often the case that obtains in reality. Here, we do not wish to simply learn a static abstraction to handle static queries from a static system. Instead, we wish to be able to answer queries over time from a dynamically changing system. To handle this in the maximum generality, we therefore need to define dynamically changing abstractions, or rather an abstract dynamical system, which tracks the relevant behaviour of the real system, while throwing away all information irrelevant to the queries. This abstract dynamical system maintains a low-dimensional set of abstract variables at  A and updates them over time in accordance with the abstract differential equation a = fa(at) where fa is the abstract update function. To specify such an abstract system, in direct analogy with the low-level system, we need only specify the initial abstraction a0 and the abstract update function fa. Similarly, we define our particular system in terms of differential equations x = f (x) with a dynamics function f . We typically want our queries to remain constant over time, but can also use queries which change over time Q(x, t). The key change comes in our definition of the maximum entropy system, given the constraints encoded by the abstractions. Here, instead of using the principle of maximum entropy, we instead use the principle of maximum calibre (Dixit et al., 2018; Jaynes, 1980), an extension of maximum entropy, which instead considers maximizing the path integral of entropy over a dynamical trajectory, given dynamical constraints, rather than simply minimizing the maximum of the entropy at each particular point. If we denote a trajectory
9

A PREPRINT - 4TH JUNE, 2021

of variables using square brackets [xt] = [x1 . . . xT ], then we can define the maximum calibre path as,

m([at]) = p~([xt]|[at]) = dt argmax H[p([xt]|[at)]] - 0 p([xt]|[at])dx - [1]

(15)

p([xt ]|[at ])

Given this, then it is straightforward to extend our previous abstraction loss functions to instead become path integrals of the loss function over time,

a = argmin L([at], [xt])
a0 ,fa

L([at], [xt]) = dt , p(qi)LQ(a, x, t)
iQ

LQ(a, x, t) = D Q(xt)||Q(m(at))

(16)

2.2.1 Learning Dynamical Abstractions

While the generalization to dynamical abstractions is straightforward, dynamical abstractions also give us an additional unique ability relative to static ones, namely that it is possible to define a contrastive objective that can learn them purely in the abstraction space, without reference to the original (or the maximum entropy version) system, if we have access to the correct composite function Q~ = Q  m. The key idea here is that with a dynamical system, where we possess both an abstract state and an abstract dynamics function, we can simply compare the dynamical evolution of the abstract state at every timestep with the abstract state inferred from the real system state at that timestep. For instance, suppose we consider the predicted abstract state according to the abstract dynamics function as p(a^t|at-1) = fa(p(at-1)), and additionally, we have the abstraction generated directly from the system state xt from the abstraction function p(at|xt) = a(xt). Given that we have these two independent sources of information about the abstraction ­ its a-priori abstract dynamics and the abstraction directly inferred from the current state of the system, we can simply minimize the divergence between these relative to the composite query function as our new abstraction objective.

a, fa = argmin dt D Q(at)p(at|xt)||Q(a^t)p(a^t|at-1)

(17)

a,fa

Importantly, this objective makes no reference to the underlying system except insofar as to infer the abstraction from it, and completely eschews the computation of the maximum-entropy system given the abstraction state, which may be a significant computational saving. This option is available in the case of dynamical abstractions, because we have multiple sources of information about the abstraction ­ namely the abstraction inferred directly from the system, and the abstract state computed by the abstract dynamics function, which we can enforce consistency between. The key challenge in this case is learning the abstract `encoder' function a(xt) which maps from the system state xt to the desired abstraction of that state at). If we possess a dataset of known pairs (xt, at then we can learn this encoder system simply by treating it as a regression problem.

2.3 Relationship to statistical inference
So far we have considered abstractions as a function of arbitrary queries Q. Here, we consider the abstraction learning objectives under one specific query ­ the reconstruction query: Q(p(x)) = p(x). This is an extreme case and is where the query is simply to precisely reconstruct the system as accurately as possible. In this case, we discover that our scheme precisely collapses into standard maximum likelihood (ML), or maximum a-posteriori (MAP)2 inference as is undertaken in classical statistics. This result provides the important conceptual link for understanding how our notion of abstraction and abstraction learning relates to standard statistical methods ­ namely that standard statistical methods can be considered to be learning abstractions under just the reconstruction query. That is, we can conceptualise statistical
2Where the prior comes in as a prior over the abstraction distribution p(a)

10

A PREPRINT - 4TH JUNE, 2021

methods as aiming to learn those abstractions which will allow them to precisely characterise the entire dataset without throwing away any information. Conversely, this allows us to view our abstraction approach as a straightforward generalization of classical statistics to the case where we are not interested in modelling the data itself, but only in modelling (lossy) functions of the data.

To begin, we return to the original abstraction objective (Equation 8) and apply it to the case where we possess a dataset of i.i.d elements drawn from the distribution over the system D = {x1 . . . xN }  p(x). In this case, the optimal abstraction is,

a = argmin Ep(D)DKL[Q(x)||Q(m(a))]
a

= argmin Ep(D)DKL[p(x)||p~(x|a)]

(18)

a

Where we have used the fact that we are assuming the reconstruction objective Q(x) = p(x). Then, using the fact that dataset distribution is simply an empirical distribution over observed datapoints p(D) = i (x - xi), we can see that this objective simplifies to,

a = argmin Ep(D)DKL[p(x)||p~(x|a)]
a

= argmin - H[p(D)] - Ep(D)[ln p~(x|a)]
a

= argmax ln p~(xi|a)

(19)

a

i

Where in the final line we have used the fact that the entropy of the data distribution H[p(D)] is fixed (with respect

to the abstraction parameters) so that it has no impact on the optimization, and the fact that the data distribution is

empirical over the datapoints, so the expectation simply reduces to a sum of the probabilities of each datapoint. This

objective is then obviously the standard maximum likelihood objective from statistics, as it simply aims to maximize the

sum of the log likelihoods of the data given the abstraction, which would correspond simply to a statistical parameter

(such as the mean or variance) in a statistical generative model. An important but subtle difference, however, to classical maximum likelihood is that here we are maximizing the likelihood of the maximum entropy distribution p~(xi|a). In almost all cases, this will be the same as the standard likelihood p(xi|a) in classical statistics, since almost all of the distributions commonly used in parametric statistics are, in fact, maximum entropy distributions. The reason for this is

simply because maximum entropy distributions are precisely those which can be parametrized with a finite number of

sufficient statistics. However, this approach to may subtly differ in the case of a nonparametric likelihood model, which

can be modelled with an implicitly infinite amount of parameters.

If we generalize this to instead learn a distribution over the abstractions p(a; ) with potentially some parameters , then the objective we optimize will become,

 = argmin Ep(D)DKL[Q(x)||Q(m(a))p(a; )]


= argmax ln p~(xi|a)p(a; )

(20)



i

Where to reach the second line, we have simply redone exactly the same steps as in the previous derivation but with our new objective. It is straightforward to see that this then corresponds to maximum a-posteriori (MAP) inference where the abstraction distribution p(a; ) becomes identified with the Bayesian prior. If we take the abstraction distribution to be deterministic p(a; ) = (f () - a), then the MAP objective collapses back down to the ML, as expected. Effectively, what we have shown is that the learning of abstractions reduces to classical ML or MAP statistical inference using a reconstruction query or, conversely, that classical statistical inference methodologies to learn latent variables can be seen as abstraction learning techniques where the query is simply to reconstruct the data. This means that our notion of abstraction considered here can be construed as a straightforward generalization of classical statistics to the case where we are not interested in reconstructing the data, but a set of lossy, or coarse-grained, functions of the data.

11

A PREPRINT - 4TH JUNE, 2021

Alternatively, we can consider statistics, or the process of learning latent variables or parameters of models, to be implicitly learning abstractions where the only query is simply to reconstruct the data as accurately as possible.

Interestingly, it is easy to show that the reconstruction objective Q(x) = p(x) is, in an information-theoretic sense, the `hardest' query to abstract in that it preserves the most possible information about x. This is obvious intuitively, since of course x (or any bijective function of x) contains the most possible information about x. It is also straightforward to show this mathematically. If we consider the information between the system state x and the query distribution under two queries, the reconstruction query q1 = Q1(x) = x and any other query q2 = Q2(x) = x.

I[q1, x] = I[x, x] = H[X]

I[q2, x] = H[X] - H[X|Q2]

 H[X]

 I[q1, x]

(21)

Where the inequality follows because the entropy is necessarily positive. Maximum likelihood statistics also has an close relationship with the principle of information-maximization (Info-Max) which is fairly straightforward and is explored in Appendix C. We briefly discuss some potential applications of our ideas for machine learning in Appendix D.

3 Why should good abstractions often exist?
I know of scarcely anything so apt to impress the imagination as the wonderful form of cosmic order expressed by the `law of frequency of error' [the normal or Gaussian distribution]. Whenever a large sample of chaotic elements is taken in hand and marshaled in the order of their magnitude, this unexpected and most beautiful form of regularity proves to have been latent all along. The law...reigns with serenity and complete self-effacement amidst the wildest confusion. The larger the mob and the greater the apparent anarchy, the more perfect is its sway. It is the supreme law of unreason.
Natural Inheritance (1894) by Francis Galton
Here, we consider the question of why there should be useful abstractions in general. What is the fundamental reason that, empirically, there often appear be low dimensional summaries that are almost perfect at answering queries about very high dimensional systems ­ and which can often generalize across many disparate queries? The key element again comes from the maximum entropy principle through the form of aggregating, or limiting, distributions. It is a well known fact in statistics that complex generative processes which consist of a large number of interacting parts often result in data which are highly regular and conform to one of a simple set of known and mathematically tractable distributions.
The most well known example of this is the Gaussian distribution which, by the Central Limit Theorem as Galton poetically describes, any process which involves the summing (or convolution) of a large number of random variables, no matter the distribution of those variables, will converge towards. This simple fact of aggregation explains why so many processes we observe in nature so often tend to obey Gaussian statistics, even if on the surface they appear to have no clear features that would predict Gaussianity. While this effect is most well known for Gaussians, there are a wide range of such aggregating distributions to which many random processes formed of interacting components converge.
The key insight which explains this, originating from the maximum entropy principle and developed to a high level by Frank (2009) is that the reason these distributions arise, and the reason they are what they are, is due to a maximum entropy process. If we consider some noisy process of interaction, which maintains only certain invariant properties of the distribution, then as more processes are included, or aggregated, then the overall distribution tends inexorably towards the maximum entropy distribution which satisfies those invariants as constraints. If the only information preserved through interactions is about variance, then a Gaussian distribution results. This maximum entropy approach

12

A PREPRINT - 4TH JUNE, 2021
generalizes the central limit theorem, which only considers the case of the addition, or convolution, of many random variables, since the maximum entropy approach demonstrates that any process of aggregation that preserves only variance will inexorably tend towards the Gaussian. Similarly, Frank (2009, 2016) extended this argument to show that many other well known distributions in classical statistics can be derived directly from maximum entropy principles given different constraints. For instance, binomial distributions arise as the maximum entropy solution when we only care about numbers of a certain kind of event and not their order, and power-law distributions arise when the aggregation process preserves the geometric mean.
At the lowest level, the invariant quantities preserved through interaction are often those invariants relating (by Noether's theorem) to symmetries in the underlying physical laws ((Blanchard & Brüning, 2012; Hanc, Tuleja, & Hancova, 2004; Lanczos, 2012)). For instance, the Boltzmann distribution in statistical physics derives entirely from the fact that the energy of a (closed) physical system is conserved no matter the interactions between its components, and this energy conservation rule derives entirely from the time-translation symmetry of space-time, and we should expect other regular distributions to arise in other circumstances due to the conservation of other quantities, such as angular momentum or charge. These natural invariants mean that, at the very least, we should expect to be able to understand physical systems composed of many interacting variables based upon the low-dimensional summaries comprising the parameters of the maximum entropy distributions such systems naturally form, given the constraints imposed by these invariants. These parameters then become our first abstractions, which often allow us to almost perfectly model physical systems comprising of many trillions of interacting elements using only a few real numbers.
We argue that this process of aggregation giving rise to well-defined and mathematically simple maximum entropy distributions with just a few key parameters, is ultimately what often leads to the existence of good abstractions to define a system. Specifically, since the maximum entropy distribution can be described in a few parameters, and many interactions involving that system only depend on the shape of the distribution as a whole, not the specifics of any event making up the distribution, then these interactions can also be predicted primarily on the basis of the maximum entropy parameters. This idea can then be extended hierarchically as well, where the maximum entropy distributions themselves become the interacting elements of a higher level process, which itself converges to another maximum entropy distribution which can then be described with just a few higher-level parameters. This hierarchical aggregation of maximum entropy distributions may allow for more complex `composite' constraints and hence distributions to be built out of simpler constraints while maintaining the ability to be described by (relatively) few parameters relative to the number of `base states' of the system. While the basic levels of aggregation in terms of preserving simple information such as means, variances, and ratios have been well worked out, as reviewed very clearly here (Frank, 2009, 2016), whether such composite distributions, which maintain more complex information about their underlying distributions, and thus have a more complex, but still finitely describable maximum entropy form, leading to more complex abstractions remains unknown and must be worked out precisely in future work. Nevertheless, while this is simply an intuitive sketch of an argument, we believe it provides a strong case for why we should naturally expect aggregation of many independent processes under some informational constraints which arise from the specifics of the interaction process to lead to limiting aggregate distributions which are easily describable with just a few parameters, and then these parameters can ultimately serve as our abstractions which can achieve high predictive accuracy of the system and its behaviour while containing vastly less information than the sum of the microstates of the system.
Since the notion of aggregating or limiting maximum entropy definitions can provide us with an understanding of why and how abstractable systems may come into being, it also simultaneously provides us with a set of conditions for when we might expect abstractable systems to arise: namely, those where we expect aggregating distributions to arise, which are those systems composed of many interacting random variables, which interact in a way which preserves only specific types of information. These conditions necessary for aggregation appear to arise regularly in the real world for a number of reasons.
The key necessary quantities are fundamentally uncertainty and distance, either spatially or temporally or both. Uncertainty, which may relate to epistemic uncertainty of the observer or else intrinsic stochasticity in the dynamics
13

A PREPRINT - 4TH JUNE, 2021
(or both) is necessary to ensure that low level information is slowly wiped out over time, meaning that only high level informational constraints are preserved over multiple interactions. This property is necessary for all aggregating distributions ­ for instance in the central limit theorem ­ to ensure that noise from many different variables interferes with and destroys the information contained within other variables during their interactions. It is important to note here that epistemic uncertainty plays exactly the same role as noise here, even if there is no intrinsic stochasticity. If there is any errors and unknowns in the initial specification of a system with many interacting parts, of the kind that are described by limiting distributions, then interactions between components will tend to distribute and increase our epistemic uncertainty about the system until the uncertainty tends to the maximum possible (the maximum entropy distribution). This idea is identical to that of chaos in dynamical systems theory, whereby small uncertainties in the initial state of the system propagate exponentially until the microscopic state of the system rapidly becomes unpredictable, even with known, deterministic dynamics. Systems composed of extremely large numbers of interacting elements are almost always chaotic in their microscopic details 3. It is this microscopic chaos, then, that ultimately allows for aggregating distributions to arise, and thus underpins the formation of predictable macrophenomena (or abstractions). The theory of maximum entropy thus provides a crucial link between reproducible and abstractable macrophenomena, and the microscopic chaos that underpins them. Conversely, microscopic chaos is what ultimately justifies the principle of maximum entropy. Namely, uncertainty in a chaotic system will increase exponentially until it hits the structural limit given by the information that is maintained across interactions, rendering the maximum entropy configuration the exponentially most likely solution (Jaynes, 1985).
The second necessary precondition for the observation of abstractions is distance, in terms of time or space. This is necessary to allow enough interactions amid the system elements for the uncertainty in those distributions to aggregate into a maximum entropy form. This can be thought of from a statistical perspective as distance is what enables a large enough `sample size' to accumulate to enable the `data' to form into a recognizable distribution. Things that are `far' from us look simpler, and can often be described accurately (in terms of their interactions with us) with fewer parameters. Things that are close to us appear more complex and their interactions with us are much more nuanced and require more parameters to describe. From the perspective of a gas molecule in the eponymous box of gas, the average energy of the gas does not seem like a useful description of the behaviour it sees around it. Conversely, from the perspective of a scientist wishing to explain its macroscopic properties, things like the average energy are perfectly sufficient. And, from the perspective of an alien in a far-off galaxy, any properties of the box of gas are irrelevant (and likely unknowable). All it needs to describe our interactions with it are extremely coarse-grained properties like the mass, centre of mass, and average luminance of the Milky Way galaxy. In some sense this is an obvious truism, but an important one. If we imagine all interactions between everything as taking place on some giant causal graph, then the distance between any two systems can be computed as the path length between them. At every node along this path, uncertainty or intrinsic noise propagates interferes with the original signal and reduces the information which can be retrieved at the end of the path, with the exception of potentially preserving some aggregate information. Over the course of this path, more and more interacting systems are aggregated together until the entropy increases to its structural limit, and the signal can be entirely represented as a maximum entropy distribution with just a few parameters. Then, if the path is long enough, this process continues recursively, with more information being lost, and the original maximum entropy distribution becomes merely an interacting element of a higher-order maximum entropy distribution, and so on, until entire swathes of the graph can be described relatively well purely in terms of a few abstraction parameters.
3.1 Are there `natural' abstractions?
Thus far, we have been considering abstractions considering only a single arbitrary query set, but this story of abstractions deriving from maximum entropy solutions arising due to aggregation suggests that there may be a set of `natural' abstractions for a given system ­ namely the parameters of the maximum entropy distribution which describes the system. These parameters, or the natural abstraction of the system, should be able to perfectly answer any query which
3If the 3-body problem in classical mechanics is chaotic, imagine how chaotic the 6 × 1023-body problem must be
14

A PREPRINT - 4TH JUNE, 2021

only needs information about the system's distribution to answer, rather than information about a particular element of the underlying system. Similarly, if maximum entropy distributions of systems can interact to produce more complex maximum entropy distributions with a more complex set of interaction constraints, as postulated previously, then the parameters which parametrize these constraints will become a higher level set of abstractions.

It may also be possible to generalize this idea, and ask, for any arbitrary system distribution, whether there exists some set of natural abstractions which can match any query concerning distributional properties of the system. Specifically, we wish to derive a measure of the universal `abstractability' of a distribution which is the amount of information in an abstraction needed to specify the full distribution of the system. This question corresponds to whether a given arbitrary distribution can be compressed and represented as the maximum entropy solution to a set of finite constraints, and is closely related to the question of the extent to which an arbitrary distribution can be compressed, or represented as a program, and thus has close relations to Kolmogorov Complexity (Chaitin, 1977; Kolmogorov, 1965) and algorithmic information theory.

We now consider how we might formalize this notion of a universal kind of `abstractability'. We start with some

distribution p(x), and we wish to measure how easily it can be encoded to a given degree of accuracy. The key problem

is to develop a method to encode an arbitrary distribution varying over a continuum. Here, we assume that we can

encode this arbitrary distribution as an infinite mixture of tractable exponential-family distributions. Here, without loss

of generality, we assume that these exponential mixture distributions are Gaussian.

1

p(x)  Z

(xi)N (x; µi, i)

(22)

i=0

where (xi) is the probability that weights that particular mixture density, µi, i are the parameters of the mixture

Gaussian, and Z is an arbitrary normalizing constant that may be necessary. We know that this infinite mixture

density can approximate any arbitrary distribution, since the value of the real distribution p(x) at a point can simply be

approximated by an infinitely narrow Gaussian distribution   0 with a mean of that point µi = xi, and the mixture weight equal to the probability (xi) = p(xi). The constraint that the mixture density coefficients must sum to one is not problematic since the real distribution shares the same constraint. While, we know we can therefore always exactly

approximate any distribution with an infinite mixture, there may be many other ways to approximate it. If there are, then

we can derive a measure of the universal abstractbility of the distribution as the entropy of the mixture distribution (x).

If we are to use (x) as a measure of abstractability, then to make it a meaningful measure of the true abstractability,

we must choose the minimum entropy solution of (x) under the constraint that the full set of (x), µi, i equals the real distribution. If we formalize this mathematically using Lagrange multipliers, we define the universal abstractability

measure A[p(x)] as follows,

A[p(x)] = H[(x)]

(x) = argmin H[(x)] + 
 (x),µi ,i

1 Z


(xi)N (x; µi, i) - p(x)
i=0

(23)

Let's consider the extreme cases. Suppose that the distribution p(x) simply is an exponential-family (Gaussian) distributions p(x) = N (x; µ¯, ¯). In this case, the minimum entropy mixture distribution is to set one mixture coefficient to 1 and the rest 0, and then set the parameters of that distribution to the parameters of the real distribution µi = µ¯; i = ¯. In this case, the abstractability A = H[(x)] = H[(x - xi)] = 0 (A really represents `unabstractability' so that the smallest value it can take is 0, meaning that all the information in the real distribution p(x) can be abstracted). Conversely, suppose that we cannot abstract anything and are forced to match every point of p(x) with its own mixture distribution. In this case, we have that A = H[(x)] = H[p(x)], or that the worst-case abstractability is simply the entropy, or Shannon information content of the distribution 4. Perhaps unsurprisingly, this
4While it may be possible to have solutions to the mixture density problem with higher mixture entropies than the actual distribution, for instance a uniform (x), these possibilities are eliminated by the minimum entropy constraint in Eq 23, since we know the (x) = p(x) solution always exists, it provides a strict upper bound on the abstractability

15

A PREPRINT - 4TH JUNE, 2021
highlights the close connection notions of abstractability have with information theory and Kolmogorov Complexity and Minimum Description Length, where we consider the concept of `universal abstractability' to be the same as its compressibility and closely related to its Kolmogorov complexity (i.e. the length of the smallest program needed to generate the object. This approach here effectively generalizes these ideas from discrete strings to continuous distributions. Importantly, the universal abstractability of a distribution is distinct from just the Shannon entropy of the distribution (the entropy provides an upper bound), as can be straightforwardly seen in the case where the distribution p(x) takes the form of a single exponential family distribution. The precise relationship between the measure of universal abstractability proposed here and Kolmogorov complexity remains to be elaborated upon in future work. There is also a close connection between our conception of density approximation using an infinite mixture distribution and the field of nonparametric statistics which follow a similar approach of trying to model the data distribution using an implicitly infinite mixture distribution (Higgins, 2004; Wasserman, 2006). A key difference to our proposed method is the way the mixture distribution is computed. Nonparametric methods typically define an explicit generative process which generates the mixture distribution (x) such as, for instance, the Dirichlet stick breaking process (Teh, 2010), or the Indian Buffet process (Griffiths & Ghahramani, 2011). By contrast, we find the mixture distribution through the solution of a variational maximum entropy problem (Eq 23). Beyond this, the relationship between our method of estimating abstractability and nonparametric statistics remains to be fully elucidated.
4 Discussion
In this paper, we have endeavoured to lay out the potential beginnings for a mathematical theory of abstraction; a concept which is widely used and understood intuitively, and with close connections to folk notions of understanding, learning, and inference, but which has so far mostly eluded mathematical formalization and scrutiny. We have argued that the two key defining properties of an abstraction are that it is query-dependent, in that any given abstraction is only designed to answer certain questions about a system accurately, and that the abstraction throws away information which is not relevant to answering those queries. Secondly, we formalize this notion of `throwing away' information through the use of a maximum entropy system which represents the knowledge of the system given only by the abstraction itself, and we can use this definition to define an objective which intuitively corresponds to the `leakiness' of an abstraction as a basis for both evaluating the value of any specific abstraction against a query set, as well as potentially as an objective function which, when combined with a parameterised abstraction model could be used to learn abstractions from data.
While our definition of abstraction is closely related to classical ideas in statistics, it actually comes from a subtly different perspective. Statistics is ultimately concerned with modelling the data ­ we infer parameters which can best explain the observed data. Maximum likelihood methods make this explicit, but this philosophy underpins other approaches as well. We, on the other hand, are not, in general, concerned with modelling the data itself, but only the answers to a set of queries on the data, which may or may not require all the information contained within the dataset to answer. We thus have a notion of relevant or irrelevant information which classical statistical methods do not, as shown by the close connection discussed earlier (and in Appendix C) between maximum likelihood and information-maximization. Indeed, on a mathematical level, our definitions can simply be considered to be the application of standard statistical methods and objectives applied to a set of functions of the data, rather than the data itself. Conversely, we can consider classical statistics to be concerned with learning abstractions which are specifically just coarse-grainings of the dataset, in that they allow for the most efficient possible reconstruction of the full dataset. A similar story plays out with the relationship between our notion of abstraction and other notions of complexity such as Kolmogorov' Algorithmic Complexity, and the ideas of Minimum Description Length coding (Grünwald & Grunwald, 2007). These methods are fundamentally interested in the information necessary to encode the data (or object) perfectly, or if there is a loss, ensuring that it is small and relatively uniformly distributed across the full data-space. Our notion of abstraction, on the other hand, does not try to preserve all the information in the data, but only keeps that which is necessary to answer queries from the query set and discards everything else.
16

A PREPRINT - 4TH JUNE, 2021
Our results have deep implications for our understanding of inferential and cognitive systems in general. Firstly, it may be the case that we should not necessarily model such systems through the lens of classical statistics where we aim only to reconstruct data that we are given, but instead through the lens of first understanding the kinds of queries which the system needs abstractions and representations to answer, and then the kinds of representations which can best answer those queries. This is of especial interest for evolved biological systems which have evolved not, in general, to perfectly reconstruct the world, but only to respond adaptively to the world. This means that we might expect that the abstractions or representations learnt by such cognitive systems should be heavily tuned for the type of queries that are often necessary for survival and reproduction rather trying to build a detailed veridicial model of all the detail in the world. This view has close links to enactivist and embodied ideas in the philosophy of cognition which hold, at a broad level, that the key purpose of cognition is in enabling adaptive action rather than simply trying to understand the world in an unbiased way. Cognitive agents built according to such ideas might have representations and models of the world which are substantially `wrong' from the viewpoint of accurately representing the world, but which nevertheless are able to drive adaptive and successful action in the circumstances such agents usually find themselves. Our definition of abstraction can be thought of as providing a comprehensive mathematical formalism which can make these ideas precise.
Finally, it is important to note that the framework here is only preliminary and may be subject to change. Specifically, while we have attempted to put together a consistent and precise theory of abstraction, it is still undetermined whether this is actually the optimal or most useful definition of abstraction available. We believe that our definition matches many of the properties of our intuitive notion of abstraction, while also making them precise and available in a computationally tractable framework which permits the learning and inference of abstractions from both static datasets and dynamical systems. Nevertheless, it remains an open question whether the definitions of abstraction given here are the most felicitous possible, and in general the goal efficiently learning the optimal abstractions from data is still a long way away.
A key hurdle the theory must clear before it becomes useful is whether it is computable in practice and empirically leads to good results on learning benchmarks, especially if the optimization of Equation 8 actually leads to learning useful or recognizable abstractions given ecologically valid query sets. The computation of the maximum entropy system seems likely to be the key bottleneck in many cases, although for simple cases it can be worked out analytically using standard constrained optimization methods. Developing methods to make computing and optimizing Eq 8 and Eq 7 efficiently, as well as designing statistical methods containing the right inductive biases to make abstraction learning straightforward remains an open and challenging task. With regards to applications for machine learning, one clear suggestion by our theory is simply that practitioners think much more deeply about the kinds of query they actually want to make of a given system or dataset, and then train their system against those queries, and especially consider training against a large number of queries if that is desired, instead of just optimizing one proxy. For machine learning, this would consist of training with many loss functions simultaneously, an area which is largely unexplored, and may yet yield substantial improvements to performance, robustness, and generalizability for a relatively small effort in understanding exactly what queries are desirable, and then designing an objective function that optimizes against those queries.
5 Acknowledgements
I wish to thank the many discussions with and edits by Christopher L Buckley, which substantially improved this work and especially the mathematical notation, and the contribution of Mycah Banks in helping proofread the document and prepare the figures. My work here owes a substantial intellectual debt to John Wentsworth whose Lesswrong articles on abstraction provided many useful insights and got me interested in providing a mathematical formulation of abstraction in the first place. The section on why abstractions are possible is heavily intellectually indebted to S.A Frank's papers on aggregation and limiting processes to a much greater degree than can be established by a simple citation.
17

A PREPRINT - 4TH JUNE, 2021
References
Barlow, H. B. (1961). The coding of sensory messages. Current problems in animal behavior. Beal, M. J. (2003). Variational algorithms for approximate bayesian inference (Unpublished doctoral dissertation).
UCL (University College London). Bell, A. J., & Sejnowski, T. J. (1995). An information-maximization approach to blind separation and blind
deconvolution. Neural computation, 7(6), 1129­1159. Bishop, C. M. (2006). Pattern recognition and machine learning. springer. Blanchard, P., & Brüning, E. (2012). Variational methods in mathematical physics: a unified approach. Springer
Science & Business Media. Blei, D. M., Kucukelbir, A., & McAuliffe, J. D. (2017). Variational inference: A review for statisticians. Journal of the
American statistical Association, 112(518), 859­877. Casella, G., & Berger, R. L. (2021). Statistical inference. Cengage Learning. Chaitin, G. J. (1977). Algorithmic information theory. IBM journal of research and development, 21(4), 350­359. Chipman, H., George, E. I., McCulloch, R. E., Clyde, M., Foster, D. P., & Stine, R. A. (2001). The practical
implementation of bayesian model selection. Lecture Notes-Monograph Series, 65­134. Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood from incomplete data via the em algorithm.
Journal of the Royal Statistical Society: Series B (Methodological), 39(1), 1­22. Dixit, P. D., Wagoner, J., Weistuch, C., Pressé, S., Ghosh, K., & Dill, K. A. (2018). Perspective: Maximum caliber is a
general variational principle for dynamical systems. The Journal of chemical physics, 148(1), 010901. Frank, S. A. (2009). The common patterns of nature. Journal of evolutionary biology, 22(8), 1563­1585. Frank, S. A. (2016). Common probability patterns arise from simple invariances. Entropy, 18(5), 192. Gibbs, J. W. (1879). On the equilibrium of heterogeneous substances. Goodfellow, I., Bengio, Y., Courville, A., & Bengio, Y. (2016). Deep learning (Vol. 1) (No. 2). MIT press Cambridge. Griewank, A., et al. (1989). On automatic differentiation. Mathematical Programming: recent developments and
applications, 6(6), 83­107. Griffiths, T. L., & Ghahramani, Z. (2011). The indian buffet process: An introduction and review. Journal of Machine
Learning Research, 12(4). Grünwald, P. D., & Grunwald, A. (2007). The minimum description length principle. MIT press. Hamming, R. W. (1986). Coding and information theory. Prentice-Hall, Inc. Hanc, J., Tuleja, S., & Hancova, M. (2004). Symmetries and conservation laws: Consequences of noether's theorem.
American Journal of Physics, 72(4), 428­435. Higgins, J. J. (2004). An introduction to modern nonparametric statistics. Brooks/Cole Pacific Grove, CA. Hinton, G. E., & Zemel, R. S. (1994). Autoencoders, minimum description length, and helmholtz free energy. Advances
in neural information processing systems, 6, 3­10. Jaynes, E. T. (1957). Information theory and statistical mechanics. ii. Physical review, 108(2), 171. Jaynes, E. T. (1980). The minimum entropy production principle. Annual Review of Physical Chemistry, 31(1),
579­601. Jaynes, E. T. (1985). Macroscopic prediction. In Complex systems--operational approaches in neurobiology, physics,
and computers (pp. 254­269). Springer. Jaynes, E. T. (1988). The relation of bayesian and maximum entropy methods. In Maximum-entropy and bayesian
methods in science and engineering (pp. 25­29). Springer. Jaynes, E. T. (1989). Clearing up mysteries--the original goal. In Maximum entropy and bayesian methods (pp. 1­27).
Springer. Jaynes, E. T. (2003). Probability theory: The logic of science. Cambridge university press. Kingma, D. P., & Welling, M. (2013). Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114. Knill, D. C., & Richards, W. (1996). Perception as bayesian inference. Cambridge University Press. Kolmogorov, A. N. (1965). Three approaches to the definition of the concept "quantity of information". Problemy
18

A PREPRINT - 4TH JUNE, 2021
peredachi informatsii, 1(1), 3­11. Koopman, B. O. (1936). On distributions admitting a sufficient statistic. Transactions of the American Mathematical
society, 39(3), 399­409. Lanczos, C. (2012). The variational principles of mechanics. Courier Corporation. Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., . . . Lerer, A. (2017). Automatic differentiation in
pytorch. Pitman, E. J. G. (1936). Sufficient statistics and intrinsic accuracy. In Mathematical proceedings of the cambridge
philosophical society (Vol. 32, pp. 567­579). Sakamoto, Y., Ishiguro, M., & Kitagawa, G. (1986). Akaike information criterion statistics. Dordrecht, The Netherlands:
D. Reidel, 81(10.5555), 26853. Shannon, C. E. (1948). A mathematical theory of communication. The Bell system technical journal, 27(3), 379­423. Stephan, K. E., Penny, W. D., Daunizeau, J., Moran, R. J., & Friston, K. J. (2009). Bayesian model selection for group
studies. Neuroimage, 46(4), 1004­1017. Teh, Y. W. (2010). Dirichlet process. Wainwright, M. J., & Jordan, M. I. (2008). Graphical models, exponential families, and variational inference. Now
Publishers Inc. Wasserman, L. (2006). All of nonparametric statistics. Springer Science & Business Media.

6 Appendix A: Derivation of the Gaussian Distribution from Maximum Entropy Principles

Here, we derive the Gaussian distribution directly from the maximum entropy principle where we aim to maximize the entropy distribution based only on knowing a fixed variance of the distribution dx p(x)(x - µ)2 = 2. The first step is to write out the maximum entropy objective.

L = - dx p(x) ln p(x) - 0 dx p(x) - 1 - 1 dx p(x)(x - µ)2 - 2

(24)

For which we have the solution for p(x) as,

L = 0 = p(x) = e-(0-1)e-1(x-µ)2

(25)

p(x)

Then, we substitute this into the first (normalization) constraint to get,

dx e-(0-1)e-1(x-µ)2 = 1

e-(0-1) dx e-1(x-µ)2 = 1

e-(0-1) dz e-1z2 = 1

e-(0 -1)

 =1
1  = e0-1 1

(26)

19

A PREPRINT - 4TH JUNE, 2021

Where we have undertaken a change of variables z = (x - µ) and applied the Gaussian integral

dx e-x2

=

 .

Given this relation, we substitute into the second (variance) condition,

e-(0-1) dx e1(x-µ)2 (x - µ)2 = 2

e-(0-1) dz e1z2 z2 = 2

e-(0-1) 1 2

 31

= 2

e(0-1)2 = 1



21 1

(27)

Then, putting together Eq 26 and Eq 27, we have that,

e0-1 =

 1

=

221e(0-1)

= 221 = 1

1

= 1 = 22

(28)

Now that we have 1, we can substitute back to get 0,

e0-1 =   1

= 22



= 0 - 1 = ln 22

(29)

Substituting our expressions for the Lagrange multipliers 0 and 1 back into our expression for p(x) (Eq 25) gives us,

p(x) = e-(0-1)e-1(x-µ)2



= e- ln

2  2 -

1 22

(x-µ)2

=  1 e-

(x-µ)2 22

2

(30)

which is the Gaussian pdf.

7 Appendix B: Relationship of the Maximum Entropy Principle to Variational Inference and Variational Free Energy Minimization
The maximum entropy principle shares a close and interesting relationship with variational inference, which is a method to approximate optimal Bayesian inference, which involves the minimization of a variational free energy functional (Beal, 2003; Blei, Kucukelbir, & McAuliffe, 2017; Hinton & Zemel, 1994; Wainwright & Jordan, 2008). Indeed, variational inference originated in statistical physics and involves an information-theoretic analogue of an unimpeachable thermodynamic quantity ­ the thermodynamic free energy. Here we explore connections between these two theories, and ultimately show that variational inference is a subtle generalization of the maximum entropy principle to the case where the energy term (which represents the constraints in the maximum entropy formulation) are not fixed but depend on the state of the system, and can thus be maximized in parallel with the entropy. The maximum entropy principle, by contrast, treats the energy term as a fixed constraint which is not affected by the system state, and thus turns the optimization of the variational free energy from an unconstrained to a constrained optimization problem.
The maximum entropy principle proposes that given certain knowledge about macroscopic properties of a system ­ such that its average energy E¯ = E = i p(xi)Ei is equal to some constant, we can derive the most likely probability
20

A PREPRINT - 4TH JUNE, 2021

distribution over the states as the one that maximizes their entropy while fulfilling the constraint on the average entropy,

p(xi) = argmax H[p(xi)] - iEi

(31)

p(xi )

i

where E represents the set of constraints ­ for instance that the average energy equals a known constant i p(xi)Ei = E¯, and that the probability distribution of the states sums to one i p(xi) = 1, and  represents the lagrange multiplier. More generally, we can write this as minimizing a free-energy objective which is simply the energy minus the entropy,

p(xi) = argmin F
p(xi )

F= E - H

(32)

Energy Entropy

This functional is known as the free energy of a system in thermodynamics and is central to the field. Conversely, in

Bayesian inference, we often want to infer posterior distributions of some latent variables x given some data o. By

Bayes'

rule

we

can

write

p(x|o)

=

p(o,x) p(o)

where

p(o)

=

dxp(x, o) is known as the marginal likelihood and is often

intractable to compute due to the integration over all latent variables required. If the marginal likelihood is intractable,

then the Bayesian posterior will also be intractable as the marginal likelihood is precisely the normalization condition

for the posterior. While many approaches have been developed in the literature for approximating the true Bayesian

posteriors, one approach is known as variational inference, which instead postulates a separate `approximate posterior'

distribution q(x|o) which is designed to be tractable, and to optimize this approximate posterior by minimizing the

divergence between it and the true posterior (Beal, 2003; Wainwright & Jordan, 2008),

q(x|o) = argmin KL q(x|o)||p(x|o)

(33)

q(x|o)

However, this divergence is itself intractable due to containing the intracatable posterior. Instead, we minimize an upper bound on this divergence known as the variational free energy F. By minimizing this bound, the approximate posterior q(x|o) converges to the true posterior.

F = Eq(x|o) ln q(x|o) - ln p(o, x)

= KL q(x|o)||p(x|o) - ln p(o)

 KL q(x|o)||p(x|o)

(34)

Crucially, this `variational free energy' can be decomposed into precisely the energy and entropy terms of the free energy minimized by the maximum entropy principle,

F = Eq(x|o)[ln q(x|o)] - Eq(x|o)[ln p(o, x)]

= -H + E

(35)

Where -H = Eq(x|o)[ln q(x|o)] and E = -Eq(x|o)[ln p(o, x)]. So if they both involve minimizing a free energy functional, how do they differ? To understand the close relationship, we must first understand how to consider the maximum entropy objective as encoding an inference problem. First, it is clear that to phrase the constrained optimization as inference, we can define the values the constraints take to be our `observations' or `data' within the paradigm of Bayesian inference. This make sense, as the values of the constraints, such as the average energy of the box of gas, are precisely the `data' we work with when trying to infer the maximum entropy distribution of a system. Secondly, since the distribution p(x) over the system states is what we are trying to infer, and which really represents our beliefs about the system states rather than the system state itself, it makes sense to simply consider the maximum entropy distribution which we solve for as our approximate variational posterior, which allows us to make the identification pmaxent(x) = q(x|o). This identification allows us to identify the entropy term in the variational free energy with the entropy term in the maximum entropy objective. All that remains now is to understand how the energy terms of the two objectives relate. Crucially, we need to relate the constraints of the maximum entropy problem to the probabilistic generative model of variational inference. This can be done quite straightforwardly by

21

A PREPRINT - 4TH JUNE, 2021

assuming a factorized Gaussian form for the generative model with a set of independent constraints. That is, we define
p(o, x) = i p(oi, x) = i N (oi; f (xi), ) where fi(x) encodes a specific constraint function ­ i.e. for the average energy fi(x) = j p(xj)E(xj) and oi = ci where ci is a constraint value ­ i.e. the average energy equals some constant ci. This allows us to write the energy term of the free energy as,

E = Eq(x|o)[ln p(o, x)] = Ep(x) ln p(oi, x)

i

-

Ep(x)

1 22

(ci

-

fi(x))2

i

We can see this term approximates the constraint, since the best possible solution will be when E = 0 or when the

constraint is satisfied such that ci = fi(x). This then allows us to identify the variance of this Gaussian with the

lagrange

multiplier

by

defining



=

1 22

.

Thus,

the

constraint

becomes

tight

as







or,

equivalently





0.

This

set of definitions allows us to translate maximum entropy problems into variational inference problems and vice versa,

thus allowing us to see the close connections between these two approaches. Importantly, we can see that the maximum

entropy problem can be construed as a variational inference problem with the approximate posterior distribution being

the our maximum entropy belief distribution over the system state, and with this Gaussian generative models which

considers the constraint values as Bayesian observations, and the constraint functions as the prior over the system states,

and additionally allows for the identification of the variance of the generative model with the lagrange multiplier. This

means that we can consider the maximum entropy problem to be a special case of variational inference under certain

conditions, and may also lead to the ability to extend the maximum entropy approach to handle uncertainty natively, for

instance we can now represent uncertainty in our constraint values in a natural manner.

8 Appendix C: Relationship to the principle of Information-Maximization (InfoMax)

A widely used principle in machine learning and neuroscience is the idea that to learn good latent representations we should try to maximize their mutual information with the data. The intuition is that if the latent variables contain large amounts of mutual information with the data, then they must presumably be good representations for it. Here we show how this principle relates to our definition of abstraction. Specifically, we show that this objective emerges naturally from simple maximum likelihood maximization under the assumption that the abstraction or statistical parameters is a deterministic function of the data, and thus mutual information maximization is an inseparable consequence of maximum likelihood estimation. Secondly, we show that this fact also naturally extends to our notion of abstraction, whereby optimizing our abstraction objective naturally tends to maximize the mutual information between the query and the abstraction distribution ­ thus ensuring that the abstraction vector stores as much information as possible about the query (but not the data) as possible. Finally, in the presence of latent variables, we show how this mutual information maximization objective results in the minimization the conditional mutual information between the latent variables and the data, given the deterministic parameters, reproducing classical results in coding and information theory showing that non-redundant (seemingly random) codes provide the greatest possible information, as well as their application into neuroscience by Barlow's principle of minimum redundancy (Barlow, 1961).

We begin with our reconstruction abstraction objective, which we have shown reduces to a maximum likelihood objective.

a = argmin Ep(D) DKL[p(x)||p~(x|a)]
a

= argmin Ep(D) ln p(x) - ln p~(x|a)

(36)

a

Where the double expectation under x disappears since the data expectation is an empirical distribution consisting solely of delta distributions around the observed data-points. Then, if we assume that the abstraction distribution is a

22

A PREPRINT - 4TH JUNE, 2021

deterministic function of the data, we can write this as,

a = argmin Ep(D)p(a|D) ln p(x) - ln p~(x|a)
a

= argmin - Ep(D)p(a|D) ln p~(x|a) - ln p(x)
a

= argmax DKL p(D, a)||p(D)p(a)
a

= argmax I[D, a]

(37)

a

Where we see that the objective directly corresponds to maximizing the mutual information between the data distribution

and the abstraction. This can be generalized straightforwardly to the case with an arbitrary query-set q as follows,

a = argmin Ep(q)p(D)DKL Q(x)||Q(m(a))
a

= argmin Ep(q)p(D)p(a|D) ln Q(x) - ln Q(m(a))
a

= argmin - Ep(q)p(D)p(a|D) ln p(q|a) - ln p(q|x)
a

= argmin - Ep(q,a,D) ln p(q|a) - ln p(q|x) + ln p(a|x) - ln p(a|x)
a

= argmax DKL p(q, a|x)||p(q|x)p(a|x)
a

= I[q, a|x]

(38)

Where we see that in the case of an arbitrary query, where the abstraction is simply a deterministic function of the data, we can see that minimizing the abstraction objective is equivalent to maximizing the mutual information of the query and abstraction, given the data.

Finally, returning to the case of the reconstruction query, supposing we no longer have the abstraction being a direct function of the data, but instead we take it to be an abstraction distribution p(a) which depends on a deterministic parameter  which is itself a deterministic function of the data. In probabilistic terms, this means that we can consider the abstractions a now as latent variables while the  are the parameters of the generative model. Thus, if we wish to maximize the mutual information between the data and the parameters, this mutual information can then be decomposed into two terms ­ the mutual information between the data and both the latent variables and the parameters, minus the mutual information between the latent variables and data, given the parameters.

I[x; ] = I[x; a, ] - I[a; x|]

(39)

Maximizing I[x; ] thus entails minimizing I[a; x|] which is the mutual information between the abstraction latent variables and the data, given the parameters. Effectively, minimizing this term reduces the `redundancy' of the data encoding ­ in that there is a minimum of information about the data left in the latent variables; all information has been taken over by the parameters. This makes sense in terms of coding ­ an ideal code would be highly non-redundant for which there is no predictable information between the latents and the data which is encoded in the latents since, by the tenets of information theory, that would mean a more efficient code could exist. This derivation thus ties the maximization of mutual information via maximum likelihood, and its generalization to arbitrary queries and abstraction to classical results in information theory and coding theory (Hamming, 1986; Shannon, 1948), as well as its extensions such as the minimum redundancy principle for neural systems (Barlow, 1961; Bell & Sejnowski, 1995).

9 Appendix D: Applications to Machine Learning
The immediate applications of our method to modern machine learning methods arise directly from the relationship of our notion of abstraction to classical statistical (maximum likelihood) learning discussed previously. Specifically, most machine learning systems can be considered as performing some kind of maximum likelihood inference, or related

23

A PREPRINT - 4TH JUNE, 2021
Bayesian or variational inference schemes. These can, in our framework, be interpreted as trying to learn abstractions under the reconstruction query Q(x) = p(x). The key suggestion our framework would make to the field of machine learning is a conceptual one: consider whether the reconstruction query is really the only query you are interested in learning about, whether you want abstractions that only try to reconstruct the data, or rather that can use other queries about the dataset. If the latter, then our method provides an immediate approach to do so. Our abstraction objective (Eq 8) is straightforwardly computable and can thus be optimized against the parameters of the abstraction function using automatic differentiation and gradient descent. The key additional idea arises in Eq 9 where we argue the true loss function to optimize against a query set is the average over all queries. This corresponds to a weighted sum of query functions, and thus in machine learning terminology, suggests that we should train machine learning models using a weighted sum of many loss functions simultaneously, where each loss function corresponds to a specific query. This approach of optimizing using a large number of loss functions simultaneously has not been widely explored in the literature and thus may have the potential to yield significant improvements with relatively little cost. Supporting evidence comes from the notion of regularization, which often adds additional penalty terms of various sorts to the loss function to discourage pathological behaviour (typically overfitting) of the optimizer when trained only upon a single loss function. This has been found to be highly beneficial in practice, and often careful regularisation and tuning is necessary to train many complex architectures successfully. From our perspective of abstraction, we argue that the key issue, which regularisation methods try to ameliorate, is that the neural networks are typically optimized only against a single loss function, or a single query. Conversely, we would argue that the real solution would be to figure out the precise query set that the network should be able to answer with its learned abstractions, and then optimize against the weighted sum of all the corresponding queries according to Equation 9. We can think of this as a sort of very high dimensional multi-objective optimization problem, which generalizes standard regularisation methods, and may yield substantially more robust and effective abstractions than are learnt by just optimizing a single loss function.
24

