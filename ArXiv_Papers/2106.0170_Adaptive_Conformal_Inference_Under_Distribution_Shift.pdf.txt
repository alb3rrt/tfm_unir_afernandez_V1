Adaptive Conformal Inference Under Distribution Shift

arXiv:2106.00170v1 [stat.ME] 1 Jun 2021

Isaac Gibbs Department of Statistics
Stanford University igibbs@stanford.edu

Emmanuel J. Candès Department of Statistics Department of Mathematics
Stanford University candes@stanford.edu

Abstract
We develop methods for forming prediction sets in an online setting where the data generating distribution is allowed to vary over time in an unknown fashion. Our framework builds on ideas from conformal inference to provide a general wrapper that can be combined with any black box method that produces point predictions of the unseen label or estimated quantiles of its distribution. While previous conformal inference methods rely on the assumption that the data points are exchangeable, our adaptive approach provably achieves the desired long-term coverage frequency irrespective of the true data generating process. We accomplish this by modelling the distribution shift as a learning problem in a single parameter whose optimal value is varying over time and must be continuously re-estimated. We test our method, adaptive conformal inference, on two real world datasets and find that its predictions are robust to visible and significant distribution shifts.
1 Introduction
Machine learning algorithms are increasingly being employed in high stakes decision making processes. For instance, deep neural networks are currently being used in self-driving cars to detect nearby objects [2] and parole decisions are being made with the assistance of complex models that combine over a hundred features [1]. As the popularity of black box methods and the cost of making wrong decisions grow it is crucial that we develop tools to quantify the uncertainty of their predictions.
In this paper we develop methods for constructing prediction sets that are guaranteed to contain the target label with high probability. We focus specifically on an online learning setting in which we observe covariate-response pairs {(Xt, Yt)}tN  Rd × R in a sequential fashion. At each time step t  N we are tasked with using the previously observed data {(Xr, Yr)}1rt-1 along with the new covariates, Xt, to form a prediction set C^t for Yt. Then, given a target coverage level   (0, 1) our generic goal is to guarantee that Yt belongs to C^t at least 100(1 - )% of the time.
Perhaps the most powerful and flexible tools for solving this problem come from conformal inference [see e.g. 30, 15, 28, 19, 27, 14, 3] . This framework provides a generic methodology for transforming the outputs of any black box prediction algorithm into a prediction set. The generality of this approach has facilitated the development of a large suite of conformal methods, each specialized to a specific prediction problem of interest [e.g. 26, 11, 20, 8, 21, 18]. Common to all of these methods is the guarantee that if the data are exchangeable, then the prediction set has valid marginal coverage P(Yt  C^t) = 1 - .
While exchangeability is a common assumption, there are many real-world applications in which we do not expect the marginal distribution of (Xt, Yt) to be stationary. For example, in finance and economics market behaviour can shift drastically in response to new legislation or major world
Preprint. Under review.

events. Alternatively, the distribution of (Xt, Yt) may change as we deploy our prediction method in new environments. This paper develops adaptive conformal inference (ACI), a method for forming prediction sets that are robust to changes in the marginal distribution of the data. Our approach is both simple, in that it requires only the tracking of a single parameter that models the shift, and general as it can be combined with any modern machine learning algorithm that produces point predictions or estimated quantiles for the response. We show that over long time intervals ACI achieves the desired target coverage frequency without any assumptions on the data-generating distribution. Moreover, when the distribution shift is small and the prediction algorithm takes a certain simple form we show that ACI will additionally obtain approximate marginal coverage at most time steps.

1.1 Conformal inference

Suppose we are given a fitted regression model for predicting the value of Y from X. Let y  R be a candidate value for Yt. To determine if y is a reasonable estimate of Yt, we define a conformity score S : Rd × R  R that measures how well the value y conforms with the predictions of our fitted model. For example, if our regression model produces points predictions µ^(X) then we could use a conformity score that measures the distance between µ^(Xt) and y. One such example is

S(Xt, y) = |µ^(Xt) - y|.

Alternatively, suppose our regression model produces estimates q^(X; p) of the pth quantile of the distribution of Y |X. Then we could use the method of conformal quantile regression (CQR) [25], which examines the signed distance between y and fitted upper and lower quantiles through the score

S(Xt, y) = max{q^(Xt; /2) - y, y - q^(Xt; 1 - /2)}.

Regardless of what conformity score is chosen the key issue is to determine how small S(Xt, y) should be in order to accept y as a reasonable prediction for Yt. Assume we have a calibration set Dcal  {(Xr, Yr)}1rt-1 that is different from the data that was used to fit the regression model. Using this calibration set we define the fitted quantiles of the conformity scores to be





Q^(p)

:=

inf

 s


:

1 |Dcal|

1{S (Xr ,Yr )s}
(Xr ,Yr )Dcal



 p,


(1)

and say that y is a reasonable prediction for Yt if S(Xt, y)  Q^(1 - ).
The crucial observation is that if the data Dcal  {(Xt, Yt)} are exchangeable and we break ties uniformly at random then the rank of S(Xt, Yt) amongst the points {S(Xr, Yr)}(Xr,Yr)Dcal  {S(Xt, Yt)} will be uniform. Therefore,

P(S(Xt, Yt)  Q^(1 - )) =

|Dcal|(1 - ) . |Dcal| + 1

Thus, defining our prediction set to be C^t := {y : S(Xt, y)  Q^(1 - )} gives the marginal coverage guarantee

P(Yt  C^t) = P(S(Xt, Yt)  Q^(1 - )) =

|Dcal|(1 - ) . |Dcal| + 1

By introducing additional randomization this generic procedure can be altered slightly to produce a set C^t that satisfies the exact marginal coverage guarantee P(Yt  C^t) = 1 -  [30]. For the purposes of this paper this adjustment is not critical and so we omit the details here. Additionally, we

remark that the method outlined above is often referred to as split or inductive conformal inference

[24, 30, 23]. This refers to the fact that we have split the observed data between a training set used to

fit the regression model and a withheld calibration set. The adaptive conformal inference method

developed in this paper can also be easily adjusted to work with full conformal inference in which

data splitting is avoided at the cost of greater computational resources [30].

2 Adapting conformal inference to distribution shifts
Up until this point we have been working with a single score function S(·) and quantile function Q^(·). In the general case where the distribution of the data is shifting over time both these functions should

2

be regularly re-estimated to align with the most recent observations. Therefore, we assume that at each time t we are given a fitted score function St(·) and corresponding quantile function Q^t(·). We define the realized miscoverage rate of the prediction set C^t() := {y : St(Xt, y)  Q^t(1 - )} as
Mt() := P(St(Xt, Yt) > Q^t(1 - )),
where the probability is over the test point (Xt, Yt) as well as the data used to fit St(·) and Q^t(·).
Now, since the distribution generating the data is non-stationary we do not expect Mt() to be equal or even close to . Even so, we may still postulate that if the conformity scores used to fit Q^t(·) cover the bulk of the distribution of St(Xt, Yt) then there may be an alternative value t  [0, 1] such that Mt(t) = . More rigorously, assume that with probability one, Q^t(·) is continuous, non-decreasing and such that Q^t(0) = - and Q^t(1) = . This does not hold for the split conformal quantile functions defined in (1), but in the case where there are no ties amongst the conformity scores we can adjust our definition to guarantee this by smoothing over the jump discontinuities in Q^(·). Then, Mt(·) will be non-decreasing on [0, 1] with Mt(0) = 0 and Mt(1) = 1 and so we may define
t := sup{  [0, 1] : Mt()  }.
Moreover, if we additionally assume that

P(St(Xt, Yt) = Q^t(1 - t)) = 0,
then we will have that Mt(t) = . So, in particular we find that by correctly calibrating the argument to Q^t(·) we can achieve either approximate or exact marginal coverage.
To perform this calibration we will use a simple online update. This update proceeds by examining the empirical miscoverage frequency of the previous prediction sets and then decreasing (resp. increasing) our estimate of t if the prediction sets were historically under-covering (resp. over-covering) Yt. In particular, let 1 denote our initial estimate (in our experiments we will choose 1 = ). Recursively define the sequence of miscoverage events

errt :=

1, if Yt / C^t(t), 0, otherwise,

where C^t(t) := {y : St(Xt, y)  Q^t(t)}.

Then, fixing a step size parameter  > 0 we consider the simple online update

t+1 := t + ( - errt).

(2)

We refer to this algorithm as adaptive conformal inference. Here, errt plays the role of our estimate of the historical miscoverage frequency. A natural alternative to this is to consider the update

t

t+1 = t +   - wserrs ,

(3)

s=1

where {ws}1st  [0, 1] is a sequence of increasing weights with

t s=1

ws

=

1.

This

update

has

the appeal of more directly evaluating the recent empirical miscoverage frequency when deciding

whether or not to lower or raise t. In practice, we find that (2) and (3) produce almost identical

results. For example, in Section A.2 in the Appendix we show some sample trajectories for t

obtained using the update (3) with

ws :=

0.95t-s

t s

=1 0.95t-s

.

We find that these trajectories are very similar to those produced by (2). The main difference is that the trajectories obtained with (3) are smoother with less local variation in t. In the remainder of this article we will focus on (2) for simplicity.

2.1 Choosing the step size
The choice of  gives a tradeoff between adaptability and stability. While raising the value of  will make the method more adaptive to observed distribution shifts, it will also induce greater volatility in

3

the value of t. In practice, large fluctuations in t may be undesirable as it allows the method to oscillate between outputting small conservative and large anti-conservative prediction sets.
In Theorem 4.2 we give an upper bound on (Mt(t)-)2 that is optimized by choosing  proportional to |t+1 - t|. While not directly applicable in practice, this result supports the intuition that in environments with greater distributional shift the algorithm needs to be more adapatable and thus  should be chosen to be larger. In our experiments we will work with the value  = 0.005. This value was chosen because it was found to give relatively stable trajectories for t while still being sufficiently large as to allow t to adapt to observed shifts. In agreement with the general principles outlined above we found that larger values of  also successfully protect against distribution shifts, while taking  to be too small causes adaptive conformal inference to perform similar to non-adaptive methods that hold t =  constant across time.

2.2 Real data example: predicting market volatility

We apply ACI to the prediction of market volatility. Let {Pt}1tT denote a sequence of daily open prices for a stock. For all t  2, define the return Rt := (Pt - Pt-1)/Pt-1 and realized volatility Vt = Rt2. Our goal is to use the previously observed returns Xt := {Rs}1st-1 to form prediction sets for Yt := Vt. More sophisticated financial models might augment Xt with additional market covariates (available to the analyst at time t - 1). As the primary purpose of this section is to illustrate
adaptive conformal inference we work with only a simple model.

We start off by forming point predictions using a GARCH(1,1) model [4]. This model assumes that Rt = t t with 1, . . . , T taken to be i.i.d. N (0, 1) and t satisfying the recursive update
t2 =  + Vt-1 + t2-1.
This is a common model used for forecasting volatility in economics. In practice, shifting market dynamics can cause the predictions of this model to become inaccurate over large time periods. Thus, when forming point predictions we fit the model using only the last 1250 trading days (i.e. approximately 5 years) of market data. More precisely, for all times t > 1250 we fit the coefficients ^t, ^t, ^t as well as the sequence of variances {^st}1st-1 using only the data {Rr}t-1250r<t. Then, our point prediction for the realized volatility at time t is

(^tt)2 := ^t + ^tVt-1 + ^t(^tt-1)2.

To form prediction intervals we define the sequence of conformity scores

St

:=

|Vt

- (^tt)2| (^tt)2

and the corresponding quantile function

Q^t(p) := inf

1 x:
1250

t-1

1Srx  p .

r=t-1250

Then, our prediction set at time t is

C^t(t) :=

v

:

|v

- (^tt)2| (^tt)2



Q^t(t)

,

where {t} is initialized with 1250 =  = 0.1 and then updated recursively as in (2).

We compare this algorithm to a non-adaptive alternative that takes t =  fixed. To measure the performance of these methods across time we examine their local coverage frequencies defined as the average coverage rate over the most recent two years, i.e.

1

t+250

localCovt := 1 - 500

errr .

(4)

r=t-250+1

If the methods perform well then we expect the local coverage frequency to stay near the target value 1 -  across all time points.

4

Local Coverage Level Local Coverage Level

Adaptive Alpha Nvidia
0.95

Fixed Alpha

0.90

0.85

AMD

Baseline Coverage Bernoulli

BlackBerry
0.95

Fannie Mae

Bernoulli

0.90

0.85

2005

2010

2015

2020

2000

2005

2010

Time

2015

2020 2005

2010

2015

2020

Figure 1: The leftmost four panels show local coverage frequencies for adaptive conformal (blue) and a non-adaptive method that holds t =  fixed (red) for the prediction of stock market volatility. The coloured dotted lines mark the average coverage obtained across all time points, while the black line indicates the target level of 1 -  = 0.9. For a visual comparison the two rightmost panels show the value of the local coverage (4) in cases where {errt}1tT is an i.i.d. Bernoulli(0.1) sequence.

Daily open prices were obtained from publicly available datasets published by The Wall Street Journal. The realized local coverage frequencies for the non-adaptive and adaptive conformal methods on four different stocks are shown in Figure 1. These stocks were selected out of a total of 13 stocks that we examined because they showed a clear failure of the non-adaptive method. Adaptive conformal inference was found to perform well on all stocks that we tested (data not shown).

As

a

visual

aid,

the

rightmost

panel

of

Figure

1

shows

the

moving

average

1 500

t+250 r=t-250+1

Ir

for sequences {It}1tT that are i.i.d. Bernoulli(0.1). We see that the local coverage frequencies

obtained by adaptive conformal inference (blue lines) always stay within the variation that would be

expected from an i.i.d. Bernoulli sequence. On the other hand, the non-adaptive method undergoes

large excursions away from the target level of 1 -  = 0.9 (red lines). For example, in the bottom

middle panel we can see that the non-adaptive method fails to cover the realized volatility of Fannie

Mae during the 2008 financial crisis, while the adaptive method is robust to this event (see Figure 3

in the Appendix for a plot of the price of Fannie Mae over this time period).

3 Comparison to prior work
Prior work on conformal inference has considered two different types of distribution shift [29, 10]. In both cases the focus was on environments in which the calibration data is drawn i.i.d. from a single distribution P0, while the test point comes from a second distribution P1. In this setting Tibshirani et al. [29] showed that valid prediction sets can be obtained by re-weighting the calibration data using the likelihood ratio between P1 and P0. However, this requires the conditional distribution of Y |X to be constant between training and testing and the likelihood ratio P1(X)/P0(X) to be either known or very accurately estimated. On the other hand, Cauchois et al. [10] develop methods for forming prediction sets that are valid whenever P1 and P0 are close in f -divergence. Similar to our work they show that if Df (P1||P0)   then there exists a conservative value   (0, 1) such that
M () := P(S(Xt, Yt) > Q^(1 - ))  .
The difference between our work and theirs is twofold. First, while they fix a single conservative value  our methods aim to estimate the optimal choice  satisfying M () = . This is not possible in the setting of [10] as they do not observe any data from which the size of the distribution shift can be estimated. Second, while they consider only one training and one testing distribution we work in a fully online setting in which the distribution is allowed to shift continuously over time.

5

4 Coverage guarantees

4.1 General results
In this section we outline the theoretical coverage guarantees of adaptive conformal inference. We will assume throughout that with probability one 1  [0, 1] and Q^t is non-decreasing with Q^t(x) = - for all x < 0 and Q^t(x) =  for all x > 1. Our first result shows that over long time intervals adaptive conformal inference obtains the correct coverage frequency irrespective of any assumptions on the data-generating distribution.

Lemma 4.1 With probability one we have that t  N, t  [-, 1 + ].

Proof: Assume by contradiction that with positive probability {t}tN is such that inft t < - (the case where supt t > 1 +  is identical). Note that supt |t+1 - t| = supt | - errt| < . Thus, with positive probability we may find t  N such that t < 0 and t+1 < t. However,
t < 0 = Q^t(t) =  = errt = 0 = t+1 = t + ( - errt)  t
and thus P(t such that t+1 < t < 0) = 0. We have reached a contradiction.

Proposition 4.1 With probability one we have that for all T  N,

1 T

T

errt - 



max{1, 1 - 1} +  . T

(5)

t=1

In

particular,

limT 

1 T

T t=1

errt

a=.s.

.

Proof: By expanding the recursion defined in (2) and applying Lemma 4.1 we find that

T
[-, 1 + ] T +1 = 1 + ( - errt).
t=1

Rearranging this gives the result.

Proposition 4.1 makes no assumptions about the data generating distribution. One may immediately ask whether these results can be improved by making mild assumptions on the distribution shifts. We argue that without assumptions on the quality of the initialization the answer to this question is negative. To understand this, consider a very simple example in which Mt(p) = p for all p  [0, 1]. Assume for simplicity that E[errt|t] = Mt(t).1 Then,

E[errt] -  = E[t - ] = E[t-1 + ( - errt-1) - ] = (1 - )E[errt-1 - ].

Repeating this calculation recursively gives that

E[errt] = (1 - )t-1E[err1 - ] = (1 - )t-1(1 - ),

and thus,

1T

1 - T

T E[errt] -  = T  |1 - |.

t=1

The comparison of this bound to (5) is self-evident. The main difference is that we have replaced max{1 - 1, 1} with |1 - |. This arises from the fact that in this example, choosing t =  gives well-calibrated prediction sets. In a more general version of this construction we would need to replace  by the target   [0, 1]. As this value is unknown we can view max{1, 1 - 1} as an upper bound on |1 - |. Thus, we view Proposition 4.1 as both an agnostic guarantee that shows that our method gives the correct long-term empirical coverage frequency irrespective of
the true data-generating process, and as an approximately tight bound on the worst-case behaviour
immediately after initialization.

1In general this will not be the case unless Q^t(·) and St(·) are computed on different subsets of the data.

6

4.2 Performance in a hidden Markov model

Although we believe Proposition 4.1 to be an approximately tight characterization of the behaviour after initialization, we can still ask whether better bounds can be obtained for large time steps. In this section we answer this question positively by showing that if 1 is initialized appropriately and the distribution shift is small then tighter coverage guarantees can be given. In order to obtain useful results we will make some simplifying assumptions about the data generating process. While we do not expect these assumptions to hold exactly in any real-world setting, we do consider our results to be representative of the true behaviour of adaptive conformal inference and we expect similar results to hold under alternative models.

4.2.1 Setting
We model the data as coming from a hidden Markov model. In particular, we let {At}tN  A denote the underlying Markov chain for the environment and we assume that conditional on {At}tN, {(Xt, Yt)}tN is an independent sequence with (Xt, Yt)  PAt for some collection of distributions {Pa : a  A}. In order to simplify our calculations, we assume additionally that the estimated quantile function Q^t(·) and score function St(·) do not depend t and we denote them by Q^(·) and S(·). This occurs for example in the split conformal setting with fixed training and calibration sets.
In this setting, {(t, At)}tN forms a Markov chain on [-, 1 + ] × A. We assume that this chain has a unique stationary distribution  and that (1, A1)  . This implies that (t, At, errt) is a stationary process and thus will greatly simplify our characterization of the behaviour of errt. While there is little doubt that the theory can be extended, recall our main goal to get useful and simple results. That said, what we really have in mind here is that {At}tN is sufficiently well-behaved to guarantee that (t, At) has a limiting stationary distribution. In Section A.3 we give an example where this is indeed provably the case. Lastly, the assumption that (1, A1)   is essentially equivalent to assuming that we have been running the algorithm for long enough to exit the initialization phase described in Section 4.1.

4.2.2 Large deviation bound for the errors

Our first observation is that errt has the correct average value. More precisely, by Proposition 4.1

we have that limT  T -1

T t=1

errt

a=.s.



and

since

errt

is

stationary

it

follows

that

E[errt]

=

.

Thus, to understand the deviation between T -1

T t=1

errt

and



we

simply

need

to

characterize

the

dependence structure of {errt}tN.

We accomplish this in Theorem 4.1, which gives a large deviation bound on |T -1

T t=1

errt

-

|.

The idea behind this result is to decompose the dependence in {errt}tN into two parts. First, there is

dependence due to the fact that t is a function of {errr}1rt-1. In Section A.5 in the Appendix

we argue that this dependence induces a negative correlation and thus the errors concentrate around

their expectation at a rate no slower than that of an i.i.d. Bernoulli sequence. This gives rise to the

first term in (6), which is what would be obtained by applying Hoeffding's inequality to an i.i.d.

sequence. Second, there is dependence due to the fact that At depends on At-1. More specifically,

consider a setting in which the distribution of Y |X has more variability in some states than others.

The goal of adaptive conformal inference is to adapt to the level of variability and thus return larger

prediction sets in states where the distribution of Y |X is more spread. However, this algorithm is

not perfect and as a result there may be some states a  A in which E[errt|At = a] is biased away

from . Furthermore, if the environment tends to spend long stretches of time in more variable (or

less variable) states this will induce a positive dependence in the errors and cause T -1

T t=1

errt

to deviate from . To control this dependence we use a Bernstein inequality for Markov chains to

bound |T -1

T t=1

E[errt|At]

-

|.

This

gives

rise

to

the

second

term

in

(6).

Theorem 4.1 Assume that {At}tN has non-zero absolute spectral gap 1 -  > 0. Let B := sup |E[errt|At = a] - | and B2 = E[(E[errt|At] - )2].
aA

Then,

1T

T2

T (1 - ) 2

P T errt -  
t=1

 2 exp - 8

+ 2 exp - 8(1 + )B2 + 40B .

(6)

7

A formal proof of this result can be found in Section A.5. The quality of this concentration inequality will depend critically on the size of the bias terms B and B2 . To understand these quantities, let
Ma(p) := P(S(Xt, Yt) > Q^(1 - p)|At = a)
denote the realized miscoverage level in state a  A obtained by the quantile Q^(1 - p). Assume that Ma(p) is continuous. This will happen for example when Q^ is continuous and S(Xt, Yt)|At = a is continuously distributed. Then, there exists an optimal value a such that Ma(a) = . Lemma A.4 in the Appendix shows that if in addition Ma admits a second order Taylor expansion, then

B  C  + -1 sup sup E[|A t+1 - A t | At+k = a]
aA kN

and B2  B2.

Here, the constant C will depend on how much Ma differs from the ideal case in which Q^ is the true quantile function for S(Xt, Yt)|At = a. In this case we would have that Ma is the linear function Ma(p) = p, p  [0, 1] and C  2.

We remark that the term E[|A t+1 - A t | At+k = a] can be seen as a quantitative measurement of the size of the distribution shift in terms of a change in the critical value a. Thus, we interpret these results as showing that if the distribution shift is small and a  A, Q^(·) gives reasonable coverage

of the distribution of S(Xt, Yt)|At = a, then T -1

T t=1

errt

will

concentrate

well

around

.

4.2.3 Achieving approximate marginal coverage

Theorem 4.1 bounds the distance between the average miscoverage rate and the target level over long stretches of time. On the other hand, it provides no information about the marginal coverage frequency at a single time step. The following result shows that if the distribution shift is small, the realized marginal coverage rate MAt (t) will be close to  on average.

Theorem 4.2 Assume that there exists a constant L > 0 such that for all a  A and all 1, 2  R,

|Ma(2) - Ma(1)|  L|2 - 1|.

Assume additionally that for all a  A there exists a  (0, 1) such that Ma(a) = . Then,

E[(MAt (t)

-

)2]



L(1 + 

) E[|A t+1

-

A t |] +

L .
2

(7)

Proof of this result can be found in Section A.6 of the Appendix. We remark that the right-hand side of (7) is minimized by choosing  = (2E[|A t+1 - A t |])1/2. This choice of  gives the inequality
 E[(MAt (t) - )2]  L( 2 + 1) E[|A t+1 - A t |].
As above we have that in the ideal case Q^(·) is a perfect estimate of the quantiles of S(Xt, Yt)|At = a and thus Ma(p) = p and L = 1. Moreover, we once again have the interpretation that E[|A t+1 - A t |] is a quantitative measurement of the distribution shift. Thus, this result can be interpreted as bounding the average difference between the realized and target marginal coverage in terms of the size of the underlying distribution shift. Finally, note that the choice of  = (2E[|A t+1 - A t |])1/2 formalizes our intuition that  should be chosen to be larger in domains with greater distribution shift, while not being so large as to cause t to be overly volatile.

5 Real data example: election night predictions

During the 2020 presidential election The Washington Post used conformalized quantile regression (CQR) (see (1) and Section 1.1) to produce county level predictions of the vote total on election night [12]. Here we replicate the core elements of this method using both fixed and adaptive quantiles.
To make the setting precise, let {Yt}1tT denote the number of votes cast for Joe Biden in the 2020 presidential election in each of approximately T = 3000 counties in the United States. Let Xt denote a set of demographic covariates associated to the tth county. In our experiments Xt will

8

Adaptive Alpha Fixed Alpha 0.95  = 0

 = 3. 74e-6

 = 3. 745e-6

 = Infinity

Local Coverage Level

0.90

0.85

0.80 500 1000 1500 2000 2500

500 1000 1500 2000 2500
Time

500 1000 1500 2000 2500

500 1000 1500 2000 2500

Figure 2: Local coverage frequencies of adaptive conformal (blue) and a non-adaptive method that holds t =  fixed (red) on county-level election predictions. Coloured dotted lines show the average coverage across all time points, while the black line indicates the target coverage level of 1 -  = 0.9. Note that here  =  corresponds to ordering the counties exactly by their population size. In our experiments we examined a wider range of values for . We have chosen to display results from these four values because they demonstrate a clear transition (in terms of coverage) between the exchangeable case and the perfectly ordered case.

include information on the make-up of the county population by ethnicity, age, sex, median income and education (see Section A.4.1 for details). On election night county vote totals were observed as soon as the vote count was completed. If the order in which vote counts were completed was uniformly random {(Xt, Yt)}1tT would be an exchangeable sequence on which we could run standard conformal inference methods. In reality, larger urban counties tend to report results later than smaller rural counties and counties on the east coast reported earlier than those on the west coast. Thus, the distribution of (Xt, Yt) can be viewed as drifting throughout election night.
We apply CQR to predict the county-level vote totals (see Section A.4.2 for details). We consider four different orderings of the counties each obtained by sampling counties without replacement with probability proportional to exp( · county population size). Here,  > 0 is a parameter whose value we vary. Figure 2 shows the realized local coverage frequency over the most recent 300 counties (see (4)) for the non-adaptive and adaptive conformal methods. When  = 0 (leftmost panel) the county data are exchangeable and both the non-adaptive and adaptive method perform well. As  increases (right panels) the size of the distribution shift increases and the non-adaptive method fails to achieve 90% coverage for later counties. On the other hand, the adaptive method adjusts accordingly and maintains an approximate 90% local coverage rate across all time points. In fact, similar to what was observed in Section 2.2 we find that the maximum deviation of the local coverage rate from 90% is no larger than what is observed in the ideal case where the data are exchangeable.
6 Discussion
There are still many open problems in this area. The methods we develop are specific to cases where Yt is revealed at each time point. However, there are many settings in which we receive the response in a delayed fashion or in large batches. In addition, our theoretical results in Section 4.2 are limited to a single model for the data generating distribution and the special case where the quantile function Q^(·) is fixed across time. It would be interesting to determine if similar results can be obtained in settings where Q^(·) is fit in an online fashion on the most recent data. Another potential area for improvement is in the choice of the step size . In Section 2.1 we give some heuristic guidelines for choosing  based on the size of the distribution shift in the environment. Ideally however we would like to be able to choose  adaptively without prior knowledge. Finally, our experimental results are limited to just two domains. Additional work is needed to determine if our methods can successfully protect against a wider variety of real-world distribution shifts.
9

7 Acknowledgements
E.C. was supported by Office of Naval Research grant N00014-20-12157, by the National Science Foundation grants OAC 1934578 and DMS 2032014, by the Army Research Office (ARO) under grant W911NF-17-1-0304, and by the Simons Foundation under award 814641. We thank John Cherian for valuable discussions related to Presidential Election Night 2020.

References

[1] Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. Machine bias:

There's software used across the country to predict future criminals. and it's bi-

ased against blacks, 2016.

URL https://www.propublica.org/article/

machine-bias-risk-assessments-in-criminal-sentencing.

[2] Claudine Badue, Rânik Guidolini, Raphael Vivacqua Carneiro, Pedro Azevedo, Vinicius B. Cardoso, Avelino Forechi, Luan Jesus, Rodrigo Berriel, Thiago M. Paixão, Filipe Mutz, Lucas de Paula Veronese, Thiago Oliveira-Santos, and Alberto F. De Souza. Self-driving cars: A survey. Expert Systems with Applications, 165:113816, 2021. ISSN 0957-4174. doi: https: //doi.org/10.1016/j.eswa.2020.113816. URL https://www.sciencedirect.com/science/ article/pii/S095741742030628X.

[3] Rina Foygel Barber, Emmanuel J. Candès, Aaditya Ramdas, and Ryan J. Tibshirani. Predictive inference with the jackknife+. The Annals of Statistics, 49(1):486 ­ 507, 2021. doi: 10.1214/ 20-AOS1965. URL https://doi.org/10.1214/20-AOS1965.

[4] Tim Bollerslev. Generalized autoregressive conditional heteroskedasticity. Journal of Econometrics, 31(3):307­327, 1986. ISSN 0304-4076. doi: https://doi.org/10.1016/ 0304-4076(86)90063-1. URL https://www.sciencedirect.com/science/article/ pii/0304407686900631.

[5] United States Census Bureau. County characteristics resident population estimates, 2019. data retrieved from https://www.census.gov/data/tables/time-series/demo/popest/ 2010s-counties-detail.html.

[6] United States Census Bureau. 2015-2019 american community survey 5-year average countylevel estimates, 2019. data retrieved from https://www.ers.usda.gov/data-products/ county-level-data-sets/download-data/.

[7] United States Census Bureau. Small area income and poverty estimates: 2019,

2019.

data retrieved from https://www.ers.usda.gov/data-products/

county-level-data-sets/download-data/.

[8] Emmanuel J. Candès, Lihua Lei, and Zhimei Ren. Conformalized survival analysis, 2021.

[9] X. Cao, J. Zhang, and H. V. Poor. On the time-varying distributions of online stochastic optimization. In 2019 American Control Conference (ACC), pages 1494­1500, 2019. doi: 10.23919/ACC.2019.8814889.

[10] Maxime Cauchois, Suyash Gupta, Alnur Ali, and John C. Duchi. Robust validation: Confident predictions even when distributions shift, 2020.

[11] Maxime Cauchois, Suyash Gupta, and John C. Duchi. Knowing what you know: valid and validated confidence sets in multiclass and multilabel prediction. Journal of Machine Learning Research, 22(81):1­42, 2021. URL http://jmlr.org/papers/v22/20-753.html.

[12] John Cherian and Lenny Bronner. How the washington post estimates outstanding votes for the 2020 presidential election. https://elex-models-prod.s3.amazonaws.com/ 2020-general/write-up/election_model_writeup.pdf, 2020.

[13] MIT Election Data and Science Lab. County Presidential Election Returns 2000-2016, 2018. URL https://doi.org/10.7910/DVN/VOQCHQ.

[14] Rina Foygel Barber, Emmanuel J Candès, Aaditya Ramdas, and Ryan J Tibshirani. The limits of distribution-free conditional predictive inference. Information and Inference: A Journal of the IMA, 08 2020. ISSN 2049-8772. doi: 10.1093/imaiai/iaaa017. URL https: //doi.org/10.1093/imaiai/iaaa017. iaaa017.

10

[15] Alexander Gammerman and Vladimir Vovk. Hedging predictions in machine learning. The Computer Journal, 50(2):151­163, 2007. doi: 10.1093/comjnl/bxl065.
[16] Wassily Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American Statistical Association, 58(301):13­30, 1963. doi: 10.1080/01621459.1963. 10500830.
[17] Bai Jiang, Qiang Sun, and Jianqing Fan. Bernstein's inequality for general markov chains, 2020.
[18] Danijel Kivaranovic, Robin Ristl, Martin Posch, and Hannes Leeb. Conformal prediction intervals for the individual treatment effect, 2020.
[19] Jing Lei and Larry Wasserman. Distribution-free prediction bands for non-parametric regression. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 76, 01 2014. doi: 10.1111/rssb.12021.
[20] Jing Lei, Max G'Sell, Alessandro Rinaldo, Ryan J. Tibshirani, and Larry Wasserman. Distribution-free predictive inference for regression. Journal of the American Statistical Association, 113(523):1094­1111, 2018. doi: 10.1080/01621459.2017.1307116. URL https://doi.org/10.1080/01621459.2017.1307116.
[21] Lihua Lei and Emmanuel J. Candès. Conformal inference of counterfactuals and individual treatment effects, 2021.
[22] David Leip. Dave leip's atlas of u.s. presidential elections., 2020. http://uselectionatlas. org.
[23] Harris Papadopoulos. Inductive conformal prediction: Theory and application to neural networks. In Tools in Artificial Intelligence,, pages 315­330, 2008.
[24] Harris Papadopoulos, Kostas Proedrou, Volodya Vovk, and Alex Gammerman. Inductive confidence machines for regression. In Tapio Elomaa, Heikki Mannila, and Hannu Toivonen, editors, Machine Learning: ECML 2002, pages 345­356, Berlin, Heidelberg, 2002. Springer Berlin Heidelberg. ISBN 978-3-540-36755-0.
[25] Yaniv Romano, Evan Patterson, and Emmanuel Candes. Conformalized quantile regression. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/ 5103c3584b063c431bd1268e9b5e76fb-Paper.pdf.
[26] Yaniv Romano, Matteo Sesia, and Emmanuel Candes. Classification with valid and adaptive coverage. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 3581­3591. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/ file/244edd7e85dc81602b7615cd705545f5-Paper.pdf.
[27] Mauricio Sadinle, Jing Lei, and Larry Wasserman. Least ambiguous set-valued classifiers with bounded error levels. Journal of the American Statistical Association, 114(525):223­234, 2019. doi: 10.1080/01621459.2017.1395341. URL https://doi.org/10.1080/01621459.2017. 1395341.
[28] Glenn Shafer and Vladimir Vovk. A tutorial on conformal prediction. Journal of Machine Learning Research, 9(12):371­421, 2008. URL http://jmlr.org/papers/v9/shafer08a. html.
[29] Ryan J Tibshirani, Rina Foygel Barber, Emmanuel Candes, and Aaditya Ramdas. Conformal prediction under covariate shift. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/ file/8fb21ee7a2207526da55a679f0332de2-Paper.pdf.
[30] Vladimir Vovk, Alex Gammerman, and Glenn Shafer. Algorithmic Learning in a Random World. Springer-Verlag, Berlin, Heidelberg, 2005. ISBN 0387001522.
[31] Jingyi Zhu and James Spall. Tracking capability of stochastic gradient algorithm with constant gain. In 2016 IEEE 55th Conference on Decision and Control (CDC), pages 4522­4527, 12 2016. doi: 10.1109/CDC.2016.7798957.
11

A Appendix
A.1 Stock prices Figure 3 shows stock prices for the four stocks considered in Section 2.2.

Open Price

Nvidia
600
400
200

AMD
100 50

0
150 BlackBerry
100
50

0
Fannie Mae
75
50
25

0 2000

2005

2010

2015

0 2020
Time

2000

2010

2020

Figure 3: Daily open prices for the four stocks considered in Section 2.2.

Open Price

A.2 Trajectories of t
In this section we show the realized trajectories of t obtained in our experiments from Sections 2.2 and 5.

Nvidia
0.15

AMD

t

0.10

0.05
BlackBerry
0.15

Fannie Mae

t

0.10

0.05

2005

2010

2015

2020
Time

2000

2005

2010

2015

2020

Figure 4: Realized trajectories of t for predicting stock market volatility as outlined in Section 2.2 using update (2).

12

Nvidia
0.15

AMD

t

0.10

0.05
BlackBerry
0.15

Fannie Mae

t

0.10

0.05

2005

2010

2015

2020
Time

2000

2005

2010

2015

2020

Figure 5: Realized trajectories of t for predicting stock market volatility as outlined in Section 2.2 using update (3) with ws  0.95t-s.

 = 0
0.125

 = 3. 74e-6

 = 3. 745e-6

 = Infinity

0.100

t

0.075

0.050

0.025

500 1000 1500 2000 2500

500 1000 1500 2000 2500
Time

500 1000 1500 2000 2500

500 1000 1500 2000 2500

Figure 6: Realized trajectories of t for election night forecasting as outlined in Section 5 using update (2). Note that here  =  corresponds to ordering counties exactly by their population size. In our experiments we examined a wider range of values for . We have chosen to display results from these four values because they demonstrate a clear transition (in terms of coverage) between the exchangeable case and the perfectly ordered case.

13

 = 0
0.125

 = 3. 74e-6

 = 3. 745e-6

 = Infinity

0.100

t

0.075

0.050

0.025

500 1000 1500 2000 2500

500 1000 1500 2000 2500
Time

500 1000 1500 2000 2500

500 1000 1500 2000 2500

Figure 7: Realized trajectories of t for election night forecasting as outlined in Section 5 using update (3) with ws  0.95t-s. Note that here  =  corresponds to ordering counties exactly by their population size. In our experiments we examined a wider range of values for . We have chosen to display results from these four values because they demonstrate a clear transition (in terms of coverage) between the exchangeable case and the perfectly ordered case.

A.3 Existence of a stationary distribution for (t, At)

In this section we give one simple example in which the Markov chain {(t, At)}tN will have a unique stationary distribution. The setting considered here is the same as the one described in Section
4.2.

Let t be initialized with 1  { + k : k  Z}. Assume that A is finite. Let P be the transition
matrix of {At}tN and assume that for all a1, a2  A, Pa1,a2 = P(At+1 = a2|At = a1) > 0. Assume that  satisfies -1(1 - )  N. This will hold for common choices of  such as  = 0.1 and  = 0.05. Finally, assume that for all a  A and all p  (0, 1), P(S(Xt, Yt)  Q^(p)|A = a)  (0, 1). This will occur for example when S(Xt, Yt)|At = a is supported on R and Q^ is finite valued
for all p  (0, 1).

We claim that in this case {(t, At)}tN has a unique stationary distribution. To prove this it is sufficient to show that this chain is irreducible and has a finite state space. To check that it has a finite state space it is sufficient to show that t has a finite state space. We claim that with probability one we have that for all t  N, t  { + k : k  Z}. To prove this we proceed by induction. The base case is given by our choice of 1. For the inductive step note that
t  { + k : k  Z}

= t+1 = t + ( - errt) =

t + , if errt = 0, t - (-1(1 - )), if errt = 1,

 { + k : k  Z}.

Since t is also bounded (see Lemma 4.1) this implies that t has a finite state space.

Finally, the fact that {(t, At)}tN is irreducible follows easily from our assumptions on {At}tN, Q^, and P(S(Xt, Yt)  Q^(p)|A = a).

A.4 Additional information for Section 5
A.4.1 Dataset description
The county-level demographic characteristics used for prediction were the proportion of the total population that fell into each of the following race categories (either alone or in combination): black or African American, American Indian or Alaska Native, Asian, Native Hawaiian or other Pacific islander. In addition to this, we also used the proportion of the total population that was male, of Hispanic origin and that fell within each of the age ranges 20-29, 30-44, 45-64, and 65+.

14

Demographic information was obtained from 2019 estimates published by the United States Census Bureau and available at [5]. In addition to these demographic features we also used the median household income and the percentage of individuals with a bachelors degree or higher as covariates. Data on county-level median household incomes was based on 2019 estimates obtained from [7]. The percentage of individuals with a bachelors degree or higher was computed based on data collected during the years 2015-2019 and published at [6]. As an aside, we remark that we used 2019 estimates because this was the most recent year for which data was available.
Vote counts for the 2016 election were obtained from [13], while 2020 election data was taken from [22]. In total, matching covariate and election vote count data were obtained for 3111 counties.
A.4.2 Detailed prediction algorithm
Algorithm 1 below outlines the core conformal inference method used to predict election results.

Algorithm 1: CQR method for election night prediction

Data: Observed sequence of county-level votes counts and covariates {(Xt, Yt)}1tT and vote counts for the democratic candidate in the previous election {Ytprev}1tT .
for t = 1, 2, . . . , T do Compute the residual rt = (Yt - Ytprev)/Ytprev
for t = 501, 502, . . . , T do
// We start making predictions once 500 counties have been observed. Randomly split the data {(Xl, rl)}1lt-1 into a training set Dtrain and a calibration set Dcal with |Dtrain| = (t - 1) · 0.75 ; Fit a linear quantile regression model q^(x; p) on Dtrain; for (Xl, rl)  Dcal do
Compute the conformity score Sl = max{q^(Xl; /2) - rl, rl - q^(Xl; 1 - /2)};

Define the quantile function Q^t(p) = inf

x

:

1 |Dcal |

1 (Xl,rl)Dcal Slx  p ;

Return the prediction set

C^t()

:=

{y

:

max{q^(Xt; /2)

-

, y-Ytprev
Ytprev

y-Ytprev Ytprev

-

q^(Xt; 1

-

/2)}



Q^t(1

-

)};

A.5 Large deviation bounds for the error sequence

In this section we prove Theorem 4.1. So, throughout this section we define the sequences {t}tN, {errt}tN, and {At}tN as in Section 4.2 and we assume that {(t, At)}tN is a stationary Markov chain from which it follows immediately that {(t, At, errt)}tN is also stationary. Finally, we assume throughout that Q^(·) and S(·) are fixed functions such that Q^(·) is non-decreasing with Q^(x) = - for all x < 0 and Q^(x) =  for all x > 1. The proof of Theorem 4.1 will rely on the following lemmas.
Lemma A.1 Let f : Rn  R and g : Rn  R be such that either
1. f is non-increasing and g is non-decreasing in each of its arguments,
2. or f is non-decreasing and g is non-increasing in each of its arguments.

Then, for any random variables Y1, . . . , Yn, E[f (Y1, . . . , Yn)g(Y1, . . . , Yn)]  E[f (Y1, . . . , Yn)]E[g(Y1, . . . , Yn)].

The proof of this result is straightforward and can be found in Section A.8.

Lemma A.2 For any   R and t  N we have that

t

t-1

E exp((errs - E[errs|As]))  exp(2/2)E exp((errs - E[errs|As])) . (8)

s=1

s=1

15

Proof: By conditioning on 1 and A1, . . . , At on both the left and right-hand side of (8) we may view these quantities as fixed. For ease of notation in the calculations that follow we do note denote this conditioning explicitly, but it should be understood that 1 and A1, . . . , At are fixed. Then,

t

E exp((errs - E[errs|As]))

s=1

t-1

= E exp((errs - E[errs|As]))E exp((errt - E[errt|At])) err1, . . . , errt-1 .

s=1

Recall that t = 1 + 

t-1 s=1

(

-

errs)

is

a

deterministic

function

of

1,

err1,

.

.

.

,

errt-1.

So,

we

may define the functions f (err1, . . . , errt-1) =

t-1 s=1

exp((errs

-

E[errs|As]))

and

g(err1, . . . , errt-1) = E [exp((errt - E[errt|At]))|err1, . . . , errt-1]

= PAt (S(Xt, Yt)  Q^(1 - t)) exp(-E[errt|At])

+ (1 - PAt (S(Xt, Yt)  Q^(1 - t)) exp((1 - E[errt|At])),
where on the last line At and t should be viewed as fixed quantities. Now, since t is monotonically decreasing in (err1, . . . , errt-1) it should be clear that if   0 then g is non-increasing (resp. non-decreasing for  < 0) in each of its arguments. So, by Lemma A.1 we have that

t-1

E exp((errs - E[errs|As]))E exp((errt - E[errt|At])) err1, . . . , errt-1

s=1

t-1

 E exp((errs - E[errs|As])) E E exp((errt - E[errt|At])) err1, . . . , errt-1

s=1

t-1

= E exp((errs - E[errs|As])) E[exp((errt - E[errt|At]))]

s=1

t-1
 E exp((errs - E[errs|As])) exp(2/2),

s=1

where the last inequality follows by Hoeffding's lemma (see Lemma A.5).

The final result we will need in order to prove Theorem 4.1 is a large deviation bound for Markov chains.

Definition A.1 Let {Xi}iN  X be a Markov chain with transition kernel P and stationary distribution . Define the inner product space

with inner product For any h  L2(X , ), let

L2(X , ) = h : h(x)2(dx) < 
X
h1, h2  = h1(x)h2(x)(dx).
X
L2(X , ) P h := h(y)P (·, dy).

Then, we say that {Xi}iN has non-zero absolute spectral gap 1 -  if

 := sup

P h, P h  : h, h  = 1, h(x)(dx) = 0 < 1.
X

Theorem A.1 (Theorem 1 in [17]) Let {Xi}iN  X be a stationary Markov chain with invariant

distribution of functions

 and non-zero absolute spectral with (fi) = 0 and define 2 :=

gap 1 -  > 0.

n i=1

(fi2

)/n.

Let fi Then,

: X  [-C, for  > 0,

C]

be

a

sequence

1n P n fi(Xi) 
i=1

n(1 - ) 2/2  exp - (1 + )2 + 5C .

Finally, we are ready to prove Theorem 4.1.

16

Proof: [Proof of Theorem 4.1.] Write

1T

P T errt -  >

(9)

t=1

1T

1T

 P T errt - E[errt|At] > /2 + P T E[errt|At] -  > /2

(10)

t=1

t=1

By applying lemma A.2 inductively we have that for all  > 0,

1T

T

P T errt - E[errt|At] > /2  exp(-T  /2)E

exp((errt - E[errt|At]))

t=1

t=1

 exp(-T  /2) exp(T 2/2),

with an identical bound on the left tail. Choosing  = /2 gives the bound

P

1T T errt - E[errt|At] > /2

 2 exp(-T 2/8).

t=1

On the other hand, the second term in (10) can be bounded directly using Theorem A.1.

A.6 Approximate marginal coverage In this section we prove Theorem 4.2.

Proof: [Proof of Theorem 4.2] Our proof follows similar steps to those presented in previous works on stochastic gradient descent under distribution shift [9, 31]. First, note that

(t+1 - A t )2 = (t - A t )2 + 2( - errt)(t - A t ) + 2( - errt)2.

Now recalling that MAt (A t ) = , we find that

-E[( - errt)(t - A t )] = E[E[(errt - )(t - A t )|At, t]] = E[(MAt (t) - MAt (A t ))(t - A t )]



1 L

E[(MAt

(t)

-

MAt

(A t

))2]

=

1 L E[(MAt (t)

-

)2].

Thus it follows that

T

T

2L-1 E[(MAt (t) - )2]  E[(t - A t )2 - (t+1 - A t )2 + 2( - errt)2]

t=1

t=1

T



E[(t+1

-


At+1

)2

-

(t+1

-

A t )2]

+

E[(1

-

A 1 )2]

+

2T

t=1

T

=

E[2t+1(A t

-


At+1

)]

+

(A T +1 )2

+

E[(1

-

A 1 )2]

+

2T

t=1

T
 2(1 + )E[|A t+1 - A t |] + (A T +1 )2 + E[(1 - A 1 )2] + 2T,
t=1

where the last inequality follows from Lemma 4.1. So, re-arranging we get the inequality

1 T

T

E[(MAt (t) - )2]

t=1

L 
2T 

T
2(1 + )E[|A t+1 - A t |] + (A T +1 )2 + E[(1 - A 1 )2] + 2T .

t=1

17

Finally, since {(At, t)}tN is stationary we may let T   to get that

E[(MAt (t)

-

)2]



L(1 + 

) E[|A t+1

-

A t |]

+

L 2

as claimed.

A.7 Bounds on B and B2

In this section we bound the constants B and B2 appearing in the statement of Theorem 4.1. Let

1=

sup

sup E[|A T -k

-


AT -k-1

||AT

=

a]

k{0,1,2,... } aA

and 2 = sup sup E[(A T -k - A T -k-1 )2|AT = a].
k{0,1,2,... } aA

Then, our main result is Lemma A.4 which shows that

B  C( + -1( 1 + 2)) and B2  B2,

(11)

where the constant C depends on how close Ma is to the ideal linear function Ma(p) = p.

Plugging (11) into Theorem 4.1 gives a concentration inequality for |T -1

T t=1

errt

-

|.

We

now

provide some discussion as to how one should judge the size of this bound. In general, there are two

main regimes in which we expect |T -1

T t=1

errt

-

|

to

be

small:

1. Environments in which the state At changes frequently, but |A t+1 - A t | is always small. In this case it is reasonable to expect 1 -  to not be too small and so plugging (11) into
Theorem 4.1 will give a reasonable bound.

2. Environments in which the state changes very infrequently. In this case {At}tN will mix

slowly

and

so

we

expect

1-

to

be

quite

small.

Additionally,

we

also

have

that


At+1

=

A t

a large proportion of the time and thus B and B2 will also both be small. As a result, it

is not immediately clear what Theorem 4.1 tells us about |T -1

T t=1

errt

-

|.

Below

we

give one simple example that demonstrates that Theorem 4.1 can also be a reasonable bound

in this instance.

Example A.1 Let {At}tN be the Markov chain with n states and transition matrix

P=

1-p p-

I + 1 - p 11T .

n-1

n-1

where p  [0, 1] is taken to be very close to optimal choice of   1 - p we have that this chain has spectral gap 1 -  = 1 - p.

1. Then, we B  O( 1 So, we have

have that 1, 2  (1 - p). - p) and B2  O(1 - p). that the bound in Theorem

So, by taking the Finally, note that 4.1 simplifies to

1T P T errt -  
t=1

2

2

 2 exp -T 8

+ 2 exp -T O(1) + O(1) (1 - p)-1/2 .

The first term above is always well-controlled. For the second, term note that since p is close to 1 we have that when is small this term is comparable to

2 exp -O(1)T 1 - p = 2 exp (-O(1)T ) .

Thus, we find that T -1

T t=1

errt

concentrates

well

around



as

soon

as

T

  = 1 - p. The

dependence on T  is intuitively quite reasonable. In particular, note that  dictates the rate of

convergence of t to its optimal value A t . More explicitly, we expect t to contract towards A t at

rate (1 - ) and thus to have cumulative error

1 T

T

|t

-

A t |



1 T

T
(1 - )t-1 =

1 .

T

t=1

t=1

Thus, the appearance of the term T  in this upper bound is to be expected.

18

We now derive (11).

Lemma A.3 Assume that 0 < c < 1/(2) such that for all a  A and all p  [-, 1 + ],

|Ma(p) - Ma(a)|  c|p - a|. Then, for all a  A, k  {0, 1, 2, . . . }, and T  N

E[(1 - A 1 )2|A1+k = a]  (1 - 2c)T -1E[(1 - A 1 )2|AT +k = a]
T
+ (1 - 2c)T -t 2 + 2(1 + )E[|A t-1 - A t ||AT +k = a] + E[(A t-1 - A t )2|AT +k = a] .
t=2

Furthermore, if we assume that a  A and k  {0, 1, 2, . . . },

E[|A t-k

-


At-k-1

||At

=

a]



1

and

E[(A t-k

-


At-k-1

)2

|At

=

a]



2,

then we find that

E[(1

-

A 1 )2|A1+k

=

a]



1 2c

2 + 2(1 + ) 1 +

2

.

Proof: Fix any T  N. Since {(t, At)}tN is stationary we have that E[(1 - A 1 )2|A1+k] = E[(T - A T )2|AT +k].
Now note that E[(T - A T )2|AT +k] = E[(T - A T -1 )2|AT +k] + 2E[(T - A T -1 )(A T -1 - A T )|AT +k]
+ E[(A T -1 - A T )2|AT +k]  E[(T - A T -1 )2|AT +k] + 2(1 + )E[|A T -1 - A T ||AT +k]
+ E[(A T -1 - A T )2|AT +k],
where on the last line we have applied Lemma 4.1. The first term above can be bounded as E[(T - A T -1 )2|AT +k]  E[(T -1 - A T -1 )2|AT +k] + 2E[( - errT -1)(T -1 - A T -1 )|AT +k] + 2,
where we additionally have that E[( - errT )(T -1 - A T -1 )|AT +k] = E[( - E[errT -1|AT -1, T -1, AT +k])(T -1 - A T -1 )|AT +k] = E[(MAT -1 (A T -1 ) - MAT -1 (T -1))(T -1 - A T -1 )|AT +k]  -cE[(T -1 - A T -1 )2|AT +k].
Whence, E[(T - A T -1 )2|AT +k]  (1 - 2c)E[(T -1 - A T -1 )2|AT +k] + 2,
and plugging this into our first inequality yields E[(T - T )2|AT +k]  (1 - 2c)E[(T -1 - A T -1 )2|AT +k] + 2 + 2(1 + )E[|A T -1 - A T ||AT +k] + E[(A T -1 - A T )2|AT +k].
Repeating this argument inductively gives E[(T - A T )2|AT +k = a]  (1 - 2c)T -1E[(1 - A 1 )2|AT +k = a]
T
+ (1 - 2c)T -t 2 + 2(1 + )E[|A t-1 - A t ||AT +k = a] + E[(A t-1 - A t )2|AT +k = a] .
t=2
The final part of the lemma follows by sending T  .

19

Lemma A.4 Assume that for all a  A and p  [-, 1 + ], Ma admits the second order Taylor expansion
Ma(p) - Ma(a) = Ca1(p - a) + Cp2,a(p - a)2,
where 0 < c1  Ca1  C1 < 1/ and |Cp2,a|  C2. Then, for all T  N and a  A,

|E[err1|A1 = a] - |  C1(1 - c1)T -1E[|1 - A 1 ||AT = a]

T -1

+

C1C2(1 - c1)T -t-1E[(t - At )2|AT = a]

t=1

T -1

+

C1(1 - c1)T -t-1E[|A t+1 - A t ||AT ] + C2E[(T - A T )2|AT = a].

t=1

Furthermore, suppose that the assumptions of Lemma A.3 hold and that a  A and k  {0, 1, 2, . . . },

E[|A T -k - A T -k-1 ||AT = a] 

1

and E[(A T -k

-


AT -k-1

)2|AT

=

a]



2.

Then a  A,

|E[err1|A1 = a] - | 

1 C1C2 c1 + C2

1 (2 2c

+ 2(1 +

)

1

+

2)

+

C1 c1

1.

Proof: Fix any T  N. Since {(errt, At)}tN is stationary we have that
E[err1|A1 = a] = E[errT |AT = a].
Then, by Taylor expanding MAT we find that |E[errT |AT = a] - | = E[MAT (T ) - MAT (A T )|AT ]  E[CA1 T (T - A T )|AT ] + E[C2T ,AT (T - A T )2|AT ]  E[CA1 T (T - A T )|AT ] + C2E[(T - A T )2|AT ].
The first term above can be further bounded as E[CA1 T (T - A T )|AT ] = E[CA1 T (T -1 + ( - errT -1) - A T -1 )|AT ] + E[CA1 T (A T -1 - A T )|AT ]
 E[CA1 T (T -1 - A T -1 )] + E[CA1 T (MAT -1 (A T -1 ) - MAT -1 (T -1))|AT ] + C1E[|A T -1 - A T ||AT ]
= E[CA1 T (1 - CA1 T -1 )(T -1 - A T -1 )|AT ] + C1C2E[(T -1 - A T -1 )2|AT ] + C1E[|A T -1 - A T ||AT ].
The desired result follows by repeating this process inductively. Finally, the last part of the Lemma follows by sending T   and applying the result of Lemma A.3.

As a final aside we remark that in the main text we claimed that in the ideal case where Ma(p) = p for all p  [0, 1] this bound can be replaced by
|E[err1|A1 = a] - |  2( + -1 1). This can be justified by using the fact that in this case we have that for all p  [-, 1 + ]
Ma(p) - Ma(a) = (p - a) + Cp2,a with |Cp2,a|  . The desired result then follows by repeating the argument of Lemma A.4.
20

A.8 Technical lemmas

Proof: [Proof of Lemma A.1:] We assume without loss of generality that f is non-decreasing and g is non-increasing in each of its arguments as otherwise one can simply multiply both f and g by -1. We proceed by induction on n. Let n = 1. Let gU := sup{g(y) : f (y) > E[f (Y1)] and gL := inf{g(y) : f (y)  E[f (Y1)]. By the monotonicity of f and g we clearly have that gL  gU . Therefore,
E[f (Y1)g(Y1)] - E[f (Y1)]E[g(Y1)] = E[(f (Y1) - E[f (Y1)])g(Y1)]
 E[(f (Y1) - E[f (Y1)])gL1f(Y1)E[f(Y1)]] + E[(f (Y1) - E[f (Y1)])gU 1f(Y1)>E[f(Y1)]]  E[(f (Y1) - E[f (Y1)])gL1f(Y1)E[f(Y1)]] + E[(f (Y1) - E[f (Y1)])gL1f(Y1)>E[f(Y1)]]
= 0,
which proves the base case. For the inductive step, write
E[f (Y1, . . . , Yn)g(Y1, . . . , Yn)] = E[E[f (Y1, . . . , Yn)g(Y1, . . . , Yn)|Y1, . . . , Yn-1]]  E[E[f (Y1, . . . , Yn)|Y1, . . . , Yn-1]E[g(Y1, . . . , Yn)|Y1, . . . , Yn-1]] = E[f~(Y1, . . . , Yn-1)g~(Y1, . . . , Yn-1)],
where f~(Y1, . . . , Yn-1) := E[f (Y1, . . . , Yn)|Y1, . . . , Yn-1] g~(Y1, . . . , Yn-1) := E[g(Y1, . . . , Yn)|Y1, . . . , Yn-1].
Now, it is easy to verify that f~ and g~ are non-decreasing and non-increasing, respectively, in their arguments and so by applying the induction hypothesis we find that
E[f~(Y1, . . . , Yn-1)g~(Y1, . . . , Yn-1)]  E[f~(Y1, . . . , Yn-1)]E[g~(Y1, . . . , Yn-1)] = E[f (Y1, . . . , Yn)]E[g(Y1, . . . , Yn)]
as desired.

Lemma A.5 [Hoeffding's Lemma [16]] Let X be a mean 0 random variable such that X  [a, b] almost surely. Then, for all   R

E[exp(X)]  exp

2 (b - a)2 8

.

21

