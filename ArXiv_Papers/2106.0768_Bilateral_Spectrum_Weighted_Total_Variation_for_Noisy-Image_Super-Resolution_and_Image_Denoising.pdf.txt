1
Bilateral Spectrum Weighted Total Variation for Noisy-Image Super-Resolution and Image Denoising
Kaicong Sun, Sven Simon

arXiv:2106.00768v3 [eess.IV] 5 Jun 2021

Abstract--In this paper, we propose a regularization technique for noisy-image super-resolution and image denoising. Total variation (TV) regularization is adopted in many image processing applications to preserve the local smoothness. However, TV prior is prone to oversmoothness, staircasing effect, and contrast losses. Nonlocal TV (NLTV) mitigates the contrast losses by adaptively weighting the smoothness based on the similarity measure of image patches. Although it suppresses the noise effectively in the flat regions, it might leave residual noise surrounding the edges especially when the image is not oversmoothed. To address this problem, we propose the bilateral spectrum weighted total variation (BSWTV). Specially, we apply a locally adaptive shrink coefficient to the image gradients and employ the eigenvalues of the covariance matrix of the weighted image gradients to effectively refine the weighting map and suppress the residual noise. In conjunction with the data fidelity term derived from a mixed Poisson­Gaussian noise model, the objective function is decomposed and solved by the alternating direction method of multipliers (ADMM) algorithm. In order to remove outliers and facilitate the convergence stability, the weighting map is smoothed by a Gaussian filter with an iteratively decreased kernel width and updated in a momentum-based manner in each ADMM iteration. We benchmark our method with the state-of-the-art approaches on the public real-world datasets for super-resolution and image denoising. Experiments show that the proposed method obtains outstanding performance for superresolution and achieves promising results for denoising on realworld images.
Index Terms--Super-resolution, denoising, total variation, mixed Poisson-Gaussian noise, ADMM, computed tomography.
I. INTRODUCTION
S uper-resolution (SR) and image denoising are both fundamental and challenging image processing tasks. Superresolution is an image enhancement technique dedicated to improving the image spatial resolution and image denoising is an image restoration task aiming to recover the underlying clean image from the noisy counterpart. In many applications, such as medical diagnostics, remote sensing, surveillance, and astronomy, due to the inherent limitation of imaging systems and imaging conditions, SR and denoising are usually required to boost the image quality and the visual perception. Generally, imaging system can be formulated as y = Ax +  where A represents the system matrix, x denotes the latent image and  indicates an additive noise. We have a multi-frame SR problem as A = DBM [1], [2] where matrices D, B, M describes respectively downsampling, blurring, and motion
K. Sun and S. Simon are with the Department of Parallel Systems, Institute of Parallel and Distributed Systems, University of Stuttgart, 70569, Stuttgart, Germany (e-mail: kaicong.sun@ipvs.uni-stuttgart.de; sven.simon@ipvs.unistuttgart.de). This work was supported by the Federal Ministry of Education and Research (BMBF, Germany) under the grand No. 105M18VSA.

effects and a denoising problem when A being an identity matrix. Due to their severe ill-posedness, image prior plays an essential role to regularize the solution domain. Over the last decades, fruitful study of image priors has been conducted, including approaches based on nonlocal self-similarity [3]­ [5], image gradient [6]­[8], sparsity [9], [10]. In recent years, we have witnessed the great success of deep learning and the learning-based methods [11]­[15] benefit significantly from the massive amount of the training data. However, the learningbased methods usually suffer from two major drawbacks. First, the performance of the deep learning approaches highly relies on the training datasets. In practice, it might be difficult to prepare synthetic datasets which adequately resemble the real-world measurements covering diverse imaging conditions. Even for unsupervised learning which do not require groundtruth, assembling enough measurements for training might also be challenging. Second, although networks are able to describe more sophisticated image priors, the functions generated by the networks are uninterpretable. Especially, the existence of undesirable artifacts is unpredictable which may encumber the employment of the learning-based approaches in applications such as geometric dimensioning and non-destructive testing.
In this work, inspired by the nonlocal TV (NLTV) [8], we intend to smooth the image in the flat regions and meanwhile maintain the sharpness at edges by applying a locally adaptive weighting map to the total variation. Different from the NLTV, our bilateral spectrum weighted total variation (BSWTV) shrinks the mask of the edges in the weighting map explicitly such that it suppresses the residual noise surrounding the edges effectively without compromising the sharpness. The contribution of this work is summarized as follows:
· We propose a regularization technique for effectively suppressing the noise and meanwhile preserving the sharpness of fine structures. Particularly, a shrink coefficient is introduced to adaptively weight the image gradient and the weighting map of TV is estimated based on the spectrum of the weighted-gradient covariance matrix.
· Combining the proposed BSWTV with the data fidelity term derived from a mixed Poisson-Gaussian noise model, the overall objective function is solved based on the ADMM algorithm where the update of the weighting map is integrated as the first step in the ADMM framework. In order to remove outliers and facilitate the convergence stability, the weighting map is smoothed by a Gaussian filter with an iteratively decreased kernel width and updated in a momentum-based fashion.
· We benchmark our approach with the state-of-the-art

2

methods on the public real-world datasets for superresolution and image denoising. The proposed method shows promising performance on the real-world images.

II. RELATED WORK
In last decades, there has been intensive investigation on SR [7], [13], [15]­[22] and image denoising [3]­[6], [8], [14], [23]­[27]. Due to the ill-posedness of the problems, the existing methods employ either explicitly handcrafted image priors or implicit priors. Specially, the majority of the optimization-based traditional methods exploit the handcrafted priors. Rudin et al. [6] introduce the total variation (TV) as the regularization for image denoising. In [7], bilateral total variation (BTV) is proposed by concerning photometric and geometric distance in an extended neighborhood for multiframe SR. Yuan et al. [17] propose a regional spatially adaptive total variation (RSATV) for SR based on spatial information filtering and clustering which partition the image into multiple segments. However, pixels within each segment are limited to an equal weight.
Besides the above gradient-based priors, nonlocal-means (NL-means) [3] based on the self-similarity exploits the natural redundancy of image patterns aiming to average the pixels which are surrounded by similar textures. Specially, the NLmeans algorithm is formulated as

x(i) = w(i, j)x(j),

(1)

jRi

where x(i) is the estimated image pixel. Weight w(i, j) depicts
the similarity between pixel i and j with j w(i, j) = 1, j  Ri where Ri denotes the search window of pixel i. The weight w(i, j) is measured by

w(i, j)

=

1

||N (i)

exp(-

Z (i)

- N (j)||22, 2

).

(2)

N (i), N (j) indicate respectively the square neighborhood of pixel i and j. ||N (i) - N (j)||22, is the weighted Euclidean distance with  being the standard deviation of the Gaussian

kernel. Z(i) denotes the normalizing constant with Z(i) =

j

exp(-

||N

(i)-N 2

(j)||22,

)

and



being

the

constant

filtering

parameter. In [28], the authors combine the NL-means with

the TV regularization with the purpose of exploring both the

redundant and the smooth properties of images to overcome

the drawbacks of oversmoothness and inefficient denoising.

BM3D [5] is another discriminative denoising method based

on self-similarity which groups similar patches and performs

collaborative filtering by shrinkage in the 3D transform do-

main.

To overcome the performance decline caused by contrast

losses, Gilboa et al. [8] propose a variational regularization,

nonlocal TV (NLTV), based on the self-similarity which can

be formulated as

Vc(x) =

||D(SD - I)x||1,

(3)

D=(Dx,Dy )

where (Dx, Dy) indicates the shift vector with Dx, Dy  [-(R - 1)/2, (R - 1)/2] and R is the window size. Matrix

SD acts as the shift operator and D represents the weighting map associated with the shift vector D defined as

D (i,

j)

=

exp(-

||N

(i,

j)

-

N

(i + 2

Dx,

j

+

Dy )||22

).

(4)

N (i, j) denotes the neighbors of the center pixel (i, j) in the similarity patch of size r and  is the filtering parameter which controls the smoothness. An advantage of NLTV over NLmeans is that we can easily plug the regularization technique into different image processing tasks. However, NLTV usually suffers from the drawback that it is prone to residual noise in the surroundings of the edges especially when the image is not oversmoothed.
In recent years, learning-based methods have achieved great success in many applications. Most of the work takes advantage of learning features and implicit image priors from external datasets [13]­[15], [20]­[22], [27], [29]­[31]. Particularly, Dong et al. [13] introduce a convolutional neural network (CNN) for single-frame SR. Afterwards, a series of work [15], [20], [21] has achieved noticeable performance. Lim et al. [21] propose a deep and compact residual network EDSR by effectively removing unnecessary modules in the conventional residual networks. In [32], the authors propose an iterative network structure for super-resolving noisy images contaminated by an additive white Gaussian noise (AWGN). In the literature of SR and imaging denoising, most of the models are derived based on the assumption that the images are corrupted by the AWGN. However, in reality, the composition of noise in imaging systems is more sophisticated. There are mainly two sources of noise dominating in digital imaging process: the intensity-independent readout noise and reset noise which can be modeled as an additive Gaussian noise and the intensity-dependent photon shot noise which obeys a Poisson distribution [33], [34]. To the best of our knowledge, despite the importance of adopting an accurate noise description in the imaging model, the literature on SR and image denoising based on a mixed Poisson­Gaussian noise model is limited [18], [35]­[37].
In this paper, we address the drawback of the NLTV and propose a generalized algorithm coping with mixed PoissonGaussian noise for real-world noisy-image super-resolution and image denoising.

III. METHODS
A. Bilateral Spectrum Weighted Total Variation
TV performs smoothing based on the image gradients without concerning the features such that it is prone to oversmoothness, staircasing effect, and contrast losses. In order to alleviate the contrast losses, inspired by [38], we employ the information entailed in the gradient covariance matrix to locate features such as edges. Generally, flat regions and edges can be distinguished by the spectrum of the gradient covariance matrix [39]. For images contaminated by a mixed Poisson­ Gaussian noise, according to Proposition III.1, no matter if it has a white Gaussian component, we can formulate the gradients in the flat regions by a white isotropic Gaussian distribution with a limited variance which theoretically enables us to differentiate the mixed noise in flat areas from the edges.

3

Proposition III.1. Let us define an observed digital image y : N20  R contaminated by a mixed Poisson­Gaussian noise as y = z + np(z) + ng where (zi + np(zi))/  P (zi/) with
zi being the expected pixel value and  being a scalar. ng is an independent additive Gaussian noise with ng(i)  N (µi, i2). If we have a homogeneous region   N20, where i, j  , |zi+µi-zj -µj| < 1, |zi+i2-zj -j2| < 2, 1, 2 > 0, then the gradient of each element i in  has the same isotropic
white Gaussian distribution xy(i), yy(i)  N (0, (zi + i2)/2) and a collection of the gradients obeys an isotropic white Gaussian distribution. (See Appendix A for a proof)

In order to efficiently suppress the noise in flat regions and meanwhile preserve the fine structures, we propose a novel regularizer BSWTV as formulated in Eq. (5). BSWTV possesses the merit that it enables a refinement of the weighting map by introducing an inhomogeneous shrink coefficient.
BSW T V (x) := ||x||1,  = diag[1, · · · , n] (5)

a) HR image

b) weighting map

c) ROI

Fig. 1. Impact of the decay parameter  on the SR performance (2×). Top:  = 1, PSNR = 30.35dB, SSIM = 0.8577; Bottom:  = 0.8, PSNR = 30.47dB, SSIM = 0.8607.

The ith diagonal element of the weighting map  is defined

as

i = exp(-|i1 - i2|/2),

(6)

where  is the smoothing parameter which controls the dynamic range of  and i1, i2 are the eigenvalues of the covariance matrix of the bilateral weighted gradients Gi which is formulated as

Gi =

1gx1, . . . , j gxj , . . . , qgxq 1gy1, . . . , j gyj , . . . , qgyq

, j = jd(i,j)

with

jk

= jk-1( +

(1 - ) 1 + expf (N k-j 1) ),

j  Ni.

(7)

gj represents the gradient at pixel j and is expressed as gj := (gxj , gyj ) = (xxj, yxj). The square patch centered at pixel i has the amount of q = r2 pixels and is defined as Ni = {j : |i - j|  (r - 1)/2} with r being the odd size of the patch. j acts as the weight assigned to each individual neighbor in Ni and indicates the significance of the neighbor j to the center pixel i which depends on the distance d(i, j) := |dx(i, j)|+|dy(i, j)| along x and y axis with dx, dy  [-(r - 1)/2, (r - 1)/2] and the local adaptive shrink coefficient j. The superscript of jk depicts the kth iteration of the ADMM algorithm and the decay scalar   [0, 1] serves
for the shrinkage of the spread of the gradients within the patch. The intuition of introducing  and  is to adaptively "squeeze" the gradient matrix G such that the discrepancy between eigenvalues i1 and i2 decreases as the algorithm converges and the mask of the edges in the weighting map  becomes thinned. Nj denotes the neighbors of pixel j in the weighting map . f is a function of Nj which controls the whitening based on the image content and enables an inhomogeneous decay of . Specially, for flat regions, f is
supposed to be a large positive value such that the shrink coefficient j is decreased by  and the weighting map gets further whitened, while for fine structures, f should be a large negative value so that the shrink coefficient j is not attenuated. A simple choice of f (x) could be an affine function

f (x) := a(x¯ - b) where x¯ denotes the mean of vector x and the positive scalars a, b are the amplitude and shift parameters, respectively. Hence, based on the previous , map  is inhomogeneously shrinked by factors in the range of (, 1). In Fig. 1, we illustrate the effectiveness of leveraging the decay parameter . The top row illustrates the weighting map  and the SR image without decaying the shrink coefficient. The bottom row exhibits the results with  = 0.8. As we can see, the weighting map  in the bottom row has much thinned mask for edges than the counterpart in the top row under the same smoothing parameter . Consequently, the SR image has much cleaner and pleasant contours without oversmoothing the fine structures. We demonstrate a detailed analysis of the effectiveness of the decay scalar , the smoothing parameter , and the shift parameter b on the reconstruction performance in Section V-E.
The update of the weighting map  is embedded in the ADMM framework as described in Algorithm 2 in Section IV-C. For the sake of suppressing the outliers and enhancing the convergence stability in the ADMM update scheme, the weighting map  calculated by Eqs. (6) and (7) is followed by a Gaussian filter with an iteratively decreased kernel width and updated in a momentum-based fashion in each ADMM iteration. A detailed description of the update of the weighting map  is given in Section IV-B.

B. Super-Resolution and Image Denoising Based on BSWTV
In digital imaging systems as mentioned in Section II, the intensity-dependent photon shot noise arises from the stochastic nature of the photon-counting process and can be modeled as a Poisson noise. Meanwhile, Gaussian noise exists due to the intrinsic thermal and electronic fluctuations in the sensors [35]. Therefore, the imaging system is formulated based on a mixed Poisson-Gaussian noise model as following:

yi = zi + np(zi) + ng,

(8)

where yi stands for the intensity value at the ith pixel of the observed image y which is contaminated by a mixed Poisson­

4

Gaussian noise. zi indicates the clean pixel value. np(zi) is an intensity-dependent noise with (zi + np(zi))/  P (zi/) where  is a scalar accounting for quantum efficiency and analog gain [40]. ng represents an additive Gaussian noise with ng  N (µi, i2). np(zi) describes mostly photon shot noise and ng embodies mainly readout noise and reset noise. In fact, there are other noises existing in the complementary
metal-oxide-semiconductor (CMOS) or charge-coupled device
(CCD) detectors such as the Poissonian dark current shot noise which is negligible for exposure time less than 1s and the
quantization noise which is uniformly distributed and can be
omitted compared to the readout noise except in very low-
illumination conditions [34]. Without loss of generality, we define A = DBM being the system matrix as described in Section I and x = [x1, . . . , xN ] being the vectorized latent image with z = Ax.
Assuming that np and ng are mutually independent, we yield the mean and the variance of the intensity of pixel i as

E (yi) = E (zi + np) + E (ng) = [A]ix + µi Var (yi) = Var (zi + np) + Var (ng) = [A]ix + i2,

(9)

where [A]i indicates the ith row of matrix A and x represents the expected image. It should be noted that in this paper, the degradation matrix A, the scalar  and the Gaussian noise parameters µi and i are assumed to be known. According to the Central Limit Theorem (CLT), we have P (zi/) N (zi/, zi/) as zi/ being sufficiently large. Hence, the observed value yi can be approximated by a Gaussian distribution. Based on Eq. (9), we yield yi  N ([A]ix+µi, [A]ix+i2). Therefore, the probability mass function (PMF) of yi conditioned on the expected image x is expressed as

P (yi|x) =

1 2([A]ix

+

i2)

exp

-(yi - [A]ix - µi)2 2([A]ix + i2)

.

(10)

According to Bayes' theorem, we have the associated negative log-likelihood formulated as

n

- log P (y|x) = - log P (yi|x)

i=1

1 =
2

y - Ax - µ

2 W

+

log (Ax

+

2), 1

(11) + c,

where log(·) is an elementwise operation, ·, · indicates the inner product and c is a constant. For the sake of brevity, we will omit the constant c in the latter formulation. The intensitydependent diagonal weight matrix W is expressed as

1

W = diag{ [A]ix + i2 }.

(12)

Specially, for image denoising we set A = I and for singleframe SR, we can formulate A = DB. With regard to multiframe SR, instead of having one observed low-resolution (LR) image y, there are m LR images yi with the individual system matrix Ai and additive noise ni. Assuming the LR images are

independent, we can extend the formulation for single-frame input expressed in Eq. (11) as below:

m

- log P (y1, . . . , ym|x) = - log P (yi|x)

1m =
2
i=1

i=1

yi - Aix - µi

2 Wi

+

log (iAix

+

i2), 1

.

(13)

In the rest of the paper, we formulate the data fidelity term in general by Eq. (13). Denoising and single-frame SR are considered as the special cases with m = 1.
Combining the regularization term expressed in Eq. (5) with the data fidelity term formulated in Eq. (13), we yield the overall objective function as

1m J=
2
i=1

yi - Aix - µi

+ ||x||1,

2 Wi

+

log (iAix

+

i2), 1

(14)

with  being the weight of the regularization term. Due to the fact that the data fidelity term is derived from a mixed Poisson­Gaussian noise model, we name the above algorithm as MPG+BSWTV.

IV. OPTIMIZATION METHOD

A. Decomposition and ADMM

Considering the complexity of the algorithm, the objective function J in Eq. (14) can be decomposed into subfunctions such that the reformulated optimization problem can be attacked by means of constrained optimization, e.g., dual ascent and ADMM. Dual ascent is based on the Lagrangian and usually has inferior convergence properties, while ADMM benefits from the augmented Lagrangian and improves the convergence [41]. In this paper, we utilize the ADMM algorithm to solve the decomposed objective function. Particularly, we adopt the anisotropic TV in the implementation: ||x||1 = ||(Sx -I)x||1 +||(Sy -I)x||1 where matrices Sx, Sy perform respectively the shift operation along x and y axis by one pixel. Therefore, the overall optimization problem can be split into m + 2 subproblems with the corresponding constraints as

m+2

arg min J = gi(zi)

x,zi

i=1

(15)

subject to Tix - zi = 0, i  [1, m + 2]

with zi  RN and Ti being a matrix:



IN×N , 

i  [1, m],

Ti = (Sx - IN×N ), i = m + 1,

(16)

(Sy - IN×N ), i = m + 2.

5

Specially, gi(·) is defined as following:

1 gi(zi) := 2

||yi - Aizi - µi||2Wi +

log(iAizi + i2), 1

i  [1, m],

the convergence of the primal residual rki and the dual residual ski with the scheme in [41]:

,

 c1 

ki

,

||rki ||2 > c||ski ||2,

ki +1 = ki /c2, ||ski ||2 > c||rki ||2,

(23)

gi(zi) := ||zi||1, i  [m + 1, m + 2].

ki ,

otherwise,

(17) where c1, c2, c are constants with c1 > 1, c2 > 1, c > 1. The

The augmented Lagrangian is hence formulated as

primal and dual residuals rki , ski are calculated as

m+2

LH (x, z, p) = LHi (x, zi, pi)

i=1

(18)

m+2
=

gi(zi) +

pi, Tix - zi

+

1 2 ||Tix

-

zi||2Hi

,

i=1

where pi is the dual variable associated with the individual constraint and matrix Hi is defined as

Hi := diag[i, . . . , i], i  [1, · · · , m + 2] (19)

with i being a positive scalar acting as the update step size of the dual variable pi.
The decomposed objective function formulated in Eq. (15) is solved in the following iterative scheme:

xk+1

=

m+2

arg min

x

i=1

i 2

||Ti

x

-

zki

+

pki i

||22

zki +1

=

arg min gi(zi)
zi

+

i 2

||zi

-

Tixk+1

-

pki i

||22

pki +1 = pki + i(Tixk+1 - zki +1).

(20a)
(20b) (20c)

Since Eq. (20a) is quadratic and differentiable, the update of xk+1 can be achieved by, e.g., the conjugate gradient
(CG) algorithm. gi(zi) with i  [1, m] is nonconvex which
is solved by the scaled conjugate gradient (SCG). To update zki +1 associated with the BSWTV prior, i.e., i  [m+1, m+2], we utilize the proximal operator of the L1-norm:

rki +1 = Tixk+1 - zki +1 ski +1 = -ki TTi (zki +1 - zki ).

(24)

An early stopping criteria based on the primal and dual residuals is used as depicted in Algorithm 2.

B. Update of Weighting Map
The weighting map  is updated iteratively within the ADMM framework. In particular, in order to enhance the convergence stability and update efficiency, we perform two additional steps following Eqs. (6) and (7). Firstly, we smooth the weighting map  by convolving with an isotropic 2D Gaussian kernel G() to alleviate the effect of the outliers on the weighting map. Secondly, we update the smoothed weighting map in a momentum-based manner to avoid strong fluctuation in the objective function during convergence. Specially, the decay scalar  is employed to iteratively decrease the Gaussian parameter  and the momentum coefficient . The insight behind decaying the width of the Gaussian kernel is to silently remove the outliers in the weighting map by convolving with a relatively wide Gaussian kernel in the first ADMM iterations and along with the convergence of the objective function, the weighting map becomes less smoothed by leveraging a narrowed Gaussian filter. Consequently, the mask of the edges in the weighting map is thinned and sharpened in a moderate manner and the remaining noise surrounding the edges is effectively suppressed. The update framework of the weighting map  in the kth ADMM iteration is formulated as following in Algorithm 1.

Algorithm 1 Update of Weighting Map

zki +1

=

arg min
zi

||zi||1

+

i 2

||zi

-

Tixk

-

pki i

||22

(21)

=

prox(i)-1||·||1 (Tixk

+

pki i

)

and we can yield the closed-form solution as


[Tixk  

+

pki i

]j

-

 i

,





[zki +1]j = 0,



  [Tixk

+

pki i

]j

+

 i

,

[Tixk

+

pki i

]j



 ,
i

|[Tixk

+

pki i

]j

|



 ,
i

[Tixk

+

pki i

]j



 -.
i

(22)

In order to improve the convergence and reduce the dependency of the initialization in practice, the penalty parameter i is updated iteratively, for instance, by means of synchronizing

1: Initialize , , , , , r, , min.

2: procedure CALCULATING WEIGHTING MAP

3: Calculate k(k-1, k-1, )

by Eq. (7)

4: k  Calculate (xk-1, k, )

by Eq. (6)

5:

k = max(min, k-1)

6: k = G(k )  k

7: k = k-1.

8: k = kk-1 + (1 - k)k

C. Overall Optimization Framework
The core of the overall optimization is to integrate the update of the weighting map as described in Algorithm 1 into the ADMM framework. As the weighting map  is coupled with the latent image x as expressed in Eq. (20a) and is used for the update of the variables zi and pi for i  [m + 1, m + 2] as formulated in Eqs. (21), (20c), we

6

update  with x fixed and perform the update of  as the
first step in the ADMM iteration. The pseudocode for solving
the overall objective function is presented in Algorithm 2. As
depicted, in each ADMM iteration there are four main steps in
sequence to respectively update , x, z, and p. Specially, the
computational complexity for updating the weighting map  in each ADMM iteration is O(r2w2N ) with r2 being the patch size and w2 being the Gaussian kernel size. x is iteratively
solved by CG which has a computational complexity of O(kxN 2) with kx being the amount of iterations of CG. For solving zi with respect to the data term with i  [1, m], we employ the SCG which has the computational cost of O(mkzN 2) with kz being the number of iterations for SCG. For zi associated with the regularization term, we employ the proximal operator which has the complexity of O(N 2). The
last step is to solve the dual variables p. For pi with i  [1, m], Ti denotes the identity matrix and the computational cost is O(N ) and for i  [m + 1, m + 2], the update of pi has O(N 2) computational complexity. Hence, the overall computational complexity for each ADMM iteration is O((kx + mkz)N 2).

Algorithm 2 Proposed Algorithm

1: Initialize , , , , r, , , , , min, , iter, , c, c1, c2 2: Load observed images yi i  [1, · · · , m] 3: procedure SOLVING ADMM 4: z0i = y1 for denoising, Bicubic(y1) for SR, i  [1, m] 5: z0i = 0, i  [m + 1, m + 2] 6: p0i = 0, i  [1, m + 2] 7: x0 = 0

8: while k < iter do

9:

Update weighting map 

10:

CG(xk )

by Alg. 1 by Eq. (20a)

11:

for i = 1 to m + 2 do

12:

if i  [1, m] then

13:

SCG(zki )

by Eq. (20b)

14:

else

15:

Prox(zki )

by Eqs. (20b), (21), (22)

16:

Update ki

17:

Update pki

by Eqs. (23), (24) by Eq. (20c)

18:

if i(||rki -1||22 - ||rki ||22)/ i(||rki -1||22) < 1 and

i(||ski -1||22 - ||ski ||22)/ i(||ski -1||22) < 2 then

19:

break

20:

k = k+1

21: end while 22: return reconstructed image x.

V. EXPERIMENTS AND RESULTS
In this section, we conducted extensive experiments to evaluate our proposed method on the synthetic and the realworld images for both multi-frame SR and image denoising. We benchmark our approach with the state-of-the-art methods for SR and denoising on the real-world datasets SupER [42] and [43], respectively.

Fig. 2. 8-bit gray-scale natural images for quantitative analysis.
A. Super-Resolution on Synthetic Images
We evaluated the proposed MPG+BSWTV on the grayvalue reference images shown in Fig. 2. Specially, we assume the system matrix DBM is known and set the scalar  = 1. Accordingly, we generated four LR images for each reference image. Firstly, we rescaled the gray-value image to peak intensity 200 and considered as the GT image. The rescaled image was then shifted by (0, 0), (0.5, 0), (0.5, 0.5), and (0, 0.5) pixel to obtain four images. The four images were blurred by an isotropic 3×3 Gaussian kernel and then subsampled by a factor of 2. Each of the degraded LR images was corrupted by a mixed Poisson­Gaussian noise with peak intensity 200 and  = 2. We compared the proposed method with L1+BTV [7], L2+NLTV [8], MPGSR [18], L2+BSWTV, EDSR [21], RBPN [44], and DPSR [15]. Note that the notation L2+NLTV indicates the L2-norm data term in conjunction with NLTV as the regularizer and the same notation manner is employed for L1+BTV and L2+BSWTV. To achieve a fair comparision, all the above TV-based methods were implemented by the ADMM algorithm. For a better interpretation, MPGSR is denoted as MPG+BTV in this paper. EDSR and DPSR are CNN-based single-frame SR methods and RBPN is one of the state-of-the-art video SR (VSR) networks which uses multiple LR frames as input. Since EDSR and RBPN are originally trained on noiseless images, we retrained EDSR and RBPN using the original code on the datasets which were contaminated by the mixed Poisson­Gaussian noise with the same noise level as the testing images. For all the investigated methods, the parameters which generated the best PSNR performance were adopted. We demonstrate the reconstructed image PPT3 by the investigated approaches in Fig. 3. It is shown that our MPG+BSWTV provides a remarkable improvement quantitatively and qualitatively by jointly enhancing the image resolution and suppressing the residual noise surrounding the characters. The VSR method RBPN generates better result than EDSR as expected by exploiting the information entailed in the neighboring frames. The DPSR tends to suppress the noise aggressively which leads to a degradation of the detailed structures. We summarize the quantitative comparison in Tab. I.
B. Super-Resolution on Real-World Images
1) SR Reconstruction on SupER Dataset: To validate the proposed method, we conducted experiments on the publicly

7

a-1) Bicubic (24.81dB, 0.6115)

b-1) L1+BTV (28.09dB, 0.9058)

c-1) MPG+BTV (28.72dB, 0.9336)

d-1) L2+NLTV (30.35dB, 0.9466)

e-1) L2+BSWTV (30.60dB, 0.9476)

f-1) EDSR (27.75dB, 0.9297)

g-1) RBPN (28.17dB, 0.9322)

h-1) DPSR (28.53dB, 0.9018)

i-1) MPG+BSWTV (31.03dB, 0.9537)

a-2) Bicubic

b-2) L1+BTV

c-2) MPG+BTV

d-2) L2+NLTV

e-2) L2+BSWTV

f-2) EDSR

g-2) RBPN

h-2) DPSR

i-2) MPG+BSWTV

Fig. 3. Comparison of different SR methods for 2× on PPT3 contaminated by a mixed Poisson­Gaussian noise with peak intensity 200 and  = 2: (a) bicubic, (b) L1+BTV, (c) MPGSR, (d) L2+NLTV, (e) L2+BSWTV, (f) EDSR, (g) RBPN, (h) DPSR, and (i) MPG+BSWTV.

TABLE I COMPARISON OF DIFFERENT SR METHODS FOR 2× UPSCALING UNDER A MIXED POISSON­GAUSSIAN NOISE WITH PEAK INTENSITY 200,  = 2 IN PSNR (dB) AND SSIM. BEST: BOLD; SECOND BEST: UNDERLINE. (ALL TV-BASED METHODS WERE IMPLEMENTED USING ADMM FRAMEWORK.)

Cameraman

Lena

Page

Comic

Face

PPT3

Zebra

Average

PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM

Bicubic

26.68

L1+BTV [7] 29.15

L2+NLTV [8] 29.96

MPG+BTV [18] 29.97

L2+BSWTV 30.24

EDSR [21]

28.69

RBPN [44]

29.22

DPSR [15]

29.08

MPG+BSWTV (ours) 30.49

0.6506 27.27 0.8412 29.20 0.8591 29.41 0.8571 29.84 0.8622 29.75 0.8404 28.84 0.8593 29.53 0.8404 28.72 0.8706 29.99

0.6934 22.80 0.8210 23.75 0.8277 25.69 0.8410 24.70 0.8387 26.07 0.8215 23.88 0.8458 24.67 0.8059 24.59 0.8516 26.26

0.5412 24.31 0.7420 25.96 0.8133 26.40 0.7864 26.39 0.8240 26.72 0.7560 24.97 0.7898 25.99 0.7218 25.18 0.8401 27.00

0.6921 31.12 0.7914 33.40 0.8196 33.36 0.8077 33.81 0.8305 33.67 0.7359 33.19 0.7995 34.00 0.7461 32.22 0.8360 34.04

0.7271 24.81 0.8143 28.09 0.8080 30.35 0.8248 28.72 0.8172 30.60 0.7956 27.75 0.8292 28.17 0.7652 28.53 0.8303 31.03

0.6115 27.04 0.9058 29.77 0.9466 30.07 0.9336 30.45 0.9476 30.42 0.9297 28.65 0.9322 29.54 0.9018 28.57 0.9537 30.77

0.7224 26.29 0.8064 28.47 0.8024 29.32 0.8222 29.13 0.8202 29.64 0.7683 28.00 0.8246 28.73 0.7729 28.13 0.8465 29.94

0.6626 0.8174 0.8395 0.8390 0.8486 0.8068 0.8401 0.7934 0.8613

PSNR (dB) Time (s)

32.0

NUISR

Ours

31.8

31.6

DBRSR WNUISR

31.4 31.2 31.0

L1BTV VDSNRBBSVRSDSFRBRRECCPNNSNRA+

IRWSR

30.8

EBSR

30.6 ScSR

0.850 0.855 0.860 0.865 S0S.I8M70 0.875 0.880 0.885 0.890

EBSR

VDSR

L1BTV

350

ScSR

A+

IRWSR

300

NBSRF SRCNN

NUISR WNUISR

BEPSR BVSR

250

DRCN

DBRSR

Ours

200

150

100

50

00

2

4 Inde6x of met8hods 10 12 14

Fig. 4. Comparison with other 14 SR methods on the SupER dataset [42] in average PSNR and SSIM for 2×. Red color map denotes the single-frame SR methods and the blue one represents the multi-frame SR methods.

Fig. 5. Comparison with other 14 SR methods on the SupER dataset [42] in runtime for 2×. Red color map denotes the single-frame SR methods and the blue one represents the multi-frame SR methods.

available SupER dataset [42] which contains images of 14 scenes captured by a CMOS camera. Each of the 14 scenes is captured under multiple modes including motion types, binning factor, and compression levels. Each mode contains 40 LR images by capturing stop-motion videos. We performed SR reconstruction for images captured by binning factor of 2 under global motion which includes translation in 3D space and panning in a joint sinusoidal and circular moving trajectory. Following [42], we selected a sliding window of size 5

centered at the 10th LR image and compared with other 14 SR methods [1], [7], [13], [19], [20], [45]­[53] implemented in [42]. Since the LR images are not severely contaminated by noise, we set  = 0.1 for all the 14 scenes. We estimated the scalar  and the Gaussian noise parameter  shown in Eq. (14) by [40] and assumed the mean µ = 0. The estimated negative parameters by [40] were clamped to 10-6. Besides, we set the decay scalar as  = 0.95 and the penalty parameter as  = 103 for a smooth convergence over 16 iterations. The smoothing

8

a) LR (PSNR/SSIM)

b) GT

c) L1+BTV

d) SRCNN

e) DRCN

f) A+

g) VDSR

h) MPG+BSWTV

(24.34/0.7793) (24.53/0.8118) (24.42/0.8079) (24.67/0.8140) (24.26/0.8026) (24.73/0.8298)

Fig. 6. Comparison of different SR methods on the Coffee dataset (2×). Top: reconstructed SR images; Bottom: ROI

a) LR (PSNR/SSIM)

b) GT

c) L1+BTV

d) SRCNN

e) DRCN

f) A+

g) VDSR

h) MPG+BSWTV

(38.70/0.9303) (38.48/0.9276) (38.50/0.9274) (38.56/0.9286) (38.41/0.9261) (40.84/0.9557)

Fig. 7. Comparison of different SR methods on the Dolls dataset (2×). Top: reconstructed SR images; Bottom: ROI

parameter  was set as 3 to make the flat regions and edges distinguishable in the weighting map. The shift parameter b was tuned as 1 so that the fine structures can be preserved. We used the original implementation and parameters in [42] for the other 14 SR methods. The performance of the 15 SR methods is assessed by PSNR and SSIM and summarized in Fig 4. Single-frame and multi-frame SR methods are respectively marked by red and blue. We can observe that most of the multi-frame SR methods perform better than the single-frame ones under global motion. The proposed approach achieves considerable improvement comparing to the other investigated methods in both PSNR and SSIM. In Fig. 5, we illustrate the computation time of different methods. It is necessary to note that all the other methods were implemented in Matlab and some of them were accelerated by C++. Our method was implemented in Python without C/C++ speedup. In Fig. 6 and Fig. 7, we demonstrate the reconstructed images of some representative methods. As shown in Fig. 6, comparing to the other methods, the proposed MPG+BSWTV generates more distinguishable characters and much cleaner background. In Fig. 7, we can observe that our method provides a more pleasant visual perception and resembles the GT image most.
2) SR Reconstruction on X-ray Images: In addition to the SupER dataset which contains 8-bit natural images, we conducted experiments on 16-bit X-ray images which were captured by the Nikon HMX ST 225 CT scanner as shown in Fig. 8. The CT scanner is equipped with a flat panel Varian PaxScan@4030E detector which has a pixel size of

(a)

(b)

(c)

Fig. 8. CT scanner equipped with mounted linear stages. (a) the side view, (b) X-ray source and rotation table, (c) X-ray detector mounted on linear stages.

127µm×127µm. The detector is mounted on the controllable linear stages for x- and y-positioning such that the detector can be shifted to a predefined position with a movement accuracy up to 1µm. Two objects were taken as test specimens: a resolution target and a printed circuit board (PCB). Specially, four 16-bit X-ray images were captured by shifting the detector with a half pixel distance rightwards, downwards, and leftwards for both the specimens. The SR reconstructed images by different methods are demonstrated in Fig. 9 and Fig. 10. It is shown that the proposed method performs better than the others in visual perception by jointly sharpening the edges and suppressing the noise in the flat regions which coincides with the observations in the other SR experiments.
C. Image Denoising on Synthetic Images
In order to evaluate the performance of the proposed MPG+BSWTV for image denoising, we carried out experi-

9

a) Resolution target

b) Bicubic

c) L1+BTV

d) L2+NLTV

e) L2+BSWTV

f) MPG+BSWTV

Fig. 9. Comparison of different SR methods for 2× on the 16-bit X-ray image of a resolution target: (a) X-ray image of the resolution target, (b) bicubic, (c) L1+BTV, (d) L2+NLTV, (e) L2+BSWTV, and (f) MPG+BSWTV.

a) PCB

b) Bicubic

c) L1+BTV

d) L2+NLTV

e) L2+BSWTV

f) MPG+BSWTV

Fig. 10. Comparison of different SR methods for 2× on the 16-bit X-ray image of a printed circuit board (PCB): (a) X-ray image of the PCB, (b) bicubic, (c) L1+BTV, (d) L2+NLTV, (e) L2+BSWTV, and (f) MPG+BSWTV.

a-1) Noisy image

b-1) L1+BTV

c-1) L2+NLTV

d-1) L2+BSWTV

e-1) BM3D

f-1) TWSC

g-1) MPG+SWTV

(24.29dB, 0.6239) (26.50dB, 0.6950) (29.08dB, 0.8641) (29.21dB, 0.8680) (28.78dB, 0.8719) (29.19dB, 0.8765) (29.46dB, 0.8846)

a-2) Noisy image

b-2) L1+BTV

c-2) L2+NLTV

d-2) L2+BSWTV

e-2) BM3D

f-2) TWSC

g-2) MPG+BSWTV

Fig. 11. Comparison of different denoising methods on Page contaminated by a mixed Poisson­Gaussian noise with peak intensity 200 and  = 10 in PSNR and SSIM: (a) noisy image, (b) L1+BTV, (c) L2+NLTV, (d) L2+BSWTV, (e) BM3D, and (f) MPG+BSWTV.

ments on the synthetic natural images under mixed Poisson­ Gaussian noise. As described in Section I, we set the system matrix A as the identity matrix and the amount of input frames as m = 1. The experiments were conducted on the grayvalue images shown in Fig. 2 which were corrupted by a mixed Poisson­Gaussian noise with peak intensity 200 and  = 0.01,  = 2. We compared the proposed MPG+BSWTV with L1+BTV [7], L2+NLTV [8], L2+BSWTV, BM3D [5], and TWSC [54]. We set the window size as R = 3 for L2+NLTV and the patch size was selected as r = 3 for both NLTV and BSWTV. The number of ADMM iterations of all the TV-based methods was set as 20. The decay scalar  is normally tuned in a range of [0.5, 0.95]. Empirically, large decay  tends to yield a gradually descent shrink coefficient  and results in a flat convergence curve, while small decay usually leads to a fast and slightly fluctuated convergence. The weighting parameter of the regularization term  and the momentum coefficient  were tuned to achieve the best PSNR performance in a trial and error manner. The smoothing parameter  was selected in a way that the structures were distinguishable in the weighting map. The Gaussian parameter of the kernel G() was initialized with  = 3 and the

constants for updating the penalty parameters were set as c1 = c2 = 2, c = 10. The amplitude parameter a in function f shown in Eq. (7) was chosen as 20 and the shift parameter b was tuned within the interval [0, 1]. For the other methods, the parameters which generated the best PSNR were employed. In Fig. 11, we demonstrate the superior performance of our approach for denoising texts. In contrast to BM3D and TWSC, our method restores the characters effectively and meanwhile removes the noise in the empty space which provides a pleasant result. The overall quantitative evaluation in PSNR and SSIM is depicted in Tab II.
D. Image Denoising on Real-world Images
In this experiment, we evaluated our method on the realworld images [43] for image denoising. The dataset contains noisy images of 40 static scenes which are captured by Canon 5D, Canon 80D, Canon 600D, Nikon D800, and Sony A7 under different ISO levels. 100 cropped regions of size 512×512 are provided in [43], based on which we compared with other 10 representative denoising methods [14], [24]­[26], [54]­[59]. Specially, CBM3D [55], EPLL [24],

10

TABLE II COMPARISON OF DIFFERENT DENOISING METHODS UNDER MIXED POISSON­GAUSSIAN NOISE WITH PEAK INTENSITY 200,  = 0.01,  = 2 IN PSNR (dB) AND SSIM. BEST: BOLD; SECOND BEST: UNDERLINE. (ALL TV-BASED METHODS WERE IMPLEMENTED USING ADMM FRAMEWORK.)

Cameraman

Lena

Page

Comic

Face

PPT3

Zebra

Average

PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM

Noisy image 40.95

L1+BTV [7] 42.25

L2+NLTV [8] 42.81

L2+BSWTV 43.43

BM3D [5]

43.85

TWSC [54]

43.81

MPG+BSWTV (ours) 43.75

0.9524 40.93 0.9703 41.19 0.9752 41.48 0.9796 42.08 0.9833 41.86 0.9815 42.23 0.9826 42.21

0.9687 40.71 0.9743 41.19 0.9756 42.32 0.9782 42.96 0.9801 43.15 0.9786 42.98 0.9788 43.21

0.9584 40.72 0.9737 40.75 0.9817 40.55 0.9821 41.22 0.9860 41.09 0.9833 41.16 0.9865 41.28

0.9928 41.03 0.9932 41.54 0.9934 41.24 0.9942 41.68 0.9939 41.26 0.9939 42.05 0.9946 41.92

0.9711 40.45 0.9747 41.08 0.9734 44.20 0.9756 45.05 0.9785 45.22 0.9785 45.60 0.9780 45.14

0.9555 40.76 0.9713 40.80 0.9934 41.01 0.9952 41.07 0.9949 40.99 0.9968 41.28 0.9962 41.17

0.9856 40.79 0.9862 41.26 0.9861 41.94 0.9865 42.50 0.9864 42.49 0.9863 42.73 0.9863 42.67

0.9692 0.9777 0.9827 0.9845 0.9862 0.9856 0.9861

TABLE III COMPARISON OF DIFFERENT STATE-OF-THE-ART DENOISING METHODS BASED ON 100 CROPPED REAL-WORLD IMAGES [43] IN AVERAGE PSNR
(dB) AND SSIM.

CBM3D [55] EPLL [24] PGPD [56] NCSR [25] WNNM [26] DnCNN [14] NC [57] CSF [58] NI [59] TWSC [54] MPG+BSWTV

PSNR 37.40

36.17

36.18

36.40

36.59

36.08

36.92 37.71 37.77 38.60

38.31

SSIM 0.9526

0.9216 0.9206 0.9290

0.9247

0.9161 0.9449 0.9571 0.9570 0.9685

0.9608

PGPD [56], NCSR [25], WNNM [26], CSF [58], DnCNN [14] are denoising methods based on the AWGN model. As our MPG+BSWTV is proposed for gray-value images, we conducted denoising on each channel of the RGB images individually. The Gaussian noise  and the real scalar  were predicted by [40]. The weighting parameter  was tuned in a range of [5, 10]. To obtain a proper weighting map, the smoothing parameter  was set as 5. The penalty parameter  was initialized with 102 and the number of ADMM iterations was set as 6. Based on the available performance of the other methods in [43], we summarize the average PSNR and SSIM in Tab. III. It is shown that the proposed method MPG+BSWTV performs better than most of the investigated

well-known denoising approaches except TWSC which is dedicated to multi-channel images. Besides, we can see that the methods based on AWGN do not perform as well as expected because the real-world noise is not AWGN but signal dependent.
E. Weighting Map and Parameter Analysis
In this section, we illustrate the effectiveness of the shrink coefficient on the weighting map  and analyze the impact of the penalty parameter , the decay scalar , the smoothing parameter , and the shift parameter b on the performance of MPG+BSWTV.

Noisy image (PSNR, SSIM)

BSWTV weighting map over iterations

MPG+BSWTV (37.98dB, 0.9954)

PSNR [dB]

35 30 25 20
0

L2+NLTV Proposed ( = 0.3)

10

20

30

40

50

Iterations

L2+NLTV

NLTV weighting NLTV weighting NLTV weighting NLTV weighting NLTV weighting NLTV weighting NLTV weighting NLTV weighting

(36.43dB, 0.9886)

map[1]

map[2]

map[3]

map[4]

map[5]

map[6]

map[7]

map[8]

ROI: L2+NLTV ROI: MPG+BSWTV ROI: L2+NLTV ROI: MPG+BSWTV ROI: L2+NLTV ROI: MPG+BSWTV Residual L2+NLTV Residual MPG+BSWTV
Fig. 12. Illustration of the effectiveness of the shrink coefficient on the weighting map of BSWTV and the reconstructed image comparing to L2+NLTV by denoising an 8-bit gray-value image contaminated by a mixed Poisson­Gaussian noise with peak intensity 200 and  = 10.

11

PSNR (dB) Objective

30 29 28 27 26 25 24 23
0

=10 1 =10 2 =10 3 =10 4 =10 5 =10 6

×105
2.3 2.2 2.1 2.0 1.9

=10 1 =10 2 =10 3 =10 4 =10 5 =10 6

25 50 75 100 125 150 Iterations

0

25 50 75 100 125 150

Iterations

PSNR (dB) PSNR (dB)

30.5 30.0 29.5 29.0 28.5 28.0 27.5 27.0
0

30

29

=0.01

28

=0.3

=0.5

27

=0.7

=0.9

26

=1

20

40

60

80

100

25 0

Iterations

=0.1 =1 =4 =6 =8 =10

20

40

60

80

100

Iterations

Fig. 13. Impact of the initial penalty parameter  on the convergence. Left: Fig. 14. Left: impact of the decay scalar  on the convergence; Right: impact

PSNR over iterations; Right: objective over iterations.

of the smoothing parameter  on the convergence.

1) Weighting map : In this experiment, we demonstrate the refinement of the weighting map in MPG+BSWTV over ADMM iterations and compare with the resultant weighting maps of L2+NLTV. The synthetic image contains multiple basic shapes including ellipses, rectangles, and bars as shown in Fig. 12. The image was contaminated by a mixed Poisson­ Gaussian noise with peak intensity 200 and  = 10. We chose a search window of size R = 3 for NLTV and hence NLTV generates R2 - 1 weighting maps. For a fast convergence, we set the decay parameter as  = 0.3 and the momentum coefficient as  = 0.5. The smoothing parameters  and the weighting parameters  for both NLTV and BSWTV were tuned to achieve the best PSNR performance. As shown in Fig. 12, both approaches converge over iterations and the proposed method outperforms L2+NLTV quantitatively and qualitatively. We can observe that the mask of the edges in the weighting map of BSWTV becomes thinner and sharper along with the convergence. Consequently, the noise surrounding the edges is significantly suppressed without compromising the sharpness as shown in the marked regions.
2) Penalty parameter : Experimental analysis has been conducted to study the influence of different initial  on the convergence of the algorithm. As shown in Fig 13, the magnitude of  has noticeable impact on the convergence rate although  is iteratively updated. Large  stabilizes the convergence and tends to slow down the convergence rate. On the contrary, small  accelerates the convergence but may cause overshoot of the objective function and lead to undesirable degradation of image quality. Depending on the expected convergence rate and the noise level, an empirical choice of  may vary in a range of [10-3, 103] for 8-bit images.
3) Decay parameter : The decay parameter  aims to refine the weighting map  by thinning the mask of the edges such that the surrounding noise can be better suppressed via TV. We investigated  in the range of [0.01, 1] where  = 1 indicates without decay. As shown in the left graph of Fig. 14, extremely small  attenuates the shrink coefficient  aggressively so that the weighting map of regions containing fine low-contrast structures also gets whitened and the fine structures might be smoothed by the regularizer which causes performance degradation. In contrast,  = 1 prevents the weighting map from whitening which limits the performance of the algorithm. For a gradual refinement of the weighting map, usually we choose the decay parameter in a range of [0.5, 0.95].

PSNR (dB) SSIM

30.0 29.5 29.0 28.5 28.0 27.5
0

0.85

30.10 30.05 Zoom-in view

30.00

29.95

29.90 0

10

20

30

40

50

b=0

b=0.5

b=0.8

b=1

10

20

30

40

50

Iterations

0.80 0.75 0.70 0.65
0

b=0 b=0.5 b=0.8 b=1

10

20

30

40

50

Iterations

Fig. 15. Impact of the shift parameter b on the convergence. Left: PSNR over iterations; Right: SSIM over iterations.

4) Smoothing parameter : The smoothing parameter  is used to control the impact of the eigenvalue discrepancy on the weighting map. As depicted in the right graph of Fig. 14, small  can not brighten the weighting map and results in a deteriorated performance. However, too large  causes saturation of the weighting map and the proposed regularization term acts as the standard TV. Depending on the dynamic range of the image, a proper choice of  for 8-bit images would be in the interval of [2, 6].
5) Shift parameter b: The flat regions and strong edges can be easily tackled by a homogeneous shrink coefficient. The shift parameter b is introduced to cope with the fine textures with relative low contrast. It behaves as a threshold and masks the fine textures in the weighting map by inhomogeneously shrinking the coefficient . Specially,  is expected to be shrinked by  in flat regions while maintain the same in finestructure regions. Consequently, the fine structures are masked out in the weighting map and are not smoothed by TV. As illustrated in Fig. 15, b has noticeable impact on SSIM and might have limited influence on PSNR because PSNR is prone to slightly oversmoothed images.
VI. CONCLUSION
In this paper, we propose a bilateral spectrum weighted total variation (BSWTV) based on the spectrum of the covariance matrix of the adaptively weighted image gradients for real-world noisy-image super-resolution and image denoising. Particularly, we apply a locally adaptive shrink coefficient to the image gradients such that the mask of the edges in the weighting map of the total variation is iteratively refined and the noise surrounding the edges is effectively suppressed. Combining with the data fidelity term MPG derived from a mixed Poisson­Gaussian noise model, we introduce a generalized algorithm addressing real-world non-Gaussian noise for

12

super-resolution and image denoising. The overall objective function is decomposed and solved based on the alternating direction method of multipliers (ADMM) algorithm. Specially, different from the standard ADMM framework, we integrate the update of the weighting map as the first step in the ADMM algorithm by considering the other variables as constants. In order to remove the outliers in the weighting map and facilitate the stability of the convergence of the objective function in the modified ADMM, the estimated weighting map is smoothed by a Gaussian filter with an iteratively decreased kernel width and updated in a momentum-based fashion. We have conducted extensive experiments and benchmarked our approach with the state-of-the-art methods on the publicly available real-world datasets for super-resolution and image denoising. Experimental results demonstrate that our MPG+BSWTV outperforms 14 investigated super-resolution methods by an average gain of 0.2dB in PSNR on the SupER dataset. Although MPG+BSWTV is originally derived for super-resolution, it achieves also promising performance for image denoising on the real-world noisy images.
APPENDIX A PROOF OF PROPOSITION A
Proof. Considering a digital image y : N20  R contaminated by a mixed Poisson­Gaussian noise as y = z + np(z) + ng where (zi,j + np(zi,j))/  P (zi,j/) with zi,j being the noiseless intensity value at pixel (i, j) and  being a scalar. ng is an additive Gaussian noise with ng(i, j)  N (µi,j, i2,j). According to the Central Limit Theorem (CLT), when zi,j/ is sufficiently large, we have (zi,j + np(zi,j))/  P (zi,j/) N (zi,j /, zi,j /). Therefore, we have zi,j + np(zi,j)  N (zi,j, zi,j). As np and ng are independent, we yield y(i, j)  N (zi,j +µi,j, zi,j +i2,j). As element (i + 1, j) and (i - 1, j) are independent, we have E(xy(i, j)) = (zi+1,j + µi+1,j - zi-1,j - µi-1,j )/2 and V ar(xy(i, j)) = (zi+1,j + i2+1,j + zi-1,j + i2-1,j )/4. If elements (i - 1, j), (i, j), (i + 1, j)   where (m, n), (p, q) satisfying |zm,n + µm,n - zp,q - µp,q| < 1, |zm,n + m2 ,n - zp,q - p2,q| < 2, 1, 2 > 0, then we have xy(i, j)  N (0, (zi,j + i2,j)/2). The derivation holds also for yy(i, j). In the homogeneous region , a collection of the gradients with the same isotropic white Gaussian distribution can be considered as multiple realizations of an isotropic white Gaussian distributed variable at different image locations.
REFERENCES
[1] S. Park, M. Park, M. G. Kang, Super-resolution image reconstruction, a technical overview, IEEE Signal Process. Mag. 20 (5) (2003) 21­36.
[2] K. Nasrollahi, T. B. Moeslund, Super-resolution: A comprehensive survey, Mach. Vis. Appl. 25 (6) (2014) 1423­1468.
[3] A. Buades, B. Coll, J. M. Morel, A non-local algorithm for image denoising, in: Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Vol. 2, 2005, pp. 60­65.
[4] A. Buades, B. Coll, J. M. Morel, Nonlocal image and movie denoising, Int. J. Comput. Vis. 76 (2) (2008) 123­139.
[5] K. Dabov, A. Foi, V. Katkovnik, K. Egiazarian, Image denoising by sparse 3-d transform-domain collaborative filtering, IEEE Trans. Image Process. 16 (8) (2007) 2080­2095.
[6] L. I. Rudin, S. Osher, E. Fatemi, Nonlinear total variation based noise removal algorithms, Physica D: Nonlinear Phenomena 60 (1-4) (1992) 259­268.

[7] S. Farsiu, M. D. Robinson, M. Elad, P. Milanfar, Fast and robust multiframe super-resolution, IEEE Trans. Image Process. 13 (10) (2004) 1327­1344.
[8] G. Gilboa, S. Osher, Nonlocal operators with applications to image processing, Multiscale Modeling & Simulation 7 (3) (2009) 1005­1028.
[9] J. Mairal, F. Bach, J. Ponce, G. Sapiro, A. Zisserman, Non-local sparse models for image restoration, in: Proc. IEEE Int. Conf. Comput. Vis., 2009, pp. 2272­2279.
[10] W. Dong, L. Zhang, G. Shi, X. Li, Nonlocally centralized sparse representation for image restoration, IEEE Trans. Image Process. 22 (4) (2012) 1620­1630.
[11] L. Dong, Y. Gan, X. Mao, Y. Yang, C. Shen, Learning deep representations using convolutional auto-encoders with symmetric skip connections, in: Proc. IEEE Int. Conf. Acoust. Speech Signal Process., 2018, pp. 3006­3010.
[12] D. Ulyanov, A. Vedaldi, V. Lempitsky, Deep image prior, in: Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2018, pp. 9446­9454.
[13] C. Dong, C. C. Loy, K. He, X. Tang, Learning a deep convolutional network for image super-resolution, in: Proc. Eur. Conf. Comput. Vis., 2014, pp. 184­199.
[14] K. Zhang, W. Zuo, Y. Chen, D. Meng, L. Zhang, Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising, IEEE Trans. Image Process. 26 (7) (2017) 3142­3155.
[15] K. Zhang, W. Zuo, L. Zhang, Deep plug-and-play super-resolution for arbitrary blur kernels, in: Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2019, pp. 1671­1681.
[16] A. Singh, F. Porikli, N. Ahuja, Super-resolving noisy images, in: Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2014, pp. 2846­2853.
[17] Q. Yuan, L. Zhang, H. Shen, Regional spatially adaptive total variation super-resolution with spatial information filtering and clustering, IEEE Trans. Image Process. 22 (6) (2013) 2327­2342.
[18] K. Sun, T. Tran, R. Krawtschenko, S. Simon, Multi-frame superresolution reconstruction based on mixed poisson­gaussian noise, Signal Processing: Image Communication 82 (2020) 115736.
[19] T. Ko¨hler, X. Huang, F. Schebesch, A. Aichert, A. Maier, J. Hornegger, Robust multiframe super-resolution employing iteratively re-weighted minimization, IEEE Trans. Comput. Imag. 2 (1) (2016) 42­58.
[20] J. Kim, J. K. Lee, K. M. Lee, Accurate image super-resolution using very deep convolutional networks, in: Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2016, pp. 1646­1654.
[21] B. Lim, S. Son, H. Kim, S. Nah, K. M. Lee, Enhanced deep residual networks for single image super-resolution, in: Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshop, 2017, pp. 136­144.
[22] C. Ren, X. He, Y. Pu, T. Q. Nguyen, Enhanced non-local total variation model and multi-directional feature prediction prior for single image super resolution, IEEE Trans. Image Process. 28 (8) (2019) 3778­3793.
[23] X. Zhang, M. Burger, X. Bresson, S. Osher, Bregmanized nonlocal regularization for deconvolution and sparse reconstruction, SIAM J. Imaging Sci. 3 (3) (2010) 253­276.
[24] D. Zoran, Y. Weiss, From learning models of natural image patches to whole image restoration, in: Proc. IEEE Int. Conf. Comp. Vis., 2011, pp. 479­486.
[25] W. Dong, L. Zhang, G. Shi, X. Li, Nonlocally centralized sparse representation for image restoration, IEEE Trans. Image Process. 22 (4) (2012) 1620­1630.
[26] S. Gu, L. Zhang, W. Zuo, X. Feng, Weighted nuclear norm minimization with application to image denoising, in: Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2014, pp. 2862­2869.
[27] S. Lefkimmiatis, Universal denoising networks: a novel cnn architecture for image denoising, in: Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2018, pp. 3204­3213.
[28] C. Sutour, C. Deledalle, J. Aujol, Adaptive regularization of the nlmeans: Application to image and video denoising, IEEE Trans. Image Process. 23 (8) (2014) 3506­3521.
[29] M. Elad, M. Aharon, Image denoising via sparse and redundant representations over learned dictionaries, IEEE Trans. Image Process. 15 (12) (2006) 3736­3745.
[30] W. Dong, L. Zhang, G. Shi, X. Li, Nonlocally centralized sparse representation for image restoration, IEEE Trans. Image Process. 22 (4) (2012) 1620­1630.
[31] J. Yang, J. Wright, T. Huang, Y. Ma, Image super-resolution via sparse representation, IEEE Trans. Image Process. 19 (11) (2010) 2861­2873.
[32] W. Bao, X. Zhang, S. Yan, Z. Gao, Iterative convolutional neural network for noisy image super-resolution, in: Proc. IEEE Int. Conf. Image Proc., 2017, pp. 4038­4042.

13
[33] D. L. Snyder, A. M. Hammoud, R. L. White, Image recovery from data acquired with a charge-coupled-device camera, J. Opt. Soc. Am. A 10 (5) (1993) 1014­1023.
[34] C. Aguerrebere, J. Delon, Y. Gousseau, P. Muse´, Study of the digital camera acquisition process and statistical modeling of the sensor raw data, hal-00733538v4 (2013) 1­11.
[35] F. Luisier, T. Blu, M. Unser, Image denoising in mixed poisson-gaussian noise, IEEE Trans. Image Process. 20 (3) (2011) 696­708.
[36] J. Li, Z. Shen, R. Yin, X. Zhang, A reweighted l2 method for image restoration with poisson and mixed poisson-gaussian noise, Inverse Probl. Imaging 9 (3) (2015) 875­894.
[37] Y. Traonmilin, C. Aguerrebere, Simultaneous high dynamic range and superresolution imaging without regularization, SIAM J. Imaging Sci. 7 (3) (2014) 1624­1644.
[38] H. Takeda, S. Farsiu, P. Milanfar, Kernel regression for image processing and reconstruction, IEEE Trans. Image Process. 16 (2) (2007) 349­366.
[39] C. Harris, M. Stephens, A combined corner and edge detector, in: Proc. Alvey Vis. Conf., Vol. 15, 1988, pp. 10­5244.
[40] A. Foi, M. Trimeche, V. Katkovnik, K. Egiazarian, Practical poissoniangaussian noise modeling and fitting for single-image raw-data, IEEE Trans. Image Process. 17 (10) (2008) 1737­1754.
[41] S. Boyd, N. Parikh, E. Chu, B. Peleato, J. Eckstein, Distributed optimization and statistical learning via the alternating direction method of multipliers, Foundations and Trends® in Machine learning 3 (1) (2011) 1­122.
[42] T. Ko¨hler, et al., Toward bridging the simulated-to-real gap: Benchmarking super-resolution on real data, IEEE Trans. Pattern Anal. Mach. Intell. 41 (11) (2019) 2944­2959.
[43] J. Xu, H. Li, Z. Liang, D. Zhang, L. Zhang, Real-world noisy image denoising: A new benchmark, arXiv preprint arXiv:1804.02603.
[44] M. Haris, G. Shakhnarovich, N. Ukita, Recurrent back-projection network for video super-resolution, in: Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2019, pp. 3897­3906.
[45] J. Kim, J. K. Lee, K. M. Lee, Deeply-recursive convolutional network for image super-resolution, in: Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2016, pp. 1637­1645.
[46] J. Yang, J. Wright, T. S. Huang, Y. Ma, Image super-resolution via sparse representation, IEEE Trans. Image Process. 19 (11) (2010) 2861­2873.
[47] K. K. In, Y. Kwon, Single-image super-resolution using sparse regression and natural image prior, IEEE Trans. Pattern Anal. Mach. Intell. 32 (6) (2010) 1127­1133.
[48] J. Salvador, E. Perez-Pellitero, Naive bayes super-resolution forest, in: Proc. IEEE Int. Conf. Comp. Vis., 2015, pp. 325­333.
[49] R. Timofte, V. D. Smet, L. V. Gool, A+: Adjusted anchored neighborhood regression for fast super-resolution, in: Proc. Asian Conf. Comp. Vis., 2014, pp. 111­126.
[50] M. Ba¨tz, A. Eichenseer, A. Kaup, Multi-image super-resolution using a dual weighting scheme based on voronoi tessellation, in: Proc. IEEE Int. Conf. Image Proc., 2016, pp. 2822­2826.
[51] M. Ba¨tz, J. Koloda, A. Eichenseer, A. Kaup, Multi-image superresolution using a locally adaptive denoising-based refinement, in: Proc. Int. Workshop Multimedia Signal Process., 2016, pp. 1­6.
[52] X. Zeng, L. Yang, A robust multiframe super-resolution algorithm based on half-quadratic estimation with modified btv regularization, Digital Signal Process. 23 (1) (2013) 98­109.
[53] C. Liu, D. Sun, On bayesian adaptive video super resolution, IEEE Trans. Pattern Anal. Mach. Intell. 36 (2) (2013) 346­360.
[54] J. Xu, L. Zhang, D. Zhang, A trilateral weighted sparse coding scheme for real-world image denoising, in: Proc. Eur. Conf. Comput. Vis., 2018, pp. 20­36.
[55] K. Dabov, A. Foi, V. Katkovnik, K. Egiazarian, Color image denoising via sparse 3d collaborative filtering with grouping constraint in luminance-chrominance space, in: Proc. IEEE Int. Conf. Image Proc., 2007, pp. 313­316.
[56] J. Xu, L. Zhang, W. Zuo, D. Zhang, X. Feng, Patch group based nonlocal self-similarity prior learning for image denoising, in: Proc. IEEE Int. Conf. Comp. Vis., 2015, pp. 244­252.
[57] M. Lebrun, M. Colom, J. Morel, The noise clinic: a blind image denoising algorithm, Image Processing On Line 5 (2015) 1­54.
[58] U. Schmidt, S. Roth, Shrinkage fields for effective image restoration, in: Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2014, pp. 2774­2781.
[59] N. ABSoft, Neat image, https://ni.neatvideo.com/home, accessed: 202105-14.

