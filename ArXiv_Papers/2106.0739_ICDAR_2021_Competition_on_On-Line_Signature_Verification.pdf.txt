arXiv:2106.00739v1 [cs.CV] 1 Jun 2021

ICDAR 2021 Competition on
On-Line Signature Verification
Ruben Tolosana1, Ruben Vera-Rodriguez1, Carlos Gonzalez-Garcia1, Julian Fierrez1, Santiago Rengifo1, Aythami Morales1, Javier Ortega-Garcia1, Juan Carlos Ruiz-Garcia1, Sergio Romero-Tapiador1, Jiajia Jiang2, Songxuan Lai2, Lianwen Jin2,3, Yecheng Zhu2, Javier Galbally4, Moises Diaz5, Miguel Angel Ferrer6, Marta Gomez-Barrero7, Ilya Hodashinsky8, Konstantin Sarin8, Artem Slezkin8, Marina Bardamova8, Mikhail Svetlakov8, Mohammad Saleem9, Cintia
Lia Szu¨cs9, Bence Kovari9, Falk Pulsmeyer10, Mohamad Wehbi10, Dario Zanca10, Sumaiya Ahmad11, Sarthak Mishra11, and Suraiya Jabin11
1 Biometrics and Data Pattern Analytics Lab, UAM, Spain (ruben.tolosana;ruben.vera;julian.fierrez;aythami.morales;javier.ortega)@uam.es
(santiago.rengifo;juanc.ruiz)@uam.es (carlos.gonzalezgarcia;sergio.romerot)@estudiante.uam.es
2 South China University of Technology, China 3 Guangdong Artificial Intelligence and Digital Economy Laboratory, China
eejiajia jiang@mail.scut.edu.cn;eesxlai@qq.com; eelwjin@scut.edu.cn;claytonzyc@foxmail.com
4 European Commission - Joint Research Centre, Italy javier.galbally@ec.europa.eu
5 Universidad del Atlantico Medio, Spain moises.diaz@atlanticomedio.es
6 Universidad de las Palmas de Gran Canaria, Spain miguelangel.ferrer@ulpgc.es 7 Hochschule Ansbach, Germany
marta.gomez-barrero@hs-ansbach.de 8 Tomsk State University of Control Systems and Radioelectronics, Russia
hodashn@rambler.ru;sks@security.tomsk.ru; saotom724@gmail.com;722bmb@gmail.com;rvvincle@gmail.com 9 Budapest University of Technology and Economics, Hungary
(Mohammad.Saleem;Szucs.CintiaLia;kovari)@aut.bme.hu 10 Machine Learning and Data Analytics Lab, FAU, Germany
(falk.pulsmeyer;mohamad.wehbi;dario.zanca)@fau.de 11 Jamia Millia Islamia, India
sumaiya.hld@gmail.com;sarthak.mishra2905@gmail.com;sjabin@jmi.ac.in
Abstract. This paper describes the experimental framework and results of the ICDAR 2021 Competition on On-Line Signature Verification (SVC 2021). The goal of SVC 2021 is to evaluate the limits of on-line signature verification systems on popular scenarios (office/mobile) and writing inputs (stylus/finger) through large-scale public databases. Three different tasks are considered in the competition, simulating realistic scenarios as both random and skilled forgeries are simultaneously considered on each task. The results obtained in SVC 2021 prove the high potential of deep

2

R. Tolosana et al.

learning methods. In particular, the best on-line signature verification system of SVC 2021 obtained Equal Error Rate (EER) values of 3.33% (Task 1), 7.41% (Task 2), and 6.04% (Task 3). SVC 2021 will be established as an on-going competition12, where researchers can easily benchmark their systems against the state of the art in an open common platform using large-scale public databases such as DeepSignDB13 and SVC2021 EvalDB14, and standard experimental protocols.
Keywords: SVC 2021 · Biometrics · Handwriting · On-Line Signature · Benchmark · DeepSignDB · SVC2021 EvalDB · Deep Learning.

1 Introduction
On-line handwritten signature verification has always been a very active area of research due to its high popularity for authentication scenarios [9] and the variety of open challenges that are still under research nowadays [14], e.g., one/few-shot learning [20,10,27,45], device interoperability [2,30,36,44], aging [22,41], types of impostors [40,21], signature complexity [24,43,47], template storage [8], etc. Despite all these challenges, the performance of on-line signature verification systems has been improved in the last years due to several factors, especially: i) the evolution in the acquisition technology going from devices specifically designed to acquire handwriting and signature in office-like scenarios through a pen stylus (e.g. Wacom devices) to the current touch screens of mobile scenarios in which signatures can be captured anywhere using our own personal smartphone through the finger [36,38,3,13], and ii) the extended usage of deep learning technology in many different areas, overcoming traditional handcrafted approaches and even human performance [46,39,26,48,1]. So, with all these aspects in mind, the question is: what are the current performance limits of the on-line signature verification technology under realistic scenarios?
This paper describes the experimental framework and results of the ICDAR 2021 Competition on On-Line Signature Verification (SVC 2021). The goal of SVC 2021 is to evaluate the limits of on-line signature verification systems on popular scenarios (office/mobile) and writing inputs (stylus/finger) through large-scale public databases. Three different tasks are considered in the competition:
­ Task 1: Analysis of office scenarios using the stylus as input. ­ Task 2: Analysis of mobile scenarios using the finger as input. ­ Task 3: Analysis of both office and mobile scenarios simultaneously.
In addition, we simulate in SVC 2021 the following realistic operational conditions, to the best of our knowledge, not considered in previous on-line signature verification competitions [49,4,25,29,28]:
12 https://sites.google.com/view/SVC2021 13 https://github.com/BiDAlab/DeepSignDB 14 https://github.com/BiDAlab/SVC2021_EvalDB

ICDAR 2021 Competition on On-Line Signature Verification

3

­ Over 1,700 subjects and 100 different acquisition devices are considered in the competition, using both Wacom devices (office scenarios) and general purpose devices such as tablets and smartphones (mobile scenarios).
­ Random and skilled forgeries are simultaneously considered in each task. In addition, different types of skilled forgeries are considered in the competition such as static (i.e., only the image of the signature to forge is available) and dynamic forgeries (i.e., both image and dynamics are available), in both trained and blueprint cases [40].
­ High intra-subject variability (a.k.a. aging) as different acquisition set-ups are considered in the competition ranging from 1 to 5 sessions, and with a time gap between sessions from days to months.
This realistic scenario has been achieved thanks to the public DeepSignDB database [46] and the novel SVC2021 EvalDB database (this later one specifically acquired for SVC 2021). Besides, we have designed realistic and challenging experimental protocols making public the corresponding signature comparisons files and the benchmarking platform.
SVC 2021 will be established as an on-going competition15, where researchers can easily benchmark their systems against the state of the art using a common experimental protocol and an open computing platform (CodaLab16).
The remainder of the paper is organised as follows. Sec. 2 and 3 describe the details of the databases and the set-up considered in the competition, respectively. Sec. 4 provides a description of the submitted on-line signature verification systems. Sec. 5 describes the results of the competition. Finally, Sec. 6 draws the final conclusions.

2 SVC 2021: Databases
Two databases are considered in SVC 2021: DeepSignDB and SVC2021 EvalDB. These databases are publicly available for the research community and can be downloaded following the instructions included in17 18. We provide next a description of them.

2.1 DeepSignDB
The DeepSignDB database [46] comprises on-line signatures from a total of 1,526 subjects from four different well-known databases: MCYT (330 subjects) [34], BiosecurID (400 subjects) [16], Biosecure DS2 (650 subjects) [25], eBioSign (65 subjects) [38], and a novel signature database composed of 81 subjects. DeepSignDB comprises more than 70K signatures acquired using both stylus and finger writing inputs in both office and mobile scenarios. A total of 8 different
15 https://sites.google.com/view/SVC2021 16 https://competitions.codalab.org/competitions/27295 17 https://github.com/BiDAlab/DeepSignDB 18 https://github.com/BiDAlab/SVC2021_EvalDB

4

R. Tolosana et al.

devices are considered in the acquisition (i.e., 5 Wacom devices and 3 Samsung general purpose devices). In addition, different types of impostors and number of acquisition sessions are considered along the database. For more details about DeepSignDB, we refer the reader to the published article [46].

2.2 SVC2021 EvalDB
The SVC2021 EvalDB database is a novel database specifically acquired for SVC 2021. Two acquisition scenarios are considered: office and mobile scenarios.
­ Office scenario: on-line signatures from 75 total subjects were acquired using a Wacom STU-530 device with the stylus as writing input. Regarding the acquisition protocol, the device was placed on a desktop and subjects were able to rotate it in order to feel comfortable with the writing position. It is important to highlight that the subjects considered in the acquisition of SVC2021 EvalDB are different compared to the ones considered in the DeepSignDB database. Signatures were collected in two separated sessions with a time gap between them of at least 1 week. For each subject, there are 8 total genuine signatures (4 signatures/session) and 16 skilled forgeries (8 signatures/type) performed by four different subjects in two different sessions. Regarding the skilled forgeries, both static and dynamic forgeries were considered in the first and second acquisition sessions, respectively. Information related to X and Y spatial coordinates, pressure, and timestamp is recorded for the Wacom device. In addition, pen-up trajectories are also available.
­ Mobile scenario: on-line signatures from 119 total subjects were acquired using the same acquisition framework considered in MobileTouchDB [42]. Regarding the acquisition protocol, we implemented an Android App and uploaded it to the Play Store in order to study an unsupervised mobile scenario. This way all subjects could download the App and use it on their own devices without any kind of supervision, simulating a practical scenario in which subjects can generate touchscreen on-line signatures in any possible scenario, e.g., standing, sitting, walking, indoors, outdoors, etc. As a result, 94 different smartphone models from 16 different brands were collected during the acquisition. Regarding the acquisition protocol, between four and six separated sessions in different days were considered with a total time gap between the first and last session of at least 3 weeks. For each subject, there are at least 8 total genuine signatures (2 signatures/session) and 16 skilled forgeries (8 signatures/type) performed by four different subjects. Regarding the skilled forgeries, both static and dynamic forgeries were considered, similar to the office scenario. Information related to X and Y spatial coordinates, and timestamp is recorded for all devices. Pen-up information is not available in this case.

ICDAR 2021 Competition on On-Line Signature Verification

5

3 SVC 2021: Competition Set-Up

3.1 Tasks
The goal of SVC 2021 is to evaluate the limits of on-line signature verification systems on popular scenarios (office/mobile) and writing inputs (stylus/finger) through large-scale public databases. As a result, the following three tasks are considered in the competition:
­ Task 1: Analysis of office scenarios using the stylus as input. ­ Task 2: Analysis of mobile scenarios using the finger as input. ­ Task 3: Analysis of both office and mobile scenarios simultaneously.
In addition, SVC 2021 simulates realistic operational conditions considering random and skilled forgeries simultaneously in each task.

3.2 Evaluation Criteria
The SVC 2021 competition follows a ranking based on points. Each task is evaluated separately, having three winners with their corresponding points (gold medal: 3, silver medal: 2, and bronze medal: 1). The participant/team that gets more points in total (Task 1, 2, and 3) in the final evaluation stage of the competition is the winner of SVC 2021.
The evaluation metric considered is the popular Equal Error Rate (%) similar to most on-line signature verification studies in the literature.

3.3 Experimental Protocol
The two following stages are considered in SVC 2021:
­ Development: the goal of this stage is to provide the participants with the data needed to train the on-line signature verification systems. Only the DeepSignDB database is provided to the participants in this stage of the competition. In addition, participants can freely use other databases to train their systems. In order to allow the participants to test their trained systems under similar conditions considered in the final evaluation stage of the competition, we divide the DeepSignDB database into training and evaluation datasets. The training dataset is based on 1,084 subjects whereas the evaluation dataset comprises the remaining 442 subjects of the database. For the training of the systems (1,084 subjects), no instructions are given to the participants. They can use the data as they like. Nevertheless, for the evaluation of the systems (442 subjects), we provide the participants with the signature comparisons to run. Participants can run their on-line signature verification systems using the signature comparisons files provided to obtain the scores and test the EER performance on the public web platform (CodaLab) created for the

6

R. Tolosana et al.

competition19. This way participants can obtain a quantitative measure of the performance of the developed systems for the final evaluation stage of the competition. In this development stage of the competition, participants can submit up to 300 system evaluation trials in total for all three tasks together. Results are updated in CodaLab in real time and they are visible to everyone in a ranking dashboard. ­ Final Evaluation: the final evaluation of SVC 2021 is carried out using only the novel SVC2021 EvalDB database. The database together with the corresponding signature comparisons files (one file per task) are sent to the participants after signing the corresponding license agreement. It is important to highlight that all signatures are included in a single folder, and both the nomenclature of the signatures and the signature comparisons files are randomized to avoid cheating. Ground-truth labels are not provided to the participants. In addition, and in order to consider a very challenging impostor scenario, the skilled forgery comparisons included in the corresponding files are optimised using machine learning methods, selecting only the best high-quality forgeries. In this final evaluation of SVC 2021, participants are allowed to submit the scores achieved by up to 3 different signature verification systems for each of the tasks considered in the competition.

4 SVC 2021: Description of Evaluated Systems
A total of 54 participants/teams initially registered in SVC 2021. However, only 6 teams finally submitted their scores with a total of 12 different on-line signature verification systems. Next, we describe briefly the systems provided by each of the teams of the competition.

4.1 DLVC-Lab Team
The DLVC-Lab team is composed of members of the South China University of Technology, and the Guangdong Artificial Intelligence and Digital Economy Laboratory.
The DLVC-Lab team proposed an end-to-end trainable deep soft-DTW (DSDTW) model, which greatly enhances the classical Dynamic Time Warping (DTW) method with the capability of deep representation learning. In particular, they use neural networks to learn deep time functions as inputs for DTW. As DTW is not fully differentiable with regards to its inputs, they introduce its smoothed formulation, soft-DTW [7], and incorporate the soft-DTW distances of signature pairs into a triplet loss function for optimization. As soft-DTW is differentiable, the entire system is end-to-end trainable and achieves a perfect integration of neural networks and DTW.
19 https://competitions.codalab.org/competitions/27295

ICDAR 2021 Competition on On-Line Signature Verification

7

Three different approaches were submitted to SVC 2021. System 1 is based on Convolutional Recurrent Neural Networks (CRNN) whereas System 2 and 3 are based on fully Convolutional Neural Networks (CNN). Systems 2 and 3 only differ in the training data. Concretely, Systems 1 and 2 use the development set of the DeepSignDB database for training (1,084 subjects), including both stylus-written and finger-written signatures. System 3 uses only finger-written signatures for training.
Regarding the feature extraction, 12 total time functions are extracted for each signature, considering information such as velocity and acceleration. These time functions are fed to the DSDTW.

4.2 SIG Team
The Spanish-Italian-German (SIG) team is composed of members of the European Commission (Italy), Universidad del Atlantico Medio (Spain), Universidad de las Palmas de Gran Canaria (Spain), and Hochschule Ansbach (Germany).
The signature verification system presented is based on the main principle laid out in [19]: the generation of synthetic off-line signatures from the real on-line samples and the fusion of both types of data can lead to the overall improvement of the on-line verification performance. Following that rationale, the system submitted is based on the combination of on- and off-line signature information.
The on-line signature approach is based on local features and the wellknown DTW algorithm. In particular, the system is based on a subset of the initial 27 time functions introduced in [32] and selected using the Sequential Floating Forward Selection (SFFS) algorithm. The specific implementation of the DTW algorithm uses the Euclidean Distance to compute the optimal path in between signatures and outputs as score son the last value of the optimal path, normalised by the path length. Please be aware that, for the cases where pressure p is not available (i.e., mobile scenario in Task 2 of the competition), the time signal is simply discarded, together with any other time function derived from it.
Regarding the off-line signature approach, the first step performed is the generation of the synthetic off-line data starting from the real on-line signatures. Two different methods are used for this purpose: i) continuous trace [12,19], and ii) dotted trace [11]. Once the two synthetic off-line signatures are created (for each dynamic signature given as input), three different handcrafted features are extracted: i) run-length distribution [5], ii) geometrical features [15], and iii) quad-tree implementation of histogram of templates [37].
The score for each of the three feature sets is obtained by comparing the reference and probe vectors using the DTW algorithm followed by the cityblock distance. This process leads to six off-line intermediate scores (s1off , s2off ,..., s6off ) for each on-line comparison defined in the competition (recall that each individual on-line signature is converted to two off-line synthetic signatures, defined by three different feature sets).

8

R. Tolosana et al.

The six intermediate scores obtained by the off-line approach are finally fused into one unique off-line score soff using a weighted sum. The weights for the fusion are empirically calculated on the training databases of the competition optimising the EER for each of the tasks considered in the assessment.
Finally, the on- and off-line scores (son and soff ) are normalised to the [0,1] range using the tanh-estimators and fused into the final score s given as output by the system based on the weighted sum.
Only the DeepSignDB database provided in the development stage of SVC 2021 was considered for training and evaluating the system.

4.3 TUSUR KIBEVS Team
The TUSUR KIBEVS team is composed of members of the Tomsk State University of Control Systems and Radioelectronics.
The on-line signature verification system presented is based on the use of global features and a gradient boosting classifier. First, a set of 100 global features is extracted for each enrolled and test signatures (Fenrolled and Ftest) based on previous approaches in the literature [17]. Then, a new feature vector F is obtained based on the subtraction of the previous enrolled and test feature vectors: F = |Fenrolled - Ftest|. The resulting feature vector F is introduced to CatBoost [35], a fast, scalable, and high performance Gradient Boosting on Decision Trees (GBDT) that is available as an open source library20.
Regarding the training procedure, only the DeepSignDB database provided in the development stage of SVC 2021 is considered. A total of 10K signature comparisons are randomly selected (5K genuine and 5K forgeries), considering both office (stylus) and mobile (finger) scenarios simultaneously. Forgery comparisons included 2.5K skilled forgeries and 2.5K random forgeries.

4.4 SigStat Team
The SigStat team is composed of members of the Budapest University of Technology and Economics.
Three different on-line signature verification systems were presented. All of them are implemented using the SigStat framework21. First, all signatures go through a preprocessing stage. Time samples with zero pressure are removed from the stylus-based signatures to reduce noise and remove some artifacts. Finally, X, Y, and pressure information are scaled to the [0,1] range and shifted by the average of their values. After this preprocessing stage, the biometric information is used to calculate different distance scores between signature pairs, considering three different approaches.
The first system considers local thresholds to detect whether the query signature is genuine of forgery. In particular, it uses DTW to calculate signature distances and the k-Nearest Neighbours (k-NN) approach to set a lower and an
20 https://catboost.ai/ 21 http://www.sigstat.org

ICDAR 2021 Competition on On-Line Signature Verification

9

upper threshold for each reference signature. During the development stage, the system is tested on the evaluation subset of the DeepSignDB (442 users). The distances and comparisons between the signatures are used to calculate and tune several parameters, selecting the optimal values of the genuine Gth and forgery Fth thresholds and a scaling parameter s for the classification purpose.
For testing, the distance d between the questioned signature (Sq) and the reference signature (Sr) is obtained using DTW. The final score Pq is calculated as follows:

Pq

=

s · Fth - d s · Fth - Gth

(1)

The second system considers global thresholds and is based on 4 classifiers and a linear fusion of them. The first three classifiers take advantage of global features such as the standard deviation of X and Y spatial coordinates, and the signing time duration. The last classifier is based on the DTW distance of signature pairs.
In the development stage, the evaluation subset of DeepSignDB is used to make genuine-genuine and genuine-forgery comparisons. For each comparison, the calculated DTW distance, the device input, and the expected prediction are stored. Next, the comparisons and their results are sorted into four different groups based on expected prediction and input device (genuine finger, genuine stylus, forgery finger, and forgery stylus). For each group some statistical parameters such as the minimum and median values are calculated and used to set the global thresholds for the system.
For testing, the score of the questioned signature Pq is calculated based on the DTW distance of the reference-questioned pair d, the minimum distance of genuine comparisons dgmin and the median distance of forgery comparisons dfmed :

Pq

=

1

-

dfmed - d dfmed - dgmin

(2)

In case of d < dgmin , the score Pq is automatically 0 and when d > dfmed is 1. A similar approach is considered for the remaining three classifiers based on global features.
Finally, the third system extends the set of global features considered in the second system, for example including the DTW distance as feature. Contrary to previous systems, a gradient boosting classifier (XGBoost) is considered for the final prediction.

4.5 MaD-Lab Team
The MaD-Lab team is composed of members of the Machine Learning and Data Analytics Lab (FAU).
The proposed system consists of a 1D CNN trained to classify pairs of signatures as matching or not matching. Features are extracted using a mathematical

10

R. Tolosana et al.

concept called path signature together with statistical features. These features are then used to train an adapted version of ResNet-18 [23].
Regarding the preprocessing stage, the X and Y spatial coordinates are normalised to a [-1, 1] range whereas the pressure information to [0, 1]. In case that no pressure information is available (Task 2, mobile scenario), a vector with all one values is considered.
For the feature extraction, a set of global features related to statistical information is extracted for each signature. Besides, additional features are extracted using the signature path method [6]. This is a mathematical tool that extracts features from paths. It is able to encode linear and non-linear features from the signature path. The path signature method is applied over the raw X and Y spatial coordinates, their first-order derivatives, the perpendicular vector to the segment, and the pressure.
Finally, for classification, a 1D adapted version of the ResNet-18 CNN is considered. To adapt the ResNet-18 image version, every 2D operation is exchanged with a 1D one. Also, a sigmoid activation function is added in the last layer to output values between 0 and 1. Pairs of signatures are presented to the network as two different channels.
Regarding the training parameters of the network, binary cross-entropy is used as the loss function. The network is optimised using stochastic gradient descent (SGD) with a momentum of 0.9 and a learning rate of 0.001. The learning rate is decreased by a factor 0.1 if the accumulated loss in the last epoch is larger than the epoch before. In case the learning rate drops to 10-6, the training process is stopped. Also, if the learning rate does not decrease below 10-6, the training process is stopped after 50 epochs.

4.6 JAIRG Team
The JAIRG team is composed of members of the Jamia Millia Islamia. Three different systems were presented, all of them focused on Task 2 (mobile
scenarios). The on-line signature verification systems considered are based on an ensemble of different deep learning models training with different sets of features. The ensemble is formed using a weighted average of the scores provided by five individual systems. The specific weights to fuse the scores in the ensemble approach are obtained using a Genetic Algorithm (GA) [18].
For the feature extraction, three different approaches are considered: i) a set of 18 time functions related to X and Y spatial coordinates [44], ii) a subset of 40 global features [33], and iii) a set of global features extracted after applying 2D Discrete Wavelet Transform (2D-DWT) over the image of the signatures.
For classification, Bidirectional Gated Recurrent Unit (BGRU) models with a Siamese architecture are considered [39]. Different models are studied varying the number of hidden layers, input features, and training parameters. Finally, an ensemble of the best BGRU models in the evaluation of DeepSignDB is considered, selecting the fusing weight parameters through a GA.

ICDAR 2021 Competition on On-Line Signature Verification

11

Table 1: Final evaluation results of SVC 2021 using the novel SVC2021 EvalDB database acquired for the competition. For each specific task, we include the points achieved by each team depending on the ranking position (gold medal: 3, silver medal: 2, and bronze medal: 1).

Task 1: Office Scenario

Task 2: Mobile Scenario Task 3: Office/Mobile Scenario

Points

Team

EER(%) Points

Team

EER(%) Points

Team

EER(%)

3

DLVC-Lab 3.33% 3

DLVC-Lab 7.41% 3

DLVC-Lab

6.04%

2 TUSUR KIBEVS 6.44% 2

SIG

10.14% 2

SIG

9.96%

1

SIG

7.50% 1

SigStat

13.29% 1 TUSUR KIBEVS 11.42%

0

MaD

9.83% 0 TUSUR KIBEVS 13.39% 0

MaD

14.21%

0

SigStat

11.75% 0 Baseline DTW 14.92% 0

SigStat

14.48%

0 Baseline DTW 13.08% 0

MaD

17.23% 0 Baseline DTW 14.67%

0

JAIRG

18.43

Table 2: Global ranking of SVC 2021.

Position

Team

Total Points

1

DLVC-Lab

9

2

SIG

5

3 TUSUR KIBEVS

3

4

SigStat

1

5

MaD

0

6

JAIRG

0

5 SVC 2021: Experimental Results
This section describes the final evaluation results of the competition using the novel SVC2021 EvalDB database acquired for SVC 2021. It is important to highlight that the winner of SVC 2021 is based only on the results achieved in this stage of the competition as described in Sec. 3.3. Tables 1 and 2 show the results achieved by the participants in each of the three tasks, and the final ranking of SVC 2021 based on the total points, respectively. For completeness, we include in Table 1 a Baseline DTW system (similar to the one described in [31]) based on X, Y spatial coordinates, and their first- and second-order derivatives for a better comparison of the results.
As can be seen in Tables 1 and 2, DLVC-Lab is the winner of SVC 2021 (9 points), followed by SIG (5 points) and TUSUR KIBEVS (3 points). It is important to highlight that the on-line signature verification systems proposed by DLVC-Lab achieve the best results in all three tasks. In particular, an EER absolute improvement of 3.11%, 2.73%, and 3.92% is achieved in each of the tasks compared to the results obtained by the second-position team. Also, it is interesting to compare the best results achieved in each task with the results obtained using traditional approaches in the field (Baseline DTW). Concretely, for each of the tasks, DLVC-Lab achieves relative improvements of 74.54%, 50.34%, and 58.3% EER compared to the Baseline DTW. These results prove the high

12

R. Tolosana et al.

potential of deep learning approaches for the on-line signature verification field, as commented in previous studies [46,45].
Other approaches like the ones presented by the SIG team based on the use of on- and off-line signature information have provided very good results, achieving points in all three tasks (5 total points). The same happens with the system proposed by the TUSUR KIBEVS team based on global features and a gradient boosting classifier (CatBoost [35]), achieving 3 points in total. In particular, the approach presented by TUSUR KIBEVS has outperformed the approach proposed by the SIG team for the office scenario (6.44% vs. 7.50% EER). Nevertheless, much better results are obtained by the SIG team for the mobile and office/mobile scenarios (10.14% and 9.96% EERs) compared to the TUSUR KIBEVS results (13.39% and 11.42% EERs).

6 Conclusions
This paper has described the experimental framework and results of the ICDAR 2021 Competition on On-Line Signature Verification (SVC 2021). The goal of SVC 2021 is to evaluate the limits of on-line signature verification systems on popular scenarios (office/mobile) and writing inputs (stylus/finger) through large-scale public databases. The following tasks are considered in the competition: i) Task 1, analysis of office scenarios using the stylus as input; ii) Task 2, analysis of mobile scenarios using the finger as input; and iii) Task 3, analysis of both office and mobile scenarios simultaneously. In addition, both random and skilled forgeries are simultaneously considered in each task in order to simulate realistic scenarios.
The results achieved in the final evaluation stage of SVC 2021 have proved the high potential of deep learning methods compared to traditional approaches such as Dynamic Time Warping (DTW). In particular, the winner of SVC 2021 has been the DLVC-Lab team that proposed an end-to-end trainable deep softDTW (DSDTW). The results achieved in terms of Equal Error Rates (EER) are 3.33% (Task 1), 7.41% (Task 2), and 6.04% (Task 3). These results prove the challenging conditions of SVC 2021 compared to previous international competitions [49,4,25,29,28], specially for the mobile scenario (Task 2).
SVC 2021 will be established as an on-going competition22, where researchers can play fair by benchmarking easily their systems against the state of the art in an open common platform using large-scale public databases such as DeepSignDB23 and SVC2021 EvalDB24, and standard experimental protocols.
22 https://sites.google.com/view/SVC2021 23 https://github.com/BiDAlab/DeepSignDB 24 https://github.com/BiDAlab/SVC2021_EvalDB

ICDAR 2021 Competition on On-Line Signature Verification

13

Acknowledgments
This work has been supported by projects: PRIMA (H2020-MSCA-ITN-2019860315), TRESPASS-ETN (H2020-MSCA-ITN-2019-860813), BIBECA (RTI2018101248-B-I00 MINECO/FEDER), Orange Labs, and by UAM-Cecabank.

References
1. Ahrabian, K., Babaali, B.: Usage of Autoencoders and Siamese Networks for Online Handwritten Signature Verification. Neural Computing and Applications pp. 1­14 (2018)
2. Alonso-Fernandez, F., Fierrez-Aguilar, J., Ortega-Garcia, J.: Sensor Interoperability and Fusion in Signature Verification: A Case Study using Tablet PC. In: Proc. International Workshop on Biometric Recognition Systems (2005)
3. Antal, M., Szab´o, L.Z., Tordai, T.: Online Signature Verification on MOBISIG Finger-Drawn Signature Corpus. Mobile Information Systems (2018)
4. Blankers, V.L., van den Heuvel, C.E., Franke, K., Vuurpijl, L.: ICDAR 2009 Signature Verification Competition. In: Proc. International Conference on Document Analysis and Recognition (2009)
5. Bouamra, W., Djeddi, C., Nini, B., Diaz, M., Siddiqi, I.: Towards the design of an offline signature verifier based on a small number of genuine samples for training. Expert Systems with Applications 107, 182­195 (2018)
6. Chevyrev, I., Kormilitzin, A.: A Primer on the Signature Method in Machine Learning. arXiv preprint arXiv:1603.03788 (2016)
7. Cuturi, M., Blondel, M.: Soft-DTW: a Differentiable Loss Function for Time-Series. In: Proc. International Conference on Machine Learning (2017)
8. Delgado-Mohatar, O., Fierrez, J., Tolosana, R., Vera-Rodriguez, R.: Biometric Template Storage with Blockchain: A First Look into Cost and Performance Tradeoffs. In: Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRw) (2019)
9. Diaz, M., Ferrer, M.A., Impedovo, D., Malik, M.I., Pirlo, G., Plamondon, R.: A Perspective Analysis of Handwritten Signature Technology. ACM Computing Surveys 51, 1­39 (2019)
10. Diaz, M., Fischer, A., Ferrer, M.A., Plamondon, R.: Dynamic Signature Verification System Based on One Real Signature. IEEE Transactions on Cybernetics 48(1), 228­239 (2016)
11. Diaz, M., Ferrer, M.A., Impedovo, D., Pirlo, G., Vessio, G.: Dynamically enhanced static handwriting representation for parkinson's disease detection. Pattern Recognition Letters 128, 204­210 (2019)
12. Diaz-Cabrera, M., Gomez-Barrero, M., Morales, A., Ferrer, M.A., Galbally, J.: Generation of enhanced synthetic off-line signatures based on real on-line data. In: Proc. Intl. Conf. on Frontiers in Handwriting Recognition (ICFHR). pp. 482­487 (2014)
13. Ellavarason, E., Guest, R., Deravi, F., Sanchez-Riello, R., Corsetti, B.: Touchdynamics based Behavioural Biometrics on Mobile Devices­A Review from a Usability and Performance Perspective. ACM Computing Surveys (CSUR) 53(6), 1­36 (2020)
14. Faundez-Zanuy, M., Fierrez, J., Ferrer, M.A., Diaz, M., Tolosana, R., Plamondon, R.: Handwriting Biometrics: Applications and Future Trends in e-Security and e-Health. Cognitive Computation 12(5), 940­953 (2020)

14

R. Tolosana et al.

15. Ferrer, M.A., Alonso, J.B., Travieso, C.M.: Offline geometric parameters for automatic signature verification using fixed-point arithmetic. IEEE Trans. on Pattern Analysis and Machine Intelligence 27(6), 993­997 (2005)
16. Fierrez, J., Galbally, J., Ortega-Garcia, J., Freire, M.R., Alonso-Fernandez, F., Ramos, D., Toledano, D.T., Gonzalez-Rodriguez, J., Siguenza, J.A., Garrido-Salas, J., et al.: BiosecurID: A Multimodal Biometric Database. Pattern Analysis and Applications 13(2), 235­246 (2010)
17. Fierrez-Aguilar, J., Nanni, L., Lopez-Pen~alba, J., Ortega-Garcia, J., Maltoni, D.: An On-Line Signature Verification System Based on Fusion of Local and Global Information. In: Proc. IAPR Intl. Conf. on Audio- and Video-based Biometric Person Authentication, AVBPA (2005)
18. Galbally, J., Fierrez, J., Freire, M.R., Ortega-Garcia, J.: Feature Selection based on Genetic Algorithms for On-Line Signature Verification. In: Proc. IEEE Workshop on Automatic Identification Advanced Technologies (2007)
19. Galbally, J., Diaz-Cabrera, M., Ferrer, M.A., Gomez-Barrero, M., Morales, A., Fierrez, J.: On-Line Signature Recognition through the Combination of Real Dynamic Data and Synthetically Generated Static Data. Pattern Recognition 48(9), 2921­2934 (2015)
20. Galbally, J., Fierrez, J., Martinez-Diaz, M., Ortega-Garcia, J.: Improving the Enrollment in Dynamic Signature Verification with Synthetic Samples. In: Proc. International Conference on Document Analysis and Recognition (2009)
21. Galbally, J., Gomez-Barrero, M., Ross, A.: Accuracy Evaluation of Handwritten Signature Verification: Rethinking the Random-Skilled Forgeries Dichotomy. In: Proc. IEEE International Joint Conference on Biometrics (IJCB) (2017)
22. Galbally, J., Martinez-Diaz, M., Fierrez, J.: Aging in Biometrics: An Experimental Analysis on On-Line Signature. PLOS ONE 8(7), e69897 (2013)
23. He, K., Zhang, X., Ren, S., Sun, J.: Deep Residual Learning for Image Recognition. In: Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition (2016)
24. Houmani, N., Garcia-Salicetti, S., Dorizzi, B.: A Novel Personal Entropy Measure Confronted to Online Signature Verification Systems Performance. In Proc. International Conference on Biometrics: Theory, Applications and System, BTAS pp. 1­6 (2008)
25. Houmani, N., Mayoue, A., Garcia-Salicetti, S., Dorizzi, B., Khalil, M., Moustafa, M., Abbas, H., Muramatsu, D., Yanikoglu, B., Kholmatov, A., Martinez-Diaz, M., Fierrez, J., Ortega-Garcia, J., Alcob´e, J.R., Fabregas, J., Faundez-Zanuy, M., Pascual-Gaspar, J., Carden~oso-Payo, V., Vivaracho-Pascual, C.: BioSecure Signature Evaluation Campaign (BSEC'2009): Evaluating On-Line Signature Algorithms Depending on the Quality of Signatures. Pattern Recognition 45(3), 993 ­ 1003 (2012)
26. Lai, S., Jin, L.: Recurrent Adaptation Networks for Online Signature Verification. IEEE Trans. on Information Forensics and Security 14(6), 1624­1637 (2018)
27. Lai, S., Jin, L., Lin, L., Zhu, Y., Mao, H.: SynSig2Vec: Learning Representations from Synthetic Dynamic Signatures for Real-World Verification. In: Proc. AAAI Conference on Artificial Intelligence (2020)
28. Malik, M.I., Ahmed, S., Marcelli, A., Pal, U., Blumenstein, M., Alewijns, L., Liwicki, M.: ICDAR2015 Competition on Signature Verification and Writer Identification for On- and Off-Line Skilled Forgeries (SigWIcomp2015). In: Proc. International Conference on Document Analysis and Recognition (ICDAR) (2015)

ICDAR 2021 Competition on On-Line Signature Verification

15

29. Malik, M.I., Liwicki, M., Alewijnse, L., Ohyama, W., Blumenstein, M., Found, B.: ICDAR 2013 Competitions on Signature Verification and Writer Identification for On- and Offline Skilled Forgeries (SigWiComp 2013). In: Proc. International Conference on Document Analysis and Recognition (2013)
30. Martinez-Diaz, M., Fierrez, J., Galbally, J., Ortega-Garcia, J.: Towards Mobile Authentication Using Dynamic Signature Verification: Useful Features and Performance Evaluation. In: Proc. International Conference on Pattern Recognition (2008)
31. Martinez-Diaz, M., Fierrez, J., Hangai, S.: Signature Matching. S.Z. Li and A. Jain (Eds.), Encyclopedia of Biometrics, Springer pp. 1382­1387 (2015)
32. Martinez-Diaz, M., Fierrez, J., Krish, R.P., Galbally, J.: Mobile signature verification: Feature robustness and performance comparison. IET Biometrics 3, 267­277 (2014)
33. Martinez-Diaz, M., Fierrez, J., Krish, R.P., Galbally, J.: Mobile Signature Verification: Feature Robustness and Performance Comparison. IET Biometrics 3(4), 267­277 (2014)
34. Ortega-Garcia, J., Fierrez-Aguilar, J., et al.: MCYT Baseline Corpus: A Bimodal Biometric Database. Proc. IEEE Vision, Image and Signal Processing, Special Issue on Biometrics on the Internet (2003)
35. Prokhorenkova, L., Gusev, G., Vorobev, A., Dorogush, A., Gulin, A.: Catboost: Unbiased Boosting with Categorical Features. In: Proc. Advances in Neural Information Processing Systems (2018)
36. Sae-Bae, N., Memon, N.: Online Signature Verification on Mobile Devices. IEEE Transactions on Information Forensics and Security 9(6), 933­947 (2014)
37. Serdouk, Y., Nemmour, H., Chibani, Y.: Handwritten signature verification using the quad-tree histogram of templates and a support vector-based artificial immune classification. Image and Vision Computing 66, 26­35 (2017)
38. Tolosana, R., Vera-Rodriguez, R., Fierrez, J., Morales, A., Ortega-Garcia, J.: Benchmarking Desktop and Mobile Handwriting across COTS Devices: the eBioSign Biometric Database. PLoS ONE 12(5), 1­17 (2017)
39. Tolosana, R., Vera-Rodriguez, R., Fierrez, J., Ortega-Garcia, J.: Exploring Recurrent Neural Networks for On-Line Handwritten Signature Biometrics. IEEE Access 6, 5128­5138 (2018)
40. Tolosana, R., Vera-Rodriguez, R., Fierrez, J., Ortega-Garcia, J.: Presentation Attacks in Signature Biometrics: Types and Introduction to Attack Detection. S. Marcel, M.S. Nixon, J. Fierrez and N. Evans (Eds.), Handbook of Biometric AntiSpoofing (2nd Edition), Springer (2019)
41. Tolosana, R., Vera-Rodriguez, R., Fierrez, J., Ortega-Garcia, J.: Reducing the Template Ageing Effect in On-Line Signature Biometrics. IET Biometrics 8(6), 422­430 (2019)
42. Tolosana, R., Vera-Rodriguez, R., Fierrez, J., Ortega-Garcia, J.: BioTouchPass2: Touchscreen Password Biometrics Using Time-Aligned Recurrent Neural Networks. IEEE Transactions on Information Forensics and Security 15, 2616­2628 (2020)
43. Tolosana, R., Vera-Rodriguez, R., Guest, R., Fierrez, J., Ortega-Garcia, J.: Exploiting Complexity in Pen- and Touch-based Signature Biometrics. Int. Journal on Document Analysis and Recognition (2020)
44. Tolosana, R., Vera-Rodriguez, R., Ortega-Garcia, J., Fierrez, J.: Preprocessing and Feature Selection for Improved Sensor Interoperability in Online Biometric Signature Verification. IEEE Access 3, 478­489 (2015)

16

R. Tolosana et al.

45. Tolosana, R., Delgado-Santos, P., Perez-Uribe, A., Vera-Rodriguez, R., Fierrez, J., Morales, A.: DeepWriteSYN: On-Line Handwriting Synthesis via Deep Short-Term Representations. In: Proc. AAAI Conference on Artificial Intelligence (2021)
46. Tolosana, R., Vera-Rodriguez, R., Fierrez, J., Ortega-Garcia, J.: DeepSign: Deep On-Line Signature Verification. IEEE Transactions on Biometrics, Behavior, and Identity Science 3(2), 229­239 (2021)
47. Vera-Rodriguez, R., Tolosana, R., Caruana, M., Manzano, G., Gonzalez-Garcia, C., Fierrez, J., Ortega-Garcia, J.: DeepSignCX: Signature Complexity Detection using Recurrent Neural Networks. In: Proc. International Conference on Document Analysis and Recognition (ICDAR) (2019)
48. Wu, X., Kimura, A., Iwana, B.K., Uchida, S., Kashino, K.: Deep Dynamic Time Warping: End-to-End Local Representation Learning for Online Signature Verification. In: Proc. International Conference on Document Analysis and Recognition (ICDAR) (2019)
49. Yeung, D.Y., Chang, H., Xiong, Y., George, S., Kashi, R., Matsumoto, T., Rigoll, G.: SVC2004: First International Signature Verification Competition. In: Proc. Int. Conf. on Biometric Authentication (2004)

