arXiv:2106.01241v1 [math.PR] 2 Jun 2021

Stochastic maximum principle for systems driven by local martingales with spatial parameters
Jian Song and Meng Wang
Research Center for Mathematics and Interdisciplinary Sciences, Shandong University, Qingdao, Shandong, 266237, China; School of Mathematics, Shandong University, Jinan, Shandong, 250100, China
e-mail: txjsong@hotmail.com School of Mathematics, Shandong University, Jinan, Shandong, 250100, China
e-mail: wangmeng22@mail.sdu.edu.cn
Abstract: We consider the stochastic optimal control problem for the dynamical system of stochastic differential equation driven by a local martingale with spatial parameter. Assuming convexity of the control domain, we obtain the stochastic maximum principle as a necessary condition for an optimal control. The linear quadratic (LQ) problem in this setting is also discussed.
AMS 2000 subject classifications: Primary 93E20, 60H10. Keywords and phrases: stochastic optimal control, stochastic maximum principle, local martingale with spatial parameter.
Contents
1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 2 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
2.1 Regularity of M(t, x) with respect to the spatial parameter x . . . . . . . 4 2.2 Stochastic calculus with respect to local martingales with spatial parameter 6 3 Stochastic maximum principle . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 3.1 Formulation of stochastic optimal control problem . . . . . . . . . . . . . . 8 3.2 Variational equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 3.3 Maximum principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 4 A discussion on stochastic LQ problems . . . . . . . . . . . . . . . . . . . . . . 22 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
1. Introduction
This paper concerns the stochastic maximum principle for the dynamical system of stochastic differential equation (SDE) driven by a local martingale with spatial parameter.
1

J. Song and M. Wang/Stochastic maximum principle

2

On a filtered probability space (, F , {Ft}t0, P) satisfying the usual conditions, we consider the following stochastic controlled system

dxu(t) = b t, xu(t), u(t) dt + M dt, xu(t), u(t) , xu (0) = xu0 ,

(1.1)

where b : [0, T ] × Rd × U ×   Rd is an {Ft}t0-adapted process and

M(t, x, u), t  [0, T ] (x,u)Rd×U

is a family of d-dimensional local martingales with parameter (x, u)  Rd × U  Rd × Rk. We assume the control domain U is a convex subset of Rk. Let

T
U[0, T ] = u : [0, T ] ×   U : u is {Ft}t0-adapted and E |u(t)|2 dt < 
0

(1.2)

denote the set of all admissible controls. The cost functional J(u) is given by

T

J (u) = E

f t, xu(t), u(t) dt +  xu(T ) , u  U[0, T ],

0

(1.3)

where f : [0, T ] × Rd × U  R and  : Rd  R are measurable functions. For an optimal control u¯  U[0, T ], i.e., a control u¯ satisfying J(u¯) = infuU[0,T ] J(u),
let x¯ = xu¯, and we call (x¯, u¯) an optimal pair. The goal of this paper is to find a necessary condition which is the so-called stochastic maximum principle for an optimal pair (x¯, u¯) for the optimal control problem (1.1)­(1.3) under proper conditions.
Stochastic differential equations driven by Brownian motion have been well studied, in particular, by the celebrated It^o calculus. The diffusion processes described by SDEs have been playing an important role in the study of stochastic dynamical systems. In order to study various problems concerning stochastic differential equations driven by random vector fields (infinite dimensional random processes), Kunita[12] developed stochastic calculus for semimartingales with spatial parameters and studied SDEs of the following form

t
Xt = x0 + F (ds, Xs),
0

(1.4)

where {F (t, x), t  [0, T ]}xRd is a family of continuous semimartingales with spatial parameter x  Rd. Note that (1.1) is a specific form of (1.4).
On one hand, It^o's SDE is a special case of (1.4) if we set

t

mt

F (t, x) = f0(r, x)dr +

fk(r, x)dBrk,

0

k=1 0

where (B1, . . . , Bm) is a m-dimensional Brownian motion. On the other hand, if F (t, x) is a C-Brownian motion, i.e., for any partition 0  t0 < t1 · · · < tn  T of [0, T ], the increments

J. Song and M. Wang/Stochastic maximum principle

3

F (ti+1, x) - F (ti, x), i = 0, 1, · · · , n are independent, Kunita [11] proved that there exist a sequence of independent Brownian motions {Bk}kN and functions {fk}kN such that

t

t

F (t, x) = f0(r, x)dr +

fk(r, x)dBrk.

0

k=1 0

Thus, the equation (1.4) can be formally viewed as an SDE driven by an infinite dimensional Brownian motion.
Stochastic optimal control problems of dynamical systems driven by a finite dimensional Brownian motion have been well studied. Here, we briefly mention some literature on stochastic maximum principles, which is by no means complete. Bismut[2] obtained the local maximum principle for stochastic optimal control problems with a convex control set. Peng[18] obtained the maximum principle for the general case in which the diffusion coefficient may contain the control variable and the control domain need not be convex. In more recent years, stochastic maximum principles for mean-field control problems were studied in, for instance, Li[13], Buckdahn, Li and Ma[3], Meyer-Brandis, Øksendal and Zhou[17], and for stochastic recursive optimal control problems by employing backward stochastic differential equations (BSDEs) in Chen and Epstein[4], Ji and Zhou[10], Hu[7], etc. For stochastic maximum principles in other various situations, we also refer to, for instance, Hu and Peng[9], Ma and Yong[15], Hu, Ji and Xue[8], Tang[20], Zhou[23], Wu[21], Han, Peng and Wu[6], Yong and Zhou[22], and the references therein.
The present paper concerns the optimal control problem (1.1)­(1.3) driven by a local martingale with spatial parameter. One obvious motivation is that, viewing (1.1) as an SDE driven by infinite-dimensional Brownian motion, it arises naturally when studying financial markets consisting of a large number of stocks. Another motivation comes from the study of an illiquid financial market where the trades of a single large investor can influence market prices. For such a market, Peter and Dietmer[1] employed a family of continuous semimartingales {P (t, v), t  [0, T ]}vR to model the price fluctuations of the risky asset given that the large investor holds a constant stake of v shares in this asset.
We would also like to point out that the existence and uniqueness of the solution to (1.4) was obtained under suitable Lipschitz conditions in Kunita[12], and this result was extended in Liang[14] to the Non-Lipschitz case. The backward doubly stochastic differential equations involving martingales with spatial parameters were studied in Bally and Matoussi[16] and Song, Song and Zhang[19], and the solutions were proved therein to be probabilistic interpretations (nonlinear Feynman-Kac formulae) for corresponding stochastic partial differential equations.
We would like to make a few remarks on our work to close this introduction. In our optimal control problem (1.1)­(1.3), we assume the control domain U  Rk is a convex set, and this enables us to apply the standard variational method to derive the stochastic maximum principle. One key step of the variational method is to derive the variational equation (see eq. (3.6) in Section 3.2) for the generalized SDE (1.1), which involves calculating the derivatives of the local martingale M with respect to the spatial parameters x and u. This is the major difference compared with the classical case, and to obtain the

J. Song and M. Wang/Stochastic maximum principle

4

variational equation we shall employ the stochastic calculus for semimartingales with parameters developed in [12]. Furthermore, the corresponding adjoint equation (see BSDE (3.18) in Section 3.3) contains an extra martingale which is orthogonal to M in order to guarantee the existence and uniqueness of the solution. This is because the BSDE is driven by a general martingale rather than Brownian motion (see El Karoui and Huang [5]). Despite all these differences, we can show that the classical stochastic maximum principle is indeed a special case in our setting.
The rest of this paper is organized as follows. In Section 2, we provide some preliminaries on stochastic calculus for martingales with spatial parameters. In Section 3, we formulate our optimal control problem and prove the stochastic maximum principle which is the major result of this paper. Finally in Section 4, we discuss the linear quadratic optimal control problems (LQ problems) in our setting.
Throughout the article, we use C to denote a generic constant which may vary in different places.

2. Preliminaries

In this section, we collect some preliminaries on regularity results and stochastic calculus

for local martingales with spatial parameter. We refer to [12] for more details. We recall some conventional notations. Denote by Rd the d-dimensional real Euclidean

space. We use the notation x =

 x1

,

·

·

·

,

 xd

for x  Rd. Then for  : Rd  R, x =

 xj



is a row vector, and for  : Rd  Rn, x =
1×d

 xj

i

is an n × d matrix.
n×d

For two vectors u, v  Rd, u, v denotes the scalar product of u and v, and |v| = v, v

means the Euclidean norm of v. We also use ·, · to denote the quadratic covariation of two continuous local martingales. For A, B  Rd×n, we denote the scalar product of M and N by M, N = tr MN T (resp., M = tr[MMT ]), where the superscript  stands

for the transpose of vectors or matrices.

2.1. Regularity of M (t, x) with respect to the spatial parameter x

In this subsection, we shall recall some results on the differentiability of continuous local martingales with respect to spatial parameter.
Let M := {M(t, x), t  [0, T ]}xRd be a family of local martingales with joint quadratic variation (quadratic covariation) on the interval [0, t] given by a.s.

t
M(·, x), M(·, y) t = q(s, x, y)ds, 0

(2.1)

where q(t, x, y) is a predictable process and is called the local characteristic of M.
Let  = (1, . . . , d) be a multi-index and || = 1 + · · · + d. Let d and l be positive integers and m be a nonnegative integer. Denote by Cm(Rd; Rl) or simply Cm the set of m-times continuously differentiable functions f : Rd  Rl. We use the convention that if m = 0, C0(Rd; Rl) is just the set C(Rd; Rl) of continuous functions.

J. Song and M. Wang/Stochastic maximum principle

5

Let K be a subset of Rd. Denote

f

m,K

=

sup
xK

|f (x)| 1 + |x|

+

sup
1||m xK

|Df (x)| ,

where

D

:=

 || (x1)1 ...(xd)d

is the differential

operator. Then Cm

is

a

Fr´echet

space endowed

with seminorms { · m,K : K  Rd is compact}. When K = Rd, we also write · m :=

· m,Rd. We denote by Cbm the set {f  Cm : f m < }.

For a constant   (0, 1], let Cm, denote the set of functions f  Cm such that the

partial derivatives Df with || = m are -Ho¨lder continuous. Similarly, Cm, is a Fr´echet

space under the seminorms,

f

m+,K :=

f

m,K

+

||=m

sup
x,yK x=y

|Df (x) - Df (y)|

|x - y|

,

where K are compact subsets of Rd. Clearly Cm,0 = Cm. We also write · m+,Rd := · m+, and denote by Cbm, the set {f  Cm, : f m+ < }.
We say that a continuous function f (t, x), (t, x)  [0, T ] × Rd belongs to the class Cm,

(or f (t, ·) is a Cm,-valued function) if for each fixed t  [0, T ], f (t, ·) belongs to Cm, and

T 0

f (t, ·) m+,Kdt <  for any compact subset K  Rd.

Similarly, the function space Cm consists of all Rl-valued functions g(x, y) which are

m-times differentiable with respect to each x, y  Rd. Define, for K  Rd,

g

 m,K

:=

sup
x,yK

(1

|g(x, y)| + |x|)(1 +

|y|)

+

1||m

sup
x,yK

DxDyg(x, y)

.

Then Cm is a Fr´echet space equipped with the seminorms {

·

 m,K

,

K



Rd

is

compact}.

For   (0, 1], define

g

 m+,K

=

g

 m,K

+

DxDyg

 ,K

||=m

where

g

 ,K

=

sup
x,y,x,yK

|g(x,

y)

-

g(x, y) - g(x, y) + |x - x| |y - y|

g(x,

y)| .

x=x,y=y

Let Cm, denote the space of functions g such that

g

 m+,K

<  for any compact subset

K, and thus Cm, is a Fr´echet space with the seminorms {

·

 m+,K

,

K



Rd

is

compact}.

We also have Cm,0 = Cm.

When K = Rd, we write

·

 m

:=

·

 m,Rd

and

·

 m+

:=

·

 m+,Rd

.

We

also

define

Cbm := {g  Cm :

g

 m

<

}

and

Cbm,

:=

{g



Cm

:

g

 m+

<

}.

J. Song and M. Wang/Stochastic maximum principle

6

Consider a random field {F (, t, x), t  [0, T ], x  Rd}. If F (, t, x) is m-times continuously differentiable with respect to x for almost all    and for all t  [0, T ], then it is called a Cm-valued process. If furthermore, for almost all , t  F (, t, ·) is a continuous mapping from [0, T ] to Cm, then we call it a continuous Cm-process. In the same way, one can define Cm,-valued process, continuous Cm,-process, Cm-valued process, continuous Cm-process, Cm,-valued process, and continuous Cm,-process.
The following two theorems, which are adopted from Theorem 3.1.2 and Theorem 3.1.3 in [12] respectively, describe the relationship of the spatial regularity between local martingales and their joint quadratic variations.

Theorem 2.1. Let {M(t, x), t  [0, T ]}xRd be a family of continuous local martingales with M(0, x)  0. Assume the joint quadratic variation Q(t, x, y) has a modification of a
continuous Cm,-process for some m  N and   (0, 1]. Then M(t, x) has a modification of continuous Cm,-process for any  < . Furthermore for any ||  m, {DxM(t, x), t  [0, T ]}xRd is a family of continuous local martingales with the joint quadratic variation DxDyQ(t, x, y).
Theorem 2.2. Let {M (t, x), t  [0, T ]}xRd and {N (t, y), t  [0, T ]}yRd be continuous local martingales with values in Cm, for some m  0 and   (0, 1]. Then the joint quadratic
variation has a modification of a continuous Cm,-process for any  < . Furthermore, the
modification satisfies, for ||, ||  m,

DxDy M (·, x), N (·, y) t = DxM (·, x), DyN (·, y) t

(2.2)

for all t  [0, T ].

Fix some nonnegative integer m and   (0, 1]. The local characteristic q(t, x, y) of M is

said to belong to the class Bm,, if q(t, ·, ·) has a modification of a predictable Cm,-valued

process with

T 0

q(t)

 m+,K

dt

<



a.s.

for

any

compact

set

K



Rd.

Furthermore,

if

T 0

q(t)

 m+

dt

<



a.s.,

we

say

that

q(t,

x,

y)

belong

to

the

class

Bbm, ,

and

if

q(t)

 m+

c

holds for all t  [0, T ] and   , we say that q(t, x, y) belongs to the class Bumb,.

2.2. Stochastic calculus with respect to local martingales with spatial parameter

Let {Xt , 0  t  T } be a Rd-valued predictable process such that

T
q(s, Xs, Xs)ds <  a.s.
0

(2.3)

Then the generalized It^o integral Mt(X) :=

t 0

M

(ds,

Xs)

is

well

defined

and

is

a

local

martingale. In particular, if the sample paths of Xt are continuous a.s., the integral can be

approximated by Riemann sums:

t

n-1

Mt(X) =

0

M(ds, Xs) = lim ||0 k=0

M (tk+1, Xtk ) - M (tk, Xtk ) ,

(2.4)

J. Song and M. Wang/Stochastic maximum principle

7

where  is a partition of the interval [0, T ] with || being the maximum length of all subintervals.
Let Y be another predictable process satisfying (2.3). Then Mt(Y ) is also well defined, and the joint quadratic variation of Mt(X) and Mt(Y ) is given by

t
M (X), M (Y ) t = q(s, Xs, Ys)ds a.s.
0

(2.5)

Remark 2.1. Assume M(t, x) = g(x)Wt, where Wt is a standard Brownian motion and g

is a measurable function on Rd such that

T 0

|g(Xs)|2ds

<



a.s.

The

quadratic

variation

of M is

M(·, x), M(·, y) t = g(x)g(y)t

with the local characteristic q(t, x, y) = g(x)g(y). The stochastic integral

t
Mt(X) = M (ds, Xs)
0

now coincides with the classical It^o integral

t 0

g

(Xs)dWs.

Let M(t, x) = (M1(t, x), M2(t, x), . . . , Md(t, x)), t  [0, T ]

be a family of d-

xRd

dimensional continuous local martingales. Here Mi(t, x), 1  i  q are 1-dimensional

continuous local martingales with joint quadratic variation

t
M i(·, x), M j(·, y) t = qij(s, x, y)ds a.s. 0

(2.6)

Denote q(t, x, y) = qij(t, x, y), 1  i, j  d . Then q(t, x, y) is a d×d-matrix-valued process such that qij(t, x, y)=qji(t, y, x) a.s. for all x, y  Rd, t  [0, T ] and 1  i, j  d. Therefore, q(t, x, y) = q(t, y, x). Moreover, q(t, x, x) is a nonnegative-definite symmetric matrix a.s. for all (t, x)  [0, T ] × Rd.
We introduce the following set of stochastic processes,

S2 [0, T ]; Rd :=  : [0, T ] ×   Rd;  is predictable, E sup |(t)|2 <  .
0tT
Consider the following SDE

dXt = b(t, Xt)dt + M (dt, Xt), t  (0, T ], X0 = x0,

(2.7)

where x0  Rd and b : [0, T ] × Rd ×   Rd is an adapted stochastic process.
Definition 1. We say that X = (Xt, t  [0, T ]) adapted to {Ft}t0 is a solution to (2.7) if X satisfies the following integral equation

t

t

Xt = X0 + b(s, Xs)ds + M (ds, Xs)

0

0

for t  [0, T ] almost surely.

J. Song and M. Wang/Stochastic maximum principle

8

Combining Theorem 3.4.1 and Lemma 3.4.3 in [12], we have the following result. Theorem 2.3. Assume that there exists a positive constant K such that

|b(t, x) - b(t, y)|  K |x - y| , |b(t, x)|  K(1 + |x|),
q(t, x, x) - 2q(t, x, y) + q(t, y, y)  K |x - y|2 , q(t, x, y)  K(1 + |x|)(1 + |y|),

hold for all x, y  Rd a.s. Then SDE (2.7) has a unique solution in S2 [0, T ]; Rd . Remark 2.2. If we assume q  Bu0,b1, then q satisfies the conditions on q in Theorem 2.3. Remark 2.3. Consider the following classical SDE

t

t

Xt = x0 + b(s, Xs)ds + (s, Xs)dWs,

0

0

where b(·, x) and (·, x) are adapted processes for each fixed x  Rd taking values in Rd

and Rd×d respectively, and W is a d-dimensional standard Brownian motion. We can write

t 0

M

(ds,

Xs)

=

t 0

(s,

Xs)dWs,

where

M(t, x)

=

t 0



(s,

x)dWs

with

the

joint

quadratic

variation

d

qij(t, x, y) = ik(t, x)jk(t, y).

k=1

If we assume  is uniformly Lipschitz and linear growth as in the classical setting, then q(t, x, y) satisfies the conditions in Theorem 2.3.

3. Stochastic maximum principle
In this section, we will derive the stochastic maximum principle for the optimal control problem associated to (1.1), (1.2) and (1.3).

3.1. Formulation of stochastic optimal control problem
Recall the stochastic controlled system (1.1)
dxu(t) = b t, xu(t), u(t) dt + M dt, xu(t), u(t) , xu (0) = xu0 ,
the set of all admissible controls defined by (1.2)
T
U[0, T ] = u : [0, T ] ×   U : u is {Ft}t0-adapted, E |u(t)|2 dt <  ,
0

J. Song and M. Wang/Stochastic maximum principle

9

and the cost functional given by (1.3)

T

J (u) = E

f t, x(t), u(t) dt +  xu(T ) .

0

In (1.1), M (t, x, u) = (M 1(t, x, u), M 2(t, x, u), . . . , M d(t, x, u)), t  [0, T ] (x,u)Rd×Rk is a family of d-dimensional continuous local martingales, of which the joint quadratic varia-

tion is given by

t
M i(·, x, u), M j(·, y, v) t = qij(s, x, u, y, v)ds.
0

(3.1)

We assume the following conditions.

(H1) The functions b, f ,  are continuous and continuously differentiable in (x, u). More-
over, bx and bu are bounded, and there exists a positive constant K1 such that for all t  [0, T ], (x, u)  Rd+k,

(|fx| + |fu|) (t, x, u) + |x(x)|  K1 (1 + |x| + |u|) .
(H2) For all (x, u), (y, v)  Rd+k, q(t, x, u, y, v) belongs to Bu1,b(Rd+k × Rd+k, Rd×d) for some   (0, 1]. It follows that for x = (x, u)  Rd+k, y = (y, v)  Rd+k, the partial derivative DxDyq(t, x, u, y, v) is uniformly bounded in (x, y).
Note that in particular, Condition (H2) implies q  Bu0,b1, i.e, there exist positive constants K2 and K3 such that

q(t, x, u, y, v)  K2(1 + |x| + |u|)(1 + |y| + |v|); q(t, x, u, y, v) - q(t, x, u, y, v) - q(t, x, u, y, v) + q(t, x, u, y, v) K3 (|x - x| + |u - u|) (|y - y| + |v - v|) .

This (the second inquality) also yields q(t, x, u, x, u) - 2q(t, x, u, y, v) + q(t, y, v, y, v)  2K3(|x - y|2 + |u - v|2).

(3.2)

Therefore, assuming (H1) and (H2), we can apply Theorem 2.3 to SDE (1.1) which consequently has a unique solution xu(t) with E sup0tT |xu(t)|2 <  for each u  U([0, T ]).
Recall that the goal of the optimal control problem is to minimize the cost functional J(u) over the set of admissible controls U[0, T ]. Suppose u  U[0, T ] is an optimal control, i.e.,
J(u) = inf J(u), uU[0,T ]
and x := xu  S2([0, T ]; Rd) is the corresponding solution of the state equation (1.1), then (x,u) is called an optimal pair. For u  U[0, T ] and   [0, 1], define

u(t) = u(t) +  u(t) - u(t) , t  [0, T ].

J. Song and M. Wang/Stochastic maximum principle

10

Then clearly u converges to u in L2( × [0, T ]) as  goes to zero. Recall that the control domain U is convex, and hence u belongs to U[0, T ] for each u  U[0, T ], and we denote by
x(t) := xu(t), t  [0, T ] the corresponding unique solution of (1.1) in S2([0, T ]; Rd).
Lemma 3.1. Assume (H1) and (H2). Let
y(t) = x(t) - x(t).

Then, there exists a positive constant C independent of  such that E |y(t)|2  C2.

(3.3)

Proof. Clearly y(t) is a semimartingale of the following form

t
y(t) = b s, x(s), u(s) - b s, x(s), u(s) ds

0

t

t

+ M ds, x(s), u(s) - M ds, x(s), u(s) .

0

0

Applying It^o's formula to |y(t)|2, we have

t
|y(t)|2 = 2 y(s), b s, x(s), u(s) - b s, x(s), u(s) ds

0

t

t

+ 2 y(s), M ds, x(s), u(s) - 2 y(s), M ds, x(s), u(s)

0

0

d
+

·

·

M i ds, x(s), u(s) - M i ds, x(s), u(s) .

i=1

0

0

t

(3.4)

Here we shall prove that E

t 0

y(s), M

ds, x(s), u(s)

is equal to zero. Since

t
Mt := M ds, x(s), u(s)
0

is a continuous Rd-valued local martingale and y(t) is square integrable, the stochastic

integral

t 0

y(s), dMs

is a local martingale as well. Then it remains to show the local

martingale

t 0

y(s), dMs

is also a martingale. The Burkholder-Davis-Gundy inequality

yields

t

E sup

y(s), M ds, x(s), u(s)

0tT 0

d
C E
j=1

T

1 2

|yj(t)|2qjj t, x(t), u(t), x(t), u(t) dt

0

J. Song and M. Wang/Stochastic maximum principle

11

d
C E
j=1
< ,

sup |yj(t)|2 +
0tT

T
qjj t, x(t), u(t), x(t), u(t) dt
0

where the last inequality follows from (H2) and the integrability of y, x and u. Hence

t
E y(s), M ds, x(s), u(s) = 0.
0
Similarly, one can also show

t
E y(s), M ds, x(s), u(s) = 0.
0
Now taking expectation for both sides of (3.4), we have

E |y(t)|2  CE

t
|y(s)|2 + 2 |u(s) - u(s)|2 ds

0

d

t

+ E qii s, x(s), u(s), x(s), u(s)

i=1

0

- 2qii s, x(s), u(s), x(s), u(s) + qii s, x(s), u(s), x(s), u(s) ds

t

 CE

|y(s)|2 + 2 |u(s) - u(s)|2 ds ,

0

(3.5)

where in the first inequality we use the Lipschitz property of b and the fact 2| x, y |  |x|2 + |y|2, and the second inequality follows from (3.2).
Finally, the desired result (3.3) follows from applying Gronwall's inequality to (3.5).

3.2. Variational equation

Assume Conditions (H1) and (H2). By Theorem 2.1, M(t, x, u) has a modification of a continuous C1,-local martingale for any   (0, ). In particular, the modification, which is denoted by M(t, x, u) again, is differentiable with respect to x and u. Moreover, the partial derivatives xM(t, x, u) and uM(t, x, u) are continuous local martingales.
For notational simplicity, throughout the rest of this article, we write

dM(t) = M(dt) := M dt, x(t), u(t) ,

where M(t) =

t 0

M

ds, x(s), u(s)

is a continuous local martingale. We also take the

following notations,

bx(t) = bx t, x(t), u(t) , bu(t) = bu t, x(t), u(t) ,

J. Song and M. Wang/Stochastic maximum principle

12

xM(dt) = xM dt, x(t), u(t) , uM(dt) = uM dt, x(t), u(t) ,

where





bx(t) = xj bi(t) d×d =  b1x1...(t) · · · b1xd...(t)  ,

bdx1(t) · · · bdxd (t)

and the other matrices bu(t), xM(dt), uM(dt) are defined in the same way. Let x(t)  Rd be the solution to the following SDE

dx(t) = bx(t)x(t) + bu(t) (u(t) - u(t)) dt + xM(dt)x(t) + uM(dt) u(t) - u(t) , x(0) = 0.
(3.6) where the multiplication used in xM(dt)x(t) and uM(dt) u(t) - u(t) is the matrix multiplication, for instance,

d



xM (dt)x(t)

=



xj(t)xj M 1(dt)
j=1
...
d

 .

xj(t)xj M d(dt)

j=1

Now we show that SDE (3.6) has a unique solution in S2([0, T ], Rd). If we denote

~b t, x(t) = bx(t)x(t) + bu(t) u(t) - u(t) ,

and

t

t

t

M~ ds, x(s) = xM(ds)x(s) + uM(ds) u(s) - u(s) ,

0

0

0

i.e.

t

t

M~ (t, x) = xM(ds)x + uM(ds) u(s) - u(s) .

0

0

Then the varational equation (3.6) becomes

dx(t) = ~b(t, x(t))dt + M~ dt, x(t) , x(0) = 0,

(3.7)

which has the same form as (1.1) with the local characteristic q~(t, x, y) of M~ being

q~(t, x, y) ij = x

2qij t, x(t), u(t), x(t), u(t) xy

+ x 2qij t, x(t), u(t), x(t), u(t) xv

y u(t) - u(t)

J. Song and M. Wang/Stochastic maximum principle

13

+ u(t) - u(t)  2qij t, x(t), u(t), x(t), u(t) uy
+ u(t) - u(t)  2qij t, x(t), u(t), x(t), u(t) uv

y u(t) - u(t) .

It can be easily seen that ~b and q~ are uniformly Lipschitz continuous and satisfy the following generalized linear growth condition

|~b(t, x)|  C(|at| + |x|),

q~(t, x, y)  C(1 + |at||x|)(1 + |at||y|),

where {at}t[0,T ] is an adapted square integrable process. Then using the same argument as in Kunita's proof in [12] for Theorem 2.3 yields that SDE (3.6) has a unique solution with

E sup |x(t)|2 < .
0tT

We refer to (3.6) as the variational equation along the optimal pair (x, u), since as we

will

show

in

Proposition

3.1

that

x(t)-x(t) 

converges

to

x(t)

in

L2()

as



goes

to

0.

Set

(t) = x(t) - x(t) - x(t). 

(3.8)

Proposition 3.1. Under assumptions (H1) and (H2), for any fixed T > 0, we have

lim sup E |(t)|2 = 0.
0 0tT

(3.9)

Proof. By the state equation (1.1) and variational equation (3.6), we have

(t) = 1 

t

t

b s, x(s), u(s) - b s, x(s), u(s) ds + M ds, x(s), u(s)

0

0

t

t

- M ds, x(s), u(s) -  bx (s) x(s) + bu (s) (u(s) - u(s)) ds

0

0

t

t

- xM ds, x(s), u(s) x(s) -  uM ds, x(s), u(s) u(s) - u(s) .

0

0

Denote

A(t) = B(dt) =
C(t) = D(dt) =
(t) = (dt) =

1 01 01 01 0

bx t, xM bu t, uM

x(t) + (x(t) - x(t)), u(t) + (u(t) - u(t)) d, dt, x(t) + (x(t) - x(t)), u(t) + (u(t) - u(t)) x(t) + (x(t) - x(t)), u(t) + (u(t) - u(t)) d, dt, x(t) + (x(t) - x(t)), u(t) + (u(t) - u(t))

d, d,

[A(t) - bx(t)] x(t) + [C(t) - bu(t)] (u(t) - u(t)),

[B(dt) - xM(dt)] x(t) + [D(dt) - uM(dt)] (u(t) - u(t)).

J. Song and M. Wang/Stochastic maximum principle

14

Using the fact that for a continuously differentiable function f (x, y) : Rd × Rk  Rd and   Rd,   Rk,

1
fx(x + , y + ) + fy(x + , y + ) d = f (x + , y + ) - f (x, y),
0

we have

d(t) = A(t)(t) + (t) dt + B(dt)(t) + (dt) , (0) = 0.

(3.10)

Therefore,

d

t

t

2

E |(t)|2 = E

Ai(s)(s) + i(s) ds + Bi(ds)(s) + i(ds)

i=1

0

0

d
 CE
i=1

t

2

t

2

Ai(s)(s)ds + Bi(ds)(s)

0

0

t

2

t

2

+ i(s)ds + i (ds)

0

0

T
 C E |(s)|2 ds + J(t) ,
0

where

d
J(t) = E
i=1

t

2

t

2

i(s)ds + i(ds) .

0

0

For simplicity of notations, we denote

x,(t) = x(t) +  x(t) - x(t) , u,(t) = u(t) +  u(t) - u(t) .

(3.11)

Here, the last inequality holds because of the boundedness of bx by assumption (H1) and the following estimation,

d

t

2

E Bi(ds)(s)

i=1

0

d

d

t

1

2

=E

j(s) xj M i ds, x,(s), u,(s) d

i=1 j=1 0

0

dd



CE

i=1 j=1

t

1

2

j(s) xj M i ds, x,(s), u,(s) d

0

0

dd

T



CE

j(s) 2 d

i=1 j=1

0

·1

xj M i dr, x,(r), u,(r) d

00

s

J. Song and M. Wang/Stochastic maximum principle

15

dd

T

=

CE

j(s) 2

i=1 j=1

0

T
CE |(s)|2 ds.
0

Obviously

1 0

1 2qii
0

s, x1,(s), u1,(s), x2,(s), u2,(s) xj yj

d1d2

ds

T

sup E |(t)|2  C E |(s)|2 ds + sup J(t)

0tT

0

0tT

C

T

sup E |(r)|2 ds + sup J(t) .

0 0rs

0tT

By Gronwall's lemma, we can obtain

sup E |(t)|2  CeCT sup J(t) .

0tT

0tT

(3.12)

Now, to obtain the desired result, it suffices to show sup J(t)  0 as   0. Note that
0tT

d

sup J(t) = sup E

0tT

0tT i=1

d

 E sup
i=1 0tT

t

2

t

2

i(s)ds + i (ds)

0

0

t

2

t

2

i(s)ds + i(ds) .

0

0

For the first term on the right-hand side of (3.13), we have

(3.13)

d
E sup
i=1 0tT

t

2

d

T

i(s)ds  C E

i(s) 2 ds

0

i=1

0

d

T

=C E

Ai(s) - bix(s) x(s) + Ci(s) - biu(s) u(s) - u(s) 2 ds

i=1

0

T

CE

A(s) - bx(s) 2 |x(s)|2 + C(s) - bu(s) 2 |u(s) - u(s)|2 ds

0

T1
CE
00

bx(s, x,(s), u,(s)) - bx(s) 2 |x(s)|2

+ bu(s, x,(s), u,(s)) - bu(s) 2 |u(s) - u(s)|2 dds.

Thus, by the dominated convergence theorem, we can conclude

d
lim sup E
0 0tT i=1

t

2

i(s)ds = 0.

0

(3.14)

J. Song and M. Wang/Stochastic maximum principle

16

For the second term on the right-hand side of (3.13),

d
E sup
i=1 0tT

t

2

i (ds)

0

d

t

2

= E sup

Bi(ds) - xM i(ds) x(s) + Di (ds) - uM i(ds) u(s) - u(s)

i=1 0tT 0

d

d

t

2

 CE sup

i=1

0tT

xj(s) Bij(ds) - xj M i(ds)
j=1 0

k

t

2

+

ul(s) - ul(s) Dil(ds) - ul M i(ds)

l=1 0

d

 CE sup

i=1

0tT

d

t

2

xj(s) Bij(ds) - xj M i(ds)

j=1 0

k
+
l=1

t

2

ul(s) - ul(s) Dil(ds) - ul M i(ds)

0

d
C E
i=1

d

T

|xj(s)|2 d

j=1 0

·1

·

xj M i dr, x,(r), u,(r) d - xj M i(dr)

00

0

s

k

T

+

|ul(s) - ul(s)|2 d

l=1 0

·1

·

ul M i dr, x,(r), u,(r) d - ul M i(dr)

.

00

0

s

(3.15)

Note that

·1

·

xj M i dr, x,(r), u,(r) d - xj M i(dr)

00

0

s

s
=
0

1 0

1 2qii
0

s, x1,(r), u1,(r), x2,(r), u2,(r)  xj  yj

d1d2

+ 2qii r, x(r), u(r), x(r), u(r) - 2 1 2qii r, x,(r), u,(r), x(r), u(r) d dr.

xj yj

0

xj yj

Recall

that

in

(H2)

we

assume

q



Bu1,b

which

yields

that

the

partial

derivatives

2q xiyj

of

q are uniformly bounded. Thus, we have

dd

T

E |xj(s)|2 d

i=1 j=1

0

·1

·

xj M i dr, x,(r), u,(r) d - xj M i(dr)

00

0

s

(3.16)

J. Song and M. Wang/Stochastic maximum principle

17

is

finite.

Furthermore,

(H2)

also

implies

the

continuity

of

2q xiyj

,

and

hence

(3.16)

converges

to 0 as   0. The same analysis can be applied to

dk

T

E |ul(s) - ul(s)|2 d

i=1 l=1

0

·1

·

ulM i dr, x,(r), u,(r) d - ul M i(dr) .

00

0

s

Then by the dominated convergence theorem, we have

d
lim E
0 i=1

sup
0tT

t

2

i (ds)

0

= 0.

The proof is complete.

Theorem 3.1. Assume (H1) and (H2). Then we have

lim J(u) - J(u) = E

0



Proof. Denote

T
fx(t)x(t) + fu(t) u(t) - u(t) dt + x x(T ) x(T ) .
0

H

=

1 

-

T
f t, x(t), u(t) - f (t) dt +  x(T ) -  x(T )
0
T
fx(t)x(t) + fu(t) u(t) - u(t) dt + x x(T ) x(T ) .
0

Then to prove the desired result, it suffices to show lim E 0

|H|

= 0.

By Taylor expansion, we have, recalling the definition (3.8) of (t) and using the ab-

breviated notations (3.11) in the last Proposition,

1

1

H =

x x,(T ) d (T ) +

x x,(T ) - x x(T ) d

0

0

T

1

+

fx t, x,(t), u,(t) d (t)dt

0

0

T

1

+

fx t, x,(t), u,(t) - fx(t) d x(t)dt

0

0

T

1

+

fu t, x,(t), u,(t) - fu(t) d u(t) - u(t) dt.

0

0

x(T )

Then H¨older inequality implies

E |H|  E

1

2

x x,(T ) d

1

2

E |(T )|2

1 2

0

J. Song and M. Wang/Stochastic maximum principle

18

+E
T
+
0
T
+
0
T
+
0

1
x x,(T ) - x x(T )
0

2
d

1

2

E |x(T )|2

1 2

E

1

2

fx t, x,(t), u,(t) d

1

2

E |(t)|2

1
2 dt

0

E

1

2

fx t, x,(t), u,(t) - fx(t) d

1

2

E |x(t)|2

1
2 dt

0

1

E

1

2

fu t, x,(t), u,(t) - fu(t) d

2

E |u(t) - u(t)|2

1
2 dt.

0

Noting Proposition 3.1 and that the functions x, fx and fu are continuous and satisfy the

linear growth condition, one can conclude lim E 0

|H|

= 0 by the dominated convergence

theorem.

3.3. Maximum principle

Denote q(t, x, u, y, v) := (qij(x, u, y, v))d×d where qij is given by (3.1). Thus we have q(t, x, u, x, u) = q(t, x, u, x, u). Throughout the rest of this article, we consider both

q := q(t, x, u, y, v) and q := q(t, x, u, y, v) as functions of (t, x, u, y, v), and we shall use

 x

,

 u

,

 y

and

 v

to

denote

the

partial

derivatives

with

respect

to

x, u, y

and

v,

respectively.

Clearly, at any point p0 = (t0, x0, u0, x0, u0), we have

 x

q

(p0)

=

 y

q(p0),

 u

q(p0)

=

 v

q(p0)

(3.17)

Now we consider the adjoint equation which is the following BSDE



dy(t) = - bx (t) y(t) +

 x

tr

z(t)q

t, x(t), u(t), x(t), u(t)

 + fx(t) dt

y(T ) = x

+z(t)dM(t) + dN(t), x(T ) .

(3.18)

where recalling that dM(t) = M dt, x(t), u(t) and (x, u)  Rd+k is an optimal pair for the control problem introduced in Section 3.1.
Denote

T
M2 [0, T ]; Rd :=  : [0, T ] ×   Rd;  is predictable with E |(t)|2 dt <  ,
0

and

Q2 [0, T ]; Rd×d :=  : [0, T ] ×   Rd×d;  is predictable with

J. Song and M. Wang/Stochastic maximum principle

19

T
E tr (t)q t, x(t), u(t), x(t), u(t) (t) dt <  .
0

Then according to [5], there exists a unique triple of stochastic processes

(y, z, N )  M2 [0, T ]; Rd × Q2 [0, T ]; Rd×d × L2

satisfying (3.18), where L2 is the space consisting of all square integrable martingales. Here, N is a Rd-valued square integrable martingale orthogonal to M, i.e., for 1  i, j  d,

·
N i, Mj ds, x(s), u(s) = 0, t  [0, T ].

0

t

Lemma 3.2. Let y, z, N be the adapted solution of (3.18). Then

E y(T ), x(T )

T
=E
0

bu(t)y(t) +

 tr z(t)q t, x(t), u(t), x(t), u(t) u

Proof. Applying It^o formula to y(t), x(t) , we have


, u(t) - u(t) - fx(t), x(t) dt.

E y(T ), x(T )

T

=E dy(t), x(t) + y(t), dx(t) + d y, x t 0

T
=E -
0

bx(t)y(t) +

 tr z(t)q t, x(t), u(t), x(t), u(t) x


+ fx(t), x(t) dt

+ y(t), bx(t)x(t) + bu(t) u(t) - u(t) dt

·

·

·

+ d z(s)dM(s) + N (·), xM(ds)x(s) + uM(ds) u(s) - u(s) ,

0

0

0

t

where we use the notation, for d-dimensional local martingales M = (M1, . . . , Md) and N = (N 1, . . . , N d),

d

(M 1, . . . , M d), (N 1, . . . , N d) t :=

Mj,Nj t .

j=1

Note that it follows from Theorem 2.2 and (3.17),

·

·

d z(s)M(ds), xM(ds)x(s)

0

0

t

=  tr z(t)q t, x(t), u(t), x(t), u(t) y


, x(t) dt

J. Song and M. Wang/Stochastic maximum principle

20

=

 tr z(t)q t, x(t), u(t), x(t), u(t)


, x(t) dt

x

and

·

·

d z(s)M(ds), uM(ds) u(s) - u(s)

0

0

t

=

 tr z(t)q t, x(t), u(t), x(t), u(t)


, u(t) - u(t) dt

v

=

 tr z(t)q t, x(t), u(t), x(t), u(t)


, u(t) - u(t) dt.

u

By the orthogonality of M and N, we also have

·

·

d N, xM(ds)x(s) + uM(ds) u(s) - u(s) = 0.

0

0

t

Combining the above equalities, the desired result can be obtained.

Now by Theorem 3.1, the adjoint equation (3.18) and Lemma 3.2, we have

lim J(u) - J(u)

0



T

=E

bu(t)y(t) +

0

 tr z(t)q t, x(t), u(t), x(t), u(t) u


+ fu(t), u(t) - u(t) dt.

Since u is an optimal control at which J(u) is minimized, we have for almost all t  [0, T ],

bu(t)y(t) +

 tr z(t)q t, x(t), u(t), x(t), u(t) u


+ fu(t), u(t) - u(t)  0 a.s.

(3.19)

We now state our maximum principle in the following theorem, defining the Hamiltonian

as follows

H(t, x, u, y, z) = y(t), b(t, x, u) + tr[z(t)q(t, x, u, x, u)] + f (t, x, u).

(3.20)

Theorem 3.2. Assume conditions (H1)-(H2). Let u be an optimal control associated to the stochastic control problem (1.1)­(1.3) and (x(·), u(·)) be the optimal pair. Then there exists (y, z)  M2([0, T ]; Rd) × Q2([0, T ]; Rd×d) satifying the adjoint equation (3.18) such that for all u  U[0, T ],

Hu t, x(t), u(t), y(t), z(t) u(t) - u(t)  0 a.s.

for

almost

all

t



[0, T ],

where

H

is

given

by

(3.20)

and

Hu

:=

 u

H

.

(3.21)

J. Song and M. Wang/Stochastic maximum principle

21

Remark 3.1. If the control domain U is the whole space Rk, let u(t) = -u(t) + 2u(t) for t  [0, T ], and then u  U[0, T ] = M2([0, T ]; Rk). Now Theorem 3.2 yields

Hu t, x(t), u(t), y(t), z(t) u(t) - u(t)  0 a.s.,

i.e. Hu t, x(t), u(t), y(t), z(t) u(t) - u(t)  0 a.s.

This implies

Hu t, x(t), u(t), y(t), z(t) = 0 a.s.

Remark 3.2. If we assume

t
M(t, x, u) = (s, x, u)dWs,
0

(3.22)

similar to Remark 2.3, the joint quadratic variation of M(·, x, u) and M(·, y, v) is given by

q(t, x, u, y, v) = (t, x, u)(t, y, v),

the controlled system (1.1) is reduced to the classical one:

t

t

xu(t) = xu0 + b s, xu(s), u(s) ds +  s, xu(s), u(s) dWs,

0

0

(3.23)

and the adjoint equation (3.18) becomes



dy(t) =

- bx (t) y(t) +

 x

tr

z(t)

t, x(t), u(t)



t, x(t), u(t)

y(T ) =

+z(t) t, x(t), u(t) dWt + dN (t), x x(T ) ,

 + fx(t) dt (3.24)

where

 x

tr

z(t)

t, x(t), u(t)



t, x(t), u(t)

:=

 x

tr

z(t)

t, y, v



t, x, u

.
(x,u,y,v)=(x(t),u(t),x(t),u(t))

If we assume the filtration is generated by the Brownian motion W , then a mean-zero local martingale N is orthogonal to W if and only if N  0. Denoting z~(t) = z(t) t, x(t), u(t) , the adjoint equation (3.24) can be written as

dy(t) =

- bx (t) y(t) +

 x

tr

z~(t)

t, x(t), u(t)

 + fx(t) dt + z~(t)dWt,

y(T ) = x x(T ) ,

and the variational inequality (3.19) becomes

bu(t)y(t) +

 u

tr

z~(t)

t, x(t), u(t)


+ fu(t), u(t) - u(t)  0 a.s.

from which the classical maximum principle can be otained.

J. Song and M. Wang/Stochastic maximum principle

22

4. A discussion on stochastic LQ problems

In this section, we study the stochastic linear quadratic optimal control problems (LQ problems) in our setting, where the controlled system (1.1) is driven by a local martingale M(t, x, u) which has (x, u) as parameters. To make (1.1) "linear" in terms of (x, u) in the martingale part, we impose the following condition on the local characteristic q of M: for any d × d matrix A and all (x, u), (y, v)  Rd+k,

tr A q(t, x, u, y, v) - q(t, x, u, x, u)

  tr Aq(t, x, u, x, u) , y - x +  tr Aq(t, x, u, x, u) , v - u .

x

u

(4.1)

Now we consider following linear state equation,

dxu(t) = [A(t)xu(t) + B(t)u(t)] dt + M (dt, xu(t), u(t)) , xu (0) = xu0 ,
with the quadratic cost functional

(4.2)

J (u)

=

1 E
2

T 0

Q(t)xu(t), xu(t) + R(t)u(t), u(t) dt + Gxu(T ), xu(T )

.

(4.3)

Here, for t  [0, T ], A(t) and B(t) are matrices with appropriate dimensions, Q(t) and

G are symmetric nonnegative definite matrices, and R(t) is a symmetric positive definite matrix. Here we use U[0, T ] = M2 [0, T ]; Rk to denote the set of admissible controls.
Then the adjoint equation (3.18) becomes

  dy(t) =  y(T ) =

- A(t)y(t) +

 x

tr

z(t)q t, x(t), u(t), x(t), u(t)

+z(t)dM(t) + dN(t),

Gx(T ).

 + Q(t)x(t) dt

(4.4)

The Hamiltonian (3.20) now is

H t, x, u, y, z = A(t)x(t) + B(t)u(t), y(t) + tr z(t)q t, x(t), u(t), x(t), u(t)

+

1 2

Q(t)x(t), x(t)

+

1 2

R(t)u(t), u(t)

+

1 2

G(t)x(T ), x(T )

.

Then it follows from the stochastic maximum principle (Theorem 3.2) that

B(t)y(t) +  tr z(t)q t, x(t), u(t), x(t), u(t)


+ R(t)u(t) = 0

u

(4.5)

holds for a.e. t  [0, T ] almost surely, which is a necessary condition for an optimal pair (x, u). As in the classical situation, now we verify that u satisfying the necessary condition (4.5) is actually an optimal control for the generalized stochastic LQ problems.

J. Song and M. Wang/Stochastic maximum principle

23

Theorem 4.1. If u satisfies (4.5), then u is an optimal control for the generilized linear quadratic problem (4.2)­(4.3).

Proof. To prove the optimality of u, it suffices to show J(u) - J(u)  0 for all u  U[0, T ]. By the nonnegative definiteness of Q(t), R(t) and G, we have

J(u) - J(u)

=12 E

T
Q(t)xu(t), xu(t) - Q(t)x(t), x(t) + R(t)u(t), u(t) - R(t)u(t), u(t) dt
0

+ Gxu(T ), xu(T ) - Gx(T ), x(T )

T

E

Q(t)x(t), xu(t) - x(t) + R(t)u(t), u(t) - u(t) dt + Gx(T ), xu(T ) - x(T ) .

0

(4.6)

Then applying It^o's formula to xu(t) - x(t), y(t) , we have

E Gx(T ), xu(T ) - x(T )

T

=E

-A(t)y(t) -

 tr z(t)q t, x(t), u(t), x(t), u(t)

0

x


- Q(t)x(t), xu(t) - x(t) dt

T
+ E y(t), A(t) xu(t) - x(t) + B(t) u(t) - u(t) dt

0 T
+E d

·

·

·

·

z(s)M(ds) + dN (s), M ds, xu(s), u(s) - M ds, x(s), u(s)

0

0

0

0

0

t

T

=E

-Q(t)x(t), xu(t) - x(t) + B(t)y(t), u(t) - u(t)

0

+ -  tr z(t)q t, x(t), u(t), x(t), u(t)


, xu(t) - x(t)

dt

x

T
=E
0

T
+ E tr z(t) q(t, xu(t), u(t), x(t), u(t)) - q(t, x(t), u(t), x(t), u(t)) dt
0
-Q(t)x(t), xu(t) - x(t)

+ B(t)y(t) +  tr z(t)q t, x(t), u(t), x(t), u(t)


, u(t) - u(t)

dt.

u

(4.7)

where the last equality follows from (4.1). Then the desired inequality follows from (4.5), (4.6) and (4.7):

J(u) - J(u)

J. Song and M. Wang/Stochastic maximum principle

T
E
0
=0.

R(t)u(t) + B(x)y(t) +

 tr z(t)q t, x(t), u(t), x(t), u(t) u

24

, u(t) - u(t) dt

This concludes the proof.
Remark 4.1. If the equality in the condition (4.1) is attained for all (x, u), (y, v)  Rd+k, it can be easily checked that q is linear with respect to x, y, u and v, and hence the classical LQ problem is covered. More precisely, consider the linear form of (3.23):

m

dxu(t) = xu0 + A(t)xu(t) + B(t)u(t) dt +

Cj(t)xu(t) + Dj(t)u(t) dWtj,

j=1

(4.8)

where A, B, Cj, Dj are deterministic matrix-valued functions of suitable dimensions. Then the local characteristic q of

m
M(t, x, u) =
j=1

t

t

Cj(s)xdWsj + Dj(s)udWsj

0

0

is given by

m

q(t, x, u, y, v) =

Cj(t)xyCj(t) + Cj(t)xvDj(t) + Dj(t)uyCj(t) + Dj(t)uvDj(t) ,

j=1

which satisfies (4.1) with equality.

Acknowledgement. The authors would like to thank Prof. Mingshang Hu for helpful discussions. J. Song is partially supported by Shandong University grant 11140089963041.

References
[1] Peter Bank and Dietmar Baum, Hedging and portfolio optimization in financial markets with a large trader, Math. Finance 14 (2004), no. 1, 1­18.MR2030833
[2] Jean-Michel Bismut, An introductory approach to duality in optimal stochastic control, SIAM Rev. 20 (1978), no. 1, 62­78.MR469466
[3] Rainer Buckdahn, Juan Li, and Jin Ma, A stochastic maximum principle for general mean-field systems, Appl. Math. Optim. 74 (2016), no. 3, 507­534.MR3575614
[4] Zengjing Chen and Larry Epstein, Ambiguity, risk, and asset returns in continuous time, Econometrica 70 (2002), no. 4, 1403­1443.MR1929974
[5] N. El Karoui and S.-J. Huang, A general result of existence and uniqueness of backward stochastic differential equations, Backward stochastic differential equations (Paris, 1995­1996), 1997, pp. 27­ 36.MR1752673
[6] Yuecai Han, Shige Peng, and Zhen Wu, Maximum principle for backward doubly stochastic control systems with applications, SIAM J. Control Optim. 48 (2010), no. 7, 4224­4241.MR2665464

J. Song and M. Wang/Stochastic maximum principle

25

[7] Mingshang Hu, Stochastic global maximum principle for optimization with recursive utilities, Probab. Uncertain. Quant. Risk 2 (2017), Paper No. 1, 20.MR3625730
[8] Mingshang Hu, Shaolin Ji, and Xiaole Xue, A global stochastic maximum principle for fully coupled forward-backward stochastic systems, SIAM J. Control Optim. 56 (2018), no. 6, 4309­4335.MR3881235
[9] Ying Hu and Shi Ge Peng, Maximum principle for semilinear stochastic evolution control systems, Stochastics Stochastics Rep. 33 (1990), no. 3-4, 159­180.MR1082339
[10] Shaolin Ji and Xun Yu Zhou, A maximum principle for stochastic optimal control with terminal state constraints, and its applications, Commun. Inf. Syst. 6 (2006), no. 4, 321­338.
[11] H. Kunita, Lectures on stochastic flows and applications, Tata Institute of Fundamental Research Lectures on Mathematics and Physics, vol. 78, Published for the Tata Institute of Fundamental Research, Bombay; by Springer-Verlag, Berlin, 1986.MR867686
[12] Hiroshi Kunita, Stochastic flows and stochastic differential equations, Cambridge Studies in Advanced Mathematics, vol. 24, Cambridge University Press, Cambridge, 1990.MR1070361
[13] Juan Li, Stochastic maximum principle in the mean-field controls, Automatica J. IFAC 48 (2012), no. 2, 366­373.MR2889429
[14] Zongxia Liang, Stochastic differential equations driven by spatial parameters semimartingale with nonLipschitz local characteristic, Potential Anal. 26 (2007), no. 4, 307­322.MR2300335
[15] Jin Ma and Jiongmin Yong, Forward-backward stochastic differential equations and their applications, Lecture Notes in Mathematics, vol. 1702, Springer-Verlag, Berlin, 1999.MR1704232
[16] Anis Matoussi and Michael Scheutzow, Stochastic PDEs driven by nonlinear noise and backward doubly SDEs, J. Theoret. Probab. 15 (2002), no. 1, 1­39.MR1883201
[17] Thilo Meyer-Brandis, Bernt Ø ksendal, and Xun Yu Zhou, A mean-field stochastic maximum principle via Malliavin calculus, Stochastics 84 (2012), no. 5-6, 643­666.MR2995516
[18] Shi Ge Peng, A general stochastic maximum principle for optimal control problems, SIAM J. Control Optim. 28 (1990), no. 4, 966­979.MR1051633
[19] Jian Song, Xiaoming Song, and Qi Zhang, Nonlinear feynman­kac formulas for stochastic partial differential equations with space-time noise, SIAM Journal on Mathematical Analysis 51 (2019), no. 2, 955­990.
[20] Shanjian Tang, The maximum principle for partially observed optimal control of stochastic differential equations, SIAM J. Control Optim. 36 (1998), no. 5, 1596­1617.MR1626880
[21] Zhen Wu, A general maximum principle for optimal control of forward-backward stochastic systems, Automatica J. IFAC 49 (2013), no. 5, 1473­1480.MR3044030
[22] Jiongmin Yong and Xun Yu Zhou, Stochastic controls: Hamiltonian systems and HJB equations, Vol. 43, Springer Science & Business Media, 1999.
[23] Xun Yu Zhou, A unified treatment of maximum principle and dynamic programming in stochastic controls, Stochastics Stochastics Rep. 36 (1991), no. 3-4, 137­161.MR1128491

